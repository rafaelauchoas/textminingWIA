Artificial Intelligence 262 (2018) 15–51Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintClassical logic, argument and dialecticM. D’Agostino a, S. Modgil b,∗a Department of Philosophy, University of Milan, Italyb Department of Informatics, King’s College London, United Kingdoma r t i c l e i n f oa b s t r a c tArticle history:Received 10 July 2017Received in revised form 10 May 2018Accepted 24 May 2018Available online 20 June 2018Keywords:Classical logicArgumentationDialecticRationality postulatesNatural deductionPreferred subtheoriesBounded reasoningA well studied instantiation of Dung’s abstract theory of argumentation yields argumenta-tion-based characterisations of non-monotonic inference over possibly inconsistent sets of classical formulae. This provides for single-agent reasoning in terms of argument and counter-argument, and distributed non-monotonic reasoning in the form of dialogues between computational and/or human agents. However, features of existing formalisations of classical logic argumentation (Cl-Arg) that ensure satisfaction of rationality postulates, preclude applications of Cl-Arg that account for real-world dialectical uses of arguments by resource-bounded agents. This paper formalises dialectical classical logic argumentation that both satisfies these practical desiderata and is provably rational. In contrast to standard approaches to Cl-Arg we: 1) draw an epistemic distinction between an argument’s premises accepted as true, and those assumed true for the sake of argument, so formalising the dialectical move whereby arguments’ premises are shown to be inconsistent, and avoiding the foreign commitment problem that arises in dialogical applications; 2) provide an account of Cl-Arg suitable for real-world use by eschewing the need to check that an argument’s premises are subset minimal and consistent, and identifying a minimal set of assumptions as to the arguments that must be constructed from a set of formulae in order to ensure that the outcome of evaluation is rational. We then illustrate our approach with a natural deduction proof theory for propositional classical logic that allows measurement of the ‘depth’ of an argument, such that the construction of depth-bounded arguments is a tractable problem, and each increase in depth naturally equates with an increase in the inferential capabilities of real-world agents. We also provide a resource-bounded argumentative characterisation of non-monotonic inference as defined by Brewka’s Preferred Subtheories.© 2018 Elsevier B.V. All rights reserved.1. IntroductionArgumentation is a form of reasoning that makes explicit the reasons for the conclusions that are drawn and how conflicts between reasons are resolved. While informal studies of argumentation have a rich tradition, recent years have witnessed intensive study of logic-based models of argumentation and their use in formalising agent reasoning, decision making, and inter-agent dialogue [11,53]. Much of this work builds on Dung’s seminal theory of abstract argumentation [26], and the theory’s provision of argumentative characterisations of nonmonotonic inference. Given a possibly inconsistent set of logical formulae (base) one defines the arguments and a binary attack relation denoting that one argument is a * Corresponding author.E-mail address: sanjay.modgil@kcl.ac.uk (S. Modgil).https://doi.org/10.1016/j.artint.2018.05.0030004-3702/© 2018 Elsevier B.V. All rights reserved.16M. D’Agostino, S. Modgil / Artificial Intelligence 262 (2018) 15–51counter-argument to another. Various developments of Dung’s theory additionally accommodate a preference relation over arguments, which is used to determine which attacks succeed as defeats [1,9,43]. The resulting directed graph of arguments related by defeats, referred to as an argumentation framework (AF), is then said to be ‘instantiated’ by the base. Evaluation of the justified arguments is then based on the intuitive principle that an argument is justified if all its defeaters are themselves defeated by justified arguments. The conclusions of justified arguments identify the ‘argumentation defined’ non-monotonic inferences from the instantiating base.The widespread impact of Dung’s theory is in large part due to this characterisation of non-monotonic inference in terms of the dialectical use of arguments and counter-arguments familiar in everyday reasoning and debate. The theory thus provides foundations for reasoning by individual computational and human agents, and distributed non-monotonic reasoning involving agents resolving conflicts amongst beliefs or deciding amongst alternative actions, or negotiating alloca-tions of resources (e.g., [2,3,8,38,40,44,45,48,58]). These ‘monological’ and ‘dialogical’ applications have motivated the study of rationality postulates for logical instantiations of A F s [15,16], as well as desiderata for practical applications [27,44].This paper focuses on classical logic instantiations of A F s (Cl-Arg) [1,33,43]. Features of the current paradigm have been shown to provide sufficient conditions for satisfaction of the rationality postulates. However, these features preclude satisfaction of practical desiderata that account for modelling real-world uses of arguments by resource-bounded agents. This paper therefore aims at an account of Cl-Arg that satisfies both practical desiderata and the rationality postulates.In Section 2 we review Dung’s theory, Cl-Arg, and the rationality postulates. In Section 3 we argue that monological and dialogical applications of Dung’s theory require formalisation of real-world uses of argument suitable for resource-bounded agents. However, current approaches to Cl-Arg tacitly assume that all arguments defined by a base can be constructed and included in an A F , and that prior to inclusion the legitimacy of each constructed argument is verified by checking that its premises are consistent and not redundant in the strong sense that their conclusion is not entailed by any proper subset of the premises. These assumptions are computationally unfeasible (even in the propositional case) for real-world uses of argument by resource-bounded agents. However, they are proposed as sufficient conditions for satisfaction of the consistency and closure postulates [15] for first order Cl-Arg with preferences [43],1 and of the ‘non-contamination’ postulates [16] for propositional Cl-Arg without preferences. Moreover, checking the legitimacy of arguments prior to inclusion in an A F fails to account for real-world uses of argument. Firstly, in real-world uses the inconsistency of arguments’ premises is typically demonstrated dialectically. Secondly, agents do not interrogate premises for subset minimality. Rather, it is the specific proof-theoretic means for constructing arguments that determines whether or not premises are redundantly used in deriving the conclusion; that is, redundant in the obvious sense that they are syntactically disjoint from the remaining premises and the conclusion.Section 3 then presents a new account of first order Cl-Arg that satisfies practical desiderata. Our approach introduces a new notion of argument that distinguishes amongst the premises accepted as true and those supposed true ‘for the sake of argument’. We can therefore model a ubiquitous feature of dialectical practice, whereby the inconsistency of a set of premises (cid:2) is shown dialectically, by defeats from arguments that claim that a contradiction is implied if one supposes (for the sake of argument) the truth of (cid:2). The distinction also solves the so called foreign commitment problem that arises in dialogical applications when agents are forced to commit to the premises of their interlocutors in order to challenge their arguments [17]. We also drop the computationally demanding checks on the legitimacy of arguments, and define ‘partially instantiated’ A F s that include subsets of the arguments defined by a base. We thus accommodate real-world uses of argument in which agents do not (or may not have sufficient resources to) construct all arguments from a base when determining whether arguments are justified. We show that our account satisfies standard properties of Dung’s theory. We also show that despite dropping the legitimacy checks on arguments and making minimal assumptions as to the arguments defined by a base for inclusion in an A F , the consistency and closure postulates are satisfied (where the latter are adapted to account for the fact that not all defined arguments may be included in the A F ). Moreover, in contrast with [43], these postulates are satisfied assuming any preference relation over arguments.Finally, in Section 3 we identify the notion of an argument whose use of obviously redundant (in the sense described above) premises can be excluded proof-theoretically, in contrast with the use of impractical subset-minimality checks We generalise the ‘non-contamination’ postulates defined for propositional instantiations of A F s in [16], to first order instanti-ations. We then show that despite dropping consistency and subset minimality checks on arguments’ premises, our account of first order Cl-Arg satisfies these postulates under the assumption that preference relations are ‘coherent’.Standard accounts of Cl-Arg typically leave implicit the specific proof theoretic means by which one entails a conclusion from a set of premises. In Section 4 we illustrate use of our dialectical account of argumentation by formalising arguments as intelim trees: a new natural deduction formalism for propositional classical logic [20,21] that allows measurement of the ‘depth’ of an argument such that the construction of depth-bounded arguments is a tractable problem, and each increase in depth naturally equates with an increase in the inferential capabilities of real-world agents. We then show that A F s instantiated by arguments up to any given depth satisfy the rationality postulates and practical desiderata. Furthermore, intelim natural deduction allows for a notion of proof that excludes arguments that use obviously redundant premises. Sec-tion 4 also develops a resource-bounded argumentative characterisation of non-monotonic reasoning in Brewka’s Preferred Subtheories [13].1 Consistency postulates closely related to [15] are also studied for propositional Cl-Arg without preferences in [33].M. D’Agostino, S. Modgil / Artificial Intelligence 262 (2018) 15–5117Section 5 reviews related work; in particular the practical desiderata described in [27], and works [34,61] that exclude arguments that make use of inconsistent formulae so as to ensure satisfaction of [16]’s non-contamination postulates. We then conclude in Section 6 and outline directions for future work.2. Background2.1. Classical logic instantiations of Dung’s argumentation theoryWe first recapitulate Dung’s argumentation theory [26].Definition 1 (Dung framework, conflict free and acceptability). A Dung argumentation framework ( A F ) is a tuple (A, C), where A is a set of arguments and C ⊆ A × A is a binary attack relation defined over A. Let S ⊆ A. Then:• S is conflict free iff ∀ X, Y ∈ S: ( X, Y ) /∈ C.• X ∈ A is acceptable with respect to S iff ∀Y ∈ A such that (Y , X) ∈ C : ∃Z ∈ S such that (Z , Y ) ∈ C.Definition 2 (Dung semantics). Let (A, C) be an A F , and S ⊆ A conflict free. Then S is an admissible extension iff X ∈ Simplies X is acceptable w.r.t. S.• An admissible extension S is a complete extension iff ∀ X ∈ A : X is acceptable w.r.t. S implies X ∈ S;• S is a preferred extension iff it is a set inclusion maximal complete extension;• S is the grounded extension iff it is the set inclusion minimal complete extension;• S is a stable extension iff ∀Y ∈ A, if Y /∈ S then ∃ X ∈ S s.t. ( X, Y ) ∈ C.For T ∈ {complete, preferred, grounded, stable}, X is sceptically, respectively credulously justified under the T semantics if Xbelongs to all, respectively at least one, T extension.Extensions can also be defined in terms of an A F ’s characteristic function F(A,C):F(A,C)(S) = { X| X is acceptable w.r.t. S}, where S ⊆ A.Then for any conflict free S ⊆ A, S is: admissible iff S ⊆ F(A,C)(S); complete iff S = F(A,C)(S) (i.e., S is a fixed point of F(A,C)); grounded iff S is the least fixed point of F(A,C); preferred iff S is a maximal fixed point of F(A,C).Dung explicitly considered ‘instantiations’ of A F s by sets of logical formulae (cid:3), and showed that his theory provides a general framework for various species of non-monotonic reasoning. Given (cid:3) in some logic L, the conclusions of the justified arguments (i.e., the argumentation defined inferences from the instantiating (cid:3)) are exactly those obtained from (cid:3) by the inference relation of the logic. Dung thus provides argumentation based characterisations of logic programming, Reiter’s Default Logic [54] and Pollock’s Inductive Defeasible logic [47].We now review classical logic instantiations of A F s (Cl-Arg). We assume a full first order language L consisting of the usual logical operators ∧, ∨, →, ¬, ∀, ∃, a countable set of individual variables, a (possibly empty) set of function symbols of various arities, where as usual function symbols of arity 0 are interpreted as constant symbols, and a non-empty set of predicate symbols of various arities that includes the 0-ary symbol (cid:2) interpreted as a patently false atomic formula (i.e. one that is always false under any interpretation of the language). A term is an individual variable or constant, or a functional expression f (t1, . . . , tn) where each ti is a term. The wffs of L are defined in the usual way. We shall use lower case Greek letters to refer to arbitrary wffs, and upper case Greek letters, possibly with subscripts, to refer to sets of classical wffs. The language of propositional classical logic is then defined as a sub-language of L that consists only of the usual logical connectives and predicate symbols of arity 0 (i.e., ‘propositional atomic formulae’) (cid:2), a, b, c, . . . , z. We also assume the first order classical consequence relation (cid:10)c , and write Cn((cid:3)) to denote {α|(cid:3) (cid:10)c α}. If Cn((cid:3)) = L we say that (cid:3) is inconsistent; else (cid:3) is consistent. We will make use of the following notions of a complement function and ‘symbols’ in a set of wff.Definition 3 (Complement function). Let φ, ψ be classical wff. Then φ = ψ if φ = ¬ψ ; else φ = ¬φ.Definition 4 (Symbols). Let (cid:3) be a set of classical formulae. Then symbols((cid:3)) = {P |P is either a predicate or function symbolin (cid:3)}.Note that in case (cid:3) is a set of propositional formulae, symbols((cid:3)) consists of all the propositional atomic formulae in (cid:3), whereas if (cid:3) is an arbitrary set of first order formulae, symbols((cid:3)) consists of the predicate, function and constant symbols in (cid:3). By defining symbols in arbitrary sets of first order formulae in this way, we are able to generalise the non-contamination postulates defined for propositional argumentation in [16], to the first order case (see later in Section 2.2).Arguments are defined with respect to a set or ‘base’ B of classical formulae, which we assume does not contain (cid:2); in the sequel (cid:2) will be exclusively used to express that an inconsistency has been reached when constructing an argument.18M. D’Agostino, S. Modgil / Artificial Intelligence 262 (2018) 15–51Fig. 1. i) Solid arrows are undermine attacks. If in addition to undermine attacks that target only premises, one also allowed attacks targeting conclusions, then one would also have the attacks represented by dotted arrows. In ii) and iii), arrows are defeats.Definition 5 (Base). A base B is a finite set of classical wff such that (cid:2) /∈ symbols(B).Definition 6 (Classical logic arguments). [1,12,33] ((cid:3), φ) is an argument defined by a base B, if (cid:3) ⊆ B, and:1. (cid:3) (cid:10)c φ2. Cn((cid:3)) (cid:11)= L ((cid:3) is consistent)3. ¬∃(cid:3)(cid:12) ⊂ (cid:3) such that (cid:3)(cid:12) (cid:10)c φ ((cid:3) is said to be ‘subset minimal’).(cid:3) and φ are respectively referred to as the premises and conclusion of ((cid:3), φ).[33] s tudies propositional classical logic instantiations of A F s, identifying attack relations which ensure satisfaction of postulates closely related to [15]’s consistency postulates. For well-behaved attack relations, the premises of arguments in stable extensions of an A F instantiated by B are simply the maximal (under set inclusion) consistent subsets of B. Hence, [1,43] employ preferences over arguments to enable argumentation based arbitration of conflicts in a classical base. X successfully attacks (defeats) Y iff X attacks Y and Y is not strictly preferred to X . In this way, a defeat relation D ⊆C is defined. The notions of conflict freeness, acceptability of arguments, and extensions are then defined exactly as in Definitions 1 and 2 above (with D replacing C).In [43], a general framework – ASPIC(building on ASPIC [15]) – for instantiating A F s is defined. ASPICidentifies properties of preference relations and logical instantiations of A F s that use strict (deductive) and defeasible inference rules, such that these properties ensure satisfaction of [15]’s consistency and closure rationality postulates. ASPICstudies first order classical logic instantiations in which arguments are built from premises in a given base B, and strict inference rules {φ1, . . . , φn → φ|φ ∈ Cn({φ1, . . . , φn}}. Hence arguments can be represented as in Definition 6, where an argument’s premises entail an argument’s conclusion through application of a single strict inference rule encoding the entailment condition 1 in Definition 6. (Note that the consistency check on an argument’s premises is enforced in [43], whereas the subset minimality check (condition 3 in Definition 6) is not enforced; we comment on this later.) Then:+++Definition 7 (Undermine attacks). ((cid:3), φ) undermine attacks ((cid:3)(cid:12), φ(cid:12)) on ψ if φ = ψ for some ψ ∈ (cid:3)(cid:12).Henceforth we may say that X ‘undermines’ rather than ‘undermine attacks’ Y .Definition 8 (Elementary arguments). Let (cid:3) be a set of classical wff. Then ∀α ∈ (cid:3), ({α}, α) is said to be the ‘elementary argument’ defined by α.Undermine attacks only target premises, and as illustrated in the example below, can equivalently be said to target the ‘elementary arguments’ defined by such premises. Henceforth, we will for the sake of simplicity restrict ourselves to propositional examples.Example 1. Let B be a base {a, b, ¬a ∨ ¬b}. A subset A(cid:12)of the arguments defined by B are shown in Fig. 1i). Undermine attacks are indicated with solid arrows. For example, F attacks A on the premise a (i.e., F attacks A on the elementary argument A), and F attacks H on a (i.e., F attacks H on A). H attacks F on ¬a ∨ ¬b (i.e., on C ), and G attacks H on b (i.e., on B). There are three stable extensions – call them E1, E2 and E3 – such that {G, A, C} ⊆ E1, {F , B, C} ⊆ E2M. D’Agostino, S. Modgil / Artificial Intelligence 262 (2018) 15–5119and {H, A, B} ⊆ E3. The premises (and conclusions) of arguments in each extension correspond to the maximal consistent subsets of B (and their consequences). Hence, for example, ((cid:3), α) ∈ E3 iff α ∈ Cn({a, b}).+ASPIC[43] studies extensions of AFs consisting of arguments, and defeats obtained from attacks and a preference relation. It is then shown in [43] that [15]’s consistency and closure postulates are satisfied only if preferences are used to compare the attacker and the targeted elementary argument (premise).Definition 9 (Defeats). Let (A, C) be an A F where A and C are the arguments and undermine attacks defined by B, and ≺⊆ A × A a strict partial ordering.Let (Y , X) ∈ C, where Y undermine attacks X on ψ (i.e., on X(cid:12) = ({ψ}, ψ)). Then (Y , X) ∈ D (Y defeats X ) if Y ⊀ X.(cid:12)Modgil and Prakken [43] study specific preference relations. For example, given a partial ordering ≤ over B (with < and ≈defined in the usual way), then the ‘Elitist’ preference is defined as:((cid:2), φ) ≺E ((cid:3), θ) iff ∃α ∈ (cid:2) such that ∀β ∈ (cid:3), α < β(Elitist Preference)Example 2. Referring to Fig. 1, suppose ¬a ∨ ¬b < a ≈ b. Then F ≺E A, G ≺E B, and so F does not defeat A, or H or G(on A), and G does not defeat B, or H or F (on B). We obtain the A F with defeats in Fig. 1ii). This A F ’s single stable and preferred extension contains A, B, H . Suppose instead ¬a ∨ ¬b < a. Then only F ≺E A. Now G’s attacks on B, H and Fsucceed as defeats (Fig. 1iii)), and we have two stable and preferred extensions; one containing A, B and H , the other A, Cand G.Refs. [4,43,57] show that one can obtain an argumentation-based characterisation of non-monotonic inference defined by Brewka’s Preferred Subtheories [13]. The latter starts with a totally ordered B partitioned into equivalence classes (B1, . . . , Bn) such that ∀α ∈ Bi, ∀β ∈ B j , i < j iff β < α. A ‘preferred subtheory’ (ps) is obtained by taking a maximal (under set inclusion) consistent subset of B1, maximally extended with a subset of B2, and so on. Multiple ps may be constructed, and [43] shows that with undermine attacks defined over the arguments A defined by B, and the defeats D obtained using the Elitist preference, then each ps corresponds to the premises of arguments in a stable extension of (A, D). Hence, α is classically entailed from a ps iff α is the conclusion of an argument in a stable extension. Then α is a sceptical (credulous) ps-inference iff α is entailed by all (respectively at least one) ps, iff α is a sceptical (credulous) argumentation defined inference (i.e., α is the conclusion of an argument in all, respectively at least one, stable extension(s)). Preferences over arguments can of course be defined by criteria other than the Elitist comparison, and neither are preferences necessarily based on an ordering over B. For example, preferences may be based on the relative importance of values promoted [9], or the goals realised [51], by actions whose justifying rationales are encoded in the arguments. Hence inference relations other than those corresponding to Preferred Subtheories can be defined by classical logic instantiations of AFs with preferences.2.2. Rationality postulates for argumentation+The consistency and closure postulates [15] identify rational properties that one would want to hold of the complete (and hence grounded, preferred and stable) extensions of an instantiated A F . ASPIC [15] also identified sufficient conditions on logical instantiations which ensure satisfaction of these postulates. ASPIC[43] then identified conditions for a broader range of instantiations while additionally accounting for the use of preferences. We now review these postulates as they apply to classical logic argumentation (sufficient conditions for satisfying these postulates will be reviewed in Section 3.2). Note that we will use the notation conc(E) to denote the set of conclusions of arguments in an extension E.+Recall that ASPIC and ASPICis a child node of φ iff φ(cid:12)are general frameworks for defining instantiations of A F s. They assume an arbitrary lan-guage, and arguments are built from premises and (strict/defeasible) inference rules. An argument X is a tree whose root node is the argument’s conclusion, the leaves are its premises, and any non-leaf node is the consequent φ of an inference rule r where φ(cid:12)is a formula in the antecedent of r. Sub-arguments of X are identified as sub-trees of X , and the sub-argument closure postulate states that if X is in a complete extension E then all sub-arguments of X are in E. The standard representation of classical logic arguments consists only of premises paired with the entailed conclusion, applies a single strict inference rule to a set of premises (as described in Sec-and so a classical logic argument in ASPICtion 2.1), yielding a tree whose root node – the argument’s conclusion – has child leaf nodes that are the premises. Thus, the sub-trees are simply the premises in the leaf nodes, and the sub-arguments are the elementary arguments associated with premises. Hence for Cl-Arg2:– Closure under sub-arguments amounts to stating that (in the remainder of this section we assume complete extensions E, E(cid:12) . . .):+2 This rendition of the postulate for classical logic argumentation is due to the ‘schematic’ representation of classical logic arguments as premises paired with a conclusion. As we suggest later, arguments ‘proper’ should include the proof theoretic means whereby one entails the conclusion from the premises, in which case the postulate would then require that all subproofs of a proof be included in a complete extension.20M. D’Agostino, S. Modgil / Artificial Intelligence 262 (2018) 15–51Let X = ((cid:3), φ) ∈ E. If α ∈ (cid:3) then ({α}, α) ∈ E– Closure under strict rules states that if a strict rule with consequent φ can be applied to the conclusions of arguments in a complete extension, then there is an argument in that extension that concludes φ. For Cl-Arg:If conc(E) (cid:10)c φ, then φ ∈ conc(E)– Direct and indirect consistency respectively state that the conclusions of arguments in a complete extension, and their closure under strict rules, do not conflict:∀α, β ∈ conc(E) : α (cid:11)= β and ∀α, β ∈ Cn(conc(E)) : α (cid:11)= βClearly, closure under strict rules and direct consistency imply indirect consistency.More recently, two further rationality postulates were proposed for instantiations of A F s based on propositional lan-guages [16]. We introduce notation that (together with Definition 4) allows us to generalise these postulates to first order instantiations. This generalization can be seen as a modest contribution to the specification of rationality postulates for logic-based argumentation.Notation 3. Let S y denote a set of symbols (recall Definition 4).3 Then B|S y = {α ∈ B|symbols({α}) ⊆ S y}, e.g., {¬a ∨ ¬b, c ∧a}|{a,b} = {¬a ∨ ¬b} and {∀xP (x) → Q (x), ∃z P (z) ∧ R(z)}|{P ,Q } = {∀xP (x) → Q (x)}. Also, B(cid:17)B(cid:12)denotes that symbols(B) ∩symbols(B(cid:12)) = ∅, and B and B(cid:12)are said to be syntactically disjoint. Hence two sets of first order formulae are syntactically disjoint if they share no predicate or function (including constant) symbols (in the propositional case this equates to no shared propositional atomic formulae).– Non-interference states that for any B composed of two independent (i.e., syntactically disjoint) bases B1 and B2, neither should ‘influence’ each other’s argumentation defined inferences. That is to say, given frameworks A F and A Finstantiated respectively by B1 and B1 ∪ B2, where B1(cid:17)B2, then:(cid:12)E is an extension of A F iff there is an extension E(cid:12)of A F(cid:12), where conc(E)|symbols(B1) = conc(E(cid:12))|symbols(B1)– Crash resistance states that there is no ‘contaminating’ B1 that when merged with an unrelated B2, makes the latter irrelevant. That is to say, given frameworks A F and A Finstantiated respectively by B1 and B1 ∪ B2, where B1(cid:17)B2, then:(cid:12){conc(E)|E is an extension of A F } (cid:11)= {conc(E)|E is an extension of A F(cid:12)}3. Dialectical classical logic argumentationIn this section we propose practical desiderata for applications of logical instantiations of Dung’s theory. We also discuss why features of standard approaches to Cl-Arg preclude satisfaction of these desiderata, while at the same time being proposed as sufficient conditions for satisfaction of the rationality postulates. We then formalise a provably rational account of Cl-Arg that satisfies practical desiderata.3.1. Applications and practical desiderataSection 2.1 reviewed the definition of argumentation-based inference relations over logical (in particular classical logic) bases instantiating A F s. Formalisations of ‘instantiated argumentation’ have thus been widely advocated for individual agent reasoning over uncertain and conflicting beliefs (e.g., [15,39]) and decision making in which practical arguments for alterna-tive actions attack each other. In the latter case preferences may be based on the prioritisation of agent goals or the values promoted by actions, and are used to arbitrate amongst these practical arguments (e.g., [3,8,39,51]).Argumentation’s dialectical characterisation of non-monotonic inference provides for generalisation of the above ‘mono-logical’ applications to dialogues involving both computational and human agents. Argumentation-based dialogues enable distributed reasoning amongst agents communicating to persuade one another of the truth of a proposition, decide amongst alternative action options, or negotiate allocations of resources (e.g., [2,38,45,48,58]). Agents submit locutions consisting of arguments and counter-arguments, as well as locutions that implicitly define arguments (e.g., when an agent asserts a claim, and subsequently asserts supporting reasons in response to another agent challenging the claim). The contents of locutions are incrementally included in a public commitment store Bp [60], and agents can submit arguments constructed from their private distinct bases and Bp . At any point in the dialogue, an agent can be said to ‘win the dialogue’ – i.e., successfully establish the dialogue ‘topic’ α which may be a belief or decision option – by countering arguments moved by 3 In [16], the term ‘atoms’ is used instead of symbols. We use the term symbols as we generalise to the first order case.M. D’Agostino, S. Modgil / Artificial Intelligence 262 (2018) 15–5121his interlocutor, effectively showing (under the assumption of ‘logically perfect’ play, as discussed in the example below) that an argument X claiming α is in an admissible extension E of the A F instantiated by Bp [31,48]. These dialogues can be seen as generalising argument game proof theories (e.g. [42]) for monological applications in which an agent shows that a given argument X is justified by successfully countering defeating arguments that the agent can construct from his base (in this case the base, and hence instantiated A F , is assumed fixed rather than being incrementally updated). As in these argument games, dialogue rules regulating legal moves can then be varied to establish that the admissible E is a subset of an extension under different semantics.4Example 4. Consider Example 1. Suppose Ag1 submits A constructed from its own base B1. A is countered by Ag2 submit-ting F , constructed from her base B2. At this point Ag2 is winning the dialogue. However note that A is in an admissible extension of the A F instantiated by the committed premises a, b, ¬a ∨ ¬b. The agents have not played in a ‘logically perfect’ way [48]: Ag1 can construct and submit G.5Another key reason for the impact of Dung’s theory is that evaluation of justified arguments is essentially based on the intuitive and familiar ‘reinstatement principle’ whereby an argument is defended if all its defeaters are themselves defeated. The theory’s compatibility with human modes of reasoning and debate has prompted empirical studies of human uses of the reinstatement principle [52], and development of theories and applications supporting both computational and human reasoning and dialogue [44]. For example, computational models of dialogue for normatively guiding human–human [58] and human–computer [37] dialogue. Hence, real-world modes of dialectical reasoning have been formalised,6 often drawing on insights from philosophical and informal logic. For example, the notion of an ‘audience’ [46] to whom an argument is addressed, has been modelled in extensions to Dung’s theory [10] and in making classical logic arguments more believable [35]. Dung’s theory has also been extended to accommodate other real-world uses of argument, such as arguments supporting arguments (see [40] for a review) and the weighing up of arguments for and against claims (accrual) [41,49]. The above monological and dialogical applications involving computational and/or human agents, warrant consideration of two key practical desiderata for formalisations of argumentation:1. One needs to account for the fact that real-world computational and human agents are resource-bounded.2. Formalisations should be compatible with real-world modes of dialectical reasoning.We now review the extent to which standard features of Cl-Arg preclude satisfaction of these practical desiderata.3.2. Practicality versus rationality+Both [1], [33], and ASPIC’s formalisation of Cl-Arg with preferences [43], assume instantiation of an A F by all argumentsdefined by a base B (which will in general be infinite).7 This is clearly unfeasible for agents with limited resources, given the undecidability of first order classical logic, and that even in the propositional case, deciding whether (cid:3) (cid:10)c α is in general NP-hard, and therefore most likely intractable. Moreover, for each argument constructed, one must not only check consistency of the premises but also that they are subset-minimal; a problem in the second level of the polynomial hierarchy [30], so that in the worst case, for every constructed argument ((cid:3), α) one needs to verify that ∀(cid:3)(cid:12) ⊂ (cid:3), (cid:3)(cid:12) (cid:4)c α. Hence, to accommodate uses by resource-bounded agents, one needs to study the outcomes of argument evaluation assuming A F s that may include only a subset of the arguments defined by a base (which henceforth we refer to as partially instantiatedA F s) and avoid enforcing checks on the legitimacy of arguments before inclusion in an A F .Standard formalisations of Cl-Arg are also incompatible with real-world modes of dialectical reasoning. Firstly, in both monological and dialogical applications in which an agent attempts to establish whether an argument X is justified, agents may simply not construct all arguments defined by a base (be it an individual agent’s base or one incrementally constructed by the dialogue). Agents pragmatically operate on the basis of beliefs or chosen actions that are provisionally acceptable, until later seeking further counter-arguments from a given base, or from a base that is subsequently augmented with newly acquired information. Moreover, it may not be necessary to construct all arguments, given that in argument game proof theories and dialogues, it may suffice to show membership of X in an admissible extension (and hence an extension 4 In [42], variations in rules yield games for membership under grounded, preferred and stable semantics, and a game is proposed for showing sceptical justification under preferred semantics.5 Whether Ag2 is declared the winner depends on the context in which the dialogue model is deployed. One might argue that the onus is on Ag1 to use Ag2’s premise ¬a ∨ ¬b to construct G and counter F . Alternatively, a ‘dialogue manager’ [58] might be deployed to prompt the agents to submit arguments that can be constructed, so ensuring (and possibly enforcing) logically perfect play.6 See the series of workshops www.cmna .info /CMNA14.7 In fact, although not considered in these works, it would suffice (under the assumption that undermine attacks are used) to consider a possibly finite of an infinite A F , such that for each α in a base B one includes the corresponding elementary argument and constructs and includes sub-framework A Fin A Fwill fully determine the status of any argument X = ((cid:3), γ ) defined by B in the infinite A F ; if ∀α ∈ (cid:3), ({α}, α) is justified, then ((cid:3), γ ) is justified. However, this would still be unfeasible for bases of any significant size, and more so given the required checks on the legitimacy of arguments.all arguments that claim α. Then the justified elementary arguments in A F(cid:12)(cid:12)(cid:12)22M. D’Agostino, S. Modgil / Artificial Intelligence 262 (2018) 15–51under other semantics depending on the rules regulating legal moves). In other words, in practice agents are not logically perfect for pragmatic reasons other than that they are resource limited, further testifying to the need for studying partially instantiated A F s.Secondly, establishing whether an individual argument’s premises are consistent, is a special case of establishing the mutual consistency of a set of arguments’ premises, and this is addressed dialectically in real-world dialogues. For example, an often used dialectical move illustrated in the Socratic Elenchus [59] involves showing that an opponent’s arguments collectively make use of inconsistent premises, by constructing an argument from these premises to show that the opponent contradicts himself.Thirdly, accounts of Cl-Arg typically make no reference to specific proof theories for constructing arguments, and so the subset minimality check is imposed as a somewhat blunt instrument for ensuring that no premises are redundant with respect to deriving the argument’s conclusion.8 However, in practice agents do not interrogate premises for subset minimality. Rather, the exclusion of trivially redundant premises is determined by the proof theoretic means used to derive the conclusion from the premises.Fourthly, the exclusive targeting of premises by defeating arguments leads to the so called ‘foreign commitment’ problem in dialogues. Agents may be forced to commit to the truth of interlocutors’ premises for which they have insufficient reasons to believe (see [17] for a concrete example of this problem), and may be subsequently obligated to defend [60]. Consider Example 4. After A is attacked by F , Ag1 cannot counter with A, as attacks cannot target conclusions of arguments. Ag1has to counter F with either G or H , and so commit to Ag2’s premise ¬a ∨ ¬b, respectively b. Suppose then that another agent Ag3 were to attack Ag1’s argument H on B, requiring that Ag1 now defend Ag2’s argument B.We have argued that standard features of Cl-Arg preclude its suitability for use by real-world resource-bounded agents. However, dispensing with these features may result in violation of the rationality postulates. Dropping the consistency check on premises may lead to violation of non-interference and crash-resistance. Consider the syntactically disjoint B1 = {s} and B2 = {p, ¬p}. Assuming all attacks succeed as defeats, then ({s}, s) is in the grounded extension of the A F based on B1. However ∅ is the grounded extension of the A Fevery argument is defeated by arguments ({p, ¬p}, φ) (φ ∈ L),9 and it is well known that the grounded extension is empty if there are no un-defeated arguments. Hence non-interference is violated. Moreover, B2 is contaminating as the grounded extension of the framework based on B2 is ∅, and for any B1 (e.g., B1 = {s}) ∅ is the grounded extension of the A Fbased on B1 ∪ B2. Hence crash resistance is violated. Thus, arguments with inconsistent premises are said to be contaminating as they may attack arguments with syntactically unrelated premises.based on B1 ∪ B2, since in A F(cid:12)(cid:12)(cid:12)As for the subset minimality check, we show in Section 3.7 that allowing non-subset minimal arguments may also result in violation of non-interference. That this is the case is suggested by a result shown for ASPIC’s formulation of Cl-Arg [43]. The authors show that if one were to allow non-subset minimal arguments, then the argumentation defined inferences remain unchanged only if one assumes preference relations that do not strengthen subset minimal arguments by adding (cid:12)premises. That is to say, if A is subset minimal and a non-subset minimal Ais obtained by adding premises to the support (cid:12) ≺ B. (Intuitively, one would not want the strength of an argument to depend on premises that of A, then A ≺ B implies Aare redundantly used in deriving the conclusion.) Indeed, by definition, the Elitist preference (see Section 2) satisfies this property. Thus one can dispense with subset minimality checks. But for preference relations that do not satisfy this property (e.g., the Democratic preference relation studied in [43]), one needs to identify subset minimal arguments and impose this constraint on the preference relation. However this would not be necessary if one can identify a notion of non-redundancy enforceable by proof theories for constructing arguments, and such that the proof theoretic exclusion of arguments that use redundant premises suffices to ensure satisfaction of non-interference and crash resistance independently of the preference relation used. (We revisit this issue in Section 4.)+The rationality postulates are shown to hold [15,43] under the assumption that all arguments defined by a base are in-cluded in an A F . Consider the following example uses of argumentation. Suppose that in attempting to defend an argument, an agent constructs arguments P = ({p, p → ¬q}, ¬q) and Q = ({p, p → q}, q). To ensure that no complete extension E can include P and Q and so violate direct consistency (i.e., that no such irrational defense is possible), one needs to assume that the A F , by virtue of including all defined arguments, includes the arguments X, Y and Z , where:• X = ({p, p → q}, ¬(p → ¬q)) attacks A = ({p → ¬q}, p → ¬q);• Y = ({p, p → ¬q}, ¬(p → q)) attacks B = ({p → q}, p → q);• Z = ({p → q, p → ¬q}, ¬p) attacks C = ({p}, p).Then [43] shows that direct consistency is satisfied under the assumption that the preference relation used is ‘reasonable’ ([43] shows that the Elitist preference relation is reasonable), which in this example means that either X ⊀ A or Y ⊀ B or Z ⊀ C . Now, suppose X ≺ A and Y ≺ B and ≺ is reasonable. Then it must be that Z ⊀ C . This means that the agent cannot 8 This can be contrasted with the weaker condition that all premises are ‘used’ (as opposed to necessary) to obtain the conclusion. There may well be inferences from non-subset minimal sets of premises in which all premises are used, e.g., three applications of modus ponens deriving q from p, p → r, p → q, r → ((p → q) → q).9 In particular ({s}, s) is defeated by an argument ({p, ¬p}, ¬s) that concludes a conclusion syntactically disjoint from the premises via the explosivity of the inconsistent premises.M. D’Agostino, S. Modgil / Artificial Intelligence 262 (2018) 15–5123use P and Q in its attempted defense, since Z will defeat both P and Q on C , and so to defend against Z , will mean including in its attempted defense (i.e., E), some V ∈ E that defeats Z . But any such V must then defeat P ∈ E or Q ∈ E, contradicting the admissibility of E.However, if the agent does not construct all arguments then direct consistency may be violated. For example, resources may not suffice to construct Z ; indeed, in the resource bounded proof theory presented in Section 4, we show that con-struction of Z assumes a higher bound on inferential capabilities than construction of X or Y .Consider also a variation of the above example in which an agent Ag1, in the course of a persuasion dialogue with Ag2, submits arguments that make use of premises p, p → q and p → ¬q (without as yet having constructed and submitted arguments P and Q ). Again, one must assume a reasonable preference relation and that Ag2 can construct from these premises the arguments X , Y and Z , to prevent Ag1 winning the dialogue by forcing Ag1 to move some V that defeats one of Ag1’s own arguments (i.e., Ag2 effectively shows that Ag1 is indirectly inconsistent).We therefore want that the consistency postulates are satisfied by partially instantiated A F s. Moreover, one would in-tuitively expect that having explicitly recognised the inconsistency of premises (e.g., p, p → q, p → ¬q) in an extension E, through construction of arguments with conflicting conclusions (e.g., P , Q ) then this should suffice to ensure that E cannot be rationally accepted as a defendable set of arguments, without needing to assume construction of the additional argu-ments X , Y and Z , or any properties of preference relations.10 Also note that the closure under strict rules postulate also assumes construction of all arguments defined by a base, and so assumes an idealised notion of an agent that is clearly un-realistic in its assumption of logical omniscience [56]. We therefore later modify this closure postulate to account for partially instantiated A F s.Finally, suppose one were to avoid the foreign commitment problem by allowing attacks on conclusions, as indicated (cid:12) = { A, B, C} is now admissible and so a subset of a complete extension E. However by the dotted arrows in Fig. 1. Then EE cannot be closed (neither F , G or H can be in E since E would not then be conflict free). Also E would be indirectly inconsistent.We now formalise an account of Cl-Arg that drops the consistency and subset minimality checks on arguments, for-malises the dialectical demonstration that the premises of an argument, or set of arguments, is inconsistent, and solves the foreign commitment problem. We then show that despite dropping checks on the legitimacy of arguments, and making only minimal assumptions as to the arguments included in a partially instantiated A F , the closure (we will modify closure under strict rules to account for partially instantiated frameworks) and consistency postulates are satisfied assuming anypreference relation over arguments. We also show that the non-interference and contamination postulates, generalised here so as to apply to first order instantiations of A F s, are satisfied under the assumption that preference relations are ‘coherent’.3.3. Dialectical frameworks and acceptabilityWe begin by observing that interlocutors in dialogues typically distinguish their own premises, namely those that they accept as true, from the premises that their opponent commits to and that they want to criticise: “on the basis of the premises I regard to be true, and supposing for the sake of argument what you regard to be true, then I can show some conclusion that contradicts one of your premises” or “I can show that your premises are inconsistent”. This pattern is pervasive in real argumentation practice,11 and motivates a dialectical ‘ontology’ for classical logic arguments that explicitly differentiates between an argument’s assumptions that are premises regarded as true, and those supposed true for the sake of argument (the argument’s suppositions). We also drop the subset minimality and consistency checks. Hence, arguments with inconsistent assumptions can now conclude (cid:2).Definition 10 (Dialectical arguments). X = ((cid:3), (cid:2), α) is a dialectical argument defined by a base B, if ((cid:3) ∪ (cid:2)) ⊆ B, (cid:3) ∩ (cid:2) = ∅, and (cid:3) ∪ (cid:2) (cid:10)c α.If α = (cid:2) then X is said to be a falsum argument. If (cid:2) = ∅ then X is said to be unconditional; else X is conditional. Finally, if (cid:3) = ∅ then X is said to be unassailable (since X cannot then be attacked).Notation 5. Let X = ((cid:3), (cid:2), α) be a dialectical argument, S a set of dialectical arguments.• (cid:3), (cid:2) and α are, respectively, X ’s premises, suppositions and conclusion, denoted prem( X), suppositions( X) and conclusion( X). Also, assumptions( X) denotes prem( X) ∪ suppositions( X).(cid:2)• Generalising the above notation to sets of arguments in the obvious way: prem(S) =(cid:2)X∈S suppositions( X); assumptions(S) = prem(S) ∪ suppositions(S); conclusion(S) =(cid:2)X∈S prem( X); suppositions(S) =X∈S conclusion( X).10 It should be obvious that in real-world argumentation, an agent recognises that he is committing to inconsistent premises the moment he constructs arguments with conflicting conclusions.11 For example, in his Dialogues Concerning Two New Sciences [32], Galileo presents a famous refutation of Aristotle’s theory of falling bodies, in the form of a dialogue between their respective alter-egos Salviati and Simplicio. Salviati demonstrates that the premises of Simplicio’s arguments justifying that heavier bodies fall faster than lighter bodies, lead to a contradiction (i.e., are inconsistent).24M. D’Agostino, S. Modgil / Artificial Intelligence 262 (2018) 15–51Example 6. The dialectical arguments A defined by B = {a, b, ¬a ∨ ¬b} include:A1 = ({a}, ∅, a)F 1 = ({b, ¬a ∨ ¬b}, ∅, ¬a)F 2 = ({b}, {¬a ∨ ¬b}, ¬a)X1 = (∅, {a, b, ¬a ∨ ¬b}, (cid:2))X4 = ({a}, {b, ¬a ∨ ¬b}, (cid:2))B 1 = ({b}, ∅, b)G 1 = ({a, ¬a ∨ ¬b}, ∅, ¬b)G 2 = ({a}, {¬a ∨ ¬b}, ¬b)X2 = ({a, b, ¬a ∨ ¬b}, ∅, c)Z1 = ({a, b, ¬a ∨ ¬b}, ∅, ¬a)C1 = ({¬a ∨ ¬b}, ∅, ¬a ∨ ¬b)H1 = ({a, b}, ∅, ¬(¬a ∨ ¬b))H2 = ({a}, {b}, ¬(¬a ∨ ¬b))X3 = ({b, ¬a ∨ ¬b}, {a}, (cid:2))Z2 = ({b, ¬a ∨ ¬b}, {a}, ¬a)As in [43], we interpret an attack between two arguments as declaratively denoting that the conclusion of the attack-ing argument conflicts with some element in the attacked argument. In particular, we here formalise undermine attacks, denoting that the conclusion of the attacking argument conflicts with an assumption in the attacked argument that is a premise regarded as true. Preferences are then applied to determine the defeat relation, which is interpreted dialectically, in that it denotes the use of the defeating argument as a counter-argument to the defeated argument. We will then utilise the distinction between premises and suppositions when accounting for the dialectical use of defeats in determining the accept-ability of arguments. Intuitively, when an agent constructs a candidate set of admissible arguments S, the agent commits to the premises of arguments in S. Any of these premises can then be supposed true when challenging the acceptability of some Y w.r.t. S. That is to say, when moving some X as a defeat on Y , X ’s suppositions can include premises of anyarguments in S. In turn, when defending Y by some Z ∈ S that defeats X , Z ’s suppositions can include any of X ’s premises. In the latter case, Z supposes for the sake of argument only X ’s premises, since in order to invalidate the admissibility of S, it suffices that only one such defeat by some X on Y ∈ S be undefended (rather than having to construct some candidate that includes X ). Note that a defeat by a falsum argument X = ((cid:3), (cid:2), (cid:2)) on Y indicates that under set of arguments Sthe assumption that the premises (cid:3) is true, the ‘supposed premises’ (i.e., suppositions) (cid:2) in S are inconsistent, and Y in particular is targeted since at least one of the suppositions in (cid:2) is also a premise of Y .(cid:12)Definition 11 (Attacks). Let A be a set of dialectical arguments defined by B. The attack relation C ⊆ A × A is defined as follows. For any X = ((cid:3), (cid:2), α), Y = ((cid:10), (cid:11), β) ∈ A: ( X, Y ) ∈ C (which we may denote by writing X → Y ) iff exactly one of the following holds:• α (cid:11)= (cid:2) and α ∈ (cid:10) (we say that X attacks Y on α, equivalently on Y• α = (cid:2) and (cid:2) ∩ (cid:10) (cid:11)= ∅ (we say that X attacks Y on any φ ∈ (cid:2) ∩ (cid:10), equivalently on any Y(cid:12) = ({α}, ∅, α));(cid:12) = ({φ}, ∅, φ)).(cid:12)Notice that Definition 11 adapts the notion of an undermine attack (Definition 7) in the sense that the premises of an attacked argument are targeted by the attacking argument. We thus also adapt the term ‘elementary argument’ (Definition 8) to refer to Y(recall the comment after Definition 8).(cid:12) = ({α}, ∅, α) in the above definition, and say that X is equivalently said to attack Y on YNotice that by definition, no argument in any set S can be attacked with unconditional falsum arguments ((cid:3), ∅, (cid:2)). Indeed, it would be insensible to allow such attacks, since an agent would be irrationally attacking with an argument that she herself recognises as based on inconsistent premises.12We now define the defeat relation. Firstly, recall that the distinction between (cid:3) and (cid:2) in X = ((cid:3), (cid:2), φ) is an epistemicdistinction between assumptions one commits to as being true and supposed true for the sake of argument. Logically, X is (cid:12) = ((cid:3)(cid:12), (cid:2)(cid:12), φ) where (cid:3)(cid:12) ∪(cid:2)(cid:12) = (cid:3) ∪(cid:2). Hence G 1 and G 2 in Example 6 are logically equivalent. We consider equivalent to any Xthe strength (and hence relative preference) of an argument to be independent of whether assumptions are regarded as true or supposed true. To illustrate, suppose the Elitist preference relation (Section 2.1) defined on the basis of the well known temporal ordering over rules in the legal domain, such that later rules override earlier rules [50]. Suppose such an ordering on conflicting legal rules: a → b < a → ¬b, so that X = ({a, a → b}, ∅, ¬(a → ¬b)) does not defeat Y = ({a → ¬b}, ∅, a →(cid:12)(cid:12) = ({a}, {a → b}, ¬(a → ¬b)) is that in X¬b) since X ≺E Y . In dialogical applications, the only distinction between X and Xa → b is a premise that an interlocutor commits to. (Clearly, no such distinction arises in monological applications.) Thus, (cid:12) ≺E Y ; the fact that a → b is a premise used by an interlocutor one still uses the temporal ordering to conclude that Xis irrelevant to defining the temporal based preference. Henceforth, we therefore assume preferences over arguments are invariant modulo logical equivalence:Definition 12 (Logically equivalent arguments). Let A be the dialectical arguments defined by B and ≺ a strict partial ordering over A. Let X = ((cid:3), (cid:2), α) ∈ A. Then:• [ X] = { X(cid:12) = ((cid:3)(cid:12), (cid:2)(cid:12), α)|(cid:3)(cid:12) ∪ (cid:2)(cid:12) = (cid:3) ∪ (cid:2)}.∀Y , Z ∈ [ X] we say that Y and Z are logically equivalent.• ≺ is said to be invariant modulo logical equivalence (imle) if ∀Y(cid:12) ∈ [Y ], ∀ X(cid:12) ∈ [ X] : Y ≺ X iff Y(cid:12) ≺ X(cid:12).12 Note that allowing such attacks would not pose theoretical problems, since ((cid:3), ∅, (cid:2)) would be counter-attacked by (∅, (cid:3), (cid:2)) which by virtue of having empty premises (and so being un-attackable) would be acceptable w.r.t. any set E.M. D’Agostino, S. Modgil / Artificial Intelligence 262 (2018) 15–5125In the case that X = (∅, (cid:2), (cid:2)) attacks Y , the attack dialectically demonstrates that the proponent of Y commits to the inconsistent premises (cid:2), either because (cid:2) ⊆ prem(Y ), or (cid:2) ⊆ prem(Y ) ∪ prem(E) when challenging the acceptability of Yw.r.t. E. It would clearly be incoherent to use preferences to reject such an attack.Definition 13 (Defeats). Let A be a set of dialectical arguments, C the attack relation, and ≺ a strict partial ordering, over A. Then ∀( X, Y ) ∈ C, ( X, Y ) ∈ D ( X defeats Y ) iff exactly one of the following holds:• X is an argument of the form (∅, (cid:2), (cid:2))13;• ∃α ∈ prem( X) s.t. Y → X on α, and Y ⊀ ({α}, ∅, α).We may write Y ⇒ X to denote (Y , X) ∈ D, and Y (cid:5) X to denote (Y , X) /∈ D.Recall that we are interested in A F s that do not necessarily include all arguments defined by a base. Hence, we define the notion of a dialectical A F that includes any subset of the arguments defined by a base. We will then identify (in this section and in Section 3.7) sufficient conditions on the arguments that must be included in order to ensure satisfaction of the rationality postulates.Definition 14 (Dialectical AF instantiated by a base). Let A be any subset of the set of dialectical arguments defined by a base B, and D the defeat relation defined by the attack relation C, and a strict partial ordering ≺ over A. Then (A, D) is a dialectical A F defined by B and ≺.Recall that the suppositions of an argument X can suppose for the sake of argument the premises of arguments in Swhen challenging the acceptability of some Y w.r.t. S. Then Z ∈ S can suppose the premises of X when defeating X in order to defend Y .Definition 15 (Dung semantics for dialectical A F s). Let (A, D) be a dialectical A F , and S ⊆ A, X, Y ∈ A. Then:• X defeats Y with respect to S, denoted X ⇒S Y , if ( X, Y ) ∈ D and suppositions( X) ⊆ prem(S ∪ {Y }).• S is conflict free if ∀Z , Y ∈ S, Z (cid:5)S Y .• Y is acceptable w.r.t. S if ∀ X s.t. X ⇒S Y ,14 ∃Z ∈ S s.t. Z ⇒{ X} X .• Let S be conflict free. Then S is: an admissible extension iff X ∈ S implies X is acceptable w.r.t. S; a complete extension iff S is admissible and if X is acceptable w.r.t. S then X ∈ S; a preferred extension iff it is a set inclusion maximal complete extension; the grounded extension iff it is the set inclusion minimal complete extension; a stable extension iff ∀Y /∈ S, ∃ X ∈ S s.t. X ⇒{Y } Y .• For T ∈ {complete, preferred, grounded, stable}, X is sceptically, respectively credulously justified under the T semantics if X belongs to all, respectively at least one, T extension.• F(A,D)(S) = { X| X is acceptable w.r.t. S}.Notice that every stable extension of a dialectical A F is a preferred (and hence complete) extension. This result is shown in exactly the same way as for Dung A F s.15In Section 2.1, the argumentation defined inferences are obtained by detaching the conclusions of arguments in exten-sions. However, the extensions of dialectical A F s may contain conditional arguments that suppose the truth of assumptions when used dialectically. Once the extensions are defined, we detach only the conclusions (which we call ‘claims’) of uncon-ditional arguments all of whose assumptions are premises presumed true.Definition 16 (Conclusions (‘claims’) of an extension). Let E be an extension of a dialectical A F . Then claims(E) = {φ|((cid:3), ∅, φ)∈ E}.13 We later consider ‘coherent’ preference relations s.t. ∀α ∈ (cid:2) it cannot be that (∅, (cid:2), (cid:2)) ≺ ({α}, ∅, α). Then, even if we don’t impose that attacks from such arguments always succeed as defeats, coherent preference relations guarantee that such attacks always succeed as a defeat on at least one premise in (cid:2).14 Of course, in practice, when submitting a defeating argument X , one need only reference the set Spremises are referenced by suppositions( X).15 Suppose E is stable, X ∈ E and Y ⇒E X . If Y ∈ E then this contradicts E is conflict free. If Y /∈ E, then Z ∈ E, Z ⇒{Y } Y , and so X is acceptable w.r.t. E. Moreover, if X /∈ E, then X cannot be acceptable w.r.t. E since ∃Y ∈ E s.t. Y ⇒{X} X . Hence if X were acceptable w.r.t. E then Z ∈ E, Z ⇒{Y } Y(cid:12) ⊃ E cannot be conflict and so Z ⇒E Y , contradicting E is conflict free. Hence E is complete and must be maximal complete (i.e., preferred) since any Efree.are the arguments in S whose (cid:12) ⊆ S such that S(cid:12)26M. D’Agostino, S. Modgil / Artificial Intelligence 262 (2018) 15–51Fig. 2. All arguments outside of E defeat A1, G 2 and H2. H2 defeats all arguments outside of E. Hence E is admissible.The dialectical ontology for arguments solves the foreign commitment problem described in Section 3.2. Recall that Ag1submits A and Ag2 counters with F . Then to defend A, Ag1 must defeat F with either G or H , respectively committing to Ag2’s premise b or ¬a ∨ ¬b in Ag2’s argument F . Now suppose the following continuation of Example 6.Example 7. Consider E in Fig. 2. Suppose ∀V ∈ {F 1, Z 1, Z 2, X3}, V ⊀ A1. Then for each V we have that V ⇒E A1, and V ⇒E G 2 on A1, V ⇒E H2 on A1. Suppose also that G 1 ≺ B1, H1 ⊀ C1, and since ≺ is imle, G 2 ≺ B1 and H2 ⊀ C1. Hence ∀V ∈ {F 1, X3, Z 1, Z 2}, G 2 (cid:5){V } V and H2 ⇒{V } V (on C1).E is admissible, despite Ag1 not having to commit to either ¬a ∨ ¬b or b as premises, since G 2 and H2 respectively include ¬a ∨ ¬b and b as suppositions. H 2 defends against each of V ’s defeats on members of E (where H 2’s assumption bis only supposed true for the sake of argument).Remark 8. Suppose a dialectical A F containing exactly the arguments in Example 6. No admissible extension E can contain the arguments X2 and Z 1, both of whose premises are inconsistent, since X1 ⇒E X2 ( X1 ⇒E Z 1), and the unassailable X1cannot be defeated by virtue of its premises being empty. Hence X2 ( Z 1) cannot be defended and so cannot be acceptable w.r.t. E. Moreover, no admissible (and not just complete) extension E can contain arguments with conflicting conclusions. Suppose E contains A1 and F 1. But then X1 ⇒E A1 on A1, and X1 ⇒E F 1 on both B1 and C1, indicating that the proponent of arguments in E has committed to inconsistent premises. No argument in E can defend against X1, and so E cannot be admissible.In contrast with Example 1, which assumes the standard ontology for arguments, Remark 8 highlights that one does not require that all arguments (i.e., G 1 and H1) can be constructed in order to guarantee satisfaction of the direct consistency postulate. It suffices that the assumptions of arguments with conflicting conclusions (i.e., A1 and F 1) be combined to yield a falsum argument (i.e., X1), which we argue is a less demanding, and indeed more intuitive assumption as to the arguments that an agent can construct.In general, if the inconsistency of a set of premises is recognised by constructing at least two arguments from these premises with conflicting conclusions, then this guarantees consistency of extensions under the assumption that one com-bines their assumptions to yield an argument concluding (cid:2). Of course, if either of the two arguments is constructed from inconsistent premises, and this is recognisable through construction of an argument from those premises that concludes (cid:2), then it is not necessary to assume that one combines their assumptions. This points to properties of any set A of arguments in a dialectical A F that suffice to ensure satisfaction of the consistency and closure postulates:Definition 17 (Properties of sets of arguments in dialectical A F s). Let (A, D) be a dialectical A F . We define properties that Amay satisfy:(P1) ∀ X ∈ A: α ∈ prem( X) implies ({α}, ∅, α) ∈ A.(cid:12) ∈ [ X] implies X(P2) ∀ X ∈ A: X(P3) If ((cid:3), ∅, α) ∈ A and ((cid:2), ∅, α) ∈ A, then either ((cid:3), ∅, (cid:2)) ∈ A or ((cid:2), ∅, (cid:2)) ∈ A or ((cid:3) ∪ (cid:2), ∅, (cid:2)) ∈ A.(cid:12) ∈ A.We believe that requiring that A satisfies P1, P2 and P3 would impose minimally restrictive assumptions as to the arguments that agents should be able to construct. P3 is discussed above. P1 is a kind of reflexivity property, and states that for any premise α of an argument in A, the corresponding ‘elementary’ argument ({α}, ∅, α) is also in A. P2 says that if X ∈ A, then A contains all logically equivalent arguments that are distinct only in the epistemic distinction between premises and suppositions. Note that P2 does not imply use of additional resources in constructing arguments. Rather, given a constructed argument ((cid:3), (cid:2), α), the practical meaning of P2 is that any differential labelling of the assumptions in (cid:3) ∪ (cid:2)is accessible to an agent when using the argument dialectically. Of course there is a distinct issue with respect to the computational effort required to list all logically equivalent arguments (which for each given argument are exponential in the number of assumptions). However, we suggest that in practice this will not be necessary. An interesting topic for future work would be to identify (given an A F instantiated by dialectical arguments moved in monological and dialogical applications) the minimal set of logically equivalent arguments that need to be listed to ensure satisfaction of the rationality postulates (e.g., given arguments ((cid:3), (cid:2), α) and ((cid:3)(cid:12), (cid:2)(cid:12), ¬α), it may suffice to list only ((cid:2) ∪ (cid:2)(cid:12), (cid:3) ∪ (cid:3)(cid:12), (cid:2))).M. D’Agostino, S. Modgil / Artificial Intelligence 262 (2018) 15–51273.4. Closure and consistency postulatesWe prove closure and consistency postulates for dialectical A F s that include any subset of the arguments defined by a base, subject to the above assumptions P1–P3. We first show the following lemmas:Lemma 9. Let E be a complete extension of a dialectical A F (A, D) where A satisfies P1. Then ∀ X ∈ A such that prem( X) ⊆ prem(E), X ∈ E.(cid:12)(cid:12)(cid:12)(cid:12) ∈ E s.t. Y ⇒E X(cid:12) = ({α}, ∅, α), Y = ((cid:3), (cid:2), φ) (φ = (cid:2) or φ = α).16 Since prem( X) ⊆ prem(E), then (cid:2) ⊆ prem(E). . Since E is complete ∃Z ∈ E s.t. Z ⇒{Y } Y . Hence X is acceptable Proof. By definition, a complete extension E is an admissible (and hence conflict free) set such that all arguments acceptable w.r.t. E are in E. Hence we need to show that X is acceptable w.r.t. E and E ∪ { X} is conflict free.– Suppose Y ⇒E X on some XSince α ∈ prem( X) ⊆ prem(E), ∃ Xw.r.t. E.– Suppose for contradiction that E ∪ { X} is not conflict free. Then either:1. Y ∈ E, Z ∈ E, Y (cid:11)= X, Z (cid:11)= X , and Y ⇒E∪{ X} Z . Hence Y ⇒E Z , contradicting E is complete and so conflict free.2. Y ∈ E and Y ⇒E∪{ X} X . Hence Y ⇒E X . Since X acceptable w.r.t. E, ∃Z ∈ E, Z ⇒{Y } Y . Hence Z ⇒E Y , contradicting E is complete and so conflict free.3. Y ∈ E and X ⇒E∪{ X} Y . Hence X ⇒E Y . Since E is complete, ∃Z ∈ E, Z ⇒{ X} X . Hence Z ⇒E X . Since X is acceptable w.r.t. E, ∃W ∈ E, W ⇒{ Z } Z and so W ⇒E Z , contradicting E is complete and so conflict free.4. X ⇒E∪{ X} X . Hence X ⇒E X . Since X acceptable w.r.t. E, ∃Y ∈ E, Y ⇒{ X} X . Hence Y ⇒E X , and so ∃Z ∈ E, Z ⇒{Y } Y and Z ⇒E Y , contradicting E is complete and so conflict free. (cid:2)on X(cid:12)Recall that for Cl-Arg, the sub-argument postulate states that if X is in a complete extension E then all the elementary arguments associated with its premises are in E.Theorem 10 (Sub-argument closure). Let E be a complete extension of a dialectical A F (A, D) such that A satisfies P1. Let X ∈ E. Then if α ∈ prem( X) then ({α}, ∅, α) ∈ E.Proof. By P1, X(cid:12) = ({α}, ∅, α) ∈ A. Since X ∈ E, prem( X(cid:12)) ⊆ prem(E). By Lemma 9, X(cid:12) ∈ E. (cid:2)Direct consistency (see Section 2.2) states that no arguments in a complete extension have conflicting conclusions. Since we allow arguments concluding (cid:2), we show that claims(E) (recall that these are the conclusions of unconditional arguments that make no suppositions for the sake of argument) neither contains (cid:2) nor conflicting conclusions, for the more general case of admissible extensions.Theorem 11 (Direct consistency). Let E be an admissible extension of a dialectical A F (A, D). If A satisfies P1, P2 and P3, then ∀α, β ∈ claims(E), α (cid:11)= (cid:2) and β (cid:11)= α.(cid:12)is an unassailable falsum argument, every such attack succeeds as a defeat. Moreover, XProof. Case 1: Suppose X = ((cid:3), ∅, (cid:2)) ∈ E. By P2, Xthat since Xcontradicting X is acceptable w.r.t. E.(cid:12) = ((cid:2), ∅, (cid:2)) ∈ A, then (given P2) either Case 2: X, Y ∈ E, X = ((cid:3), ∅, α), Y = ((cid:2), ∅, α). If either X(∅, (cid:3), (cid:2)) ⇒E X or (∅, (cid:2), (cid:2)) ⇒E Y , contradicting X (Y ) is acceptable w.r.t. E as in case 1). Else, by P3, Z = ((cid:3) ∪ (cid:2), ∅, (cid:2)) ∈A. By P2, Zis unassailable, this contradicts X, Y acceptable w.r.t. E. (cid:2)attacks X on every α ∈ (cid:3). Recall (Definition 13) cannot be defeated, (cid:12) = (∅, (cid:3) ∪ (cid:2), (cid:2)) ∈ A. Since (cid:3) ∪ (cid:2) ⊆ prem(E), Z(cid:12) ⇒E Y (on all γ ∈ (cid:2)). Since Z(cid:12) ⇒E X (on all δ ∈ (cid:3)) and Z(cid:12) = ((cid:3), ∅, (cid:2)) ∈ A or Y(cid:12) = (∅, (cid:3), (cid:2)) ∈ A. X(cid:12)(cid:12)(cid:12)Satisfaction of direct consistency for admissible (and not just complete) extensions is a desirable property for both monological and dialogical applications. As discussed in Sections 3.1 (see also footnote 4) and 3.2, in both application types it often suffices that an agent identify an admissible extension E containing the argument X whose status is to be established. Clearly, agents do not then proceed to include all arguments that can be defended by E so as to define a complete extension. Hence one would want that direct consistency holds for admissible extensions. Of course, in real-world applications an agent may simply refrain from submitting any arguments with conflicting conclusions, whereas an agent may unwittingly commit to arguments whose premises are mutually inconsistent (e.g., the example in Section 3.2 in which Ag1 commits to premises p, p → q and p → ¬q, and the dialogue referred to in footnote 11). However, no admissible Ecan contain arguments with premises whose inconsistency is recognised by the construction (from those premises) of an argument concluding (cid:2), or a pair of arguments with directly conflicting conclusions.16 Henceforth we may simply write φ, leaving it to the reader to interpret φ as denoting (cid:2) or α.28M. D’Agostino, S. Modgil / Artificial Intelligence 262 (2018) 15–51Theorem 12 (Premise consistency). Let (A, D) be a dialectical A F such that A satisfies P2. If for some (cid:3) ⊆ prem(E) : ((cid:3), ∅, (cid:2)) ∈ A, then E cannot be an admissible extension of (A, D).Proof. Suppose for contradiction that ∃(cid:3) ⊆ prem(E) s.t. ((cid:3), ∅, (cid:2)) ∈ A, and E is admissible. By P2, Z = (∅, (cid:3), (cid:2)) ∈ A, and so for all β ∈ (cid:3), ∃ X ∈ E s.t. β ∈ prem( X) and Z ⇒E X , contradicting E is admissible. (cid:2)Note of course that under the assumption that P3 holds, a sufficient condition for satisfaction of premise consistency would be that for some (cid:3), (cid:2) ⊆ prem(E): ∃((cid:3), ∅, α) ∈ A and ∃((cid:2), ∅, ¬α) ∈ A.We now adapt the closure under strict rules postulate to account for the fact that it may be that not all arguments defined by a base are included in a dialectical A F . In general, even though claims(E) (cid:10)c α, it may not be that there exists an X ∈ E such that X concludes α, given that agents are not logically omniscient and do not construct all arguments from (cid:12) ⊆ E, and there is an a base (e.g., because of insufficient resources). However, if α is entailed by the claims of arguments Eargument X that, from the premises in E, concludes α, then X is in E.(cid:12)Theorem 13 (Closure under strict rules for dialectical A F s). Let E be a complete extension of (A, D), where A satisfies P1. Let Eand claims(E)(cid:12) (cid:10)c α. If there exists an X = ((cid:3), ∅, α) ∈ A such that (cid:3) = prem(E(cid:12)), then X ∈ E.(cid:12) ⊆ EProof. Follows immediately from Lemma 9. (cid:2)We have shown satisfaction of the consistency and (modified) closure postulates under the assumption that agents only construct possibly finite subsets of the set of all arguments defined by a base (provided the subsets satisfy P1, P2 and P3). framework [43], the postulates have been shown to hold without making any assumptions as to Moreover, unlike the ASPICthe properties of the preference relation used to determine whether attacks succeed as defeats (recall that ASPICassumes ‘reasonable’ preference relations that satisfy a number of properties; see Section 3.2), and both consistency of conclusions and premises is shown for admissible extensions.++3.5. The fundamental lemma and monotonicity of the characteristic functionTwo key properties of Dung AFs are the Fundamental Lemma (FL) [26, p. 7] – if X and Xare acceptable w.r.t. an (cid:12)is acceptable w.r.t. E ∪ { X} – and monotonicity of an A F ’s characteristic admissible E, then E ∪ { X} is admissible and X(cid:12)). The FL implies that any admissible extension is a subset of a preferred implies F (E) ⊆ F (Efunction [26, p. 9]: E ⊆ Eextension. Monotonicity of F allows one to show that F has a unique least fixed point that is the grounded extension, and that iterating F (starting with ∅) yields the grounded extension.(cid:12)(cid:12)Both these properties can straightforwardly be shown for Dung A F s, since when determining the acceptability of Xw.r.t. E, the defeats on X are independent of the set E under consideration. However for dialectical A F s, the defeats on Xw.r.t. E may be a subset of the defeats on X w.r.t. Ecan now be suppositions in arguments that did not defeat X w.r.t. E). However, these properties can be shown by focusing on sets of arguments that are ‘epistemically maximal’. Intuitively, if X = ((cid:3), (cid:2), α) ∈ E, and some supposition β ∈ (cid:2) is also a premise of an argument in E, then commitment to the truth of the premise β also implies a commitment to the logically equivalent X(cid:12) ⊃ E (since the additional premises committed to in E(cid:12) = ((cid:3) ∪ {β}, (cid:2) \ {β}, α).(cid:12)Definition 18 (Epistemically maximal sets). Let (A, D) be a dialectical A F . Then E ⊆ A is epistemically maximal (em) iff:If X = ((cid:3), (cid:2), α) ∈ E, (cid:2)(cid:12) ⊆ ((cid:2) ∩ prem(E)), then X(cid:12) = ((cid:3) ∪ (cid:2)(cid:12), (cid:2) \ (cid:2)(cid:12), α) ∈ E.A (cid:22)→ 2The function Clem : 2maps any E to its epistemically maximal set:(cid:12)) ⊆ prem(E)}(cid:12)| X ∈ E, XClem(E) = E ∪ { X(cid:12) ∈ [ X], prem( X) ⊆ prem( X(cid:12)), prem( XAWe now show some straightforward results (note that when referring to the characteristic function F(A,D) we will omit the subscript). Henceforth we assume that the arguments A in a dialectical A F satisfy P1, P2 and P3 (Definition 17).Lemma 14. Let (A, D) be a dialectical A F . Then ∀S ⊆ A: Clem(S) ⊆ A.Proof. The result follows immediately from P2, which states that if X ∈ A then all arguments logically equivalent to X are in A. (cid:2)Lemma 15. Let F be the characteristic function of (A, D), and E ⊆ A a fixed point of F (i.e., E = F (E)). Then E is epistemically maximal.Proof. Suppose for contradiction that E is not em, hence ∃ XX(cid:12) ∈ E by Lemma 9. Contradiction. (cid:2)(cid:12) ∈ Clem(E) \ E. Since prem( X(cid:12)) ⊆ prem(E) and E is complete, Lemma 16. Let E(cid:12) = Clem(E), and ∀ X ∈ E, X is acceptable w.r.t. E(cid:12). Then ∀Y ∈ E(cid:12) \ E, Y is acceptable w.r.t. E(cid:12).M. D’Agostino, S. Modgil / Artificial Intelligence 262 (2018) 15–5129Proof. Suppose Y ∈ Eand so ∃ X ∈ E, α ∈ prem( X), and Z ⇒E(cid:12) X on α. By assumption of X acceptable w.r.t. Eacceptable w.r.t. E(cid:12) \ E, Z ⇒E(cid:12) Y on α. Hence Z ⊀ ({α}, ∅, α). Since E(cid:12) = Clem(E), then prem(E, ∃Q ∈ E. (cid:2)(cid:12)(cid:12)(cid:12)) = prem(E), α ∈ prem(E), , Q ⇒{ Z } Z . Hence Y is (cid:12)3.5.1. Proving a variant of the fundamental lemma and implied propertiesWe now present results for use in proving a variant of the fundamental lemma.Lemma 17. Let E ⊆ A such that every argument in E is acceptable w.r.t. E, and A satisfies P1, P2 and P3. Then E is conflict free.Proof. Suppose for contradiction that X, Y ∈ E, X ⇒E Y on α, where X = ((cid:3), (cid:2), φ), φ = (cid:2) or φ = α.1) Suppose φ = (cid:2). Then (by Definition 11) it must be that (cid:2) (cid:11)= ∅. By P2, Z = (∅, (cid:3) ∪ (cid:2), (cid:2)) ∈ A. Since (cid:3) ∪ (cid:2) ⊆ prem(E), then ∀β ∈ (cid:3) ∪ (cid:2), ∃W ∈ E s.t. Z ⇒E W on β, contradicting W is acceptable w.r.t. E.2) Suppose φ = α. By P2, X• ((cid:3) ∪ (cid:2), ∅, (cid:2)) ∈ A (in which case (cid:3) ∪ (cid:2) (cid:11)= ∅) and (cid:3) ∪ (cid:2) ⊆ prem(E), so that ∀β ∈ (cid:3) ∪ (cid:2), ∃W ∈ E s.t. (∅, (cid:3) ∪ (cid:2), (cid:2)) ⇒E Won β, contradicting W is acceptable w.r.t. E, or• ({α}, ∅, (cid:2)) ∈ A, and since α ∈ prem(E), (∅, {α}, (cid:2)) ⇒E Y on α, contradicting Y is acceptable w.r.t. E, or• ((cid:3) ∪ (cid:2) ∪ {α}, (cid:2)) ∈ A. By P2, Z = (∅, (cid:3) ∪ (cid:2) ∪ {α}, (cid:2)) ∈ A. Since (cid:3) ∪ (cid:2) ∪ {α} ⊆ prem(E), Z ⇒E Y on α and ∀β ∈ (cid:3) ∪ (cid:2), ∃W ∈ E s.t. Z ⇒E W on β, contradicting Y , W acceptable w.r.t. E. (cid:2)(cid:12) = ((cid:3) ∪ (cid:2), ∅, α) ∈ A. By P1 ({α}, ∅, α) ∈ A. By P3, either:Lemma 18. Let E(cid:12) ⇒E Y .A and Z(cid:12) ⊆ A, Z = ((cid:3), (cid:2), φ) and Z ⇒E(cid:12) Y on α. Let (cid:2)(cid:12) = (cid:2) ∩ prem(E ∪ {Y }) where E ⊆ E(cid:12). Then Z(cid:12) = ((cid:3) ∪ ((cid:2) \ (cid:2)(cid:12)), (cid:2)(cid:12), φ) ∈(cid:12) ∈ A. Since Z ⇒E(cid:12) Y on α and ≺ is imle: ZProof. By P2, ZSuppose φ = α. By definition, (cid:2)(cid:12) ⊆ prem(E ∪ {Y }). Hence ZSuppose φ = (cid:2). Then α ∈ (cid:2), and by definition α ∈ (cid:2)(cid:12)(cid:12) ⊀ ({α}, ∅, α).(cid:12) ⇒E Y .. Since (cid:2)(cid:12) ⊆ prem(E ∪ {Y }), Z(cid:12) ⇒E X . (cid:2)We now prove a variant of the fundamental lemma:Lemma 19. Let X, Xacceptable w.r.t. Clem(E ∪ { X}).(cid:12)be acceptable w.r.t. an admissible extension E of (A, D). Then: 1) Clem(E ∪ { X}) is admissible, and 2) X(cid:12)is Proof. Let E(cid:12) = E ∪ { X} and E(cid:12)(cid:12) = Clem(E(cid:12)). Note that prem(E(cid:12)) = prem(E(cid:12)(cid:12)).Proof of 1). We show that every argument in EWe first show that every argument in EE. Then ∃Z = ((cid:3), (cid:2), φ) (φ = (cid:2) or α) s.t. Z ⇒E(cid:12)(cid:12) Y on Yis acceptable w.r.t. E(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)is acceptable w.r.t. E(cid:12)(cid:12).(cid:12) = ({α}, ∅, α) (hence Z ⊀ Y(cid:12)), and:. Suppose for contradiction that Y ∈ E(cid:12)is not acceptable w.r.t. (cid:12)(cid:12)¬∃Q ∈ Es.t. Q ⇒{Z } ZSuppose Y = X . Since prem(E ∪ { X}) = prem(Eso Q ∈ E) Q ⇒{ Z } Z , contradicting Eq. (1).Suppose Y (cid:11)= X . Let (cid:2)(cid:12) = (cid:2) ∩ prem(E ∪ {Y }) (and so (cid:2) \ (cid:2)(cid:12)(cid:12) = ((cid:3) ∪ ((cid:2) \ (cid:2)(cid:12)), (cid:2)(cid:12), φ), ZZ(cid:12)) = prem(E(cid:12) ⇒E Y .(cid:12)(cid:12)(1)(cid:12)(cid:12)), Z ⇒E X . By assumption of X acceptable w.r.t. E, ∃Q ∈ E (and are premises of X that are not premises in E or Y ). By Lemma 18, By assumption of E admissible and so every Y in E acceptable w.r.t. E:∃W = ((cid:10), (cid:11), ψ) ∈ E s.t. W ⇒{Z (cid:12)} Z(cid:12)(ψ = (cid:2) or ψ = β)on β ∈ (cid:3) ∪ ((cid:2) \ (cid:2)(cid:12)), where W ⊀ ({β}, ∅, β), (cid:11) ⊆ (cid:3) ∪ ((cid:2) \ (cid:2)(cid:12)). Consider two cases:1. Suppose β ∈ ((cid:2) \ (cid:2)(cid:12)) (in which case β ∈ prem( X) and if ψ = (cid:2) then β ∈ (cid:11) ∩ ((cid:2) \ (cid:2)(cid:12))).(2)(cid:12)Let Wand Wprem(Wbe the logically equivalent ((cid:11) ∩ (cid:3), (cid:10) ∪ ((cid:11) ∩ ((cid:2) \ (cid:2)(cid:12))), ψ). Since (cid:10) ⊆ prem(E) and ((cid:11) ∩ ((cid:2) \ (cid:2)(cid:12))) ⊆ prem( X), (cid:12) ⊀ ({β}, ∅, β), then W. Since (cid:12)) ⊆ prem(Z ), Q ⇒{ Z } Z , contradicting Eq. (1).(cid:12) ⇒E X . By assumption of the acceptability of X w.r.t. E, ∃Q ∈ E s.t. Q ⇒{W (cid:12)} W(cid:12)2. Suppose β ∈ (cid:3), (hence β ∈ prem(Z ) and if ψ = (cid:2) then β ∈ (cid:11) ∩ (cid:3)). Let W(cid:12)) ⊆ prem(E(cid:12)), then W(cid:12)is in the epistemic closure E(cid:12)be the logically equivalent ((cid:10) ∪ ((cid:11) ∩(cid:12) ⊀ ({β}, ∅, β), . Since Wof E(cid:12)(cid:12)(cid:12)((cid:2) \ (cid:2)(cid:12))), (cid:11) ∩ (cid:3), ψ). Since prem(W(cid:12) ⇒{ Z } Z , contradicting Eq. (1).W30M. D’Agostino, S. Modgil / Artificial Intelligence 262 (2018) 15–51We have shown ∀Y ∈ EE, Yis conflict free. Hence E(cid:12)(cid:12)(cid:12)(cid:12)is acceptable w.r.t. E(cid:12)(cid:12) = Clem(E(cid:12)) is admissible.(cid:12)(cid:12). By Lemma 16, all arguments in E(cid:12)(cid:12)are acceptable w.r.t. E(cid:12)(cid:12). By Lemma 17, (cid:12)(cid:12)s.t. Q ⇒{ Z } Z .Proof of 2) Suppose for contradiction that X¬∃Q ∈ ELet Z = ((cid:3), (cid:2), φ) (φ = (cid:2) or α), (cid:2)(cid:12) = (cid:2) ∩ prem(E ∪ { XBy Lemma 18, Z.(cid:12)(cid:12) = ((cid:3) ∪ ((cid:2) \ (cid:2)(cid:12)), (cid:2)(cid:12), φ), Z(cid:12)By assumption of the acceptability of Xand (cid:11) ⊆ (cid:3) ∪ ((cid:2) \ (cid:2)(cid:12)). We can now reason as in 1) above, contradicting ¬∃Q ∈ E(cid:12) ⇒E Xw.r.t. E, ∃W = ((cid:10), (cid:11), ψ) ∈ E, W ⇒{ Z (cid:12)} Z(cid:12)(cid:12)(cid:12)is not acceptable w.r.t. E(cid:12)(cid:12). Then Z ⇒E(cid:12)(cid:12) X(cid:12)on ({α}, ∅, α), Z ⊀ ({α}, ∅, α) and (cid:12)}) (and so (cid:2) \ (cid:2)(cid:12)are premises in X that are not premises in E or X(cid:12)).on ({β}, ∅, β), where W ⊀ ({β}, ∅, β)(cid:12)s.t. Q ⇒{ Z } Z . (cid:2)Assuming the admissible set E in Lemma 19 is epistemically maximal, it immediately follows that:Corollary 20. The set of all epistemically maximal admissible extensions of a dialectical A F form a complete partial order w.r.t. set inclusion.Lemma 21. Let E be an admissible extension of (A, D). Then E ⊆ F (E) and Clem(F (E)) is admissible.Proof. By assumption of the admissibility of E, E ⊆ F (E). To show Clem(F (E)) is admissible, we make use of the function: ∗(E, X) = Clem(E ∪ { X}).FLet F (E) \ E be the possibly countably infinite set { X1, . . . , Xn, . . .}, and let:F∗1= F∗(E, X1), F∗2= F∗(F∗1 , X2), . . . , F∗i= F∗(F∗i−1, Xi), . . .That is to say, the sequence obtained by adding, one by one, the arguments X1, . . . , Xn, . . ., whereupon after each argument is added, the set is closed to obtain an em set. One can straightforwardly show that:∀i : Clem(E ∪ { X1, . . . , Xi}) = F∗i(3)That is to say, adding all arguments up to some i, and then closing, yields the same result as adding each argument one by one and closing prior to each subsequent addition.Given Eq. (3), it suffices to show that ∀Fin the above sequence, Fis admissible:∗i∗iBase case: By assumption of the acceptability of X1 w.r.t. E, and Lemma 19-1), FX2, . . . , Xi are acceptable w.r.t. F∗1 .∗1= F∗(E, X1) is admissible. By Lemma 19-2), General case: By inductive hypothesis, Fble. (cid:2)∗i−1 is admissible, and Xi is acceptable w.r.t. F∗i−1. By Lemma 19-1), F∗iis admissi-We can now show the following key result:Proposition 22. Every admissible extension of a dialectical A F is a subset of a preferred extension.Proof. Let E be an admissible extension. We consider two cases:1. Suppose E = F (E). By Lemma 15, E is epistemically maximal.2. Suppose E (cid:11)= F (E). By Lemma 21, E ⊆ F (E), and E(cid:12) = Clem(F (E)) is admissible, where trivially, E ⊆ E(cid:12).(cid:12)In both cases, E ⊆ Einclusion em admissible set Esuch a fixed point would be em. Hence E(cid:12) = E in case 1), where E(cid:12)(cid:12)(cid:12) ⊇ E(E(cid:12)(cid:12)(cid:12) ⊇ E is a preferred extension. (cid:2). There cannot exist a fixed point of F that is a strict superset of Eis a em admissible set. By Corollary 20, there exists a maximal under set , since by Lemma 15, (cid:12)(cid:12)The importance of Proposition 22 for monological and dialogical applications, is that it suffices to show that an argument X is in an admissible extension, in order to show that X is credulously justified under the preferred semantics.3.5.2. Monotonicity and a constructive definition of the grounded extensionWe now show monotonicity of a dialectical AF’s characteristic function, restricted to the domain of epistemically maximal admissible sets.Lemma 23. Let E, E(cid:12)be two em admissible extensions such that E ⊆ E(cid:12). Then F (E) ⊆ F (E(cid:12)).M. D’Agostino, S. Modgil / Artificial Intelligence 262 (2018) 15–5131Proof. We show that X acceptable w.r.t. E ( X ∈ F (E)) implies X acceptable w.r.t. EZ = ((cid:3), (cid:2), φ) (φ = (cid:2) or α), and Z ⇒E(cid:12) X on X1) Suppose Z ⇒E X . Since X ∈ F (E), ∃Y ∈ E s.t. Y ⇒{ Z } Z . Since E ⊆ E(cid:12)), by showing an argument in E2) Suppose Z (cid:5)E X . We show X ∈ F (ELet (cid:2)(cid:12) = (cid:2) ∩ prem(E ∪ { X}) ((cid:2) \ (cid:2)(cid:12)By Lemma 18, Z∃W = ((cid:10), (cid:11), ψ) ∈ E (ψ = (cid:2) or β), W ⇒{ Z (cid:12)} Zthat are not in E ∪ { X}).(cid:12) ⇒E X . Since X is acceptable w.r.t. E:on ({β}, ∅, β) and W ⊀ ({β}, ∅, β).(cid:12) = ({α}, ∅, α), and so Z ⊀ X(cid:12) = ((cid:3) ∪ (cid:2) \ (cid:2)(cid:12), (cid:2)(cid:12), φ), Z., Y ∈ E(cid:12)are premises in E(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12))., and so X ∈ F (Ethat defeats Z = ((cid:3), (cid:2), φ).(cid:12)( X ∈ F (E(cid:12))). Suppose X ∈ F (E), • Suppose β ∈ (cid:2) \ (cid:2)(cid:12)(where if ψ = (cid:2) then β ∈ (cid:11) ∩ ((cid:2) \ (cid:2)(cid:12))). Hence ∃ X(cid:12) ∈ E(cid:12) \ E ∪ { X} s.t. β ∈ prem( X(cid:12)).(cid:12) = ((cid:11) ∩ (cid:3), (cid:10) ∪ ((cid:11) ∩ ((cid:2) \ (cid:2)(cid:12))), ψ). Since W ∈ E, then (cid:10) ⊆ prem(E). Since (cid:11) ∩ ((cid:2) \ (cid:2)(cid:12)) ⊆(cid:12)) ⊆on ({β}, ∅, β). By assumption of admissibility of E. Since prem(Ws.t. Q ⇒{W (cid:12)} W, ∃Q ∈ E(cid:12)(cid:12)(cid:12)Given (cid:11) ⊆ (cid:3) ∪ ((cid:2) \ (cid:2)(cid:12)), let W(cid:12) ⇒E(cid:12) X(cid:12)), Wprem(Eprem(Z ), Q ⇒{ Z } Z .(cid:12)• Suppose β ∈ (cid:3) (if ψ = (cid:2), β ∈ (cid:11) ∩ (cid:3)). Let WSince (cid:11) ∩ (cid:3) ⊆ prem(Z ), W(cid:12) ⇒{ Z } Z . (cid:2)(cid:12) = ((cid:10) ∪ ((cid:11) ∩ ((cid:2) \ (cid:2)(cid:12))), (cid:11) ∩ (cid:3), ψ). By assumption of E(cid:12)being em, W(cid:12) ∈ E(cid:12). By definition of Clem, for any S ⊆ S(cid:12), Clem(S) ⊆ Clem(S(cid:12)). Hence Lemma 23 immediately implies that:Corollary 24. Let E, E(cid:12)be two em admissible extensions such that E ⊆ E(cid:12). Then Clem(F (E)) ⊆ Clem(F (E(cid:12))).Consider now a characteristic function Fp whose domain is sets E that are em admissible, and that returns Clem(F (E)). By Lemma 21, Fp returns a em admissible set. We then show that the fixed points of F and Fp coincide. Corollary 24 then guarantees existence of a least fixed point of Fp and hence F . Formally:Definition 19. Let (A, D) be a dialectical AF and A2Fp(E) = Clem(F (E)).p the set of all em admissible subsets of A. Then Fp : A2p(cid:22)→ A2p , where Proposition 25. Let (A, D) be a dialectical AF. Then there exists a least fixed point of F(A,D).Proof. Firstly, let E be a fixed point of Fp . Since E is admissible, E ⊆ F (E). By definition of Clem, F (E) ⊆ Clem(F (E)). Hence since E = Fp(E) = Clem(F (E)), then it must be that E = F (E).Secondly, let E be a fixed point of F (E = F (E)). By Lemma 15, E = F (E) is em. By definition of Clem, if S is em then Clem(S) = S. Hence E = F (E) = Clem(F (E)). That is, E is a fixed point of Fp . We have shown:E is a f ixed point of Fp iff E is a f ixed point of F(4)By Corollary 24, Fp is monotonic, and so there exists a least fixed point of Fp , which given Eq. (4) is a least fixed point of F . (cid:2)We can therefore identify the grounded extension of a dialectical A F as the least fixed point of the framework’s char-acteristic function. If we define a sequence, starting with the empty set, and iteratively applying Fp , the monotonically increasing sequence approximates, and in the case of a finitary dialectical A F (see below) constructs, the least fixed point (lfp) of Fp , i.e., the grounded extension.Proposition 26. Let (A, D) be a dialectical A F , and F 0 = ∅, F i+1 = Fp(F i). Let E be the grounded extension of (A, D). Then:(cid:2)∞1. E ⊆2. If (A, D) is finitary, i.e., ∀ X ∈ A, the set {Y |(Y , X) ∈ D} is finite, then E =i=0(F i).(cid:2)∞i=0(F i).Proof. Trivially, F 0 = ∅ is em admissible. By Corollary 24, F 0, . . . , F ishown, given that E is the lfp of Fp . 2 is then shown by showing that Fp is ω-continuous. Let Eand let X ∈ Fp(ETherefore Fp(Eis a monotonically increasing sequence. 1 is then (cid:12) = F 0 ∪ · · · ∪ F n ∪ . . ., (cid:12)). Since there are finitely many arguments that defeat X , there exists a number m such that X ∈ Fp(F m). (cid:12)) = F 0 ∪ · · · ∪ F n ∪ . . .. (cid:2)Finally, before formally showing satisfaction of these postulates, we discuss what it means for a preference relation to be dialectically coherent when determining the success of attacks as defeats. A preference Y ≺ X invalidating an attack from Y = ((cid:3), ∅, α) to X = ({α}, ∅, α), can be interpreted as:from amongst the inconsistent (cid:3) ∪ {α}, one preferentially accepts (i.e., includes in a complete extension E) arguments constructed from α and rejects (excludes from E) arguments constructed from (cid:3) \ {α}.32M. D’Agostino, S. Modgil / Artificial Intelligence 262 (2018) 15–51Now, let Y(cid:12) = ((cid:3) ∪ {α}, ∅, φ) (φ = (cid:2) or φ = α). Then Y ≺ X should imply that Y(cid:12) ⊀ X . (cid:12) ⊀ X would mean that from amongst But then this would contradict the interpretation ascribed above to Y ≺ X , since Ythe inconsistent (cid:3) ∪ {α}, one does not preferentially accept arguments constructed from α and reject arguments constructed from (cid:3) ∪ {α} \ {α} (i.e., from (cid:3) \ {α}).(cid:12) ≺ X . To see why, suppose YMoreover, suppose that for every αiin some inconsistent (cid:3) = {α1, . . ., αn}, one constructs the argument Ai = ((cid:3) \{αi}, ∅, αi), and that ∀i: Ai ≺ ({αi}, ∅, αi). Reasoning as above, we would then have ∀i: A= ((cid:3), ∅, φi) ≺ ({αi}, ∅, αi)(φi = (cid:2) or φi = αi ). In other words one preferentially accepts arguments built from α1 to those built from (cid:3), from α2 to those built from (cid:3), and so on. But then (by Lemma 9), if E includes arguments with premises α1, . . . , αn then E includes arguments built from premises (cid:3). Contradiction. Hence, it would be incoherent to have that ∀α ∈ (cid:3): ((cid:3), ∅, (cid:2)) ≺ ({α}, ∅, α)and (since ≺ is imle) (∅, (cid:3), (cid:2)) ≺ ({α}, ∅, α). Indeed, all the results shown thus far would hold if instead of enforcing that attacks from (∅, (cid:3), (cid:2)) on each α ∈ (cid:3) always succeed as a defeat (given that it would be incoherent to reject the dialectical demonstration of inconsistency), one instead assumed a coherent preference relation implying that for at least one α ∈ (cid:3), (∅, (cid:3), (cid:2)) defeats ({α}, ∅, α).17(cid:12)iDefinition 20 (Dialectically coherent preference relations). Let (A, D) be a pd A F defined by B and ≺. Then ≺ is dialectically coherent iff∀(∅, (cid:3), (cid:2)) ∈ A: ∃α ∈ (cid:3) such that (∅, (cid:3), (cid:2)) ⊀ ({α}, ∅, α). ∀ X = ({α}, ∅, α), Y = ((cid:3), ∅, α), Y(cid:12) = ((cid:3) ∪ {α}, ∅, φ) (φ = α or φ = (cid:2)): Y ≺ X implies Y(cid:12) ≺ X . (Pref1)(Pref2)In Section 4 we show that the Elitist preference satisfies Pref1 and Pref2. Notice that since ≺ is imle, Pref2 implies that if ((cid:3), (cid:2), α) ≺ ({α}, ∅, α) then ((cid:3), (cid:2) ∪ {α}, φ) ≺ ({α}, ∅, α). To see why preference relations that do not satisfy Pref2 may yield counter-intuitive results, suppose that in Example 28 we have that C ≺ A but D ⊀ A, thus violating Pref2. We would then have an additional complete extension E 2 containing C and D, since the defeats by A and B on C and D would now be defended by defeats from D on A and B. Counter-intuitively one would obtain a complete extension containing C , despite a strict preference for A over C .Finally, in now proving the non-interference and crash resistance postulates, we will make use of the following result that holds for preference relations satisfying Pref1:Lemma 27. Let (A, D) be a pd A F defined by B and ≺, where ≺ satisfies Pref1. Then for any Y = ((cid:3), (cid:2), (cid:2)), YY(cid:12) ⇒{Y } Y .or Y(cid:12)(cid:12) = ((cid:2), (cid:3), (cid:2)): Y ⇒{Y (cid:12)}Proof. Suppose for contradiction that Y (cid:5){Y (cid:12)} Ycontradicting Pref1. (cid:2)(cid:12)and Y(cid:12) (cid:5){Y } Y . Since ≺ is imle, ∀α ∈ (cid:3) ∪ (cid:2): (∅, (cid:3) ∪ (cid:2), (cid:2)) ≺ ({α}, ∅, α), 3.6. Contaminated argumentsDialectical A F s satisfy consistency and closure given relatively undemanding assumptions as to the arguments con-structed from a base, while assuming arbitrary preference relations and eschewing the need for checking the legitimacy of arguments’ assumptions. However, dropping consistency and subset minimality checks on arguments’ assumptions may result in violation of the non-contamination postulates.Example 28. Let B = {p, ¬p}. Fig. 3-i) shows arguments and attacks defined by B. Suppose C ≺ A, D ≺ A, and so we have the defeats in Fig. 3-ii) and E 1 is the single grounded, preferred and stable extension (notice that C (cid:5)E1 B since C attacks Bon A and C ≺ A). Suppose we now add s to B, and suppose the defined arguments in Fig. 3-iii). Again, assume only C ≺ A, D ≺ A. Intuitively, since s is syntactically disjoint from p, ¬p, we should continue to obtain a single grounded, preferred and stable extension { A, B, X, S}.Firstly, note that in contrast with the example in Section 3.2, we avoid the ‘contaminating effect’ (in the sense that the non-contamination postulates are violated) of arguments that are used to entail syntactically disjoint conclusions via the defeats S (Fig. 3-iii), membership of S in ‘explosivity’ (recall footnote 9) of classically inconsistent premises. Although Dany complete extension E can never be invalidated since any such E will contain the unassailable X that defeats Dand so defends S. Hence crash resistance is not violated ( X ’s defence of S also prevents violation of non-interference that may occur due to the defeat by DSecondly, with the addition of s to B, we can also construct CWe then have an additional complete extension E 2 = {C, Cdefeat is defended given that C(cid:12) ⇒E1 A. (cid:12), D}, each such (cid:12) ⇒{ A} A. This is clearly counter-intuitive. We no longer obtain a single grounded, preferred (cid:12), D, S, X}, since although A ⇒E2 V , V ∈ {C, C(cid:12) = ({s, ¬p}, ∅, ¬p). Since C(cid:12) ⊀ A, we have that C).(cid:12)(cid:12)(cid:12)17 In Remark 8, it would remain the case that no admissible extension can contain A1 and F 1 since a coherent ≺ would imply that the unassailable X1defeats either A1 on A1 or F 1 on either B 1 or C1.M. D’Agostino, S. Modgil / Artificial Intelligence 262 (2018) 15–5133Fig. 3.C ≺ A, Ci) All attacks are bidirectional; ii) Defeats resulting in single complete extension E1; iii) Arguments and defeats given base {p, ¬p, s} and (cid:12) ⊀ A.and stable extension containing A; indeed the grounded extension E will now only contain S and X . Thus, by adding the syntactically disjoint s to B, A is no longer a sceptically justified argument under any semantics, and hence non-interference is violated.The above example describes two types of contamination. The first type of contamination may occur when the assumptions (cid:2) of an argument X , with conclusion α (cid:11)= (cid:2), include some inconsistent (cid:3) that is syntactically disjoint from (cid:2) \ (cid:3) ∪ {α}, and α may be derived by the explosivity of (cid:3) (i.e., (cid:3) contaminates X by explosivity).Remark 29. Notice that:1. if α = (cid:2) then X is of the form ((cid:11), (cid:14), (cid:2)) and cannot have a contaminating effect due to explosivity, since X can only attack arguments on assumptions in (cid:14) (cid:11)= ∅, indicating that (cid:11) ∪ (cid:14) is inconsistent (recall Definition 11).2. We emphasise above that α may be derived by explosivity since we are presently considering representations of ar-guments independently of the proof theory used for their construction. Hence, given an argument represented as ({p, ¬p, r, r → q}, ∅, q) it may be that q is derived from r, r → q, or explosively from p, ¬p; there is no way of telling which is the case without reference to the proof theory. Note that the same reasoning applies to ({p, ¬p}, ∅, q ∨ ¬q) in that the tautology may be derived from empty assumptions or explosively.3. In addition to the arguments A in a dialectical A F satisfying P1, P2 and P3 in Definition 17, we will later stipulate that if X ∈ A and (cid:3) contaminates X by explosivity, then A also contains a falsum argument with assumptions (cid:3). (Intuitively, if an argument’s inconsistent assumptions are used to conclude a syntactically disjoint conclusion via explosivity, then this can be explicitly recognised by concluding the syntactically disjoint (cid:2).)Violation of the non-contamination postulates due to arguments contaminated by explosivity is then avoided if the by explosivity. However, we also have X =assumption in 3 above is satisfied. In Example 28, {p, ¬p} contaminates D(∅, {p, ¬p}, (cid:2)) that defeats D.(cid:12)(cid:12)(cid:12)(cid:12) ⊀ A, and so CA second type of contamination may arise because we do not enforce that arguments’ assumptions are subset minimal. that is stronger than its subset minimal counterpart CAdding s to the premises of C yields the non-subset minimal C(cid:12) ⇒E1 A). As discussed in Section 3.2, [43] shows that if subset minimal arguments are not (C ≺ A but Cstrengthened when adding redundant assumptions, then the argumentation defined inferences of a framework consisting only of subset minimal arguments, is not changed when adding non-subset minimal arguments to the framework. Intuitively, this also means that non-interference would not be violated due to inclusion of non-subset minimal arguments. However, we have argued that ensuring that assumptions are not redundant with respect to deriving an argument’s conclusion, should not be enforced by computationally expensive checks on subset minimality, but rather should in principle be enforceable by the proof system used for constructing arguments. Recall that the issue here is not whether assumptions are actually used in deriving the conclusion (footnote 8 on page 12 provides an example of a non-subset minimal argument in which all assumptions are used in the proof), since one can readily exclude assumptions not actually used in a given proof. Rather, the focus is on identifying whether arguments specified ‘abstractly’ as tuples consisting of assumptions paired with a conclusion (i.e.,without reference to a specific proof system) include obviously redundant assumptions. One such obvious notion of 34M. D’Agostino, S. Modgil / Artificial Intelligence 262 (2018) 15–51redundancy is implied by the following property of classical logic (recall – Notation 3 – that (cid:17) denotes ‘syntactically disjoint’; to spare on parentheses, we also assume that ∪ binds more tightly than (cid:17)):Proposition 30. Let B be a base. For all (cid:2) ⊆ B, if (cid:2) (cid:10)c α and ∃(cid:3) ⊆ (cid:2) such that (cid:3)(cid:17)((cid:2) \ (cid:3)) ∪ {α}, then either (cid:3) (cid:10)c (cid:2) or (cid:2) \ (cid:3) (cid:10)c α.Proof. Suppose for contradiction that (cid:3) (cid:4)c (cid:2) and (cid:2) (cid:4)c α. By classical semantics, there is a model M1 such that the value (cid:12)of all the formulas in (cid:2) is 1 and the value of α is 0. The same holds true of every model M1 that agrees with M1 on the interpretation of symbols((cid:2) ∪ {α}). Moreover, since (cid:3) is consistent, there is a model M2 such that the value of all the (cid:12)formulas in (cid:3) is 1. The same holds true of every model M2 that agrees with M2 on the interpretation of symbols((cid:3)). Now, since (cid:3)(cid:17)(cid:2) ∪ {α}, there is a model M3 that agrees with M1 on the interpretation of symbols((cid:2) ∪ {α}) and with M2on the interpretation of symbols((cid:3)). For such a model the values of all the formulas in (cid:3) ∪ (cid:2) is 1 and the value of α is 0, contradicting the hypothesis that (cid:3) ∪ (cid:2) (cid:10)c α. (cid:2)Remark 31. Suppose a dialectical A F (A, D) such that Y = ((cid:2), ∅, α) ∈ A, and there is a non-empty (cid:3) ⊆ (cid:2) such that (cid:3)(cid:17)((cid:2) \ (cid:3)) ∪ {α}. Then, given Proposition 30:1. If (cid:2) \ (cid:3) (cid:11)= ∅ then either:i) (cid:3) ‘redundantly weakens’18 Yii) (cid:2) \ (cid:3) redundantly weakens YFor example, given Y = ({s, ¬p}, ∅, ¬p) then (cid:3) = {s} redundantly weakens Y({q, p, ¬p}, ¬s), then (cid:2) \ (cid:3) = {q} redundantly weakens Y(cid:12) = ((cid:2) \ (cid:3), ∅, α) (i.e., (cid:3) ⊆ assumptions(Y ) are trivially unnecessary for obtaining α), or(cid:12) = ((cid:3), ∅, α) (where (cid:3) explosively entails α by virtue of the inconsistency of (cid:3)).(cid:12) = ({¬p}, ∅, ¬p) (case 1i). Given Y =(cid:12) = ({p, ¬p}, ∅, ¬s) (case 1ii).2. If (cid:2) \ (cid:3) = ∅ then either:i) (cid:3) (cid:4)c (cid:2) and so by classical semantics α must be a tautology, and (cid:2) redundantly weakens Yii) (cid:3) (cid:10)c (cid:2) and so either α is a tautology and (cid:2) redundantly weakens Y(cid:12) = (∅, ∅, α), or (cid:3) explosively entails α by (cid:12) = (∅, ∅, α), orvirtue of the inconsistency of (cid:3).For example, given Y = ({s}, ∅, p ∨ ¬p), then (cid:2) = {s} redundantly weakens Y({s, ¬s}, ∅, p ∨ ¬p), then either (cid:2) = {s, ¬s} redundantly weakens Yfrom the inconsistent {s, ¬s} (case 2ii).(cid:12) = (∅, ∅, p ∨ ¬p) (case 2i). Given (cid:12) = (∅, ∅, p ∨ ¬p), or p ∨ ¬p is explosively entailed 3. In addition to P1, P2 and P3, we will later stipulate that if Y ∈ A, then:(cid:12) = ((cid:3), ∅, α), A also includes ((cid:3), ∅, (cid:2)) (e.g., Y– In case 1 A also includes the redundantly weakened YY– In case 2, A also includes the redundantly weakened Y((cid:3), ∅, (cid:2)) (e.g., ({s, ¬s}, ∅, (cid:2))).(cid:12) = ((cid:2) \ (cid:3), ∅, α), or, given the redundantly weakened explosive (cid:12)(cid:12) = ({p, ¬p}, ∅, (cid:2))) as stipulated in Remark 29-3.(cid:12) = (∅, ∅, α), or, given the explosive ((cid:3), ∅, α), A also includes Let us formally define the above notions. We first identify the notion of a contaminated argument, and then further distinguish when such an argument is redundantly and/or explosively contaminated.Definition 21 (Contaminated arguments). Let Y be an argument with assumptions(Y ) = (cid:2) and conclusion(Y ) = α. We say that Y is contaminated if there exists some non-empty (cid:3) ⊆ (cid:2) such that the following conditions hold:1. (cid:3)(cid:17)((cid:2) \ (cid:3)) ∪ {α};2. either (cid:2) \ (cid:3) (cid:11)= ∅ or α (cid:11)= (cid:2).We also say that any such (cid:3) is a contaminating set for Y .Note that if an argument Y satisfies condition 1 and is not contaminated, then it violates condition 2; that is to say, assumptions(Y ) cannot be partitioned into non-empty syntactically disjoint subsets, so that the only contaminating (cid:3) for Yis such that (cid:2) \ (cid:3) = ∅, and conclusion(Y ) = (cid:2) (recall that (cid:2) does not appear in a base and so it must be that (cid:2) = (cid:3) is syntactically disjoint from (cid:2)). Hence Y has not been obtained by some assumptions redundantly weakening an argument in any of the senses described in Remark 31. Moreover, recalling Remark 29-1, such an argument is not explosively contam-inating. To illustrate, ({p, ¬p}, ∅, (cid:2)) is an example of such a Y that is not contaminated (either redundantly or explosively). On the other hand ({p, ¬p, r}, ∅, (cid:2)) is contaminated redundantly but not explosively, and ({p, ¬p}, ∅, {q}) is contaminated explosively but not redundantly.Definition 22 (R-contaminated arguments). Let Y be a contaminated argument such that assumptions(Y ) = (cid:2) and conclusion(Y ) = α. We say that Y is redundantly contaminated or R-contaminated if:18 We use the term ‘weakens’ in keeping with the standard use of the term weakening in logic to denote that an entailment from (cid:3) continues to be valid when adding some (cid:2) to (cid:3).M. D’Agostino, S. Modgil / Artificial Intelligence 262 (2018) 15–5135either (i) for some contaminating set (cid:3) ⊆ (cid:2) for Y , (cid:2) \ (cid:3) (cid:11)= ∅, or(ii) the only contaminating set for Y is (cid:2) itself (i.e., (cid:2) \ (cid:3) = ∅) and (cid:3) (cid:4)c (cid:2).Conditions i) and ii) respectively state that Y is an R-contaminated argument of the type described in 1 and 2i) of Remark 31. Arguments of the type described in 2ii), such as Y = ({p, ¬p}, ∅, q ∨ ¬q), cannot be definitively recognised as being R-contaminated. This is because it may be that X = (∅, ∅, q ∨ ¬q) /∈ A. That is to say Y has not been obtained by {p, ¬p} redundantly weakening X . Rather, q ∨ ¬q is only derived by explosivity and so we have (given Remark 29-3) that ({p, ¬p}, ∅, (cid:2)) ∈ A (and so the property described in Remark 31-3 is satisfied). On the other hand one can definitively identify Y = ({p, ¬p, q, q → r}, ∅, r) as being R-contaminated, since satisfaction of the property in Remark 31-3 means that either ({p, ¬p}, ∅, r) ∈ A or ({q, q → r}, ∅, r) ∈ A. In either case Y includes a redundantly weakening set of assumptions ({q, q → r} respectively {p, ¬p}).We now formally define explosively contaminated arguments:Definition 23 (E-contaminated arguments). Let Y be a contaminated argument such that conclusion(Y ) = α. We say that Y is explosively contaminated or E-contaminated if α (cid:11)= (cid:2) and (cid:3) (cid:10)c (cid:2) for some (cid:3) that is a contaminating set for Y .Example 32 (Examples of (non) contaminated arguments).1. X = ({p, ¬p, q, q → r}, ∅, r), Y = ({p, ¬p, q}, ∅, r), Z = ({p, ¬p, q, ¬q}, ∅, r) are all both R-contaminated and E-contaminated;2. Both ({p, ¬p}, ∅, {q}) and ({p, ¬p}, ∅, {q ∨ ¬q}) are E-contaminated, but not R-contaminated;3. Both ({p, ¬p}, ∅, {p ∧ q}) and ({p, ¬p, r}, ∅, r ∧ p) are neither R-contaminated nor E-contaminated (as neither is con-taminated);4. ({p, ¬p, r}, ∅, (cid:2)) is R-contaminated but not E-contaminated. ({p, ¬p}, ∅, (cid:2)) is neither R-contaminated nor E-contaminated.For the examples in 1 above, if the property in Remark 31-3 is satisfied, then:• if X ∈ A then either X(cid:12) = ({q, q → r}, ∅, r) ∈ A and X(cid:12)has been redundantly(cid:12)(cid:12) = ({p, ¬p}, ∅, r) has been redundantlyweakened by {p, ¬p}, or the explosive Xweakened by {q, q → r}, and so ({p, ¬p}, ∅, (cid:2)) ∈ A.• If Y ∈ A then ({p, ¬p}, ∅, (cid:2)) ∈ A.• If Z ∈ A then:– either ({q, ¬q}, ∅, r) ∈ A or ({p, ¬p}, ∅, (cid:2)) ∈ A, and– either ({p, ¬p}, ∅, r) ∈ A or ({q, ¬q}, ∅, (cid:2)) ∈ A.3.7. Coherent preference relations and partially instantiated dialectical A F sSection 4 describes a propositional natural deduction proof theory that does not license construction of R-contaminated arguments. However, satisfaction of the non-contamination postulates when using proof systems that do generate such argu-ments, requires that preference relations are ‘redundance-coherent’ in the sense that arguments are not strengthened when redundantly weakening with syntactically disjoint assumptions (the Elitist preference is shown to be redundance-coherent in Section 4):Definition 24 (Redundance-coherent preference relations). Let A be a set of dialectical arguments. A strict partial ordering ≺over A is redundance-coherent iff∀ X, Y , Y(cid:12)such that Y = ((cid:2), ∅, α), Y(cid:12) = ((cid:3) ∪ (cid:2), ∅, α), and (cid:3)(cid:17)(cid:2) ∪ {α}: if Y ≺ X then Y(cid:12) ≺ X .We now define partially instantiated dialectical A F s (pd A F s) whose arguments A satisfy P1, P2 and P3, and the property described in Remark 31-3 (which, as is easy to verify, subsumes the property in Remark 29-3). We also distinguish non-redundant pd A F s whose arguments are obtained by proof theories that do not generate R-contaminated arguments. In this case it suffices that A satisfies the property relating to arguments contaminated by explosivity described in Remark 29-3.Definition 25 ((Non-redundant) partially instantiated dialectical AF). Let (A, D) be a dialectical A F such that D is the defeat relation over A defined by the attacks C and the strict partial ordering ≺ over A.• (A, D) is a partially instantiated dialectical A F (pd A F ) if A is any subset of the dialectical arguments defined by a base Bsuch that A satisfies P1, P2 and P3, and:(P4) If ((cid:2), ∅, α) ∈ A, (cid:3) ⊆ (cid:2), (cid:3) (cid:11)= ∅ and (cid:3)(cid:17)(cid:2) \ (cid:3) ∪ {α}, then either ((cid:3), ∅, (cid:2)) ∈ A or ((cid:2) \ (cid:3), ∅, α) ∈ A.36M. D’Agostino, S. Modgil / Artificial Intelligence 262 (2018) 15–51• (A, D) is a non-redundant pd A F if A is any subset of the dialectical arguments defined by a base B such that A satisfies P1, P2 and P3, and:(cid:12)(P4) If ((cid:2), ∅, α) ∈ A, (cid:3) ⊆ (cid:2), (cid:3) (cid:11)= ∅ and (cid:3)(cid:17)((cid:2) \ (cid:3)) ∪ {α}, then ((cid:3), ∅, (cid:2)) ∈ A.(P5) ¬∃Y ∈ A such that Y is R-contaminated.We say that (A, D) is a (non-redundant) pd A F defined by B and ≺.(cid:12)By virtue of non-redundant pd A F s satisfying P5, any argument in such a pd A F that satisfies the precondition of P4 (and ) can only be explosively contaminated, and the argument’s assumptions cannot be partitioned into non-empty . Indeed, we leave it to the reader to hence P4syntactically disjoint subsets. Hence it suffices that a non-redundant pd A F satisfy P4verify that:(cid:12)Remark 33. Let (A, D) be a non-redundant pd A F , and ((cid:2), ∅, α) ∈ A, (cid:3) ⊆ (cid:2), (cid:3) (cid:11)= ∅ and (cid:3)(cid:17)((cid:2) \ (cid:3)) ∪ {α}. Then it must be the case that (cid:3) = (cid:2).Henceforth, when referring to ‘pd A F s’ we assume pd A F s in the general sense or non-redundant pd A F s. Finally note that since the arguments in (non-redundant) pd A F s satisfy P1, P2 and P3, the results in Sections 3.4 and 3.5 all hold for such frameworks.(cid:12) ≺ A. Hence CLet us now review the significance of the concepts thus far introduced. Suppose the pd A F (A, D) in Example 28 satisfies (cid:12) ∈ A, P4 implies C ∈ A. Moreover, if the pd A F ’s preference relation is redundance-coherent, P4. Given the R-contaminated C(cid:12) (cid:5){ A} A and non-interference is no longer violated. Furthermore, we have already then C ≺ A implies Cnoted that if P4 is satisfied, then an E-contaminated argument Y implies existence of an argument concluding (cid:2) from the inconsistent (cid:3) in assumptions(Y ), and this ensures satisfaction of the non-contamination postulates. Now, as will be shown in Section 4, one can define proof theories that do not generate R-contaminated arguments (such as C). However, to the best of our knowledge, proof theories cannot be defined so as to exclude non-subset minimal arguments. We have therefore defined non-redundant pd A F s that only need satisfy the property P4implied by P4, and as shown in the following section, need not assume redundance-coherent preference relations (given the absence of R-contaminated arguments) in order that the non-contamination postulates are satisfied.(cid:12)(cid:12)3.7.1. Proving the non-interference and crash resistance postulatesThe non-interference and crash resistance postulates [16] (reviewed in Section 2.2) are stated with respect to A F s defined by bases B1, B2 and B = B1 ∪ B2. For pd A F s, we also need to account for preferences over arguments defined by these bases.Definition 26 (Composing pd A F s). Let (A1, D1) defined by B1 and ≺1, and (A2, D2) defined by B2 and ≺2. Then (A, D)defined by B = B1 ∪ B2 and ≺ is said to be composed from (A1, D1) and (A2, D2), denoted (A, D) = (A1, D1) ⊕ (A2, D2), iff:1. A1 ∪ A2 ⊆ A.192. ∀ X ∈ A : if assumptions( X) ⊆ B1 then X ∈ A1 and if assumptions( X) ⊆ B2 then X ∈ A2.3. ≺ is any preference ordering such that:• ∀ X1, Y 1 ∈ A1 : ( X1, Y 1) ∈≺1 iff ( X1, Y 1) ∈≺• ∀ X2, Y 2 ∈ A2 : ( X2, Y 2) ∈≺2 iff ( X2, Y 2) ∈≺The above formalises the assumption that preferences defined over any set of arguments A, remain unchanged when adding further arguments to A (3), and that the arguments constructed from some base B are exactly those constructed from the subset B of some base B ∪ B(cid:12)(1 and 2). Intuitively, if the available resources are the limiting factor determining construction of arguments, then we assume the same resources available for constructing arguments from B, independently of whether B is included in a larger base B ∪ B(cid:12).Remark 34 (Assumptions on composed pd A F s). In what follows, when stating that (A, D) = (A1, D1) ⊕ (A2, D2), we assume the pd A F s defined by B1, ≺1 and B2, ≺2 and B1 ∪ B2, ≺ respectively, and that B1(cid:17)B2 (B1 is syntactically disjoint from B2).Remark 35 (Assumptions on preference relations in (non-redundant) pd A F s). In the following results, when referring to pd A F s in general, we will assume pd A F s defined by preference relations that satisfy Pref1 (and hence the results can make use 19 It is obvious to then see that for the attack relations C1, C2 and C that are used to obtain the defeats D1, D2 and D: (C1 ∪ C2) ⊆ C.M. D’Agostino, S. Modgil / Artificial Intelligence 262 (2018) 15–5137of Lemma 27) and are redundance-coherent. When referring to non-redundant pd A F s, we assume only that the preference relations satisfy Pref1.Lemma 36. Let (A, D) = (A1, D1) ⊕ (A2, D2). Suppose Y ∈ A \ A1, X ∈ A1, and Y ⇒S⊆A X on XLet Y = ((cid:3), (cid:2), φ), (cid:3)1 = (cid:3) ∩ B1, (cid:2)1 = (cid:2) ∩ B1, (cid:3)2 = (cid:3) ∩ B2, (cid:2)2 = (cid:2) ∩ B2. Then:(cid:12) = (α, ∅, α).1. ((cid:3)2, (cid:2)2, (cid:2)) ∈ A2, or2. ((cid:3)1, (cid:2)1, (cid:2)) ∈ A1, or3. ((cid:3)1, (cid:2)1, α) ∈ A1Proof. Suppose φ = (cid:2). Since Y ∈ A \ A1, then by Definition 26.2, (cid:3)2 ∪ (cid:2)2 (cid:11)= ∅. Since (cid:2) is not an atom in B, then (cid:3)2 ∪(cid:2)2(cid:17)(cid:3)1 ∪ (cid:2)1 ∪ {(cid:2)}. By P4 and P2, either Y 1 = ((cid:3)1, (cid:2)1, (cid:2)) ∈ A and (by Definition 26.2), Y 1 ∈ A1, or Y 2 = ((cid:3)2, (cid:2)2, (cid:2)) ∈ A(cid:12) ∈ A1, (cid:3)2 ∪ (cid:2)2(cid:17)α. Hence (cid:3)2 ∪ (cid:2)2(cid:17)(cid:3)1 ∪ (cid:2)1 ∪ {α}. By P4 and P2: and (by Definition 26.2), Y 2 ∈ A2. Suppose φ = α. Since XY 1 = ((cid:3)1, (cid:2)1, α) ∈ A hence Y 1 ∈ A1, or Y 2 = ((cid:3)2, (cid:2)2, (cid:2)) ∈ A hence Y 2 ∈ A2. (cid:2)Lemma 37. Let (A, D) = (A1, D1) ⊕ (A2, D2), and EX(cid:12) = ({α}, ∅, α), and:(cid:12) ⊆ A, E = E(cid:12) ∩ A1. Suppose Y = ((cid:3), (cid:2), φ) ∈ A, X ∈ A ∩ A1, Y ⇒E(cid:12) X on A1 X is acceptable w.r.t. E in (A1, D1);A2 ∀(cid:3) ⊆ prem(E(cid:12) \ E): (prem( A) = (cid:3)) → ( A ∈ E(cid:12)and A is acceptable w.r.t. E(cid:12)).Then ∃Z ∈ E(cid:12)such that Z ⇒{Y } Y .(cid:12)(cid:12)(cid:12), Z ⊀1 Yand so Z ⊀ Y) Y ⇒E⊆A1 X .(cid:12) ∪ { X}) ∩ B1, then (given Y ⊀ X(cid:12) ∩ A1 and (given X ∈ A1) (cid:2) ⊆ prem(EProof. 1) Suppose Y ∈ A1. Since E = EY ⊀1 XGiven A1, ∃Z ∈ E s.t. Z ⇒{Y } Y on Y2) Suppose Y ∈ A \ A1. By Lemma 36, either: i) Y 1 = ((cid:3) ∩ B1, (cid:2) ∩ B1, (cid:2)) ∈ A1, or ii) Y 1 = ((cid:3) ∩ B1, (cid:2) ∩ B1, α) ∈ A1, or iii) Y 2 = ((cid:3) ∩ B2, (cid:2) ∩ B2, (cid:2)) ∈ A2.(cid:12)2.1) Suppose we are in cases i) or ii). (cid:2) ∩ B1 ⊆ prem(E) and by redundance-coherence of ≺, Y ⊀ X(cid:12)Y 1 ⊀1 X, Z ⇒{Y 1} Y 1. Since prem(Y 1) ⊆ prem(Y ), Z ⇒{Y } Y .2.2) Suppose we are in case iii). By P2, YLemma 27:(cid:12)Y2Y 2 ⇒{Y⇒{Y 2} Y 2 and (since prem(Y 2) ⊆ prem(Y )) the result is shown for Z = Y= ((cid:2) ∩ B2, (cid:3) ∩ B2, (cid:2)) ∈ A2. (cid:2) ∩ B2 ⊆ prem(Eand Y 1 ⇒E⊆A1 X . Given A1, ∃Z ∈ E ⊆ E(cid:12)2, or(by A2), then ∃Z ∈ E(cid:12), Z ⇒{Y 2} Y 2, hence Z ⇒{Y } Y . (cid:2)(cid:12) \ E) and so by A2, Y(cid:12)2, in which case, since Y(cid:12)2 is acceptable w.r.t. Eand Z ⇒{Y } Y on Yimplies Y 1 ⊀ X. Since E ⊆ E, then Z ∈ E. Hence implies . By ∈ E} Y(cid:12)2(cid:12)2.(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)2Corollary 38. Lemma 37 holds for non-redundant pd A F s (A, D).Proof. 1) is shown as in Lemma 37. In 2), Y /∈ A1 implies ((cid:3) ∩ B2) ∪ ((cid:2) ∩ B2) (cid:11)= ∅. Suppose ((cid:3) ∩ B1) ∪ ((cid:2) ∩ B1) (cid:11)= ∅. Then ((cid:3) ∩ B2) ∪ ((cid:2) ∩ B2) (cid:17) ((cid:3) ∩ B1) ∪ ((cid:2) ∩ B1) ∪ {φ}, contradicting (A, D) is non-redundant (recall Remark 33). Hence (cid:12) ((cid:3), (cid:2), (cid:2)) ∈ A2. assumptions(Y ) is a non-empty subset of B2 and Y ∈ A2. If φ = α,20 then since assumptions(Y )(cid:17){α}, by P4We then reason as in 2.2) in Lemma 37, which does not assume redundance-coherent preference relations, to conclude ∃Z ∈(cid:12), Z ⇒{Y } Y . (cid:2)ELemma 39. Let (A, D) = (A1, D1) ⊕ (A2, D2). Then:If E is a complete extension of (A1, D1) then ∃E(cid:12) ⊇ E s.t. E(cid:12)is a complete extension of (A, D) and E = E(cid:12) ∩ A1Proof. Suppose E is a complete extension of (A1, D1). Let E(Ass1).(cid:12) \ E = {Y ∈ A \ A1|Y is acceptable w.r.t. EE(That there exists such an Ewith E(cid:12)}(cid:12)arguments in A \ A1; these are acceptable w.r.t. any EFirstly, suppose (cid:3) ⊆ prem(EE), then for some Y ∈ Eacceptable w.r.t. E. Hence:(cid:12)(cid:12) ⊆ A.)(cid:12) \ E (cid:11)= ∅, can be seen by the limiting case in which E(cid:12) \ E is the set of unassailable (cid:12) \ E), prem(V ) = (cid:3). Hence V ∈ A \ A1. Suppose Z ⇒E(cid:12) V on some β. Since prem(V ) ⊆ prem(E(cid:12) \ E, Z ⇒E(cid:12) Y on β. By Ass1, Y is acceptable w.r.t. E(cid:12)and so ∃W ∈ E(cid:12) \, W ⇒{ Z } Z . Hence V is (cid:12)(cid:12) ⊇ E, such that E = E(cid:12) ∩ A1, and let us assume:∀(cid:3) ⊆ prem(E(cid:12) \ E) : (prem( A) = (cid:3)) → A ∈ E(cid:12)and A acceptable w.r.t. E(cid:12)(5)20 Note that in fact, it cannot be that φ = (cid:2) since this would mean prem( X) ∩ (cid:2) (cid:11)= ∅, contradicting assumptions(Y ) ⊆ B2.38M. D’Agostino, S. Modgil / Artificial Intelligence 262 (2018) 15–51(cid:12)We show X ∈ E implies X acceptable w.r.t. Eacceptable w.r.t. E in (A1, D1). Hence, given Eq. (5), we can apply Lemma 37 to conclude that ∃Z ∈ EX acceptable w.r.t. EGiven Ass1 we now have that all arguments in E(cid:12)Esuch X . Since E is a complete extension of (A1, D1), X is not acceptable w.r.t. E. Hence:are acceptable w.r.t. E(cid:12)is complete, it then remains to show (given Ass1) that X ∈ A1, X /∈ E. Hence by Lemma 17, Eimplies X is not acceptable w.r.t. E. Let Y ∈ A, Y ⇒E(cid:12) X . Since E is a complete extension of (A1, D1), X is s.t. Z ⇒{Y } Y . Hence is conflict free. To show . Suppose some .(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)∃Y ∈ A1, Y ⇒E X, ¬∃Z ∈ E s.t. Z ⇒{Y } Y .Since E ⊆ E(cid:12), Y ⇒E(cid:12) X . Suppose for contradiction that X is acceptable w.r.t. E(cid:12)in (A, D). Hence:∃Z = ((cid:3), (cid:2), φ) ∈ E(cid:12)s.t. Z ⇒{Y } Y on Y(cid:12) = ({α}, ∅, α) (and so Z ⊀ Y(cid:12))(6)(7)(cid:12)(cid:12)implies Z ⊀1 Y1) Suppose Z ∈ A1. Hence Z ∈ E. Z ⊀ Y2) Suppose Z ∈ A \ A1. Since (cid:2) ⊆ prem(Y ), Y ∈ A1, it must be that (cid:2) ⊆ B1. Hence by Lemma 36 either: i) Z 1 = ((cid:3) ∩B1, (cid:2), (cid:2)) ∈ A1, or ii) Z 1 = ((cid:3) ∩ B1, (cid:2), α) ∈ A1, or iii) Z 2 = ((cid:3) ∩ B2, ∅, (cid:2)) ∈ A2.2.1) In case i) or ii), since ((cid:3) ∩ B1) ⊆ prem(E), and E is a complete extension of (A1, D1), then by Lemma 9, Z 1 ∈ E. Since (cid:12)Z ⊀ Y2.2) In case iii). By Eq. (5), Z 2 ∈ E. But then (∅, (cid:3) ∩ B2, (cid:2)) ⇒E(cid:12) Z 2, contradicting Z 2 acceptable w.r.t. E, and so Z ⇒{Y } Y in (A1, D1), contradicting Eq. (6)., and ≺ is redundance-coherent, Z 1 ⊀ Y, and Z 1 ⇒{Y } Y , contradicting Eq. (6).. Hence Z 1 ⊀1 Y. (cid:2)(cid:12)(cid:12)(cid:12)(cid:12)Corollary 40. Lemma 39 holds for non-redundant pd A F s.Proof. Proof proceeds exactly as in Lemma 39, except that:• ‘Corollary 38’ replaces ‘Lemma 37’ (underlined in the proof of Lemma 39);• In 2) in the proof of Lemma 39, we show as in Corollary 38 that Z ∈ A2 (substituting ‘ Z ∈ A2’ for ‘Y ∈ A2’ in Corol-lary 38) and ((cid:3), ∅, (cid:2)) ∈ A2. We then only need reason to a contradiction as in 2.2) of Lemma 39, which does not assume redundance-coherent preference relations. (cid:2)Lemma 41. Let (A, D) = (A1, D1) ⊕ (A2, D2). Then if Eof (A1, D1).Proof. Suppose E(cid:12)is a complete extension of (A, D).(cid:12)is a complete extension of (A, D) then E = E(cid:12) ∩ A1 is a complete extension Part 1 Since Eadmissible extension of (A1, D1). Hence ∃ X ∈ E, Y ∈ A1, Y ⇒E X on Xis conflict free then E = E(cid:12)(cid:12)(cid:12) ∩ A1 is conflict free.21 Suppose for contradiction that E = E(hence Y ⊀1 X(cid:12)), and:¬∃Z ∈ E s.t. Z ⇒{Y } Y .(cid:12) ∩ A1 is not an (8)Since Y ⊀ X(cid:12), and prem(E) ⊆ prem(E(cid:12)), then Y ⇒E(cid:12) X . By assumption of E(cid:12)being a complete extension of (A, D):Z = ((cid:3), (cid:2), φ) ∈ E(cid:12)s.t. Z ⇒{Y } Y on Y(cid:12) = ({α}, ∅, α), Z ⊀ Y(cid:12).(cid:12)1) Suppose Z ∈ A1. Then Z ∈ E. Since Z ⊀1 Y, Z ⇒{Y } Y , contradicting Eq. (8).2) Suppose Z ∈ A \ A1. Since (cid:2) ⊆ prem(Y ), Y ∈ A1, it must be that (cid:2) ⊆ B1. We then reason to a contradiction as in 2) in the proof of Lemma 39, except that:in 2.1), we have that since ((cid:3) ∩ B1) ⊆ prem(EZ 1 ∈ E;in 2.2), Z 2 ∈ EPart 2 We have shown that E is admissible. Suppose for contradiction that E is not complete. Hence ∃ X /∈ E that is accept-able w.r.t. E. We show X is acceptable w.r.t. EY = ((cid:3), (cid:2), φ), Y ⇒E(cid:12) X on XSince Eis a complete extension of (A, D), then by Lemma 9 Z 1 ∈ E. Suppose:(cid:12)(cid:12) = ({α}, ∅, α), hence Y ⊀ Xis complete, then (by Lemma 9):being complete and Lemma 9.by virtue of E(cid:12)) and E, hence .(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)∀(cid:3) ⊆ prem(E(cid:12) \ E) : (prem( A) = (cid:3)) → A ∈ E(cid:12)and A acceptable w.r.t. E(cid:12)Given Eq. (9) and X is acceptable w.r.t. E, we can apply Lemma 37 to conclude that ∃Z ∈ E(cid:12)acceptable w.r.t. E(cid:12) ∩ A1. Contradiction. (cid:2)is complete, X ∈ E. Hence X ∈ E = E. Since E(cid:12)(cid:12)(9)(cid:12)s.t. Z ⇒{Y } Y . Hence X is 21 Trivially, ∀E, EX ⇒E(cid:12) Y , contradicting Es.t. E ⊆ E(cid:12)(cid:12)is conflict free.(cid:12), X ⇒E Y implies X ⇒E(cid:12) Y . Hence suppose E(cid:12)is conflict free and E is not conflict free. Then X, Y ∈ E ⊆ E(cid:12), X ⇒E Y and so Corollary 42. Lemma 41 holds for non-redundant pd A F s.M. D’Agostino, S. Modgil / Artificial Intelligence 262 (2018) 15–5139Proof. Proof as in Lemma 41, except:• ‘Corollary 38’ replaces ‘Lemma 37’ (underlined);• In 2) in Part 1 of the proof of Lemma 41, we show as in Corollary 38 that Z ∈ A2 (substituting ‘ Z ∈ A2’ for ‘Y ∈ A2’ in Corollary 38) and ((cid:3), ∅, (cid:2)) ∈ A2. Since ((cid:3), ∅, (cid:2)) ∈ Ebeing complete and Lemma 9, this leads to a contradiction as in 2.2) in the proof of Lemma 39. (cid:2)by virtue of E(cid:12)(cid:12)The following is a corollary of Lemmas 39 and 41 and Corollaries 40 and 42:Corollary 43. Let (A, D) = (A1, D1) ⊕ (A2, D2), where (A, D), (A1, D1) and (A2, D2) are (non-redundant) pd A F s. Then:1. If E is a complete extension of (A1, D1) then there exist complete extensions {E 1, . . . , En} of (A, D) such that for i = 1 . . . n, E = E i ∩ A1.2. If {E 1, . . . , En} are complete extensions of (A, D) such that for i = 1 . . . n, E = E i ∩A1, then E is a complete extension of (A1, D1).That there is a one to (possibly) many mapping between complete extensions of (A1, D1) and (A, D) is witnessed by an example in which B1 = {a}, B2 = {b, ¬b}, B = {a, b, ¬b}, and ≺1=≺2=≺= ∅. Then E is a single complete extension of (A1, D1) containing A = ({a}, ∅, a) and E 1 and E 2 are the complete extensions of (A, D), where E 1 contains A and ({b}, ∅, b), and E 2 contains A and ({¬b}, ∅, ¬b).Note that Corollary 43 immediately implies that:1. X is credulously justified under the complete semantics in (A1, D1) iff X is credulously justified under the complete 2. X is sceptically justified under the complete semantics in (A1, D1) iff X is sceptically justified under the complete semantics in (A, D).semantics in (A, D).In [16,61], the non-interference and crash resistance postulates are formulated w.r.t. the ‘consequences’ of proposi-tional instantiations of AFs. Our formalisation of symbols (Definition 4) and syntactic disjointedness for first order theories (Notation 3) allows us to generalise these postulates to first order instantiations of A F s, and show their satisfaction by (non-redundant) pd A F s.Definition 27 (Consequence relation for pd A F s). Let (A, D) be a (non-redundant) pd A F . Then CnT ((A, D)) = {claims(E 1),. . . , claims(En)} where E 1, . . . , En are the T extensions of (A, D), T ∈ {complete, grounded, preferred, stable}.Referring to the above example, and writing Cncp as an abbreviation for Cncomplete , Cncp((A1, D1)) = {Cn({a})}22 and Cncp((A, D)) = {Cn({a, b}), Cn({a, ¬b})}. Recall that we define claims(E) as the conclusions of unconditional arguments that have empty suppositions. Also recall the notation B|S y in Notation 3.Definition 28 (Non interference). Let (A1, D1) be defined by B1 and ≺1, (A2, D2) defined by B2 and ≺2, and (A, D) defined by B1 ∪ B2 and ≺, where (A, D) = (A1, D1) ⊕ (A2, D2), and B1(cid:17)B2. Then non-interference is satisfied iff:Cncp((A1, D1))|symbols(B1) = Cncp((A, D))|symbols(B1)Theorem 44 (Non interference). Non-interference is satisfied by (non-redundant) pd A F s.Proof. By Corollary 43: E is a complete extension of (A1, D1) iff {E 1, . . . , En} are complete extensions of (A, D), where for i = 1 . . . n, E = E i ∩ A1. Then assuming unconditional arguments X s.t. symbols(conclusion( X)) ⊆ symbols(B1):1) If X ∈ E then ∀E i , X ∈ E i .2) If X ∈ E i , X ∈ A ∩ A1, then for j = 1 . . . n, X ∈ E j and X ∈ E.3) If X = ((cid:3), ∅, α) ∈ E i , X ∈ A \ A1, then (cid:3) = (cid:10) ∪ (cid:11), where (cid:10) ⊆ B1, (cid:11) ⊆ B2, (cid:11) (cid:11)= ∅ (since if (cid:11) = ∅ then given Defini-tion 26.2, X ∈ A1) and so (cid:11)(cid:17)(cid:10) ∪ {α}.• Assuming arbitrary pd A F s, then by P4, either:3.1) X3.2) X• Assuming non-redundant pd A F s, then it must be that (cid:10) = ∅ (recall Remark 33), and so by P4we are in case 3.2).(cid:12) = ((cid:10), ∅, α) ∈ A and so (by Definition 26.2), X(cid:12) = ((cid:11), ∅, (cid:2)) ∈ A. By Lemma 9, X(cid:12) ∈ E i , contradicting Theorem 11.(cid:12) ∈ E i , and we are in case 2), or(cid:12) ∈ A1. By Lemma 9, X(cid:12) = ((cid:11), ∅, (cid:2)) ∈ A, and , X(cid:12)22 Where ‘Cn’ is the classical consequence relation.40M. D’Agostino, S. Modgil / Artificial Intelligence 262 (2018) 15–51Cases 2) & 3) show that if an unconditional X is in some E i and symbols(α) ⊆ symbols(B1), then for j = 1 . . . n, there (cid:12) ∈ E. This, together with 1), establishes that: claims(E)|symbols(B1) =is an Xclaims(E i)|symbols(B1), where for i = 1 . . . n, E = E i ∩ A1. Hence the theorem is shown. (cid:2)has conclusion α, and X(cid:12) ∈ E j where X(cid:12)In our example, Cncp((A1, D1))|symbols(B1) = {{a}} and Cncp((A, D)) = {{a}}.We now prove crash resistance, adapting the strategy employed in [16,61]. We show that (non-redundant) pd A F s are non-trivial, and then show that this property, together with non-interference, implies crash resistance.Lemma 45. Let S y be any set of predicate, function and constant symbols. Then there exist (non-redundant) pd A F s (A1, D1)and (A2, D2), respectively defined by B1, ≺1 and B2, ≺2, s.t. symbols(B1) = symbols(B2) = S y, and Cncp((A1, D1))|S y (cid:11)=Cncp((A2, D2))|S y .is a vector of 0 or more terms, and such that −→Proof. Let {P 1, . . . , P n} be the predicate symbols in S y, and for i = 1 . . . n, let αi denote the atomic formula P i(ti ) where (cid:2)−→−→ti ) = {t|t is a function or constant symbol in S y}. Let ni=1 symbols(tiB1 = {α1, . . . , αn}, B2 = {α1 → α1, . . . , αn → αn}, ≺1=≺2= ∅. Then each pd A F has a single complete extension whose unconditional arguments have conclusions that differ: Cncp ((A1, D1)) = {Cn({α1, . . . , αn})} (cid:11)= Cncp((A2, D2)) = {Cn({α1 →α1, . . . , αn → αn})}. (cid:2)Definition 29 (Contaminating base). Let B1 be a base such that symbols(B1) ⊂ symbols(L). B1 is said to be contaminating for (non-redundant) pd A F s iff:there exists a (A1, D1) defined by B1, ≺1, such that for any B2 such that (A2, D2) is defined by B2, ≺2, and B1(cid:17)B2: Cncp((A1, D1)) = Cncp((A, D)), where (A, D) = (A1, D1) ⊕ (A2, D2).Theorem 46 (Crash resistance). There does not exist a contaminating base B for pd A F s and non-redundant pd A F s.Proof. Suppose for contradiction that there exists a contaminating base B1. Hence symbols(B1) ⊂ symbols(L). Let S y =symbols(L) \ symbols(B1). By Lemma 45, there exists a pd A F 3 and pd A F 4 respectively defined by B3, ≺3 and B4, ≺4, such that symbols(B3) = symbols(B4) = S y, and:Cncp(pd A F 3)|S y (cid:11)= Cncp(pd A F 4)|S y . (1)Since B1 is contaminating, then there is a pd A F 1 = (A1, D1) such that:Cncp(pd A F 1) = Cncp(pd A F 1 ⊕ pd A F 3) = Cncp(pd A F 1 ⊕ pd A F 4)Hence Cncp(pd A F 1 ⊕ pd A F 3)|S y = Cncp(pd A F 1 ⊕ pd A F 4)|S y . This, together with (1) implies that Cncp(pd A F 3)|S y (cid:11)=Cncp(pd A F 1 ⊕ pd A F 3)|S y or Cncp(pd A F 4)|S y (cid:11)= Cncp(pd A F 1 ⊕ pd A F 4)|S y .Since symbols(B3) = symbols(B4) = S y, we immediately have that either Cncp(pd A F 3)|B3Cncp(pd A F 4)|B4(cid:11)= Cncp(pd A F 1 ⊕ pd A F 4)|B4 . In either case, Theorem 44 (non-interference) is violated. (cid:2)(cid:11)= Cncp(pd A F 1 ⊕ pd A F 3)|B3 or 4. Instantiating dialectical classical frameworks4.1. C-intelim argumentationWe now instantiate pd A F s in which, in contrast with standard approaches to Cl-Arg [1,33,43], the proof theoretic means for constructing arguments is given. Indeed, we suggest that arguments conceived of as assumptions in support of a con-clusion should be understood as ‘argument schemata’ that are concretely realised as ‘arguments proper’ through provision of the proof theoretic means by which the conclusion is inferred from the assumption. We argue that the persuasive force of a non-trivial argument partly depends on whether valid reasoning steps have been employed in inferring the argumen-t’s conclusion. For example, a mathematical argument claiming that a certain theorem follows from the Euclidean axioms would be incomplete and entirely unpersuasive without explicit representation of the proof steps involved. It is the means by which the conclusion is obtained that renders the argument understandable, and furthermore, one would not want to rely on the recipient expending resources to reconstruct the proof from assumptions to conclusion (we revisit this issue in Section 5 when discussing the ‘transparency’ postulate proposed for practical applications [27]).In this section we therefore ‘instantiate’ pd A F s with propositional natural deduction proofs. We present a non-standard version of classical natural deduction which, given some straightforward restrictions on the application of the rules, does not allow construction of R-contaminated arguments and admits definition of a simple notion of argument ‘depth’. The latter may be taken to reflect the inferential capabilities of resource-bounded agents. We then show that arguments constructed under any fixed bound on their depth, define non-redundant pd A F s that satisfy the rationality postulates. In dialectical frameworks we use the word “assumption” as a general term that refers to both premises and suppositions.M. D’Agostino, S. Modgil / Artificial Intelligence 262 (2018) 15–5141Table 1The intelim rules.INTRODUCTION RULESϕ ψϕ ∧ ψ∧ I¬ϕ¬ψ¬∧ I1¬∧ I2¬(ϕ ∧ ψ)¬(ϕ ∧ ψ)ϕϕ ∨ ψ¬ϕ∨ I1→ I1ϕ → ψψϕ ∨ ψ∨ I2ψϕ → ψ→ I2¬ϕ ¬ψ¬(ϕ ∨ ψ)ϕ ¬ψ¬∨ I¬→ I¬(ϕ → ψ)ϕ¬¬ϕ¬¬IELIMINATION RULESϕ ∨ ψ ¬ϕ∨E1ψϕ ∨ ψ ¬ψ∨E2ϕ¬(ϕ ∧ ψ) ϕ¬∧ E1¬ψ¬(ϕ ∧ ψ) ψ¬∧ E2¬ϕ¬(ϕ ∨ ψ)¬∨ E1¬(ϕ ∨ ψ)¬∨ E2¬ϕϕ ∧ ψϕ∧ E1¬ψϕ ∧ ψψ∧ E2ϕ → ψ ϕ→ E1ψϕ → ψ ¬ψ→ E2¬ϕ¬(ϕ → ψ)¬→ E1ϕ¬(ϕ → ψ)¬ψ¬→ E2¬¬ϕϕ¬¬ETable 2Falsum rules and RB.ϕ ¬ϕRNC(cid:2)(cid:2)ϕXFQ(cid:2), [ϕ]D1ψ(cid:3), [¬ϕ]D2ψRBψ4.1.1. C-intelim natural deductionNatural deduction proofs apply intuitive introduction and elimination rules (or “intelim rules” for short) that are akin to natural modes of human reasoning (in contrast to other proof theories e.g., axiomatic systems, Gentzen-style sequent calculi or resolution), and are thus particularly appropriate if one is to simulate human understanding and reasoning.23We use a non-standard version of classical natural deduction [20,22,23], that we call “C-intelim” (for “classical intelim”). As discussed in [20,24], this version is more faithful to the intuitive classical meaning of the logical operators and naturally suggests a simple measure of the “depth” of an argument. This is used to define a hierarchy of tractable, albeit increasingly complex, approximations to classical propositional logic that converge to it in the limit (for ideal “unbounded” agents). Each level in the hierarchy equates with increments in the maximum depth of the arguments that can be constructed and the resources required to construct such arguments. Thus, C-intelim proofs provide a perspicuous account of argumentation for resource-bounded agents employing natural rules that are faithful to the classical interpretation of the logical operators.The C-intelim rules are displayed in Table 1. Besides the intelim rules we have two extra rules for the “falsum” constant (cid:2) (the first two displayed in Table 2), representing a sentence which is false in every possible world. RNC (“Rule of Non-Contradiction”) simply says that two contradictory sentences cannot be both true, and the XFQ (Ex Falso Quodlibet) rule says that every sentence follows from (cid:2). The two falsum rules taken together imply that any arbitrary conclusion follows from a contradiction.23 For a recent contribution that makes use of a restricted version of standard Gentzen-style natural deduction in the context of formal argumentation theory see [36].42M. D’Agostino, S. Modgil / Artificial Intelligence 262 (2018) 15–51The intelim and falsum rules contain no discharge rules, namely rules that involve the temporary introduction of as-sumptions that are subsequently “discharged”, to the effect that their conclusion no longer depends on them.24 To obtain a complete set of rules for classical propositional logic we only need add a single discharge rule: if we have a deduction D1of ψ depending on assumptions (cid:2) ∪ {ϕ} and a deduction D2 of ψ depending on assumptions (cid:3) ∪ {¬ϕ}, we thereby have a deduction of ψ depending on (cid:2) ∪ (cid:3). This typical pattern of classical case reasoning relies on the Aristotelian principle of bivalence; a cornerstone of classical semantics whereby any sentence is either true or false, and there are no other possibil-ities. Hence we call this pattern Rule of Bivalence (RB), which is the third rule displayed in Table 2 where the conclusion ψdoes not depend on the “discharged” assumptions ϕ and ¬ϕ that are enclosed in square brackets.C-intelim proofs can be presented using the standard natural deduction tree format in which the conclusion is at the root and the assumptions at the leaves. However this format involves a good deal of redundancy,25 and we therefore resort to a different more concise format that is better suited to algorithmic treatment.26 In this new format proofs are still represented by trees, but these trees branch downwards (like Smullyan’s Tableaux). The premises of each application of the intelim or the falsum rules do not occur on adjacent branches, but on the same branch as the conclusion, and anywhere above it. So, the application of these rules is sequential, and we call an intelim sequence for (cid:2) any sequence of formulae generated in this way. On the other hand, each application of RB splits an intelim sequence into two branches: one containing a formula ϕand the other its negation ¬ϕ, as in the examples displayed in Fig. 4. In this case we say that RB has been applied to ϕ, and ϕ is the RB-formula of this RB application. Every application of RB introduces, on each branch, an extra assumption, that we call virtual to distinguish it from the actual assumptions that are usually listed at the top, starting from the root. For example, in the leftmost branch of the first tree in Fig. 4, the formula ¬q is obtained from the actual assumption p → ¬qat the top of the tree and from the virtual assumption p by means of an application of the rule → E1; and r is obtained from the derived formula ¬q and the actual assumption q ∨ r by means of an application of ∨E1. [22,23] argue that the minimum number of nested applications of RB required to develop a deductive argument, provides a natural and plausible measure of the ‘difficulty’ involved in constructing it.In the sequel we shall use the expression “tree of formulae” as an abbreviation of “tree whose nodes (except possibly the root) are labelled with formulae”. The special case when the root is unlabelled will be used to represent proofs from the empty set of assumptions (starting with an application of the RB rule).Definition 30 (C-intelim trees, proofs, refutations). A C-intelim tree based on a set (cid:2) is a tree of formulae such that (cid:2) is the set of all its actual assumptions and every other node results from the application of one of the C-intelim rules. A C-intelim proof of ϕ depending on (cid:2) is a C-intelim tree based on (cid:2) such that (i) ϕ occurs as the final formula in every branch and (ii) all actual assumptions in (cid:2) are used as premises of some rule application. A C-intelim refutation of (cid:2) is a C-intelim proof of (cid:2) depending on (cid:2).C-intelim is sound and complete for classical propositional logic: if ϕ is a classical consequence of (cid:2), then there is a C-intelim proof of ϕ depending on some (cid:3) ⊆ (cid:2). Fig. 4 shows examples of C-intelim proof trees. The actual assumptions are marked with a ∗.A crucial role for practical applications in classical logic argumentation is played by normal C-Intelim proofs. These normal proofs can be generated by straightforward restrictions on the applications of the rules that (i) limit the choice of the RB-formula of an RB-application to a tractable space defined by the assumptions and the conclusion and (ii) avoid obvious redundancies in the construction of a proof. More specifically normal C-intelim proofs: (a) enjoy the (weak) subformula property,27 which makes their construction amenable to algorithmic treatment, and (b) do not allow the construction of R-contaminated arguments (as described in Section 3.6, Definition 22).It can be shown (see [24]) that restricting to normal C-intelim proofs involves no loss of deductive power in that for each C-intelim proof there exists a normal one with the same assumptions and the same conclusion. The simple restrictions on the construction of normal C-intelim proofs ensure that such proofs are not trivially redundant (see [24] for a discussion). This allows us to bar convoluted proofs such as those shown on the left in each of Fig. 5 (a), (b), (c) and (d) and to generate the normal ones on the right instead. In particular, notice the redundant proof in Fig. 5(a), which makes contrived use of an assumption (¬q) that is syntactically disjoint from the other assumptions and from the conclusion.4.1.2. Depth-bounded instantiations of p DC F sOne of the main advantages of C-intelim deduction is that, unlike standard natural deduction, it immediately provides a sharp measure of the depth of an argument that can be associated with the resources required for its construction.In the sequel we shall restrict our attention to normal C-intelim proofs.24 By contrast, in Gentzen-style natural deduction, ∨ elimination and →-introduction are discharge rules.25 Whenever a formula inferred from assumptions is used more than once as a premise of further inferences, its proof tree has to be replicated.26 See [24, Section 8].27 Every formula occurring in the proof is a subformula of the premises or of the conclusion, or the negation of such a subformula.M. D’Agostino, S. Modgil / Artificial Intelligence 262 (2018) 15–5143Fig. 4. C-intelim proofs. Actual assumptions are marked with “*”.Fig. 5. Convoluted proofs are shown on the left, and their non-convoluted versions are shown on the right. Connection links between nodes have been removed for ease of presentation.Definition 31 (Depth of C-intelim proofs). The depth of a C-intelim proof T is the maximum number of virtual assumptions occurring in a branch of T .44M. D’Agostino, S. Modgil / Artificial Intelligence 262 (2018) 15–51A C-intelim proof of depth 0 contains no virtual assumptions, i.e., no application of RB (and is therefore a C-intelim sequence). A C-intelim proof of depth k contains at most k nested applications of RB. Consider the rightmost C-intelim proof in Fig. 4 which makes use of one application of RB. A reasoning agent (whether human or artificial) with actual assump-tions p → q and p → ¬q considered true, does not possess the information that ¬p is true, unless it is able to simulate information states containing virtual assumptions. This is a non-trivial step both from the computational (and arguably cog-nitive) viewpoint, and the depth at which the iterated use of such virtual assumptions is required is an interesting measure of the computational effort involved in extracting the information (¬p) implicitly contained in the actual assumptions. Let C-Intelimk be the system allowing only (normal) C-intelim proofs of depth ≤ k.Definition 32 (C-Intelimk). Let (cid:10)k⊆ 2L × L be defined as follows:(cid:2) (cid:10)k ϕ if and only if there is a C-intelimk proof of ϕ depending on some (cid:3) ⊆ (cid:2).Proposition 47. For each k ∈ N, whether or not (cid:2) (cid:10)k ϕ can be decided in time O (nk+2), where n is the total number of occurrences of symbols in (cid:2) ∪ {ϕ}.For a proof see [23].The relations (cid:10)k of Definition 32 form a sequence of increasingly powerful deducibility relations that are all (by Proposi-tion 47) tractable and converge to classical propositional logic, which is the limit of the sequence for k approaching infinity.Definition 33 (k-depth C-intelim arguments). Let T be any normal C-intelimk proof of ϕ depending on (cid:11) (recall – Defini-tion 30 – that (cid:11) are the actual, and not virtual assumptions in T ), where ∀α ∈ (cid:11), α is annotated in T by p(cid:27) or s(cid:27), where p(cid:27) stands for “premise” and s(cid:27) stands for “supposition”.Then ((cid:3), (cid:2), ϕ) is a C-intelimk argument, where (cid:3) ∪ (cid:2) = (cid:11), α ∈ (cid:3) iff α is annotated by p(cid:27), and α ∈ (cid:2) iff α is annotated by s(cid:27). We call ((cid:3), (cid:2), ϕ) the C-intelimk argument associated with T .A set A of C-intelimk arguments is defined by B if ∀ X ∈ A, assumptions( X) ⊆ B.The following key result is shown in [24]:Proposition 48. If T is a normal C-intelimk proof of ϕ depending on (cid:2), then the C-intelimk argument associated with T is not R-contaminated.Moreover [24] shows that if an argument associated with T is contaminated, and so given Proposition 48, can only by E-contaminated (e.g. a proof of q from p, ¬p), then:Proposition 49. If an argument associated with a normal C-intelimk proof T depending on (cid:2) is E-contaminated, then the proof is said to be improper in that every branch in the downward-branching tree ends with an application of XFQ (and so (cid:2) (cid:10)c (cid:2)).Remark 50. [24] shows that it is easy to turn an improper proof into a proof of (cid:2) (i.e., a refutation) of the same depth.Proposition 48 shows that normal proofs satisfy a basic relevance requirement, which is, however, weaker than the stan-dard requirement that an argument’s assumptions are subset-minimal. For example, recalling the discussion in Section 3.2, and in particular Footnote 8 on p. 22, one could build an argument for q depending on {p, p → r, p → q, r → ((p → q) → q)}which is not R-contaminated and in which all the assumptions are actually used (i.e., it is relevant in the sense of relevance logic), although it is not subset-minimal.We now formally instantiate non-redundant pd A F s (recall Definition 25) with C-intelimk arguments. Firstly, we show that and P5 on the arguments in given a non-redundant pd A F instantiated by C-intelimk arguments, then the conditions P1–P4the pd A F can be satisfied. This follows from the following result:(cid:12)Proposition 51. Let A be any set of C-intelimk arguments defined by B. Then there exists a set A(cid:12) ⊇ A of C-intelimk arguments defined by B such that A(cid:12)(cid:12)satisfies P 1– P 4and P 5.Proof. Proposition 48 states that P5 is satisfied by any set of C-intelimk arguments. P1 is trivially satisfied, since for any depth n ≥ 0, α ∈ B implies ({α}, ∅, α) ∈ A(cid:12). P2 is trivially satisfied given that logically equivalent arguments are of equal depth. P3 is satisfied given the following result:Let ((cid:3), ∅, α) and ((cid:2), ∅, α) be C-intelimk arguments. Then either ((cid:3), ∅, (cid:2)) or ((cid:2), ∅, (cid:2)) or ((cid:3) ∪ (cid:2), ∅, (cid:2))are C-intelimk arguments.(10)M. D’Agostino, S. Modgil / Artificial Intelligence 262 (2018) 15–5145Given the structure of (normal) C-intelimk arguments, the proof of (10) follows again from results in [24]. In particular, if one of the two arguments is improper, then it is easy to turn its proof into a normal refutation of the same depth (Remark 50). If neither is improper, then it is easy to combine the two arguments via a single application of the RNC rule to obtain an argument of the same depth concluding to (cid:2). For P4, observe that given satisfaction of P5 and Remark 33, it suffices to show that:(cid:12)Let ((cid:3), (cid:2), α) be a C-intelimk argument such that (cid:3) ∪ (cid:2)(cid:17)α. Then there exists a C-intelimk argument ((cid:3), (cid:2), (cid:2)). (11)This is again straightforward given that such an argument cannot be R-contaminated, hence is E-contaminated, improper, and easily turned into an argument concluding (cid:2). (cid:2)Proposition 51 allows instantiation of a non-redundant pd A F by C-intelimk arguments:Definition 34 (C-intelimk non-redundant pd A F ). A C-intelimk non-redundant pd A F defined by B and ≺ is a tuple (A, D)where A is any set of C-intelimk arguments satisfying P1, P2, P3, P4and P5.(cid:12)The results in Sections 3.4 and 3.7.1 show that the consistency and closure postulates are satisfied by C-intelimk non-redundant pd A F s defined by any B and ≺, and the non-interference and crash resistance postulates are satisfied under the assumption that ≺ satisfy Pref1 (given that P5 is satisfied, it is not necessary that ≺ satisfies relevance-coherence).Example 52. We conclude by recalling the example in Section 3.2, on p. 22, in which [43] requires that X , Y and Z =({p → q, p → ¬q}, ∅, ¬p) can be constructed, to ensure no admissible extension can contain arguments with premises p, p → q and p → ¬q. However, suppose a 0-depth C-intelim pd A F (A, D). Then A does not contain the 1-depth argument Z (the rightmost proof in Fig. 4), but does contain the 0-depth arguments ({p, p → ¬q}, ∅, ¬q), ({p, p → q}, ∅, q) and (∅, {p, p → q, p → ¬q}, (cid:2)).4.2. A resource-bounded dialectical characterisation of preferred subtheoriesSection 2.1 reviewed [43]’s argumentation-based characterisation of non-monotonic inference relations defined by Pre-ferred Subtheories [13]. Recall that arguments are defined by a totally ordered base, and the Elitist preference relation is used. We now provide a dialectical resource-bounded characterisation of Brewka’s non-monotonic inference relations. First, we show that the Elitist preference relation, defined for the more general case of a base equipped with a partial preordering ≤ (where as usual < is defined as α < β iff α ≤ β and β (cid:6) α) is a coherent strict partial ordering.Definition 35 (Elitist preference ordering). Let X, Y be dialectical classical logic arguments defined by a base B, and ≤ a partial preordering over B. Then X ≺E Y iff ∃α ∈ assumptions( X) such that ∀β ∈ assumptions(Y ), α < β.Proposition 53 (Properties of elitist preferences). ≺E is a strict partial ordering, invariant modulo logical equivalence (imle), dialecti-cally coherent, and relevance-coherent.Proof. In this proof we abuse notation writing α ∈ A instead of α ∈ assumptions( A).• ≺E is a strict partial ordering:Irreflexivity: Suppose for contradiction that X ≺E Y and Y ≺E X . Then ∃α ∈ X s.t. ∀β ∈ Y , α < β, and ∃β ∈ Y s.t. ∀α ∈ X , β < α. But then for some α, β, α < β and β < α, contradicting the asymmetry of the strict partial ordering <.Asymmetry: Suppose for contradiction that X ≺E X . Then ∃α ∈ X s.t. α < α, contradicting the irreflexivity of <.Transitivity: Suppose X ≺E Y ≺E Z . Firstly, Y ≺E Z implies assumptions(Y ) (cid:11)= ∅ and ∃β ∈ Y s.t. ∀γ ∈ Z , β < γ . By assumption of X ≺E Y , ∃α ∈ assumptions( X) s.t. α < β. Hence by transitivity of <, ∀γ ∈ Z , α < γ . Hence X ≺E Z .• ≺E is imle. Suppose X ≺E Y , and Xassumptions(Y ). Hence X• ≺E is dialectically coherent. For the proof of Pref1, consider any X = (∅, (cid:3), (cid:2)). By the properties of classical logic, (cid:3) is a non-empty finite (since B is finite) set {α1, . . . , αn}. Suppose for contradiction that ∀i: X ≺E ({αi}, ∅, αi). Abusing notation by representing arguments by their assumptions, we have the sequence:(cid:12)) = assumptions( X) and assumptions(Y(cid:12) ∈ [Y ]. Then assumptions( X(cid:12) ∈ [ X], Y(cid:12) ≺E Y(cid:12)) =.(cid:12)S1 = {α1, . . . , αn} ≺ {α1} . . . Sn = {α1, . . . , αn} ≺ αn1. For S1, by irreflexivity of <, α1 ≮ α1. If n = 1, then this contradicts S1. Else we can assume without loss of generality 2. For S2, by asymmetry and irreflexivity of <, α1 ≮ α2, α2 ≮ α2. If n = 2, then this contradicts S2. Else, we can assume that α2 < α1.without loss of generality that α3 < α2.46M. D’Agostino, S. Modgil / Artificial Intelligence 262 (2018) 15–513. For S3, by transitivity of <, α3 < α1, and so by asymmetry and irreflexivity α1 ≮ α3, α2 ≮ α3, α3 ≮ α3. If n = 3, then this contradicts S3. Else, we can assume without loss of generality that α4 < α3.4. It is easy to see that one can continue reasoning in the same way, until for Sn , αi ≮ αn for i = 1 . . . n, contradicting Sn.For the proof of Pref2, let X = ({α}, ∅, α), Y = ((cid:3), ∅, α) and Y(cid:12)), Yassumptions(Y ) s.t. β < α. Since assumptions(Y ) ⊂ assumptions(Y• ≺E is relevance-coherent. Suppose Y = ((cid:3), ∅, α) ≺E X . Hence ∃β ∈ (cid:3), and so β ∈ (cid:3) ∪ (cid:2) for any Y∀α ∈ assumptions( X): β < α. (cid:2)(cid:12) = ((cid:3) ∪ {α}, ∅, φ). Suppose Y ≺E X . Then ∃β ∈(cid:12) ≺E X .(cid:12) = ((cid:3) ∪ (cid:2), ∅, α), s.t. We now adapt [13]’s Preferred Subtheories so as to accommodate agents whose classical reasoning is resource-bounded:Definition 36 (Resource bounded preferred subtheories). Let (cid:10)r ⊆ (cid:10)c be a resource-bounded classical consequence relation, such that: 1) for any (cid:3), if β ∈ (cid:3) then (cid:3) (cid:10)r β; 2) if (cid:3) (cid:10)r α and (cid:3) (cid:10)r ¬α then (cid:3) (cid:10)r (cid:2). We say that (cid:3) is r-inconsistent iff (cid:3) (cid:10)r (cid:2); r-consistent otherwise.Let (B, ≤) be a totally ordered set of propositional wff and let B1, . . . , Bn be a partition of B such that for all α ∈ Bi , and all β ∈ B j, i < j iff β < α. An r-preferred subtheory (cid:11) is a set (cid:11)1 ∪ . . . ∪ (cid:11)n such that for i = 1, . . . , n, (cid:11)1 ∪ · · · ∪ (cid:11)i is a ⊂-maximal r-consistent subset of B1 ∪ · · · ∪ Bi .We now show a correspondence between the r-preferred subtheories of a base B and the stable extensions of a pd A Fdefined by B, and using Elitist preferences. Note that in what follows we use the notation Args((cid:11)) = { X|prem( X) ⊆ (cid:11)}.Theorem 54. Let (A, D) be defined by B and ≺E be defined on the basis of a total ordering ≤ over B, and such that ((cid:3), (cid:2), α) ∈ A iff (cid:3) ∪ (cid:2) (cid:10)r α. Then:1) If (cid:11) is an r-preferred subtheory of B, then E = Args((cid:11)) is a stable extension of (A, D).2) If E is a stable extension of (A, D), then (cid:11) =X∈E Prem( X) is an r-preferred subtheory of B.(cid:2)Proof.Proof of 1): We show E is conflict free. Since (cid:11) is r-consistent, (cid:11) (cid:4)r (cid:2). Suppose for contradiction that E is not conflict free, in which case ∃ X, Y ∈ E s.t. X = ((cid:3), (cid:2), φ) (φ = (cid:2) or β) and X ⇒E Y on β ∈ prem(Y ). Since (cid:3) ⊆ prem(E) and (cid:2) ⊆ prem(E)(given Y ∈ E), then φ = (cid:2) implies (cid:11) (cid:10)r (cid:2). φ = β implies (cid:11) (cid:10)r β and since β ∈ prem(Y ), (cid:11) (cid:10)r β. Hence (cid:11) (cid:10)r (cid:2). Contradiction.We show ∀Y ∈ A \ E, ∃ X ∈ E s.t. X ⇒{Y } Y . Consider any such Y (Y cannot be an argument of the form (∅, (cid:3), φ) since any such Y is in E = Args((cid:11))). Then ∃γ ∈ prem(Y ), γ /∈ (cid:11). By construction, (cid:11) = (cid:11)1 ∪ . . .∪ (cid:11)n such that for i = 1 . . . n, (cid:11)1 ∪ . . . ∪(cid:11)i is a maximal r-consistent subset of B1, . . . , Bi . Hence, suppose γ ∈ B j for some j = 1 . . . n. Then (cid:11)1 ∪ . . . ∪ (cid:11) j ∪ {γ } (cid:10)r (cid:2). Hence ∃ X = ((cid:3), {γ }, (cid:2)) ∈ Args((cid:11)1 ∪ . . . ∪ (cid:11) j), and so X ∈ E. Since γ ∈ B j , and (cid:3) ⊆Bk, then X ⊀E ({γ }, ∅, γ ). Hence X ⇒{Y } Y on γ .jk=1(cid:2)X∈E Prem( X) is r-consistent. Suppose for contradiction that (cid:11) (cid:10)r (cid:2). Then Z = (∅, (cid:3), (cid:2)) ∈ AProof of 2): We show that (cid:11) =for some (cid:3) ⊆ (cid:11). Hence ∀α ∈ (cid:3), ∃B ∈ E s.t. Z ⇒E B on α,28 contradicting E is stable.Now let (cid:11)1, . . . , (cid:11)n be the partition of the r-consistent (cid:11) s.t. for i = 1 . . . n, (cid:11)i is a (possibly empty) subset of Bi in the stratification B1, . . . , Bn of B. Suppose for contradiction that for some i, (cid:11)1 ∪ . . . ∪ (cid:11)i is not a ⊂-maximal r-consistent subset of B1 ∪ . . . ∪ Bi . Without loss of generality we can assume that for k = 1 . . . i − 1, (cid:11)1, . . . , (cid:11)k is a ⊂-maximal r-consistent subset of B1, . . . , Bi−1. Then ∃α ∈ Bi s.t.(cid:2)i) α /∈ (cid:11)iii) (cid:11)1 ∪ . . . ∪ (cid:11)i−1 ∪ (cid:11)i ∪ {α} (cid:4)r (cid:2).Given i), Y = ({α}, ∅, α) /∈ E. Since E is stable, ∃ X ∈ E, X ⇒{Y } Y , where:a) X = ((cid:3), {α}, (cid:2)) or b) X = ((cid:3), {α}, α) or c) X = ((cid:3), ∅, α).(cid:12) ⇒E X ), and the latter implies {α} (cid:10)r (cid:2), contradicting ii)., and in b) we have (by P2) XNote that since E is stable then E is complete (see immediately following Definition 15 and Footnote 15). Suppose either (cid:12) = (∅, (cid:3), (cid:2)) ∈ AZ = ((cid:3), ∅, (cid:2)) ∈ A or ({α}, ∅, (cid:2)) ∈ A. The former contradicts X ∈ E is acceptable w.r.t. E (given that Zand Z(cid:12) = ((cid:3) ∪ {α}, ∅, α) ∈ A.Let us now rename X in c) to X, and having shown ((cid:3), ∅, (cid:2)) /∈ A and ({α}, ∅, (cid:2)) /∈ A, we have by P3 that ((cid:3) ∪ {α}, ∅, (cid:2)) ∈ A. For both instances of XThese cases and case a) imply (cid:3) ∪ {α} (cid:10)r (cid:2). But then given ii) and (cid:3) ⊆ (cid:11)1, . . . , (cid:11)n, it must be that ∃β ∈ (cid:3), s.t. β ∈ (cid:11) j , j > i. But then in cases a), b) and c), X ≺E Y , contradicting X ⇒{Y } Y . (cid:2)(cid:12)(cid:12)The above correspondence yields a resource bounded dialectical characterisation of non-monotonic inference in Preferred Subtheories (both sceptical and credulous inference relations, as described in Section 2.1).28 Note also that by virtue of ≺E satisfying Pref1 it must be that ∃α ∈ (cid:3) s.t. Z ⊀E ({α}, ∅, α) and so ∃B ∈ E s.t. Z ⇒E B on α.M. D’Agostino, S. Modgil / Artificial Intelligence 262 (2018) 15–51475. Related workDesign guidelines for theoretical models of argumentation suitable for real world applications29 have been proposed by Dung et al. in [27]. Firstly, submitted arguments and attacks should be transparent (Postulate 2.1) in that the com-putational cost of verifying: 1) the legitimacy of submitted arguments should be at most polynomial in the size of the (constructed) arguments; 2) that an argument attacks another should be at most linear (in the size of the argument’s con-clusion). Our approach satisfies the first desideratum,30 since we drop the consistency and subset minimality checks on arguments’ assumptions, which is what makes legitimacy checks intractable under a widely accepted conjecture in compu-tational complexity. By contrast, the time required to check the correctness of a constructed proof is bounded above by a polynomial in the size of the proof.31 As for the second desideratum, we note that it is satisfied by the purely “declarative” notion of attack in Definition 11. However, we also make essential use of the more complex notion of dialectical defeat in Definition 15, that allows the defeating argument X to include, as suppositions, any premises of arguments in the extension S with respect to which the acceptability of the defeated argument Y is challenged. This notion of defeat can be checked in polynomial time with respect to suppositions( X) ∪ prem(S ∪ {Y }) ∪ {conclusion( X)}.32 Transparency guarantees that con-structed arguments and defeats can be understood by any parties, independently of their level of sophistication [27], with a use of resources which is polynomial with respect to the complexity of the input.33 We go one step further in this paper, arguing against the assumption that an agent constructs all arguments defined by a base; in particular because they may be resource bounded. Hence we drop the consistency and subset minimality checks on arguments’ assumptions, and formally study partially instantiated frameworks. Moreover, for depth-bounded instantiations (see Section 4.1.2), it is worth noting that even finding a C-intelimk proof takes time at most polynomial in the size of the input assumptions and conclusion (see Proposition 47).Secondly, an argument’s assumptions should be relevant to its conclusion (Postulate 2.2), at least in the “weaker sense [...] that the argument is a defeasible proof of its claim from its support, without any obvious redundancy of any parts of the support” [27, p. 187, our emphasis]. In this paper we propose an analogous notion of “obvious” redundancy in terms of the syntactic unrelatedness of some part of the assumptions to the other assumptions and to the conclusion, which unlike that imposed by subset minimality, can be enforced proof theoretically (as shown in Section 4).Thirdly, the no dismissal postulate (Postulate 2.3) proposes that legitimate arguments should not be dismissed without reason, and if dismissed (i.e., not submitted), their dismissal should not change the semantics of the given argumentation framework. We concur in the sense that all arguments constructed must be included in a pd A F , unless their exclusion does not change the semantics. Related to the no dismissal postulate, ‘redundant’ arguments are distinguished from ‘non-redundant’ arguments in [27], where some Y is redundant if there is an X that attacks every Z that is attacked by Y , and any Z attacking X also attacks Y . One can then, having partitioned all the arguments defined by a base, exclude those that are redundant, while guaranteeing that the status of non-redundant arguments will remain unchanged.A key feature of our approach is the distinction between premises accepted as true, and suppositions assumed true for the sake of argument. One can thus model the dialectical move of showing that an interlocutor’s supposed premises, together with premises accepted as true, imply a contradiction. Caminada [14] is similarly motivated to develop accounts of argumentation for application in dialogues involving human and computational agents. He formalises what he terms ‘hang yourself’ (HY) arguments built from a language consisting of premises that are literals – atomic propositions and their negations – as well as defeasible rules L0 ∧ . . . Ln−1 ⇒ Ln and ‘foreign commitments’ (cid:3) L. The latter refer to premises and conclusions of rules in attacked arguments, by way of supposing these to be true for the sake of argument. HY argu-ments can only reference premises or conclusions in an attacked argument Y (rather than in additional arguments used to defend Y ). Clearly, Caminada is concerned with formalising intuitions similar to ours, albeit in a more restricted logical setting, only under the grounded semantics, and without accommodating the use of preferences. Satisfaction of rationality postulates is not studied in [14].It is worth noting at this point that the distinction between premises and suppositions in ((cid:3), {φ1, . . . , φn}, ψ) cannot equivalently be made using the standard ontology, by an argument ((cid:3), φ1, . . . , φn → ψ). This does not faithfully represent the intuitive meaning of the conditional claim because of the well-known qualms concerning the use of material implication to express a kind of entailment [5]. For example, most reasoners would not be prepared to accept that the falsity of such a conditional claim implies that all the φi are factually true, nor that the factual falsity of one of the premises in φi implies that the claim is true. Moreover, one would then either only be able to use such arguments as attacks on sets of premises rather than individual premises, or require that the premises of the attacked argument contain ¬(φ1, . . . , φn → ψ).29 The guidelines are stated in the context of applications involving computational and/or human agents.30 This requirement was first put forward by Cook and Rechow, in their seminal [18].31 This depends on the proof system adopted, but is certainly true for natural deduction systems like the one presented in Section 4. Indeed, we are unaware of any conventional proof systems for classical logic whose proofs cannot be verified in polynomial time.32 Note also, that in practice, the check can be restricted to the subset Ssuppositions( X) (recall Footnote 14 on page 18).33 For dialectical defeats, the input includes, besides the conclusion, the suppositions of the defeating argument, the defeated argument Y , and the set Swith respect to which it is intended as a defeat.of S consisting of the arguments of S whose premises are actually referenced in (cid:12)48M. D’Agostino, S. Modgil / Artificial Intelligence 262 (2018) 15–51Recently, pragmatic considerations also motivate dropping consistency and subset minimality checks on propositional ar-guments in [6,7]. Arguments are Gentzen style sequents and arguments with inconsistent premises are attacked by sequents with empty antecedents. In this work, the distinction between premises and suppositions, and the use of preferences are not considered. The postulates in [15] are not studied and neither is there consideration of partially instantiated frame-works. Types of redundancy in arguments are also identified in the context of assumption based argumentation (ABA), and are excluded by switching from a conception of arguments as trees to graphs [19]. While ABA does not capture classical logic argumentation, insights from [19] may potentially usefully be studied in the setting of Cl-Arg.A key study of propositional classical logic instantiations of Dung A F s [33] considers various definitions of attacks amongst a (in general infinite) set of arguments defined by a base, and study (without use of preferences) consistency postulates closely related to those in [15] and the premise consistency postulate described here in Section 3.4. The two attack relations shown to be well behaved are those in which the attacking argument’s conclusion is classically equivalent to, respectively classically entails, the negation of a premise in the attacked argument.34 Note that neither of these two attack definitions satisfy condition 2) of the transparency postulate described above.[43]’s study of classical logic argumentation with preferences, as an instance of the ASPICframework, has been reviewed (in Section 2) and compared with our approach at various points in this paper. In summary, the ASPICinstantiation requires checks on the consistency of arguments’ premises and does not model the dialectical demonstration that a set of arguments’ premises are inconsistent. While the foreign commitment problem has been addressed in [17], by allowing attacks on that accommodates classical logic instantiations, the consistency and closure arguments’ conclusions in a version of ASPICrationality postulates of [15] only then hold for the grounded semantics, and then only if argument preferences are defined by a totally ordered base B under the Elitist principle [17]. In this paper we have argued that subset minimality is a blunt and prohibitively expensive35 instrument for ensuring non-redundancy of an argument’s premises. As already discussed, also eschews subset minimality checks on arguments’ premises, and show that the argumentation defined inferences ASPICremain unchanged under the assumption that preference relations do not strengthen non-subset minimal arguments. We have advocated a notion of non-redundancy defined in terms of the syntactic relatedness of formulae; one that can be enforced through appropriate restrictions on applications of proof rules in which case no such assumption on preference relations is required.++++Satisfaction of the non-interference and crash resistance postulates [16] is not studied for the ASPICformalisation of Cl-Arg. Consistency and closure are satisfied by complete extensions, for a restricted class of (reasonable) preference relations, and assuming all arguments defined by a base are included in an A F . However we show direct consistency for admissible extensions, and (modified) closure postulates for complete extensions, assuming arbitrary preference relations and for par-tially instantiated frameworks. Note that recent work [28] studies propositional instantiations of A F s that combine strict and defeasible rules, and without use of preferences. Dung and Thang [28] show that to guarantee closure and consistency, it is not necessary that the strict inference rules satisfy the property of contraposition (see [15,43]). Their aim is different to ours. We consider first order classical logic instantiations with preferences in which all arguments are definable by a base, while we drop the assumption that all such arguments are constructed and included in a framework in order to ensure satisfaction of closure, consistency and the non-contamination postulates.+A number of works attempt to show satisfaction of the non-interference and crash resistance postulates for propositionalargumentation formalisms that integrate deductive and defeasible reasoning. In [16], propositional logic programming and Default Logic [54] instantiations of Dung frameworks are shown to satisfy these postulates under the semi-stable semantics. In [61], arguments are built from a set of classically consistent propositional formulae P , and defeasible (D) and strict infer-ence rules. The latter encode only those classical inferences (cid:3) (cid:10)c α such that the atoms in (cid:3) ∪ {α} are a subset of the atoms appearing in P and D. Wu and Podlaszewski [61] relate the constructed arguments by attacks and so do not consider the use of preferences. Inconsistent arguments are identified as those whose contained premises together with the conclusions of defeasible rules are classically inconsistent. They then show satisfaction of the consistency, closure, non-interference and crash resistance postulates for ‘inconsistency cleansed’ Dung frameworks in which inconsistent arguments are excluded. Finally, Grooters and Prakken [34] define a version of the ASPICframework in which the strict inference rules encode inference in [55]’s paraconsistent logic. Essentially, arguments are built from premises, defeasible inference rules and strict inference rules, where the latter encode classical inferences from only consistent sets of formulae. Grooters and Prakken [34] focus on showing that the adapted ASPICframework satisfies closure and consistency postulates. Satisfaction of non-interference and crash resistance is not shown (although the authors state that satisfaction of these postulates can be taken for granted given the absence of the Ex Falso principle).++Finally, note that this paper revises and substantially extends [25]. We have revised the definition of attacks and defeats originating from arguments concluding (cid:2), modified the conditions on arguments in pd A F s, and specified a new class of non-redundant frameworks that exclude R-contaminated arguments. The closure and consistency postulates are satisfied 34 Both these attacks are shown to be equivalent to the undermine attacks used in this paper, in the sense that the complete extensions are the same (even when assuming use of preferences) [43].35 Note that there are attempts to ameliorate the computational expense of the consistency and subset minimality checks; most notably [29], in which algorithms are implemented for generating arguments whose claims are clauses, from propositional knowledge bases in clausal form, where connection graphs are used to reduce the computational expense. Tests on these implementations yield encouraging results, and the authors indicate that a compre-hensive empirical evaluation will be the subject of future work.M. D’Agostino, S. Modgil / Artificial Intelligence 262 (2018) 15–5149for a restricted class of preference relations in [25], whereas this paper shows satisfaction of these postulates for arbitrary preference relations. This paper also additionally: 1) formally proves the Fundamental Lemma and existence of a unique least fixed point of a pd A F ’s characteristic function; 2) provides a comprehensive study of two types of contaminated arguments; 3) formally proves the non-interference and crash resistance postulates, generalised here to first order argumen-tation; 4) studies instantiation of pd A F s by natural deduction proof theories that exclude R-contaminated arguments and accommodate agents that have bounds on their inferential capabilities.6. ConclusionsDung’s theory of argumentation has been proposed as a basis for applications, in large part because of its provision of intuitive dialectical characterisations of non-monotonic inference for individual and distributed (dialogical) reasoning accommodating computational and human agents. We have argued that such applications require that the theory account for resource bounded agents and features of real-world dialectical reasoning. Our focus has been on classical logic instantiations of Dung argumentation frameworks (Cl-Arg) that yield non-monotonic inference relations over first order knowledge bases. We have shown that features of current formulations of Cl-Arg that suffice to ensure satisfaction of rationality postulates, preclude satisfaction of these practical desiderata. We have thus been motivated to formalise an account of Cl-Arg that is both practical and rational.Our solution is to essentially account for the dialectical use of argument by refining the ontology of arguments so as to make explicit the epistemic distinction between an argument’s premises assumed true, and those supposed true for the sake of argument. Our approach can thus accommodate a ubiquitous feature of argumentative practice, whereby the in-consistency of arguments’ premises is demonstrated dialectically. We eschew the computationally unfeasible checks on the consistency and subset minimality of arguments’ premises that are used to verify the legitimacy of arguments prior to inclu-sion in an A F , and enumerate minimal and intuitive assumptions as to the arguments constructed from a base for inclusion in an A F , such that they suffice to ensure rational outcomes. In particular: 1) arguments with conflicting conclusions are obviously indicative of the inconsistency of their supporting assumptions, as recognised by inclusion of an argument that combines the assumptions to conclude (cid:2); 2) construction of an argument whose support makes use of redundant premises that contaminate an argument, implies construction of the non-contaminated argument excluding the redundant premises. We have shown that assuming only partially instantiated frameworks (pd A F s), key properties of Dung frameworks are sat-isfied. Also, the consistency and closure postulates are satisfied assuming arbitrary preference relations, with consistency being shown for admissible (and not just complete) extensions; a result that we argue is important for practical applica-tions in which it often suffices to defend an argument by showing membership in an admissible extension. We have also identified a notion of redundancy of an argument’s assumptions that does not appeal to subset minimality, but rather to the syntactic relatedness of the assumptions and conclusion, such that redundant arguments that make use of syntacti-cally disjoint assumptions can be excluded proof theoretically. Thus non-redundant pd A F s instantiated by proof theories that exclude redundant arguments, trivially satisfy condition 2) above. Moreover, we have shown that despite dropping the legitimacy checks on arguments, pd A F s satisfy the non-interference and crash resistance postulates (which in this paper are generalised to argument frameworks instantiated by first order theories) under the assumption that preference relations are dialectically and redundance coherent. For non-redundant pd A F s it suffices that preference relations are dialectically coherent.Existing accounts of Cl-Arg typically neglect the study of the proof theoretic means for constructing arguments. We have argued that such accounts provide ‘schemata’ for classical logic argumentation, as an argument properly constituted should include the reasoning steps employed in entailing the conclusion from the premises (in keeping with the transparency pos-tulate advocated in [27]). We have therefore proposed a natural deduction proof theory for propositional Cl-Arg that in keeping with practical desiderata for applications: i) provides a more perspicuous account of classical reasoning (in com-parison with Gentzen style natural deduction); ii) allows definition of a hierarchy of tractable depth-bounded deducibility relations equating with stepwise increments in agents’ assumed inferential resources, and such that pd A F s instantiated up to any given depth meet conditions for satisfaction of the rationality postulates; iii) can be adapted so that only non-redundant arguments are constructed. We also provided an argumentative characterisation of the non-monotonic Preferred Subtheories [13], under the assumption that agents may have limited inferential capabilities.This paper suggests an ambitious agenda for future work. We are currently generalising our approach to the ASPICframework [43] in which arguments are built from strict inference rules that encode the inference relations of deductive logics, as well as defeasible inference rules and premises. We believe this will pose few serious challenges, and will involve:+1. Differentially labelling the constituents of ASPICtree structured arguments so as to distinguish rules and premises that are assumed true and supposed true, and adapting this paper’s notions of attack defeat and acceptability. Hence, for example, an argument X concluding (cid:2) would target those defeasible rules and premises in the attacked argument that are labelled as suppositions in X .2. Identifying syntactically disjoint subsets of premises and rules in an ASPICredundantly contaminated arguments, and adapting P1, . . .,P5 and P4+argument so as identify explosively and so as to define (non-redundant) pd A F s. Note that (cid:12)+50M. D’Agostino, S. Modgil / Artificial Intelligence 262 (2018) 15–51this may require stipulating assumptions as to the strict rules used in constructing arguments, such that the property satisfied by classical logic (in Proposition 30) applies to ASPICarguments.36+With appropriate adaptations of dialectical and redundance coherent preference relations, we then intend showing that partially instantiated frameworks satisfy the consistency and closure postulates (without assumptions on preference rela-tions), and the non-contamination postulates. Notice that violation of the non-contamination postulates arises because of the encoding of classical logic inference in the strict rules, and as discussed in Section 5 when reviewing [61], avoiding , and ‘cleansing’ the framework of inconsistent this problem involves significantly compromising the generality of ASPICand without any arguments. We therefore aim for satisfaction of these postulates for the fully general version of ASPICneed for cleansing.++Secondly, we intend adapting for pd A F s, argument game proof theories developed for Dung A F s [42]. We will then gen-eralise these argument games to persuasion dialogues in which agents submit arguments constructed from their own bases and the premises of arguments that are incrementally added to a public commitment store. We believe these to be impor-tant steps in achieving our long term aim of formalising accounts of monological reasoning and distributed non-monotonic reasoning through dialogue, suitable for real-world rather than idealised agents. Moreover, this paper has investigated in-stantiation of pd A F s by propositional resource bounded proof theories that exclude redundantly contaminated arguments. An important future research focus will be the development of first order resource bounded proof theories that exclude redundantly contaminated arguments.AcknowledgementsWe would like to thank the anonymous reviewers whose detailed and constructive comments have helped to improve this paper.References[1] L. Amgoud, C. Cayrol, A reasoning model based on the production of acceptable arguments, Ann. Math. Artif. Intell. 34 (1–3) (2002) 197–215.[2] L. Amgoud, N. Maudet, S. Parsons, Modelling dialogues using argumentation, in: Proc. 4th Int. Conference on MultiAgent Systems, 2000, pp. 31–38.[3] L. Amgoud, H. Prade, Using arguments for making and explaining decisions, Artif. Intell. 173 (34) (2009) 413–436.[4] L. Amgoud, S. Vesic, Handling inconsistency with preference-based argumentation, in: 4th International ConferenceScalable Uncertainty Management: 4th International Conference, SUM 2010, 2010, pp. 56–69.[5] A.R. Anderson, N.D. Belnap Jr., Entailment: The Logic of Relevance and Necessity, vol. 1, Princeton University Press, Princeton, 1975.[6] O. Arieli, C. Straßer, Sequent-based logical argumentation, Argum. Comput. 6 (1) (2015) 73–99.[7] O. Arieli, C. Straßer, Deductive argumentation by enhanced sequent calculi and dynamic derivations, Electron. Notes Theor. Comput. Sci. 323 (2016) 21–37.[8] K. Atkinson, T. Bench-Capon, P. Mcburney, Computational representation of practical argument, Synthese 152 (2005) 2006.[9] T.J.M. Bench-Capon, Persuasion in practical argument using value-based argumentation frameworks, J. Log. Comput. 13 (3) (2003) 429–448.[10] T.J.M. Bench-Capon, S. Doutre, P.E. Dunne, Audiences in argumentation frameworks, Artif. Intell. 171 (1) (2007) 42–71.[11] T.J.M. Bench-Capon, P.E. Dunne, Argumentation in artificial intelligence, Artif. Intell. 171 (2007) 10–15.[12] P. Besnard, A. Hunter, Elements of Argumentation, MIT Press, 2008.[13] G. Brewka, Preferred subtheories: an extended logical framework for default reasoning, in: Proc. 11th International Joint Conference on Artificial Intelligence, 1989, pp. 1043–1048.[14] M. Caminada, Dialogues and HY-arguments, in: Non-Monotonic Reasoning, 2004, pp. 94–99.[15] M. Caminada, L. Amgoud, On the evaluation of argumentation formalisms, Artif. Intell. 171 (5–6) (2007) 286–310.[16] M. Caminada, W. Carnielli, P. Dunne, Semi-stable semantics, J. Log. Comput. 22 (5) (2012) 1207–1254.[17] M. Caminada, S. Modgil, N. Oren, Preferences and unrestricted rebut, in: Proc. Computational Models of Argument, COMMA’14, 2014, pp. 209–220.[18] S.A. Cook, R. Rechow, On the length of proofs in the propositional calculus, in: Proc. 6th Annual Symposium on the Theory of Computing, 1974, pp. 135–148.[19] R. Craven, F. Toni, Argument graphs and assumption-based argumentation, Artif. Intell. 233 (C) (2016) 1–59.[20] M. D’Agostino, Classical natural deduction, in: S.N. Artëmov, et al. (Eds.), We Will Show Them!, vol. 1, College Publications, 2005, pp. 429–468.[21] M. D’Agostino, Analytic inference and the informational meaning of the logical operators, Log. Anal. 57 (227) (2014) 407–437.[22] M. D’Agostino, An informational view of classical logic, Theor. Comput. Sci. 606 (2015) 79–97.[23] M. D’Agostino, M. Finger, D.M. Gabbay, Semantics and proof-theory of depth-bounded Boolean logics, Theor. Comput. Sci. 480 (2013) 43–68.[24] M. D’Agostino, D.M. Gabbay, S. Modgil, Normality, Non-Contamination and Logical Depth in Classical Natural Deduction, Technical Report, Parts I and II, 2017, http://www.filosofia .unimi .it /dagostino /wp -content /uploads /2018 /05 /NNC _TR1.pdf, http://www.filosofia .unimi .it /dagostino /wp -content /uploads /2018 /05 /NNC _TR2 .pdf.[25] M. D’Agostino, S. Modgil, A rational account of classical logic argumentation for real-world agents, in: European Conference on Artificial Intelligence, [26] P.M. Dung, On the acceptability of arguments and its fundamental role in nonmonotonic reasoning, logic programming and n-person games, Artif. [27] P.M. Dung, F. Toni, P. Mancarella, Some design guidelines for practical argumentation systems, in: Proc. Computational Models of Argument, COMMA’10, [28] P.M. Dung, P.M. Thang, Closure and consistency in logic-associated argumentation, J. Artif. Intell. Res. 49 (1) (2014) 79–109.[29] V. Efstathiou, A. Hunter, Algorithms for generating arguments and counterarguments in propositional logic, Int. J. Approx. Reason. 52 (6) (2011) 672–704.36 By substituting (cid:10)of arguments defined by these sets.A+ for (cid:10)c in the statement of this property, where the former is a relation between sets of rules and premises, and the conclusions ECAI 2016, 2016, pp. 141–149.Intell. 77 (2) (1995) 321–358.2010, pp. 183–194.COMMA’12, 2012, pp. 513–514.pp. 261–280.Agent Systems, LADS 07, 2007, pp. 37–53.2010, pp. 335–346.tion in AI, Springer, 2009, pp. 105–129.M. D’Agostino, S. Modgil / Artificial Intelligence 262 (2018) 15–5151[30] T. Eiter, G. Gottlob, The complexity of logic-based abduction, J. ACM 42 (1) (1995) 3–42.[31] X. Fan, F. Toni, A general framework for sound assumption-based argumentation dialogues, Artif. Intell. 216 (2014) 20–54.[32] G. Galilei, Dialogues Concerning Two New Sciences [1638], Dover, NY, 1954.[33] N. Gorogiannis, A. Hunter, Instantiating abstract argumentation with classical logic arguments: postulates and properties, Artif. Intell. 175 (2011) 1479–1497.[34] D. Grooters, H. Prakken, Combining paraconsistent logic with argumentation, in: Proc. Computational Models of Argument, COMMA’14, 2014, pp. 301–312.[35] A. Hunter, Making argumentation more believable, in: Proceedings of AAAI 2004, 2004, pp. 269–274.[36] A. Kakas, P. Mancarella, F. Toni, On argumentation logic and propositional logic, Stud. Log. 106 (2) (2018) 237–279.[37] J. Lawrence, F. Bex, C. Reed, Dialogues on the argument web: mixed initiative argumentation with arvina, in: Proc. Computational Models of Argument, [38] P. McBurney, S. Parsons, Chapter 13: dialogue games for agent argumentation, in: I. Rahwan, G. Simari (Eds.), Argumentation in AI, Springer, 2009, [39] S. Modgil, An argumentation based semantics for agent reasoning, in: Proc. Workshop on Languages, Methodologies and Development Tools for Multi-[40] S. Modgil, Revisiting abstract argumentation frameworks, in: Theory and Applications of Formal Argumentation, TAFA’14, 2014, pp. 1–15.[41] S. Modgil, T.J.M. Bench-Capon, Integrating dialectical and accrual modes of argumentation, in: Proc. Computational Models of Argument, COMMA’10, [42] S. Modgil, M. Caminada, Chapter 6: proof theories and algorithms for abstract argumentation frameworks, in: I. Rahwan, G. Simari (Eds.), Argumenta-[43] S. Modgil, H. Prakken, A general account of argumentation and preferences, Artif. Intell. 195 (2013) 361–397.[44] S. Modgil, F. Toni, F. Bex, I. Bratko, C.I. Chesnevar, X. Fan, S. Gaggl, A.J. Garcia, M.P. Gonzalez, T. Gordon, J. Leite, M. Mozina, C. Reed, G.R. Simari, S. Szeider, P. Torroni, S. Woltran, The added value of argumentation, in: Handbook of Agreement Technologies, Springer-Verlag, 2013, Chapter 21.[45] S. Parsons, M. Wooldridge, L. Amgoud, On the outcomes of formal inter-agent dialogues, in: Proc. 2nd International Joint Conference on Autonomous Agents and Multi-Agent Systems, 2003, pp. 683–688.[46] C. Perelman, L. Olbrechts-Tyteca, The New Rhetoric: A Treatise on Argumentation, University of Notre Dame Press, 1969.[47] J.L. Pollock, Defeasible reasoning, Cogn. Sci. 11 (1987) 481–518.[48] H. Prakken, Coherence and flexibility in dialogue games for argumentation, J. Log. Comput. 15 (2005) 1009–1040.[49] H. Prakken, A study of accrual of arguments, with applications to evidential reasoning, in: Proc. International Conference on AI and Law, 2005, pp. 85–94.[50] H. Prakken, G. Sartor, Argument-based extended logic programming with defeasible priorities, J. Appl. Non-Class. Log. 7 (1997) 25–75.[51] I. Rahwan, L. Amgoud, An argumentation-based approach for practical reasoning, in: N. Maudet, S. Parsons, I. Rahwan (Eds.), Argumentation in Multi-Agent Systems, in: Lecture Notes in Computer Science, vol. 4766, Springer, Berlin Heidelberg, 2007, pp. 74–90.[52] I. Rahwan, M. Madakkatel, J. Bonnefon, R.N. Awan, S. Abdallah, Behavioral experiments for assessing the abstract argumentation semantics of reinstate-ment, Cogn. Sci. 34 (8) (2010) 1483–1502.[53] I. Rahwan, G. Simari (Eds.), Argumentation in AI, Springer-Verlag, 2009.[54] R. Reiter, A logic for default reasoning, Artif. Intell. 13 (1980) 81–132.[55] N. Rescher, R. Manor, On inference from inconsistent premises, Theory Decis. 1 (1970) 179–219.[56] R. Stalnaker, The problem of logical omniscience, Synthese 89 (3) (1991) 425–440.[57] P.M. Thang, H.T. Luong, Translating preferred subtheories into structured argumentation, J. Log. Comput. 24 (4) (2014) 831–849.[58] P. Tolchinsky, S. Modgil, K. Atkinson, P. McBurney, U. Cortes, Deliberation dialogues for reasoning about safety critical actions, J. Auton. Agents Multi-Agent Syst. 25 (2012) 209–259.[59] G. Vlastos, The Socratic Elenchus, J. Philos. 79 (11) (1982) 711–714.[60] D.N. Walton, E.C.W. Krabbe, Commitment in Dialogue: Basic Concepts of Interpersonal Reasoning, State University of New York Press, 1995.[61] Y. Wu, M. Podlaszewski, Implementing crash-resistance and non-interference in logic-based argumentation, J. Log. Comput. 25 (2015) 303–333.