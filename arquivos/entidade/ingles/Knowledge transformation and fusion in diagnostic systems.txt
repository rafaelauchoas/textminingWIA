Artificial Intelligence 163 (2005) 1–45www.elsevier.com/locate/artintKnowledge transformation and fusion indiagnostic systems ✩Mingsheng Ying a,ba State Key Laboratory of Intelligent Technology and Systems,Department of Computer Science and Technology, Tsinghua University, Beijing 100084, Chinab Laboratory of Intelligent Information Processing, Department of Computer Science and Engineering,Fudan University, Shanghai 230031, ChinaReceived 1 August 2003; accepted 3 October 2004Available online 8 December 2004AbstractDiagnostic systems depend on knowledge bases specifying the causal, structural or functionalinteractions among components of the diagnosed objects. A diagnostic specification in a diagnos-tic system is a semantic interpretation of a knowledge base. We introduce the notion of diagnosticspecification morphism and some operations of diagnostic specifications that can be used to modelknowledge transformation and fusion, respectively. The relation between diagnostic methods in thesource system and the target system of a specification morphism is examined. Also, representationsof diagnostic methods in a composed system modelled by operations of specifications are given interms of the corresponding diagnostic methods in its component systems. 2004 Elsevier B.V. All rights reserved.Keywords: Diagnostic system; Diagnostic specification; Notion of diagnosis; Knowledge transformation;Knowledge fusion; Specification morphism; Operations of specification✩ This work was partly supported by the National Foundation of Natural Sciences of China (Grant No:60496321, 60321002, 60273003) and the Key Grant Project of Chinese Ministry of Education (Grant No: 10403).E-mail address: yingmsh@tsinghua.edu.cn (M. Ying).0004-3702/$ – see front matter  2004 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2004.10.0082M. Ying / Artificial Intelligence 163 (2005) 1–451. IntroductionTo diagnose is to determine the nature of a trouble (for example, a disease) from ob-servations of signs and symptoms, and it is an important human ability, with importantapplications in medicine, industrial processes and computer software, among others. Dueto its importance, diagnostic reasoning has long been an active research area of ArtificialIntelligence. Throughout the 1970’s, several expert systems aimed in whole or in part at di-agnosis were developed (e.g., MYCIN [21]), exploring different knowledge representationand reasoning techniques, but the field lacked unified underlying principles.One of the first formal theories of diagnosis is Reggia, Nau and Wang’s set-coveringmodel for diagnostic expert systems [18], where causal knowledge of abnormality isrepresented by binary relations. Diagnosis then reduces to determining whether actuallyobserved findings can be inferred from observed defects and the causal relations.In 1987, a logical theory of diagnosis was proposed by Reiter [19], and it is usuallycalled the theory of consistency-based diagnosis. This theory was largely extended by deKleer et al. [10] in 1992. Their main idea is to establish a model of the normal structureand behavior of the diagnosed objects. Diagnosis is then modelled as finding a discrepancybetween the normal behavior predicted from the model and the actually observed abnormalbehavior. The discrepancy in this approach is formalized as logical inconsistency.Another logical theory of diagnosis, called abductive diagnosis, was developed by Coxand Pietrzykowski [9], Console et al. [3,7,8] and others around 1990. They used logi-cal implications from causes to effects to represent causal knowledge, and a diagnosis isthen formalized as reasoning from effects (observed findings) to causes (abnormalities orfaults).Lucas [13] recently introduced a framework allowing these and other formal theories(for example, heuristic classification [6], goal-directed diagnosis [20] and explicit means-end model [12]), to be compared in a unified way. It consists mainly of two parts: (1)diagnostic specification, a mapping from defects to observable findings, specifying thecausal relation from defects to findings; and (2) notion of diagnosis, a mapping from ob-served findings to defects, modelling how to get a diagnostic solution from the observedfindings. This is a high-level formalism of diagnosis, and various formal theories of diag-nosis can be expressed in it, including consistency-based diagnosis, abductive diagnosisand heuristic classification. In this framework a diagnostic specification need not corre-spond to a unique notion of diagnosis. Different strategies of diagnosis can be introducedaccording to varied philosophical considerations or practical purposes. In [13], given a di-agnostic specification, Lucas proposed a hierarchy consisting of six notions of diagnosisinduced by it, namely, most general subset diagnosis, most general superset diagnosis,most general intersection diagnosis, most specific subset diagnosis, most specific supersetdiagnosis as well as most specific intersection diagnosis. The six notions of diagnosis forma flexible spectrum in which one notion may refine another. Thus, they provide the userwith an opportunity to choose a diagnosis method suited to his own criterion.A diagnostic specification in Lucas’s formalism is intended to serve as a semantic in-terpretation of the knowledge base in a diagnostic system. But the cost of gathering andprocessing knowledge is often very high. Such a situation makes effective reuse of knowl-edge essential. One of the mechanisms that support reuse of knowledge is knowledgeM. Ying / Artificial Intelligence 163 (2005) 1–453transformation which maps various different knowledge bases to each other, enabling acommon interfaces between different domains and application systems. Many differentformal representations of knowledge transformation have already been proposed; for ex-ample, conditional rules [4], function [5], logical relations [11], and tables and procedures[22]. Another important mechanism for effective use and reuse of knowledge is the fusionand merging of different knowledge resources, often represented in terms of operationson knowledge bases. Examples include Stanford’s ontology algebra [24] and Barwise andSeligman’s theory of information flow [1].This leads us to explore the possibility of reusing knowledge in diagnostic systems.In this paper, we consider the following two problems concerning change, evolution ofknowledge for diagnosis as well as gathering and combining diagnostic knowledge frommultiple sources: (1) if the knowledge base in one diagnostic system is transformed intothe knowledge base in another, then to what extent can the diagnostic method adoptedin the first system be reused in the second? and (2) if the knowledge bases in a set ofdiagnostic systems are fused or merged to construct a larger one, how we can producea suitable diagnostic method for the composed system from the diagnostic methods ofits components? In order to solve the first problem, the notion of diagnostic specificationmorphism is introduced. As a solution to the second problem, some algebraic operations ofdiagnostic specifications are proposed to model the construction of a complex diagnosticsystem composed from simpler ones.This paper is organized as follows: in Section 2, we recall some basic notions from [13].We also present some new results in this section. First, it is shown that some global proper-ties such as monotonicity and interaction freeness of partial diagnostic specifications, canbe extended to the whole specifications generated by them. Second, for the six diagnosticnotions in the Lucas refinement diagnosis spectrum, some properties of the Galois con-nection style are observed. Third, some necessary and sufficient conditions under whichthe six diagnostic notions respects the given diagnostic specification are found. Fourth, weshow that certain relations between diagnostic specifications are preserved and some globalproperties of diagnostic specifications are inherited by the six diagnostic notions inducedfrom them. These results are useful in the analysis and comparison of various notions ofdiagnosis. In Section 3, the notion of diagnostic specification morphism is introduced formodelling transformations of knowledge bases in different diagnostic systems. It is shownthat the relation that a notion of diagnosis respects a diagnostic specification can be pre-served by some morphisms. Also, it is demonstrated that certain global properties of thesource diagnostic specification may be transferred by a specification morphism to the tar-get specification. Thus, some diagnosis methods depending heavily on these properties canbe safely reused after knowledge transformation. We prove that some partial specificationmorphism can be smoothly extended to a specification morphism. This gives a conve-nient technique for constructing specification morphisms because in many applicationsdiagnostic knowledge bases are often specified only partially. The relationship betweenthe diagnostic strategies in the source diagnostic system and the target system of a mor-phism is thoroughly analyzed. The obtained results provide us with a logical support forknowledge reuse in diagnostic systems. Section 4 is devoted to examining carefully variousoperations of diagnostic specifications. These operations aim at describing different waysto fuse and merge diagnostic knowledge bases. They include optimistic and pessimistic4M. Ying / Artificial Intelligence 163 (2005) 1–45fusions, optimistic merging and pessimistic merging, sum, and direct product. For each ofthem, we examine how the global properties of component systems are preserved by thecomposed system. We also clarify the relationship between the diagnostic methods in thecomponent systems and those in the composed system. These results enable us to know towhat an extent the diagnostic strategies used in a diagnostic system can be reused when itis embedded into a larger system.To conclude this introduction, we would like to comment on applicability of the con-cepts and results presented in the current paper. Although the work reported in the paperis mainly concerned with the problem of system diagnosis, the formal methods developedfor modelling knowledge transformation and fusion may be used in some other areas ofArtificial Intelligence and related subjects. The Semantic Web is envisaged as the Web en-riched with numerous domain ontologies, which specify formal semantics of data existingon the Web [2]. Recent successful projects in the ontology area have resulted at creation ofthousands of ontologies [25]. However, the absence of efficient techniques of knowledgetransformation and fusion hampers further development of the Semantic Web. The formal-ism established in this paper might provide some useful mathematical tools, supporting thedevelopment of knowledge transformation and fusion technology in such an rapidly grow-ing area. Another potential application area of this paper is knowledge management [15],where various technologies that support knowledge transformation have been developed,but solid theoretical foundations are still to be found. Knowledge fusion and merging arekey issues in the area of multi-agent systems (MAS) [23]. A very interesting problem forfurther study is to model learning in MAS with the fusion operations introduced here.2. Lucas formalism of system diagnosisOur work will be carried out entirely within the Lucas formal framework of diagnosis.So, for convenience of the reader, here we first recall some basic notions from [13]. Fordetailed explanations and examples illustrating these notions we refer to [13].Each diagnostic system requires a knowledge base as the basis of implementing diag-nostic task. Such a knowledge base usually specifies certain interactions between defectsand observable findings. In the Lucas formalism it is interpreted as an evidence functionwhich associates a set of observable findings to a set of defects and intends to use thesefindings to represent the evidence of occurrence of the defects.The Lucas formalism is established in the set-theoretical setting. Let ∆P and ΦP betwo nonempty sets. The elements of ∆P will be used to denote positive defects, and theelements of ΦP will be positive findings. We write∆N = {¬d: d ∈ ∆P }and ΦN = {¬f : f ∈ ΦP }for the sets of negative defects and findings, respectively. Furthermore, let∆ = ∆P ∪ ∆N and Φ = ΦP ∪ ΦN ,where it is assumed that ∆P ∩ ∆N = ∅ and ΦP ∩ ΦN = ∅, and ¬¬x = x for every x ∈∆P ∪ ΦP . A subset D of ∆ will be used to represent a set of defects. Here, we adopt aninterpretation of three-valued logic in the following sense: for each d ∈ ∆P ,M. Ying / Artificial Intelligence 163 (2005) 1–455(i) d indicates the presence of defect d;(ii) ¬d indicates the absence of defect d; and(iii) if both d and ¬d are not in D, then it is understood that defect d is unknown.Similarly, a subset E of Φ will be seen as a set of findings, with the same three-valuedlogical interpretation.For any set X, we use ℘ (X) to express the power set of X, i.e., the set of all subsetsof X. After introducing the above notations, we are able to present the first key notion inthe Lucas formalism of diagnosis.Definition 1 (Diagnostic specification; [13, Definition 1]). A diagnostic specification isa triple Σ = (∆, Φ, e), where ∆ and Φ are sets of defects and findings, respectively, asexplained before, ande : ℘ (∆) → ℘ (Φ) ∪ {⊥}is a mapping, called evidence function, such that(i) for any D, D(cid:7) ⊆ ∆, if d, ¬d ∈ D then e(D) = ⊥; and(ii) for any D, D(cid:7) ⊆ ∆, if e(D) (cid:9)= ⊥ and D(cid:7) ⊆ D then e(D(cid:7)) (cid:9)= ⊥.In addition, if e satisfies the following condition(iii) for each f ∈ Φ there exists a set D ⊆ ∆ with f ∈ e(D) or ¬f ∈ e(D), then Σ is saidto be complete.For each D ⊆ ∆, if e(D) (cid:9)= ⊥, then D is called consistent.Intuitively, for each set D of defects, allowing both positive and negative occurrences(i.e., presence or absence) of defects, e(D) expresses the set of findings which are observ-able when defects in D simultaneously occur.The above definition is a slightly modified version of Definition 1 in [13]. The differencebetween them is that a weaker concept of diagnostic specification with only the conditions(1) and (2) is introduced, and the original concept of diagnostic specification is renamed ascomplete specification.The nature of a diagnostic specification has a heavy influence on the choice of our di-agnostic methods in the diagnostic system with this specification as its knowledge base.Thus, it is worthwhile to carefully analyze various properties of diagnostic specifications.The following two definitions give some common global properties of diagnostic specifi-cations.Definition 2 (Monotonicity; [13, Definition 7]). A diagnostic specification Σ = (∆, Φ, e)is called increasing (respectively decreasing) if for all D, D(cid:7) ⊆ ∆,(respectively e(D(cid:7) ⊆ e(D))implies e(D) ⊆ e(D(cid:7))D ⊆ D(cid:7)provided D(cid:7) is consistent.6M. Ying / Artificial Intelligence 163 (2005) 1–45Monotonicity is very familiar to us and does not need any further explanation. In theabove definition, monotonicity is required to hold globally, i.e., to be valid for all sets Dand D(cid:7) of defects. Some localized versions of monotonicity were also introduced in [13].Definition 3 (Interaction freeness; [13, Definition 8]). A diagnostic specification Σ =(∆, Φ, e) is said to be interaction free if for each consistent set of defects D ⊆ ∆, it holdsthate(D) =(cid:2){d}(cid:3).(cid:1)ed∈DA slightly different presentation of interaction freeness is that(cid:5)Di=(cid:4)(cid:1)ei∈I(cid:1)i∈Ie(Di)for any family {Di}i∈I of consistent subsets of ∆, where I is an arbitrary nonempty indexset. The intuitive meaning of interaction freeness is then that the evidence for the unionof a family of defect sets is simply the union of their respective evidences, and thus nointeraction among defects exist.One of the most important relations between diagnostic specifications is the subspec-ification relation. A diagnostic specification is a subspecification of another if the formergives less evidences than the latter for the same defects.Definition 4 (Subspecification). Let Σ = (∆, Φ, e) and Σ (cid:7) = (∆, Φ, e(cid:7)) be two specifica-tions with the same sets of defects and findings. If for any D ⊆ ∆, e(D) ⊆ e(cid:7)(D) whenevere(D) (cid:9)= ⊥ and e(cid:7)(D) (cid:9)= ⊥, then Σ is called a subspecification of Σ (cid:7), and we write Σ (cid:10) Σ (cid:7).It is often very difficult or even impossible to specify the whole knowledge base whenthe diagnostic system is very large and too many defects have to be considered. A solutionto this problem that one may naturally conceive is that we only specify a small part of theknowledge base and the remaining part can be generated automatically in some way fromthe part specified already. This simple idea motivates the following two definitions.Definition 5 (Partial specification). (1) A partial specification is a quadruple Σ =(∆, Φ, V , e), where ∆ and Φ are as in Definition 2.1, V ⊆ ℘ (∆), and e : V → ℘ (Φ) ∪ {⊥}is a mapping satisfying conditions (1) and (2) in Definition 1.(2) A partial specification Σ = (∆, Φ, V , e) is said to be up-inductive (respectivelydown-inductive) if any chain W ⊆ V (i.e., D1 ⊆ D2 or D2 ⊆ D1 for all D1, D2 ∈ W ) hasan upper (respectively a lower) bound D (i.e., D(cid:7) ⊆ D (respectively D ⊆ D(cid:7)) for eachD(cid:7) ∈ W ).It is clear that the unique difference between a diagnostic specification and a partialspecification is that the domain V of the evidence function in the latter is allowed to be aproper subset of ℘ (∆); in other words, the evidences of some defects can be unspecifiedin a partial specification. If V = ℘ (∆), then a partial specification Σ = (∆, Φ, V , e) is(cid:5)(cid:7),(cid:5)(cid:7),M. Ying / Artificial Intelligence 163 (2005) 1–457exactly a diagnostic specification. Note that a partial specification Σ = (∆, Φ, V , e) isautomatically up-inductive and down-inductive when ∆ is finite.Given a partial specification, there will be many different ways to recover a whole spec-ification. Two of the ways that we use most often are presented in the following definition.Definition 6 (Bottom-up and top-down partial specifications; [13, Definitions 12 and 17]).Let Σ = (∆, Φ, e) be a diagnostic specification, and let Σ (cid:7) = (∆, Φ, V , e(cid:7)) be a partialspecification with the same sets of defects and findings.(1) If for any D ∈ ℘ (∆),(cid:1)(cid:6)e(D) =(cid:4)(cid:7)e(cid:7)(D): D(cid:7) ∈ m(V , D)(cid:8)(cid:6)respectively e(D) =e(cid:7)(D): D(cid:7) ∈ m(V , D)where m(V , D) is the set of maximal elements of {D(cid:7) ∈ V : D(cid:7) ⊆ D} with respect to setinclusion ⊆, then Σ (cid:7) is called an increasing (respectively a decreasing) bottom-up partialspecification of Σ.(2) If for any D ∈ ℘ (∆),(cid:8)(cid:6)e(D) =(cid:4)(cid:7)e(cid:7)(D): D(cid:7) ∈ M(V , D)(cid:1)(cid:6)respectively e(D) =e(cid:7)(D): D(cid:7) ∈ M(V , D)where M(V , D) is the set of minimal elements of {D(cid:7) ∈ V : D ⊆ D(cid:7)} with respect to setinclusion ⊆, then Σ (cid:7) is called an increasing (respectively a decreasing) top-down partialspecification of Σ.The philosophy of bottom-up partial specifications is to use the specified evidences toapproximate the unspecified evidences from bottom, and top-down partial specificationsare defined in a dual fashion. Recall from [16, p. 20] that Zorn’s lemma asserts if everychain in a partially ordered set P has an upper bound then P has a maximal element.Thus, Zorn’s lemma guarantees the existence of maximal (respectively minimal) elementsof {D(cid:7) ∈ V : D(cid:7) ⊆ D} (respectively {D(cid:7) ∈ V : D ⊆ D(cid:7)}) in the above definition when Σ (cid:7) isup-inductive (respectively down-inductive), and e(D) is well-defined for all D ⊆ ∆.Some global properties of diagnostic specifications, such as monotonicity and interac-tion freeness, can be easily generalized to partial specifications.Definition 7 (Increasing, decreasing and interaction free partial specifications). Let Σ =(∆, Φ, V , e) be a partial specification. Then(1) Σ is called increasing (respectively decreasing) if for any consistent D, D(cid:7) ∈ V , D ⊆D(cid:7) implies e(D) ⊆ e(D(cid:7)) (respectively e(D) ⊇ e(D(cid:7))).(2) Σ is called interaction free if(i) {d} ∈ V for all d ∈ ∆; and(ii) for all consistent D ∈ V , e(D) =(cid:9)d∈D e({d}).8M. Ying / Artificial Intelligence 163 (2005) 1–45The following proposition demonstrates how some properties of partial specificationscan be extended to the whole specifications generated by them.Proposition 8. Let Σ = (∆, Φ, e) be a diagnostic specification, and let Σ (cid:7) = (∆, Φ, V , e(cid:7))be a partial specification with the same sets of defects and findings.(1) If Σ (cid:7) is an increasing bottom-up or top-down partial specification of Σ, and Σ (cid:7) isincreasing, then Σ is also increasing.(2) If Σ (cid:7) is an decreasing bottom-up or top-down partial specification of Σ, and Σ (cid:7) isdecreasing, then Σ is also decreasing.(3) If Σ (cid:7) is an increasing bottom-up partial specification of Σ, and Σ (cid:7) is interaction free,then Σ is also interaction free.∈ M(V , D2), we have D(cid:7)2Proof. We only consider the case where Σ (cid:7) is an increasing top-down partial specificationof Σ, and Σ (cid:7) is decreasing. For any consistent D1, D2 ⊆ ∆, if D1 ⊆ D2, then for eachD(cid:7)∈ V and D(cid:7)∈ {D ∈ V2: D ⊇ D1}.22Note that Σ (cid:7) is down-inductive. We known from Zorn’s lemma that there exists D(cid:7)∈1M(V2, D1) with D(cid:7)1). Therefore,2we obtain1. Since Σ is decreasing, it holds that e(cid:7)(D(cid:7)⊇ D2 ⊇ D1. Hence, D(cid:7)22) ⊆ e(cid:7)(D(cid:7)⊇ D(cid:7)e(D2) =⊆(cid:7)(cid:1)(cid:6)e(D(cid:1)(cid:6)e(cid:7)(D(cid:7)(cid:7)(cid:7)2): D21): D(cid:7)1(cid:7)∈ M(V , D2)∈ M(V , D1)(cid:7)= e(D1),and Σ is decreasing. (cid:1)We now turn to present the second key component in the Lucas formalism of diagnosis.The evidence function in a diagnostic specification gives the expected evidences for thecombined occurrences of defects. Conversely, a notion of diagnosis will seek the defectsthat may cause the observed findings. In a sense, diagnostic specification and notion ofdiagnosis are two concepts conjugate to each other.Definition 9 (Notion of diagnosis, diagnostic problem and diagnostic solution; [13, Defin-ition 20]). (1) A notion of diagnosis is a triple Π = (∆, Φ, R), where ∆ and Φ are respec-tively sets of defects and findings, R = {RH : H ⊆ ∆}, and RH : ℘ (Φ) → ℘ (∆) ∪ {u} is amapping for each hypothesis H ⊆ ∆, called diagnostic function.(2) A diagnostic problem is a triple P = (∆, Φ, E) in which ∆ and Φ are as in (1), andE ⊆ Φ is a set of observed findings such that if f ∈ E then ¬f /∈ E; i.e., contradictoryobserved findings are not allowed.(3) Let Π = (∆, Φ, R) be a notion of diagnosis, let P = (∆, Φ, E) be a diagnosticproblem with the same sets of defects and findings, and let H ⊆ ∆ be a hypothesis. Thenthe diagnostic solution of P under Π with respect to H is defined to be RH (E).The intuitive meaning of a notion of diagnosis is already clear from its formal definition.The set H ⊆ ∆ in the above definition is a hypothesis. This means that we already knowall possible defects must be in H , and thus we only need to conduct the diagnostic taskM. Ying / Artificial Intelligence 163 (2005) 1–459with the scope of H . For any set E ⊆ Φ, denoting the actually observed findings, RH (E)is viewed as the diagnostic solution to E under the hypothesis H ; that is, the defects thatpossibly cause E. For the case of RH (E) = u, no diagnostic solution exists. For a visualinterpretation of the relation among all components of a diagnostic system, including di-agnostic specification, notion of diagnosis, and diagnostic problem and solution, we referto [13, Fig. 9].We often need to compare strictness of different notions of diagnosis. A suitable math-ematical tool for this purpose is given in the following definition.Definition 10 (Sub-diagnostic relation; [13, Definition 29]). Let Π = (∆, Φ, R) and Π (cid:7) =(∆, Φ, R(cid:7)) be two notions of diagnosis with the same sets of defects and findings. If forany E ⊆ Φ and for any H ⊆ ∆, RH (E) ⊆ R(cid:7)H (E) (cid:9)= u,then Π is said to be sub-diagnostic to Π (cid:7), and we write Π (cid:10) Π (cid:7).H (E) provided RH (E) (cid:9)= u and R(cid:7)It is not the case that any pair consisting of a diagnostic specification and a notion ofdiagnosis forms a reasonable diagnostic system. Usually, some conditions must be im-posed to a notion of diagnosis so that it gives a suitable diagnostic method with respectto a given diagnostic specification. One of such conditions is presented in the followingdefinition.Definition 11 (A notion Π of diagnosis respects a diagnostic specification Σ; [13, Defi-nition 22]). Let Σ = (∆, Φ, e) be a diagnostic specification, and let Π = (∆, Φ, R) be anotion of diagnosis with the same sets of defects and findings. It is said that Π respects Σif(i) for each set of observed findings E ⊆ Φ, there exists a hypothesis H ⊆ ∆ such thate(RH (E)) = E; and(ii) for each consistent D ⊆ ∆, there exists a hypothesis H ⊆ ∆ such that RH (e(D)) = D.If condition (ii) is strengthened as follows:(ii)(cid:7) for each consistent D ⊆ ∆, there exists a hypothesis H ⊆ ∆ such that RH (e(D)) = Dand RH (cid:7) (e(D)) = u for all H (cid:7) (cid:9)⊇ H ,then we say that Π strictly respects Σ.A notion Π of diagnosis respects a diagnostic specification Σ actually means that thediagnostic function R in Π is a pseudo-inverse of the evidence function e in Σ. In orderto explain further the main idea of the above definition, it is worth comparing it with thenotion of Galois connection. Let A and B be two partially ordered sets, and let G : A → Band F : B → A be order-preserving functions. Recall from [14, p. 93] that (F, G) is called aGalois connection provided the following equivalence holds: F b (cid:1) a if and only if b (cid:1) Gafor all a ∈ A and b ∈ B. Then it may be noted that the above definition is given in a stylesimilar to the Galois connection.10M. Ying / Artificial Intelligence 163 (2005) 1–45Except the case considered in the above definition, there are many different require-ments for a notion of diagnosis to be suitable with respect to a given diagnostic specifica-tion. This flexibility comes from different philosophical considerations that the user takeswhen choosing his diagnostic method. Thus, a spectrum of different notions of diagno-sis could be introduced for a diagnostic system with a given diagnostic specification asits knowledge base. Indeed, six of such notions of diagnosis, namely, most general sub-set diagnosis, most general superset diagnosis, most general intersection diagnosis, mostspecific subset diagnosis, most specific superset diagnosis and most specific intersectiondiagnosis, were proposed by Lucas [13], and they give rise to a refinement hierarchy ofdiagnostic methods.Definition 12 (Most general subset diagnosis; [13, p. 333]). Let Σ = (∆, Φ, e) be a di-agnostic specification. Then the notion of most general subset diagnosis generated by Σis defined to be the notion of diagnosis ΠGS(Σ) = (∆, Φ, GS), where for each hypothesisH ⊆ ∆, and for each set E ⊆ Φ of observed findings,(cid:10) (cid:9){H (cid:7) ⊆ H : e(H (cid:7)) ⊆ E},GSH (E) =uif H is consistent, ande(H (cid:7)) ⊆ E for some H (cid:7) ⊆ H ,otherwise.The idea behind the notion of most general subset diagnosis is that if a specific diagnosisis not acceptable, then the ‘nearest’ acceptable sub-hypothesis should be taken instead. Werefer to [13] for more detailed explanations for the above definition as well as the other fivenotions of diagnosis in the Lucas refinement (see Definitions 15, 18, 21, 24 and 27 below).Some basic properties of most general subset diagnosis are presented in the followingproposition.Proposition 13. Let Σ = (∆, Φ, e) be a diagnostic specification, and let ΠGS(Σ) =(∆, Φ, GS) be the notion of most general subset diagnosis generated by Σ.(1) If H is consistent, then GSH (e(D)) ⊇ D for any D ⊆ H .(2) If Σ is interaction free, and H is consistent, then e(GSH (E)) ⊆ E for any E ⊆ Φ.(3) If Σ is interaction free, then for each H ⊆ ∆, and for each E ⊆ Φ,GSH (E) ={d ∈ H : e({d}) ⊆ E}uif H is consistent,otherwise.(4) If Σ is decreasing and GSH (E) (cid:9)= u, i.e., H is consistent, and e(H ) ⊆ E, thene(GSH (E)) ⊆ E.(5) If Σ is decreasing, thenGSH (E) =H if H is consistent and e(H ) ⊆ E,uotherwise.(cid:11)(cid:11)Proof. (1), (2), (4) and (5) are straightforward.(3) First we note that e(∅) = ∅ ⊆ E because Σ is interaction free. Thus, GSH (E) (cid:9)= uwhenever H is consistent. We now only need to consider the case that H is consistent. Let(cid:6)d ∈ H : e(cid:2){d}(cid:3)(cid:7).⊆ EX =M. Ying / Artificial Intelligence 163 (2005) 1–4511From interaction freeness of Σ it follows thate(X) =(cid:3)(cid:2){d}⊆ X.(cid:1)ed∈XThenand(cid:6)H (cid:7) ⊆ H : e(H (cid:7)) ⊆ E(cid:7)X ∈(cid:1)(cid:6)HX ⊆(cid:7) ⊆ H : e(H(cid:7)) ⊆ E(cid:7).On the other hand, for any H (cid:7) ⊆ H , if e(H (cid:7)) ⊆ E, then for each d ∈ H (cid:7), e({d}) ⊆ e(H (cid:7)) ⊆E. This is because e is increasing when Σ is interaction free. Consequently, d ∈ X, andH (cid:7) ⊆ X. This implies further that(cid:1)(cid:6)(cid:7) ⊆ H : e(H(cid:7)) ⊆ E(cid:7).(cid:1)HX =The parts (1) and (2) of the above proposition show that the evidence function e and themost general subset diagnosis GSH form a Galois connection. The part (5) indicates thatthe notion of most general subset diagnosis is trivial for decreasing diagnostic specifica-tions.The next proposition gives a sufficient and necessary condition under which the no-tion of most general subset diagnosis generated by a diagnostic specification respects thespecification.Proposition 14. Let Σ = (∆, Φ, e) be a diagnostic specification and ΠGS(Σ) = (∆, Φ, GS)be the notion of most general subset diagnosis generated by Σ. Then ΠGS(Σ) respects Σif and only if e is surjective.Proof. Suppose that e is surjective. For any consistent D ⊆ ∆, we have(cid:2)GSDe(D)(cid:3)=(cid:1)(cid:6)(cid:7) ⊂ D: e(H(cid:7) ⊆ e(D)(cid:7)= D.HFor any E ⊆ Φ, since e is surjective, there must be H0 ⊆ ∆ such that e(H0) = E. Then H0is consistent,(cid:1)(cid:6)(cid:7)GSH0 (E) =H (cid:7) ⊆ H0: e(H (cid:7)) ⊆ Eand e(GSH0(E)) = e(H0) = E. This means that ΠGS(Σ) respects Σ.= H0,Conversely, if ΠGS(Σ) respects Σ, then for any E ⊆ Φ, there exists H ⊆ ∆ such thate(GSH (E)) = E. Then it is clear that e is surjective. (cid:1)The second notion of diagnosis that forms the Lucas refinement diagnosis [13] is mostgeneral superset diagnosis. It is similar to the notion of most general subset diagnosis,and the unique difference between them is that the ‘nearest’ acceptable super-hypothesisis used to replace an unacceptable hypothesis when necessary in the most general supersetdiagnosis, as indicated by its name.12M. Ying / Artificial Intelligence 163 (2005) 1–45Definition 15 (Most general superset diagnosis; [13, p. 335]). Let Σ = (∆, Φ, e) be adiagnostic specification. Then the notion of most general superset diagnosis generated byΣ is defined to be ΠGO(Σ) = (∆, Φ, GO), where for each E ⊆ Φ, and for each H ⊆ ∆,(cid:10) (cid:9)GOH (E) =u{H (cid:7) ⊆ H : e(H (cid:7)) ⊇ E}if H is consistent ande(H (cid:7)) ⊇ E for some H (cid:7) ⊆ H,otherwise.It may be observed that most general subset diagnosis and most general superset diagno-sis approach the observed findings from opposite directions. The following proposition issimilar to Proposition 14, presenting some fundamental properties of most general supersetdiagnosis in the Galois connection style.Proposition 16. Let Σ = (∆, Φ, e) be a diagnostic specification, and let ΠGO(Σ) =(∆, Φ, GO) be the notion of most general superset diagnosis generated by Σ.(1) If H is consistent, then GOH (e(D)) ⊇ D for any D ⊆ H .(2) If Σ is increasing and GOH (E) (cid:9)= u, i.e., H is consistent, and e(H ) ⊇ E, thene(GOH (E)) ⊇ E.(3) If Σ is increasing, then(cid:11)GOH (E) =H if H is consistent and e(H ) ⊇ E,uotherwise.Proof. Straightforward. (cid:1)The part (3) of the above proposition points out that the notion of most general supersetdiagnosis generated by an increasing diagnostic specification is trivial.It is interesting to note that a necessary and sufficient condition under which the notionof most general superset diagnosis respects the diagnostic specification generating it is thesame as that for most general subset diagnosis. This fact is exposed by the next proposition.Proposition 17. Let Σ = (∆, Φ, e) be a diagnostic specification and ΠGO(Σ) =(∆, Φ, GO) be the notion of most general superset diagnosis generated by Σ. ThenΠGO(Σ) respects Σ if and only if e is surjective.Proof. Similar to Proposition 14. (cid:1)As pointed out above, if we replace the subset relation in the defining equation of mostgeneral subset diagnosis with the superset relation, then we obtain the notion of most gen-eral superset diagnosis. For most general subset diagnosis, it is required that all possibleevidences must be observed; but for most general superset diagnosis, the condition is in-stead that no observed findings are not evidences specified by the diagnostic knowledgebase. In a sense, we may think that the subset relation and the superset relation are at thetwo extremes of the conditions that we can impose on a notion of diagnosis. An alternativeat the middle is then the relation of nonempty intersection. This motivates the followingdefinition.M. Ying / Artificial Intelligence 163 (2005) 1–4513Definition 18 (Most general intersection diagnosis; [13, p. 336]). Let Σ = (∆, Φ, e) be adiagnostic specification. Then the notion of most general intersection diagnosis generatedby Σ is defined to be ΠGI(Σ) = (∆, Φ, GI), where for any E ⊆ Φ and H ⊆ ∆,{H (cid:7) ⊆ H : e(H (cid:7)) = ∅ or e(H (cid:7)) ∩ E (cid:9)= ∅}if H is consistent, E (cid:9)= ∅ and e(H (cid:7)) = ∅ or e(H (cid:7)) ∩ E (cid:9)= ∅for some H (cid:7) ⊆ H,GIH (E) =(cid:9)H if H is consistent and E = ∅;uotherwise.The properties of most general intersection diagnosis are much more complicated thanthose of most general subset or superset diagnosis, and some of them are presented in thefollowing proposition.Proposition 19. Let Σ = (∆, Φ, e) be a diagnostic specification, let ΠGI(Σ) = (∆, Φ, GI)be the notion of most general intersection diagnosis generated by Σ, and let H ⊆ ∆ beconsistent and ∅ (cid:9)= E ⊆ Φ.(1) GIH (e(D)) ⊇ D for any D ⊆ H .(2) Suppose that Σ is increasing. Then(i) if e(∅) (cid:9)= ∅ and e(H ) ⊆ Φ − E, then GIH (E) = u;(ii) if e(H ) ∩ E (cid:9)= ∅, then GIH (E) = H ; and(iii) if e(H ) ⊆ Φ − E, then GIH (E) =(cid:9)H : e({d}) = ∅} whenever Σ is interaction free.{H (cid:7) ⊆ H : e(H ) = ∅}, and GIH (E) = {d ∈(3) Suppose that Σ is decreasing. Then(i) if e(H ) (cid:9)= ∅ and e(∅) ⊆ Φ − E, then GIH (E) = u;(ii) if e(H ) = ∅, then GIH (E) = H ; and(cid:9)(iii) if e(∅) ∩ E (cid:9)= ∅, then GIH (E) ={H (cid:7) ⊆ H : e(H (cid:7)) ∩ H (cid:9)= ∅}.Proof. Straightforward. (cid:1)Part (3) of the above proposition points out that the notion of most general supersetdiagnosis generated by an increasing diagnostic specification is trivial.A necessary and sufficient condition under which the notion of most general intersectiondiagnosis respects the diagnostic specification that generates it is also found to be the sameas that for most general subset diagnosis, and it is given by the next proposition.Proposition 20. Let Σ = (∆, Φ, e) be a diagnostic specification and ΠGI(Σ) = (∆, Φ, GI)be the notion of most general superset diagnosis generated by Σ. Then ΠGI(Σ) respectsΣ if and only if e is surjective.Proof. Similar to Proposition 14. (cid:1)We may see that in the above definitions we approximate an unacceptable hypothesiswith acceptable ones from the bottom. Of course, an alternative is to do the same fromtop. This observation suggests defining the notions of most specific subset diagnosis, most14M. Ying / Artificial Intelligence 163 (2005) 1–45specific superset diagnosis and most specific intersection diagnosis. What we need to dois to simply replace the union operation by intersection in the defining equation of thecorresponding notions. This leads us to the following three definitions.Definition 21 (Most specific subset diagnosis; [13, p. 337]). Let Σ = (∆, Φ, e) be a diag-nostic specification. Then the notion of most general subset diagnosis generated by Σ isdefined to be ΠSS(Σ) = (∆, Φ, SS), where for all E ⊆ Φ, and H ⊆ ∆,(cid:10) (cid:16){H (cid:7) ⊆ H : e(H (cid:7)) ⊆ E}SSH (E) =uif H is consistent and e(H (cid:7)) ⊆ Efor some H (cid:7) ⊆ H ;otherwise.In a sense, the notion of diagnosis given in the above definition is dual to that in Defini-tion 12. The following proposition gives some properties of most specific subset diagnosisin the Galois style with respect to the diagnostic specification generating it. Also, it presentsa simplified version of most specific subset diagnosis for increasing diagnostic specifica-tions.Proposition 22. Suppose that Σ = (∆, Φ, e) is a diagnostic specification, and ΠSS(Σ) =(∆, Φ, SS) the notion of most specific subset diagnosis generated by Σ.(1) If D ⊆ H is consistent, then SSH (e(D)) ⊆ D.(2) If Σ is increasing and SSH (E) (cid:9)= u, then e(SSH (E)) ⊆ E.(3) If Σ is increasing, then(cid:11)SSH (E) =∅ if H is consistent and e(∅) ⊆ E,u otherwise.Proof. Straightforward. (cid:1)The last part of this proposition indicates that the notion of most specific subset diagno-sis is not reasonable for increasing diagnostic specifications.We are only able to find a sufficient condition for a diagnostic specification to be re-spected by its most specific subset diagnosis.Proposition 23. Let Σ = (∆, Φ, e) be a diagnostic specification. If e is surjective, and itsatisfies the condition that D ⊂ D(cid:7) implies e(D) (cid:9)⊆ e(D(cid:7)) for all consistent D, D(cid:7) ⊆ ∆,then ΠSS(Σ) respects Σ.Proof. Similar to Proposition 14. (cid:1)The relation between the following definition and Definition 21 is similar to that be-tween Definitions 12 and 15; that is, we can derive the defining equation of SOH (E) in thefollowing definition by replacing directly ⊆ in the defining equation of SSH (E) with ⊇.M. Ying / Artificial Intelligence 163 (2005) 1–4515Definition 24 (Most specific superset diagnosis; [13, p. 339]). Let Σ = (∆, Φ, e) be adiagnostic specification. Then the notion of most general superset diagnosis generated byΣ is defined to be ΠSO(Σ) = (∆, Φ, SO), where for all E ⊆ Φ, and H ⊆ ∆,(cid:10) (cid:16){H (cid:7) ⊆ H : e(H (cid:7)) ⊇ E}SOH (E) =uif H is consistent ande(H (cid:7)) ⊇ E for some H (cid:7) ⊆ H ;otherwise.The following proposition presents some basic properties of most specific superset di-agnosis, and it is dual to Proposition 16.Proposition 25. Suppose that Σ = (∆, Φ, e) is a diagnostic specification, and ΠSO(Σ) =(∆, Φ, SO).(1) If D ⊆ H is consistent, then SOH (e(D)) ⊆ D.(2) If Σ is decreasing and SOH (E) (cid:9)= u, then e(SOH (E)) ⊇ E.(3) If Σ is decreasing, then(cid:11)SOH (E) =∅ if H is consistent and e(∅) ⊇ E,u otherwise.Proof. Straightforward. (cid:1)From the above proposition, we see that the notion of most specific superset diagnosisis not suited to act as a diagnostic method with respect to a decreasing diagnostic specifi-cation.The following proposition gives a sufficient condition under which the notion of mostspecific superset diagnosis respects its diagnostic specification. It is interesting to compareit with the condition in Proposition 23. The only difference between them is the conversenon-inclusion relations of e(D) and e(D(cid:7)).Proposition 26. Let Σ = (∆, Φ, e) be a diagnostic specification. If e is surjective andsatisfies the condition that D ⊂ D(cid:7) implies e(D) (cid:9)⊇ e(D(cid:7)) for all consistent D, D(cid:7) ⊆ ∆,then ΠSO(Σ) respects Σ.Proof. Similar to Proposition 14. (cid:1)It is still an open problem to find a necessary and sufficient condition under whichΠSS(Σ) or ΠSO(Σ) respects Σ.By replacing the union operation in the defining equation of most general intersectiondiagnosis, we obtain:16M. Ying / Artificial Intelligence 163 (2005) 1–45Definition 27 (Most specific intersection diagnosis; [13, p. 340]). Let Σ = (∆, Φ, e) be adiagnostic specification. Then the notion of most specific intersection diagnosis generatedby Σ is defined to be ΠSI(Σ) = (∆, Φ, SI), where for any E ⊆ Φ and for any H ⊆ ∆,{H (cid:7) ⊆ H : e(H (cid:7)) = ∅ ore(H (cid:7)) ∩ E (cid:9)= ∅}SIH (E) =(cid:16)Huif H is consistent,E (cid:9)= ∅ and e(H (cid:7)) = ∅ ore(H (cid:7)) ∩ E (cid:9)= ∅ for some H (cid:7) ⊆ H,if H is consistent and E = ∅;otherwise.Some basic properties of most specific intersection diagnosis are given in the followingproposition.Proposition 28. Let Σ = (∆, Φ, e) be a diagnostic specification, let ΠSI(Σ) = (∆, Φ, SI),and let H ⊆ ∆ be consistent and ∅ (cid:9)= E ⊆ Φ.(1) If D ⊆ H , then SIH (e(D)) ⊆ D.(2) Suppose that Σ is increasing. Then(i) if e(∅) (cid:9)= ∅ and e(H ) ⊆ Φ − E, then SIH (E) = u;(ii) if e(∅) = ∅, then SIH (E) = ∅; and(iii) if e(∅) (cid:9)= ∅, then SIH (E) =(3) Suppose that Σ is decreasing. Then(cid:16){H (cid:7) ⊆ H : e(H (cid:7)) ∩ E (cid:9)= E}.(i) if e(H ) (cid:9)= ∅ and e(∅) ⊆ Φ − E, then SIH (E) = u;(ii) if e(∅) ∩ E (cid:9)= ∅, then SIH (E) = ∅; and(iii) if e(∅) ∩ E = ∅, then SIH (E) ={H (cid:7) ⊆ H : e(H (cid:7)) = ∅}.(cid:16)Proof. Straightforward. (cid:1)A sufficient condition under which the notion of most specific intersection diagnosisrespects its diagnostic specification is presented in the following proposition.Proposition 29. If Σ = (∆, Φ, e) is a diagnostic specification fulfilling the condition thatD(cid:7) ⊂ D and e(D) (cid:9)= ∅ implies e(D(cid:7)) (cid:9)= ∅ and e(D(cid:7)) ∩ e(D) = ∅ for all consistent D, D(cid:7) ⊆∆, then ΠSI(Σ) respects Σ.Proof. Similar to Proposition 14. (cid:1)To conclude this section, we examine the influence of the global properties of a diagnos-tic specification on various notions of diagnosis generated from it and how certain relationsbetween diagnostic specifications are preserved by the notions of diagnosis generated bythem. The next proposition shows that most general superset diagnosis and most specificsubset diagnosis preserve the sub-relation of the diagnostic specifications generating them,but most general subset diagnosis and most specific superset diagnosis reverse this rela-tion. Unfortunately, the sub-relation of most general or specific intersection diagnoses isM. Ying / Artificial Intelligence 163 (2005) 1–4517not completely determined by the corresponding relation of diagnosis specifications thatgenerate them.Proposition 30. Let Σ and Σ (cid:7) be two diagnostic specifications with the same sets of defectsand findings. If Σ (cid:10) Σ (cid:7), then(1) ΠGS(Σ (cid:7)) (cid:10) ΠGS(Σ);(2) ΠGO(Σ) (cid:10) ΠGO(Σ (cid:7));(3) ΠSS(Σ) (cid:10) ΠGS(Σ (cid:7)); and(4) ΠSO(Σ (cid:7)) (cid:10) ΠSO(Σ).Proof. By a routine argument. (cid:1)In order to present the last proposition of this section in a more compact way, we needto introduce a notation expressing some global properties for diagnostic specifications andnotions of diagnosis.Definition 31. Let Σ = (∆, Φ, e) be a diagnostic specification. Then for each A, B ∈{∪, ∩} and C ∈ {⊆, ⊇}, the property (ABC) is defined as follows:(ABC) e(Ai∈I Di )CBi∈I e(Di )for any Di ⊆ ∆ (i ∈ I ) with e(Di) (cid:9)= ⊥ (i ∈ I ) and e(Ai∈I Di) (cid:9)= ⊥, where I is an arbitraryindex set.Similarly, we can define the corresponding properties for notion of diagnosis.It is easy to see that interaction freeness is equivalent to (∪∪ ⊆) plus (∪∪ ⊇).The properties defined above are very interesting. For example, the property (∪∩ ⊆)may be rewritten as(cid:8)RH (E) ⊆(cid:3)(cid:2){f }RHf ∈Efor each E ⊆ Φ and H ⊆ ∆. It depicts a method of diagnosis that we often adopt in ourdaily life. Suppose that a set E of findings are observed, and we want to find a diagnosticsolution to E. Usually, we first find all defects RH ({f }) that may cause the single find-ing f for each f ∈ E. Then it allows us to locate the true solution among the commondefects for all findings in E. The next proposition indicates that global properties of a di-agnosis specification of type (ABC) are inherited by most general (or specific) subset (orsuperset) diagnosis generated from it. However, both most general and specific intersectiondiagnoses do not enjoy such an inheritance.Proposition 32. Let Σ = (∆, Φ, e) be a diagnostic specification, and let A, B ∈ {∪, ∩}.(1) If Σ satisfies (AB ⊆), then ΠGS(Σ) satisfies (BA ⊇).(2) If Σ satisfies (AB ⊇), then ΠGO(Σ) satisfies (BA ⊇).18M. Ying / Artificial Intelligence 163 (2005) 1–45(3) If Σ satisfies (AB ⊆), then ΠSS(Σ) satisfies (BA ⊆).(4) If Σ satisfies (AB ⊇), then ΠSO(Σ) satisfies (BA ⊆).Proof. We prove (1) as an example. From the definition of most general subset diagnosisit follows thatGSH (Bi∈I Ei) =and(cid:1)(cid:6)H (cid:7) ⊆ H : e(H (cid:7)) ⊆ Bi∈I Ei(cid:7)(cid:7)Ai∈I GSH (Ei) = Ai∈I ∪(cid:6)H (cid:7)iAi∈I H (cid:7)⊆ H : e(H (cid:7)i : H (cid:7)i ) ⊆ Ei⊆ H and e(H (cid:7)i(cid:1)(cid:6)=i ) ⊆ Ei (i ∈ I )(cid:7).Now we only need to show that if for each i ∈ I , H (cid:7)⊆ Hiand e(Ai∈I H (cid:7)i ) ⊆ Bi∈I Ei . The first inclusion is obvious, and the second one is guaranteedby the property (AB⊆) of Σ. (cid:1)i) ⊆ Ei , then Ai∈I H (cid:7)⊆ H and e((cid:7)i3. Diagnostic specification morphismsThis section is devoted to establish a mathematical model of knowledge transformationin diagnostic problem solving, namely, diagnostic specification morphism. We will care-fully compare the diagnostic strategies in the source system of a specification morphismand its target system. First, we introduce a formal definition of specification morphism.Definition 33 (Specification morphism). Let Σ1 = (∆1, Φ1, e1) and Σ2 = (∆2, Φ2, e2) betwo diagnostic specifications. A specification morphism from Σ1 to Σ2 is a pair M = (g, h)of mappings g : ∆1 → ∆2 and h : Φ1 → Φ2 fulfilling the following two conditions:(i) for all d ∈ ∆1 and f ∈ Φ1,g(¬d) = ¬g(d)and h(¬f ) = ¬h(f ); and(ii) for each D ⊆ ∆1, it holds that(cid:2)= e2f (D)(cid:2)e1(D)g(cid:3)(cid:3);in other words, the following diagram commutes:℘ (∆1)e1℘ (Φ1)fg℘ (∆2)e2℘ (Φ2)where f and g are respectively the extensions of g and h to ℘ (∆1) and ℘ (Φ1), i.e., forany D ⊆ ∆1 and E ⊆ Φ1,g(D) =h(E) =(cid:7)(cid:6)g(d): d ∈ D(cid:6)h(f ): f ∈ E,(cid:7),andh(⊥) = ⊥.Table 1Knowledge in system A{d1}{f1, f2}eA(D)D∅∅M. Ying / Artificial Intelligence 163 (2005) 1–4519{d2}{f2}{d3}{f3}{d1, d2}{f1, f2}{d1, d3}{f1, f2, f3}{d2, d3}{f2, f3}{d1, d2, d3}{f1, f2, f3}Table 2Knowledge in system B{v1}{w3}eB (D)D∅∅. . .. . .{v4}{w1, w3}. . .. . .{v1, v4}{w1, w3}. . .. . .For simplicity, we will write g and h in place of g and h, respectively.Obviously, (id∆, idΦ ) is a morphism from diagnostic specification Σ = (∆, Φ, e) toitself, where idX stands for the identity function on set X. In addition, it is easy to verifythat if both M1 = (g1, h1) : Σ1 → Σ2 and M2 = (g2, h2) : Σ2 → Σ3 are specification mor-phisms, then M2 ◦ M1 = (g2 ◦ g1, h2 ◦ h1) : Σ1 → Σ3 is a morphism too. Thus, we have acategory of diagnostic specifications together with specification morphisms.To illustrate the above definition, consider the following simple example.Example 34. A typical application of specification morphism is analyzing the relation-ship between different medical systems, say, traditional Chinese medicine and the westernmedicine. Suppose that A and B are two different medical systems. A piece of medicalknowledge in system A is represented by the diagnostic specification ΣA = (∆A, ΦA, eA),where ∆A = {d1, d2, d3}, ΦA = {f1, f2, f3}, d1, d2, d3 are the names of three symptoms,f1, f2, f3 are the names of three diseases, and the evidence function eA depicting the causalknowledge between symptoms and diseases is given by Table 1.Furthermore, we assume that a piece of medical knowledge in system B is describedby the diagnosis specification ΣB = (∆B, ΦB , eB) in which ∆B = {v1, v2, v3, v4}, ΦB ={w1, w2, w3}, and (a fragment of) the evidence function eB is given by Table 2.We now compare the two medical systems. The symptom d1 in system A is renamedas v4 in system B, both symptoms d2 and d3 are called v1 in system B, and in system Athere is no counterpart of symptoms v2 and v3 in system B. This gives a defect mappingg : ∆A → ∆B . On the other hand, a finding mapping h : ΦA → ΦB is defined by h(f1) =w1 and h(f2) = h(f3) = w3. Then it is easy to verify that (g, h) is a specification morphismfrom ΣA to ΣB , and it establishes a reasonable link between the two medical systems Aand B.The following proposition shows that a specification morphism is able to carry someglobal properties, including monotonicity and interaction freeness, of its source specifica-tion forward to its target specification.Proposition 35. Suppose that M = (g, f ) : Σ1 = (∆1, Φ1, e1) → Σ2 = (∆2, Φ2, e2) is aspecification morphism, and g is surjective. Then20M. Ying / Artificial Intelligence 163 (2005) 1–45(1) if Σ1 is increasing (respectively decreasing), then Σ2 is also increasing (respectivelydecreasing);(2) if Σ1 is interaction free, so is Σ2.Proof. (1) We only consider the increasing case. For any D2, D(cid:7)2⊆ ∆2, we have(cid:2)(cid:3)D2 = g(cid:7)and D2because g is surjective. If D2 ⊆ D(cid:7)−1(D2)g(cid:2)(cid:3)−1(D(cid:7)2)(cid:2)(cid:3)(cid:3)= gg2 and D(cid:7)2 is consistent in Σ2, then(cid:3)(cid:3)= e2(D(cid:7)g−1(D(cid:7)2) (cid:9)= ⊥.2)g2)) (cid:9)= ⊥; i.e., g−1(D(cid:7)2) is also consistent in Σ1. Otherwise, it2). Since2) = h(⊥) = ⊥, a contradiction. Note that g−1(D2) ⊆ g−1(D(cid:7)(cid:2)(cid:2)(cid:2)he1g−1(D(cid:7)= e22)This implies that e1(g−1(D(cid:7)follows that e2(D(cid:7)Σ1 is increasing, it holds thatg−1(D2)(cid:7)−1(Dg2)e2(D2) = e2(cid:2)⊆ h(cid:2)ge1(cid:2)(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:2)(cid:2)= he1= e2(Dg−1(D2)(cid:7)2).(2) For each D ⊆ ∆2, if D is consistent in Σ2, then from (1) we know that g−1(D) isconsistent in Σ1. Since e1 is interaction free, it holds that(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)(cid:2)(cid:2)(cid:2)(cid:4) (cid:1)e2(D) = e2gg−1(D)(cid:2)= h= hge1(cid:4) (cid:1)−1(D)= h(cid:2)(cid:2)e1g−1{d}(cid:3)(cid:3)e1(cid:5)=d∈D(cid:1)(cid:5)(cid:5)(cid:3)(cid:2){d}−1g(cid:2)e1h(cid:2)g−1(cid:2){d}(cid:3)(cid:3)(cid:3)(cid:1)d∈D(cid:2)(cid:2)e2g=(cid:2){d}g−1(cid:3)(cid:3)(cid:3)=d∈D(cid:1)e2(cid:2)(cid:3).{d}(cid:1)d∈Dd∈DFor reason of limited space, we are not going to examine carefully how other globalproperties, such as those of type (ABC) defined at the end of the previous section, ofdiagnostic specification is preserved by specification morphism.We now want to observe how a morphism between partial specifications can be extendedto a morphism between the total specifications generated from them. To this end, we firstintroduce the following definition.Definition 36 (Partial specification morphism). Let Σ1 = (∆1, Φ1, V1, e1) and Σ2 =(∆2, Φ2, V2, e2) be two partial specifications. Then a specification morphism from Σ1 toΣ2 is a pair M = (g, h) of mappings g : ∆1 → ∆2 and h : Φ1 → Φ2 such that(i) g(V1) = {g(D): D ∈ V1} ⊆ V2; and(ii) h(e1(D)) = e2(g(D)) for each D ∈ V1.The notion of specification morphism for partial specifications is obviously a gener-alization of the one for (total) diagnostic specifications. The next proposition shows thata partial specification morphism can also serve as a specification morphism for the caseM. Ying / Artificial Intelligence 163 (2005) 1–4521of increasing bottom-up construction. To save space, we omit a detailed discussion of thecorresponding problem for the other constructions given in Definition 6.Proposition 37. Let Σ (cid:7)iof Σi = (∆i, Φi , ei) (i = 1, 2), and M = (g, h) is a specification morphism from Σ (cid:7)Σ (cid:7)i) be an increasing bottom-up partial specification1 to= (∆i, Φi, Vi , e(cid:7)2. If(1) g−1(D2) ∈ V1 for any D2 ∈ V2;(2) g−1(g(D1)) = D1 for any D1 ∈ V1; and(3) g(g−1(D2)) = D2 for any D2 ∈ V2,then M is also a specification morphism from Σ1 to Σ2.Proof. For each D1 ⊆ ∆1, it follows that⊆ D1. We have g(D(cid:7)1) ⊆ g(D1). Moreover, since1) ∈ V2. Then Zorn’s lemma warrants1 to Σ (cid:7)2, g(D(cid:7)∈ m(V1, D1)∈ m(V1, D1)∈ m(V1, D1)(cid:5)(cid:7)(cid:7)(cid:7).(cid:3)(cid:4)(cid:1)(cid:6)(cid:2)he=== h(cid:1)(cid:6)(cid:1)(cid:6)(cid:7)1(De1(D1)(cid:2)1(D(cid:7)e(cid:7)h1)(cid:2)g(D(cid:7)1)(cid:7)(cid:7)1): D1(cid:3): D(cid:7)1(cid:3): D(cid:7)1If D(cid:7)∈ V1 and D(cid:7)11M is a specification morphism from Σ (cid:7)that g(D(cid:7)(cid:2)he(cid:7)2∈ m(V1, D1), then D(cid:7)12 for some D(cid:7)1) ⊆ D(cid:7)(cid:1)(cid:6)(cid:3)2(D(cid:7)e(cid:7)⊆e1(D1)∈ m2(cid:2)∈ m(V2, g(D1)). Consequently,2): D(cid:7)∈ m(V2, g(D1)), it holds that D(cid:7)2V2, g(D1)= e2(cid:3)(cid:7)(cid:2)2(cid:3).g(D1)Conversely, for any D(cid:7)2condition (1) we obtain g−1(D(cid:7)D1. Again, Zorn’s lemma tells us that g−1(D(cid:7)= g(g−1(D(cid:7)follows from condition (3) that D(cid:7)2(cid:2)(cid:3)V2, g(D1)2) ∈ V1, and from (2) we have g−1(D(cid:7)2) ⊆ D(cid:7)2)) ⊆ g(D(cid:7)(cid:3)(cid:7)1 for some D(cid:7)1), and(cid:2)g(D1)∈ m(cid:1)(cid:6)e2=1∈ V2 and D(cid:7)2⊆ g(D). From2) ⊆ g−1(g(D1)) =∈ m(V1, D1). Thus, it2(D(cid:7)e(cid:7)(cid:2)e(cid:7)22): D(cid:7)(cid:3)g(D(cid:7)1)2: D(cid:7)1(cid:1)(cid:6)⊆∈ m(V1, D1)(cid:7)(cid:2)= h(cid:3)e1(D1).(cid:1)We now come to present the main results of this section. The following group of propo-sitions will provides us with a close connection between a transformation of knowledgebases in different diagnostic systems and a transformation of their diagnostic strategies.The intuitive idea of transformation between diagnostic strategies is captured by the con-cept of diagnosis morphism given in the following definition.Definition 38 (Diagnosis morphism). Let Π1 = (∆1, Φ1, R1) and Π2 = (∆2, Φ2, R2) betwo notions of diagnosis. A diagnosis morphism from Π1 to Π2 is a pair M = (g, h)22M. Ying / Artificial Intelligence 163 (2005) 1–45∅ETable 3Diagnosis notion in system A{f1}∅uu{d1, d2}RA,∅(E)RA,{d1}(E)RA,{d2}(E)RA,{d1,d2}(E)∅∅∅∅∅ETable 4Diagnosis notion in system B{w1}∅uu{v1, v2}RB,∅(E)RB,{v1}(E)RB,{v2}(E)RB,{v1,v2}(E)∅∅∅∅{f2}∅∅{d2}{d1}{f3}∅∅{d2}{d1}{f1, f2}∅{d1}∅{d1}{f2, f3}∅∅{d2}{d1}{f1, f3}∅{d1}∅{d1}{f1, f2, f3}∅{d1}∅∅{w2}∅∅∅∅{w3}∅{v1}∅{v2}{w1, w2}∅uu{v1, v2}{w2, w3}∅{v1}∅{v2}{w1, w3}∅∅{v2}{v2}{w1, w2, w3}∅{v2}∅∅of mappings g : ∆1 → ∆2 and h : Φ1 → Φ2 satisfying condition (i) in Definition 33 andcommutativity of the following diagram:℘ (∆1)R1,H℘ (Φ1)gh℘ (∆2)R2,g(H )℘ (Φ2)in other words, for any E ⊆ Φ and H ⊆ ∆, g(R1,H (E)) = R2,g(H )(h(E)), where it isassumed that g(u) = u.The following simple example illustrates the notion of diagnosis morphism very well.Example 39. Suppose A and B are two expert systems for medical diagnosis. Let ∆A ={d1, d2}, ∆B = {v1, v2}, g(d1) = v2 and g(d2) = v1, and let ΦA, ΦB and h be the sameas in Example 34. Part of diagnosis method used in system A is represented by Table 3,and part of the diagnosis method used in B is given in Table 4. Then it is easy to checkthat (g, h) is a diagnosis morphism from RA to RB , and we may think that it provides amechanism for reusing diagnosis method of system A in system B.We now investigate some fundamental properties of diagnosis morphism and its con-nection to specification morphism. The next proposition tells us that the information that anotion of diagnosis respects a diagnostic specification can be carried forward and backwardby specification morphisms and diagnosis morphisms under a certain condition.Proposition 40. Let Σi = (∆i, Φi , ei) be a diagnostic specification and Πi = (∆i, Φi , Ri )a notion of diagnosis with the same sets of defects and findings (i = 1, 2). Suppose thatΠ1 respects Σ1. If there is a pair M = (g, h) of mappings such that M is a specificationmorphism from Σ1 to Σ2, it is also a diagnosis morphism from Π1 to Π2, and both g andM. Ying / Artificial Intelligence 163 (2005) 1–4523h are surjective, then Π2 respects Σ2. Furthermore, if Π1 strictly respects Σ1, then Π2also strictly respects Σ2.Proof. For each E ⊆ Φ2, there exists H ⊆ ∆1 such that e1(R1,H (h−1(E))) = h−1(E)because Π1 respects Σ1. Since h is surjective, we have h(h−1(E)) = E. This yields that(cid:2)E = h= e2(cid:2)(cid:3)(cid:2)= h(cid:2)(cid:2)hh−1(E)(cid:2)R2,g(H )= e2R2,g(H )(E)On the other hand, for each consistent D ⊆ ∆2, we are able to find some H ⊆ ∆1 suche1h−1(E)R1,H(cid:3)(cid:3)(cid:3)R1,Hg(cid:3).(cid:2)h−1(E)(cid:2)= e2(cid:2)h−1(E)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:2)(cid:2)that R2,g(H )(e2(D)) = D. Therefore, Π2 respects Σ2.For the case that Π1 strictly respects Σ1, we can assume that R1,H (cid:7)(e1(g−1(D))) = ufor all H (cid:7) (cid:9)⊇ H. Our purpose is to show that R2,H (cid:7)(cid:7) (e2(D)) = u for each H (cid:7)(cid:7) (cid:9)⊇ g(H ). If notso; i.e., there is H (cid:7)(cid:7) ⊆ ∆2 with H (cid:7)(cid:7) (cid:9)⊇ g(H ) and R2,H (cid:7)(cid:7) (e2(D)) (cid:9)= u, then from the fact thatg is surjective we know that(cid:2)(cid:3)R2,H (cid:7)(cid:7)e2(D)= R2,g(g−1(H (cid:7)(cid:7)))(cid:3)(cid:2)e2(D)(cid:2)= gR1,g−1(H (cid:7)(cid:7))e1(cid:2)(cid:2)−1(D)g(cid:3)(cid:3)(cid:3),and R1,g−1(H (cid:7)(cid:7))(e1(g−1(D))) (cid:9)= u. If g−1(H (cid:7)(cid:7)) ⊇ H , then g(H ) ⊆ g(g−1(H (cid:7)(cid:7))) = H (cid:7)(cid:7), andit is impossible. Thus, it holds that g−1(H (cid:7)(cid:7)) (cid:9)⊇ H . This contradicts to the previous assump-tion. (cid:1)The following two propositions clarify the relationship between the six diagnosticstrategies of the Lucas refinement diagnosis [13] in the source diagnostic systems of aspecification morphism and those in the target system. Suppose we are given a diagnosticproblem in the source system. The next proposition carefully compares the following twopaths: (i) we first find a diagnostic solution by using the diagnostic method in the sourcesystem, and then map it into the target system; and (ii) we map our diagnostic problem andhypothesis into the target system, and then find a diagnostic solution by employing the di-agnostic methods in the target system. For example, if we adopt the notion of most generalintersection diagnosis in both the source and target systems, then Propositions 41(5) and(6) indicate that path (i) always gives a stricter solution than path (ii), but the two solutionsaccording to paths (i) and (ii) are the same when the defect mapping is bijective and thefinding mapping is injective.Proposition 41. Let Σi = (∆i, Φi , ei) be a diagnostic specification (i = 1, 2), and letM = (g, h) be a specification morphism from Σ1 to Σ2. For any E ⊆ Φ1 and H ⊆ ∆1, wehave(1) g(GS1,H (E)) ⊆ GS2,g(H )(h(E)) if GS1,H (E) (cid:9)= u;(2) GS2,g(H )(h(E)) ⊆ g(GS1,H (E)) if GS2,g(H )(h(E)) (cid:9)= u, g is bijective and h is injec-tive;(3) g(GO1,H (E)) ⊆ GO2,g(H )(h(E)) if GO1,H (E) (cid:9)= u;(4) GO2,g(H )(h(E)) ⊆ g(GO1,H (E)) if GO2,g(H )(h(E)) (cid:9)= u, g is bijective and h is in-jective;(5) g(GI1,H (E)) ⊆ GI2,g(H )(h(E)) if GI1,H (E) (cid:9)= u;24M. Ying / Artificial Intelligence 163 (2005) 1–45(6) GI2,g(H )(h(E)) ⊆ g(GI1,H (E)) if GI2,g(H )(h(E)) (cid:9)= u, g is bijective and h is injec-tive;(7) g(SS1,H (E)) ⊆ SS2,g(H )(h(E)) if SS2,g(H )(h(E)) (cid:9)= u, g is bijective and h is injec-tive;(8) SS2,g(H )(h(E)) ⊆ g(SS1,H (E)) if SS1,H (E) (cid:9)= u and g is injective;(9) g(SO1,H (E)) ⊆ SO2,g(H )(h(E)) if SO2,g(H )(h(E)) (cid:9)= u, g is bijective and h is injec-tive;(10) SO2,g(H )(h(E)) ⊆ g(SO1,H (E)) if SO1,H (E) (cid:9)= u and g is injective;(11) g(SI1,H (E)) ⊆ SI2,g(H )(h(E)) if SI2,g(H )(h(E)) (cid:9)= u, g is bijective and h is injective;and(12) SI2,g(H )(h(E)) ⊆ g(SI1,H (E)) if SI1,H (E) (cid:9)= u and g is injective.Proof. We only demonstrate (7) as an instance. We note that injectivity of g implies(cid:2)gSS1,H (E)(cid:3)= g(cid:4)(cid:8)(cid:6)H(cid:7) ⊆ H : e1(H(cid:7)) ⊆ E(cid:5)(cid:7)(cid:8)(cid:6)=g(H (cid:7)): H (cid:7) ⊆ H and e1(H (cid:7)) ⊆ E(cid:7),and(cid:2)SS2,g(H )h(E)(cid:8)(cid:6)(cid:3)=K (cid:7) ⊆ g(H ): e2(K (cid:7)) ⊆ h(E)(cid:7)whenever SS1,H (E) (cid:9)= u and SS2,g(H )(h(E)) (cid:9)= u. Thus, it suffices to prove the followingtwo items:(i) H is consistent if and only if g(H ) is consistent. Indeed, if e1(H ) (cid:9)= ⊥, thene2(g(H )) = h(e1(H )) (cid:9)= ⊥, and g(H ) is consistent. Conversely, if e2(g(H )) (cid:9)= ⊥, we musthave e1(H ) (cid:9)= ⊥.(ii) {g(H (cid:7)): H (cid:7) ⊆ H and e1(H (cid:7)) ⊆ E} = {K (cid:7) ⊆ g(H ): e2(K (cid:7)) ⊆ h(E)}. In fact, if H (cid:7) ⊆H and e1(H (cid:7)) ⊆ E, then g(H (cid:7)) ⊆ g(H ), and e2(g(H (cid:7))) = h(e1(H (cid:7))) ⊆ h(E). Conversely,if K (cid:7) ⊆ g(H ) and e2(K (cid:7)) ⊆ h(E), then we set H (cid:7) = g−1(K (cid:7)), and it holds that K (cid:7) = g(H (cid:7))and H (cid:7) ⊆ g−1(g(H )) = H because g is an bijection. Furthermore,(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:2)(cid:2)e1(H (cid:7)) ⊆ h−1e1(H (cid:7))= h−1g(H (cid:7))e2= h−1(cid:2)e2(K)⊆ h−1(cid:2)h(E)= E.(cid:2)(cid:2)hThe last equality comes from the fact that h is injective. (cid:1)The following simple corollary shows that sometimes a specification morphism can actas a diagnosis morphism too.Corollary 42. Let Σi = (∆i, Φi , ei) be a diagnostic specification and ΠGS(Σi ) =(∆i, Φi , GSi) be the notion of most general subset diagnosis generated by Σi (i = 1, 2),and let M = (g, h) be a specification morphism from Σ1 to Σ2. If g is a bijection and h isan injection, then M is also a diagnosis morphism from ΠGS(Σ1) to ΠGS(Σ2). The sameconclusion also holds for ΠGO, ΠGI, ΠSS, ΠSO and ΠSI.Proof. Immediate from Proposition 41. (cid:1)M. Ying / Artificial Intelligence 163 (2005) 1–4525What was considered in Proposition 41 is a forward transformation of various diagnosticnotions. The next proposition considers a backward transformation of diagnostic methods.Now the diagnostic problem is given in the target system, and the two paths under com-parison are: (i) we find a diagnostic solution in the target system, and then map it into thesource system via the inverse of defect mapping; and (ii) we map the observed findingsand hypothesis into the source system through the inverses of finding mapping and defectmapping respectively, and then find a solution using the diagnostic notion in the sourcesystem. The following proposition examines the relation between the diagnostic solutionsobtained through these two paths.Proposition 43. Let Σi = (∆i, Φi , ei) be a diagnostic specification (i = 1, 2), and letM = (g, h) be a specification morphism from Σ1 to Σ2. For any E ⊆ Φ2 and H ⊆ ∆2, wehave(1) g−1(GS2,H (E)) ⊆ GS1,g−1(H )(h−1(E)) if GS2,H (E) (cid:9)= u;(2) GS1,g−1(H )(h−1(E)) ⊆ g−1(GS2,H (E)) if GS1,g−1(H )(h−1(E)) (cid:9)= u and H is consis-tent, and in particular GS1,g−1(H )(h−1(E)) = g−1(GS2,H (E)) if GS2,H (E) (cid:9)= u andGS1,g−1(H )(h−1(E)) (cid:9)= u;(3) g−1(GO2,H (E)) ⊆ GO1,g−1(H )(h−1(E)) if GO2,H (E) (cid:9)= u, g is surjective and h isinjective;(4) GO1,g−1(H )(h−1(E)) ⊆ g−1(GO2,H (E)) if GO1,g−1(H )(h−1(E)) (cid:9)= u, H is consis-tent and h is surjective;(5) g−1(GI2,H (E)) ⊆ GI1,g−1(H )(h−1(E)) if GO2,H (E) (cid:9)= u, g is surjective and h is(6) GI1,g−1(H )(h−1(E)) ⊆ g−1(GI2,H (E)) if GI1,g−1(H )(h−1(E)) (cid:9)= u, h−1(E) (cid:9)= ∅ and(7) SS1,g−1(H )(h−1(E)) ⊆ g−1(SS2,H (E)) if SS2,H (E) (cid:9)= u;(8) g−1(SS2,H (E)) ⊆ SS1,g−1(H )(h−1(E)) if SS1,g−1(H )(h−1(E)) (cid:9)= u, H is consistent(9) SO1,g−1(H )(h−1(E)) ⊆ g−1(SO2,H (E)) if SO2,H (E) (cid:9)= u, g is surjective and h isbijective;H is consistent;and g is injective;injective;(10) g−1(SO2,H (E)) ⊆ SO1,g−1(H )(h−1(E)) if SO1,g−1(H )(h−1(E)) (cid:9)= u, H is consistent,g is injective and h is surjective;(11) SI1,g−1(H )(h−1(E)) ⊆ g−1(SI2,H (E)) if SI2,H (E) (cid:9)= u, g is surjective and h is bijec-(12) g−1(SI2,H (E)) ⊆ SI1,g−1(H )(h−1(E)) if SI1,g−1(H )(h−1(E)) (cid:9)= u, H is consistenttive;and g is injective.Proof. As examples, we demonstrate (1), (2) and (6).(1) If GS2,H (E) (cid:9)= u, then H is consistent in Σ2, i.e., e2(H ) (cid:9)= ⊥, and there is H (cid:7) ⊆ Hsuch that e2(H (cid:7)) ⊆ E. First, we show that g−1(H ) is consistent in Σ1. If not so, thene1(g−1(H )) = ⊥, and(cid:3)(cid:3)(cid:2)(cid:3)(cid:3)(cid:2)(cid:2)ge2g−1(H )(cid:2)= he1g−1(H )= ⊥.26M. Ying / Artificial Intelligence 163 (2005) 1–45Note that g(g−1(H )) ⊆ H . From condition (ii) in Definition 2.1 it follows that e2(H ) = ⊥,a contradiction.Second, it holds that(cid:3)(cid:2)GS2,H (E)g−1(cid:4)(cid:1)(cid:6)= g−1(cid:1)(cid:6)g=H (cid:7) ⊆ H : e2(H (cid:7)) ⊆ E(cid:5)(cid:7)−1(H(cid:7)): H(cid:7) ⊆ H and e2(H(cid:7)) ⊆ E(cid:7),and(cid:2)(cid:3)(cid:1)(cid:6)GS1,g−1(H )K (cid:7) ⊆ g−1(H ): e1(K (cid:7) ⊆ h−1(E)For any H (cid:7) ⊆ H with e2(H (cid:7)) ⊆ E, we have g−1(H (cid:7)) ⊆ g(cid:7)(H ), andh−1(E)=(cid:2)(cid:2)he1g−1(H (cid:7))(cid:3)(cid:3)(cid:2)(cid:2)g= e2g−1(H (cid:7))(cid:3)(cid:3)⊆ e2(H ) ⊆ E.(cid:7).Then(cid:2)g−1(H (cid:7))(cid:3)e1⊆ h−1(cid:2)(cid:2)he1(cid:2)g−1(H (cid:7))(cid:3)(cid:3)(cid:3)h−1(E).This shows that(cid:6)g−1(H (cid:7)): H (cid:7) ⊆ H and e2(H (cid:7) ⊆ E(cid:6)(cid:7)⊆K (cid:7) ⊆ g−1(H ): e1(K (cid:7) ⊆ h−1(E)(cid:7),and g−1(GS2,H (E)) ⊆ GS1,g−1(H )(h−1(E)) follows.(2) For any K (cid:7) ⊆ g−1(H ) with e1(K (cid:7)) ⊆ h−1(E), we need to find a set H (cid:7) ⊆ H suchthat e2(H (cid:7)) ⊆ E and K (cid:7) ⊆ g−1(H (cid:7)). It is easy to see that we can take H (cid:7) = g(K (cid:7)).(6) If GI1,g−1(H )(h−1(E)) (cid:9)= u, h−1(E) (cid:9)= ∅ and H is consistent, then E (cid:9)= ∅, and weobtainGI1,g−1(H )(cid:2)h−1(E)(cid:1)(cid:6)(cid:3)=(cid:7)K (cid:7) ⊆ g−1(H ): e1(K (cid:7)) = ∅ or e1(K (cid:7)) ∩ h−1(E) (cid:9)= ∅,and−1g(cid:2)GI2,H (E)(cid:3)=(cid:1)(cid:6)−1(Hg(cid:7)): H(cid:7) ⊆ H, and e2(H(cid:7)) = ∅ or e2(H(cid:7)(cid:7)) ∩ E (cid:9)= ∅.Now it suffices to show that for any K (cid:7) ⊆ g−1(H ) with e1(K (cid:7)) = ∅ or e1(K (cid:7)) ∩ h−1(E) (cid:9)=∅, there exists H (cid:7) ⊆ H with e2(H (cid:7)) = ∅ or e2(H (cid:7)) ∩ E (cid:9)= ∅, and K (cid:7) ⊆ g−1(H (cid:7)). Indeed,we take H (cid:7) = g(K (cid:7)). ThenK (cid:7) ⊆ g−1(cid:3)(cid:2)g(K)= g−1(H (cid:7)),andH (cid:7) = g(K (cid:7)) ⊆ g(cid:2)(cid:3)g−1(H )⊆ H.(cid:3)= h(∅) = ∅.If e1(K (cid:7)) = ∅, then(cid:2)e2(H (cid:7)) = e2(cid:2)e1(K (cid:7))= hIf e1(K (cid:7)) ∩ h−1(E) (cid:9)= ∅, then(cid:7)g(K (cid:7))(cid:3)(cid:7)e2(H) ∩ E = e2(cid:2)⊇ h(cid:2)⊇ h(cid:3)(cid:2)(cid:2)∩ E = hg(K)(cid:3)(cid:2)h−1(E)e1(K (cid:7))∩ h(cid:3)e1(K (cid:7)) ∩ h−1(E)e1(K(cid:3)(cid:9)= ∅.(cid:3)(cid:7))∩ E(cid:1)M. Ying / Artificial Intelligence 163 (2005) 1–45274. Operations of diagnostic specificationsThe aim of this section is to introduce several operations of diagnostic specificationswhich can model knowledge gathering, fusion, merging and combination in the processesof diagnostic problem solving. These operations include optimistic and pessimistic fusions,sum, direct product as well as optimistic and pessimistic mergings. The diagnostic strate-gies in a composite system modelled by a certain operation of diagnostic specifications willbe analyzed in terms of the corresponding diagnostic strategies in its component systems.Definition 44 (Optimistic and pessimistic fusions of specifications). Let Σi = (∆, Φ, ei )(i ∈ I ) be a family of diagnostic specifications with the same sets of defects and findings.i∈I ei)Then their optimistic and pessimistic fusions are defined to beandi∈I Σi = (∆, Φ,(cid:9)(cid:9)(cid:16)(cid:16)i∈I Σi = (∆, Φ,(cid:5)(cid:4)(cid:1)(cid:17) (cid:9)ei(D) =i∈I ei ), respectively, where for each D ⊆ ∆,i∈I ei(D)if ei(D) (cid:9)= ⊥ for all i ∈ I,otherwise,⊥(cid:11) (cid:16)(cid:5)i∈I(cid:4)(cid:8)i∈Iei(D) =⊥i∈I ei(D)if ei(D) (cid:9)= ⊥ for all i ∈ I,otherwise.It is easy to see that the notions of optimistic and pessimistic fusions are well-defined.i∈I Σi isi∈I Σi is also complete, butMoreover, if all Σi (i ∈ I ) are complete, thennot necessary to be complete.(cid:16)(cid:9)Some other interesting fusion operators for diagnostic specifications may be introduced.A typical example is contradiction-finding operator. Remember that an evidence functionallows contradictory values f and ¬f . So, a fusion operator can be defined by modifyingslightly the above definition to indicate conflicting opinions about a topic and to resolvethis conflict. We are not going to examine these extra fusion operators in detail.Example 45. We imagine a medical expert system which aggregates medical knowledgefrom different doctors. Certainly, there will be many different ways for such an aggregation.It is reasonable to say that optimistic and pessimistic fusions are at the two extremes ofthe whole spectrum formed by these aggregation ways. Let ∆ = {d1, d2, d3} and Φ ={f1, f2, f3}, where d1, d2 and d3 stand for three symptoms and f1, f2 and f3 three diseases.Suppose that a piece of medical knowledge of doctor A and a piece of medical knowledgeof doctor B (both concerning the causal relation between symptoms d1, d2, d3 and f1,f2, f3) are represented by evidence eA and eB respectively (see Table 5). Then a simplecalculation gives their optimistic fusion eA ∪ eB and pessimistic fusion eA ∩ eB as shownin Table 6.Table 5Knowledge of doctors A and BDeAeB∅∅∅{d1}{f1}∅{d2}∅{f3}{d3}{f2}{f2}{d1, d2}{f1, f3}{f3}{d1, d3}{f1, f2}{f1, f2}{d2, d3}{f2}{f2, f3}{d1, d2, d3}{f1, f2, f3}{f1, f2, f3}28M. Ying / Artificial Intelligence 163 (2005) 1–45Table 6Optimistic and pessimistic fusionsDeA ∪ eBeA ∩ eB∅∅∅{d1}{f1}∅{d2}{f3}∅{d3}{f2}{f2}{d1, d2}{f1, f3}{f3}{d1, d3}{f1, f2}{f1, f2}{d2, d3}{f2, f3}{f2}{d1, d2, d3}{f1, f2, f3}{f1, f2, f3}The next proposition indicates that some global properties of diagnostic specifications,such as monotonicity and interaction freeness, are preserved by the fusion operations. Theoptimistic fusion of a family of increasing (respectively decreasing, interaction free) diag-nostic specifications is also increasing (respectively decreasing, interaction free), and thepessimistic fusion of a family of decreasing diagnostic specifications is decreasing.Proposition 46. Let Σi = (∆, Φ, ei ) (i ∈ I ) be a family of diagnostic specifications withthe same sets of defects and findings.(1) If all Σi (i ∈ I ) are increasing, then both(cid:9)(2) If all Σi (i ∈ I ) are decreasing, so is(3) If all Σi (i ∈ I ) are interaction free, so isi∈I Σi .(cid:9)i∈I Σi .(cid:9)i∈I Σi and(cid:16)i∈I Σi are increasing.(cid:16)Proof. (1) We only consider pessimistic fusion. Suppose that D ⊆ D(cid:7) ⊆ ∆ and D(cid:7) is con-i∈I Σi . From the condition (2) in Definition 1 we know that for each i ∈ I , ifsistent inei(D(cid:7)) (cid:9)= ⊥ then ei(D) (cid:9)= ⊥. This implies that(cid:8)(cid:6)(cid:4)(cid:8)(cid:5)(cid:7)(D) =ei(D): i ∈ I and ei(D) (cid:9)= ⊥eii∈Iei(D): i ∈ I and ei(D(cid:7)) (cid:9)= ⊥): i ∈ I and ei(D(cid:7)) (cid:9)= ⊥(cid:7)(cid:7)(cid:8)(cid:6)(cid:8)(cid:6)(cid:4)(cid:8)⊆⊆=(cid:7)ei(D(cid:5)(D(cid:7))eibecause ei(D) ⊆ ei(D(cid:7)) for all i ∈ I .i∈Ii∈I ei)(D) (cid:9)= ⊥, then ei(D) (cid:9)= ⊥ for each i ∈ I , and interaction freeness of Σi(2) Similar to (1).(cid:9)(3) If ((i ∈ I ) leads to(cid:4)(cid:1)(cid:5)(D) =eii∈I(cid:1)ei (D) =(cid:4)(cid:1)i∈I(cid:1)(cid:4) (cid:1)(cid:1)(cid:2)eii∈I(cid:2){d}d∈D(cid:5)(cid:3)=ei(cid:1)(cid:5)(cid:3){d}(cid:4)(cid:4)(cid:1)(cid:5)(cid:2){d}(cid:5)(cid:3).ei(cid:1)=d∈Di∈Id∈Di∈IThe relationship between the diagnostic methods used in a fused diagnostic systemand the diagnostic methods in its component systems are established by the followingM. Ying / Artificial Intelligence 163 (2005) 1–4529two propositions. For example, if we adopt the notion of most general subset diagnosis,then Proposition 47(1) shows that the diagnostic solution in an optimistic fusion is alwaysincluded in the intersection of the solutions in its component systems, and they are the samewhen these component diagnostic specifications are all increasing. On the other hand, ifwe adopt the notion of most specific subset diagnosis, then Proposition 47(3) indicates thatthe diagnostic solution in an optimistic fusion includes the union of the solutions in itscomponent systems, and they are equal provided all component diagnostic specificationsare decreasing.Proposition 47. Let Σi = (∆, Φ, ei ) (i ∈ I ) be a family of diagnostic specifications with(cid:9)i∈I ei) be their optimisticthe same sets of defects and findings, and letfusion.i∈I Σi = (∆, Φ,(cid:9)(cid:9)(cid:9)(1) If ΠGS(Σi ) = (∆, Φ, Ri ) is the notion of most general subset diagnosis generated byi∈I Σi ) = (∆, Φ, R) the notion of most general subset diagnosisΣi (i ∈ I ) and ΠGS(i∈I Σi , then for any E ⊆ Φ and H ⊆ ∆,generated by(cid:16)i∈I Ri,H (E) when RH (E) (cid:9)= u; and(1.1) RH (E) ⊆(cid:16)i∈I Ri,H (E) if all Σi (i ∈ I ) are increasing.(1.2) RH (E) =(2) If ΠGO(Σi) = (∆, Φ, Ri ) is the notion of most general superset diagnosis generatedi∈I Σi ) = (∆, Φ, R) the notion of most general superseti∈I Σi , then for all E ⊆ Φ and H ⊆ ∆,i∈I Ri,H (E) ⊆ RH (E) whenever H is consistent in each Σi (i ∈ I ), andby Σi (i ∈ I ) and ΠGO((cid:9)diagnosis generated by(2.1)(cid:9)(cid:9)Ri0,H (E) (cid:9)= u for some i0 ∈ I ; and(cid:9)(2.2) RH (E) =i∈I Ri,H (E) if E is finite, and {Σi }i∈I is directed with respect to thesub-specification relation (cid:10), i.e., for any i1, i2 ∈ I , there is an i0 ∈ I such thatΣi1(cid:10) Σi0 and Σi2(cid:10) Σi0 .(3) If ΠSS(Σi) = (∆, Φ, Ri ) is the notion of most specific subset diagnosis generated byi∈I Σi ) = (∆, Φ, R) the notion of most specific subset diagnosis(cid:9)(cid:9)Σi (i ∈ I ) and ΠSS(generated by(cid:9)(3.1)(3.2) RH (E) =i∈I Σi , then for any E ⊆ Φ and for any H ⊆ ∆,(cid:9)i∈I Ri,H (E) ⊆ RH (E) provided RH (E) (cid:9)= u; andi∈I Ri,H (E) if all Σi (i ∈ I ) are decreasing.(4) If ΠSO(Σi ) = (∆, Φ, Ri ) is the notion of most specific superset diagnosis generatedi∈I Σi ) = (∆, Φ, R) the notion of most specific superseti∈I Σi , then for all E ⊆ Φ and H ⊆ ∆,i∈I Ri,H (E) provided Ri,H (E) (cid:9)= u for each i ∈ I ; andi∈I Ri,H (E) when E is finite, and {Σi}i∈I is directed with respectby Σi (i ∈ I ) and ΠSO((cid:9)diagnosis generated by(4.1) RH (E) ⊆(4.2) RH (E) =(cid:16)(cid:16)(cid:9)to the sub-specification relation (cid:10).Proof. We only prove (1.1), (1.2) and (4.2); the others are similar and so omitted.(cid:9)(1.1) First, we note that H is consistent inΣi (i ∈ I ). Second, we havei∈I Σi if and only if it is consistent in each(cid:1)(cid:17)H (cid:7) ⊆ H :RH (E) =(cid:18)ei(H (cid:7)) ⊆ E=(cid:1)i∈I(cid:1)H (cid:7)∈(cid:16)i∈I{H (cid:7)⊆H : ei (H (cid:7))⊆E}H (cid:7)30M. Ying / Artificial Intelligence 163 (2005) 1–45(cid:8)⊆(cid:19)(cid:1)(cid:6)H (cid:7) ⊆ H : ei(H (cid:7)) ⊆ E(cid:8)(cid:7)(cid:20)=Ri,H (E).i∈I(cid:16)i∈I Ri,H (E), then for any i ∈ I , d ∈ Ri,H (E) and there exists H (cid:7)i∈I H (cid:7)⊆ Hi . Then H (cid:7) ⊆ H , and for any i ∈ I ,(1.2) If d ∈i ) ⊆ E and d ∈ H (cid:7)i . Let H (cid:7) =such that ei(H (cid:7)ei(H (cid:7)) ⊆ ei(H (cid:7)i ) ⊆ E because ei is increasing. This means that(cid:8)(cid:7)(cid:6)H (cid:7) ⊆ H : ei(H (cid:7)H (cid:7) ∈.i∈I(cid:16)ii ) ⊆ Ei∈IConsequently, we have d ∈ H (cid:7) ⊆ RH (E), and(cid:8)i∈IRi,H (E) ⊆ RH (E).(4.2) If d /∈ RH (E), then there exists H (cid:7) ⊆ H such thati∈I ei(H (cid:7)) ⊇ E and d /∈H (cid:7). Assume that E = {f1, f2, . . . , fm}. Then for any k (cid:1) m, we have some ik ∈ I withfk ∈ eik (H (cid:7)). Since {Σi }i∈I is directed with respect to (cid:10), there must be i0 ∈ I such thateik (H (cid:7)) ⊆ ei0(H (cid:7)) for all k (cid:1) m. Now, it follows that E ⊆ ei0(H (cid:7)), d /∈ Ri0,H (E), andd /∈(cid:16)i∈I Ri,H (E). Therefore, it follows that(cid:8)(cid:9)Ri,H (E) ⊆ RH (E).(cid:1)i∈IThe next proposition deals with the case of pessimistic fusion. It is shown that thediagnostic solution in a pessimistic fusion is always looser than the union of the solutionsin its component systems if we apply the notion of most general subset diagnosis or mostspecific superset diagnosis; whereas the diagnosis in a pessimistic fusion is stricter than theintersection of the solutions in its component systems if the notion of most general supersetdiagnosis or most specific subset diagnosis is employed.Proposition 48. Let Σi = (∆, Φ, ei ) (i ∈ I ) be a family of diagnostic specifications withi∈I ei) be their pes-the same sets of defects and findings, and letsimistic fusion.i∈I Σi = (∆, Φ,(cid:16)(cid:16)(1) If ΠGS(Σi ) = (∆, Φ, Ri ) (i ∈ I ) and ΠGS(Φ and H ⊆ ∆, it holds thatRi,H (E) ⊆ RH (E).(cid:1)i∈I(2) If ΠGO(Σi ) = (∆, Φ, Ri ) (i ∈ I ) and ΠGO(Φ and H ⊆ ∆, we haveRH (E) ⊆(cid:8)Ri,H (E),i∈I(cid:16)i∈I Σi )) = (∆, Φ, R), then for any E ⊆(cid:16)i∈I Σi )) = (∆, Φ, R), then for any E ⊆and the equality holds whenever all Σi (i ∈ I ) are decreasing.(cid:16)i∈I Σi)) = (∆, Φ, R), then for any E ⊆ Φ(3) If ΠSS(Σi) = (∆, Φ, Ri ) (i ∈ I ) and ΠSS((cid:8)and H ⊆ ∆, it holds thatRH (E) ⊆Ri,H (E).i∈IM. Ying / Artificial Intelligence 163 (2005) 1–4531(4) If ΠSO(Σi ) = (∆, Φ, Ri ) (i ∈ I ) and ΠSO(Φ and H ⊆ ∆, it holds thatRi,H (E) ⊆ RH (E)(cid:1)(cid:16)i∈I (Σi )) = (∆, Φ, R), then for any E ⊆i∈Iwith the equality when all Σi (i ∈ I ) are increasing.Proof. Similar to Proposition 47. (cid:1)Definition 49 (Sum of specifications). Let Σi = (∆i , Φi, ei ) (i ∈ I ) be a family ofi∈I Σi =diagnostic specifications. Then the sum of Σi (i ∈ I ) is defined to be(cid:9)(cid:9)((cid:21)(cid:9)i∈I Φi , e), where for each D ⊆(cid:11) (cid:9)i∈I ∆i,e(D) =⊥i∈I ei(D ∩ ∆i)i∈I ∆i ,if ei(D ∩ ∆i) (cid:9)= ⊥ for all i ∈ I ;otherwise.It is easy to see that the notion of sum is well-defined; that is, e satisfies the conditionsi∈I Σi is complete whenever all Σi (i ∈ I ) are(cid:21)(1) and (2) in Definition 1. Furthermore,complete.A simple idea behind sum of diagnostic specifications is that we can divide a big sys-tem into some independent smaller systems and then examine these subsystems one byone. Thus, the notion of specification sum provides us with a mathematical model of mod-ularization technique in diagnostic problem solving.Example 50. Suppose we have an industrial system consisting of two subsystems A andB. These two systems are assumed to be independent in the sense that the function ofone subsystem cannot be affected by the defects in the other subsystem, for instance, thewater and gas systems in a plant. Let ΣA = (∆A, ΦA, eA) and ΣB = (∆A, ΦB, eB ) specifyrespectively the causal interactions among the components of the two subsystems, where∆A = {d1, d2, d3}, ΦA = {f1, f2}, ∆B = {d4, d5}, ΦB = {f3, f4}, and eA and eB are givenby Tables 7 and 8. ThenΣA ⊕ ΣB ={d1, d2, d3, d4, d5}, {f1, f2, f3, f4}, e(cid:3),(cid:2)and it may be seen as a diagnostic knowledge base of the whole system. For example,(cid:2){d4, d5}(cid:2){d3, d4, d5}= {f1, f3, f4};= eA∪ eB{d3}e(cid:2)(cid:3)(cid:3)(cid:3)Table 7Subsystem ADeA∅∅{d1}∅{d2}∅{d3}{f1}{d1, d2}∅{d1, d3}{f1}{d2, d3}{f1}{d1, d2, d3}{f1, f2, f3}Table 8Subsystem BDeB∅∅{d4}{f4}{d5}{f3}{d4, d5}{f3, f4}32M. Ying / Artificial Intelligence 163 (2005) 1–45that is, the observable findings for the simultaneous occurrences of defects d3, d4 and d5are f1, f3 and f4.Both monotonicity and interaction freeness are preserved by the operation of diagnosticspecification sum.Proposition 51. Let Σi = (∆i, Φi, ei ) (i ∈ I ) be a family of diagnostic specifications. Ifall Σi (i ∈ I ) are increasing (respectively decreasing, interaction free), so is(cid:21)i∈I Σi .Proof. We consider the interaction-free case as an example. For any consistent D ⊆(cid:9)i∈I ∆i , it holds that(cid:1)e(D) =ei(D ∩ ∆i) =(cid:1)(cid:1)(cid:1)(cid:1)(cid:3)(cid:2){d}ei=(cid:3)(cid:2){d}e=i∈I(cid:1)e(cid:9)i∈I (D∩∆i )d∈i∈I(cid:3)d∈D∩∆i(cid:1)(cid:2){d}=e(cid:3).i∈Id∈D∩∆i(cid:1)(cid:2){d}d∈DOne may naturally expects that all component diagnostic systems can be embeddedinto the sum of them via the inclusion morphisms, and specification morphisms of thecomponent systems can be glued to a morphism of their sum. This is indeed guaranteed bythe following proposition.Proposition 52. (1) Let Σi = (∆i, Φi , ei) (i ∈ I ) be a family of diagnostic specifications,and for each k ∈ I , let(cid:1)in∆k : ∆k (cid:6)→and inΦk : Φ (cid:6)→(cid:1)∆iΦii∈Ibe the inclusion mappings from ∆k intoi.e., for any d ∈ ∆k and f ∈ Φk,in∆k (d) = dand inΦk (f ) = f.i∈I(cid:9)i∈I ∆i and from Φk into(cid:9)i∈I Φi , respectively,If ∆i ∩ ∆j = ∅ for all i, j ∈ I with i (cid:9)= j , and ei(∅) = ∅ for each i ∈ I , then ink =(in∆k , inΦk ) is a specification morphism from Σk toi∈I Σi .(2) Suppose that Mi = (gi, hi ): Σi = (∆i, Φi , ei) → Σ (cid:7)ii) (i ∈ I ) be afamily of specification morphisms, and ∆i ∩ ∆j = ∅ and Φi ∩ Φj = ∅ provided i, j ∈ Iand i (cid:9)= j . Let(cid:22)= (∆(cid:7)i∈I gi,i, Φ(cid:7)i , e(cid:7)(cid:22)(cid:1)(cid:1)(cid:1)(cid:21)(cid:21)(cid:21)(cid:21)i∈I Mi = ((cid:1)∆(cid:7)∆i →i,i∈I hi), whereΦi →hi :Φ(cid:7)igi :i∈I(cid:9)i∈Iand for all d ∈(cid:5)(cid:4)(cid:22)i∈Ii∈I ∆i and f ∈(cid:9)i∈Ii∈I Φi ,gi(d) = gj (d) when d ∈ ∆ji∈Ii∈I(cid:4)(cid:22)and(cid:5)hi(f ) = hj (f ) when f ∈ Φj .i∈Ii∈IIf gi (∆i) ∩ gj (∆j ) = ∅ for all i, j ∈ I with i (cid:9)= j , theni∈I Σ (cid:7)i .phism fromi∈I Σi to(cid:21)(cid:21)(cid:21)i∈I Mi is a specification mor-M. Ying / Artificial Intelligence 163 (2005) 1–4533Proof. (1) is easy. We only prove (2). The condition that {∆i} and {Φi} (i ∈ I ) are pairwisei∈I ∆i ,disjoint warrants that bothwe havei∈I hi are well-defined. For each D ⊆i∈I gi and(cid:21)(cid:21)(cid:9)(cid:5)(cid:2)e(D)(cid:3)=(cid:4)(cid:22)hii∈I(cid:4)(cid:22)(cid:5)(cid:4)(cid:1)hiei (D ∩ ∆i)=(cid:5)(cid:4)(cid:22)(cid:1)(cid:5)(cid:2)(cid:3)ei(D ∩ ∆i)hii∈I(cid:1)(cid:2)hii∈I=i∈Iei(D ∩ ∆i )(cid:1)(cid:3)=i∈Ii∈Ii∈I(cid:2)gi (D ∩ ∆i )(cid:3).(cid:7)ieSince gi(∆i) ∩ gj (∆j ) = ∅ for all i, j ∈ I with i (cid:9)= j , it holds that(cid:24)gi (D ∩ ∆i)∩ ∆(cid:7)j= gj (D ∩ ∆j ).(cid:23)(cid:1)i∈IConsequently, it follows that(cid:5)(cid:2)e(D)(cid:4)(cid:22)(cid:1)=(cid:3)hi(cid:4)(cid:4)(cid:1)e(cid:7)i(cid:5)(cid:5)gi (D ∩ ∆i )∩ ∆(cid:7)ji∈Ii∈I(cid:4)(cid:1)= e(cid:7)i∈Ii∈I(cid:5)gi (D ∩ ∆i )= e(cid:7)(cid:4)(cid:4)(cid:22)(cid:5)(cid:5)gi(D).(cid:1)i∈IWe now are going to observe the relationship between the notions of diagnosis in a sumsystem and those in its component systems. To this end, we need to introduce the conceptof sum of diagnostic notions.Definition 53 (Sum of diagnostic notions). Let Πi = (∆i, Φi , Ri) (i ∈ I ) be a fam-ily of notions of diagnosis. Then the sum of Πi (i ∈ I ) is defined to bei∈I Πi =(cid:9)(cid:9)((cid:21)(cid:9)(cid:9)i∈I Φi and H ⊆i∈I ∆i,i∈I ∆i ,i∈I Φi , R), where for any E ⊆i∈I Ri,H ∩∆i (E ∩ Φi)(cid:17) (cid:9)RH (E) =uif Ri,H ∩∆i (E ∩ Φi ) (cid:9)= u for all i ∈ I,otherwise.If we have a large diagnostic system consisting of some subsystems, and each subsys-tem has a notion of diagnosis respected by its diagnostic specification, then the followingproposition guarantees that in the whole large system the diagnostic specification respectsthe sum of the notions of diagnosis in all subsystems.Example 54. We consider the two notions of diagnosis in Example 39, ΠA = (∆A, ΦA, RA)and ΠB = (∆B, ΦB , RB ). They were originally linked via a diagnosis morphism inExample 39, but here they are treated as two independent subsystems of a larger di-agnosis system Π . Thus, Π can be thought of as the sum of ΠA and ΠB ; that is,Π = ({d1, d2, v1, v2}, {f1, f2, f3, w1, w2, w3}, R) and R = {RH : H ⊆ {d1, d2, v1, v2}}.Let H = {d1, v1, v2} be a hypothesis and E = {f2, f3, w1, w2} a diagnostic problem in Π .Then the solution to E under hypothesis H is34M. Ying / Artificial Intelligence 163 (2005) 1–45RH (E) = RA,H ∩∆A (E ∩ ΦA) ∪ RB,H ∩∆B (E ∩ ΦB )(cid:3)(cid:3)(cid:2)(cid:2){w1, w2}{f2, f3}= RA,{d1}= ∅ ∪ {v1, v2} = {v1, v2}.∪ RB,{v1,v2}Proposition 55. Let Σi = (∆i, Φi , ei) (i ∈ I ) be a family of diagnostic specifications andΠi = (∆i, Φi , Ri) (i ∈ I ) a family of notions of diagnosis such that Σi and Πi have thesame sets of defects and findings for each i ∈ I . If for all i ∈ I , Πi (strictly) respects Σi ,theni∈I Πi (strictly) respectsi∈I Σi too.(cid:21)(cid:21)(cid:9)Proof. For each consistent D ⊆there is Hi ⊆ ∆i such that Ri,Hi (ei (D ∩ ∆i )) = D ∩ ∆i , and Ri,H (cid:7)H (cid:7)ii∈I ∆i , and for any i ∈ I , since Πi strictly respects Σi ,(ei (D ∩ ∆i)) = u for all(cid:9)i∈I Hi . Theni⊆ ∆i with H (cid:7)i(cid:3)(cid:2)e(D)RH=(cid:9)⊇ Hi . Let H =(cid:2)(cid:1)Ri,H ∩∆iei(D ∩ ∆i)(cid:3)=i∈I(cid:1)i∈I(cid:2)Ri,Hiei(D ∩ ∆i)(cid:1)(cid:3)=i∈I(D ∩ ∆i ) = D.Furthermore, if H (cid:7) (cid:9)⊇ H , then there must be i0 ∈ I such that H (cid:7) ∩ ∆i0RH (cid:7)∩∆i0(ei0(D ∩ ∆i0)) = u and RH (cid:7) (e(D)) = u.(cid:9)Likewise, we can prove that for any E ⊆(cid:9)⊇ Hi0 . Now, we have(cid:9)i∈i ∆i with(cid:21)i∈I Πi strictly respectsi∈I Φi , there exists H ⊆(cid:21)i∈I Σi . (cid:1)e(RH (E)) = E. This implies thatThe following proposition relates the diagnostic method in a sum system to the diagnos-tic strategies in its component systems. Consider a diagnostic problem with the observedfindings E and hypothesis H in a large system consisting of some subsystems. Of course,the best way to solve this problem is to deal with it directly in the whole system. Of-ten, however, this is very difficult. An alternative way is to find a diagnostic solution ineach subsystem with the piece of information in this subsystem provided by E and H . Wethen combine these solutions in all subsystems to form a diagnostic solution for the wholesystem. Now a natural question is: how far is this alternative solution from our expectedsolution? The following proposition answers this question: if we employ the notion of mostgeneral subset diagnosis or most specific superset diagnosis, then the alternative solutionis stricter than the expected one, but for the notion of most general superset diagnosis ormost specific subset diagnosis, the alternative solution is looser than the expected one; anda similar result conditionally holds for the notion of most general or specific intersectiondiagnosis.Proposition 56. Let Σi = (∆i, Φi , ei) (i ∈ I ) be a family of diagnostic specifications.(1) If ΠGS(Σi) = (∆i , Φi, Ri ) (i ∈ I ) and ΠGS((cid:9)(cid:9)i∈I Σi ) = ((cid:9)i∈I ∆i,(cid:9)i∈I Φi , R), theni∈I Φi , and for any H ⊆(cid:9)(cid:9)i∈I Ri,H ∩∆i (E ∩ Φi ); andi∈I Ri,H ∩∆i (E ∩ Φi ) if for any i, j ∈ I , ∆i ∩ ∆j = ∅ whenever(cid:21)i∈I ∆i ,for any E ⊆(1.1) RH (E) ⊆(1.2) RH (E) =i (cid:9)= j .M. Ying / Artificial Intelligence 163 (2005) 1–4535(cid:21)i∈I Σi ) = ((cid:9)i∈I ∆i,(cid:9)i∈I Φi , R),i∈I Ri,H ∩∆i (E ∩ Φi ) if for any i, j ∈ I , Φi ∩ Φj = ∅ whenever(cid:21)i∈I Σi) = ((cid:9)i∈I ∆i,(cid:9)i∈I Φi , R), then(2) If ΠGO(Σi) = (∆i, Φi , Ri ) (i ∈ I ) and ΠGO((cid:9)(cid:9)i∈I Φi and H ⊆i∈I ∆i ,i∈I Ri,H ∩∆i (E ∩ Φi ) ⊆ RH (E); and(cid:9)then for all E ⊆(cid:9)(2.1)(2.2) RH (E) =i (cid:9)= j .(3) If ΠGI(Σi) = (∆i, Φi , Ri) (i ∈ I ) and ΠGI((cid:9)(cid:9)for all E ⊆i∈I Φi and H ⊆i∈I ∆i ,(cid:1)i∈IRi,H ∩∆i (E ∩ Φi ) ⊆ RH (E)provided ∆i ∩ ∆j = ∅ for all i, j ∈ I with i (cid:9)= j .(cid:21)(4) If ΠSS(Σi ) = (∆i, Φi , Ri) (i ∈ I ) and ΠSS((cid:9)(cid:9)i∈I Σi) = ((cid:9)i∈I ∆i,(cid:9)i∈I Φi , R), then(cid:9)for all E ⊆(4.1)(4.2) RH (E) =i∈I Φi and H ⊆i∈I ∆i ,i∈I Ri,H ∩∆i (E ∩ Φi ) ⊆ RH (E); and(cid:9)(5) If ΠSO(Σi ) = (∆i, Φi , Ri ) (i ∈ I ) and ΠSO((cid:9)(cid:9)i∈I Σi) = (i∈I ∆i,i∈I Φi, R), theni∈I Ri,H ∩∆i (E ∩ Φi ) if ∆i ∩ ∆j = ∅ for all i, j ∈ I with i (cid:9)= j .(cid:21)(cid:9)(cid:9)for all E ⊆(5.1) RH (E) ⊆(5.2) RH (E) =(cid:9)(cid:9)i∈I Φi , and for all H ⊆i∈I ∆i ,i∈I Ri,H ∩∆i (E ∩ Φi ); andi∈I Ri,H ∩∆i (E ∩ Φi ) if Φi ∩ Φj = ∅ for all i, j ∈ I with i (cid:9)= j .(cid:21)(cid:9)(cid:9)(6) If ΠSI(Σi ) = (∆i, Φi , Ri) (i ∈ I ) and ΠSI((cid:9)(cid:9)i∈I Σi) = (i∈I ∆i,i∈I Φi , R), thenfor all E ⊆i∈I Φi and H ⊆i∈I ∆i ,(cid:1)RH (E) ⊆Ri,H ∩∆i (E ∩ Φi )i∈Iwhenever ∆i ∩ ∆j = ∅ for all i, j ∈ I with i (cid:9)= j .Proof. We only prove (4). From Definition 21 it follows that(cid:18)(cid:8)(cid:17)(cid:1)RH (E) =H (cid:7) ⊆ H : e(H (cid:7)) =ei (H (cid:7) ∩ ∆i) ⊆ E,and(cid:1)i∈Ii∈I(cid:6)H (cid:7)∩i(cid:1)i∈I⊆ H ∩ ∆i: ei(H (cid:7)i ) ⊆ E ∩ Φi(cid:7)i : H (cid:7)H (cid:7)i⊆ H ∩ ∆i and ei (H (cid:7)i ) ⊆ E ∩ Φi for all i ∈ I(cid:18).Ri,H ∩∆i (E ∩ Φi ) ==(cid:8)(cid:17)(cid:1)i∈INote that complete distributivity of set union over intersection is applied in the last equality.(cid:9)Now the conclusion comes immediately from the following two items:(a) If H (cid:7) ⊆ H and e(H (cid:7)) ⊆ E, then we set H (cid:7)i⊆ H ∩ ∆i , and(cid:1)(cid:25)i∈I H (cid:7)i , H (cid:7)(cid:27)(cid:1)(cid:28)(cid:26)iH (cid:7) =ei(H(cid:7)i ) = ei(H(cid:7)i ) ∩ Φi ⊆(cid:7)j ) ∩ Φi=ej (Hj ∈I(cid:7)j )ej (Hj ∈I∩ Φi ⊆ E ∩ Φi .= H ∩ ∆i for each i ∈ I . It holds that36M. Ying / Artificial Intelligence 163 (2005) 1–45(cid:9)(b) Conversely, if for each i ∈ I , H (cid:7)i⊆ H ∩ ∆i and ei(H (cid:7)i ) ⊆ E ∩ Φi , then we seti . It is clear that H (cid:7) ⊆ H . Since ∆i ∩ ∆j = ∅ whenever i (cid:9)= j , we havei and(cid:1)(cid:1)ei(H (cid:7) ∩ ∆i) ⊆(Ei ∩ Φi ) = E.(cid:1)i∈I H (cid:7)H (cid:7) =H (cid:7) ∩ ∆i = H (cid:7)e(H (cid:7)) =i∈Ii∈IAs we saw before, the concept of diagnostic specification sum models the modular-ization technique of dividing a large system into a number of subsystems. Here, we aregoing to introduce the concept of direct product of diagnostic specifications. It can be usedto describe the way that we observe various profiles of a system. The two operations ofspecification sum and product are orthogonal in a sense, and they complement each other.Definition 57 (Direct product of specifications). Let Σi = (∆i, Φi , ei) (i ∈ I ) be a fam-i∈I Σi =ily of diagnostic specifications. Then their direct product is defined to be(cid:29)(cid:29)((cid:29)(cid:29)i∈I ∆i,i∈I ∆i ,i∈I Φi , e), where for each D ⊆(cid:17) (cid:29)e(D) =(cid:29)⊥i∈I ei(proji(D))if ei (proji (D)) (cid:9)= ⊥ for all i ∈ I,otherwise,(cid:29)j ∈I ∆j → : ∆i is the projection on ∆i ; i.e., for any d = (dj )j ∈I ∈and proji :(cid:29)proji(d) = di . Moreover, we define ¬x = (¬xi)i∈I for all x = (xi)i∈I ∈(cid:29)j ∈I ∆j ,i∈I ∆i ∪i∈I Πi .The notion of direct product is well-defined; i.e.,i∈I Σi is indeed a diagnostic specifi-i∈I Σi is not necessary to be complete when all Σi (i ∈ I ) are complete.cation. However,(cid:29)(cid:29)Example 58. The direct product of diagnostic specifications models the process that oneextracts his knowledge bases from different profiles of an object and then aggregate themtogether into a single knowledge base. Suppose we have a system whose function is deter-mined by two factors A and B. The causal interactions between defects and findings relatedto factors A and B are described by the diagnostic specifications ΣA = (∆A, ΦA, eA) andΣB = (∆B, ΦB , eB), respectively, where ∆A = {d1, d2, d3}, ΦA = {f1, f2}, ∆B = {c1, c2},ΦB = {g1, g2, g3}, and eA and eB are given by Tables 9 and 10. If the two factors A and Bare assumed to be interaction free, then the direct productΣA × ΣB =(cid:2)(cid:6)(cid:7)(d1, c1), (d1, c2), (d2, c1), (d2, c2), (d3, c1), (d3, c2)(cid:6)(f1, g1), (f1, g2), (f1, g3), (f2, g1), (f2, g2), (f2, g3),(cid:7), e(cid:3)provides a diagnostic knowledge base for the whole system. For example,(cid:2)(cid:6)(cid:7)(cid:3)e(d1, c2), (d2, c1), (d2, c2)(cid:2)(cid:2){d1, d2}(cid:3){c1, c2}× eB= eA(cid:6)=(f1, g1), (f1, g2), (f1, g3)(cid:7),(cid:3)and the possible findings are (f1, g1), (f1, g2), (f1, g3) when (d1, c2), (d2, c1) and (d2, c2)occur simultaneously. The following proposition shows that the operation of direct productof diagnostic specifications preserves monotonicity.M. Ying / Artificial Intelligence 163 (2005) 1–4537Table 9Factor system ADeA∅∅{d1}∅{d2}{f1}{d3}∅{d1, d2}{f1}{d1, d3}∅{d2, d3}{f1}{d1, d2, d3}{f1, f2}Table 10Factor system BDeB∅∅{c1}{g3}{c2}∅{c1, c2}{g1, g2, g3}Proposition 59. Let Σi = (∆i, Φi, ei ) (i ∈ I ) be a family of diagnostic specifications. IfΣi (I ∈ i) are all increasing (respectively decreasing), theni∈I Σi is also increasing(respectively decreasing).(cid:29)Proof. Immediate. (cid:1)The next proposition demonstrates that the direct product of a family of specificationmorphisms is a specification morphism from the direct product of their domains to thedirect product of their co-domains.Proposition 60. Let Mi = (gi, hi ) : Σi = (∆i, Φi , ei) → Σ (cid:7)(cid:29)ibe a family of specification morphisms, and let(cid:29)i∈I Φ(cid:7)i be defined as follows:i∈I hi :i∈I gi :(cid:29)(cid:29)(cid:29)i∈I Φi →(cid:5)= (∆(cid:7)i, Φ(cid:7)i∈I ∆i →i , e(cid:7)(cid:29)i) (i ∈ I )i∈I ∆(cid:7)i andfor any d = (di)i∈I ∈(cid:30)∆i,andfor any f = (fi )i∈I ∈i∈I(cid:30)Φi .i∈Ii∈I hi ) is a specification morphism from(cid:29)i∈I Σi to(cid:29)i∈I Σ (cid:7)i .(cid:4)(cid:30)i∈I(cid:4)(cid:30)gi(d) = (gi(di))i∈I(cid:5)hi(f ) = (hi(fi ))i∈I(cid:29)i∈Ii∈I Mi = (Then(cid:29)Proof. For any D ⊆(cid:29)i∈I gi ,(cid:29)i∈I ∆i ,(cid:4)(cid:30)(cid:5)(cid:2)e(D)(cid:3)=(cid:4)(cid:30)hii∈I(cid:5)(cid:4)(cid:30)hi(cid:2)proji(D)(cid:3)ei(cid:2)=(cid:30)i∈Ie(cid:7)giii∈I(cid:4)(cid:4)(cid:30)= e(cid:7)i∈I(cid:2)proji (D)(cid:5)(cid:5)gi(D).(cid:30)(cid:3)(cid:3)=i∈I(cid:1)(cid:5)=(cid:4)i∈Ie(cid:7)iproji(cid:30)(cid:2)(cid:2)(cid:3)(cid:3)hiei(cid:4)(cid:4)(cid:30)proji (D)(cid:5)(cid:5)(cid:5)gi(D)i∈Ii∈IWe now turn to examine diagnostic problem solving in a direct product system. Givena diagnostic problem with the observed findings E and hypothesis H . We may observe38M. Ying / Artificial Intelligence 163 (2005) 1–45them from different profiles i ∈ I . The pieces of information that E and H shine on theprofile i are then represented by the projections proji (E) and proji (H ), respectively. Nowin the factor system Σi , we employ a notion Ri of diagnosis and find a diagnostic solutionRi,proji (H )(proji(E)) with information proji (E) and proji(H ). Thus, we are able to presenta diagnostic solution to the original problem by taking the direct product of these factorsolutions. The following proposition clarify the relation between such a solution and thesolution obtained directly by using a corresponding notion of diagnosis in the whole system(when possible). For example, Proposition 61(1) indicates that if we adopt the notion ofmost general subset diagnosis then the former is stricter than the latter, and they are thesame whenever all factor systems are interaction free and E and H appear as cubes. Notethat some conditions introduced in Definition 31 are needed here. We use condition (∩ ⊆∪) in the case of most specific subset diagnosis and (∩ ⊇ ∩) in the case of most specificsuperset diagnosis.Proposition 61. Let Σi = (∆i, Φi , ei) (i ∈ I ) be a family of diagnostic specifications.(1) If ΠGS(Σi) = (∆i, Φi , Ri) for all i ∈ I , and ΠGS((cid:29)i∈I Σi ) = (i∈I ∆i,i∈I Φi , R),i∈I Φi and for any H ⊆i∈I Ri,proji (H )(proji (E)) if for each i ∈ I , ei(D) (cid:9)= ∅ whenever D (cid:9)=i∈I ∆i ,(cid:29)(cid:29)(cid:29)i∈I Ri,proji (H )(proji(E)) if all Σi (i ∈ I ) are interaction free, andi∈I Ei are cubes (Ei ⊆ Φi and Hi ⊆ ∆i for eachi∈I Hi and E =(cid:29)(cid:29)(cid:29)(cid:29)(cid:29)(cid:29)(cid:29)(2) If ΠGO(Σi ) = (∆i, Φi , Ri ) for all i ∈ I and ΠGO((cid:29)i∈I Σi ) = (i∈I ∆i,i∈I Φi , R),then for any E ⊆(2.1) RH (E) ⊆(2.2) RH (E) =H =(cid:29)i∈I Φi , and for any H ⊆i∈I Ri,proji (H )(proji (E)); andi∈I Ri,proji (H )(proji(E)) if all Σi (i ∈ I ) are interaction free, and(cid:29)i∈I ∆i ,(cid:29)(cid:29)(3) If ΠGI(Σi) = (∆i , Φi, Ri ) for all i ∈ I , and ΠGI((cid:29)i∈I Hi is a cube (Hi ⊆ ∆i for each i ∈ I ).(cid:29)i∈I Σi ) = (i∈I Φi and for any cube H =i∈I ∆i,(cid:29)i∈I Hi ⊆(cid:29)i∈I Φi , R),i∈I ∆i ,then for any cube E =i∈I Ei ⊆(cid:29)(cid:29)(cid:29)then for any E ⊆(1.1) RH (E) ⊆∅;(1.2) RH (E) =H =i ∈ I ).(cid:29)(cid:30)i∈IRi,Hi (Ei) ⊆ RH (E)provided all Σi (i ∈ I ) are interaction free.(cid:29)(4) Suppose that ΠSS(Σi) = (∆i, Φi , Ri) (i ∈ I ), and ΠSS(i∈I Φi , R). If each Σi (i ∈ I ) satisfies the following condition:(cid:29)i∈I Σi ) = ((cid:29)i∈I ∆i,(cid:5)Dt⊆(cid:4)(cid:8)eit ∈T(cid:1)t ∈Tei(Dt ),where all Dt ⊆ ∆i (t ∈ T ) are consistent, then for all cubes E =and H =∆i , we have(cid:29)(cid:29)i∈I Hi ⊆(cid:30)RH (E) ⊆Ri,Hi (Ei ).i∈I(cid:29)i∈I Ei ⊆(cid:29)i∈I ΦiM. Ying / Artificial Intelligence 163 (2005) 1–45(cid:29)i∈I Σi) = (39(cid:29)i∈I ∆i,(cid:29)(5) Suppose that ΠSO(Σi) = (∆i, Φi , Ri ) (i ∈ I ) and ΠSO(i∈I Φi , R). If each Σi (i ∈ I ) satisfies the following condition:where all Dt ⊆ ∆i (t ∈ T ) are consistent, then for any E ⊆H =∆i , it holds that(cid:29)(cid:29)(cid:29)i∈I Φi and for any cube(6) If ΠSI(Σi ) = (∆i, Φi , Ri ) (i ∈ I ), and ΠSI((cid:29)(cid:29)i∈I Σi ) = (for any cube E =i∈I Ei ⊆i∈I Φi and for any cube H =i∈I ∆i,(cid:29)(cid:29)i∈I Φi , R), theni∈I ∆i ,i∈I Hi ⊆(cid:29)(cid:29)(cid:29)(cid:8)t ∈Tei(Dt ) ⊆ ei(cid:4)(cid:8)(cid:5)Dtt ∈Ti∈I Hi ⊆RH (E) ⊆(cid:30)Ri,Hi (projiE).i∈IRH (E) ⊆(cid:30)Ri,Hi (Ei )i∈Iprovided all Σi (i ∈ I ) are interaction free.Proof. We only prove (1); others are similar.(1.1) We write(cid:17)M =H (cid:7) ⊆ H : e(H (cid:7)) =(cid:2)proji(H (cid:7))(cid:3)ei⊆ E(cid:18)(cid:30)i∈Iand(cid:17)(cid:30)N =H(cid:7)i : H(cid:7)i⊆ proji(H ) and ei(H(cid:7)i ) ⊆ proji (E) for all i ∈ I.(cid:18)i∈IThen it is clear that RH (E) =(cid:3)(cid:30)(cid:2)Ri,proji (H )proji (E)i∈I(cid:9)=M, and(cid:30)(cid:6)∪H (cid:7)ii∈I⊆ proji(H ): ei (H (cid:7)i ) ⊆ proji (E)(cid:1)(cid:7)⊇N.Now it suffices to show that for any H (cid:7) ∈ M, there exists K (cid:7) ∈ N with H (cid:7) ⊆ K (cid:7). If H (cid:7) = ∅,it is obvious. We now assume that H (cid:7) (cid:9)= ∅. It holds that proji (H (cid:7)) ⊆ proji (H ). In ad-dition, ei(proji(H (cid:7))) ⊆ proji(E) follows from that e(H (cid:7)) =i∈I ei(proji(H (cid:7))) ⊆ E andej (projj (H (cid:7))) (cid:9)= ∅ for each j ∈ I − {i}. Then H (cid:7) ⊆i∈I Ei and H =i∈I proji(H (cid:7)) ∈ N .i∈I Hi be cubes. Then proji(E) = Ei and proji(H ) =(1.2) Let E =(cid:29)(cid:29)(cid:29)(cid:29)(cid:7) ⊆ Hi: ei(H(cid:9)HNi) ⊆(cid:7)i ) ⊆ Eiei(H (cid:7)(cid:7).i ) ⊆ Ei , and(cid:9)Then ei((cid:9)i∈I RiHi (Ei) =N . Furthermore, it is easy to see that N ⊆ M for cubes E and H . This completes theNi ∈ Ni . This yields∈NiH (cid:7)i(cid:29)Hi . We putNi =(cid:9)(cid:6)proof. (cid:1)Note that in a direct product diagnostic system both the defects and findings are exam-ined from different profiles. However, sometimes we only need to analyze the defects fromdifferent angles, leaving the findings unchanged. This motivates the following definition.40M. Ying / Artificial Intelligence 163 (2005) 1–45Definition 62 (Optimistic and pessimistic merging of specifications). Let Σi = (∆i , Φ, ei )(i ∈ I ) be a family of diagnostic specifications with the same set of findings. Then theiri∈I ∆i, Φ, e+) andoptimistic and pessimistic merging are defined to bei∈I Σi = ((cid:31)(cid:29)(cid:29)(cid:29)i∈I Σi = (i∈I ∆i, Φ, e−), respectively, where for each D ⊆(cid:17) (cid:9)i∈I ∆i ,+e(D) =e−(D) =⊥(cid:11) (cid:16)⊥i∈I ei (proji (D))i∈I ei (proji (D))if ei(proji(D)) (cid:9)= ⊥ for all i ∈ I,otherwise,if ei(proji(D)) (cid:9)= ⊥ for all i ∈ I,otherwise.Comparing the above definition with Definitions 44 and 57, we will find that (optimisticand pessimistic) mergings are mixtures of direct product and (optimistic and pessimistic)fusions. In the operation of merging, the defects take a structure of direct product. Thisreflects the fact that we will examine defects from different profiles. For each profile, thecausal relation between defects and findings is specified separately. Now we have manydifferent way to aggregate these specifications coming from various profiles. The waysused in optimistic and pessimistic mergings are respectively union and intersection whichare just at the two extremes of all the possible ways. Obviously, this idea follows directlyDefinition 44.Example 63. The two operations of merging express two extreme ways of aggregatingknowledge about causal interactions between findings and different profiles of defects.Suppose that ΣA = (∆A, Φ, eA) and ΣB = (∆B , Φ, eB ), where ∆A = {d1, d2, d3}, ∆B ={c1, c2}, Φ = {f1, f2, f3} and eA and eB are given as shown in Tables 11 and 12. And, weassume that ΣA and ΣB depict respectively the causal relation between findings and theprofile A of defects and the profile B of defects. Then ΣA ⊗ ΣB = (∆A × ∆B , Φ, e+) andΣA (cid:16) ΣB = (∆A × ∆B, Φ, e−) represent two different aggregation of ΣA and ΣB , andthey are able to serve as a diagnostic knowledge base of the whole system, where∆A × ∆B =(cid:6)(d1, c1), (d1, c2), (d2, c1), (d2, c2), (d3, c1), (d3, c2)(cid:7).For example, we have(cid:2)(cid:6)+e(d1, c1), (d1, c2), (d3, c2)(cid:7)(cid:3)(cid:2)= eA{d1, d3}(cid:3)(cid:2)∪ eB{c1, c2}(cid:3)= {f1, f2},Table 11Profile ADeA∅∅{d1}{f1}{d2}{f1}{d3}∅{d1, d2}{f1}{d1, d3}{f1, f2}{d2, d3}{f1}{d1, d2, d3}{f1, f2, f3}Table 12Profile BDeB∅∅{c1}{f2}{c2}{f1}{c1, c2}∅ M. Ying / Artificial Intelligence 163 (2005) 1–4541ande−(cid:2)(cid:6)(d1, c1), (d1, c2), (d3, c2)(cid:7)(cid:3)(cid:2)= eA{d1, d3}(cid:3)(cid:2)∩ eB{c1, c2}(cid:3)= ∅.Monotonicity of diagnostic specifications is preserved by both optimistic or pessimisticmergings, but only optimistic merging carries interaction freeness.Proposition 64. Let Σi = (∆i, Φ, ei ) (i ∈ I ) be a family of diagnostic specifications withthe same set of findings.(1) If all Σi (i ∈ I ) are increasing (respectively decreasing), thenare also increasing (respectively decreasing).(2) If all Σi (i ∈ I ) are all interaction free, so is(cid:31)i∈I Σi .(cid:31)i∈I Σi andi∈I ΣiProof. Immediate. (cid:1)We consider the problem of constructing a specification morphism between two opti-mistic (pessimistic) mergings from the morphisms between their component systems. Notethat the operands in an optimistic merging are a family of diagnostic specifications withthe same set of findings. Thus, the finding mappings between the mergings and betweenthe corresponding components should be same. The following proposition shows that thedirect product of defect mapping between the components together with the fixed findingmapping forms a specification morphism between the two optimistic mergings under con-sideration, and it is a morphism between the two pessimistic mergings whenever the fixedfinding mapping is injective.Proposition 65. Let Mi = (gi, h) : Σi = (∆i, Φ, ei ) → Σ (cid:7)iily of specification morphisms. Then(cid:29)(cid:29)i∈I gi , h) is a specification morphism fromi∈I gi , h) is a specification morphism fromi∈I Mi = (i∈I Mi = ((1)(2)(cid:29)(cid:29)vided h is injective.= (∆(cid:7)i, Φ(cid:7), e(cid:7)i) (i ∈ I ) be a fam-(cid:31)(cid:31)i∈I Σi toi∈I Σi toi∈I Σ (cid:7)i∈I Σ (cid:7)i ; andi pro-Proof. Straightforward. (cid:1)We conclude this section with two propositions concerning the notions of diagnosis thatform the Lucas refinement diagnosis in an optimistic or pessimistic merging system. Givena diagnostic problem in an optimistic merging with observed findings E and hypothesis H ,since the finding set is fixed, and the defect set possesses a structure of direct product, wecan analyze the hypothesis H from its different profiles. These profiles of H are then repre-sented by proji(H ), where i is the index in the merging construction. For each componentsystem i, a diagnostic problem with the original observed findings E is still present, butthe new hypothesis proji(H ) is given, and we are able to find a solution to it by employinga notion of diagnosis in this subsystem. Now what interests us is the relation between thediagnostic solution that we hope to find directly in the whole system and the family of di-agnostic solutions in these subsystems. For most general subset diagnosis, it is shown that  42M. Ying / Artificial Intelligence 163 (2005) 1–45the former is included in the direct product of the latter. The same result holds for mostspecific subset diagnosis, most specific superset diagnosis and most specific intersectiondiagnosis if certain global properties of specifications are imposed. On the other hand, thedirect product of solutions to the subproblems is included in the solution of the originalproblem for most general superset diagnosis and most general intersection diagnosis withsome global properties of specifications.Proposition 66. Let Σi = (∆i, Φ, ei ) (i ∈ I ) be a family of diagnostic specifications withthe same set of findings.(1) If ΠGS(Σi) = (∆i, Φ, Ri ) (i ∈ I ), and ΠGS((cid:29)(cid:31)i∈I Σi ) = ((cid:29)i∈I ∆i, Φ, R), then forany E ⊆ Φ and for any H ⊆(1.1) RH (E) ⊆(1.2) RH (E) =free.(cid:29)(cid:29)i∈I ∆i ,(2) If ΠGO(Σi) = (∆i, Φ, Ri ) (i ∈ I ), ΠGO(i∈I Ri,proji (H )(E); andi∈I Ri,proji (H )(E) if H is a cube and all Σi (i ∈ I ) are interaction(cid:31)i∈I Σi) = ((cid:29)i∈I ∆i, Φ, R), and all Σi (i ∈I ) fulfil the following condition:(cid:5)(cid:4)(cid:1)(cid:8)eiDt⊇ei(Dt )t ∈Tt ∈TRi,proji (H )(E) ⊆ RH (E).for all Dt ⊆ ∆t (t ∈ T ), then for each E ⊆ Φ and for each cube H ⊆(cid:29)i∈I ∆i ,(3) If ΠGI(Σi ) = (∆i, Φ, Ri ) (i ∈ I ), ΠGI(i∈I Σi) = (I ) are interaction free, then for any E ⊆ Φ and for any cube H ⊆i∈I ∆i, Φ, R), and all Σi (i ∈i∈I ∆i ,(cid:29)(cid:31)(cid:29)Ri,proji (H )(E) ⊆ RH (E).(4) If ΠSS(Σi) = (∆i , Φ, Ri ) (i ∈ I ), ΠSS(i∈I ∆i, Φ, R), and all Σi(i ∈ I ) satisfy the condition in Proposition 61(4), then for all E ⊆ Φ and cubesH ⊆i∈I Σi) = ((cid:29)(cid:31)(cid:29)i∈I ∆i ,RH (E) ⊆(cid:30)Ri,proji (H )(E).i∈I(5) If ΠSO(Σi ) = (∆i, Φ, Ri ) (i ∈ I ), ΠSO((cid:31)i∈I ∆i, Φ, R), and all Σi(i ∈ I ) fulfil the condition in Proposition 61(5), then for any E ⊆ Φ and cubeH ⊆(cid:29)i∈I Σi) = ((cid:29)i∈I ∆i ,RH (E) ⊆(cid:30)Ri,proji (H )(E).i∈I(6) If ΠSI(Σi) = (∆i, Φ, Ri ) (i ∈ I ), ΠSI((cid:31)(cid:29)i∈I Σi ) = (i∈I ∆i, Φ, R), and all Σi (i ∈(cid:29)I ) are interaction free, then for any E ⊆ Φ and cube H ⊆i∈I ∆i ,(cid:30)RH (E) ⊆Ri,proji (H )(E).i∈I(cid:30)i∈I(cid:30)i∈IM. Ying / Artificial Intelligence 163 (2005) 1–4543Proof. Similar to Proposition 61. (cid:1)For diagnosis in a pessimistic merging system, we have:Proposition 67. Let Σi = (∆i, Φ, ei ) (i ∈ I ) be a family of diagnostic specifications withthe same set of findings.(1) If ΠGS(Σi) = (∆i, Φ, Ri ) (i ∈ I ), and ΠGS((cid:29)any E ⊆ Φ and for any H ⊆i∈I ∆i ,(cid:30)i∈IRi,proji (H )(E) ⊆ RH (E).(2) If ΠGO(Σi ) = (∆i , Φ, Ri ) (i ∈ I ), and ΠGO((cid:29)any E ⊆ Φ and H ⊆(cid:30)i∈I ∆i ,RH (E) ⊆Ri,proji (H )(E),i∈Ii∈I Σi ) = ((cid:29)i∈I ∆i, Φ, R), then fori∈I Σi ) = ((cid:29)i∈I ∆i, Φ, R), then forwith the equality when H is a cube.(3) If ΠSS(Σi) = (∆i, Φ, Ri ) (i ∈ I ), and ΠSS((cid:29)E ⊆ Φ and for any cube H ⊆i∈I ∆i ,(cid:30)RH (E) ⊆Ri,proji (H )(E).i∈Ii∈I Σi) = ((cid:29)i∈I ∆i, Φ, R), then for anyThe same conclusion holds for most specific superset diagnosis.Proof. Similar to Proposition 61. (cid:1)5. ConclusionLucas [13] proposed a set-theoretic framework for diagnostic problem solving in whichthe knowledge base in a diagnostic system is represented by a diagnostic specification.A diagnostic specification is defined to be a mapping from defects to observable findings,and it establishes a causal relation between defects and findings. The solution to a diag-nostic problem is then given by a notion of diagnosis which maps observed findings todefects. A refinement diagnosis consisting of six notions of diagnosis were introduced andcarefully analyzed by Lucas in [13].This paper is a continuation of Lucas [13], and its main aim is to examine the influenceof diagnostic specification transformation on diagnostic strategies and to provide someuseful mathematical tools supporting knowledge reuse in diagnostic systems. The conceptof diagnostic specification morphism is introduced in order to describe diagnostic specifi-cation transformation. The diagnostic strategies, including the six in the Lucas refinementdiagnosis, in the source and target systems of a specification morphism are compared. Atthe same time, we propose several operations of diagnostic specifications that can serve  44M. Ying / Artificial Intelligence 163 (2005) 1–45as mathematical models of knowledge base fusion and merging in diagnostic systems.Some representations of diagnostic methods in composite diagnostic systems constructedby using our proposed operations are presented in terms of the corresponding diagnosticmethods in their subsystems.It is obvious that the diagnostic systems dealt with here and in [13] are not time-varying,and the dimension of time is ignored. In many application domains, however, the systemsto be diagnosed are dynamic, and the assumption that the relation between defects and ob-servations does not depend on time factor is not realistic. In fact, much effort has been madeto accommodate the dimension of time into diagnostic systems have been made in the pre-vious researches. Brusoni et al. [2] defined a spectrum of notions of temporal model-baseddiagnosis. As a problem for further studies, we hope to generalize the Lucas frameworkof diagnosis so that certain temporal phenomena can be taken into account. Furthermore,we need to explore the possibility of adding the time factor into the results obtained in thispaper in order to support knowledge reuse in time-varying diagnostic systems.Uncertainty management is another important problem in diagnostic systems. This isespecially clear in the field of medical diagnosis due to inherent vagueness of human doc-tor thinking. Indeed, uncertainty has been considered in many early medical diagnosticexpert systems such as MYCIN [21]. An important and much more recent work incor-porating uncertainty into diagnosis systems was done by Poole [17] using probabilisticHorn clauses to represent diagnosis knowledge with uncertainty; notions of diagnosis inhis setting were defined by assuming different probabilistic constraints. The Lucas theoryof diagnosis allows modelling particular qualitative approaches to diagnosis, such as thoseexpressed by strong causality or weak causality, but it does not provide us with an explicitmechanism for expressing uncertainty. Nowadays, a dominant method of representing un-certainty in Artificial Intelligence is given by Bayesian networks, or, more generally, byprobability theory. Thus, an interesting problem for further studies is how to introduce asuitable mechanism for coping with uncertainty and vagueness into the Lucas frameworkof diagnosis and how to model knowledge transformation and reuse in diagnostic prob-lem solving when uncertainty involved. In particular, what highly concerns us is how toaccommodate probabilistic information in the formal development presented in this paper.AcknowledgementsThe author is very grateful to Professor Raymond C. Perrault, the Editor in Chief andthe anonymous referees for their invaluable criticisms, comments and suggestions that werevery helpful for improving the presentation of this paper.References[1] J. Barwise, J. Seligman, Information Flow: The Logic of Distributed Systems, Cambridge University Press,Cambridge, 1997.[2] T. Berners-Lee, J. Hendler, O. Lassila, The Semantic Web—a new form of Web content that is meaningfulto computers will unleash a revolution of new possibilities, Scientific American 284 (5) (2001) 34.M. Ying / Artificial Intelligence 163 (2005) 1–4545[3] V. Brusoni, L. Console, P. Terenziani, D. Theseider Dupre, A spectrum of definitions for temporal model-based diagnosis, Artificial Intelligence 102 (1998) 39–79.[4] C.C.K. Chang, H. Garcia-Molina, Conjunctive constraint mapping for data translation, in: 3rd ACM Con-ference on Digital Libraries, Pittsburgh, PA, 1998.[5] S. Chawathe, H. Garcia-Molina, J. Hammer, K. Ireland, Y. Papakonstantinou, J. Ullman, J. Widom, TheTSIMMIS project: integration of heterogeneous information sources, in: IPSJ Conference Tokyo, Japan,1994.[6] W.J. Clancey, Heuristic classification, Artificial Intelligence 27 (1985) 289–350.[7] L. Console, C. Picardi, M. Ribaudo, Process algebras for systems diagnosis, Artificial Intelligence 142(2002) 19–51.[8] L. Console, P. Torasso, A spectrum of logical definitions of model-based diagnosis, Computational Intelli-gence 7 (3) (1991) 133–141.[9] P.T. Cox, T. Pietrzykowski, General diagnosis by abductive inference, in: Proceedings of IEEE Symposiumon Logic Programming, 1987, pp. 183–189.[10] J. de Kleer, A.K. Mackworth, R. Reiter, Characterizing diagnoses and systems, Artificial Intelligence 52(1992) 197–222.[11] R.V. Guha, Contexts: a formalization and some applications, PhD Thesis, Stanford University, 1991.[12] J.E. Larsson, Diagnosis based on explicit means-end models, Artificial Intelligence 80 (1996) 29–93.[13] P.J.F. Lucas, Analysis of notions of diagnosis, Artificial Intelligence 105 (1998) 295–343.[14] S. MacLane, Categories for the Working Mathematicians, Springer, New York, 1971.[15] A.D. Marwick, Knowledge management technology, IBM Syst. J. 40 (2001) 814–830.[16] J. Nagata, Modern General Topology, North-Holland, Amsterdam, 1985.[17] D. Poole, Representing diagnosis knowledge, Ann. Math. Artificial Intelligence 11 (1994) 33–50.[18] J.A. Reggia, D.S. Nau, Y. Wang, Diagnostic expert systems based on a set-covering model, Internat. J. Man-Machine Stud. 19 (1983) 437–460.[19] R. Reiter, A theory of diagnosis from first principles, Artificial Intelligence 32 (1987) 57–95.[20] R. Rymon, Goal-directed diagnosis—a diagnosis reasoning framework for exploratory-corrective domains,Artificial Intelligence 84 (1996) 257–297.[21] E.H. Shortliffe, Computer-Based Medical Consultation: MYCIN, Elsevier, New York, 1976.[22] P.C. Weinstein, P. Birmingham, Creating ontological metadata for digital library content and service, Inter-nat. J. Digital Libraries 2 (1998) 19–36.[23] G. Weiss (Ed.), Multiagent Systems: A Modern Approach to Distributed Artificial Intelligence, MIT Press,Cambridge, MA, 2000.[24] G. Wiederhold, An algebra for ontology composition, in: Proceedings of the 1994 Monterey Workshop onFormal Methods, US Naval Postgraduate School, Monterey, CA, 1994, pp. 56–61.[25] W3C Semantic Web Activity Statement, http://www.w3.org/2001/sw/Activity.