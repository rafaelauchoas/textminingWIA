Artificial Intelligence 75 (1995) 241-295 Artificial Intelligence Robust reasoning: integrating rule-based and similarity-based reasoning Ron Sun* Department of Computer Science, University of Alabama, Tuscaloosa, AL 35487, USA Received February 1993; revised March 1994 Abstract through to account for without to be accounted The paper attempts for common patterns is identified. A principled architecture with dual representations is performed, which unifies these patterns in commonsense reasoning as embodied reasoning inte- in connectionist models. grating rule-based reasoning and similarity-based syn- Reasoning examples are analyzed and a diverse range of patterns that were thesis based on simple rules and similarities individually. A two-level before difficult for connectionist in detail how the common patterns can be generated by this caving mechanism. Finally, it is argued that the brittleness problem of rule-based models can be remedied in a principled way, with the theory proposed here. This work demonstrates rules and similarities can result in more robust reasoning models, and many seemingly disparate patterns of commonsense reasoning are actually different manifestations of the same underlying process and can be generated using the integrated architecture, which captures the underlying process to a large extent. is proposed as a computational mechanism out the theory. It is shown specialized mechanisms that combining 1. Introduction 1.1. Patterns in reasoning Commonsense reasoning reasoning monsense times fallible such commonsense very concept, is one of the main problems in artificial structured yet flexible, and usually is somewhat [ 11,29,61]. It has been extremely difficult intelligence. Com- reliable but some- to capture the to characterize: we cannot define for AI programs knowledge and reasoning in all its power and flexibility. Even commonsense reasoning, is difficult * E-mail: rsun@cs.ua.edu 0004-3702/95/$09.50 SSDIOOO4-3702(94)00028-Y @ I995 Elsevier Science B.V. All rights reserved 242 R. Sun/Art$cial Intelligence 75 (199.5) 241-295 reasoning is. Roughly what commonsense what knowledge at least for the kind of commonsense informal kinds of reasoning oftentimes more critical than accuracy. in everyday is, just as it is hard to define what intelligence speaking, however, corm-nonsense reasoning explored life regarding mundane is, or reasoning can be taken, to issues, where speed is in this work, as referring the study It The study of commonsense reasoning as envisaged here is neither about reasoning reasoning idiosyncratic across a wide range of domains in any particular domain, reasoning patterns; that is, the recurrent, domain-independent that are applicable of a particular domain, nor about deals with commonsense basic forms of reasoning believe of commonsense Noticing ited by the protocols, he argues for alternative commonsense common patterns plicable across domains of them). This standpoint studying commonsense (as we that such forms do exist. ’ ) Allan Collins collected a large number of protocols and the like. the reasoning patterns exhib- found in various for patterns in the existence of believe that are widely ap- (versus domain specific and/or ad hoc processes) logical formulation (thus they actually developed a generalized and the data on which it is based is also the starting point of logic in explaining formalisms [ 8, lo] of traditional tasks. Collins and Michalski in the area of elementary the inadequacy in this work. geography reasoning reasoning [lo] 1.2. Rigor and flexibility reasoning to enable effective on the type of models is how we should handle the the exact prerequisites [ 10,27,35]. inferences agent: and so forth issue in modeling commonsense in reasoning on one hand, and the flexible, approximate, One important rigor and clarity and evidential character of the same process on the other hand. For example, we need clearly-defined structures edge possessed by a cognitive outcome of a given situation, requirements as unsuitable; works can be considered systems with the power of non-linearity from a few crucial shortcomings. For example, because of the complexity of non-linear signal propagation they cannot keep track of their reasoning processes and produce explanations been attempted by e.g. portance of conditions not) ; they do not have enough symbol manipulation for compositionality and we need precise ways of encoding knowl- the precise This imposes some necessary net- they can simulate any rule-based they suffer functions, rule extraction has the im- are necessary or essential, and which are e.g. to fully account [ 171) ; they cannot distinguish (i.e. which conditions for, although of their node activation layers, for their conclusions that are applicable. Simple backpropagation through multiple and systematicity for an action, introspection) in symbolic capabilities, (although (through systems existing [ 161. On the other hand, commonsense reasoning data (such as Collins’s protocols, later) also shows that there is much flexibility detailed agent. Specifically, we need means of evidential combination, with graded this, we also need corresponding to capture In order to be in the reasoning of a cognitive in our model. (fuzzy information flexibility ’ The question of whether independent, recurrent common patterns especially instance-based in commonsense is open reasoning models and rule-based (cf. 111,291). reasoning models It is somewhat related (see e.g. [ 36,421) there exist any domain reasoning, in reasoning, to the debate between R. Sun/Artificial Intelligence 75 (1995) 241-295 243 (to be values [ 18,581. confidence incrementally and capable of accumulating [ 34,611). We should also be able to deal with similarity (In this paper, the word$exibility is used throughout and uncertain) explained; reasoning above aspects; see Section 7.3 for further discussions.) in their prevailing in that only several be handled with separate mechanisms [ lo] regarding psychologically motivated work) ; to model similarity-based reasoning, [ 3,261. Rule-based forms seem too cumbersome isolated kinds of inexactness and analogical to denote these systems to handle various sorts of inexactness can be accounted for and they have to and approaches or analogical and/or complex search procedures too. * to strike an systems may have difficulties with other types of flexibility on both sides, rigor and flexibility, we have places a major constraint they require special structures/mechanisms (cf. [ 111 regarding them carefully-this the requirements on developing logic-based To satisfy Traditional rule-based a balance between adequate theory to account for commonsense reasoning. 1.3. Connectionism versus rule-based reasoning issue that comes to mind A relevant reasoning. versus rule-based of implementing rule-based as well as other types of reasoning. However l Can connectionist models of rule-based in this connection is the debate of connectionism It is quite clear now that connectionist models are capable etc.), in a variety of ways (e.g., [ 1,4,28,44,56], reasoning the following questions reasoning do more in terms of accounting remain: for robust human l Can connectionist soning examples rule-based systems reasoning reasoning models (as questioned reproduce directly in, for example, [ 42])? (such as those in [ lo]) that are difficult in a simple and straightforward way? those commonsense to be accounted rea- for by Clearly, symbolic constructs flexibility, lack certain leads to particularly for a compact, modular rules are efficient computational reasoning. Rules are capable of rigorous descriptions they traditionally sentation and direct, efficient relevant knowledge. However, before, which tion 7.2). There are combined probabilistic [ 34]), models bility and thus deal with the brittleness problem to date can solve two aspects: probabilistic forth. None of them deals with similarity-based repre- of as pointed out severe brittleness (or rigidity; more on this in Sec- for example, in rules factor flexi- to a certain extent, but none of them the problem very well, since each of them only deals with one or the and so fuzzy logic (as in [ 611) does not deal well with cumulative approach (for dealing with vague concepts in nature [61] ), and the certainty These models have certain fuzzy (which are probabilistic (as in [ 341) does not deal well with graded concepts, or analogical reasoning very well. theory, for treating uncertainty (based on the probability reasoning logic representations, and numerical evidence, [6,22]). Connectionist models are inherently massively parallel and have and fault tolerance. Connectionist the advantage of and reasoning being robust, exhibiting generalization * Researchers adopting a logic-based approach does not need reasoning the incorporation systems more realistic and descriptive. of such flexibility to involve such flexibility. The main point of this research, however, [ 1 I, 29 I may argue that a normative study of commonsense is precisely to make efficient manner into reasoning systems, in a computationally 244 R. Sun/Artificial Intelligence 75 (199.5) 241-295 training cases, either individually or collectively to be similarity-based: it usually involves utilizing previous in a statistical way (cf. [2,37] are often said learning similar for various analyses). We will show, in this paper, how rule-based reasoning and similarity-based in connectionist (as embodied to a new theory of robust reasoning. This theory in its simple form can be implemented in a connectionist networks) can be integrated, and that this integration architecture. reasoning leads 1.4. The plan for this paper Based on a detailed is proposed reasoning characteristics bust reasoning commonsense ing essential reasoning, CONSYDERR, tational scheme and distributed are examined in detail ponents, which enables Some discussions robust reasoning rules and logics in CONSYDERR analysis of examples that establishes a unified and data (Section 3). To implement reasoning of rule-based (Section 2), a theory of ro- in combin- framework the theory, an architecture and connectionist for diverse patterns similarity-based is proposed (Section 5). We explore is devised, which utilizes both localist representation with features (Section 4). In this architecture, a dual represen- rules) representation Some examples these two com- (Section 6). follow, especially on the problem of brittleness, which the theory of technical details of addresses (Appendix B) . the interaction between for many difficult patterns (Appendix A) and some experiments (for similarity matching). (Section 7). Appendices the system to account (encoding contain some 2. Some examples Let us look into a set of examples, most of which are protocols simplified. The goal here is not psychological though somewhat computational understanding. (1) The first example shows uncertain, evidential reasoning: they might grow rice in Florida? Q: Do you think A: Yeah. I guess certainly a nice, big, warm, flat area. they could, if there were an adequate [ 8, lo], from Collins data modeling, but a fresh water supply, is a rule in this example: flat, and has an adequate There fresh water supply, the question deduced an uncertain conclusion based on partial knowledge, although a piece of crucial information is big, warm, area. The person answering if a place it is a rice-growing (i.e. the presence of fresh water) is absent. then (2) The second example is as follows: Q: Is the Chaco the cattle country? A: It is like western Texas, so in some sense I guess it’s cattle country. Here because similarity with known knowledge. there is no known knowledge, (3) The third example is: an uncertain conclusion is drawn based on R. Sun/Artificial Intelligence 75 (1995) 241-295 245 Q: Are there roses in England? A: There are a lot of flowers in England. So I guess there are roses. is based on property inheritance. Formally, England HORTICUL- Here the deduction TURE flower; rose IS-A flower; so England HORTICULTURE the inheritance because theory; see [48] ). The conclusion to the contrary there is no information is: (4) The fourth example rose (to use the jargon of is only partially certain and is drawn (i.e. no cancellation of properties). Q: Is that [Llanos] where they grow coffee up there? A: I don’t coffee. The savanna has a rainy season and you can’t count on rain in general coffee]. is used for growing the savanna think trouble is the [for growing This example rainy season, and rainy seasons do not permit coffee growing. shows a chain of rules in reasoning: Llanos is a savanna, savanna has a (5) The fifth example is: in the Andes Mountains? Q: Is Uruguay A: It’s a good guess to say that it’s in the Andes Mountains because a lot of the countries [of South America] are. Here there is no rule stating whether Uruguay most South American Uruguay countries are in the Andes, this default value (although just “inherits” incorrectly). is in the Andes or not. However, since the default is therefore in the Andes. (6) The sixth example is: Q: Can a goose quack? A: No. A goose-well, say it can quack. No. I think beak and everything. But no, it can’t quack. it’s like a duck, but it’s not a duck. It can honk, but to its vocal cords are built differently. They have a independent than one pattern More ducks, may be able to quack. Another pattern built for quacking, they cannot quack. of knowledge is present here. One is based on similarity between geese and that geese is a rule: since geese do not have vocal cords regarding geese, yielding the conclusion (7) The seventh example is: Q: Is Florida moist? A: The temperature too. I think Florida is high there, so the water holding capacity of the air is high is moist. the concepts In this example the conclusion must be graded, facts and rules. involved are not all-or-nothing, but somehow graded, so in correspondence with the confidence values of known (8) The eighth example is: Q: Will high interest A: No. High interest causes low inflation rates cause high inflation rates will cause rates? low money supply growth, which in turn rates. 246 R. Sun/Artificial Intelligence 75 (1995) 241-295 This example shows a chaining of rules: High interest rates will cause low money supply growth, and low money rates, so high interest rates will cause low inflation is: (9) The ninth example supply growth will cause low inflation rates. Q: What kind of vehicles are you going A: For carrying cargo, I have to buy a utility vehicle, but for carrying passengers, I have to buy a passenger vehicle. So I will buy a vehicle that is both a utility and a passenger vehicle. For example, a van. to buy? shows the additive This example utility vehicle, and if carrying passengers, combination vehicle. of the two rules: something ( 10) The tenth example is: interaction of two rules: if carrying buy a passenger vehicle. The result that is both a utility vehicle and a passenger cargo, buy a is the Q: Do women A: Men living living in tropical living in tropical in that [tropical] region have short life expectancy? regions have short life expectancy, so probably women regions have short life expectancy too. This is another case of using similarity because of the lack of direct knowledge. (11) The eleventh example is: Q: Are all South American A: I think South American is in the tropical tropical region, so on and so forth. countries countries in the tropical region? are in the tropical region, Guyana is in the tropical region, because Brazil is in the region, Venezuela the conclusion Although (a form of generalization). superclass subclasses subclasses. is incorrect, Since countries” there this example is no knowledge directly associated with as to whether illustrates bottom-up inheritance the they are in the tropical or not, is drawn based on the knowledge of the “South American are looked at, and a conclusion One can observe l The same patterns are present from these examples that (cf. [ lo] ) : in many different situations (see e.g. Examples 2, 6, and 10). l People are more or less certain about their conclusions depending on their certainty of information (including rules and facts; see e.g. Examples 1 and 7). existing knowledge, there is no matching and some means of existing knowledge individually or the existence of the two processes, l People have some means of applying similarity matching when performing (many examples above indicate intermixed together). A methodological conditions of the relevant holistic process); when in similarity matching, one concept of the other. it is a case of inheritance. are explicitly mentioned features or conditions is mentioned note is in order here: in describing different patterns, we use rules if if none (it is thus suggestive of a and manipulated; we use similarity matching explicitly is a superclass (or subclass) R. Sun/Artificial Intelligence 75 (1995) 241-295 241 3. A theory for accounting for the reasoning patterns There are some important unanswered example, what are the basic patterns to best characterize be used underlying try to answer facts about commonsense the difficulty in producing (tentatively) reasoning. questions in commonsense these patterns? What commonsense about commonsense reasoning? What notions reasoning. For can problem is the most fundamental reasoning as in these data? We will some simple some of these questions. Let us first establish 3.1. Some basic forms 3.1.1. Rules representation is mounting: Smith et al. [42] present eight criteria for a number of reasons. First of all, phenomenological knowledge available, by all accounts, First of all, there is the question of the proper form of knowledge existing, directly-applicable applying Although there are many alternatives best choice as an appropriate or even necessary knowledge, existence of rules in reasoning the existence of rules show that the eight criteria can be satisfied by various data; so the conclusion that rules are an intrinsic part of cognition; Fodor and Pylyshyn guistic and others processes rule-based formance can be better modeled by utilizing Rule-based ibility reasoners. for (such as that in examples 1 and 7). rules seem to be the form for expressing various kinds of for the for results are analyzed which is drawn that lin- and require systematicity which only symbol manipulation [ 351 show that phonological per- rules, at least as a part of a mechanism. 3 some of the rigor and flex- capabilities reasoning that are necessary can provide; Pinker and Prince and symbolic manipulation detailed experimental robust reasoning in commonsense in developing in cognition; [ 161 argue reasoning evidence provide Secondly, examining the examples discussed above, there are clear indications of the a rule with four in the Florida case, there is undoubtedly existence of rules; for example, conditions (rice-growing area). Conversely, there are maybe more than one ways for encoding knowledge earlier at length. (big area, warm area, flat area, and fresh water supply) and one conclusion in Section 2, although some knowledge, all directly applied as discussed in rules rather naturally, all the examples can be captured (computationally) examining In addition, at the computational l Rules are the most common level, the following form of knowledge reasons support the use of rules: in all representation, used widely kinds of AI systems. l It has been convincingly argued that other knowledge representation schemes can be transformed into logic (rule) based schemes [ 7,20,30], l Rules are precise but allow incorporation inference processes edge, and plausible of confidence measures, uncertain knowl- [ 34,611. 3 Some people may not agree with these opinions. 1 will not get into the controversy surrounding these arguments. 248 R. Sun/Artificial Intelligence 75 (1995) 241-295 l Rules ensure modularity struct and manipulate and making existing ones (the detail of this aspect is not addressed l Representation with rules facilitates explanation generation in representation, making easy to con- it easy to incorporate new knowledge and change the representation in this paper). (explaining inferential processes) and improves human comprehensibility in many other ways. Next, back at a phenomenological are evidential, which means a priori, or transcendentally processes deterministic, uncertain. Based on the observations in rule representation: level, we can see that commonsense reasoning that the existing knowledge, or rules, are not inexact, and the following true. Rather, they are empirical, in Section 2, we further conjecture l Concepts or propositions that [ 141. For example, is a fuzzy concept and there is no fixed boundary as to what is warm and in reasoning processes but fuzzy, possibilistic, are often graded, or probabilistic involved the proposition “raining causes flooding” is a probabilistic proposition, We can associate with each of those con- that can be used to facilitate a generic confidence measure is, not all-or-nothing “warm” what is not; similarly, rather cepts and propositions reasoning processes. l As suggested by data than deterministic (e.g. Example 6), different pieces of evidence is, each of them may have more or less impact, depending weighted, that its importance or salience arguments). We need a way of combining different weights, without probabilistic l The evidential reasoning or Dempster-Shafer combination incurring (see Osherson et al. [ 321 for additional from different evidence too much computational calculus [ 34,381). overhead are often on evidence and sources with (such as in two conditions to reach a conclusion, with a confidence process may be cumulative, or in other words, it tends that to “add up” various pieces of evidence from the “sum” of the confidences of the different pieces of evidence. is determined than knowing only Knowing one. For example, is a rice-growing area, if we know all the four conditions, warm, flat, big and fresh water supply, we can make the conclusion with full confidence; when we know only three of the four conditions, we reach the same conclusion with less confidence. A cumulative evidential in a rule results in a larger confidence regarding whether Florida is therefore necessary in rule representation. in the example combination procedure 3.1.2. Similarities indicate in reasoning: The above data also clearly the current context, and come up with some plausible conclusions the need for similarity matching and some form of analogy in situations where there is no directly applicable knowledge (such as in examples 2 and 6), one can find similar concepts, propositions or situations, within based on their can be determined based on the degree of the similarity. The confidence similarity. Phenomenologically, is an process, for the above protocols and examples do not intuitive, holistic and unstructured indicate anything deliberative or analytical. This phenomenon is also recognized by e.g. [43], based on theoretical and Dreyfus and Dreyfus as experimental [ 131, Hinton observations. Computationally, however, similarity can be implemented the comparison process that determines [ 231, and Smolensky in the conclusion similarities R. Sun/Art$cial Intelligence 75 (1995) 241-295 249 [ lo] and thus only one process rules two problems: (rule application) is left. Such an approach creates ( 1) one concept is similar to be added into a system for any reasonably systems the existence of too many rules; it will be difficult and mere associations clear commonsensically. then (2) to many other concepts, and thus too many rules will have this tends to make (to say the least) because of to capture all of these similarities; large domain unwieldy to distinguish strong based on similarities, whereas between rule-governed the distinction reasoning is rather for example, and similarity matching It is evident that rule application in the protocol about geese, the application together; vocal cords is intertwined with the similarity matching with ducks. By combining processes, many it is the interaction patterns see Section 2). Therefore computational model within which the interaction are intrinsically mixed of a rule regarding the two can be made with relative ease. In other words, reasoning and cancellation; and come up with a to study their interaction can be utilized. the two processes these interesting it is important (for example, that creates inheritance, inheritance, interesting bottom-up inferences top-down between that reasoning processes with similarity matching There is evidence suggesting parison of analogous knowledge) (see e.g. [60] ), which should be taken into account rea- soning. This is also the case with rule application, which is oftentimes also parallel and spontaneous (see e.g. [ 13,251 for some arguments). are massively parallel and spontaneous (com- (i.e. automatic) in any theory of commonsense 3.2. A synthesis: the theory of robust reasoning 3.2.1. Some diverse patterns We can summarize the patterns of commonsense reasoning in the examples (in Sec- tion 2) as follows (cf. [45,46] ): l Partial information (e.g., the first example), in which not all relevant information is known but a conclusion l Uncertain or fuzzy information has to be drawn. in which informa- tion is not known exactly and with absolute certainty, but a plausible conclusion has to be drawn based on what is known. (e.g., the first example again), l Similarity matching (e.g., the second example), but different situations are used due to the lack of exact matching of novel input). in which rules describing similar rules (in case (e.g., the ninth example; rule interactions this aspect), for complete of multiple to produce strengthened, weakened, or entirely new results, made from a fragmented see [49] and conditions in which conclusions and completeness resulting l Combinational regarding details rules combine possible by the lack of consistency rule base. l Top-down inheritance in which information regarding superclasses l Bottom-up is brought inheritance garding subclasses the third example), (e.g., to bear on the subclasses. (e.g., is brought the eleventh example), to bear on the superclasses. in which information re- 250 R. SudArtijicial Intelligence 75 (1995) 241-295 Although these patterns seem disparate, a theoretical synthesis below will show their commonalities. 3.2.2. One underlying process To perform a precise theoretical analysis, we need some definitions. Some dejinitions A rule is defined here to be a structure consisting of some conditions and a conclu- sion; a numerical weight is associated with each condition. Whenever conditions are activated (to a degree commensurate with the confidence of the corresponding facts), the activation of the corresponding conclusion can be determined by multiplying the activation values of the conditions by the weights. This computation is commonly used (see [ 40,501) and adopted here for its intuitive appeal and simplicity (the justifications will be discussed in Section 61.1). We will denote a rule by A ---+ B. And if A is activated, the activation of B due to A is denoted as A * (A - B). Similarity can be defined here (a little simplistically) as a measure of the amount of overlap between the corresponding feature sets of the source and target concepts or propositions (taking into consideration the sizes of the source feature set; detailed analyses later). We will denote similarity by A N B. So if A is activated, the activation of B due to A is denoted as A*(A N B), that is, the activation of A times the similarity measure between A and B. (See [ 411 for some psychological evidence and arguments for a similar definition.) The analysis analyze each of them on the basis of rules and similarities. To achieve a synthesis of the patterns identified in Section 3.2.1, we will (1) When we have inexact information, the inexactness can be quantified with a confidence value, and the value can be used in reasoning. Given A-B if A is activated to a degree commensurate with its confidence level, then B=A*(A-B) where A and B represent respective activations, (A --+ B) represents the weight from A to B (i.e. the rule strength, a number), and “*” is multiplication. (2) When we have incomplete information (that is, when we do not have all the requisite conditions to apply a rule), we can still deduce a conclusion, although with less confidence; for the confidence of a conclusion is determined based on the vector multiplication computation (i.e. the inner product, a simple extension of scalar multiplication). Suppose we have rules ABC-D. When given confidence values of A and B with C unknown (zero activation), D is deduced with less confidence than when given full confidence values of all of A. B and C: D = (A B 0) *(ABC + D) R. Sun/Artificial Intelligence 75 (1995) 241-295 251 D) represents a vector of the three weights, and they are where (A B C - applied to the activation values of the conditions of the rule, (A B C), to get the weighted-sum (the inner-product). The similarity matching situation (due to the lack of any exactly matching rule when encountering novel input) can be described as: (3) A N B, B-C and A is activated (i.e. the activation A # 0); that is, we want to know about A (e.g. Chaco), but there is no rule directly applicable beside a similarity with B (e.g. Western-Texas). So we utilize the similarity between A and B, and the knowledge C associated with B (e.g. cattle-country): B=A*(AwB) where A represents the activation of the concept, (A N B) represents the simi- larity between A and B, and “*” is multiplication; so C=B*(B-C)=A*(ANB)*(B-C) (4) where (B --+ C) represents the weight (the rule strength) from B to C. 4 For top-down inheritance, suppose A is a subclass of B, A’s property value is unknown, B has a property value C, and we want to know the corresponding property value of A, that is, 5 A N B, B + C. When A is activated, C will be activated accordingly, i.e. C=A*(A-B)*(B-C). (5) For bottom-up inheritance, suppose B is a superclass of A, B’s property value is unknown, and A has a property value D, and we want to know the corresponding property value of B, that is, 6 B N A, A --) D. When B is activated, D will be activated accordingly, i.e. D=B*(BNA)*(A---+D), 4 Similarity matching is oftentimes context-sensitive; that is, similarity comparisons may have to be in relation to a particular context. See discussions relation in Section 7. 5 The super/sub-class is a special case of the similarity relation. It is stronger than the general case (see [49]). 6 It is generally the case that top-down case (a form of deduction), the bottom-up although inheritance they both can be based on similarity. (a form of induction) is less reliable than the 252 R. Sun/ArtiJicial Intelligence 75 (1995) 241-295 (6) For cancellation of inheritance, suppose A is a superclass (or subclass) of B, A has a property value D, and B has a property value C, then A-B. B - C. A - D. When A is activated, D will be activated more than C. In case of rule interaction, we can describe the situation as (7) A ---+ C, B - D, C N D. When A and B both are activated, something else being (see example 9). strongly the interaction of C and D might result in activated, depending on their mutual similarity The above synthesis of these different patterns provides on one hand l), and on the other hand (in the rigor and the flexibility, reasoning. A proper balance and mixture in Section the sense explained precision which underlies most patterns of commonsense of the two in a theory of commonsense is our main goal as stated in Section 1. reasoning 4. A connectionist architecture Given applications theory. the theoretical synthesis of all the patterns, and similarity matching is needed a unifying mechanism for rule for actually carrying out the proposed 4.1. Connectionist models of reasoning Let us examine some relevant existing models first. 4.1.1. Connectionist rule-based reasoning has made some claims about rule-based they might provide a unifying mechanism There are a number of connectionist models of rule-based interest because Connectionism point of view is that rule-like behavior components, difference between researchers working within point held by many connectionists reasoning reasoning, which are of for. that we are looking behavior and reasoning. One interactions of network there is no fundamental rules and non-rules. The point of view has been rebutted by many [ 16,351). Another view- for direct rule-based is the result of complex or statistical ways, and therefore paradigm advocates structuring networks [ 5 1,521. Let us examine some of these models. in deterministic the “symbolic” (see R. Sun/Artificial Intelligence 75 (1995) 241-295 253 Touretzky and Hinton [56] present the first work in implementing emulate networks. They basically system, with separate modules in connectionist soning rule-based (production) facts; an elaborate pull-out network rules (when rule is to fire. The mechanism The resulting Derthick rea- the structure of a symbolic rules, and to match working memory data against there is no exact match, the best match wins) and to decide which matching executes one rule at a time and there is no backtracking. system. in which system is the equivalent of a simple sequential rule-based system for working memory, is designed rule-based [ 121 presents are carried out a connectionist knowledge in parallel by constraints symbolic representation satisfaction the energy logical formulas, inferences energy. By constructing relations between interpretation not all most of the commonsense Section 2), cannot be accomplished way. In addition, slow, and yet does not guarantee of the inputs. However, not all logical relationships inference modes can be captured in energy reasoning, as shown by the protocols by energy minimization the Boltzmann machine (used for energy minimization) the best results. that captures through minimizing the underlying (or near optimal) between sentences and functions. As a matter of fact, (see in any obvious is extremely and examples processes function in a way this process can produce an optimal Recent work on connectionist models of rule-based reasoning includes [ 1,28,44] ; and can perform they all have a connectionist rigorous are somewhat different. However, none of them deals with similarity matching. See [50] for detailed analyses. that uses local representation ; their internal mechanisms variable binding) (including reasoning network logical Although almost all of these aforementioned in some way, they do not deal with therefore, connectionist inexactness to do more than what a typical symbolic they are unable is capable of, besides parallelism. We need a principled way of integrating rule-based systems are and similarity matching rule-based rule- could on one hand to a discretized and similarity-based in similarity-based components. The integration connectionist networks) interesting sufficiently; system based components add continuity rule-based other hand, it could add structures Section 7.1) to a structureless, precision and directedness (embodied system, so that it can better model continuous (namely rules, as well as variables and bindings; thought processes, and on the see it the rigor, network, giving associationistic connectionist necessary for modeling some cognitive tasks (cf. [ I] ) . 4.1.2. Connectionist case-based reasoning is another Case-based (CBR) reasoning It is claimed (among cases) extensively. (abstract knowledge) is a rule: there approach that “case-based I believe interesting [36] reasoning works”. However, ilarity essence of how human important, rules example, when supply, ciding whether an area is a rice-growing the conclusion of the rule is indecisive, may we apply analogous knowledge existing case-based gests the primary in AI that utilizes sim- is the reasoning that, although cases are cognitive mechanisms. For fresh water area, we only need to apply such a rule in de- there is no such a rule, or In systems, various forms of rules are used, which also sug- should be done in is warm, flat and with enough role of rules. I also believe it can be a rice-growing that similarity matching are also fundamental area; only when if a place reasoning (cases). then 254 R. Sun/Arti$cial Intelligence 75 (1995) 241-295 a massively parallel fashion (see [ 54,601 for similar points) and spontaneously (auto- matically) , without incurring huge computational overhead. Phenomenological analyses also suggest similarity matching is carried out at a lower level, the subconceptual level, and matching is an intuitive, holistic process (as explained before; see [ 131) . Thus, sim- pler, massively parallel methods of matching are preferred in carrying out case-based reasoning. Barnden and Srinivas [5] describe an attempt at utilizing case-based reasoning in connectionist networks. The system has some configuration matrices (CMs), each of which contains a case for short-term processing; a small set of gateway CMs provides the interface between short-term processing and long-term memory; cases in non-gateway CMs compete to have their contents copied into gateway CMs, where it can cause cases similar to it to be retrieved from long-term memory, and some symbol substitutions take place to adapt the cases. It is an interesting idea, though the complex structures, gateways, and copying/substitution mechanisms seem to hamper parallelism. 4.2. A unifying mechanism The above reviewed work, though not directly applicable, does suggest some useful ideas for a computational mechanism. I will outline below a unifying mechanism for carrying out the basic processes of rule-based reasoning and similarity-based reasoning. This mechanism, a connectionist architecture, consists of two levels: the first level, called CL, utilizes local representation, that is, one node for each domain concept; the other level, called CD, is more fine-grained, utilizing distributed representation with fine- grained feature (interpretable or uninterpretable) into which all domain concepts can be decomposed. By dividing the architecture into two levels, we can utilize the interaction between the two representations of different granularity to make the architecture more effective and computationally more efficient. Fig. 1 shows a sketch of the architecture. We will call this architecture CONSYDERR, which stands for a CONnectionist System with Dual representation for Evidential Robust Reasoning. The reason for explicit localist representation in CL is the need to explicitly im- plement rule applications in a connectionist network. We assume that this network carries out reasoning at the conceptual level; so the representation has to be explicit and individuated, in order for the concepts and reasoning processes to be consciously accessible and linguistically expressible, without extra matching networks or decoding networks (which is the case with distributed representations) ; we want explicitness, so that activated concepts can be easily identified, reasoning processes can be traced, and explanations can be generated (as mentioned in Section 1). This leads directly to the idea of local representation: each concept or proposition in a domain is represented by a single node in a network of nodes [ 5 1 ] ; rules are then implemented by links between nodes representing conditions and nodes representing conclusions. With rules being represented by links between nodes, reasoning can be done with activations can be calculated within one or a few nodes, only local computation-rule in place, without the need to perform indexing, retrieval, reorganization and updating of large databases of facts. Although there are various heuristics for reducing search time in large knowledge bases, none of them succeeded significantly. The overhead of R. Sun/Ar@cial Intelligence 75 (1995) 241-295 255 selecting data and moving data around can be avoided by directly connecting those pairs of facts that are related by rules so that only local computation on activations traditional in human commonsense systems. This design also has an advantage cognitively: together for passing advantage over more the speed is necessary. This design thus has a computational can be better matched rule-based reasoning [9]. reasoning by nature is evidential, cumulative, Commonsense activations combination discussed before), which rule encoding graded and continuous and weighted-sum firing) this purpose; for connectionist models and consequently network. This idea will be examined into strict needed. logical conjunctions in CL has to deal with. One possibility and graded (as has been is to use confidence values or certainty values) in rule the operation of typical combination evidential (representing functions (representing thus rule encoding coincides with has an easy implementation and evaluated later (see also [50]); or other complex combinations in a connectionist extensions are also possible when representation is proportional (based on features) to the degree of similarity between decides feature representation two sets of nodes representing a distributed level because of its distributed character; is To carry out similarity matching, thus the needed, which must be at a different that it CD level comes into play. The nature of distributed two is similarity-based: the amount of overlap between these two concepts different concepts in of the links or propositions. On the other hand, the links in CD are the replications (or the two CL (which concepts at the CL level, then we will add a link between each node in the feature set of the first concept and each node in the feature set of the second concept, connection replicating link at CL (having analytical between knowledge (which can network; see [ 131) , be partially captured by a similarity-based although we will not discuss (which can be represented by a localist network) the two feature sets). This corresponds represent they represent) that is, if there is a link between the learning process per se here. to the idea of incorporating distributed connectionist the full cross-product into intuition the original two nodes diffusely rules); For more flexibility, interactions between the operation of the system the two levels have a top-down path and in other is in cycles; and each part is independent into three phases: path separately. Also, a bottom-up words, the interaction of the two levels is not ever-present, to a certain extent. One cycle can be divided settling phase, and the bottom-up phase, in which top-down top-down phase and bottom-up words, the two levels have phasic (and in avoiding types of connectionist thus results the phenomenon structure on which time and space complexity in slow settling. This structure may also be partially streams of thoughts flows only occur during the two-level of multiple interactions networks (see e.g. [ 3 I ] ) . they operate), as in e.g. Hopfield networks and other common and justified cognitively by [ 41, which requires ever-present global connectivity flows only occur during the top-down phase, the the in other utility of cycles as will become clear later on, is the bottom-up phase; [49]. The computational 4.3. A precise description of the mechanism 4.3.1. The equations A set of equations for describing the computation during the three phases is: 256 R. Sun/Artificial Inlelligence 75 (1995) 241-295 Phase I: top-down links enabled Phase II: intra-level links enabled Phase III: bottom-up links enabled Fig. 1. The architecture. The top level is CL and the bottom level is CD. A, B and C are concepts, and the link between A and B represents a rule A -+ B. For example, A = Chaco, B = Cattle-country, and C = Western-Texas. For the top-down phase, &(t + 1) = myA f(A(t)) where A is any node in CL, FA is the set of nodes in CD that correspond represent) A, and f receives activation value; to (i.e. that is, a node in CD the largest node in CL, and chooses from the corresponding the time period. is a monotonic increasing t denotes function; For the settling phase, AA(t+ 1) =a c WJi(t) -PA(t) Axj(t+ 1) =pCWiii(t) -VXj(t) (that represent where Wi, wi are link weights discussed antecedents) at the same level and does a weighted-sum (Y, /3, CL, Y are parameters of changes, and p and u are decay rates. in rules, as later), and Zi, ii are the activation of related facts (conditions or logical from other nodes its own activation. (Y and /J are rates for incrementing the network dynamics: ; that is, in this case, each node receives activations strengths or weights controlling For the bottom-up phase, B(t+ 1) =max(B(t), g(xi(t))) C &U/l where B is any node in CL, FB denotes g is a monotonic increasing function; the set of CD nodes representing B, and that is, a CL node receives and sums up R. Sun/Artificial Intelligence 75 (1995) 241-295 257 activations from its corresponding set of CD nodes, and chooses the result as its activation if it is greater than its original activation (in case there are negative activations, absolute values are used in comparisons). To simplify the matter, in this paper, we set LY = j? = ,U = Y = 1. So, derived from the above equations, the equilibrium state equations for the settling phase are, xi = c Wi * ii where ii’s and ii’s are final converged inputs to the two nodes, respectively; these inputs are from other nodes that are linked to A and Xj; they eventually converge to some constant values, when external inputs are clamped to some nodes in the network and the network is given enough time to settle. The equilibrium equations for this architecture amount to a simple weighted-sum computation.7 Similarly, to simplify the top-down phase equation, we adopt a top-down weight td and a bottom-up weight bu; we set f(A) = tdA * A, so that only a parameter td needs to be determined. To simplify the bottom-up phase equation, we set g(xi) = bus * Xi, where xi E FB; this reduces the function to one parameter bu. So we have: l For the top-down phase, Xi(t + 1) = mEyA tuA *A(t). l For the bottom-up phase, B(t + 1) = max(B(t), C bus *xi(t)). XiEF!J 4.3.2. The parameters We need to specify the following parameters: weights for links between a node in CL and a node in CD (i.e. inter-level links, both top-down and bottom-up), denoted as tdA and buA (for any CL node A), and weights for links between two nodes in CD, denoted as SWAB, where A is the CL node that corresponds to the originating CD node and B is the CL node that corresponds to the receiving CD node. (In contrast, links between two nodes in CL, and their associated weights, are taken as given, which represent rules.) We use the following parameter values (see [49] ; detailed verifications later): td/, = 1, burl = - 1 g(lFBI) ‘Each node in the system can have one or more sites [44], each of which computes the weighted-sum (or any other similar functions whenever needed) of the inputs for one rule. The maximum of the values computed by all the sites is taken to be the activation value of the node. See Appendix A for details. 258 R. Sun/Arti$cial Intelligence 75 (1995) 241-295 where f and g are monotonic increasing functions that are slower than but close to linear functions, and f is much closer to linear functions than g; (FA[ denotes the size of the feature set of A; A is the CL node where the rule link originates, and B is the CL node where the rule link terminates; r is the rule strength between A and B (in CL). The value range of the activation is [ - 1 , 1 ] . The above parameters lead to a similarity measure (which is easily obtained from the above equations) : (A N B) x lFA “FB1 FBI . 4.3.3. Elaborations Applying the above cycle, first some nodes in CL get activated by external inputs the CD nodes (and clamped). Then the top-down phase will activate (and clamp) corresponding to the active CL nodes. In the settling phase, links representing rules related to those activated nodes take effect in both CL and CD. Because of similarities, concepts may have overlapping CD representations, so some of the CD representations will be partially activated if a concept similar to them is activated in CD. Finally in the bottom-up phase, fully or partially activated CD representations will percolate up to activate the corresponding nodes in CL. The result can be read off from CL. The massive parallelism and spontaneity in the above specified architecture are evi- dent: activations are propagated, in a massively parallel and spontaneous fashion, from all pre-link nodes to all post-link nodes; each node receives inputs as soon as it can, and therefore fires as soon as it can, ensuring a maximum degree of parallelism in terms of rule application. For similarity matching, all similar concepts are activated (in their CD representations) immediately and simultaneously once an original concept is activated, and matched automatically with the original one (through top-down and bottom-up flows); thus the architecture is extremely efficient by employing the two-level structure. 5. Analyzing some examples Some examples will help to illustrate the architecture. More extensive experiments can be found in Appendix B. 5.1. The first example Let us look at the following example: Q: Do you think they might grow rice in Florida? A: Yeah. I guess they could, if there were an adequate fresh water supply, certainly a nice, big, warm, flat area. The rule used is: big-area warm-area $at-area fresh-water-supply -+ rice-growing-area. R. SudArtijcial Intelligence 75 (1995) 241-295 259 including implications, “warm-area”, in the respective and “rice-growing-area”. “flat-area”, “ fresh-water-supply”, The by links between nodes. The weights on the links reflect degrees of the This can be handled by CONSYDERR: Each node in CL represents a concept, “big-area”, rules are represented of confidence implications. The reasoning process in these are activated (“rice- facts), then growing-area”) the activation, calculated with weighted-sum, will be less than one, but still greater than zero. Therefore we conclude are as follows: In CL, as well as positiveness/negativeness is as follows: First three out of the four conditions to the node representing that node. Because of one missing condition, that it might be a rice-growing confidence the conclusion area. The equilibrium to certain degrees the corresponding their activation state equations and activate they send (which reflect E = A * WAE + B * WBE + C * WCE + D * WDE where A = big-area, B = warm-area, C = flat-area, D = fresh-water-supply, and E = rice-growing-area; w’s are the rule weights. In CD, Overall, 5.2. The second example Another example is as follows: Q: Is the Chaco the cattle country? A: It is like western Texas, so in some sense I guess it’s cattle country. Here, because there is no direct knowledge drawn based on similarity. The knowledge regarding Chaco, an uncertain conclusion is expressed in a rule: is Western-Texas -----f cattle-country represented country”, and the link between in CL by the two nodes, one for “Western-Texas” and the other for “cattle- the two nodes. The similarity between the two areas Chaco N Western-Texas through feature overlapping is implemented in CD. The reasoning process replicated vated; in the top-down phase the CD representation shared features, proportional the CD representation to the similarity measure; is as follows: in CD. And first the node for Chaco the CL links are diffusely is acti- of Chaco is activated and because of to a degree is activated partially of Western-Texas then in the settling phase, the links representing 260 R. SudArtijcial Intelligence 75 (1995) 241-295 (3) (4) Fig. (2) 2. The reasoning process for protocol 2. Black circles represent activated nodes. ( 1) Receiving Top-down, (3) Settling (rule application), and (4) Bottom-up. inputs, rules take effect in CD, so the CD representation finally percolates up to activate the node representing in the bottom-up phase, the partially activated CD representation of cattle-country cattle-country in CL. See Fig. 2. is partially activated; of cattle-country The equation (combining CL and CD) is as follows: where A stands for Chaco, B for Western-Texas, and C for cattle-country. R. SudArtiJcial Intelligence 75 (1995) 241-295 261 5.3. The third example The following example involves and similarity matching. application inheritance, handled by a combination of both rule Q: Are there roses in England? A: There are a lot of flowers in England. So I guess there are roses. It can be described by England - Jlower, flower N rose and we have flower > rose and, in turn, Fpower c F,,,. The same way as before, can be implemented interaction. See Fig. 3 for details of the reasoning process. Overall, CONSYDERR successfully with inheritance in CONSYDERR with the two-level dual representation treatments of inheritance). for complete (see [48] this and their deals 5.4. A further point reasoning network contains the CONSYDERR In the above examples, irrelevant nodes and links. How do we find the right in this myriad? The above discussion is spontaneous, a large number of rel- for links and nodes evant and is mas- certain sively parallel and reasoning from moment to moment a particular path to pursue and performing backtracking when reaching dead end are no longer existent. Because of the massive parallelism in the architecture, we reasoning 8 in a parallel fashion efficiently, without can perform simple forward-chaining the need for backtracking the need for the more difficult backward-chaining as some other reasoning neously See Appendix B for further examples. [ 211). The results will be activated sponta- (along with other and without systems do (cf. the activation of initial conditions so the problems of selecting shows that the system information). following 6. Evaluations 6.1. Some preliminary evaluations We will first evaluate the basic representational forms of CONSYDERR. 6. I. 1. Rule encoding We will briefly examine the rule encoding scheme used in CONSYDERR (that is, FEL, or Fuzzy Evidential Logic). Facts and rules are basic elements in this scheme. A fact (an atom or its negation) is represented by a node having a value between -1 and 1 (continuously), which is * Goal components can be added to rules, so that reasoning will he more “goal-directed” (see [ 531 for details). Other devices of this sort are also possible. 262 R. Sun/Arti$cial Intelligence 75 (1995) 241-295 (3) (4) Fig. 3. The reasoning process (2) Top-down, (3) Settling for protocol 3. Black circles represent activated nodes. and (4) Bottom-up. (rule application), ( 1) Receiving inputs, A rule side (RHS) , which consists of one fact (the conclusion); side (LHS) , which consists of one or more facts (conditions), is related is a structure composed of two and a it is encoded by to the RHS (as specified before). When the fact in RHS can be assigned a value according (possibly a generic confidence measure of the fact [49,53]. The value of an atom to the value of its negation by A = -(-A). parts: a left-hand right-hand having one link from each fact in the LHS facts in LHS get assigned values, to a weighting thresholded) operation, where each weight fact. When corresponding its value, which means no information can continue despite forms a network its truth, so that reasoning together if it maps onto (a CL or a CD). A rule set is said to be hierarchical, of the a zero is assumed as is the weighted-sum the relative information. A set of such rules connected the value of a fact in LHS is unknown, form of which represent the simplest the missing importance regarding available scheme, K. Sun/Artijiciul Intelligence 75 (1995) 241-295 263 a feedforward network. To evaluate this scheme, we can show that, as a special case, this rule encoding is positive, it is sound and complete with respect logic [47]. Horn clause logic is a logic in which all scheme can implement Horn clause formulas are in the forms of P or PI P2. . . P, -+ Q, where P’s and Q are propositions. We can specify a special case of FEL, in which values associated with facts are binary, total weights of each rule sum to 1, and all thresholds are set each weight to 1. Then logic (that is, the two to Horn clause to each other). The basic idea is simple: we make the threshold of every are equivalent to each fact in the LHS of a rule that equals 1 rule to be 1, and assign divided by the number of facts in the LHS. Thus the fact in RHS of a rule is activated if and only fully. The activation of RHS is either one or zero. So whatever in FEL is true in corresponding Horn clause in this case.) The details are in Appendix A. (Therefore, LHS of an FEL rule is a logical conjunction if all of the facts in the LHS of the rule is activated logic, and vice versa. the same weight is activated To further ascertain logic-Shoham’s modal handle Shoham’s accounting its logical capability, we can show Causal Theory [39] logic as a special case, but also serve as an extension that FEL can simulate a (see Appendix A). FEL can not only to it for better for commonsense causal knowledge (see [ 501) 6.1.2. Similarity measures Similarity matching has the following characteristics (for general discussions of sim- ilarity measures, see [ 33,54,57] ): l The degree of similarity from concept A to concept B (A N B) 9 must depend on feature sets, when everything the amount of overlapping else is equal. For example, is river-valley, lowland, matches B better than A’ matches B. of the two corresponding suppose A is river-valley, tropical area, and B is temperate lowland, temperate area, A’ lowland; obviously A l The degree of similarity from concept A to concept B must depend on the size else is equal, because a larger feature set of the feature set of B, when everything of B means those of A. For example, suppose B is temperate plain and A is temperate area; A matches B quite well. Suppose B’ is temperate prairie plain; A matches B’ less well. there are a lot other features in B that do not match l The size of the feature set of A is not important A to B. For example, further suppose A’ is temperate than the match from A’ to B, because one extra feature properties more or less true for A. What not what does not get matched. from suppose B is temperate plain and A is temperate area, and rainy area; the match from A to B is no less strong in A does not make B’s in A, is what gets matched in determining the similarity is important Here similarity refers specifically to “reasoning based on similarity matching”. These above three considerations lead to the following formula: ’ Here similarity from A to B means that, when there is no direct knowledge about A available, then we will go to B, which is similar to A, to find plausible but potentially fallible answers. 264 R. SudArtijicial Intelligence 75 (1995) 241-295 (A rv BJ = fl(IFA n FBI> f2(1F~I) where f 1 and f2 can be any monotonic increasing functions, including identity functions. Therefore, the similarity measure we used in CONSYDERR is a special case of it (cf. [411): Another consideration is whether similarity should be transitive, counter-transitive, or neither: that is, if A is similar to B and B is similar to C, should A be similar to C? There are two possibilities: (1) There is something in common to all three A, B and C. In this case, A, B and C are pair-wise similar. So A is similar to C. (2) There is something in common between A and B and something else in common between B and C. In this case, A is similar to B and B is similar to C, but A is nut similar to C. Therefore, similarity should not be made to be either transitive or counter- (see [57]). The similarity matching in CONSYDERR transitive in implementation fits the criterion, since it involves only one top-down/bottom-up cycle (and thus one similarity matching) at a time. Similarly, since A N B is a numerical measure, which is not necessarily commutative, i.e. A N B j B N A, similarity measures should not be made symmetric [ 571. lo Again, the si milarity measure in CONSYDERR as shown above fits the criterion. 6.2. Some other considerations We will identify some considerations necessary for further evaluations. 6.2.1. Mixed rules and similarities We need to deal with mixed rule application and similarity matching situations. For example, in one case, suppose A N B, B - C; we want to make sure that if A is activated, then the activation of B is A * (A N B) , and the activation of C is A * (A N B) * (B --+ C). One instance of this is the following: Western Texas is similar to Chaco, Chaco is a cattle country, so Western Texas is probably a cattle country (this is similar to case-based reasoning in a way). Other cases include: l A-B,B-C; l A--+B,BNC,C-+D; .A-+B,B-C,C-D; l A--+B,B--+C,C-D; and other various combinations. In all of these cases, we want an intuitively correct result analogous to the first case. These cases will be discussed in the following subsections. to It should be noted above considerations including however, generic generic. that there are generalized is really no context-free, universally similarity measures. The from the examples and are suitable for some large classes of problems, correct. There are, to make it to, but are not claimed [57] that can be incorporated into the architecture to be universally applicable all the tasks we apply the measure forms of similarity measures R. Sun/Art@cial Intelligence 75 (1995) 241-295 265 Color Color royal elephant n white Fig. 4. Inheritance graph. 6.2.2. Inheritance scenarios We need to deal with inheritance and cancellation identified earlier, which is an impor- tant aspect of commonsense reasoning earlier. The reason for giving special consideration to this aspect, which seems to be just a mixture of rule application and similarity match- ing, is that inheritance and cancellation involves competition of mutually conflicting concepts (i.e. property values), which gives rise to some subtle requirements regarding system parameters (for general discussions of inheritance, see [55] ). The inheritance problem can be formulated as inheritance of properties, that is, we express an inheritance problem in an “inheritance graph”, which is a directed acyclic graph in which nodes represent concepts and two types of links, is-a and has-property- value, are used to connect pairs of nodes. See Fig. 4 for an example. This is slightly different from the problem formulation in [ 551 (for details, see [ 481). This “inheritance graph” will be expressed as rules and similarity (and eventually transformed into the CONSYDERR representation), to solve the problem in CONSYDERR. For example, the situation in Fig. 4 can be expressed as rules elephant - color-gray, royal-elephant - color-white and similarity royal-elephant N elephant, is-a links (such as in “royal elephants are elephants”) are implemented implicitly through the containment relations between the corresponding feature sets of the two that is, the feature set of “royal elephant” is a superset of concepts or propositions; the feature set of “elephant”, because “elephant” is a more general concept and hence has less features (less specificity) associated with it; “royal elephant” is a subclass of “elephant” and hence contain all the features of “elephant” plus some others that are unique to it. The other type of links (has-property-value) are implemented explicitly as rules as shown above, in which LHS of a rule is a concept node and RHS is a color-gray). (We treat a property-value property-value pair (for example, elephant - pair as a concept in CONSYDERR.) 266 R. SudArrijicial Intelligence 75 (1995) 241-295 Fig. 5. Inheritance case I. The interrelation of the feature sets in CD. , I Fig. 6. Inheritance case II. The interrelation of the feature sets in CD. Let A be a superclass of B, therefore the feature set of A is a subset of that of B (i.e. FA c FB). Suppose A has a property value C, and B has no specified property value. If B is activated, to a certain extent, from (top-down) inheritance property value D and A has no specified property value; activated a subset of A, to A. (remember A is a superclass of B) . On the other hand, supposing B has a if A is activated, D should be from B, inheritance) then C should be activated too, from the percolation of property values (bottom-up What is most difficult to deal with is the cancellation inheritance. As in Fig. 5, A has a property value C and B has a property value D # C. If A is activated, C should win over D (remember the feature set of A is a subset of that of B). Conversely, as in Fig. 6, A has a property value C and B has a property value D # C. If B is activated, D should win over C. These in the following cases of inheritance will be handled that A is a superclass of B, and therefore of property subsections. 6.3. Essential properties-explaining the patterns We are now ready seven patterns here). identified to see how CONSYDERR the in Section 3.2.2 (though only simple cases will be handled the requirement regarding fulfill information to a degree commensurate with its inexactness. Suppose for a concept A, a node representing the concept can there is ( 1) Given inexact be partially activated, a rule in the form of A+B R. Sun/Artificial intelligence 75 (1995) 241-295 267 and the weight on the link between A and B is WAn. Due to the rule application, the activation of B, according to the CONSYDERR equations, is as follows: From CD B=A*----* (FBI IFAI * WAB ~(IFBI) f(lFA(> . From CL B=A*WAB. So overall, B M A * WAB i.e. B = A * (A - B). When there are multiple conditions in the rule, such as ABC-D with weights WAD, WBD, and wCD, the activation of the conclusion D is D=A*WAD+B*W~D+D*WCD. Or D=(ABC)*(ABC-D) given the partial activations (inexact and uncertain information) of A, B, and C. (2) When the given information is incomplete, i.e. not all conditions in a rule are known, the above weighted-sum computation can still be applied to reach a (weaker) conclusion. Suppose ABC-D with weights WAD, WBD, and wCD, and B and C are known (e.g. B = 1 and C = 1 ), but A is unknown (A = 0). The conclusion D can still be reached, according to the CONSYDERR equations: D=A*wAD+B*wBD+D*wcD =wBD*B+wCD*D =wBD +wCD i.e. D=(ABC)*(ABC-D) =(Ol l)*(ABC-D). The situation in which the known conditions (such as B and C above) are inexact can be handled similarly, combining this method with the previous. 268 R. Sun/Art@cial Intelligence 75 (1995) 241-295 (3) When there is no rule applicable (in case of novel input), similarity matching is utilized to reach a conclusion. Given A, and the knowledge A N B, B - C, that is, A and B share features (in CD) and there is a rule from B to C (in CL and CD), we apply the equations: from CD B=A* IFAnFBI dlFAf) c = B* & *wBC, B that is, c M B * wBC ~A*SAB*WBC. so C = A * (A - B) * (B - C). Other cases can be handled similarly, such as when A is similar to a number of other concepts and those concepts are linked to many other concepts via rules (handled by straightforward extensions of the above method), or when the rules used have a number of other (unknown) conditions (handled by incorporating the previous method). (4) Top-down inheritance can be described as A N B. B - C, in which A is a subclass of B (so FA > FE), and C is a property-value (such as color-red) of B. It is obvious that this is a special case of point 3, so it can be handled exactly the same way. We should note, however, in this case SAB = IFA nFBI IFEI diFB\) =g((FBI)+ because FA > FB. And if we assume WBC = 1 (the same for all property-value rules), the resulting activation of C (representing the confidence that A has property-value C) is: so C=A*(AwB)*(B-C)=A. R. Sun/Artificial Intelligence 75 (1995) 241-295 269 (5) The bottom-up inheritance is similar: B -A, A - D, in which B is a superclass of A (so FS C FA), and D is a property-value also a special case of Case 3, so it can be handled of A. This is the same way. In this case, we have SBA = IFB~-‘FA~ Mu < l &T(iFAl) lFAi ’ because FB c FA. If we assume WAD = 1 (the same for all property-value rules), D M A * WAD M B * SBA * WAD < B, which represents is to say, the partial confidence based on the evidence from the subclass B. That D=B*(B--)*(A-D)<B. (6) Cancellation suppose A is a subclass of B, A has a property value D, and B has a property value C # D (assuming C and D have one feature node each). Then is as follows: of top-down inheritance A N B, B - C, A - D. When A is activated, D should be activated more than C to cancel the inherited property- value C. According in Section 4.1, assuming WAD to the equations = 1, = WBC AAD D=A * IFA(----- f(\FAi> =A*JFAI, .f(lF~l) C=A*IFA~IFBI~ f (IFA) =A*wllC*--- f(lF~l> =A*& B 270 R. Sun/Artificial Intelligence 75 (1995) 241-295 where FA > FB and (FA\ > \FB\. S ince f is a monotonic increasing function, slower than linear, D > C (by a small margin). (7) Cancellation of bottom-up inheritance is similar: suppose B is a superclass of A, B has a property value C, and A has a property value D f C. Then B-A, A - D, B - C. When B is activated, C should be activated more strongly than D. According to the equations in Section 4.1, assuming again WAD = wsc = 1, C=B*IF&= f(lFd) =B*&, B =B*WAD * =B*wAD*--- IFB n FAI f(iFAl) IFBI f(hI> =B*& A where FB c FA and ) FB 1 < I FAI, and f is slower than but close to linear. So we have C> D. (8) Rule interaction can be described as A - C, B - D, C N D. When A and B both are activated, the interaction of C and D might result in something else being strongly activated. Assuming FE = Fc U FD and Fc n FL, = 8, E = IFE - Fol---- 1 1 g( IFEI) C + IFd---- s(lFd> D’ If the activations C = D. E=D(IFE- FDI + IF&& R. Sun/Art@ial Intelligence 75 (1995) 241-295 271 1 =D* ~FE[ *g(l. So we have activations E > D and E > C. Other cases can be dealt with similarly, such ~sFE=F~~F~o~FE=Fc-FD. 6.4. Some further properties 64.1. More on mixed rules and similarities As mentioned (1) For A - equations, in Section 6.2, the following cases should also be dealt with correctly: to the CONSYDERR B, B N C, if A is activated, then according C=xAx FA fcFA) FsnFc c 1 =A * wAE * I IFAI dFC) /FE n Fcl g(Fc) that is, C = A * (A - B) * (B N C). (2) For A - B, B --+ C, if A is activated, then according to the CONSYDERR equations, that is, C=A*(A---+B)*(B-C). (3) For A - B, B --+ C, C - D, if A is activated, then according to the CONSYDERR equations, that is, D=A*(A-B)*(B---+C)*(C-+D). (4) For A N B, B - C, C --+ D, if A is activated, then R. Sun/Artificial Intelligence A (1995) 241-295 M A * SAB * WBC * WCD 272 D= that is, D=A*(A-B)*(B-C)*(C-D). (5) For A - B, B N C, C ---+ D, if A is activated, then X A * WAB * SBC * WCD that is, (6) For A --+ B, B - C, C N D, if A is activated, then z A * WAB * WBC * SCD that is. D=A*(A-B)*(B-C)*(CwD). (7) For A N B, B - C, C N D, if A is activated, then M A * SAB * WBC * SCD that is, D=A*(A-B)*(B-C)*(C-D). In all of the above cases, the network dynamics for each node involved, according cation requirements. Although we discussed multiple premises are straightforward to the appropriate rules with only a single premise, extensions of these cases (see [ 501) . results in the correct node activation similarity measures and rule appli- rules with It is easy to notice larity relations. This is because we do not want similarity before, CONSYDERR matching. there is no case where there are two or more consecutive simi- to propagate. As mentioned this requirement by allowing one cycle only in similarity satisfies R. Sun/Art$cial Intelligence 75 (1995) 241-295 273 Fig. 7. Inheritance case III. 6.4.2. More on inheritance There are the following (from two cases of inheritance [ 551) that are more compli- cated but need to be handled correctly. As before, assume A is a superclass of B, and thus FA c Fs. Suppose A has a property value C and B has a property value D that therefore FD > Fc) . If A is activated, C should win over D. is a subclass of C (and (say, the South), B is a subarea of A See Fig. 7. For example, A is a particular area. So if (say, the Southeast), C is a fruit-growing A is given, C should have a higher confidence value than D. region area, and D is an orange-growing In CONSYDERR, when A is activated, 1 * IFA/ * ~ f(lF~i) *A and D=A*(- <A IFCI lo%I) + IFo - Fcl lF~l g(lbI) fW’~l) ) In the other case, as shown because lF~l/g(lF~l) < 1, IFD - Fcl/g(IFDl) a property value D that is a subclass of C (and D should win over C. For example, A is a particular subarea of A (say, the Southeast), C is a fruit-growing area. So if B is given, D should have a higher confidence value than C. < 1, and lF~l/f<lF~l> < 1. So C > D. in Fig. 8, suppose A has a property value C and B has therefore FD > Fc). If B is activated, region area, and D is an orange-growing (say, the South), B is a In CONSYDERR, C = IFc( * ___ * IFB( *B * - 1 dlFcl) 1 f(hI> and D = /FD[ * ___ *IFsl*B*-. 1 g(lFDI) 1 f(lFBI) So we have D > C (since IFDl > IFcl). 214 R. Sun/Artificial Intelligence 75 (1995) 241-295 6.5. Are the two levels necessary? Fig. 8. Inheritance case IV. One objection all of its work levels interaction Specifically, in isolation, between architecture to the CONSYDERR is also done by CD. While this objection misses that the synergy the two levels can only be generated by having is that CL is not really needed, since the two from the levels. this is correct when comparing resulting two separate the point the existence of CL serves the following purposes: and bottom-up top-down role in ensuring correct cancellation l Inheritance is handled through up weight bu plays a crucial discussions able to handle detailed derivations; l In order to extract conceptual and see Appendix B). Without the two-level inheritance with such an efficiency (in constant see Appendix B for experiments). information from the distributed flows, and the bottom- (see earlier structure, we will not be for time; see [48] CD, we need the correspondence represented; the CL/CD to understand/explain l In order structure between a concept and its features is an economical way of accomplishing representation an explicit rule structures, structures as in CL is necessary, since the corresponding is distributed important and thus does not help with the comprehensibility for conceptual-level reasoning). rule representation of rules (which representation in to be explicitly this. of rule in CD is 7. Discussions 7.1. Some further extensions A simple extension is adding a thresholding mechanism the same as in the intra-level case, so that a CD node (or a CL node) the top-down received exceed a threshold. This serves to make the inter-level if the top-down (or bottom-up) phase, only (or bottom-up) interaction non-linear. to the inter-level interaction, is activated during activations Note that the similarity measure used can be easily generalized by adding different involved that and/or in Section 4.3.1; links and the nodes this can be useful to the inter-level thresholds situations similarity measures of features). (e.g. non-linear level of “hidden” nodes can also be added to provide more complex for more complex combinations functions, weights, as described require more complex An intermediate mapping capabilities. R. Sun/Artificial Intelligence 75 (1995) 241-295 275 For further expanding the expressive and reasoning power of the architecture, we add variable binding capabilities (cf. [ 16,351) . Adding variables to connectionist models is a technically complicated endeavor and many issues need to be addressed; for example, how are variables represented? how are bindings passed along? what is the complexity of the solution? what is the logical capability of the solution mechanism? These issues have already been addressed in relation to CONSYDERR and the solution is fully covered in a set of papers (see [44,47,49,53] ; cf. [ 1,281 for other solutions to the variable binding problem). The problem requires extensive technical treatments that have only marginal relevance to the theme of the present paper; because of the fact that a variety of solutions exist, this problem is no longer of high importance; considering these factors and the space limitation, I will not repeat the solution to the variable binding problem here. Yet another issue is the mechanism for taking contexts into consideration [4.5], espe- cially for context-sensitive relationships involving rules and similarities (such as Chaco N Western-Texas in terms of cattle-raising; cf. [ lo] ). The mechanism in CONSYDERR [49] is a feedforward network that takes current contexts (such as a query as in the earlier examples) as input and produces two types of modulation signals for modulat- ing feature nodes: enable and disable. The disabled feature nodes will have activations equal to 0 and therefore will not participate in similarity matching. The actual disabling occurs at the inter-level links connecting these feature nodes to their corresponding concept nodes; so the inter-level weights are adjusted accordingly, e.g. from l/g( IFA]) to I /g( IF;/), where Fi is a reduced feature set with some feature nodes disabled. In this way, similarity measures take contexts into account and produce more accurate results, e.g. comparing Chaco and Western-Texas with respect to features relevant to cattle-raising. See Fig. 9 (the full explanation is in [49] ). This feedforward network can be structured in a way similar to CL; that is, each link can represent some context rules, which decide if a feature is relevant in a given context. More complex structures, such as a backpropagation network, are also permissible. ‘i 7.2. Brittleness and robustness The term brittleness has been around for quite a while for describing some funda- mental flaws of existing rule-based approaches [ 24,591. Though different authors have ascribed somewhat different meanings to the word, basically, “brittleness” (the opposite of robustness) suggests being easily broken: the slightest deviation in inputs from what is exactly known by a system can cause a complete breakdown of the system. Specifi- cally, it can be qualified as the inability of a system to deal, in a systematic way within a unified framework, with some important aspects in reasoning, including the following aspects (which have been identified for a long time) : 0 partial information, 0 uncertain or fuzzy information, ” The outstanding contexts, and more elaborate reasonable issues time and space constraints. in this regard interactions include learning of context of contexts and reasoning, [49], hierarchical rules of all of which must be handled within structuring 276 R. Sun/Artificial Intelligence 75 (1995) 241-295 Fig. 9. The overall architecture with feature and result selections. similarity matching, rule interactions, generalization, inheritance percolation contexts and learning new rules changing They overlap the 7 patterns substantially with exemplified by the 11 examples. (i.e. top-down (i.e. bottom-up inheritance), inheritance), identified in Section 3.2.1, which are (e.g. rule-based and actions in various domains: The brittleness problem system cannot proceed without in such a system. To circumvent it shows up in all kinds of reasoning is pervasive. With the exception of some extremely specialized for example, specified there exist different values, not just missing values), narrow domains, the brittleness problem exists in decision-making: when there are no precisely preconditions a typical situation or without additional mechanisms tioned flexibility approach can be taken and decisions conditions is not always possible, especially in diagnosis, domains. The difficulty of conventional commonsense it is paramount reasoning. (cf. [ 211)) due to the lack of the aforemen- this brittleness problem, a brute force of into the system, which for large systems. The brittleness problem exists also in real world planning, and in control with expert systems, and many other in dealing with all of these the range and importance of the problem, so in order to develop systems capable of robust in such a system: every possible scenario of combinations is analyzed beforehand reasoning domains and structured this problem, information to address rule-based regarding reasoning signifies further the The idea of robust reasoning is meant in domains, and both the flexibility and the rigor associated with it; or more free from the problem of brittleness. The theory of the kind of reasoning to be reasoning that occurs to capture it is meant is able to deal with the requisite fuzzy, partial, or incomplete flexibility: or inexact matches between knowledge from known similarity-based instances, in store and and reasoning, inexact knowledge at hand, generalization commonsense precisely, robust reasoning information, situations R. Sun/Art$cial Intelligence 75 (1995) 241-295 217 issue (quite different from the representational the study of their interaction would be interesting, other kinds of flexibility. Among all the aspects of the brittleness problem, rules is a separate so dealt with. (Although the scope of this paper to cover them all.) While still look like a disparate set of problems, as rule-based provides a promising The significance lies in the fact that, based on this theory, a connectionist reasoning coupled with similarity-based learning new issues) and should be it is beyond aspects of the problem theory theory in the present reasoning. Thus the present towards robust reasoning. they are all characterized the remaining avenue architecture (to a certain extent) and solve two-level structure can deal with brittleness in a massively parallel manner; notably, the task is accomplished within a and reasoning problems effectively and computationally with a simple a certain range of representation efficiently unified framework. I2 7.3. The connection with Collins and Michalski’s analysis Collins and Michalski [ lo] present an interesting analysis of patterns in commonsense reasoning. connections I will not attempt to discuss the theory completely, except to point out some to this work. The six categories in [ lo] are of particular interest: from mutual implication, from mutual dependence, transformation, transformation, ( 1) derivation (2) derivation (3) generalization-based specialization-based (4) (5) similarity-based (6) dissimilarity-based transformation, transformation. (computationally) to the present analysis, According have little difference by rule application before) ; the rest of the categories specialization similarity matching. Dis-similarity they can be reduced as follows: the first two categories and both can, to a large extent, be dealt with (with contextual effects handled by the context module as discussed that and is, generalization they can be dealt with by are special cases of similarity, is not covered here. are similarity-related, based inference and therefore conditional In Collins and Michalski’s theory, the confidence of the conclusions in the domain of the descriptor, dominance of a subset in a set, multiplicity reached depends on a number of parameters: likelihood, degree of certainty, degree of typical- ity of a subset within a set, degree of similarity of one set to another, frequency of the referent of the referent, and finally, multiplicity a smaller set of parameters can be identified: two parameters can subsume first two, conditional weights rule weights and similarity measures. to the present analysis, rule weights and similarity measures. These the likelihood and degrees of certainty, can be easily captured by rule of the above parameters used by Collins and Michalski: for by similarity measures or a combination [ 501; the rest can be accounted of the argument. According Finally, although the theory of Collins and Michalski [ lo] the existing implementations of it seem to be a juxtaposition is consistent and justified, techniques of different ‘* However, the most common it is not a complete solution to all the problems within the scope but a solution to a subset of reasoning problems that can be solved with a simple computational mechanism. 278 R. Sun/Art@kd Intelligence 75 (1995) 241-295 I believe, implementations, there are too many similarity therefore, framework. A problem with such the brittleness problem: is used for each pair of similar concepts; within a rule-based that they still suffer from one rule rules around, because many different ways and under many different contexts, as pointed out before; systems will not be free from brittleness the difficulty of this brute force method of putting every pair of similar The computational integrated mechanism flexible reasoning large domain, considering things into rules. is tremendous, given the number of rules needed. A more types of is is handled by rules, and there may be too many in such capable of dealing with similarity matching fashion and other (also cf. [ 181) is preferred. in a massively parallel to any one particular in any reasonably things similar complexity thing, 7.4. Limitations and further work further. One aspect We shall further refine the theory and the CONSYDERR is automatically for further development is currently underway. There are several aspects worth pursuing importance tion, which grounding and through mapping algorithms pretable) may better capture the similarity between concepts and may lead to more accurate models of commonsense matching. It has been suggested into low-level processes representation high-level processes syntactic [ 151. Features developed into semantic developing distributed architecture proposed here. that may be of great representa- that this can be done through (i.e. symbol grounding representation by learning inter- in given situations, reasoning based on similarity involved [ 191) , in this way (which may not be conceptually In addition, representation exploration of the synergy which interaction generates. it is important and the more explicit local representation, to study in greater detail the interaction between especially with regard the feature to the Backward chaining and goal-directed inference are not treated in this paper. Never- theless, they are important issues and should be addressed in subsequent work. More experimental work shall be carried out as the next step in this research, which of system dynamics with complex rule structures and feature of other rep- and shall include examinations structures, detailed verifications with quantitative resentational recursive reasoning, backward chaining, types, such as temporal data, and explorations rule structures. and reasoning 8. Concluding remarks disparate) set of important problems The theory advanced here is meant to be an integrated model that can deal effectively (i.e. with a (seemingly the basic elements of commonsense similarity matching, problems any single one of these problems. Through data analyses, to a single process; and flexibility needed in both directions, and so on. The key point is that these for are reduced the rigor is carried out by CON- : rule application, evidential combination, thus a theory of robust reasoning that has no special provision reasoning. This theory is proposed, combining in a single unified in commonsense in commonsense these problems are handled framework inheritance reasoning) reasoning R. Sun/Art@ciul Intelligence 75 (1995) 241-295 279 SYDERR, CONSYDERR localist networks with similarity-based a connectionist integrates rule-based architecture, which reasoning into connectionist representation. distributed thus serves as a unifying mechanism. networks and couples Appendix A. FEL rules in CONSYDERR FEL stands for Fuzzy Evidential Logic. Here the word fuzzy gradedness Zadeh’s definition of fuzziness based on linguistic variables. or continuous inexactness of a concept or a proposition, is used to refer to the to not restricted Definition A.l. A fact (with or without a negation an atom is related the value of an atom results versa. atom or its negation, is a propositional symbol) represented by a letter and having a value between 1 and U. The value of to the value of its negation by a specific method, so that knowing the value of its negation, or vice in immediately knowing Definition A.2. A rule is a structure composed of two parts: a left-hand which consists of one or more facts, and a right-hand one fact. When value according facts in LHS get assigned values, to a weighting scheme. side (RHS), which consists of the fact in RHS can be assigned a side (LHS), (if thresholds are used) weighted-sum less than or equal to 1, and of determining Definition A.3. A weighting scheme of a rule, with the total weights the fact in RHS of a rule by thresholded values of the facts in LHS (or inner-products LHS facts). When then the weighted-sum on if its absolute value is greater than the threshold, or 0 if otherwise. When of values whether not (usually - 1 if otherwise). is a way of assigning a weight to each fact in LHS the value of of the of weight vectors and vectors of values of is passed the range then the result will be one or the other depending on (or the absolute value of it) is greater than the threshold or is greater than the threshold, 0 or the result will be 1 if the weighted-sum the range of values the weighted-sum is continuous, (or bipolar), is binary Definition A.4 A theory set of rules, W is a weighting is associated with one element is a 4-tuple: < A, R, U: T >, where A is a set of facts, R is a scheme for R, and T is a set of thresholds each of which in R. Definition A.5. A Conclusion rules and facts by doing the following: in FEL is a value associated with a fact, calculated from l for each rule having that conclusion in its RHS, obtain conclusions in its LHS (if any fact is unobtainable, the value of the conclusion in question using assume of all facts it to be zero) ; and then calculate scheme; the weighting l take the MAX of ail these values associated with that conclusion calculated from different rules or given in initial input. 280 R. Sun/Artificial tntelligence 75 (1995) 241-295 Definition A.6. A rule set is hierarchical, if the graph depicting the rule set is acyclic; the graph is constructed by drawing a unidirectional link from each fact (atom) in LHS of a rule to the fact (atom) in RHS of a rule. Definition A.7. A fuzzy evidential logic (FEL) is a 6-tuple: < A, R, W, T, I, C >, where A is a set of facts (the values of which are assumed to be zero initially), R is a set of rules, W is a weighting scheme for R, T is a set of thresholds each of which is for one rule, I is a set of elements of the form (f, u) (where f is a fact, and u is a value associated with f) , and C is a procedure for deriving conclusions (i.e. computing values of facts in RHS of a rule in R, based on the initial condition I). Definition A.8. FELl is FEL when the range of values is restricted to between 0 and 1, and the way the value of a fact is related to the value of its negation is: A=l--A for any fact A. Definition A.9. FEb 1, and the way the value of a fact related to the value of its negation is: is FEL when the range of values is restricted to between -1 and AZ-T/~ for any fact A. This range corresponds to the range of node values in CONSYDERR. Definition A.lO. An element is a structure that represents one and only one fact and has multiple sites each of which receives a group of links that represents one single rule (i.e. links from facts in LHS of the same rule that has the fact which this element represents in its RHS. Definition A.ll. An implementation of FEL is a network of elements connected via links, where each node represents an atom and its negation (there is a one-to-one mapping between an atom and a node) and links represent rules, going from nodes representing facts in LHS of a rule to nodes representing facts in RHS of a rule. Theorem A.12. There is an isomorphic one-to-one mapping between FEL and CL (or CD). Proofs can be found in [ 491. Definition A.13. Horn clause logic is a logic in which all formulas are in the forms of P or P,P2...P,, --+Q R. Sun/Art$cial Intelligence 75 (1995) 241-295 281 where P, the Pi’s and Q are propositions. Definition A.14. A binary FEL associated with facts are binary all thresholds are set to 1. is a FEL (or bipolar), (either FELl or FEL2) in which values total weights of each rule sum to 1, and Theorem A.15 The binary FEL is sound and complete with respect to Horn clause logic. inference to the definition in the form of pairs Proof. The (according values, between uniquely rule will simply add FEL facts to K until no new ones can be added: rule for FEL can be defined as a variant of forward chaining of conclusion). Let K be a set of FEL facts and their (f, v), where f is a fact and u is its value, a real number that all facts are that f is true. Assume -1 and 1 representing represented their confidence values may be zero). The inference the confidence in K (though (1) Given the FEL rule: A1 . . .A, - B (WI,. ..,w,.). . + w, *u, and assume If (Al,.q),.. are (B, u) be in K. If 10’1 3 0 .,(A,,u,) (2) Given (B,u) by (B,u’). the FEL fact: (B, 1) (the known fact), we simply replace (B, u) in K by in K, then let u’= wi *ui +.. and Iu’j > JuJ, then replace (B, 1). In case of binary FEL, we have B = 1. Also, if we know that the value of B is 1, then we know that the value of 1B is -1, vice versa. Given a Horn clause binary FEL theory into a FEL rule by a weight Wi with each fact Ai, in such a way that wi > 0 and their sum theory H, one can produce a corresponding F as follows: each Horn clause AI,. . . , A, --+ B is transformed associating is 1. Conversely, given a binary FEL theory F, one can also produce a corresponding Horn clause transformed definition of binary FEL, we always have wi > 0 and their sum is 1. that all facts in K initially have values 0. Then theory H as follows: each FEL rule Al,. . . , A, - into a Horn rule directly, by ignoring weights wi’s, since according (B, 1) is a FEL conclusion B (WI, ~2,. . . , w,) is to the Assume introduced of H. To see this, observe of F iff b is a logical consequence added to K if and only (B, 1) is only that the FEL inference clause forward chaining because forward-chaining FEL is sound and complete with respect that a FEL fact (B, 1) is if all of the facts in the LHS of the rule have values 1. Thus, in K. It follows for Horn like the forward chaining operator to facts of value 1. B can be inferred by rule. Therefore, rule is sound and complete, binary rule behaves exactly logic when we restrict our attention in H, iff (B, 1) can be inferred by the FEL inference to K if there exists facts (Ai,l),. to Horn clause Logic. (cid:144)i the Horn clause inference . .,(A,.,l) Definition A.16. A causal theory is a set of formulas of the following form Ai [7 niAi A,j On,;Bj * DC where ni’s are either 7 or nothing, A and o are two modal operators, niAi’s are necessary conditions C is concluded (causes), iff all n;Ai’s are true and all njBj’s are not known and njBi’s are possible to be false. conditions). conditions (enabling 282 R. SudArtificinl Intelligence 75 (1995) 241-295 The basic idea is that not all conditions are the same: some conditions (necessary they are the main conditions, (possible to the logic, as long are known conditions, with 0) factors in determining with o) can be assumed as we know that all necessary conditions to be false, then we deduce the conclusion important are more the causal outcome, while other conditions they usually hold. According the others, because true, since than We need to find a scheme to find a weighting find a mapping we can proceed To find a full correspondence procedure the derivation of all true formulas (see [49]), we have: in FEL that directly corresponds (tentatively). are true, and no possible conditions I3 that can equate FEL to Causal Theory. First we need to to numerical values in FEL, then to enable FEL to simulate Causal Theory. between FEL and Causal Theory, we also need a proof in CT and thus enables (theorems). When all these details are taken care of to a proof procedure scheme that links truth values in Causal Theory Theorem A.17. For every hierarchical, non-temporal Causal Theory, there is a FEL ‘A = 1’) where k denotes derivability, C is a set such that CT: C k A iff FEL: C’ b of initially known conditions for Causal Theory CT and C’ is the initial condition for FEL mapped over from C in CT. Appendix B. Experiments with CONSYDERR B.1. GIRO We construct and study the system GIRO (Geographical Information Reasoning and Organization), which stores fairly large amount of knowledge. The knowledge representation in GIRO utilizes the two-level idea in CONSYDERR into two categories: represented in the system regions and regional characterizations by dividing knowledge the geographical concepts, which include basic geographic “cattle-country”), such as “highland ” “mountainous”, features are represented to its corresponding by similar concepts, to other concepts in CL by links, Western-Texas --+ cattle-country). (such as and features, which include primitive physical descriptions of regions, in CL, and , in CL is connected region represented in CD, and because of the fact that features are shared is connected (e.g. features the CD representation and “tropical”. Concepts are represented in CD. Each geographic if this knowledge is similarity-based. to the system Each region is available [lo] Since in Collins’ experiments there was no systematic subjects’ knowledge, we have to find other means of obtaining cally. The large amount of knowledge encyclopedias agricultural [49], The knowledge stored extracted determination knowledge is extracted entirely (2) is linked systemati- from their to in the system is in the form of ( 1) regions, features. Each region characterizations, their physical and (3) of the IR This is a non-temporal proposition them with different letters). in the original definition with different version of CT [ 391; that is, we strip away all temporal notations and treat the same (and represent intervals as different propositions temporal R. Swt/Artijicinl Intelligence 75 (1995) 241-295 283 “cotton-producing-area” “coffee-growing-area” “wine-producing-area” “potato-growing-area” “rubber-producing-area” “goats-area” “rice-growing-area” “wheat-growing-area” “soybean-growing-area” “rubber-producing-area” “sheep-country” “producing-banana” “producing-tropical-fruits” “corn-growing-area” “sugar-producing-area” “fruit-veg-growing-area” Fig. B.I. Regional characterizations included in the system. temperate plateau lowland evergreen densely-populated dependable-rainfall rainy woodland coastal-land river-valley-basin arctic Mts hill deciduous highland infertile fertile farming scrub dry-arid savanna plain lake swamp upland flood rugged grassland Mediterranean tropical rainforest sparsely-populated prairie subtropical desert Fig. B.2. Geographical features included in the system. representation its agricultural distributed and concepts, knowledge all the geographical is not arbitrary tuning of weights either-all for agricultural extraction characterizations by rules its physical in CD. (For details of how knowledge (in CL), features are used in its into features is divided see [49] .) Since such knowledge is straightforward. The extraction process regions in South America, (the process can be automated; is systematic, is well-documented in encyclopedias, covering to make sure the knowledge obtained is no arbitrary hand- see [49]). There lists all the concepts used weights are set at 1. Fig. B.l characterization of regions. Fig. B.2 lists all the features used in CD. The system reasons about agricultural characterizations and similarity matching. When the form of rules), such knowledge feature overlap concepts) there is direct knowledge it is applied, and a strong conclusion is encountered), indirect knowledge (i.e. when a novel input to apply is used in CD) and a plausible conclusion is reached. of regions by means of rules associated with an area (in there is no is reached; when (through similarity matching (associated with similar To reason about “Brazil-north”, which has features such as “tropical is the main agricultural the node representing “Brazil-north”. rainforest hilly product of The plateau”, we start by giving GIRO a query: What “Brazil-north”? which amounts output is as follows: to activating from GIRO (consyderr 0) TITLE: GEOGRAPHY focusing on context AGRICULTURE: remove feature NIL setup done starting running top down cl propagating cd propagating bottom up 284 R. Sun/Artificial Intelligence 75 (1995) 241-295 the average activation is 0.1213409896658248 ( 2, "cattle-country", 0.1249998807907104 ) ( 10. "fruit-veg-growing-area", 0.1249998807907104 ) ( 12, "producing-banana", 0.1249998807907104 ) ( 13, "producing-tropical-fruits", 0.1249998807907104 ) ( 20, “rubber-producing-area", 0.9999990463256836 ) ( 29, "c-Peru", 0.125 ) ( 32, "Bolivia-orient-rainforest", 0.125 ) ( 40, “Guyana-pgs", 0.125 ) ( 41, “Guyana-hilly-country-forest", 0.1666666666666667 1 ( 42, “Guyana-hilly-country-savanna", 0.125 ) ( 45, "Brazil-cw", 0.125 1 ( 50, “Brazil-n", 1 ) ( 60, "Columbia-basin", 0.1666666666666667 ) ( 61, “Ecuador-coast”, ( 66, "Suriname-plateau", 0.125 1 0.125 1 (with confidence value 0.125), etc. l4 Despite that it is a rubber-producing and it is similar, to a small extent, value 0.167) and “Colombia-basin” that it produces bananas area for sure (with confidence value to “Guyana-hilly-country-forest” (with confidence value 0.167), (with confidence value 0.125) and the appearance of mere and similarity- result from rule-based those conclusions the top-down, actually bottom-up, from the reasoning process of the system, we see that “producing-banana” and settling information flows. For is obtained and “Brazil-north” based on the following is similar reasoning: to “Ecuador-coast” that “Brazil-north” might produce bananas. The conclusion on the other hand, is obtained based on a straightforward Other outcomes rubber-producing-area. --+ “Ecuador-coast” pro- to a small extent, so of rule in are obtained The result shows fruits retrieval, equal to 0.999999), (with confidence and there is a small chance tropical information reasoning based tracing example, (0.125) above duces bananas, there is a small chance “rubber-producing-area”, application: Brazil-notih similar Another example fashions. See Fig. B.3. is as follows: we give GIRO a query: What is the main agricultural the node representing “Ecuador coast”. The product of Ecuador coast? by activating output from GIRO is as follows: (consyderr 0) TITLE: GEOGRAPHY focusing on context AGRICULTURE: remove feature NIL setup done starting running top down cl propagating cd propagating bottom up the average activation is 0.1433035089856102 I4 If we want to choose one answer out of many, we can simply use a winner-take-all but this is not an intrinsic part of GIRO and is not needed in this case. network on top of this, R. Sun/Artificial Intelligence 75 (1995) 241-295 285 - 2 IO 12 13 20 29 32 40 41 42 45 50 60 61 66 “cattle-country” “fruit-veg-gmwing-a” “producing-banana” “producing-tropical-fruits” “rubber-producing-area” “c-Peru” “Bolivia-orient-rainforest” “Guyana-pgs” “Guyana-hilly-country-forest” “Guyana-hilly-county-savanna” “Brazil-w” “Brazil-n” “Columbia-basin” “Ecuador-coast” “Suriname-plateau” 0.1249998807907104 0.1249998807907104 0.1249998807907104 0.1249998807907104 0.9999990463256836 0.125 0.124 0:12s 0.1666666666666667 0.125 0.125 I 0.1666666666666667 0.125 0.125 Fig. B.3. Output from GIRO: case 1 ( ‘5, ‘ ‘Uruguay-coastal ’ ’ , 0.1666666666666667 1 ( 10, ( 12, ( 13, ( 30, “fruit-veg-growing-area”, “producing-banana”, “producing-tropical-fruits”, “e-Peru”, 0.1666666666666667 0.2499997615814209 1 0.9999990463256836 1 0.2499997615814209 ) ) 0.1875 1 ( 32, ( 60, ( 61, “Bolivia-orient-rainforest”, “Columbia-basin”, “Ecuador-coast”, 0.1666666666666667 1 ) 1 tropical inferred indicates that from applying (with confidence producing-banana. And the area produces banana a rule: Ecuador-coast - fruits and other fruits/vegetables value equal The result it is to 0.99999), (with confidence value very likely producing equal from mixed similarity matching and rule application: Ecuador- to 0.25), coast --+ producing-banana, and producing-banana N producing-tropical-fruits, so we have producing-tropical-fruits as one of the conclusions. in some way, due to similarity match- “eastern-Peru” to “Uruguay-coastal”, ing and each of these regions. See between Fig. B.4. and “Columbia-basin”, “Ecuador-coast” (or features overlaps) It is similar, As yet another example, we give GIRO a query: Does “Brazil-south” produce cattle? 286 R. SudArtijicial Infelligence 75 (1995) 241-295 - “Uruguay-coatal” 6 0.1666666666666667 IO “fruit-veg-growing-area” 0.2499997615814209 12 “producing-banana” 0.9999998463256836 13 “producing-uopical-fruits” 0.2499997615814209 30 “e-Peru”, 0.1666666666666667 32 “Bolivia-orient-rainforest”, 0.1875 60 “Columbia-basin” 61 “Ecuador-coast” 0.1666666666666667 1 Fig. B.4. Output from GIRO: case 2. by activating The output from GIRO is as follows: the node representing “Brazil-south” and looking for “cattle” in the results. (consyderr 0) on context AGRICULTURE: remove feature NIL TITLE : GEOGRAPHY focusing setup done starting top down cl propagating’ cd propagating bottom up running ’ ’ ’ the average activation ( 2, “cattle-country”, is 0.1492545754568917 0.9999990463256836 1 ( 11, ( 46, “sheep-country”, “Brazil-s”, 1 ) 0.9999990463256836 1 The Result ---- ( 2, “cattle-country”, 0.9999990463256836 1 ---end of results The result indicates that the area does produce cattle and sheep (due to respective rules that lead to such results). Nothing else in the network in this case. See Fig. B.5. fires strongly or distinguishably R. SudArrijcid Inre//iger~ce 75 (1995) 241-295 287 - 2 “cattle-country” 0.9999990463256836 11 “sheep-country” 0.9999990463256836 46 “Brazil-s” I Fig. B.S. Output from GIRO: case 3. 2 u m 0.6 0.2 0 A 0 0.5 1 1.5 numbers 2 of overlapping 2.5 3 3.5 features 4 4.5 5 Fig. 8.6. Similarity matching features, where S,JB = (FA n FB//IFB]~/‘“. in CONSYDERR when A has 20 features and B has small variable numbers of 1.4 1.2 1 0.8 0.6 0.4 0.2 0 R. Sun/Artificial Intelligence 75 (1995) 241-295 5 10 numbers of overlapping features 15 20 Fig. B.7. Similarity matching features, where SAB = /FA n F~l/lF~19/10. in CONSYDERR when A has 20 features and B has large variable numbers of B.2. Systematic experiments Systematic SYDERR when it is applied to a wide range of situations. experiments help to explore the whole spectrum of the behavior of CON- B.2.1. Similarity matching To test similarity matching (the ability to deal with novel input) in CONSYDERR, the difference (the activation of B) when one or more of the following the data in Fig. B.6 and Fig. B.7. A is a concept with 20 features we collected B is another concept, with varying number of features based on the similarity between A and B, B will be activated is, A * sAB. The two figures demonstrate outcome change: 1 FA 1 (the number of features 1 FA n FBI (the number of overlapping curve is almost straight, while function number of I Fs I grows large, the addition of features in B has less effect on the similarity matching outcome. The number of 1 FA 1 has basically no effect on the similarity matching outcome. in CD. in CD. When A is activated, that to a certain degree, in the final similarity matching three parameters for B), and that the results show that each linear to linear) to the linear function). When the for A), 1 FB 1 (the number of features features). Notice in fact a slower than I FB / (as an approximation is used concerning (but very close The figures demonstrate what happens when a novel input is encountered (here A is a that shares some features with A). If we assume novel input and B is an existing concept R. SudArtifciul Intelligence 75 (1995) 241-295 289 _____... _ . . . . ..___. __.. _ . . . . . . _ ._._.._.: . . . . . _ ..__-... A...: . . ..-......_....... ;c. . . . . . . ‘I. _..... 6 10 12 13 30 number of conditions activated Fig. B.8. Rule application in CONSYDERR. Activations of the conclusion relative to the number of conditions activated, with different weight distributions.. input A is activated (having activation 1 ), the figures that the novel to its full extent shows the activation of a similar concept B, where B has different numbers of features and shares different numbers of features with A. The activation of B (which is similar associated with B, so that to the novel the system will not break down due to the lack of exactly matching rules as in typical reasoning, when dealing with a novel situation, we rule-based utilize existing similar cases and adapt previous solutions to the new situation, although in this example we only deal with very simple and highly abstract cases. to bear on A the knowledge systems. As in case-based input A) brings B.2.2. Rule application To test rule application Note that the figure shows numbers of conditions, Al,A2, A3,A4, and A5, activated a fixed order but with different weight distributions. in CONSYDERR, we collected activation data in Fig. B.8. the different activations of the conclusion B with different in (and to different degrees), What the figure demonstrates is that rules in CONSYDERR can be activated partially with a partial satisfaction of conditions by input. Depending on the weight distribution, a rule with a certain portion of its conditions reach its conclusion, with varying degrees of confidence conclusion. in the figure as the activations activated can partially as shown of the R. SudArtijicid Intelligence 75 (I 995) 241-295 1.4 I I I I Activatjons of D - 0 2 4 6 10 the number of features in A Fig. B.9. Inheritance in CONSYDERR. Activations of property-values relative to the number of features in A, when A is fully activated; where A > B, Fn C FE, /FB 1 = 10, and B --+ D; the rule weight is equal to 1. B.2.3. Inheritance To test inheritance in CONSYDERR, we can examine Figs. B.9, B.lO, B.ll, top-down inheritance, bottom-up inheritance, and top-down inheritance with cancellation, These figures are for bottom-up with cancellation, inheritance) A > B, FA C FB, 1 FBI = 10, and either A - exists, or both (in case of cancellation), or B --+ D (in case of top-down inheritance) the figures show the activations with the weights equal to 1. when A is fully activated, that g(x) = x9/” of the property-values in (used Iw) . we only look at cases where each property value is represented by a distinct single feature node in CD. Other cases are similar. in bu; so that cancellation will work correctly), and f(x) = x999/‘ooo (used In these figures, we assume C (in case of bottom-up (B or D, or both). and B.12. inheritance respectively. We assume These handles is handled inheritance the situation that CONSYDERR the property value of a similar concept the canceled property value always has a weaker activation properly. When figures demonstrate the same way as in case there is inheritance but no cancellation, is activated. When of simple similarity matching: there is cancellation, than the right property value, as guaranteed by the selection of the values of the structural td, bu, and lw; see [ 491 for derivations). Note that some activation parameters values may be slightly higher than 1, in order for the comparison of conflicting property values (e.g. coZor-red versus color-white) to take place. This is not a problem: a winner- take-all network can be place on top of pairs of conflicting to decide the final activations (0 or 1) for these concepts. concepts (namely, R. SudArtijicial Intelligence 75 (1995) 241-295 291 I I I I Activatjons of C - 0 2 4 6 8 10 the number of features in A Fig. 8.10. Inheritance in CONSYDERR. Activations of property-values relative to the number of features in A, when B is fully activated; where A 3 B, F, C FB. /FBI = 10, and A -+ C; the rule weight is equal to 1. B.3. Two-level versus one-level The nagging question of whether the two-level structure is necessary can be partially answered experimentally. As argued before, one reason for the two-level dual repre- sentation architecture is to enable the correct handling of inheritance and cancellation. Fig. B.13 shows the difference in the handling of inheritance and cancellation. When there is no CL in the architecture (and therefore there is no bottom-up weight bu) , the activation of a property-value concept is calculated by summing the activations of all the feature nodes (in CD) of a property-value concept, while with CL, the activation of each is taken to be the activation of the corresponding node in CL. The fig- property-value ure demonstrates that, without CL, cancellation cannot be accomplished correctly, since the two competing concepts (property-values C and D) will have the same activation (at exactly 1) . There is no obvious way of remedying this problem beside having the CL/CD two levels. With the CL/CD two-level structure, due to the bottom-up weight bu = I/(FA(~/” (where FA is the size of the feature set of the corresponding concept), C is always activated less strongly than D. Acknowledgements I wish to thank Dave Waltz, James Pustejovsb, Tim Hickey, and Pattie Maes for many discussions, comments and suggestions. I am grateful to Larry Bookman and 292 R. Sun/Arii$cial Intelligence 75 (1995) 241-295 I I I I Activations of C - Activations of D --. 0 0 2 4 6 8 10 the number of features in A Fig. B.11. Inheritance in CONSYDERR. Activations of property-values relative to the number of features in A, when A is fully activated; where A > B, FA C FB, IFS\ = 10, and A -+ C, B --+ D; the rule weights are equal to 1. Steven Sloman for their detailed comments on the draft. I wish to thank Allan Collins for providing me with the data. Thanks also go to the anonymous reviewers for their comments. References 1 I] V. Aijanagadde and L. Shastri, Efficient inference with multi-place predicates and variables in a connectionist system, in: Proceedings Eleventh Annual Conference of the Cognitive Science Society, Ann Arbor, MI (1989) 396-403. 121 J. Anderson and E. Rosenfeld, eds., Neurocomputing (MIT Press, Cambridge, MA, 1988). 131 J. Anderson and R. Thompson, Use of analogy in a production system architecture, in: S. Vosniadou and A. Ortony, eds., Similarity and Analogical Reasoning (Cambridge University Press, Cambridge, England, 1989). I41 J. Bamden, The right of free association: relative-position encoding for connectionist data structures, in: Proceedings Tenth Annual Conference of the Cognitive Science Society, Montreal, Que. (1988) 503-509. 151 J. Barnden and K. Srinivas, Overcoming rule-based rigidity and connectionist limitations through massively parallel case-based reasoning, Int. J. Man-Mach. Stud., to appear. 161 B. Buchanan and E. Shortliffe, eds., Rule-Based Reasoning: the Mycin Experiment (Addison-Wesley, Reading, MA, 1989). 17 1 J. Chomsky, Rules and representation, Behav. Bruin Sci. ( 1980) 1-16 181 A. Collins, Fragments of a theory of human plausible reasoning, in: D. Waltz, ed., Theoretical Issues in Natural Language Processing II (University of Illinois, Urbana, IL, 1978) 194-201. R. Sun/Art$ciul Intelligence 75 (1995) 241-295 293 1.4 I I I I Activations of C - Activations of D --- 0.2 0 0 I 2 1 4 I 6 1 a the number of features in A 10 Fig. B. 12. Inheritance A, when B is fully activated; where A > B, FA C FE. IFS/ = 10, A --+ C, and B - are equal in CONSYDERR. Activations of property-values relative to I. to the number of features in D; the rule weights 191 [IO1 A. Collins and J. Loftus, Spreading activation 407-428. A. Collins and R. Michalski, The logic of plausible theory of semantic processing, f’sychol. Rev. 82 (1975) reasoning: a core theory, Cogn. Sci. 13 ( 1) ( 1989) Llll r121 reasoning by parallel constraint l-49. E. Davis, Representations of Commonsense Knowledge (Morgan Kaufmann, San Mateo, CA, 1990). M. Derthick, Mundane Carnegie-Mellon University, Pittsburg, PA ( 1988). H. Dreyfus and S. Dreyfus, Mind Over Machine (The Free Press, New York, 1987). D. Dubois and H. Prade, An introduction Nun-Standard Logics for Aufomafed Reasoning (Academic Press, San Diego, CA, 1988). M. Dyer, Distributed satisfaction, Tech. Report TR CMU-CS-88-182, formation and processing in connectionist to possibilistic and fuzzy symbol logics, in: E? Smets et al., eds. networks, 1 Expr. Theor. Artif: in: S. Pinker on adapted nets, a critical analysis, learning by searching and cognitive architecture: in: Proceedings AAAI-91, Anaheim, CA ( 1991) Intell. 2 (1990) 215-239. J. Fodor and 2. Pylyshyn, Connectionism and J. Mehler, eds., Connections and Symbols (MIT Press, Cambridge, MA, 1988). L. Fu, Rule 590-595. A. Golding and P Rosenbloom, AAAI-91, Anaheim, CA (1991) 22-27. S. Harnad, The symbol grounding problem, Physica D 42 ( l-3) PJ. Hayes, E Hayes-Roth, D.A. Waterman Reading, MA, 1983). D. Heckerman, and J.F. Lemmer, eds., Oncerfuinfy in Arf@cial Intelligence (Elsevier Science Publishers, New York. 1985) 167-196. and D.B. Lenat, eds., Building Expert Systems (Addison-Wesley, in: Proceedings IJCAI-77, Cambridge, MA ( 1977) 559-565. rule-based systems through case-based reasoning, Proceedings In defence of logic, ( 1990) 335-346. in: L.N. Kanal for MYCIN’s interpretation Probabilistic Improving certainty factors, 1131 Ll41 1151 1161 1171 1181 LJ91 1201 121 I 1221 294 R. Sun/Artijicial Intelligence 75 (1995) 241-295 1.3 ' ! 1 ! I I A&i"ations;of 1 C (wit4 CL) - 1 -r----?- +---- -+-- 0 . 95 _.. .i.. _j j.. /.. __ . . ..j ..__ 0.9 2 I 3 I 4 1 5 1 6 I 7 1 8 9 numbers of features in c Fig. B.13. One-level versus two-level: inheritance and cancellation. A 3 B, FA C Fn. A -+ C. B -+ D. All the weights are equal to 1. FC C Fo. Assume B is fully activated. D should win over C. IFo) is fixed at 10, while lFc[ varies from 2 to 9. 1231 Cl. Hinton, Mapping part-whole hierarchies into connectionist networks, Art$ Intell. 46 (1990) 47-76. [24] J. Holland, Escaping brittleness, in: R. Michalski, J. Carbonell and T. Mitchell eds., Mach. Learn. 2 (Morgan Kaufmann, San Mateo, CA, 1986) 593-625. [251 J. Holland, N. Nisbitt, T. Thagard and J. Holyoak, Induction: A Theory of Learning and Development (MIT Press, Cambridge, MA, 1986). [ 261 K. Holyoak and P. Thagard, A computational model of analogical problem solving, in: S. Vosniadou and A. Ortony, eds., Similarity and Analogical Reasoning (Cambridge University Press, New York, 1989). [ 27 1 E Keil, Concepts, Kinds, and Cognitive Development (MIT Press, Cambridge, MA, 1989). [281 T. Lange and M. Dyer, Frame selection in a connectionist model, in: Proceedings Eleventh Annual Conference of the Cognitive Science Society, Ann Arbor, MI ( 1989) 706-713. [ 291 J. McCarthy, Programs with common sense, in: M. Minsky, ed., Semantic Information Processing (MIT Press, Cambridge, MA, 1968). [ 301 N. Nilsson, Principles of ArtQicial Intelligence (Tiogo, San Mateo, CA, 1980). [ 3 I] L. Norman, Human Information Processing (Academic Press, San Diego, CA, 1977). [ 321 D. Osherson, E. Smith, and E. Shafir, Some origins of belief, Tech. Report 3, Cognitive Science and Machine Intelligence Lab., University of Michigan, Ann Arbor, MI ( 1987). 1331 D. Osherson, J. Stem, 0. Wilkie, M. Stob and E. Smith, Default probability, Cogn. Sci. 15 ( 1991) 25 l-269. 1341 J. Pearl, Probabilistic Reasoning in Intelligent Systems (Morgan Kaufmann, San Mateo, CA, 1988). [35] S. Pinker and A. Prince, On language and connectionism, in: S. Pinker and J. Mehler, eds., Connections and Symbols (MIT Press, Cambridge, MA, 1988). [ 361 C. Riesbeck and R. Schank, Inside Case-based Reasoning (Lawrence Erlbaum, Hillsdale, NJ, 1989). 1371 D. Rumelhart, J. McClelland and the PDP Research Group, Parallel Distributed Processing: Explorufions in the Microstructures of Cognition (MIT Press, Cambridge, MA, 1986). [ 381 G. Shafer, A Mathematical Theory of Evidence (Princeton University Press, Princeton, NJ, 1974). R. Sun/Arttj?cial Intelligence 75 (1995) 241-295 295 [ 391 Y. Shoham, Reasoning time and causation Ph.D. Dissertation, Computer Science Department, Yale University, New Heaven, CT ( 1987). from the standpoint of artificial about change: intelligence, 1401 T. Shultz, P Zelazo and D. Engelberg, Managing uncertainty in rule-based reasoning, in: Proceedings Eleventh Annual Conference of the Cognitive Science Society, Ann Arbor, MI (1989) 227-234. [ 411 S. Sloman, Feature-based induction, Cogn. Psychol., to appear. 142J E. Smith, C. Langston and R. Nisbett, The case for rules in reasoning, Cogn. Sci. 16 (1992) [ 431 P Smolensky, On the proper I-43. [ 44 1 R. Sun, A discrete neural network model for conceptual in: Proceedings treatment of connectionism, Behav. Brain Sci. 11 (1988) and reasoning, representation I-40. Eleventh Annual Conference of the Cognitive Science Society, Ann Arbor, MI (1989) 916-923. [ 45 ] R. Sun, Connectionist models of rule-based the Cognitive Science Society, Chicago, IL ( 1991) 437-442. reasoning, in: Proceedings Thirteenth Annual Conference of 1461 R. Sun, A connectionist model for commonsense reasoning incorporating rules and similarities, Knowledge Acquisition 4 (1992) 293-321. in connectionist [ 47 ] R. Sun, On variable binding I48 ] R. Sun, An efficient feature-based (1993) 512-522. (2) networks, Connection Sci. 4 (2) (1992) 93-124. connectionist inheritance scheme, IEEE Trans. Syst. Man Cybern. 23 149 1 R. Sun, Integrating Rules and Connectionism for Robust Commonsense Reasoning (Wiley, New York, 1994). [SO] R. Sun, A neural network model of causality, 1511 R. Sun, L. Bookman and S. Shekhar, eds. Working Notes of the AAAI Workshop on Integrating Neural IEEE Trans. Neural Networks 5 (1994) 604-611. and Symbolic Processes (AAAI, Menlo Park, CA, 1992). 1521 R. Sun and D. Waltz, Neural networks and human intelligence, J. Math. Psychol. 34 (4) 483-488. (1990). [ 53 1 R. Sun and D. Waltz, Neurally inspired massively parallel model of rule-based reasoning, in: B. Soucek, ed., Neural and Intelligent System Integration (Wiley, New York, 199 1) 34 l-38 1. [541 P Thagard and K. Holyoak, How to compute semantic similarity, in: Proceedings DARPA Case-Based Reasoning Workshop, Pensacola Beach, FL ( 1989) 85-88. [ 55 J D. Touretzky, The Mathematics of Inheritance (Morgan Kaufmann, San Mateo, CA, 1985). 1561 D. Touretzky and G. Hinton, Symbols among neurons, in: Proceedings IJCAI-85, Los Angeles, CA (1985) 238-243. 157 1 A. Tversky, Features of similarity, Psychol. Rev. 84 (4) ( 1977) 327-352. I58 ] S. Vosniadou and A. Ortony, eds., Similarity and Analogical Reasoning (Cambridge University Press, New York, 1989). I59 I D. Waltz, Connectionist models: not just a notational variant, not a panacea, Issues in Natural Language Processing (Ablex, Norwood, NJ, 1988) 1-8. in: D. Waltz, ed., Theoretical 1601 D. Waltz, Is indexing used for retrieval? in: Proceedings DARPA Case-Based Reasoning Workshop, Pensacola Beach, FL (1989) 41-45. [61 I L. Zadeh, Fuzzy Logic, Computer 21 (4) (1988) 83-93. 