Automatic Segmentation of Overlapping CervicalSmear Cells based on Local Distinctive Features andGuided Shape DeformationAfaf Tareefa,∗, Yang Songa, Weidong Caia, Heng Huangb, Hang Changc,Yue Wangd, Michael Fulhame, Dagan Fenga, Mei Chenf,gaBiomedical and Multimedia Information Technology (BMIT) Research Group, School ofInformation Technologies, University of Sydney, Australia.bDepartment of Computer Science and Engineering, University of Texas, USA.cLife Sciences Division, Lawrence Berkeley National Laboratory, USA.dBradley Department of Electrical and Computer Engineering, Virginia PolytechnicInstitute and State University, USA.eDepartment of PET and Nuclear Medicine, Royal Prince Alfred Hospital, Australia, andSydney Medical School, University of Sydney, Australia.fDepartment of Informatics, University of Albany State University of New York.gRobotics Institute, Carnegie Mellon University, USA.AbstractAutomated segmentation of cells from cervical smears poses great challenge tobiomedical image analysis because of the noisy and complex background, poorcytoplasmic contrast and the presence of fuzzy and overlapping cells. In thispaper, we propose an automated segmentation method for the nucleus and cyto-plasm in a cluster of cervical cells based on distinctive local features and guidedsparse shape deformation. Our proposed approach is performed in two stages:segmentation of nuclei and cellular clusters, and segmentation of overlappingcytoplasm. In the first stage, a set of local discriminative shape and appear-ance cues of image superpixels is incorporated and classified by the SupportVector Machine (SVM) to segment the image into nuclei, cellular clusters, andbackground. In the second stage, a robust shape deformation framework is pro-posed, based on Sparse Coding (SC) theory and guided by representative shapefeatures, to construct the cytoplasmic shape of each overlapping cell. Then,the obtained shape is refined by the Distance Regularized Level Set Evolution∗Corresponding authorEmail address: atar8654@uni.sydney.edu.au (Afaf Tareef )Preprint submitted to NeurocomputingSeptember 23, 2016(DRLSE) model. We evaluated our approach using the ISBI 2014 challengedataset, which has 135 synthetic cell images for a total of 810 cells. Our re-sults show that our approach outperformed existing approaches in segmentingoverlapping cells and obtaining accurate nuclear boundaries.Keywords: overlapping cervical smear cells, feature extraction, sparse coding,shape deformation, distance regularized level set.1. IntroductionCervical cancer is a malignant tumor of the cervix and is the fourth mostcommon cause of cancer death in women worldwide [1]. Cervical cancer, how-ever, can be effectively treated if it is detected early during a routine Pap smear5test. In the test, a sample of cells from the cervix is smeared, or spread, onto aglass slide, and examined under a microscope for nuclear and cytoplasmic atypiato detect pre-cancerous abnormalities in cervical cells based on the shape varia-tions of the nuclei and cytoplasm. The automated segmentation of overlappingcells remains one of the most critical challenges in the analysis of microscopic10cervical images [2].Although there has been substantial progress in the segmentation of cervicalcells, unfortunately, the state-of-the-art approaches tend to underperform onimages with overlapping cells. There are currently four main categories of tech-niques to segment cervical cells and they include the segmentation of: a) isolated15or free-lying cells without any overlapping between the cells [3, 4, 5, 6, 7, 8, 9, 10];b) isolated and overlapping nuclei [11, 12, 13, 14, 15, 16, 17, 14]; c) overlappingnuclei and the whole cellular clusters consisting a number of cells [18, 19]; andd) nuclei and cytoplasm from a cluster of overlapping cells [4, 20, 21, 22, 2].In this paper, we propose a two-stage segmentation technique for the nu-20clei and cytoplasm of overlapping cells. We have incorporated discriminativeshape and appearance cues that sufficiently distinguish the nuclei and the back-ground in superpixel representation level. These superpixel-based features arethen used to train the supervised SVM to separate the nuclei and cell clusters2from the background. In the second stage, there is a cytoplasmic segmentation25using sparse shape deformation that is guided toward the target shape usingrepresentative features captured from a well-established initial shape. The ob-tained shape is refined by the distance regularized level set evolution (DRLSE)model to obtain more accurate cell segmentation.2. Literature review30The classic approach for segmenting the isolated cervical cells is the thresh-olding method [3]. This method, however, leads to unsatisfactory results dueto the complex structure of cervix cells resulted from the poor contrast andvariable staining. Marker-based and multi-scale watersheds have also been usedto segment the cytoplasm [4]. Watershed segmentation treats the image inten-35sity as a topographic relief that is filled by water from different minima, andthen assigns the same label to all regions associated with the same catchmentbasin. The main limitation of watershed-based segmentation techniques is theover-segmentation of cells. Active contour model (ACM), or ’snakes’, is anotherfamily of segmentation techniques widely used to segment cervical cells [5, 6, 7].40In ACMs, a curve or a surface is evolved under a constraint toward the objectboundary. ACMs are able to recover closed object boundaries with pixel accu-racy. These approaches, however, are insufficient for touching and overlappingcell segmentation.A number of methods to segment isolated and overlapping nuclei have been45proposed based on thresholding and morphological analysis [11], active contours[12], level set [13], adaptive active shape model [14], watershed transform [15,16], and unsupervised classification [17]. For instance, Plissiti et al.[14] usedan adaptive active shape model trained on a set of images each with a singlenucleus, and the attributes of the nuclear shapes are expressed to estimate the50shape model distribution, which is used to detect the unknown overlappingnuclei boundaries.There are also approaches to segment the overlapping nuclei and cellular3clusters from the background. Gentav et al. used an unsupervised approachwith automatic thresholding to separate cells from background, a multi-scale55hierarchical watershed segmentation algorithm and a binary classifier to sepa-rate nuclei from cellular cytoplasm [18]. Kale and Aksoy applied a multi-scalewatershed algorithm to initially segment the image, and then SVM to finishthe segmentation [19]. Despite the good performance of these approaches insegmenting nuclei and single cells, they are not able to delineate the boundary60of each individual overlapping cytoplasm, which is a critical deficiency as theshape of the cytoplasm is an important feature for subsequent cellular analysis.Segmentation of both nuclei and cytoplasm from overlapping cells in Papsmears is a great challenge due to the large variation in shape and obscureboundary. Recently, a limited number of techniques have been suggested to65segment overlapping cervical cells [4, 20, 21, 22, 2]. An early technique [4] used alocally constrained watershed transform to segment partially overlapping cells.However, it cannot be used for cells with a large overlapping area. Anotherautomated segmentation approach proposed by Tareef et al. [20] was based ongradient thresholding and morphological operations. This approach worked for70the overlapping cells with noticeable difference in intensities; however, it wasnot effective with large fuzzy clusters of small cells.Recently, shape constrained deformation model has been successfully usedfor medical image segmentation, where shape priors are learned from a set oftraining samples and used on optimization methods, such as Active Shape Model75(ASM) [23], sparse shape model [45, 28, 25], and level set evolution with shapepriors [24, 26, 27]. Some recent methods have tended to segment the overlappingcervical cells by incorporating an ellipsoidal shape prior [21] and a star shapeprior [22] with level set optimization for more accurate cell segmentation. Luet al.[21] proposed an overlapping cell segmentation technique incorporating80ellipsoidal shape prior with a joint level set optimization, constrained by theintensity of the overlapping region, the length and area of each cell, and theamount of cell overlap. A new improved version of this approach is presentedin [2] where a joint optimization of multiple level set functions is utilized with4unary (intracell) constraints computed based on contour length, edge strength,85and cell shape, and pairwise (intercell) constraints computed based on the areaof the overlapping regions. Although this approach achieved good results for theoverlapping cells, there is a high degree of false negatives owing to the failure insegmenting some complicated cells.The situation for cervical smears also applies to other cytological examina-90tions.Investigators have suggested a segmentation technique for overlappingcells of breast tissue microarrays and blood smears [29]. The centers of regionscontaining densely touching and overlapping cells were detected using singlepass voting with mean-shift-based seed detection. Then a level set algorithmbased on an interactive model generated the contour of each cell using the ob-95tained centers as an initial position. Srisang et al. suggested a technique forchromosomes based on Voronoi diagrams and Delaunay triangulations [30]; withthis technique, overlapping chromosomes are cut into two chromosomes by iden-tifying all possible cut points from the contour line of overlapping chromosomesto select four target cut points to separate the overlapping chromosomes. Quel-100has et al. proposed a sliding band filter (SBF) based approach [31] to detectconvex shapes corresponding to the nucleus by analyzing the local convergenceof image gradients to estimate the cytoplasm shape. In [26, 27], a boundaryand region-based active contour model incorporating shape priors in a level setevolution was used to segment overlapping nuclei in histopathology images of105breast and prostate biopsy specimens. However, these techniques may not workeffectively with Pap smears as cervical cells have a greater degree of overlapthan the examples in which these other techniques have been used.3. The proposed overlapping nucleus and cytoplasm segmentation ap-proach110Accurate cervical cell segmentation should be able to identify backgroundcells and the nucleus and cytoplasm of individual cells. The proposed workflowof our method is shown in Figure 1 with nuclear and cellular cluster segmentation5in the first stage and then segmentation of the overlapping cytoplasm in thesecond stage. A pre-processing step is also carried out. The algorithm is outlined115in Table 1.Figure 1: Our approach is shown across the six sub-components in two stages: (1) originalPap smear image, (2) pre-processed image, (3) nuclei (green) and cellular clusters (red) seg-mentation results using the local superpixel-based features to train SVM, (4) initial shape:the detected closed regions surrounding nuclei that are used in sparse shape approximation,(5) constructed cytoplasm shape using SC with a training shape dictionary guided by robustfeature points Fp of the initial shape and, (6) final segmentation after the DRLSE-basedrefinement and candidate filtering.3.1. Pre-processingTo achieve better classification, we chose to work at the superpixel levelinstead of at the pixel-grid level for the underlying representation. Superpixelsrepresent the homogenous regions by integrating the local intensity and position120information, and hence, the features extracted at the superpixel-level can betterdescribe the difference between the local regions. Superpixels preserve imageboundaries since the boundaries of the superpixels closely match true image6Table 1: The proposed approach for overlapping cells segmentationPseudo-codeInput: Pap smear imageOutput: Individual nucleus and cytoplasm of free-laying and overlapping cells.Stage I: Nuclei and cellular clumps segmentation1. Compute SLIC superpixel map from I2. pre-process to eliminate the noise and highlight the edges3. Extract shape, texture, and boundary features, and train SVM. Assume N is thenumber of nuclei detected in this stageStage II: Cytoplasm segmentationfor i = 1 to NIf isolated cell: go to step (9), else:1. Generate two edges maps, and complete the missed edges if needed2. Generate the initial cytoplasmic shape based on the closed contour objects includedin a computed ROI3. Extract the feature points Fp of the initial cytoplasmic shape that most likelyrepresent the target contour4. Sparse approximate the starting sparse shape using the feature points Fp and thesub-dictionary ΦF to get the sparse solution XF . Then, the initial shape isreconstructed using the most relative shapes in Φ by Yo = ΦXFfor j =1 to predefined number of SC iterations5. Sparse deform the cell shape using the shape templates in the dictionary Φ6. Deform the output shape Yo based on the feature points. Fp coordinates are usedto construct the transformation aligning the output shape to the target shape space7. Assign Fp to the corresponding points of the output shape to reserve the shapeinformation8. Apply the moving average filter on the output shape to recognise the shapeconnectivity and regularity requirementend9. Refine the deformed shape by DRLSE10. Filter out the small candidates based on a present thresholdend7boundaries, and they also reduce the computational cost. The difference in thesuperpixel shapes also helps distinguish local regions and this is the principle of125the designed shape descriptor we use in our approach.For the pre-processing step, we use the simple linear iterative clustering(SLIC) algorithm [32] to segment the image into local smooth regions corre-sponding to nuclei, cellular clusters, and background. SLIC algorithm guaran-tees more regular shapes for smooth regions when appropriate superpixel size130and regularizer value were used. Fragmenting the Pap image into regularly-shaped superpixels makes it easier to differentiate the nuclei and backgroundbased on the superpixel shape. In some cases, the nucleus may be divided intotwo superpixels affecting the elliptical shape property. However, most of thenuclei superpixels can still be correctly classified based on the superpixel-level135texture and boundary features. For instance, the nucleus (a) in Figure 2 wasdivided into two superpixels, where both have a lower intensity, smoother tex-ture, and more boundary pixels than the surrounding cytoplasm superpixels.Thus, the two superpixels representing the nucleus (a) are correctly classifiedas nuclei superpixels as shown in Figure 1 (3). The output of this step is a140map of superpixels, with each superpixel labelled with an integer number in therange [1, #SP ], where #SP is the total number of superpixels in the imagedetermined by SLIC algorithm.To enhance the appearance of the image and reduce the noise, an image I isconvolved with a Gaussian filter and equalized by the Contrast-Limited Adap-145tive Histogram Equalization (CLAHE) [33] with a small threshold γ, i.e., 0.005to enhance the nuclei that have poor contrast due to cytoplasmic overlap. Thereason for generating superpixels prior to this enhancement step is to preventover-segmenting the cytoplasm and including dark regions around the nuclei inthe nuclear superpixels (see Fig 2).8(a)(b)Figure 2: The SLIC superpixel maps of the Pap image in Fig 1-(1): (a) before and (b) af-ter pre-processing step. Superpixeling after pre-processing leads to over-segment some darkregions (which become darker with image equalization), or include them in the nuclear super-pixels, e.g., nucleus a, b, c, and d.1503.2. Nuclei and Cellular Cluster Segmentation based on Distinctive Superpixel-level Cues with SVMThe aim here was to separate the nuclei and cell clusters from the back-ground. For each superpixel Si, local superpixel shape, texture, and boundarycues are extracted, and arranged into feature vector. The criteria of our feature155design are based on textural and geometrical differences between the superpixels,e.g. the nuclei superpixels tend to have an elliptical shape, whereas cytoplasmicsuperpixels usually have irregular shapes. In these instances, the eccentricityand minor axis length of the superpixels provide a good descriptor. Figure 3shows the feature extraction process. The shape, texture, and boundary features160obtained from the superpixel Si are combined into the feature vector f (Si):f (Si) = [fshap(Si) ftext(Si) fbound(Si)](1)3.2.1. Shape featuresReferring to Figure 3, the shapes of SLIC superpixels are heterogeneous, asthe nuclear superpixels tend to be elliptical, whereas the shape of the back-ground superpixels is hexagonal and the cytoplasm is irregular. Thus, two165sufficient shape features are derived: the minor axis length (Lm), and excessivelengthening or eccentricity (EC). The minor axis length Lm is the length (in9(a)(b)Figure 3: Feature extraction procedure: (a) the superpixel map of image containing sevenoverlapping cells, (b) local representitive shape, texture, and boundary features are extractedfrom each superpixel.pixels) of the shortest diameter of an ellipse completely enclosing the superpixelregion, whereas eccentricity EC = (cid:112)1 − (Lm/Lx)2 ∈ [0, 1] is the ratio of thedistance between the foci of the superpixel and its major axis length Lx, which170provides a good information about the circularity of the superpixel [34]. Theshape features are arranged in vector fShap as following:fShap(Si) = [Lm (Si) EC (Si)](2)3.2.2. Texture featuresNuclear superpixels are generally distinguished by a homogenous texture anda low intensity value compared to neighbouring superpixels. Therefore, a set of175histogram-based features along with a comparative feature are used to capturetexture properties of the superpixels. Four standard texture features were ex-tracted: the mean value (¯.) and standard deviation σ of the pixel intensities, themedian of gradient magnitude M (∇), where ∇ donates the gradient operator,and the entropy H of the superpixel Si are used for the superpixel texture [35].180We also used a comparative feature δ (Si, Bi) = |M (Bi) − M (Si)| that measuresthe change in the intensity between the superpixel Si and its boundary interfaceBi pixels located within a pre-defined Euclidean distance, i.e., 5, from Si. Thetexture feature vector can thus be written as:ftext (Si) = [ ¯Si σ (Si) M (∇Si) H (Si) δ (Si, Bi)](3)103.2.3. Boundary features185The boundary features are designed to distinguish the nuclear and the cel-lular cluster superpixels, which are the most important superpixels for the nextstage. Generally, most edges in the image are found around the nuclei and thecellular clusters. Even if the background has some edges generated by noise,they would be short and unconnected edges. The pre-processing step also helps190in reducing the background noise and highlights the nuclei and cluster bound-aries. To this end, we chose two boundary features: the number of edges in thesuperpixel, and the length of each edge, where each connected and isolated edgeis considered as a single edge. The edge map was obtained using Canny edgedetector [36] with 0.1 threshold, and then, the connected components in the195edge map are labelled and counted as described in [37]. The boundary featureshelp in distinguishing the superpixels belonging to nuclei and those belongingto the cellular clusters and background. The number of connected edges (EN )in the superpixel, and the length of them (Elen) (i.e., number of pixels in eachedge) are computed and combined as a boundary feature vector formed as:fbound(Si) = [EN (Si) Elen (Si)](4)2003.2.4. ClassificationFinally, the extracted superpixel-based feature vectors are used to classifythe image superpixels as background, cytoplasm, and nuclei superpixels. Forclassification, we chose a linear Support Vector Machine (SVM) classifier, specif-ically, C-support vector classification (C-SVC) algorithm provided by LIBSVM205software package [38] with a regularization parameter C equals 1. The SVMclassifier was trained on all labelled SLIC superpixels of the training images.SVM has been widely used in image segmentation and it has proven effec-tiveness in handling the complex segmentation problems in microscopy images[39, 40, 41, 42].112103.3. Overlapping Cell Segmentation based on Guided Shape Approximation andDRLSE ModelIn this stage, cell contours of the detected nuclei are delineated by shape ini-tialization, approximation, and deformation processes. The cytoplasm shape ofeach overlapping cell can be estimated by establishing a closed region surround-215ing each detected nucleus representing the initial cytoplasm, and sparse shapelearning based on training shapes along with representative features. Finally,the obtained shape is refined by DRLSE for more accurate segmentation. Theoverlapping cell segmentation stage is divided into an edge-based shape initial-ization, a guided Sparse Coding (SC) based shape deformation, and DRLSE-220based refinement with candidate filtering.3.3.1. Edge-based shape initializationIn this step the initial shape of the cytoplasm is established based on theclosed contour objects. First, isolated cells are identified based on the number225of nuclei in a cluster classified in the previous stage. For isolated cells, the initialcontours of the DRLSE model are directly formed by the morphological holesfilling of the cluster’s boundary edges. In this case, there is no need for a sparsecoding based cytoplasm deformation as the cell boundary is identified in theclassification stage.(a)(b)Figure 4: Example of edges map generated with (a) upper threshold, and (b) lower threshold.In this case, the first edges map has many missing pixels affecting the segmentation output,whereas the other edges map can provide a good initialization for the overlapping cells.12230If the cellular cluster has two or more nuclei, then, the Canny edge detectoris applied to extract the cell edges. Given the complexity of cervical images,it is difficult to identify the boundaries of all cells in one image using a singlethreshold. For instance, the boundaries of touching or overlapping cells withnoticeable differences in intensities can be identified using the Canny detector235with a high threshold. Whereas, a fuzzy cellular cluster, with convergent inten-sities and unclear edges, requires a low threshold to obtain more detailed edgesto generate a connected region. On the other hand, excessive edge detail willnot give a correct description for the touching or less-overlapping cells since theedges may divide a cell into multiple parts or lead to inclusion of a part of the240attached cell into the cell in focus. Since prior determination of the class ofeach cell in the image is difficult, we chose to establish two cell edge maps usingtwo different thresholds: an upper threshold βu and a lower threshold βl, whereonly one edge map will be used to generate the initial cell mask. The resultsof this step are two skeletonized edge maps for each cell, generated by applying245Canny detector twice with upper and lower thresholds on the complement of thecellular cluster (i.e., to reduce the appearance of noise), and linked by closingthe edges (with a disk with radius Cr) after removing the short ones. Finally,the nuclei boundaries and unlinked edges are removed to get connected edgemaps as shown in Figure 4.250Based on careful analysis of the geometric structure of cervical cells, we pro-pose to determine the cytoplasmic region of each nucleus dynamically basedon the surrounding edges, positioned in a reasonable Euclidean distance Γ, ex-cluding the nuclear boundary. For each nucleus n in the overlapping cluster, acircular region-of-interest (ROI) with radius r from its centroid is determined.255Usually, the mean radius is used in the literature to determine the ROI [43],which gives a reasonable initialization of the cell with a semi-circular shape andnucleus positioned in the center of the cell. However, the cervical cells have amultiform shape, and hence, using the mean radius to determine the ROI maylead to exclude part of the cell from the searching area. Based on our empirical260analysis, the ROI radius r in our approach is computed as the average of the13longest radial length (rx) and the mean of the most frequent radial lengths (rM )included in Γ, with higher weight to rx to cope with cell shape variations (seeFigure 5(a)):r (n) = (2 × rx (n) + rM (n))/3(5)The cell masks, indicating the cell area associated with n, are simply gener-265ated by the morphological holes filling and closing of the edge maps within thecomputed ROI, and picking the rough mask with the largest convex area aftereliminating the candidates whose area and circularity are smaller than thresh-olds (i.e., τc = 0.15 and τa = 0.01 of the whole image size, respectively). If thefirst edge map (i.e., generated by the upper threshold βu) passes this step, the270generated cell mask is used as an initial cell shape for the subsequent steps, oth-erwise, both edge maps are fused together by pixel-wise Exclusive-OR operator,and used to produce the cell mask. In cases where the fused edge map also failsto generate the initial mask due to the absence of a large number of boundarypixels or the high irregularity, a contour with ROI radius r is connected to the275contour pixels of the first edge map (e.g., the green line in Figure 5(b)).(a)(b)Figure 5: (a) Determining the radius of the cell region, the green lines represent the mostfrequent distances, and the yellow line represents the maximum distance, (b) the circular ROIwhere the cytoplasm masks will be found, the green line shows how the boundary is closed incase of missing edges.143.3.2. Guided SC-based shape deformationFigure 6 shows the SC-based shape approximation flowchart, where the inputshape can be deformed under guidance of the initial shape features and a dictio-280nary constructed from the annotated training cell shapes. To illustrate, assumeS denotes a 2D input shape represented by the coordinates of N contour pointsextracted, aligned, and arranged in a vector Y = [x1, y1, x2, y2, ..., xN , yN ]T ∈R2N , containing the x-y coordinates of contour points. Let Φ = [Φ1, Φ2, ..., ΦM ] ∈R2N ×M is the shape dictionary consisting of M pre-aligned and arranged train-285ing shape instances from annotated training dataset (i.e., 270 shape instancesfor our experiments). Then, the shape S can be approximately represented asa linear combination of relatively few atoms in the training shape dictionary.Mathematically, the approximation of S by Φ can be formulated as the followingsparse coding problem:arg minX(cid:107)YT − ΦX(cid:107)22s.t.(cid:107)X(cid:107)0 < s(6)290where YT is an aligned version of the input shape using Procrustes’ analysis [44]with the reference training shape to transform shapes into a standard coordinatesystem. X ∈ RM ×1 is the sparse representation of YT with s non-zero entries,i.e., s=5. Sparse coding has been successfully used in many segmentation prob-lems [45, 46, 47, 48]. However, these approaches have been designed for objects295with shapes of relatively small variation from their typical templates (e.g., thelung and heart). The large shape variation and the high degree of overlap ofcervical smear cells make it difficult to apply the existing SC-based approachesto our segmentation problem.300Training stageConsider we have M training cervical cells {C1, C2, ..., CM } and their la-belled ground truth, the shape vector for each training cell is generated byconcatenating the 2D coordinates of N edge points closing the cell shape, i.e.,N = 360 edge points, obtained by extracting one point at each degree along the15(a)(b)Figure 6: SC-based shape approximation: (a) the shape dictionary and the input shapegenerated by the edge-based shape initialization process, (b) the output shape where thered points represent the feature points Fp used to supervise the sparse shape approximationprocess.305cell contour, originated from the nucleus center. One of these training shapesis chosen as the reference shape used to perform Procrustes’ analysis to trans-form each training shape to the space of the reference shape. Let the alignedshapes be denoted as {C Ai , i = 1, ..., M }. To remove the bias from the selec-tion of reference, the mean of the aligned training shape is chosen as the newreference Sr=(cid:80)Mi )/M , and the alignment process is performed again us-ing the new reference. Finally, the aligned shapes are arranged in vector (i.e.,i=1(C A310Si = [xi1, yi1, xi2, yi2, ..., xiN , yiN ], i = 1, ..., M ), and stored in the shape dictio-nary.315Deformation stageFirstly, a set of feature points of the initial shape used to guide the approxi-mation process is determined. In detail, the contour points of the initial shape,which belong to the boundary between the cellular cluster and background thatare included in a narrow cytoplasmic domain Γ − ε (i.e., to avoid the outliers),320are marked as characteristic feature points Fp, e.g. the red points in Figure7(b). Given that the contour points of the regular cell mask generated by thefirst edge map is most likely representing the true cytoplasmic contour, they16can be also used as feature points of the generated initial shape. The extractedfeature points are used to guide the next shape deformation procedures.325The cytoplasm deformation starts by constructing the starting sparse shapeusing only Fp of the initial shape. The sparse solution of Fp is computed usinga sub-dictionary containing only the corresponding points to Fp for all traininginstances in the shape dictionary (ΦF ), which can be simply extracted usingthe feature points indices. The sparse solution XF ∈ RM ×1 is computed as330following:arg minXF(cid:107)FpT − ΦF XF (cid:107)22s.t.(cid:107)XF (cid:107)0 < s(7)where FpT is the aligned version of Fp by Procrustes’ analysis using the cor-responding points in the reference shape Sr using the feature points indices.Stagewise Orthogonal Matching Pursuit (StOMP) [49] is used in our approachto find XF due to its low computational complexity and attractive asymptotic335statistical properties. Next, using the full shape prior dictionary (Φ), the shapecontour can be approximated using few non-zero coefficients of the sparse solu-tion:Yo = ΦXF(8)To force the approximation process toward the desired shape, two subsequentprocedures are iteratively performed: contour points-based sparse approxima-340tion, followed by Fp-based deformation process.In the contour points-basedapproximation process, the earlier procedures shown by Eq. (7) and Eq. (8)are repeated using all cell contour points (i.e., 360 points). Then, Fp-baseddeformation process is performed to restrict the sparse shape for the actual cellshape, which can be partially represented by the feature points.345Particularly, the coordinate positions of Fp and the corresponding points ofthe output shape Yo are used to compute the similarity mapping transformationTs that minimizes the least squares error between them [50]. The obtainedtransform Ts is then applied to the output shape points transferring them tothe correct space of the feature points to result in the transformed shape YoT .17350Let this be denoted by TsYo, where Ts consists of (hx, hy, σ, θ) transformations;hx and hy represent the translation in x and y axis, σ represents the scale, andθ represents the rotation angle.In practice, the transformed shape YoT tends to take an elliptical shapechanging the coordinates of some feature points. To keep the distinctive shape355information and adjust the shape variation in cervical cells, the feature points Fpare assigned to the corresponding points in YoT , and then, the new output shapecoordinates are smoothed by the moving average filter [51] to recognise the shapeconnectivity and regularity. This approximation process (i.e., contour points-based sparse approximation followed by Fp-based deformation) is repeated K360times to obtain more accurate segmentation.Figure 1 shows that our guided SC-based shape approximation provides agood segmentation and the approximated contour of each cell is very close tothe target contour. However, we expect some pixels of the background or neigh-boring cells to be included within the estimated contour. Thus, DRLSE is used365to address this issue and provide a more reliable segmentation for the actualboundary of the cell in focus.3.3.3. DRLSE-based refinement and candidate filteringThis step aims to refine the segmented cell mask to remove excess pixels370connected to the cell boundary, mainly, background pixels included in cytoplasmsuperpixels in the first stage and misclassified as cytoplasm pixel, and then, filterout the cytoplasm candidate that is smaller than being a cell. To highlightsome light cytoplasmic pixels close to the background pixels, only the cellularclusters of the image are equalized by CLAHE. Finally, the obtained cell contour375is refined by a geodesic active contour model, and then, the false cytoplasmcandidates, whose areas are smaller than a size threshold, are removed. TheDistance Regularized Level Set Evolution (DRLSE) model [52] is chosen forcell refinement, where a distance regularization term is defined with a potentialfunction, such that the derived level set evolution has a unique forward-and-18380backward (FAB) diffusion effect, maintaining a desired shape of the level setfunction (LSF ). DRLSE forces the curve to evolve near the signed distancefunction, and thus, guarantees curve smoothness and eliminates the need forthe costly reinitialization procedure. Consider that φ : Ω → R denotes a LSFon a domain Ω. The energy functional to be minimized is defined as:ε = µR(φ) + λ(L)(φ) + αA(φ)(9)385where µ, λ, and α are constants (i.e., µ = 0.2, λ = 5, α = 1.5). R(φ) is a regu-larization term maintaining the signed distance property ∇φ = 1 to guaranteethe smoothness, L(φ) measures the length of the zero level, and A(φ) measuresthe area of φ < 0. The energy functional ε(φ) can be minimized by solving thefollowing gradient flow:∂φ∂t= µdiv (dp(|∇φ|∇φ) + λδ(cid:15)(φ)div(cid:19)(cid:18)g∇φ|∇φ|+ αgδ(cid:15)(φ)(10)390where δ(.) is the Dirac delta function, and g is the edge stopping function definedas:g (|∇I|) =11 + |∇Gσ × I|2(11)where Gσ is the Gaussian kernel with standard deviation σ, and I is the imageon a domain Ω.(a)(b)Figure 7: (a) The initial shape using for shape approximation, (b) the approximated cyto-plasm shape using sparse coding. Red points represent the feature points Fp which are usedto guide the sparse approximation process.194. Material and evaluation methods395We evaluated the performance of our approach using the dataset and eval-uation methodology of the ISBI 2014 “Overlapping Cervical Cytology ImageSegmentation Challenge” [53], with 135 synthetic gray-scale images (i.e., 45training images and 90 test images) artificially produced from real, free-lyingcervical cells. The total number of the nuclei and cytoplasm pairs in the images400is 810 (i.e., 270 training cells and 540 test cells), and the image size is 512×512pixels. We used the training dataset to train the SVM classifier and generate theshape dictionary, whereas the test dataset is used for performance evaluation.Object-level and pixel-level measures were used to assess the segmentationresults. We used criteria developed by Gentav et al. [18] to evaluate the quan-405titative performance of the nuclear segmentation. Considering the segmentednucleus region Od and the corresponding ground-truth Ogt, a good nuclear seg-mentation is the one satisfying the following condition:Od ∩ OgtOd> 0.6 andOd ∩ OgtOgt> 0.6(12)Based on Eq. (12), the segmented nuclei are classified as object-level truepositive (T PO), false negative (F NO) or false positive (F PO); they are used to410compute the object-level precision (PObj.) and recall (RObj.) values using thefollowing equations:PObj. = T PO/(T PO + F PO)RObj. = T PO/(T PO + F NO)(13)(14)The pixel-level precision (PP ix.) and recall (RP ix.) values are calculated forthe good segmentations that were determined using the Dice Coefficient (DC).DC was computed as:DC = 2#{Od ∩ Ogt}#{Od} + #{Ogt}(15)20415A ’good’ segmentation is considered to be the one with a DC value greaterthan 0.7. For cytoplasm segmentation, the object-level performance was eval-uated using the false negative rate; pixel-level performance was assessed usingthe true positive rate, false positive rate and DC, using the evaluation codeprovided by the challenge.4205. Experimental results and discussionTo evaluate the proposed methodology, we measured the object-level andpixel-level segmentation performance for the nuclei and cytoplasm, the perfor-mance over different cell structures, and the computational cost of the proposedapproach. We also discussed the performance improvement of our guided de-425formation process over the conventional deformation process. Further, we com-pared our cytoplasm segmentation results to the results of the ISBI challengewinners applied on the same ISBI test and train datasets: a) Ushizima’s seg-mentation approach [54], based on nuclear narrow-band seeding, graph-basedregion growing and Voronoi diagrams; and b) Nostrati’s approach [55], based430on maximally stable extremal region detector (MSER), random decision forestclassifier (RF), and signed distance map (SDM) function. We also comparedour nuclei and cytoplasm segmentation results to the results of the baselineapproach proposed by the ISBI challenge organizers [2].The main parameters of our method, which may significantly influence the435segmentation performance, are summarized in Table 2. The parameters usedby our approach were chosen based on our initial validation study on a sampleof the training and test images. For instance, the superpixel size was selectedbased on the size of the nuclei in the dataset, if a smaller superpixel size wasused, some nuclei regions would be divided into two or more superpixels, and440thus, the elliptical shape of the nuclei would be lost. Also a lower regularizervalue could lead to over-segmentation of nuclei regions. A higher equalizationthreshold in the pre-processing step could increase the intensity of some regionsand result in classifying them as nuclei by the SVM. Moreover, it is important21that the radius of the initial region corresponds to the cell size in the dataset,445so that two or more overlapping cells are not treated as the one cell. The valueof the initial radius is based on the size of the cells in the dataset, thus, itshould be properly tuned to suit other datasets, likewise, the minimum cell sizewhich is based on our test cells. We also used secondary parameters includingβu = 0.1, βl = 0.01, Cr = 3, and ε = 10 used in edge establishment. The450proposed approach is less sensitive to reasonable changes in these parameters,and hence, these parameters may work with other datasets. For instance, ourapproach has the potential to provide a good cell segmentation as long as thecanny thresholds used in edge establishment are able to provide enough featurepoints to represent the cell shape, noting that most of these feature points are455extracted from the cellular cluster boundary obtained from SVM classificationstage. Parameter sensitivity analysis is provided in Table 5.Table 2: ParametersOur approach stepsParametersStage ISuperpixel sizeRegularizer valueStage IIInitial radius ΓSC iterations KValue250.01905DRLSE iterations50 (Narrowband)Minimum cell size0.01 of image size5.1. Evaluation of Nuclei SegmentationThe nuclear segmentation results are shown in Table 3. A segmented nucleuswas considered as a true positive if the overlapping ratio computed by Eq. (12) is460larger than 0.6, causing under-segmented nuclei to be counted as false negatives.Nevertheless, our results had a good true positive rate indicated by the recallvalue of 0.94, with on average 6% improvement over the recall obtained by Luet al. at 0.88. Our method also had a high precision of 0.99, compared toLu et al.’s method with a low false positive rate. Our technique missed only2246531 true nuclei out of 540 nuclei in all images. Our false negative results aremainly related to the similarity of texture and density between the nuclei andthe surrounding cytoplasm. There were only 8 false positive nuclei; four weretrue nuclei but they did not satisfy Eq. (12) as they missed some true pixels orincluded some boundary surface pixels.470Given the importance of identifying nuclei in discriminating normal fromabnormal cells in a Pap smear, a reliable approach should also have high pixel-level segmentation performance. Table 3 shows that our approach had a highpixel-based precision of 0.95 (±0.06), recall of 0.93 (±0.07) and DC values of0.93 (±0.05), whereas the precision, recall, and DC values obtained by Lu et475al.’s approach were 0.94 (±0.08), 0.91 (±0.08) and 0.92 (±0.05), respectively.Table 3: Object-level and pixel-level Nuclei segmentation resultsThe approachesPObj.RObj.PP ix.RP ix.DCLu’s approach [2]Our approach0.980.990.880.940.94 ± 0.080.91 ± 0.080.92 ± 0.050.95 ± 0.060.93 ± 0.070.93 ± 0.04Incorporating shape and appearance features in superpixel level were themain contributing factor to our better performance in the object-level and pixel-level nuclei segmentation. Figure 8 illustrates the performance of our incorpo-rated features in classifying the superpixels. We compared the object-level nuclei480segmentation precision and recall using texture and boundary features (T B),texture and shape features (T Sh), and all the features (All). The combinationof shape and appearance features All improved recall from 0.91 to 0.94, andthere was a small improvement in precision. Nucleus superpixels were distin-guished from the other superpixels by low intensity, homogenous texture, clear485boundaries and an elliptical shape, which all were represented by our features.5.2. Evaluation of Cytoplasm SegmentationThe cytoplasm segmentation results of our approach compared to the chal-lenge are shown in Table 4. Our method had the highest pixel-level true positiverate of 0.91 (±0.09) with up to an 8% improvement over the challenge results.23Figure 8: Object-level nuclei segmentation results using different features.490The DC of 0.89 (±0.07) surpassed Ushizima and Nostrati et al.’s techniques byabout 2%. Our object-based false negative F N o rate was also lower than Lu etal.’s techniques.In general, increasing the pixel-based true positive rate T P p also increasedthe false positive rate F P p, and vice versa. Ushizima et al.’s technique had495the lowest F P p rate but at the expense of having the lowest T P p rate of 0.83.Our method had the highest T P p without increasing the false positive limit.Likewise, T P p and DC were negatively related to F N o. The high T P p and DCof Lu et al.’s approach were associated with the high F N o. We had a similarDC to Lu et al., but with higher T P p and lower F N o. Our method was twice500as fast as Lu et al., and we had better nuclear segmentation results as shownin the previous section. Our guided shape deformation improved the cytoplasmsegmentation because it excluded the false regions close to the cell boundary,where conventional deformable models stop or move slowly. We present furtherdiscussion on the performance of our guided shape deformation in Section 5.3505and 5.5.Furthermore, Table 5 shows the cytoplasm segmentation performance of ourapproach using different secondary parameters. The results in the table provedthe reliability of our proposed approach, where the pixel-based measures are inthe same high range with different secondary parameters. The results for each510measure in Table 5 were also statistically evaluated in term of the probabilityvalue (p-value) using unpaired t-test, with the null hypothesis that differentparameters led to similar segmentation results. For all cases in Table 5, the24p-values were higher than 0.11, with an average p-value={0.42,0.51,0.48,0.84}for DC, T P p, F P p, and F N o, respectively. These results proved that the515secondary parameters had no significant impact on our cytoplasm segmentationresults. It is worth mentioning that the qualitative segmentation results for thecases in Table 5 are changed (i.e., the best qualitative results were obtained bythe parameters used in our approach), however, the overall quantitative resultsare still in the same range.Table 4: Cytoplasm segmentation resultsThe approachesDCT P pF P pF N oUshizima’s approach [54] 0.87 ± 0.080.83± 0.130.002 ± 0.0020.17± 0.21Nostrati’s approach [55]0.87 ± 0.070.90 ± 0.080.005 ± 0.0040.14 ± 0.16Lu’s approach [2]Our approach0.89 ± 0.080.90 ± 0.100.003 ± 0.0050.31 ± 0.290.89 ± 0.070.91 ± 0.090.004 ± 0.0050.27 ± 0.28Table 5: Parameter sensitivity analysis.βuβlCrεDCT P pF P pF N o0.05 0.010.05 0.050.10 0.010.10 0.050.10 0.050.50 0.010.10 0.0122335531510510155100.88 ± 0.070.90 ± 0.090.004 ± 0.0050.25 ± 0.260.88 ± 0.080.90 ± 0.090.004 ± 0.0050.27 ± 0.280.89 ± 0.070.91 ± 0.090.004 ± 0.0050.28 ± 0.280.89 ± 0.070.91 ± 0.090.004 ± 0.0050.29 ± 0.300.88 ± 0.080.91 ± 0.100.005 ± 0.0050.26 ± 0.270.88 ± 0.080.91 ± 0.090.005 ± 0.0060.30 ± 0.290.89 ± 0.070.91 ± 0.090.004 ± 0.0050.27 ± 0.285205.3. Evaluation of Segmentation for Different Cell StructuresThe ISBI dataset was grouped according to the complexity of the cells struc-ture, represented by the number of cells in each image and the overlapping ratiosbetween the cells, into 45 groups. The number of cells in each Pap image is var-ied between 2 and 10 cells, where each cell overlap with at least one cell in the525same image with an overlap ratio in one of the following ranges:[0, 0.1, 0.2,0.3, 0.4]. We also chose to further evaluate our segmentation performance onimages of different groups. The results are summarized in Table 6. The results25demonstrated that our approach is not much sensitive to changes in the numberof cells in the images, whereas, a consistent improvement in performance was530shown when the overlapping ratio was decreased. According to the results, ourapproach successfully segmented cell clusters with a large number of cells (be-tween 8 and 10 cells) provided the overlapping ratios between the cells is in therange [0, 0.2]. Our method worthily segmented the cytoplasm of isolated andtouching cells (i.e., zero overlap ratio) with a very high DC rates of 0.93-0.96,535regardless the number of cells in a single image. The pixel-based false positiverate F P p for this group was low, i.e., 0.001, with high T P p rate of 0.93, onaverage. The F N o was also small at 0.01. Furthermore, the segmentation ofthe cells with overlapping ratio ∈ {0.1, 0.2} was also effective with T P p of 0.90and DC of 0.87, on average. The good results in these cases were mainly due540to the clarity of the cell boundaries, resulting in enough feature points to guideour deformation process toward the real cell shape.The most problematic case occurred when we have a large fuzzy cell clusterswith unclear edges, thus, insufficient number of feature points can be extracted.There was a high F N o of 0.44, on average, for this case (i.e., overlapping ratio545∈ {0.3, 0.4}). Nevertheless, our approach still got a good DC of 0.86, andacceptable F P p of 0.006. Moreover, the obtained T P p was 0.89, which was stillhigher than the T P p value obtained by [54] ISBI approach.Figure 9 shows examples of our segmentation results for a different numberof cells and degree of cell overlap. The first group of images in the figure shows550our segmentation results for Pap images with overlapping ratio ∈ {0, 0.1, 0.2}.The second group shows the segmentation results for the difficult cases, wherethe overlapping ratio ∈ {0.3, 0.4}. It can be seen that our approach can providean accurate, and sometime semi-optimal, segmentation for the free-lying andslightly overlapping cells.In addition, our segmentation for the overlapping555cluster of multiple cells is still good. The second group of images includes someof our failure cases, which mainly occurred when the feature points of the cellwere not enough to represent the cell shape, especially, when if the cell wasirregularly-shaped. Also, when the cell nucleus is located in one side of the cell,26this may lead to inaccurate determination of ROI radius, resulting in excluding560part of the cell from the searching area, e.g., the cell highlighted by black linein Figure 9 (g). Such this case probably can be controlled by taking an errorpercentage into consideration when the standard deviation of the radii in thecell exceed a threshold.For more evaluation, a qualitative comparison of the nuclei and cytoplasm565segmentation of our approach and the ISBI approaches is provided in Figure 10using the visual results provided by the ISBI organizers [56]. As seen in the fig-ure, the proposed approach provided the best, and semi-optimal, segmentationfor the overlapping cells in the first image. Moreover, the proposed approachgives better segmentation for the overlapping areas in the second image than570the ISBI approaches. However, parts of two cells in the second image (i.e.,highlighted by green and red lines in our results) were mis-segmented due toexcluding them from the ROI in edge establishment step. This case mainlyoccurred when the cell nucleus is located in one side of the cell, thus, the meanradius used in Eq. (5) mislead the ROI radius computation.Table 6: The cytoplasm segmentation results for different cell structure.27(a)(b)(c)(d)(e)(f )(g)(h)Figure 9: Examples of the nuclei and cytoplasm segmentation. The first row in each groupshows the original cervical image, the second row shows the ground truth of the cells, and thethird row shows the segmentation results of our approach for different cell structures. Thenuclei are highlighted in black color, and the contours are outlined by red, green, blue, black,yellow, and purple color.28Ground truthUshizima’s approach [54]Nostrati’s approach [55]Lu’s approach [2]Our approachFigure 10: Qualitative evaluation of the proposed approach and the ISBI challenge methods[56].295755.4. Evaluation of the Computational CostThe execution time (second per cell) of each major step in our approachis shown in Table 7. The time was obtained using non-optimized MATLABcode on a PC with a 3.2GHz Intel Core i5 processor and 8GB RAM. Theedge establishment time in the table includes the execution time of the isolated580cells segmentation, edge detection and linking, ROI determination, establishingthe initial shape, and the alternative shape initialization process. The sparsedeformation time is the execution time of the test phase in the SC-based defor-mation process, whereas the refinement and filtering time is the execution timefor DRLSE-based refinement step and the false candidates filtering step.585The proposed approach took 18 seconds on average to classify the Pap smearimage to its cellular components, and approximately 10 seconds to segment eachcell in the image. The execution time of the second stage varied depending onthe cell structure. For instance, the second stage of our approach needs less thanone second to segment each isolated cell, as there was no need to establish the590edge maps or use the shape deformation process. The alternative initializationprocess, in cases where the edge maps failed to generate the initial shapes, alsoinfluenced the processing time. Our method was approximately twice as fast asLu et al.’s technique, which took, on average, 56 seconds per cell. This improve-ment in the time complexity is mainly attributed to two points: 1) using the595superpixels instead of the image pixels in the classification stage; 2) the robustedge-based initialization of the cytoplasm shape, which reduces the number ofiterations needed in the sparse deformation and refinement stages. Moreover,the simplicity of the isolated cytoplasm segmentation procedure, and ignoringunnecessary steps, help in improving the time complexity of our approach.6005.5. Evaluation of the Deformation ProcessThe performance improvement of our guided shape deformation process overthe conventional deformation process is shown in Table 8. We compared thesegmentation results of our approach with the results of the deformable DRLSEmodel with a conventional initialization (e.g., the circular mask established by30Table 7: Execution time of the proposed approachThe proposed approach stepsTime in sec./cellNuclei segmentation stage18.25 ± 0.42Cell segmentation stageEdge establishmentSparse shape deformationRefinement and filtering3.51 ± 2.562.47 ± 1.753.20 ± 0.19605Eq.(5) above); let be called conventional DRLSE. As explained in Section5.2, the high F N o led to higher T P p and DC, since only the well-segmentedcells were used in evaluation. This explains the acceptable DC rate of theconventional DRLSE. The high T P p resulted from the larger cell regions thatwere detected. The cytoplasm initialization and deformation process we em-610ployed further improved the results of the deformable model using the sameinitial circular mask. We obtained around half of the F N o obtained using theconventional mask and improved the DC by 5%. Our shape initialization andapproximation process reduced the execution time by using 50 iterations to re-fine the cytoplasm contour. Whereas, two hundred iterations were needed when615using the conventional DRLSE (i.e., increasing the number of iterations couldnot enhance the results).It is generally accepted that the effectiveness of deformable models is affectedmainly by the contour initialization process. Pap smears, usually contain cyto-plasmic regions that show lower intensities than the surrounding areas. When620deformable models reach such regions in search of the cell boundary, they slowdown or stop. There can also be too many nuclei in an ROI that force thedeformable model to stop. Moreover, deformable models cannot distinguish be-tween the edges of the cell in focus and the edges of the neighbouring cells.In the end, the false positives and irregularly-shaped cytoplasm are increased.625Our deformable approach succeeded in providing a solution for outlining com-plex objects where there are marked overlaps and variations in shape.31Table 8: Evaluation of the performance improvement obtained by the SC-based deformationprocess.MeasuresConventional approachOur approachDCT P pF P pF N o0.84 ± 0.080.94 ± 0.030.01 ± 0.010.48 ± 0.320.89 ± 0.070.91 ± 0.090.00 ± 0.010.25 ± 0.256. ConclusionsThe segmentation of cervical cell smears is an ill-posed problem because ofthe varied shape and often significant overlap. In this paper we have presented630a 2-stage segmentation approach that addresses this challenging problem usingdistinctive superpixel-based shape and appearance features, and a guided sparseshape deformation process using representative feature points. Applying super-pixeling with high regularity to exploit the shape property of the superpixelsin classification, along with discriminative texture and boundary features, has635great influence in obtaining accurate nuclear segmentation, and precise cyto-plasm/background boundaries. Moreover, the shape initialization process, andusing the feature points to approximate the cell shape, provide a successfulsolution to tackle the difficulties of using sparse deformation with Pap smearimages, due to the large variation in the cell shapes and their high degree of640overlapping. Our shape initialization procedure is adaptable and able to workwith the different cell types (i.e., simple process based on classification resultsfor isolated cells, two mask candidates for more complex cell structure, andcarefully-computed alternative cell mask for the fuzzy cells without extractableedges). The qualitative and quantitative results demonstrated the practicality645and reliability of our approach in segmenting not only the isolated and touchingcells, but also cells from large clusters with high degree of overlapping. Ourapproach offers improvements over existing techniques in accuracy and speed ofcomputation. In the future work, we intend to apply our approach to stacks of32multi-focal images [57].650References[1] World cancer report 2014, World Health Organization (2014) Chapter 5.12.[2] Z. Lu, G. Carneiro, A. P. Bradley, An improved joint optimization of mul-tiple level set functions for the segmentation of overlapping cervical cells,Image Processing, IEEE Transactions on 24 (4) (2015) 1261–1272.655[3] H.-S. Wu, J. Gil, J. Barba, Optimal segmentation of cell images, in: Vision,Image and Signal Processing, IEE Proceedings-, Vol. 145, IET, 1998, pp.50–56.[4] N. B´eliz-Osorio, J. Crespo, M. Garc´ıa-Rojo, A. Mu˜noz, J. Azpiazu, Cytol-ogy imaging segmentation using the locally constrained watershed trans-660form, in: Mathematical Morphology and Its Applications to Image andSignal Processing, Springer, 2011, pp. 429–438.[5] K. Li, Z. Lu, W. Liu, J. Yin, Cytoplasm and nucleus segmentation incervical smear images using radiating GVF snake, Pattern Recognition45 (4) (2012) 1255–1264.665[6] J. Fan, R. Wang, S. Li, C. Zhang, Automated cervical cell image segmen-tation using level set based active contour model, in: Control Automa-tion Robotics & Vision (ICARCV), 2012 12th International Conference on,IEEE, 2012, pp. 877–882.[7] S.-F. Yang-Mao, Y.-K. Chan, Y.-P. Chu, Edge enhancement nucleus and670cytoplast contour detector of cervical smear images, Systems, Man, andCybernetics, Part B: Cybernetics, IEEE Transactions on 38 (2) (2008)353–366.[8] T. Chankong, N. Theera-Umpon, S. Auephanwiriyakul, Automatic cervicalcell segmentation and classification in pap smears, Computer Methods and675Programs in Biomedicine 113 (2) (2014) 539–556.33[9] L. Zhang, H. Kong, C. T. Chin, S. Liu, Z. Chen, T. Wang, S. Chen, Segmen-tation of cytoplasm and nuclei of abnormal cells in cervical cytology usingglobal and local graph cuts, Computerized Medical Imaging and Graphics38 (5) (2014) 369–380.680[10] L. Zhang, H. Kong, C. T. Chin, T. Wang, S. Chen, Cytoplasm segmenta-tion on cervical cell images using graph cut-based approach, Bio-MedicalMaterials and Engineering 24 (1) (2014) 1125–1131.[11] M. E. Plissiti, C. Nikou, A. Charchanti, Automated detection of cell nucleiin pap smear images using morphological reconstruction and clustering, In-685formation Technology in Biomedicine, IEEE Transactions on 15 (2) (2011)233–241.[12] M. Hu, X. Ping, Y. Ding, Automated cell nucleus segmentation using im-proved snake, in: Image Processing, 2004. ICIP’04. 2004 International Con-ference on, Vol. 4, IEEE, 2004, pp. 2737–2740.690[13] C. Bergmeir, M. Garc´ıa Silvente, J. M. Ben´ıtez, Segmentation of cervi-cal cell nuclei in high-resolution microscopic images: A new algorithmand a web-based software framework, Computer Methods and Programsin Biomedicine 107 (3) (2012) 497–512.[14] M. E. Plissiti, C. Nikou, Overlapping cell nuclei segmentation using a spa-695tially adaptive active physical model, Image Processing, IEEE Transactionson 21 (11) (2012) 4568–4580.[15] C. Jung, C. Kim, Segmenting clustered nuclei using H-minima transform-based marker extraction and contour parameterization, Biomedical Engi-neering, IEEE Transactions on 57 (10) (2010) 2600–2604.700[16] M. E. Plissiti, C. Nikou, A. Charchanti, Combining shape, texture andintensity features for cell nuclei extraction in Pap smear images, PatternRecognition Letters 32 (6) (2011) 838–853.34[17] C. Jung, C. Kim, S. W. Chae, S. Oh, Unsupervised segmentation of over-lapped nuclei using bayesian classification, Biomedical Engineering, IEEE705Transactions on 57 (12) (2010) 2825–2832.[18] A. Gentav, S. Aksoy, S. nder, Unsupervised segmentation and classificationof cervical cell images, Pattern Recognition 45 (12) (2012) 4151–4168.[19] A. Kale, S. Aksoy, Segmentation of cervical cell images, in: Pattern Recog-nition (ICPR), 2010 20th International Conference on, IEEE, 2010, pp.7102399–2402.[20] A. Tareef, Y. Song, W. Cai, D. Feng, M. Chen, Automated three-stage nu-cleus and cytoplasm segmentation of overlapping cells, in: Control Automa-tion Robotics & Vision (ICARCV), 2014 13th International Conference on,IEEE, 2014, pp. 865–870.715[21] Z. Lu, G. Carneiro, A. P. Bradley, Automated nucleus and cytoplasm seg-mentation of overlapping cervical cells, in: Medical Image Computing andComputer-Assisted Intervention–MICCAI 2013, Springer, 2013, pp. 452–460.[22] M. Nosrati, G. Hamarneh, Segmentation of overlapping cervical cells: A720variational method with star-shape prior, in: IEEE International Sympo-sium on Biomedical Imaging (ISBI), IEEE, 2015.[23] T. F. Cootes, C. J. Taylor, D. H. Cooper, J. Graham, Active shape models-their training and application, Computer vision and image understanding61 (1) (1995) 38–59.725[24] H. Cai, X. Xu, J. Lu, J. Lichtman, S. Yung, S. T. Wong, Shape-constrainedrepulsive snake method to segment and track neurons in 3d microscopyimages, in: 3rd IEEE International Symposium on Biomedical Imaging:Nano to Macro, 2006., IEEE, 2006, pp. 538–541.35[25] F. Xing, Y. Xie, L. Yang, An automatic learning-based framework for ro-730bust nucleus segmentation, IEEE transactions on medical imaging 35 (2)(2016) 550–566.[26] S. Ali, A. Madabhushi, An integrated region-, boundary-, shape-based ac-tive contour for multiple object overlap resolution in histological imagery,IEEE transactions on medical imaging 31 (7) (2012) 1448–1460.735[27] S. Ali, R. Veltri, J. I. Epstein, C. Christudass, A. Madabhushi, Selectiveinvocation of shape priors for deformable segmentation and morphologicclassification of prostate cancer tissue microarrays, Computerized MedicalImaging and Graphics 41 (2015) 3–13.[28] F. Xing, L. Yang, Robust selection-based sparse shape model for lung can-740cer image segmentation, in: Medical Image Computing and Computer-Assisted Intervention–MICCAI 2013, Springer, 2013, pp. 404–412.[29] X. Qi, F. Xing, D. J. Foran, L. Yang, Robust segmentation of overlappingcells in histopathology specimens using parallel seed detection and repulsiveset, Biomedical Engineering, IEEE Transactions on 59 (3) (2012) 754–765.745[30] W. Srisang, K. Jaroensutasinee, M. Jaroensutasinee, Segmentation of over-lapping chromosome images using computational geometry, Walailak Jour-nal of Science and Technology (WJST) 3 (2) (2011) 181–194.[31] P. Quelhas, M. Marcuzzo, A. M. Mendona, A. Campilho, Cell nuclei andcytoplasm joint segmentation using the sliding band filter, Medical Imaging,750IEEE Transactions on 29 (8) (2010) 1463–1473.[32] R. Achanta, A. Shaji, K. Smith, A. Lucchi, P. Fua, S. Susstrunk, SLIC su-perpixels compared to state-of-the-art superpixel methods, Pattern Anal-ysis and Machine Intelligence, IEEE Transactions on 34 (11) (2012) 2274–2282.755[33] K. Zuiderveld, Contrast limited adaptive histogram equalization,in:Graphics gems IV, Academic Press Professional, Inc., 1994, pp. 474–485.36[34] M. Yang, K. Kpalma, J. Ronsin, A survey of shape feature extractiontechniques, Pattern recognition (2008) 43–90.[35] W. Gonzalez, R. E. Woods, Eddins, digital image processing using matlab,760Third New Jersey: Prentice Hall.[36] J. Canny, A computational approach to edge detection, Pattern Analysisand Machine Intelligence, IEEE Transactions on (6) (1986) 679–698.[37] R. M. Haralock, L. G. Shapiro, Computer and robot vision, Addison-WesleyLongman Publishing Co., Inc., 1991.765[38] C.-C. Chang, C.-J. Lin, Libsvm: a library for support vector machines,ACM Transactions on Intelligent Systems and Technology (TIST) 2 (3)(2011) 27.[39] Y. Song, W. Cai, D. D. Feng, Microscopic image segmentation with two-level enhancement of feature discriminability., in: International Conference770on Digital Image Computing: Techniques and Applications (DICTA), 2012,pp. 1–6.[40] Y. Song, W. Cai, D. D. Feng, M. Chen, Cell nuclei segmentation in fluo-rescence microscopy images using inter-and intra-region discriminative in-formation, in: Engineering in Medicine and Biology Society (EMBC), 35th775Annual International Conference of the IEEE, IEEE, 2013, pp. 6087–6090.[41] Y. Song, W. Cai, H. Huang, Y. Wang, D. D. Feng, Object localizationin medical images based on graphical model with contrast and interest-region terms, in: Computer Vision and Pattern Recognition Workshops(CVPRW), IEEE Computer Society Conference on, IEEE, pp. 1–7.780[42] Y. Song, W. Cai, H. Huang, Y. Wang, D. D. Feng, M. Chen, Region-based progressive localization of cell nuclei in microscopic images with dataadaptive modeling, BMC Bioinformatics 14 (1) (2013) 173.37[43] S. M. Smith, Bet: brain extraction tool, FMRIB TR00SMS2b, Oxford Cen-tre for Functional Magnetic Resonance Imaging of the Brain), Department785of Clinical Neurology, Oxford University, John Radcliffe Hospital, Head-ington, UK.[44] C. Goodall, Procrustes methods in the statistical analysis of shape, Journalof the Royal Statistical Society. Series B (Methodological) (1991) 285–339.[45] S. Zhang, Y. Zhan, M. Dewan, J. Huang, D. N. Metaxas, X. S. Zhou, De-790formable segmentation via sparse shape representation, in: Medical ImageComputing and Computer-Assisted Intervention–MICCAI 2011, Springer,2011, pp. 451–458.[46] C. Florin, N. Paragios, G. Funka-Lea, J. Williams, Liver segmentationusing sparse 3D prior models with optimal data support, in: Information795Processing in Medical Imaging, Springer, 2007, pp. 38–49.[47] Y. Gao, S. Liao, D. Shen, Prostate segmentation by sparse representationbased classification, Medical Physics 39 (10) (2012) 6372–6387.[48] G. Gill, M. Toews, R. R. Beichel, Robust initialization of active shapemodels for lung segmentation in CT scans: A feature-based atlas approach,800International Journal of Biomedical Imaging 2014.[49] D. L. Donoho, Y. Tsaig, I. Drori, J.-L. Starck, Sparse solution of under-determined systems of linear equations by stagewise orthogonal matchingpursuit, Information Theory, IEEE Transactions on 58 (2) (2012) 1094–1121.805[50] S. Umeyama, Least-squares estimation of transformation parameters be-tween two point patterns, IEEE Transactions on Pattern Analysis and Ma-chine Intelligence 13 (4) (1991) 376–380.[51] S. W. Smith, ”Moving average filters”, in The Scientist and Engineer’sGuide to Digital Signal Processing, California Technical Pub. San Diego,8101997, Ch. 15, pp. 277–284.38[52] C. Li, C. Xu, C. Gui, M. D. Fox, Distance regularized level set evolutionand its application to image segmentation, Image Processing, IEEE Trans-actions on 19 (12) (2010) 3243–3254.[53] Overlapping Cervical Cytology Image Segmentation Challenge-ISBI 2014,815http://cs.adelaide.edu.au/~carneiro/isbi14_challenge/.[54] D. Ushizima, A. Bianch, C. Carneiro, Segmentation of subcellular com-partiments combining superpixel representation with voronoi diagrams, in:ISBI Overlapping Cervical Cytology Image Segmentation Challenge, IEEE,2014, pp. 1–2.820[55] M. Nosrati, G. Hamarneh, A variational approach for overlapping cell seg-mentation, in: ISBI Overlapping Cervical Cytology Image SegmentationChallenge, IEEE, 2014, pp. 1–2.[56] Z. Lu, G. Carneiro, A. Bradley, D. Ushizima, M. Nosrati, A. Bianchi,C. Carneiro, G. Hamarneh, Evaluation of three algorithms for the seg-825mentation of overlapping cervical cells., IEEE Journal of Biomedical andHealth Informatics, 2016.[57] The Second Overlapping Cervical Cytology Image Segmentation Challenge-ISBI 2015, http://cs.adelaide.edu.au/~zhi/isbi15_challenge/.39