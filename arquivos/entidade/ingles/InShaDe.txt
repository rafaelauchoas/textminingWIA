InShaDe: Invariant Shape Descriptors for visual 2D and3D cellular and nuclear shape analysis and classificationItem TypeArticleAuthorsCitationAl-Thelaya, Khaled; Agus, Marco; Gilal, Nauman Ullah; Yang, Yin;Pintore, Giovanni; Gobbetti, Enrico; Calí, Corrado; Magistretti,Pierre J.; Mifsud, William; Schneider, JensAl-Thelaya, K., Agus, M., Gilal, N. U., Yang, Y., Pintore, G.,Gobbetti, E., … Schneider, J. (2021). InShaDe: Invariant ShapeDescriptors for visual 2D and 3D cellular and nuclear shapeanalysis and classification. Computers & Graphics, 98, 105–125.doi:10.1016/j.cag.2021.04.037Eprint versionPublisher's Version/PDFDOI10.1016/j.cag.2021.04.037PublisherElsevier BVJournalComputers & GraphicsRightsThis is an open access article under the CC BY license.Download date03/07/2023 23:37:36Item Licensehttp://creativecommons.org/licenses/by-nc-nd/4.0/Link to Itemhttp://hdl.handle.net/10754/669717Computers & Graphics 98 (2021) 105–125 Contents lists available at ScienceDirect Computers & Graphics journal homepage: www.elsevier.com/locate/cag Special Section on VCBM 2020 InShaDe: Invariant Shape Descriptors for visual 2D and 3D cellular and nuclear shape analysis and classification Khaled Al-Thelaya a , 1 , Marco Agus a , ∗, Nauman Ullah Gilal a , Yin Yang a , Giovanni Pintore b , Enrico Gobbetti b , Corrado Calí c , Pierre J. Magistretti d , William Mifsud e , Jens Schneider a a College of Science and Engineering, Hamad Bin Khalifa University, Qatar Foundation, Doha, Qatar b Visual Computing Group, Center for Advanced Studies, Research and Development in Sardinia (CRS4), Cagliari, Italy c Department of Neuroscience ”Rita Levi Montalcini”, Neuroscience Institute ”Cavalieri Ottolenghi”, University of Turin, 10043, Turin, Italy d Biological and Environmental Sciences and Engineering Division, King Abdullah University of Science and Technology, Saudi Arabia e Sidra Medicine, Qatar Foundation, Doha, Qatar a r t i c l e i n f o a b s t r a c t Article history: Received 29 January 2021 Revised 28 April 2021 Accepted 29 April 2021 Available online 7 May 2021 Keywords: Shape analysis Histopathology Serial section electron microscopy Nuclear envelopes Discrete differential geometry We present a shape processing framework for visual exploration of cellular nuclear envelopes extracted from microscopic images arising in histology and neuroscience. The framework is based on a novel shape descriptor of closed contours in 2D and 3D. In 2D, it relies on a geodesically uniform resampling of dis- crete curves to compute unsigned curvatures at vertices and edges based on discrete differential geome- try. Our descriptor is, by design, invariant under translation, rotation, and parameterization. We achieve the latter invariance under parameterization shifts by using elliptic Fourier analysis on the resulting cur- vature vectors. Uniform scale-invariance is optional and is a result of scaling curvature features to z- scores. We further augment the proposed descriptor with feature coefficients obtained through sparse coding of the extracted cellular structures using K-sparse autoencoders. For the analysis of 3D shapes, we compute mean curvatures based on the Laplace-Beltrami operator on triangular meshes, followed by computing a spherical parameterization through mean curvature flow. Finally, we compute the Spheri- cal Harmonics decomposition to obtain invariant energy coefficients. Our invariant descriptors provide an embedding into a fixed-dimensional feature space that can be used for various applications, e.g., as input features for deep and shallow learning techniques or as input for dimension reduction schemes to pro- vide a visual reference for clustering shape collections. We demonstrate the capabilities of our framework in the context of visual analysis and unsupervised classification of 2D histology images and 3D nuclear envelopes extracted from serial section electron microscopy stacks. © 2021 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ ) 1. Introduction The last decades have witnessed the rapid improvement and proliferation of high-throughput digital acquisition technology. As a result, high-quality digital representations of real-world scenes and objects have become commonplace in many application domains. In biology and medicine in particular, the rise of whole-slide scan- ners and the digitization of traditional, confocal, and electron mi- croscopy has led to both fully digital analysis and the creation of large image databases [1] . Early uses of this technology mostly included tele-pathology, solicitation of second opinions, and ed- ∗ Corresponding author. E-mail addresses: magus@hbku.edu.qa (M. Agus), jeschneider@hbku.edu.qa (J. Schneider). 1 All authors contributed equally to the project. ucation in research and clinical practice, as well as visual ultra- structural analysis in neuroscience. In most cases, digital workflows were designed to closely mimic the traditional investigation pro- cess. Only recent years saw a shift towards exploiting the large amount of information in the acquired images and collections by means of novel data-driven analysis methods [2] . In this context, a wide array of basic tools are employed, ranging from handcrafted feature descriptors over fully data-driven approaches to combina- tions of matching of various approaches [3] . Machine learning, and, especially, deep learning approaches have become popular in the context of digital pathology and biology. Their significant success stems from their ability to provide automatic tools for tasks such as segmentation and labeling of cellular entities from large indi- vidual microscope images [4,5] or for supporting connectomics in- vestigations by reconstructing the neural connections in large por- tions of brain tissue samples [6,7] . One drawback of the current https://doi.org/10.1016/j.cag.2021.04.037 0097-8493/© 2021 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ ) K. Al-Thelaya, M. Agus, N.U. Gilal et al. Computers & Graphics 98 (2021) 105–125 Fig. 1. InShaDe pipeline: from cell contours extracted from digital histology images (on top) or 3D shapes reconstructed from Serial Section Electron Microscopy stacks (on bottom), our pipeline computes invariant energy-based Fourier descriptors on top of discrete curvature embeddings. These synthetic descriptors can be used for visual analysis, proof-reading segmentation results, domain-specific clustering and classification according to specific taxonomies. purely data-driven frameworks, however, is that they often disre- gard specific domain knowledge and taxonomies [8] . As a result, tools for domain-specific proofreading of segmented images, clas- sification according to taxonomies, filtering, visual exploration, and subsequent computation are still lacking. For this reason, many ap- plications require the use of descriptors that, by design, preserve some domain-specific characteristics. To better exploit the capabil- ities of novel learning frameworks we thus advocate not to dismiss designing features a priori. Instead, we believe that it is necessary to research the development of methods integrating such designed features into powerful descriptive models. One benefit of taking a hybrid design+data-driven approach is that domain knowledge can be integrated into the design process. This potentially leads to models that are easier to explain, and, thus, result in increased dis- crimination performance for human analysis. In addition, since fea- tures are designed, the training effort s in terms of the amount of data and computational power required can be eased. Inspired by these considerations, we propose a novel visual analysis pipeline based on discrete differential geometry concepts, whose recent findings provide very powerful theoretical formula- tions for describing 2D and 3D shapes [9,10] . The framework is based on a 2D/3D shape descriptor that can be used in various ap- plication domains to complement or enhance generic deep learn- ing networks, such as U-Net [11] . The descriptor, dubbed InShaDe , is based on the concept of discrete curvature along closed, resam- pled contours (see Fig. 1 for an overview of the proposed pipeline). In 2D, discrete curvature is computed using vertex and edge os- culating circles. Interleaving the resulting edge and vertex curva- tures produces a high-resolution curvature vector. These curvature vectors are naturally invariant under rigid body transformations (translations and rotations). Invariance under parametric shifts is ensured by using energy-based elliptic Fourier descriptors. Cellular shapes in 2D tissue samples are sliced, implying that their appar- ent size may be smaller than the real radius [12] . We therefore also propose to achieve optional invariance under uniform scaling by replacing components in the curvature vectors by standard (z- )scores. This manuscript is an extended version of the conference contribution [13] recently presented at the Eurographics Workshop on Visual Computing for Biology and Medicine (EG VCBM 2020) held in Tübingen. The conference paper presented: (i) a robust geometry processing pipeline for computing 2D in- variant shape descriptors exploiting shifted linear interpola- tion and discrete differential geometry schemes, and (ii) visual mapping schemes from 2D cellular contours to shape descriptor embeddings based on modern dimension reduc- tion schemes such as UMAP [14] . This manuscript extends the original pipeline by: (iii) extending the shape descriptors to 3D shapes represented by triangle meshes, and (iv) augmenting the shape descriptors by additional features based on sparse coding to improve analysis and classification perfor- mance. In addition, we study the use of the proposed pipeline for proofreading and visual, unsupervised classification of various his- tology images. We also present results for various 2D and 3D data sets stemming from histology and neuroscience. 2. Related work Our work is concerned with shape feature extraction from closed contours and surfaces and with the analysis of histopathol- ogy images and electron microscopy stacks. These are very broad topics and a full coverage of the state-of-the-art is beyond the scope of this paper. For a comprehensive overview of all related fields, we refer the reader to various surveys on 2D shape analy- sis [3,15] , digital histopathology analysis [16–18] , and recent deep learning methods for cellular analysis [19] . In the following, we discuss the methods that are most closely related to our approach. 2.1. Shape feature descriptors During the last two decades, significant research efforts have been carried out on both the theoretical and the practical aspects of the shape-based image retrieval problem [3] . For an overview of the seminal methods for shape-based invariant feature extraction for object recognition, we refer also to Yang et al. [20] . In general, there are two main modeling strategies for repre- senting shapes: region-based methods and boundary-based ones. Region-based techniques use moment descriptors to describe shapes, like geometrical moments [21] , Zernike moments [22,23] , Legendre moments [24] , and Tchebichef moments [25] . Although region-based approaches are global in nature and can be applied to generic shapes, boundary-based techniques appear to be more efficient for handling objects that can be described by their object contours. In this latter category, a number of boundary-based tech- niques have been proposed, including Fourier descriptors [26] , cur- vature scale space [27] , and wavelet descriptors [28] . Our descrip- tor combines the features of curvature analysis and Fourier analy- sis, similarly to the technique proposed by El Ghazal et al. [29,30] . Differently from them, our method is based on recent findings in discrete differential geometry [31] , thus resulting in a more robust 106 K. Al-Thelaya, M. Agus, N.U. Gilal et al. Computers & Graphics 98 (2021) 105–125 formulation with respect to the sampling strategy and better clas- sification results. Moreover, Osjanikov et al. applied the concepts of invariant features in the 3D world to the problem of non-rigid shape search and retrieval in large databases [32] . Complementing advances for the general classification prob- lem, machine learning strategies exploiting the existence of large amounts of data have led to significant advances [33,34] . Many cur- rent efforts attempt to work directly on raw data images [35,36] , by designing deep neural networks in which the modeling is hid- den in the network design and training strategy and the fea- ture computation and filtering of information is automatically per- formed by the network. At the same time and in an attempt to simplify classification and automatic shape generation, techniques to reduce the depth of networks by introducing meaningful pa- rameterizations or embeddings of input shapes are gaining inter- est, since such parameterizations can simplify the automatic clas- sification or shape generation (model-based or “shallow” learning) and reduce the number of training examples [37] . Our work goes towards that direction, since we propose a simplified contour de- scription that can be used either for supporting machine learning frameworks or for supervised visual analysis. In this work, we fo- cus on the latter aspect. 2.2. Histology analysis Digital pathology and microscopy-image analysis is widely used in the biomedical domain for comprehensive studies of cell mor- phology or tissue structure. In most cases, analysis is carried out through manual assessment, which is labor-intensive and prone to inter-observer variations. Computer-aided systems have recently attracted significant interest since they can dramatically reduce the manual effort s and increase reproducibility [17,38,39] . Among the various parts composing a computer-aided diagnos- tic system, nucleus or cell detection and segmentation play a key role to describe the molecular and morphological information un- derlying the investigated samples [17,40] . In the past few decades, many effort s have been devoted to automated nucleus/cell detec- tion and segmentation, and an independent field named compu- tational pathology emerged simultaneously to the rapid prolifer- ation of deep learning (DL) models for quantitative analysis of spatial patterns in digitized whole-slide images (WSIs) of cancer- ous tissue [41] . To this end, various techniques for the detection, extraction, recognition of pathological patterns at various scales have been recently established [42–44] . Various medical studies have since demonstrated the potential of DL models in detect- ing neoplastic tissue and recognizing diagnostically relevant struc- tures [44,45] . One of the most successful and widely used architecture is U- Net, introduced in 2015 by Ronneberger et al. [11] . U-Nets operate on the entire image and jointly segment and provide per-pixel la- bels, leading to an improvement in spatial segment and label co- herence. The same authors also demonstrate that U-Nets improve accuracy on several bio-image segmentation tasks, even when the data set is relatively small [11] . In the context of nuclear segmen- tation of histopathology images, Chidester et al. [4] enhance U- Nets by enforcing rotation-equivariance to groups, similar in style to group-equivariant CNNs (GCNNs) [46] . Moreover, in order to attract efforts to particular tasks in med- ical imaging, various challenge contests and public data sets have been published [41,47] . However, as of this writing, such methods are still far from being accepted in fully automated clinical work- flows [48] . Proofreading efforts from domain scientists are, thus, still required to double-check labeling consistency and segmenta- tion accuracy [8] . Consequently, the work presented herein provides a visual anal- ysis framework that supports digital histologists to efficiently carry out investigations on labeling and segmentation quality. Our input data is the automatic segmentation obtained from networks of the U-Net family [4] . The proposed framework then allows for visual analysis in a reduced parameter space obtained by performing di- mension reduction on our Fourier-based contour shape descriptor. To properly capture the visual variance of nuclear shapes under dimension reduction, autoencoders [49] provide a convenient way to effectively uncover latent feature spaces. It is thus no surprise that their use is increasing in popularity [50,51] . For instance, Xu et al. propose Stacked Sparse Autoencoders [50] to learn high-level features from pixel intensities. They are then applied to high res- olution breast cancer histopathology images. Hou et al. [51] mod- ify the general autoencoder scheme by applying adaptive convolu- tional filters to match the size of the nuclei to be represented. In this work, we use k-sparse autoencoders [52] to produce feature vectors that describe the inner visual features of nuclei. We then use these feature vectors to augment our proposed shape descrip- tor, resulting in a description of the exterior (shape descriptor) and interior (auto-encoder) of each nucleus. 2.3. Shape analysis in neuroscience Recent advances in imaging technology have led to the avail- ability of 3D sparse and dense reconstructions of brain cells at high resolution. This, in turn, has fueled the development of var- ious methods for shape analysis in the context of automatic clas- sification to aid studying the variability associated with different structures and conditions [53,54] . Likewise, the availability of high- resolution imaging data has also triggered shape analysis stud- ies of brain structures at the nanometer scale [54–56] . For in- stance, Queisser et al. [57] propose a method to reconstruct the 3D view of cell nuclear envelopes from laser scanning confocal microscopy data. Wittmann et al. [58] later use this method to show how synaptic activity induces significant modifications in the geometry of the cell nucleus. To study heterogeneities in nu- clear shapes obtained through optical projection tomographic mi- croscopy, Nandukumar et al. [59] use conformal mapping to extract rotation-invariant shape descriptors. Finally, Agus et al. [60,61] per- form classification of nuclear brain cells through implicit and ex- plicit shape representations of cell nuclei obtained from electronic- imaging data. They demonstrate an improvement in terms of classification accuracy over previous approaches based on simple spherical or ellipsoidal fittings. In this paper, we improve existing work [61] by introducing fea- ture vectors based on the spherical harmonics spectrum of mean curvatures. This reduces the amount of data serving as the descrip- tor from three complex vectors to a single real-valued vector, re- sulting in faster implementation and processing times. 3. Methodology overview Fig. 1 schematically summarizes the InShaDe framework. As can be seen, we use two separate yet similar pipelines for 2D and 3D closed nuclear envelopes that use different microscope imag- ing techniques as data source. The two methods have important similarities: • they use the curvature signal (planar curvature in the 2D case, mean curvature in the 3D case), • they involve parametrization (circular parametrization in the 2D case, and spherical parametrization in the 3D case), • they involve Fourier analysis (Elliptic Fourier Analysis in the 2D case, and Spherical Harmonics decomposition in the 3D case), It is worth noticing that the Spherical Harmonics framework is a 3D generalization of the Elliptic Fourier Analysis [62] , • they use the same strategy for computing energy descriptors according to the harmonic frequencies [63] . 107 K. Al-Thelaya, M. Agus, N.U. Gilal et al. Computers & Graphics 98 (2021) 105–125 Overview of InShaDe 2D The input to the InShaDe 2D pipeline are segmented nuclear envelopes of cells obtained by applying an U-Net [4] on microscopic histopathology images (see Fig. 1 top). We then extract closed contours ( Section 4.1 ) from each segmen- tation mask and perform the following processing steps (see also Fig. 1 , top): (1) contour smoothing ( Section 4.2 ), (2) geodesically uniform resampling ( Section 4.3 ), (3) discrete curvature computation ( Section 4.4 ), (4) opt. feature scaling using standard (z-)scores ( Section 4.5 ), (5) embedding to constant dimensions ( Section 4.6 ), (6) elliptic Fourier analysis (“EFA”, Section 4.7 ). Contour smoothing serves to reduce pixelation noise, whereas geodesically uniform resampling removes sampling biases and is a pre-requisite to computing discrete curvatures using discrete dif- ferential geometry formulations using osculating circles. Embed- ding the resulting descriptors in constant dimensions helps in re- moving noise and spurious frequencies during the EFA stage, but is also necessary to allow for easy comparison between shapes us- ing, e.g., cosine or Euclidean metrics. The Fourier analysis is used to remove shift (i.e., choice of origin) from the parameterization of the closed curve. So far the resulting descriptor is invariant un- der translation and rotation (3) and invariant under parameteri- zation shift (6). In addition, the optional feature scaling step (4) ensures invariance under uniform scaling. In the result section, we furthermore show how the final descriptor can be used in combi- nation with dimension reduction schemes for visualizing clusters of nuclear shapes with similar geometric characteristics. Overview of InShaDe 3D The input of the InShaDe 3D pipeline are closed triangular meshes extracted from image stacks obtained through Serial Section Electron Microscopy acquisition of samples from ro- dent brains [54] . These shapes represent the envelopes of brain cell nuclei and are obtained from images through a processing pipeline involving automatic segmentation tools as well as manual proof- reading tools [64] . We then process the 3D meshes by performing the following operations (also see Fig. 1 , bottom): (1) discrete mean curvature computation ( Section 5.1 ), (2) spherical parameterization using Willmore flow ( Section 5.2 ), (3) spherical harmonics decomposition ( Section 5.3 ), (4) computation of invariant energy coefficients ( Section 5.4 ). We use discrete mean curvature (1) as the basis of our embed- ding and to represent the features of 3D shapes. In contrast to pre- vious formulations of shape decomposition [60,61] , the proposed embedding is based on a single scalar- and real-valued function on the spherical domain. The result is a simpler numerical formula- tion involving only the real part of Spherical Harmonics (SPH) as well as a significantly lower number of coefficients. From the co- efficients of a truncated SPH decomposition, we then compute in- variant energy coefficients. In the result section ( Section 6.4 ), we show how the obtained descriptor can be used for shallow classi- fication of nuclei representing brain cells from different layers of somatosensory cortex of adult rodents. 4. InShaDe 2D In this section, we provide details for the various processing steps for computing the descriptor for closed shapes extracted from 2D images. 4.1. Contour extraction & chordal parameterization Given a segmentation mask, we extract a closed contour en- veloping each nucleus using isocontouring (specifically Marching 108 Squares, which is a special case of the Marching Cubes algo- rithm [65] ). We reject open contours (i.e., the nucleus intersects the image boundary) and contours falling into the lowest 5% with i } N respect to their number of samples. Let C := { p 1 , a closed curve i , the i th edge, consis- i . We let (cid:2)with N vertices p tent with Bobenko [31] , and abbreviate l 2 (edge length). We then obtain an initial chordal parameterization t ( C ) with t 1 := t ( p 1 ) = 0 and t i +1 := t ( p i +1 ) = (cid:3) (cid:2)i ∀ i > 1 . i := (cid:3) (cid:2)i +1 − p i := p i (cid:3) i (cid:3) 2 + t 4.2. Contour smoothing The discrete nature of binary segmentation masks may lead to pixelation artifacts in the extracted contour. To prevent the result- ing high spikes in curvature, we pre-smooth contours iteratively, using a superscript (cid:3) (k ) to denote quantities at iteration k . The pro- cess is shown in Fig. 2 . Specifically, we replace each vertex with a length-weighted average of the bisector of adjacent edges, (k +1) p i = (cid:2)(k ) l i p (k ) i +1 (cid:3)(k ) + p i (cid:2)(k ) l 2 i + l + l (cid:2)(k ) (k ) p i −1 i (cid:3)(k ) i −1 (cid:3)(k ) i −1 + p . (1) i , p As shown by Gottschalk [66] , this sum of length-weighted edge bisectors computes the barycenter of the points on the piecewise i −1 , p i +1 . Since it is a 2-stage convex linear curve segment p i , p combination of p i +1 , it is numerically stable and robust. Similar to virtually all smoothing operators, this does not yet pre- serve area. We therefore compute the area a (0) enclosed by the curve prior to smoothing and the area a (k ) after each iteration. We then scale the curve by (cid:4) i −1 , p (k ) p i (k ) ← p i a (0) . a (k ) 4.3. Geodesically uniform resampling (2) In order to remove sampling bias and to employ discrete dif- ferential geometry formulations for vertex and edge curvature, we perform geodesically uniform resampling. We do so by placing equidistant samples (cid:5) p on the piece-wise linear curve C, thereby yielding a new piece-wise linear curve (cid:5) C that is Arc-length param- eterized with respect to a unit scale u . Starting at a point p 1 = (cid:5) p 1 and u = 1 , we intersect the edges of (cid:5) C with a unit circle around p 1 . This yields between zero and two intersection. If we find two intersections, we select one intersection as (cid:5) p 2 and keep track of the last edge, (cid:5) (cid:2)1 = (cid:5) p 2 − (cid:5) p 1 . We then continue intersecting linear segments with unit spheres, but when deciding on (cid:5) p (cid:6)i , we chose (cid:5) (cid:2)i defined anal- the intersection that maximizes ogously to (cid:5) (cid:2)1 . This enforces progress along the curve and prevents jumping back and forth on the curve. For our data, we did not en- counter the case of finding less than two circle-curve intersections. A total of zero intersections would correspond to extremely small contours that cover less than a few pixels after processing; and we remove the bottom 5% shortest curves. One crossing would arise if part of the contour degenerates into a double line segment; March- ing Squares does not extract such pathological curves. (cid:7), with (cid:5) (cid:2)i −1 i , (cid:5) (cid:2)Once the best intersection (cid:5) p (cid:5) N “laps” past (cid:5) p 1 , we use (cid:5) p (cid:5) N = (cid:5) p 1 instead to close the loop. This means that the last edge (cid:5) (cid:2)(cid:5) N −1 may be shorter than unit length. In order to resolve this issue, we now calculate the length L of the curve. Knowing that (cid:3) (cid:5) (cid:2)i (cid:3) 2 = u for (cid:2)N (cid:3) 2 . To obtain an all but the last edge, we have L = u for which u −1 L is approximately integral, we round u −1 L to the nearest integer L (cid:6) and update u ← L (cid:6) −1 L . (cid:3)u + (cid:3) (cid:5) (cid:2)(cid:5) (cid:5) N − 2 We then revert to placing samples along the original curve C with the updated spacing u . We repeat this process until the rounding error ρ = | u −1 L − L (cid:6) | (using the old u and the updated L (cid:6) ) becomes negligibly small. While we do not have a proof of K. Al-Thelaya, M. Agus, N.U. Gilal et al. Computers & Graphics 98 (2021) 105–125 Fig. 2. Contour smoothing: we apply iterative contour smoothing to the closed contours (here, N = 271) extracted from histology images. The higher the number of iteration steps, the smoother the contours: in the example, 2, 5,10, 20 steps respectively. desired. This is achieved by dividing each κv and κe by u 2 . Fi- nally, we interleave vertex and edge curvatures to obtain a high- resolution, coherent descriptor. After this step, we also abandon the notion of curvature “living” on vertices and edges and tran- sition to the notion that the shape descriptor computed so far is a vector in a high-dimensional vector space. We also adopt the no- tion that this vector represents a 1D periodic signal on a uniform grid on the 2D circle. This interpretation is crucially supported by the fact that all edges have the same length prior to computing curvature. The descriptor computed so far is invariant under trans- lation and rotation, but neither parametric shift nor scale. We now establish the optional scale-invariance followed by shift-invariance. 4.5. Feature scaling Given a sequence of curvatures, { κscores (also called z-scores) by mapping i } 2 (cid:5) N i =1 , we compute standard κi ← κi − μκσκ, where μκ = 1 2 (cid:5) N 2 (cid:5) N (cid:8) i =1 κi and σκ = 1 2 (cid:5) N − 1 2 (cid:5) N (cid:8) i =1 ( κi − μκ ) 2 (6) (7) are the empiric mean and variance, respectively. Such a scaling is commonly employed in statistics as well as in training convo- lutional neural networks. However, normally standard scores are computed using global moments derived from the entire data set. This, in turn, does not provide full scale-invariance, since vectors with pre-dominantly small components will stay small. In con- trast, by computing individual standard scores we enforce the op- tional scale-invariance of our descriptor. Assuming that the curva- ture components of each vector are normal-distributed results in the expectation that all but 0.2% of the data is represented by z- scores in the range [ −3 , 3] . Fig. 3. Discrete curvatures: following discrete differential geometry [31] we com- pute discrete curvatures by considering vertex osculating circles (left), and edge os- culating circles (right). convergence of this heuristic at the time, we note that the rest of our method is orthogonal to this Arc-length parameterization. This means that, in the future, as more robust methods become available, this step can be exchanged. In all of our experiments, three to five iterations reduced ρ to less than 10 −4 . Given any number x ∈ R + , rounding to the nearest integer changes x by 0.25 on average. We therefore expect that | 1 − u | ≈ 0 . 25 L −1 , which we see confirmed in our experiments with typical contour lengths of more than 100 pixel widths (for reference, L = 100 → | 1 − u | ≈2 . 5 × 10 −3 ). The result of this step is a new piece-wise linear curve (cid:5) C that is Arc-length parameterized with respect to a close-to-unit scale u . 4.4. Discrete curvatures For a discrete Arc-length parameterized curve, there are two definitions of discrete curvature based on osculating circles [31] (Sec. 2.3 therein). By defining the turning angle at vertex p i as φi ≡ arccos (cid:11) (cid:2)i , (cid:2)i −1 (cid:12) , and by embedding the planar curve in the z = 0 plane (see also Fig. 3 ), we obtain, assuming for now an Arc-length parameteriza- tion with (cid:3) (cid:2)i (cid:3) = 1 for all i , the (unsigned) vertex curvature : (3) κv = 2 | sin ϕ i | (cid:3) p i +1 − p i −1 (cid:3) 2 = 2 (cid:3) (cid:2)i × (cid:2)i −1 (cid:3) 2 . (cid:3) (cid:2)i + (cid:2)i −1 (cid:3) 2 For the edge curvature we use the standard equation [31] : κe = tan φi 2 + tan φi +1 . 2 (4) (5) The choice to use unsigned vertex curvature was made to be con- sistent with the unsigned edge curvature. Using such a discrete differential geometry approach results in much more robust and stable curvature estimates than by using an intermediate interpo- lating spline. A reason may be that splines tend to over- and undershoot near vertices, and are thus not representative of the curvature in these points. Since one of our goals for the final shape descriptor is op- tional scale-invariance, we still have to scale curvatures back from our arbitrary unit length u to u = 1 in case scale-invariance is not 4.6. Constant dimensionality Resampling the contour to a constant dimensionality as de- picted in Fig. 4 allows us to control the number of elliptic har- monics in our Elliptic Fourier Analysis in a way to agree with the Nyquist sampling constraint. It is also a pre-requisite for easy com- parison of shape descriptors using, e.g., cosine and Euclidean met- rics. As an added side-benefit, it also allows us to eliminate remain- ing traces of noise on the curve. In this paper, we perform this resampling step based on shifted-linear interpolation [67] for the following reasons: (i) shifted linear interpolation achieves perfor- mances that compare favourably to cubic interpolation at a much lower computational cost, (ii) shifted-linear interpolation is still convex, albeit with respect to shifted samples. It is thus free of oscillations and the amount of foreign frequencies introduced by resampling can be computed easily. 109 K. Al-Thelaya, M. Agus, N.U. Gilal et al. Computers & Graphics 98 (2021) 105–125 Fig. 4. Resampling to constant dimension: to reduce noise and spurious frequencies during the Fourier analysis and to enforce constant dimensionality of our descriptor, we apply uniform resampling through shifted linear interpolation [67] . In this example, we show resampling with 64, 32 and 16 points respectively. The basic idea of shifted-linear interpolation is to sample the original signal at positions other than the original underlying sam- pling grid, followed by standard linear interpolation. Blu et al. prove, somewhat surprisingly, that there is a data-independent and thus constant shift τ ≈ 0 . 21 that results in L 2 −optimal reconstruc- tion of the unknown original signal given only the known sam- ples [67] . Samples κ (cid:6) i at shifted positions t (cid:6) i are obtained using the infinite impulse response scheme described by Blu et al., τ1 − τ1 1 − τκi . κ (cid:6) i −1 + κ (cid:6) i = −It should be noted, however, that linear interpolation on κ (cid:6) is lit- erally shifted “to the right” by τ , meaning that a sample κ (cid:6) (t) cor- responds to κ (t − τ ) . The resulting interpolation thus becomes a shifted discrete convolution of the hat kernel (8) (cid:9)(cid:10)(t) := 1 − | t| if | t| < 1 0 otherwise , with the shifted discrete signal κ (cid:6) : κ (t) = κ (cid:6) i (cid:10)(t − t i − τ ) . (cid:8) i 4.7. Elliptic fourier analysis (EFA) To achieve shift-invariance (i.e., invariance under choice of para- metric origin), we consider the Fourier spectrum of each given curve. In particular, we compute elliptic Fourier descriptors [62] , similarly to what was proposed by Khazhdan et al. [63] and what has been successfully used in various applications [12,60,61] . For a piecewise linear, periodic function κ (t) t ∈ [0 , 2 π ] repre- senting the curvature of a contour, its Fourier elliptic expansion is obtained through linear combination of elliptic harmonics func- tions which provide a complete orthonormal basis for the decom- position κ ( t ) = a 0 + (cid:10)∞ (cid:8) n =1 (cid:10)a n cos (cid:11)2 π nt T (cid:10)+ b n sin 2 π nt T (cid:11)(cid:11). (11) In order to compute the coefficients for the curvature function κ ( t ) representing closed contours, we normalize the parameteri- zation t to the interval [0 , 2 π ] . As we are concerned with closed contours, the assumption of periodicity, t = 0 ≡ 2 π is naturally supported. We then consider the classic method proposed by Kuhl and Giardina [68] for piecewise linear contours. This method essentially equates the discrete time derivative of Eqn. (11) , at locations p i , (cid:12)(cid:12)∂κ(cid:12), thus , (cid:12)∂t t i (cid:10)∞ (cid:8) ˙ κi := (12) (cid:11)(cid:11)2 π n T (cid:10)sin (cid:11)2 π nt i T −a n (cid:10)cos 2 π n T 2 π nt i T + b n ˙ κi = , n =1 (9) (10) with a Fourier expansion of the time derivative of the curvature, ˙ κi = (cid:10)∞ (cid:8) n =1 (cid:10)αn cos (cid:11)2 π nt i T (cid:10)+ βn sin 2 π nt i T (cid:11)(cid:11). (13) Noting that in Eqn. (13) , the coefficients αn and βn can be computed as αn = βn = 2 T 2 T N (cid:8) i =1 N (cid:8) (cid:10)˙ κi (cid:10)˙ κi (cid:10)sin (cid:11)2 π nt i T (cid:10)cos (cid:11)2 π nt i T (cid:10)− sin (cid:11)(cid:11)2 π nt i −1 T and (cid:10)− cos (cid:11)(cid:11)2 π nt i −1 T , (14) i =1 Kuhl and Giardina derive the following for the n th harmonic, by equating the two different derivative expressions in Eqn. (12) and (13) : a n = − 1 π n N (cid:8) (cid:10)˙ κi (cid:10)cos (cid:11)2 π nt i T (cid:10)− cos (cid:11)(cid:11)2 π nt i −1 T , b n = - 1 π n (cid:10)˙ κi (cid:10)sin (cid:11)2 π nt i T (cid:10)− sin (cid:11)(cid:11)2 π nt i −1 T . (15) i =1 N (cid:8) i =1 We would like to remind here that, according to the Nyquist theorem, the number N s of contour samples after smoothing and (cid:3)h of harmonics necessary to re- resampling limits the number N h ≤ N s . N construct the contour curvature without adding noise 2 Finally, in order to obtain shift-invariance, we compute harmonic energies through the Euclidean norm of the harmonic coeffi- cients [63] , resulting in the following Curvature Fourier Descriptor K with (cid:13) (cid:2)K n = n + b 2 a 2 n , (16) which provides a vector of shape features that can be used for var- ious machine learning applications. Like the more commonly em- ployed traditional Fourier transform, the elliptic Fourier transform results in a space-agnostic spectrum, thereby making our descrip- tor invariant under parameter shift (translation of the underlying domain). In this paper, we chose the elliptic Fourier transform over the traditional Fourier transform since its additional expressiveness resulted in better results. Fig. 5 demonstrates both rotation- and shift-invariance. Sorted curvatures We also consider another, much simpler scheme for obtaining shift-invariance, namely, to sort the individ- ual (unsigned) curvatures from highest to lowest (see also Fig. 6 ). The feature vector obtained in this way can be further augmented with energy-based coefficients to obtain a composite feature vec- tor. We would like to note that, in our experience, sorted descrip- tors are outperformed by spectral descriptors if used in stand- alone fashion. Sparse-coding based image descriptors Finally, we consider a compact descriptor of images represent- ing cellular structures obtained through sparse coding. To provide 110 K. Al-Thelaya, M. Agus, N.U. Gilal et al. Computers & Graphics 98 (2021) 105–125 Fig. 5. Invariant descriptor: the discrete curvature formulation of InShaDe descriptor is by design invariant to rotations (middle row), while the derive frequency-based energy descriptors are invariant also with respect to shift (bottom row). additional shape cues for this case, we place the segmented nu- clei on a black background, as shown in Fig. 7 , left. Sparse cod- ing methods are typically composed of two steps. Firstly, an offline learning process for finding a dictionary W that sparsely represents the image data { I i } N i =0 , and, secondly, an encoding step that maps a given input image I to a compressed feature vector ˆ x using W , nor- mally through a pursuit algorithm for minimizing the constrained least squares problem ˆ x = arg min (cid:3) I − W x (cid:3) 2 2 , s.t. (cid:3) x (cid:3) 0 < k. x (17) For obtaining the codebook (see also Fig. 7 , center) and creating the approximated sparse representation of nuclei images ( Fig. 7 , right), we use the K-sparse autoencoder proposed by Makhzani and Frey [52] . The technique uses linear activation functions and tied weights. In contrast to other autoencoders, only the k largest codes are used while the others are set to zero. The resulting code k-vector gives us additional cues that, albeit not rotation invari- ant, can be combined with the InShaDe descriptor (see also Fig. 6 , right). Section 6 evaluates various descriptors obtained by compos- ing the three different feature vectors: sorted curvatures, energy coefficient and sparse coding weights. 111 5. InShaDe 3D Our 3D pipeline is a natural adaptation of the 2D case. From a mathematical perspective, the Laplace-Beltrami operator on ei- ther 1- or 2-manifold induces a Fourier space. That is, the eigen- functions of the Laplace-Beltrami operator constitute the ”classic”Fourier space in the 2D case and Spherical Harmonics for the 3D spherical case. Albeit we use the elliptic Fourier transform for its superior performance in the 2D case [12] , the two pipelines share the same mathematical foundations. We then compute discrete dif- ferential geometric attributes of the manifold and express them in this Fourier space. It is imaginable to generalize this even fur- ther by utilizing manifold harmonics [69] , at the likely expense of higher computational complexity. The bottom half of Fig. 1 de- picts the pipeline schematically for easy comparison with the 2D pipeline ( Fig. 1 , top). The details of the processing steps are pro- vided in this section. 5.1. Mean curvature According to the differential geometry theory of surfaces, for every twice-differentiable surface we can find the tangent plane K. Al-Thelaya, M. Agus, N.U. Gilal et al. Computers & Graphics 98 (2021) 105–125 Fig. 6. Synthetic descriptors: In addition to the proposed InShaDe energy-based shape descriptors, we considered other representations based on sorted local curvatures (top right) and sparse coding of the foreground segment against a black background (bottom right). Fig. 7. Sparse coding: given images of segmented cell nuclei against a black back- ground (on the left some examples), we use k-sparse autoencoders to find a dictio- nary codebook (center) that can be used for computing a compressed representa- tion of the original images (on the right some examples). for a point on the surface. We can then proceed to define a quadratic form, that is a polynomial containing only terms of de- gree two, using the two tangent directions x, y [70 , chapter 19 therein]. This quadratic form, sometimes called the shape tensor describes extrinsic invariants of the surface, such as principal cur- vatures, at the point where manifold and tangent plane touch. This form is called the second fundamental form II , (cid:14)f ( x, y ) ≈ 1 2 (cid:15)dx dy (cid:16)(cid:17)dx dy II . (18) The second fundamental form approximates the surface z = f (x, y ) with z = 0 the plane tangent to the surface (informally, z is the “height over tangent plane”) in a neighborhood around the touch- ing point. Therefore, the idea of the second fundamental form is to measure, in R 3 , how a surface curves away from its tangent plane 112 Fig. 8. InShaDe 3D processing: starting with a triangular mesh of a closed ob- ject, we compute mean curvature H, and we use Willmore flow to obtain a confor- mal spherical parametrization of the original mesh. The result is a scalar function H ( θ , φ) over the spherical domain that we further decompose using spherical har- monics. 2 at a given point. The eigenvectors of the 2 × 2 matrix II are called principal directions , and the eigenvalues are called principal curva- tures , denoted κ1 , κ2 [9] . Given the principal curvatures, the mean 1 + κκcurvature H = 2 provides a meaningful and natural description of 3D surfaces, and it can be computed on triangular mesh using a discretization of the Laplace-Beltrami operator [9] . In this work, we compute the mean curvature at each vertex of a closed trian- gle mesh. Given a parameterization (s, t) of the triangle mesh, we thus obtain a discrete, scalar function H(s, t) (see also Fig. 8 ). K. Al-Thelaya, M. Agus, N.U. Gilal et al. Computers & Graphics 98 (2021) 105–125 5.2. Spherical parametrization 5.4. Energy coefficients As hinted at in the last section, our 3D pipeline relies on a sur- face parameterization. We use a spherical parameterization, which, despite its apparent simplicity, is much harder to obtain than cir- cular parameterizations of planar shapes. From a geometrical point of view, the second fundamental form can be used for classify- ing surface points according to the signs and values of principal curvatures κ1 and κ2 . Of particular interest are so-called umbilic (“locally spherical”) points for which κ1 = κ2 . A measure for “local sphericity” can thus be defined based on κ1 , κ2 , such as the Will- more energy of a surface S, ( κ1 − κ2 ) 2 E = d A . (19) (cid:18) 1 4 S The geometric flow associated with this energy, ˙ S = −∇ S E ( S ) , (20) will evolve any genus-0 surface S to a sphere, providing a way to obtain a spherical parameterization. In this work, we use the dis- crete Willmore flow formulation proposed by Crane et al. [71] that was also previously used by Agus et al. [61] . This spherical parame- terization maps each vertex of the 3D input shape to a correspond- ing point ( θ , φ) on the unit sphere S 2 , thereby also providing a parameterization for the discrete scalar function H ( θ , φ) . 5.3. Spherical harmonics decomposition The Spherical harmonic basis provides a Fourier basis for func- tions defined over a sphere. We can thus approximate a generic function defined over a closed surface as a finite linear combina- (θ , φ) up to a given maximum fre- tion of spherical harmonics Y m l quency L: L (cid:8) l (cid:8) F ( θ , φ) ≈l Y m w m l ( θ , φ) , (21) m = −l l=0 where the weights w m l can be found through least-square error minimization with respect to the samples computed on the orig- inal 3D shape. To this end, we used a method similar to [61] , with the main difference that, since the mean curvature signal is scalar, we only consider the real part of the spherical har- monics. As a result, the weight coefficients are also real. Specif- (θ , φ) = ically, given the real part of spherical harmonics R m l (θ , φ)) , a spherical parameterization of the surface S, (cid:16)S = (cid:16) (Y m (cid:20)(cid:19)l ( θi ) = ( θ (v i , φi ∈ S , and the mean curvature values computed across the surface H S = { H i ∈ S} , i := H(p the spherical harmonic decomposition is obtained by computing the coefficients w = { w m , 0 ≤ l ≤ L, −l ≤ m ≤ l} that minimize the l square error: i ) ) ∈ S 2 , ∀ v i ) , φ(v i ) , ∀ p w = arg min w (cid:21)(cid:21)(cid:8) (cid:21)(cid:21)(cid:21)H i −i (cid:8) (cid:8) l m (cid:21)(cid:21)(cid:21)l (θi , φi ) (cid:21)(cid:21)l R m w m 2 2 , (22) (23) R · w = R T leading to the linear system R T H S . We solve this system using LDL T factorization, a robust, symmetric pivoting variant of the Cholesky decomposition [72 , chapter 4.1.7 therein], in combination with Tikhonov regularization [61] . This regularization add a diagonal matrix T depending on the Spher- ical Harmonics order and weighted by a small numeric value ν (see [61] for details). Hence, the final linear system has the fol- lowing form. (cid:3)(cid:2)R + νT R T (24) We set the Tikhonov regularization weight to ν = 10 −5 in all ex- periments reported in this paper. · w = R T H S . Similarly to the 2D formulation we use the harmonic energies, to gain rotation-invariance. Energies are defined as the Euclidean norm of the Spherical Harmonic coefficients w for each harmonic frequency separately. Specifically, the 3D curvature Fourier descrip- tor (cid:18) is defined by l (cid:8) (cid:18)l := (cid:2)(cid:3)2 w m . l (25) (cid:22) m = −l These coefficients provide a compact descriptor of genus-0 shapes, and can be used for the analysis of nuclear envelopes extracted from Serial Section Electron Microscopy stacks. 6. Results We implemented our general shape descriptor pipelines and tested them on several challenging use cases. In this section, we first provide details on our implementation ( Section 6.1 ) and then provide an evaluation on general shape analysis, on the analysis of histopathological images, and nuclear shapes extracted from Se- rial Section Electron Microscopy (SSEM) stacks. We separate the evaluation of the two pipelines: for the 2D framework, we report on consistency evaluation performed on classic shape collections commonly used in literature for testing shape retrieval methods ( Section 6.2 ). We also provide results obtained with our pipeline on various histology samples for medical diagnostics and neuro- science investigations ( Section 6.3 ). For the 3D framework, we re- port on the usage of the pipeline for the classification of neural cells reconstructed from a rodent brain sample ( Section 6.4 ). In both evaluations, we involve expert domain scientists, for provid- ing a qualitative evaluation of the framework, and for getting sug- gestions for designing a full visual analytics framework for histol- ogy images. 6.1. Implementation notes The code used to generate the results presented in this paper for the InShaDe 2D pipeline is available in GitHub 2 (Python scripts & Jupyter notebooks). After further testing and cleaning, we plan to also release the C++ code for the InShaDe 3D pipeline. InShaDe 2D We implemented the 2D geometry processing pipeline in Python using the following building blocks & modules: G-U-Net [4] for automatic segmentation, sklearn, skimage for con- tour processing and dimension reduction, interactive matplotlib for visualization. For testing the pipeline, we developed simple inter- active widgets in which users can compare the clustering visualiza- tion in the parameter space to the reconstructed cellular shapes in the histology images. In order to attenuate the amplitudes of high frequencies, we used a frequency equalization scheme weighting (cid:3)(cid:2)of the InShaDe coefficients according to the square root of their order . Our geometry processing pipeline can be used k in combination with different dimension reduction schemes and clustering methods. In this work we use the recent Uniform Mani- fold Approximation and Projection (UMAP) method, which is based on Riemannian geometry and algebraic topology [14] . For cluster- ing, we used HDBSCAN [73] or k-Means [74–76] (depending on the case). w (k ) = √ InShaDe 3D We implemented the InShaDe 3D pipeline in C++, using con- formal curvature flow based on spin transformations 3 . We fur- thermore used the Eigen library [77] for the LDL T solver arising 2 3 https://github.com/HBKUVisCommunity/inshade/ . https://github.com/nitronoid/flo . 113 K. Al-Thelaya, M. Agus, N.U. Gilal et al. Computers & Graphics 98 (2021) 105–125 Fig. 9. Shape retrieval experiments: we evaluate the InShaDe 2D pipeline through classical shape collections commonly used for testing shape retrieval methods: MPEG-7 (left), and Animals (right). in the SPH least squares optimization. For the SPH functions we used boost and libigl for geometry processing. We then fed the parameters derived from the SPH decomposition to standard ma- chine learning methods (e.g., support vector machines, SVMs) us- ing Python’s sklearn to classify the nuclei. 6.2. Consistency validation We first performed a consistency validation of the InShaDe de- scriptor. For this, we used MPEG-7 and Animals [78] , which are among the most popular data sets for evaluating and comparing the accuracy of shape retrieval methods [78] . The MPEG-7 shape collection is composed of 1400 binary images containing objects of 70 different classes [79] (see Fig. 9 left), while the Animals shape collection (see Fig. 9 right) is an even more challenging data set containing 20 0 0 binary images grouped in 20 classes of 100 ani- mals each one. To test the InShaDe 2D descriptor we considered three different assessment criteria: (1) Retrieval accuracy . of a basic SVM scheme, trained on an augmented data set. We triple the size of the input data set by adding randomly rotated and shifted copies of orig- inal images. Moreover, we use a hyperparameter optimiza- tion scheme to find the best SVM linear parameters with re- spect to cross-correlation accuracy, and we test the obtained model over the original collection. We also show the accu- racy of shape retrieval in the form of a confusion matrix to highlight the accuracy differences between classes. (2) Bull’s Eye accuracy . which is commonly used to score shape retrieval tasks when the number of objects is limited: First, a similarity distance between objects represented by feature vectors is defined. For this, we use the L 1 norm (Manhattan i | . For any object O of class C, Distance), d(x , y ) = find a given K O nearest neighbors with respect to d ( K O = 4 in our case). After that, count how many objects N O in the set of K O nearest neighbors share the same class C O of object O . Finally, the Bull’s Eye score is defined as B = i − y i | x (cid:23) (cid:23) N O O . K O (3) Qualitative visual assessment of the reduced parameter space obtained by projecting the feature vectors on a 2D plane through dimension reduction techniques and observing how objects cluster together. In our experiments we used UMAP [14] . For the composition of the feature vector we consider three dif- ferent contributions: the sorted local curvature signal (cid:19), the ellip- tic Fourier analysis energy coefficients (cid:18), and the weight values of k-sparse autoencoding [52] (see the examples in Fig. 10 ). The pur- pose of using sparse coding features is not to precisely reconstruct the original image, but rather to extract the important information 114 Fig. 10. Sparse coding: we used k-sparse autoencoders for encoding MPEG-7 (top row) and Animals (bottom row) shape images. Left: dictionary W . Center: shape examples. Right: corresponding images reconstructed from sparse codes with k = 256 coefficients. The reconstructed images clearly represent the main contents of the original images. using very few parameters. The reconstructed images, using only 256 coefficients, clearly represent the main contents of the origi- nal images. We investigate all possible composition permutations: sorted local curvatures alone ( (cid:19)), Fourier energy coefficients alone ( (cid:18)), sparse coding weights alone ( (cid:20)), local curvatures and energy co- efficients ( (cid:19)(cid:18)), local curvatures and sparse coding weights ( (cid:19)(cid:20)), energy coefficients and sparse coding weights ( (cid:18)(cid:20)), local curva- tures together with energy coefficients and sparse coding weights ( (cid:19)(cid:18)(cid:20)). For merging heterogeneous feature vectors, we perform pre-normalization of the various feature vectors. Fig. 11 shows the Bull’s Eye score obtained for both shape col- lections on top of four retrievals for various feature vector com- positions at varying number of coefficients. The highest accuracy was obtained for 240 coefficients and with the descriptor (cid:19)(cid:18)(cid:20)(composing sorted curvatures, energy coefficients, and sparse co- efficients). Considering the feature coefficients alone, sparse cod- ing descriptors outperform sorted curvatures and energy descrip- tors: we suspect that this is due to the fact that sparse coding is able to provide a valid description of both the boundary shape and the inner part of the objects. Nonetheless, incorporating the energy coefficients proved to be beneficial since the composed descrip- tors can take into account transformations like rotations and shifts. The obtained values are in line with current state of the art meth- ods (see tables in [78] ): for example the obtained Bull’s Eye score on MPEG-7 data set is 0.87 (versus 0.863 for Hierarchical String Cats [80] and 0.876 for Fourier Transform Group Feature [81] ), while for the Animals data set the Bull’s Eye rate is 0.54 (ver- sus 0.436 Hierarchical String Cats [80] ). Better performances can be obtained through post-processing retrieval schemes that are or- thogonal to our method and can be incorporated successively: for example the Online to Offline O2O scheme [78] applied on top of different descriptors can achieve Bull’s Eye score up to 0.99 for the MPEG-7 data set and 0.66 for the Animals data set. In our experi- ments, we also noticed a slight degradation of accuracy for feature dimensions higher than 500, indicating that the curse of dimen- sionality can affect the proposed descriptor. We also compared the CPU computation times per shape be- tween the various descriptors on the MPEG-7 dataset (the average number of vertices per shape is 1917) and Animals (the average number of vertices per shape is 961). For timing measurements, we used a workstation equipped with an Intel i9-9900 CPU (8 cores, 3.1 Ghz), 64 GB of RAM, and an Nvidia RTX 2080 GPU with 8GB RAM. In Fig. 12 , we report the processing times per shape as function of number of coefficients, and for both datasets (left: K. Al-Thelaya, M. Agus, N.U. Gilal et al. Computers & Graphics 98 (2021) 105–125 Fig. 11. Bull’s Eye score for shape collections: various descriptors are compared with respect to the Bull’s Eye accuracy on top of 4 retrievals for varying number of coefficient. On the left, MPEG7 results, while on the right Animals results. We compare simple and composed descriptors based on sorted curvatures, elliptic Fourier energy coefficients, and sparse coefficients. The highest Bull’s Eye accuracy scores are 0.54 for Animals and 0.87 for MPEG7, and they are obtained for the composed descriptor (cid:19)(cid:18)(cid:20)containing sorted curvatures, energy coefficients, and sparse coefficients. Fig. 12. Processing time for descriptors: we compared the CPU processing time of InShaDe 2D energy descriptor with the sparse coding scheme computed through k-sparse autoencoders [52] with respect to the number of coefficients. We report the processing time per shape for MPEG-7 (on the left), and Animals (on the right). MPEG-7, right: Animals). For the k-sparse autoencoder, we report the training time for 500 epochs using the total images of the dataset for training but averaging the times reported by the num- ber of images. The input image resolution is 256 × 256 for MPEG-7 and 640 × 432 for Animals. It is worth noticing that, according to the number of coefficients, the memory resources needed for using k-sparse autoencoder are proportional to the size of input images and the size of output sparse descriptor and can easily reach the limits of available RAM in many systems. Moreover, the InShaDe pipeline can be further accelerated through GPU-friendly imple- mentations that would be able to manage batches of images in parallel. Figs. 13 and 14 show the UMAP projection of the composed de- scriptor for the various shapes for both MPEG-7 and Animals data sets as a visual reference (separated in groups of at most 12 labels to reduce clutter). It appears evident that the proposed descriptor is, in most cases, able to discriminate the shapes of MPEG-7 data set. The clusters for the Animals data set appear more confused, thus con- firming the retrieval rates in this work and prior literature. Fig. 15 depicts a typical failure case of our scheme on the An- imals data set. A leopard is considered very similar to a cow, a cat and another cow. The middle row shows the local curvature signals computed over the shape contour, while the bottom row shows the composed feature vector containing the sorted curva- tures (left), the energy coefficients (middle), and the sparse coeffi- cients (right). Fig. 16 shows the confusion matrix for linear SVM classification obtained for our composite descriptor (cid:19)(cid:18)(cid:20). In terms of accuracy, we obtain results aligned with state of the art methods ( 88 . 4% for our descriptor on the MPEG-7 data set versus 66% for Cur- vature based Fourier descriptor [29] , 78% for blurred shape mod- 115 K. Al-Thelaya, M. Agus, N.U. Gilal et al. Computers & Graphics 98 (2021) 105–125 Fig. 13. MPEG-7 UMAP clustering : we test UMAP dimension reduction on the composed descriptor (cid:19)(cid:18)(cid:20) for MPEG-7 collections (256 feature elements per descriptor for a total of 768 features). The Bull’s Eye score obtained for this collection was 0.898. In order to reduce visual cluttering, the various shapes are separated in 6 groups of maximum 12 labels. Fig. 14. Animals UMAP clustering : we test UMAP dimension reduction on the composed descriptor (cid:19)(cid:18)(cid:20) for Animals collection. The Bull’s Eye score obtained for this collection was 0.543. In order to reduce visual cluttering, the various shapes are separated in 3 groups of maximum 7 labels. els [82] , 78% Morphological Pattern Spectrum [83] and 90% for Zer- nicke moments with geometric features [79] ). It is important here to note that the composition of shape features and image features significantly improved retrieval accuracy in agreement with prior work [79] ( 88 . 4% for the composed descriptor versus 87 . 5% for the sparse coding descriptor and 78% of the simple energy shape de- scriptor proposed in the conference paper [13] ). Given that the re- sults show the proposed descriptor to be consistent for classifying shapes of natural objects, we will now proceed to analyze its per- formance for the analysis of biomedical images. 6.3. Histopathology analysis For the analysis of histopathology images, we use public do- main data from the MoNuSeg contest [47] , and the very re- cent PanNuke data set [41] . The former contains 30 images from seven organs with unclassified annotations of more than 20k individual nuclei. The latter contains more than 220K la- beled nuclei from 19 different tissue types and, as of writ- ing, is the largest open pan-cancer histology data set for nu- clei instance segmentation and classification. Finally, we apply the 116 K. Al-Thelaya, M. Agus, N.U. Gilal et al. Computers & Graphics 98 (2021) 105–125 Fig. 15. Bull’s Eye testing : Here, we show a typical failure case using the L1 Bull’s Eye score for the descriptor (cid:19)(cid:18)ω on the Animals data set. Top row, left to right: a leopard is considered similar to a cow, a cat, and another cow. We also show the curvature signal of each curve (middle row) and composite descriptor (bottom row). Fig. 16. Shape retrieval experiments : a simple Support Vector Machine classifier using our descriptor is able to obtain classification accuracy on par with standard geometry- based classification methods ( 88 . 4% for the MPEG-7 and 55% for Animals over the complete shape collection). We also show the full confusion matrix obtained on the testing data (left: MPEG-7, right: Animals collection). 117 K. Al-Thelaya, M. Agus, N.U. Gilal et al. Computers & Graphics 98 (2021) 105–125 Fig. 17. Examples of combining the InShaDe pipeline with dimension reduction and clustering for visual classification in histology: Color-coding of shape clusters in the MoNuSeg data set [47] result in recognizable spatial patterns. Similar shape features according to UMAP do not necessarily relate to intuitive discrimination through visible attributes such as length or thickness or smoothness. pipeline to a whole slide image representing a paediatric appendix specimen. Fig. 17 shows examples of images from the MoNuSeg data set [47] classified by our framework: we reduce the dimensions of the feature descriptors using UMAP, followed by k-Means for clus- tering. We then color-code contours by cluster. We notice that cells recognized as having similar shape features according to UMAP do not necessarily relate to intuitive discrimination through visible at- tributes such as length or thickness or smoothness. However, they do not only form feature clusters (same color) but also tend to form spatial clusters. The latter fact can provide additional visual information to digital pathologists for diagnosis through spatial ag- gregation of such clusters. While further investigation is needed to understand and evaluate the clinical value and to find explain- able taxonomies, initial feedback from pathologists confirmed that in many cases nuclear features and clusters can provide decisive information for recognizing specific conditions. Histopathology shal- low classification We also tested whether our descriptor could be used for shal- low classification of nuclear cells for diagnostic purposes. To this end, we tested various composed descriptors ( (cid:18), (cid:20), (cid:18)(cid:20), and (cid:19)(cid:18)(cid:20)) with varying number of features ( 64 , 128 , 256 ), and we trained a linear SVM classifier on PanNuke data set [41] for dis- criminating between three classes of nuclei: neoplastic cells, in- flammatory cells, and others. Fig. 18 , left, shows the accuracy per- formance of the various descriptors considered in this work. The highest accuracy (0.601) is obtained for the composite descriptor (cid:19)(cid:18)(cid:20) with 256 features per component. However, the improve- ment of the composed descriptor with respect to the sparse coding descriptor is almost imperceptible (0.578 for the descriptor (cid:20)). In this case, sparse coding captures not just the shape but also tex- ture information, which might be helpful for classification. Thus, the improvement brought by InShaDe is less pronounced compared to Fig. 11 , where the input images only contain shape and not tex- ture. In this case, the proposed shape descriptor cannot adequately discriminate the various cell classes according to the proposed tax- onomy. It is still far from being sufficiently accurate for reliable classification of individual nuclei. However, this preliminary accu- racy performance was obtained with a simple SVM classifier, and it can be improved by considering more sophisticated classifiers, like ANNs. In general, the dimension reduction plots show that cells of same type do not cluster together when using the InShaDe descrip- tor (see in Fig. 18 right some examples). Nonetheless, the presence of outliers in the parameter space can provide pathologists visual hints for proofreading the labeling of nuclei or evaluating the accu- racy of contours (see an example in Fig. 18 right, in which a group of images is processed together to obtain a parametric scatter plot to be used for proof-reading patches). Fig. 19 shows an example for the visual analysis of whole slide images (WSIs). We trained an SVM model on InShaDe feature vec- tors derived from PanNuke data. Then, we used the SVM to classify nuclei in a large-scale, 80 , 986 × 99 , 328 -pixel WSI of a paediatric appendix specimen. All nuclei are classified as either neoplastic (red), inflammatory (blue), or other (green). Inflamed nuclei clus- ter together, providing a clear indication of specific affected areas. Neoplastic nuclei are very rare and do not form structured clus- ters. They are therefore considered classification errors by the do- main scientists. Histopathologists can use the processing pipeline for preliminary analysis targeted at the individuation of inflamma- tory areas. We believe (a hypothesis supported by the domain sci- entists in our team) that spatial aggregation of classes, i.e., density estimations of the nuclei distribution in space (also see Fig. 19 ), could become a valuable diagnostic tool in discriminating and in- dividuating different tissue regions. Since a full study into the use- fulness of such spatial density estimates is beyond the scope of this work, it is left as a future research direction. Qualitative evaluation We tested our InShaDe processing pipeline also on histology images of rodent brain samples stemming from neuroscience. Two expert neuroscientists aided this study by providing a qualitative evaluation of the framework as applied to images obtained with different staining techniques. As a general outcome, the domain scientists particularly appreciated the fact that they could try to map specific features in the shape features space to specific pat- terns in the histology images. Specifically, Fig. 20 , left, shows the outcomes of Nissl staining of mice brain sections. clustering was obtained with k-Means. The Nissl staining is not specific for particular cell types and is com- monly used for cell counting, since it provides an excellent contrast between the cellular and extracellular space. On the other hand, it does not provide a very good contrast between the cytoplasm and the cell nucleus. In the example reported, the contrast allowed the automated algorithm to efficiently segment cell profiles, but only few nuclei were segmented correctly (mostly in light blue, some of them highlighted with blue arrows). In this case, the usage of the parameter space for highlighting the contour shapes in the image space provides visual hints for recognizing particular features, like blurred segmentations of soma mixed with dendrites, appearing as irregular and elongated shapes (see red arrows in Fig. 20 top right). So far, neuroscientists consider the framework potentially useful 118 K. Al-Thelaya, M. Agus, N.U. Gilal et al. Computers & Graphics 98 (2021) 105–125 Fig. 18. Accuracy on PanNuke data set : we trained a linear SVM model on our descriptor and we compared the accuracy with respect to different feature vectors obtained by composing energy coefficients and/or sparse coding coefficients (left). The maximum obtained accuracy over 3-classes is 0.601. PanNuke represents the largest open pan-cancer histology data set for nuclei instance segmentation and classification [41] . InShaDe can be used for proof-reading the quality and the accuracy of labelling (right). 6.4. Evaluation of 3D pipeline For the evaluation of the InShaDe 3D pipeline, we used two col- lections of 3D reconstructions of brain cells nuclei, extracted from reconstructions of nanometric scale electron microscopy stacks, ob- tained after imaging a volume of brain parenchyma from layer II/III (see Fig. 21 left)and layer VI (see Fig. 21 right) somatosensory cor- tex of a P14 rat [54] . The nuclear shapes were manually assigned to known cell types, namely neurons, astrocytes, microglia, pericytes, unknown cells (most likely oligodendrocytes), and endotelium cells for both collections. We used InShaDe 3D feature vectors as the in- put for a kernel SVM with radial basis functions. To assess the clas- sification performance, we considered four cases for SPH decompo- sition with order L max = 8 , 16 , 24 , 32 , corresponding to the number of rotation-invariant energy descriptors (see also Section 5.1 ). For each case, we performed a grid-search to configure the two hy- perparameters in the SVM model: the constant γ of the Gaussian radial basis function, and the weight C for the soft margin regular- ization function. We chose a grid logarithmic in C (ranging from 10 −2 to 10 10 ) and γ (ranging from 10 −9 to 10 3 ). We then trained the model on 95 nuclear shapes for the layer VI shape collection, and 82 shapes for the layer II/III shape collection. We performed a 5-fold cross- validation using sklearn’s StratifiedShuffleSplit function. This par- titions the input data into five image sets while maintaining the relative ratio of classes in each set. Four sets were used for train- ing and validation (using an 80/20 split) and the remaining set was used for a blind test. Fig. 22 , left, summarizes the best cross- accuracy among the five folds for the SVM models trained on dif- ferent shape collections and varying feature dimensions. We also compared the performances of this new formula- tion with respect to our previous framework WISH [61] (also see Fig. 22 right). The InShaDe accuracy is similar to WISH, with a best score of 83% versus 84% for the layer VI data set. It is worth not- ing that this is despite the new formulation proposed here contain- Fig. 19. Visual analysis of WSI : the InShaDe processing pipeline is applied to the analysis of Whole Slide Images (WSI). A paediatric appendix specimen (top left inset) is analyzed by a linear SVM model trained on InShaDe features from Pan- Nuke data. Histopathologists can identify inflammatory areas (blue) against irrele- vant background (green). Spurious cancer cells (red) do not form structures and are correctly interpreted as classification error. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.) for proofreading the quality of the staining, and filtering some in- formation even in case of wrong staining. Finally, Fig. 20 , right, shows a portion of somatosensory cor- tex from an ultrastructural work on ageing [84–86] . Nuclei were stained with toluidine blue on semithin sections prepared for elec- tron microscopy in order to count cells. The extracted contours were clustered through k-Means. In this case, the shape feature space enabled scientists to distinguish immediately between blood vessels (in red, with some of them highlighted by arrows), and nu- clei from different kind of neurons (pyramidal neurons mostly in pink, highlighted by arrows and with different distribution accord- ing to the layer). 119 K. Al-Thelaya, M. Agus, N.U. Gilal et al. Computers & Graphics 98 (2021) 105–125 Fig. 20. Visual analysis of mouse brain sections : our visual analysis pipeline is used for a neuroscience investigation. Top: a brain section fixed with paraformaldehyde is stained with Cresyl Violet, which highlights Nissl substance in the cytoplasm of neurons. Only few nuclei are segmented correctly (in light blue and highlighted with blue arrows on the right) and in various cases soma are mixed with dendrites (in red and highlighted with red arrows). Bottom: toluidine blue is used in an attempt to discriminate pyramidal neurons nuclei (in pink and highlighted by pink arrows) from blood vessels (in red and highlighted with red arrows) and artifacts. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.) 120 K. Al-Thelaya, M. Agus, N.U. Gilal et al. Computers & Graphics 98 (2021) 105–125 Fig. 21. Data sets : we tested the InShaDe 3D pipeline on two collections of brain cells nuclei extracted from layer II/III (left) and layer VI (right) of somatosensory cortex of a P14 rat. ing fewer coefficients (one real-valued vector here as opposed to three complex vectors [61] ) and is easier to compute numerically. In Fig. 23 we report the average processing times of the Spheri- cal Harmonics coefficients for varying orders of components. It is evident that the simplified formulation results in a dramatic re- duction of computation times. These timings were measured on a Razor Stealth laptop equipped with an Intel i7-8565U CPU (4 cores, 1.8GHz), 16GB RAM and connected through USB-C to an e- GPU NVIDIA Titan RTX with 24GB RAM. Moreover, the spherical parametrization step is identical between the two pipelines In- ShaDe and WISH, and the mean curvature signal is obtained as free by-product from the usage of Willmore Flow [87] . Given the availability of shape collections extracted from different layers, we tested whether models trained on one collection could be gener- alized for inference on the shapes of another collection. The re- sulting performance was poor, in particular for neurons (below 60% ). This confirms the hypothesis from domain scientists [54] that nuclear envelopes exhibit different shape features according to the layer from which they are extracted. To confirm this point, Fig. 24 shows the full shape collection under different dimension reduction schemes. It appears that it is not possible to cluster to- gether cells extracted from different layers (II & III vs VI). From these preliminary results, it appears evident that: • it is difficult to find models using InShaDe 3D descriptors that can generalize the classification of cell types regardless of the layers from which they are extracted; • neurons of different layers appear to form separate clusters, suggesting a shape variability depending on the area from which they are extracted [88] . This is an interesting hypothe- sis worthy of further investigations which we plan to carry out in the future. Fig. 23. Processing time for SH computation : we compare the processing time for coefficients computation between InShaDe 3D and WISH [61] . The simplified formulation results in a dramatic reduction of processing times. 6.5. Discussion We summarize the main outcomes of this study as follows. • Relationships between shape parameter space and image space : in various cases we notice that spatial clusters of cells exhibit closer shape features in the reduced parameter space. Further investigation is needed to understand whether and in which cases spatial patterns or clusters in the image space correspond to patterns or clusters in the parameter space, and to associate shape clusters to specific taxonomies. In this context, we would like to remind that performing clustering on parameter space obtained after dimension reduction is still considered a com- plex task prone to producing unreliable results [89] . Therefore, we plan to explore different automatic and manual dimension reduction techniques to support domain scientists during their analysis. • Coupling with image descriptors: we integrated the InShaDe 2D with sparse coding for decomposing the inner part of nuclei as function of specific texture patterns with different physi- cal and molecular characteristics. Sparse coding features out- perform the proposed descriptor (we suspect that the reason is related to the fact that they can also describe shape bound- ary features), while composed descriptors provide slightly bet- ter discrimination capabilities for standard evaluation datasets because they recover invariance with respect to transforma- tions. However, the composed descriptors are not reliable yet for fine-grain diagnosis on histopathology images. Spatial ag- gregation (i.e., class density estimation) could be used to allevi- ate this problem, but future research is needed. We also suspect Fig. 22. Accuracy for 3D nuclei classification: we trained SVMs with InShaDe 3D features on nuclei shape collections from somatosensory cortex of a juvenile rat in layer III and layer VI. Left: cross accuracy of the SVM model for layer III collection, layer VI collection and full collection. Right: we compare the accuracy performance of InShaDe with respect to WISH [61] on the same data. Despite the simplified formulation, the accuracy is similar. 121 K. Al-Thelaya, M. Agus, N.U. Gilal et al. Computers & Graphics 98 (2021) 105–125 Fig. 24. Dimension reduction: dimension reduction projections of InShaDe 3D features for all collection shapes. From top to bottom: PCA, t-SNE, and UMAP. Neurons from different layers tend to form clearly separate clusters. that we have hit a performance wall for engineered and model- based descriptors. Therefore, we plan to integrate model-based descriptors into more general deep learning architectures. • Caveats due to staining techniques: depending on the structure to be identified within a cell, or the type of tissue, a large plethora of immunohistochemical staining techniques are avail- able. The proposed analysis framework can provide effective proof-reading tools for checking the quality of staining methods and semi-automatically individuating the structures of interest. • Taxonomy-based visual analytics system: a real challenge in the analysis of histology images is the difficulty to individuate cor- rect taxonomies of nuclei in order to simplify understanding and diagnosis. A visual analytics framework incorporating con- tour analysis, image analysis, and expert domain knowledge would help digital pathologists in labeling and proof-reading, and would provide fast ways for creating labeled data for more sophisticated artificial intelligence frameworks.To this end, our processing pipeline provides encouraging results and can be easily integrated in such systems. • 2D Arc-length parameterization : while we have yet to observe our Arc-length parameterization algorithm to diverge, we do not have a formal proof of convergence at the time of writing. We believe it works so well since changes in u happen very gradually and the original curve remains untouched. Each repa- rameterization attempt therefore slides vertices around the in- put curve. While formal analysis is hindered by the fact that our method is discontinuous at original vertices, we believe a full treatise to be an interesting direction for future work. • Benefits of scale-invariance: for the MPEG-7 and animals data sets, utilizing the optional scale-invariance boosts performance 122 K. Al-Thelaya, M. Agus, N.U. Gilal et al. Computers & Graphics 98 (2021) 105–125 by up to 10% in many of our experiments. This should come as no surprise, since, e.g., the outline of a butterfly stays the out- line of a butterfly under magnification and minification. Con- sequently, deep learning-based pipelines have made rescaling a main step of their data augmentation stage, in an attempt the achieve de-facto rather than by-design scale-invariance. What is surprising, however, is that scale-invariance added only marginal and in many cases statistically insignificant improve- ments for cell nuclei classification. We believe that this is due to the “apparent size” problem, in which cell nuclei always ap- pear smaller than the original size due to slicing. It seems that having plenty of slices under different angles at the classifiers disposal is more important than to remove scale-variance. A full analysis of this problem is beyond the scope of this paper and offers an interesting future research direction. • Limitations of 3D pipeline: the encouraging results obtained with our 3D formulation are counterbalanced by two important lim- iting bottlenecks. Firstly, the process for producing nuclear sur- faces from electron microscopy image stacks is still time con- suming and requiring highly specialized human effort s. Even though important progresses in automatic segmentation of EM stacks has recently been made [19] , custom models for auto- matic extraction of nuclei are not available to our knowledge. We plan to focus future effort s towards this direction. Secondly, the spherical parameterization task is complex and can be un- stable. One of its limitations is that it cannot be applied to ar- bitrary closed shapes but only genus-0 and (if the flow is ap- propriately regularized) genus-1 surface (that is, surfaces either homeomorphic to spheres or torii with at most 1 hole). To over- come these limitations, we plan to investigate more general in- variant formulations based on manifold harmonics [90] . 7. Conclusion We have presented a general shape processing framework rooted in a novel differential-geometry-based descriptor of closed contours and surfaces. Our descriptor provides an embedding into a fixed-dimensional feature space that can be utilized for vari- ous applications, which range from serving as input feature for deep and shallow learning techniques to supporting dimension reduction schemes for providing a visual reference for clustering collection of shapes. While our methods are of general use, our work is motivated by the study of cellular nuclear envelopes ex- tracted from histopathological images and serial section electron microscopy stacks. In this context, we have shown the capabili- ties of the proposed framework for visual analysis and unsuper- vised classification. Our results are very encouraging and we iden- tify several major areas of future work in the previous section. In particular, we plan to develop, on top of our pipeline, a taxonomy- based visual analytics system to simplify study and diagnosis. Declaration of Competing Interest The authors declare that they have no known competing finan- cial interests or personal relationships that could have appeared to influence the work reported in this paper. Acknowledgments This work was supported by the College of Science and En- gineering at Hamad Bin Khalifa University. It was partially sup- ported by Sardinian Regional Authorities under projects VIGECLAB and DIFRA, and by the KAUST-EPFL Alliance for Integrative Model- ing of Brain Energy Metabolism https://www.kaust.edu.sa/en under KAUST CRG6 Grant No. 2313. Access funding provided by the Qatar National Library. References [1] Boges DJ, Agus M, Magistretti PJ, Calì C. Forget about electron micro- graphs: a novel guide for using 3d models for quantitative analysis of dense reconstructions. In: Volume Microscopy; 2020. p. 263–304. doi: 10.1007/ 978- 1- 0716- 0691- 9 _ 14 . [2] Madabhushi A, Lee G. Image analysis and machine learning in digital pathol- ogy: challenges and opportunities. Med Image Anal 2016;33:170–5. doi: 10. 1016/j.media.2016.06.037 . [3] Kurnianggoro L, Wahyono SK, Jo K-H. A survey of 2D shape representation: methods, evaluations, and future research directions. Neurocomp 2018;300:1–16. doi: 10.1016/j.neucom.2018.02.093 . [4] Chidester B, Ton T-V, Tran M-T, Ma J, Do MN. Enhanced rotation-equivariant U-Net for nuclear segmentation. In: Proc. IEEE/CVF Conf. on Computer Vision and Pattern Recognition Workshops (CVPRW); 2019. p. 0. doi: 10.1109/CVPRW. 2019.00143 . [5] Gamper J, Koohbanani NA, Benet K, Khuram A, Rajpoot N. PanNuke: An open pan-cancer histology dataset for nuclei instance segmentation and classifi- cation. In: Proc. European Congress on Digital Pathology; 2019. p. 11–19. doi: 10.1007/978- 3- 030- 23937- 4 _ 2 . [6] Scheffer LK , Xu CS , Januszewski M , Lu Z , Takemura S-y , Hayworth KJ , Huang GB , Shinomiya K , Maitlin-Shepard J , Berg S , et al. A connectome and analysis of the adult drosophila central brain. Elife 2020;9:e57443 . [7] Motta A , Berning M , Boergens KM , Staffler B , Beining M , Loomba S , Hennig P , Wissler H , Helmstaedter M . Dense connectomic reconstruction in layer 4 of the somatosensory cortex. Science 2019;366(6469) . [8] Tajbakhsh N, Jeyaseelan L, Li Q, Chiang JN, Wu Z, Ding X. Embracing imperfect datasets: a review of deep learning solutions for medical image segmentation. Med Image Anal 2020:101693. doi: 10.1016/j.media.2020.101693 . [9] Bobenko AI , Sullivan JM , Schröder P , Ziegler G . Discrete differential geometry. Springer; 2008 . ISBN 978-3-7643-8621-4 [10] Crane K, Wardetzky M. A glimpse into discrete differential geometry. Notices of the American Mathematical Society 2017;64(10). doi: 10.1090/noti1578 . [11] Ronneberger O, Fischer P, Brox T. U-Net: Convolutional networks for biomed- ical image segmentation. In: Int’l Conf. on Medical Image Computing and Computer-Assisted Intervention (MICCAI); 2015. p. 234–41. doi: 10.1007/ 978- 3- 319- 24574- 4 _ 28 . [12] Diaz G, Zuccarelli A, Pelligra I, Ghiani A. Elliptic fourier analysis of cell and nuclear shapes. Comput Biomed Res 1989;22(5):405–14. doi: 10.1016/ 0 010-4809(89)90 034-7 . [13] Agus M, Al-Thelaya K, Calì C, Boido M, Yang Y, Pintore G, Gobbetti E, Schnei- der J. InShaDe: Invariant shape descriptors for visual analysis of histology 2d cellular and nuclear shapes. In: Proc. Eurographics Workshop on Visual Computing for Biology and Medicine (VCBM); 2020a. p. 61–70. doi: 10.2312/ vcbm20201173 . [14] McInnes L., Healy J., Melville J.. UMAP: Uniform manifold approximation and projection for dimension reduction. arXiv preprint; 2018. https://arxiv.org/abs/ 1802.03426 . [15] Mingqiang Y, Kidiyo K, Joseph R. A survey of shape feature extraction tech- niques. Pattern Recognit 2008;15(7):43–90. doi: 10.5772/6237 . [16] Irshad H, Veillard A, Roux L, Racoceanu D. Methods for nuclei detection, seg- mentation, and classification in digital histopathology: a review–current status and future potential. IEEE Rev Biomed Eng 2013;7:97–114. doi: 10.1109/RBME. 2013.2295804 . [17] Xing F, Yang L. Robust nucleus/cell detection and segmentation in digital pathology and microscopy images: a comprehensive review. IEEE Rev Biomed Eng 2016;9:234–63. doi: 10.1109/RBME.2016.2515127 . [18] Jothi JAA, Rajam VMA. A survey on automated cancer diagno- sis from histopathology images. Artif Intell Rev 2017;48(1):31–81. doi: 10.1007/s10462- 016- 9494-6 . [19] Moen E , Bannon D , Kudo T , Graf W , Covert M , Van Valen D . Deep learning for cellular image analysis. Nat Methods 2019;16(12):1233–46 . [20] Yang M, Kpalma K, Ronsin J. Shape-based invariant feature extraction for ob- ject recognition. In: Advances in Reasoning-Based Image Processing Intelligent Systems; 2012. p. 255–314. doi: 10.1007/978- 3- 642- 24693- 7 _ 9 . [21] Xu D, Li H. Geometric moment invariants. Pattern Recognit 2008;41(1):240–9. doi: 10.1016/j.patcog.20 07.05.0 01 . [22] Khotanzad A, Hong YH. Invariant image recognition by zernike moments. IEEE Trans Pattern Anal Mach Intell 1990;12(5):489–97. doi: 10.1109/34.55109 . [23] Novotni M, Klein R. Shape retrieval using 3D Zernike descriptors. Comput Aided Des 2004;36(11):1047–62. doi: 10.1016/j.cad.2004.01.005 . [24] Shu H, Luo L, Bao X, Yu W, Han G. An efficient method for computation of legendre moments. Graph Models 20 0 0;62(4):237–62. doi: 10.10 06/gmod.20 0 0. 0523 . [25] Mukundan R, Ong S, Lee PA. Image analysis by Tchebichef moments. IEEE Trans Image Process 2001;10(9):1357–64. doi: 10.1109/83.941859 . [26] Zhang D, Lu G. A comparative study of curvature scale space and fourier descriptors for shape-based image retrieval. J Vis Commun Image Represent 2003;14(1):39–57. doi: 10.1016/S1047- 3203(03)00003- 8 . [27] Mokhtarian F. Silhouette-based isolated object recognition through curvature scale space. IEEE Trans Pattern Anal Mach Intell 1995;17(5):539–44. doi: 10. 1109/34.391387 . [28] Laga H, Takahashi H, Nakajima M. Spherical wavelet descriptors for content- based 3d model retrieval. In: IEEE Int’l Conf. on Shape Modeling and Applica- tions; 2006 . 15–15 123 K. Al-Thelaya, M. Agus, N.U. Gilal et al. Computers & Graphics 98 (2021) 105–125 [29] El-Ghazal A, Basir O, Belkasim S. A novel curvature-based shape fourier de- scriptor. In: Proc. IEEE Int’l Conf. on Image Processing; 2008. p. 953–6. doi: 10. 1109/ICIP.2008.4711914 . [30] El-Ghazal A, Basir O, Belkasim S. Invariant curvature-based fourier shape de- scriptors. Journ of Visual Comm and Image Representation 2012;23(4):622–33. doi: 10.1016/j.jvcir.2012.01.011 . [31] Bobenko A.I.. Geometry II: Discrete differential geometry. Lecture Notes, Math Dept., TU Berlin, Germany; 2015. [32] Ovsjanikov M , Bronstein AM , Bronstein MM , Guibas LJ . Shape google: a com- puter vision approach to isometry invariant shape retrieval. In: 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops. IEEE; 2009. p. 320–7 . [33] Chang A.X., Funkhouser T., Guibas L., Hanrahan P., Huang Q., Li Z., Savarese S., et al.. Shapenet: An information-rich 3D model repository. arXiv preprint; 2015. https://arxiv.org/abs/1512.03012 . [34] Wu Z, Song S, Khosla A, Yu F, Zhang L, Tang X, Xiao J. 3D shapenets: A deep representation for volumetric shapes. In: Proc. IEEE/CVF Conf. on Computer Vi- sion and Pattern Recognition (CVPR); 2015. p. 1912–20. doi: 10.1109/CVPR.2015. 7298801 . [35] Wang P-S, Liu Y, Guo Y-X, Sun C-Y, Tong X. O-CNN: Octree-based convolu- tional neural networks for 3D shape analysis. ACM Trans Graph 2017;36(4):72. doi: 10.1145/3072959.3073608 . [36] Yi L, Su H, Guo X, Guibas LJ. SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation. In: Proc. IEEE/CVF Conf. on Computer Vision and Pattern Recognition (CVPR); 2017. p. 2282–90. doi: 10.1109/CVPR.2017.697 . [37] Sinha A, Bai J, Ramani K. Deep learning 3D shape surfaces using geometry images. In: Proc. ECCV; 2016. p. 223–40. doi: 10.1007/978- 3- 319- 46466- 4 _ 14 . [38] Jeong W-K, Schneider J, Turney S, Faulkner-Jones BE, Meyer D, Westermann R, Reid RC, et al. Interactive histology of large-scale biomedical image stacks. IEEE Trans Vis Comput Graph 2010;16(6):1386–95. doi: 10.1109/TVCG.2010.168 . [39] Jeong W , Schneider J , Hansen A , Lee M , Turney SG , Faulkner-Jones BE , Hecht JL , et al . A collaborative digital pathology system for multi-touch mobile and desktop computing platforms. Comput Graphics Forum 2013;32:227–42 . [40] Rohde GK, Ribeiro AJ, Dahl KN, Murphy RF. Deformation-based nuclear morphometry: capturing nuclear shape variation in Hela cells. Cytometry Part A: The Journal of the International Society for Analytical Cytology 2008;73(4):341–50. doi: 10.1002/cyto.a.20506 . [41] Gamper J., Koohbanani N.A., Graham S., Jahanifar M., Khurram S.A., Azam A., Hewitt K., Rajpoot N.. PanNuke dataset extension, insights and baselines. arXiv preprint; 2020. https://arxiv.org/abs/2003.10778 . [42] Xing F, Xie Y, Su H, Liu F, Yang L. Deep learning in microscopy image analysis: asurvey. IEEE Trans Neural Netw Learn Syst 2017;29(10):4550–68. doi: 10.1109/ TNNLS.2017.2766168 . [43] Zheng Y, Jiang Z, Xie F, Zhang H, Ma Y, Shi H, Zhao Y. Feature extraction from histopathological images based on nucleus-guided convolutional neu- ral network for breast lesion classification. Pattern Recognit 2017;71:14–25. doi: 10.1016/j.patcog.2017.05.010 . [44] Al-Milaji Z, Ersoy I, Hafiane A, Palaniappan K, Bunyak F. Integrating segmenta- tion with deep learning for enhanced classification of epithelial and stromal tissues in h&e images. Pattern Recognit Lett 2019;119:214–21. doi: 10.1016/j. patrec.2017.09.015 . [45] Nagpal K, Foote D, Liu Y, Chen P-H C, Wulczyn E, Tan F, Olson N, et al. De- velopment and validation of a deep learning algorithm for improving gleason scoring of prostate cancer. NPJ Digital Medicine 2019;2(1):1–10. doi: 10.1038/ s41746- 019- 0112- 2 . [46] Cohen T , Welling M . Group equivariant convolutional networks. In: Proc. Int’l Conf. on Machine Learning; 2016. p. 2990–9 . [47] Kumar N, Verma R, Anand D, Zhou Y, Onder OF, Tsougenis E, Chen H, et al. A multi-organ nucleus segmentation challenge. IEEE Trans Med Imaging 2019;39(5):1380–91. doi: 10.1109/TMI.2019.2947628 . [48] Schneider J, Agus M. Reflections on the clinical acceptance of artificial in- telligence. In: Househ M, Kushniruk A, Borycki E, editors. Multiple Perspec- tives on Artificial Intelligence in Healthcare: From Challenges to Opportunities. SpringerBriefs; 2021. p. 0. doi: 10.1007/978- 3- 030- 67303- 1 . To appear [49] Kingma D.P., Welling M.. Auto-encoding variational Bayes. arXiv preprint; 2013. https://arxiv.org/abs/1312.6114 . [50] Xu J, Xiang L, Liu Q, Gilmore H, Wu J, Tang J, Madabhushi A. Stacked sparse au- toencoder (SSAE) for nuclei detection on breast cancer histopathology images. IEEE Trans Med Imaging 2015;35(1):119–30. doi: 10.1109/TMI.2015.2458702 . [51] Hou L, Nguyen V, Kanevsky AB, Samaras D, Kurc TM, Zhao T, Gupta RR, et al. Sparse autoencoder for unsupervised nucleus detection and representa- tion in histopathology images. Pattern Recognit 2019;86:188–200. doi: 10.1016/ j.patcog.2018.09.007 . [52] Makhzani A., Frey B.. K-sparse autoencoders. arXiv preprint; 2013. https://arxiv. org/abs/1312.5663 . [53] Kalinin AA, Allyn-Feuer A, Ade A, Fon G-V, Meixner W, Dilworth D, Husain SS, et al. 3D Shape modeling for cell nuclear morphological analysis and classifi- cation. Sci Rep 2018;8. doi: 10.1038/s41598- 018- 31924- 2 . [54] Calì C , Agus M , Kare K , Boges D , Lehvaslaiho H , Hadwiger M , Magistretti P . 3D Cellular reconstruction of cortical glia and parenchymal morphometric analy- sis from serial block-face electron microscopy of juvenile rat. Prog Neurobiol 2019:101696 . j.pneurobio.2019.101696 [55] Härtel S , Jara J , Lemus C , Concha M . 3D morphotopological analysis of asym- metric neuronal morphogenesis in developing zebrafish. Computational mod- elling of objects represented in images Fundamentals, methods and applica- tions 2018;6:215–20 . [56] Calì C, Baghabra J, Boges DJ, Holst GR, Kreshuk A, Hamprecht FA, Srinivasan M, et al. Three-dimensional immersive virtual reality for studying cellular com- partments in 3D models from EM preparations of neural tissues. Journal of Computational Neurology 2016;524(1):23–38. doi: 10.1002/cne.23852 . [57] Queisser SG, Wittmann M, Bading H, Wittum G. Filtering, reconstruction, and measurement of the geometry of nuclei from hippocampal neurons based on confocal microscopy data. J Biomed Opt 20 08;13(1):0140 09. doi: 10.1117/1. 2829773 . [58] Wittmann M, Queisser G, Eder A, Wiegert JS, Bengtson CP, Hellwig A, Wit- tum G, Bading H. Synaptic activity induces dramatic changes in the geom. of the cell nucleus: interplay between nuclear structure, histone H3 phos- phorylation, and nuclear calcium signaling. J Neurosci 2009;29(47):14687–700. doi: 10.1523/JNEUROSCI.1160-09.2009 . [59] Nandakumar V, An X, Wang Y, Johnson R, Meldrum D. Conformal mapping of nuclei in 3D tomographic cell images to assess shape heterogeneity. In: Proc. IEEE Int’l Symp. on Biomedical Imaging; 2012. p. 222–5. doi: 10.1109/ISBI.2012. 6235524 . [60] Agus M, Veloz Castillo M, Garnica Molina JF, Gobbetti E, Lehvaslaiho H, Morales Tapia A, Magistretti P, et al. Shape analysis of 3D nanoscale recon- structions of brain cell nuclear envelopes by implicit and explicit parametric representations. Computers & Graphics 2019a. doi: 10.1016/j.cagx.2019.10 0 0 04 . [61] Agus M, Gobbetti E, Pintore G, Calì C, Schneider J. WISH: Efficient 3D biological shape classification through Willmore flow and spherical harmonics decompo- sition. In: Proc. IEEE/CVF Conf. on Computer Vision and Pattern Recognition Workshops (CVPRW); 2020b. p. 972–3. doi: 10.1109/CVPRW50498.2020.00494 . [62] Shen L, Makedon F. Spherical mapping for processing of 3D closed surfaces. Image Vis Comput 2006;24(7):743–61. doi: 10.1016/j.imavis.2006.01.011 . [63] Kazhdan M , Funkhouser T , Rusinkiewicz S . Rotation invariant spherical har- monic representation of 3D shape descriptors. In: Proc. EG Symp. Geometry Processing; 2003. p. 156–64 . [64] Coggan JS, Calì C, Keller D, Agus M, Boges D, Abdellah M, Kare K, et al. A pro- cess for digitizing and simulating biologically realistic oligocellular networks demonstrated for the neuro-glio-vascular ensemble. Front Neurosci 2018;12. doi: 10.3389/fnins.2018.00664 . [65] Lorensen WE, Cline HE. Marching cubes: A high resolution 3d surface con- struction algorithm. In: Proc. ACM SIGGRAPH; 1987. p. 163–9. doi: 10.1145/ 37401.37422 . [66] Gottschalk S.. Collision queries using oriented bounding boxes. PhD Thesis, University of North Carolina at Chapel Hill; 20 0 0. [67] Blu T, Thévenaz P, Unser M. Linear interpolation revitalized. IEEE Trans Image Process 2004;13(5):710–19. doi: 10.1109/TIP.2004.826093 . [68] Kuhl FP, Giardina CR. Elliptic fourier features of a closed contour. Computer Graphics and Image Processing 1982;18(3):236–58. doi: 10.1016/0146-664X(82) 90034-X . [69] Vallet B, Lévy B. Spectral geometry processing with manifold harmonics. Com- put Graphics Forum 2008;27(2):251–60. doi: 10.1111/j.1467-8659.2008.01122.x . [70] Farin G . Curves and surfaces for CAGD–A practical guide. 5th. Morgan Kauf- man; 2001. ISBN 978-1-558-60737-8 . [71] Crane K, Pinkall U, Schröder P. Robust fairing via conformal curvature flow. ACM Trans Graph 2013;32(4):61:1–61:10. doi: 10.1145/2461912.2461986 . [72] Golum GH , Van Loan CF . Matrix computations. 4th. The Johns Hopkins Univer- sity Press; 2013. ISBN 978-1-4214-0859-0 . [73] Campello RJ, Moulavi D, Sander J. Density-based clustering based on hierarchi- cal density estimates. In: Pacific-Asia Conf. on Knowledge Discovery and Data Mining (PAKDD); 2013. p. 160–72. doi: 10.1007/978- 3- 642- 37456- 2 _ 14 . [74] Arthur D , Vassilvitskii S . k-means++: The advantages of careful seeding. In: Proc. ACM/SIAM Symp. on Discrete Algorithms (SODA); 2007. p. 1027–35 . [75] Linde Y, Buzo A, Gray R. An algorithm for vector quantizer design. IEEE Trans Commun 1980;28(1):84–95. doi: 10.1109/TCOM.1980.1094577 . [76] Lloyd S. Least squares quantization in PCM. IEEE Trans Inf Theory 1982;28(2):129–37. doi: 10.1109/TIT.1982.1056489 . [77] Guennebaud G., Jacob B., Avery P., Bachrach A., Barthelemy S., et al.. Eigen. http://eigen.tuxfamily.org ; 2010. [78] Zheng Y, Guo B, Yan Y, He W. O2O method for fast 2D shape retrieval. IEEE Trans Image Process 2019;28(11):5366–78. doi: 10.1109/TIP.2019.2919195 . [79] Abbas S, Farhan S, Fahiem MA, Tauseef H. Efficient shape classification using zernike moments and geometrical features on mpeg-7 dataset. Advances in Electrical and Computer Engineering 2019;19(1):45–51. doi: 10.4316/AECE.2019. 01006 . [80] Wang B, Gao Y. Hierarchical string cuts: a translation, rotation, scale, and mirror invariant descriptor for fast shape retrieval. IEEE Trans Image Process 2014;23(9):4101–11. doi: 10.1109/TIP.2014.2343457 . [81] Zheng Y , Meng F , Liu J , Guo B , Song Y , Zhang X , Wang L . Fourier transform to group feature on generated coarser contours for fast 2d shape matching. IEEE Access 2020;8:90141–52 . [82] Escalera S, Fornés A, Pujol O, Radeva P, Sánchez G, Lladós J. Blurred shape model for binary and grey-level symbol recognition. Pattern Recognit Lett 2009;30(15):1424–33. doi: 10.1016/j.patrec.2009.08.001 . [83] Shekar B, Pilar B. Shape representation and classification through pattern spec- trum and local binary pattern–a decision level fusion approach. In: Proc. Int’l Conf. on Signal and Image Processing; 2014. p. 218–24. doi: 10.1109/ICSIP.2014. 41 . [84] Calì C, Wawrzyniak M, Becker C, Maco B, Cantoni M, Jorstad A, Nigro B, et al. The effects of aging on neuropil structure in mouse somatosensory cortex-a 3D electron microscopy analysis of layer 1. PLoS ONE 2018. doi: 10.1371/journal. pone.0198131 . 124 K. Al-Thelaya, M. Agus, N.U. Gilal et al. Computers & Graphics 98 (2021) 105–125 [85] Agus M, Boges D, Gagnon N, Magistretti PJ, Hadwiger M, Calì C. GLAM: Glycogen-derived lactate absorption map for visual analysis of dense and sparse surface reconstructions of rodent brain structures on desktop systems and virtual environments. Computers & Graphics 2018;74:85–98. doi: 10.1016/ j.cag.2018.04.007 . [86] Agus M, Calì C, Al-Awami A, Gobbetti E, Magistretti P, Hadwiger M. Interactive volumetric visual analysis of glycogen-derived energy absorption in nanomet- ric brain structures. Comput Graphics Forum 2019b;38(3):427–39. doi: 10.1111/ cgf.13700 . [87] Willmore T. A survey on Willmore immersions. In: Geometry and Topology of Submanifolds IV; 1992. p. 11–16. doi: 10.1142/1723 . [88] Tomassy GS , Berger DR , Chen H-H , Kasthuri N , Hayworth KJ , Vercelli A , Seung HS , Lichtman JW , Arlotta P . Distinct profiles of myelin distribu- tion along single axons of pyramidal neurons in the neocortex. Science 2014;344(6181):319–24 . [89] Sedlmair M, Tatu A, Munzner T, Tory M. A taxonomy of visual cluster sepa- ration factors. Comput Graphics Forum 2012;31(3pt4):1335–44. doi: 10.1111/j. 1467-8659.2012.03125.x . [90] Vallet B, Lévy B. Spectral geometry processing with manifold harmonics. Com- put Graphics Forum 2008;27(2):251–60. doi: 10.1111/j.1467-8659.2008.01122.x . 125 