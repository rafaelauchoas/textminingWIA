Artificial Intelligence 134 (2002) 9–22Disjoint pattern database heuristicsRichard E. Korf a,∗, Ariel Felner ba Computer Science Department, University of California, Los Angeles, Los Angeles, CA 90095, USAb Department of Mathematics and Computer Science, Bar-Ilan University, Ramat-Gan, 52900 IsraelAbstractWe describe a new technique for designing more accurate admissible heuristic evaluationfunctions, based on pattern databases [J. Culberson, J. Schaeffer, Comput. Intelligence 14 (3)(1998) 318–334]. While many heuristics, such as Manhattan distance, compute the cost of solvingindividual subgoals independently, pattern databases consider the cost of solving multiple subgoalssimultaneously. Existing work on pattern databases allows combining values from different patterndatabases by taking their maximum. If the subgoals can be divided into disjoint subsets so that eachoperator only affects subgoals in one subset, then we can add the pattern-database values for eachsubset, resulting in a more accurate admissible heuristic function. We used this technique to improveperformance on the Fifteen Puzzle by a factor of over 2000, and to find optimal solutions to 50random instances of the Twenty-Four Puzzle.  2002 Elsevier Science B.V. All rights reserved.Keywords: Problem solving; Single-agent search; Heuristic search; Heuristic evaluation functions; Patterndatabases; Sliding-tile puzzles; Fifteen Puzzle; Twenty-Four Puzzle; Rubik’s Cube1. Introduction and overviewThe sliding-tile puzzles are a classic challenge for search algorithms in AI. The key tofinding optimal solutions to these problems is an accurate admissible heuristic function. Wedescribe a generalization of the Manhattan distance heuristic that considers the interactionsamong multiple tiles, while allowing the moves of different groups of tiles to be addedtogether without violating admissibility. This results in a much more accurate admissibleheuristic.* Corresponding author.E-mail addresses: korf@cs.ucla.edu (R.E. Korf), felner@macs.biu.ac.il (A. Felner).0004-3702/02/$ – see front matter  2002 Elsevier Science B.V. All rights reserved.PII: S 0 0 0 4 - 3 7 0 2 ( 0 1 ) 0 0 0 9 2 - 310R.E. Korf, A. Felner / Artificial Intelligence 134 (2002) 9–22Fig. 1. The Fifteen and Twenty-Four Puzzles in their goal states.1.1. Sliding-tile puzzlesThe 4 × 4 Fifteen, and 5 × 5 Twenty-Four Puzzles are shown in Fig. 1. A square frame isfilled with tiles, except for one empty or blank position. Any tile horizontally or verticallyadjacent to the blank can be slid into that position. The task is to rearrange the tiles froma given initial configuration into a particular goal configuration, ideally or optimally in aminimum number of moves. The state space for the Fifteen Puzzle space contains about1013 states, and the Twenty-Four Puzzle contains almost 1025 states.The Fifteen Puzzle was invented by Sam Loyd in the 1870s [13], and appeared in thescientific literature shortly thereafter [7]. The editor of the journal added the followingcomment to the paper: “The ‘15’ puzzle for the last few weeks has been prominently beforethe American public, and may safely be said to have engaged the attention of nine out often persons of both sexes and of all ages and conditions of the community”. The reason forthe Fifteen Puzzle craze was that Loyd offered a $1000 cash prize to transform a particularinitial state to a particular goal state. Johnson and Story proved that it wasn’t possible, sincethe state space was divided into even and odd permutations, with no way to transform oneinto the other by legal moves.1.2. Search algorithmsThe 3 × 3 Eight puzzle, with only 181,440 reachable states, can be solved optimally bya brute-force breadth-first search in a fraction of a second.To address the Fifteen Puzzle requires a heuristic search algorithm, such as A∗ [6]. A∗ isa best-first search in which the cost of a node n is computed as f (n) = g(n) + h(n), whereg(n) is the length of the path from the start to node n, and h(n) is a heuristic estimate ofthe length of a shortest path from node n to the goal. If h(n) is admissible, or never overes-timates distance to the goal, then A∗ is guaranteed to find a shortest solution, if one exists.The classic heuristic function for the sliding-tile puzzles is Manhattan distance. For eachtile we count the number of grid units between its current and goal locations, and sum thesevalues for all tiles. Manhattan distance is a lower bound on actual solution length, becauseevery tile must move at least its Manhattan distance, and each move only moves one tileone square.Unfortunately, A∗ cannot solve random instances of the Fifteen Puzzle, because it storesevery node generated, and exhausts the available memory in minutes on most problems.Iterative-Deepening-A∗ (IDA∗) [8] is a linear-space version of A∗. It performs a series ofdepth-first searches, pruning a path when the cost f (n) = g(n) + h(n) of the last node n onR.E. Korf, A. Felner / Artificial Intelligence 134 (2002) 9–2211the path exceeds a threshold for that iteration. The threshold is initially set to the heuristicestimate of the initial state, and increases in each iteration to the lowest cost of all nodespruned on the last iteration, until a goal node is expanded. IDA∗ also guarantees an optimalsolution if the heuristic function is admissible. Unlike A∗, however, IDA∗ only requiresmemory that is linear in the maximum search depth. IDA∗ with the Manhattan distanceheuristic was the first algorithm to find optimal solutions to random instances of the FifteenPuzzle [8]. An average of about 400 million nodes are generated per problem instance,requiring almost five hours on a DEC 2060 in 1984.1.3. OverviewOn larger problems, IDA∗ with Manhattan distance takes too long, and more accurateheuristic functions are needed. While Manhattan distance sums the cost of solving eachtile independently, we consider the costs of solving several tiles simultaneously, takinginto account the interactions between them. Our main contribution is to show how heuristicvalues for different groups of tiles can be added together, rather than taking their maximum.We first present existing heuristics, including non-additive pattern databases, using theexample of Rubik’s Cube. Next, we describe disjoint pattern databases, showing how theycan be precomputed, and combined into an admissible heuristic. We then present exper-imental results on the Fifteen and Twenty-Four puzzles, finding optimal solutions to theFifteen Puzzle 2000 times faster than with Manhattan distance, and finding optimal solu-tions to 50 random Twenty-Four Puzzles. Initial results of this work first appeared in [11].2. Existing heuristics2.1. Manhattan distanceWhere did the Manhattan distance heuristic come from? In addition to the standardanswer to this question, we present an alternative that suggests the disjoint pattern databaseextension.The standard explanation for the origin of admissible heuristic functions is that theyrepresent the cost of exact solutions to simplified versions of the original problem [15].For example, in a sliding-tile puzzle, to move a tile from position x to position y, x andy must be adjacent, and position y must be empty. If we ignore the empty constraint, weget a simplified problem where any tile can move to any adjacent position, and multipletiles can occupy the same position. In this new problem, the tiles are independent of eachother, and we can solve any instance optimally by moving each tile along a shortest path toits goal position, counting the number of moves made. The cost of an optimal solution tothis simplified problem is exactly the Manhattan distance from the initial to the goal state.Since we removed a constraint on the moves, any solution to the original problem is alsoa solution to the simplified problem, and the cost of an optimal solution to the simplifiedproblem is a lower bound on the cost of an optimal solution to the original problem. Thus,any heuristic derived in this way is admissible.Alternatively, we can derive Manhattan distance by observing that a sliding-tile puzzlecontains subproblems of getting each tile to its goal location. This suggests considering thecost of solving each subproblem independently, assuming no interactions between them.12R.E. Korf, A. Felner / Artificial Intelligence 134 (2002) 9–22In other words, we could search for the minimum number of moves needed to get each tileto its goal location, ignoring the other tiles, which is the Manhattan distance of that tile.Since each move only moves one tile, we can add these individual distances together toget an admissible heuristic for the problem. While the first derivation requires a problemdescription in terms of constraints on the legal moves, the second only requires recognizinga single tile as a subproblem.The key idea here, which makes it possible to efficiently compute Manhattan distance,is the assumption that the individual tiles do not interact with one another. The reasonthe problem is difficult, and why Manhattan distance is only a lower bound on actualsolution cost, is that the tiles get in each other’s way. By taking into account some ofthese interactions, we can compute more accurate admissible heuristic functions.2.2. Non-additive pattern databasesPattern databases [1], originally applied to the Fifteen Puzzle, are one way to do this.Fig. 2 shows a subset of the Fifteen Puzzle tiles, called the fringe tiles. For a given state, theminimum number of moves needed to get the fringe tiles to their goal positions, includingrequired moves of other tiles, is a lower bound on the number of moves needed to solve theentire puzzle.This number depends on the current positions of the fringe tiles and the blank, but isindependent of the positions of the other tiles. Thus, we can precompute all these values,store them in memory, and look them up as they are needed during the search. Since thereare seven fringe tiles and one blank, and sixteen different locations, the total number ofpossible permutations of fringe tiles and blank is 16!/(16 − 8)! = 518,918,400. For eachpermutation, we store the number of moves needed to move the fringe tiles and the blankto their goal locations, which takes less than one byte. Thus, we can store the whole patterndatabase table in less than 495 megabytes of memory.We can compute this entire table with a single breadth-first search backward from thegoal state shown in Fig. 2. The unlabelled tiles are all equivalent, and a state is uniquelydetermined by the positions of the fringe tiles and the blank. As each configuration of thesetiles is encountered for the first time, the number of moves made to reach it is stored in thecorresponding entry of the table, until all entries are filled. Note that this table is onlycomputed once for a given goal state, and its cost is amortized over the solution of multipleproblem instances with the same goal state.Once the table is stored, we use IDA∗ to search for an optimal solution to a particularproblem instance. As each state is generated, the positions of the fringe tiles and the blankFig. 2. The fringe pattern for the Fifteen Puzzle.R.E. Korf, A. Felner / Artificial Intelligence 134 (2002) 9–2213are used to compute an index into the pattern database, and the corresponding entry, whichis the number of moves needed to solve the fringe tiles and blank, is used as the heuristicvalue for that state.Using this pattern database, Culberson and Schaeffer reduced the number of nodesgenerated to solve random Fifteen Puzzles by a factor of 346, and reduced the running timeby a factor of six, compared to Manhattan distance [1]. Combining this with another patterndatabase, and taking the maximum of the two database values as the overall heuristic value,reduced the nodes generated by about a thousand, and the running time by a factor oftwelve.2.2.1. Rubik’s CubeNon-additive pattern databases were also used to find the first optimal solutions toRubik’s Cube [10] (see Fig. 3). Rubik’s Cube was invented in 1974 by Erno Rubikof Hungary, and like the Fifteen Puzzle a hundred years earlier, became a world-widesensation. More than 100 million Rubik’s Cubes have been sold, making it the best-knowncombinatorial puzzle of all time. Each 3 × 3 plane of the cube can be rotated independently,and the task is to rearrange the individual pieces so that each side shows only one color.The 3 × 3 × 3 Rubik’s Cube contains about 4.3252 × 1019 different reachable states.There are 20 movable subcubes, or cubies, which can be divided into eight corner cubies,with three faces each, and twelve edge cubies, with two faces each. There are 88,179,840different positions and orientations of the corner cubies, and the number of moves neededto solve just the corner cubies ranges from zero to eleven. At four bits per entry, a patterndatabase for the corner cubies can be stored in about 42 megabytes of memory. Six of thetwelve edge cubies generate 42,577,920 different possibilities, and a corresponding patterndatabase occupies about 20 megabytes of memory. The remaining six edge cubies generateanother database of the same size.Given a state of an IDA∗ search, we use the configuration of the corner cubies tocompute an index into the corner-cubie pattern database, whose value tells us the numberof moves needed to solve just the corner cubies. We also use each of the two sets of sixedge cubies to compute indices into the corresponding edge-cubie databases, yielding thenumber of moves needed to solve each set of six edge cubies. Given these three differentheuristic values, the best way to combine them, without overestimating actual solutioncost, is to take their maximum, even though each cubie belongs to only one database. Thereason is that every twist of the cube moves four edge cubies and four corner cubies,and moves that contribute to the solution of cubies in one pattern database may alsoFig. 3. 3 × 3 × 3 Rubik’s Cube.14R.E. Korf, A. Felner / Artificial Intelligence 134 (2002) 9–22contribute to the solution of the others. IDA∗, using the maximum of the three pattern-database heuristic values described above, will find optimal solutions to random instancesof Rubik’s Cube [10]. The median optimal solution length is only 18 moves. One probleminstance generated a trillion nodes, and required a couple weeks to run. With improvementsby Herbert Kociemba and Michael Reid, larger pattern databases, and faster computers,most states can now be solved optimally in about an hour.2.2.2. Limitations of non-additive pattern databasesThe main limitation of non-additive pattern databases is that they can’t solve largerproblems. For example, since the Twenty-Four puzzle contains 25 different positions,a pattern database covering n tiles and the blank requires 25!/(25 − n − 1)! entries.A database of only six tiles and the blank would require over 2.4 billion entries.Furthermore, the values from a database of only six tiles would be smaller than theManhattan distance of all the tiles. With multiple databases, the best way to combine themadmissibly is to take the maximum of their values, even if the sets of tiles are disjoint. Thereason is that non-additive pattern database values include all moves needed to solve thepattern tiles, including moves of other tiles.Instead of taking the maximum of different pattern database values, we would like to beable to sum their values, to get a more accurate heuristic, without violating admissibility.This is the main idea of disjoint pattern databases.3. Disjoint pattern databasesTo construct a disjoint pattern database for the sliding-tile puzzles, we partition the tilesinto disjoint groups, such that no tile belongs to more than one group. We then precomputetables of the minimum number of moves of the tiles in each group that are required to getthose tiles to their goal positions. We call the set of such tables, one per group of tiles, adisjoint pattern database, or a disjoint database for short. Then, given a particular state inthe search, for each group of tiles, we use the positions of those tiles to compute an indexinto the corresponding table, retrieve the number of moves required to solve the tiles in thatgroup, and then add together the values for each group, to compute an overall heuristic forthe given state. This value will be at least as large as the Manhattan distance, and usuallylarger, since it accounts for interactions between tiles in the same group.The key difference between disjoint databases and the non-additive databases describedabove is that the non-additive databases include all moves required to solve the pattern tiles,including moves of tiles not in the pattern set. As a result, given two such databases, evenif there is no overlap among their tiles, we can only take the maximum of the two valuesas an admissible heuristic, because moves counted in one database may move tiles in theother database, and hence these moves would be counted twice. In a disjoint database, weonly count moves of the tiles in the group. While this idea is very simple, it eluded at leasttwo groups of researchers who worked on this problem [1,9].A second difference between these two types of databases is that our disjoint databasesdon’t consider the blank position, decreasing their size. A disjoint database contains theminimum number of moves needed to solve a group of tiles, for all possible blank positions.R.E. Korf, A. Felner / Artificial Intelligence 134 (2002) 9–2215Fig. 4. Disjoint database for Fifteen Puzzle and its reflection.Manhattan distance is a trivial example of a disjoint database, where each group containsonly a single tile. While Manhattan distance was initially discovered by hand, it could alsobe “discovered” automatically as follows. For each tile in each position, perform a searchuntil it reaches its goal location, in which all other tiles are indistinguishable. A state ofthis search is uniquely determined by the position of the tile in question and the positionof the blank, and only moves of the tile of interest are counted. Since the operators ofthe sliding-tile puzzle are invertible, we can perform a single search for each tile, startingfrom its goal position, and record how many moves of the tile are required to move it toevery other position. Doing this for all tiles results in a set of tables which give, for eachpossible position of each tile, its Manhattan distance from its goal position. Since we onlycounted moves of the tile of interest, and each move only moves a single tile, we can sumthe Manhattan distances to get an admissible heuristic.Two non-trivial examples of disjoint databases for Fifteen Puzzle are shown in Fig. 4,where we have divided the tiles into a group of seven and a group of eight. The seven-tile database contains 57,657,600 entries, which range from 0 to 33 moves. The eight-tiledatabase contains 518,918,400 entries, which range from 0 to 38 moves. In neither case isthe blank position part of the index to the database. As a general rule, when partitioningthe tiles, we want to group together tiles that are near each other in the goal state, sincethese tiles will interact the most with one another.4. Experimental results4.1. Fifteen PuzzleWe found all optimal solutions to 1000 random Fifteen Puzzle problem instances, usingIDA∗ with a variety of heuristics. The average optimal solution length of these instancesis 52.522 moves, and the average number of optimal solutions is 15.9. Table 1 shows theresults. The first data column shows the average value of the heuristic function over the1000 initial states. The second column gives the average number of nodes generated perproblem instance to find the first optimal solution. The third column displays the averagespeed of the algorithm, in nodes per second, on a 440 MegaHertz Sun Ultra10 workstation.The fourth column indicates the average running time, in seconds, to find the first optimalsolution. The last column gives the average number of nodes generated to find all optimalsolutions to a problem instance.The first row gives results for the Manhattan distance heuristic. The second row is forManhattan distance enhanced by linear conflicts. Historically, the linear-conflict heuristicwas the first significant improvement over Manhattan distance [5]. It applies to tiles in theirgoal row or column, but reversed relative to each other. For example, assume the top rowof a given state contains the tiles (2 1) in that order, but in the goal state they appear in16R.E. Korf, A. Felner / Artificial Intelligence 134 (2002) 9–22Table 1Experimental results on the Fifteen PuzzleHeuristic functionValueNodesNodes/secSecondsAll solutionsManhattan distance36.940401,189,6307,269,02655.1921,178,106,819Linear conflictsDisjoint databaseDisjoint + reflected38.78844.75245.63040,224,6254,142,193136,2892,174,36236,7101,377,6309.7100.0630.027144,965,491472,595130,367the order (1 2). To reverse them, one of the tiles must move out of the top row, to allowthe other tile to pass by, and then move back into the top row. Since these two moves arenot counted in the Manhattan distance of either tile, two moves can be added to the sumof the Manhattan distances of these two tiles without violating admissibility. The sameidea can be applied to tiles in their goal column as well. In fact, a tile in its goal positionmay participate in both a row and a column conflict simultaneously. Since the extra movesrequired to resolve a row conflict are vertical moves, and those required to resolve a columnconflict are horizontal moves, both sets of moves can be added to the Manhattan distance,without violating admissibility. The linear-conflict heuristic reduces the number of nodesgenerated by an order of magnitude, at a cost of almost factor of two in speed, for an overallspeedup of over a factor of five, compared to Manhattan distance.The next two rows are for disjoint pattern database heuristics. The third row representsthe heuristic which is the sum of the seven and eight-tile database values depicted on theleft side of Fig. 4. We used one byte per entry for efficiency, occupying a total of 550megabytes, but these databases could be compressed. For example, we could store onlythe additional moves exceeding the Manhattan distances of the pattern tiles, and separatelycompute the Manhattan distances during the search. Furthermore, since the parity of theadditional moves is the same as that of the Manhattan distance, we could store only halfthe number of additional moves, and multiply by two.The fourth row represents a heuristic computed by starting with the heuristic of the thirdrow. We then compute the sum of the seven- and eight-tile database values shown on theright side of Fig. 4. Finally, the overall heuristic is the maximum of these two sums. Sincethe two different partitions are reflections of one another, we use the same pair of tablesfor both databases, and simply reflect the tiles and their positions about the main diagonalto obtain the reflected values.This last heuristic reduces the number of node generations by over four orders ofmagnitude, and the running time by a factor of over two thousand, compared to Manhattandistance. This comes at the cost of 550 megabytes of memory. By contrast, the best non-additive pattern database heuristic used by Culberson and Schaeffer [1], using a similaramount of memory, generated almost ten times more nodes then our best disjoint database,and ran only twelve times faster than simple Manhattan distance.4.2. Twenty-Four PuzzleFinding optimal solutions to the Twenty-Four Puzzle is only practical with our mostpowerful heuristics. We optimally solved fifty random problem instances with IDA∗, usingR.E. Korf, A. Felner / Artificial Intelligence 134 (2002) 9–2217Fig. 5. Disjoint databases for Twenty-Four Puzzle.a disjoint pattern database heuristic, and its reflection about the main diagonal, shown inFig. 5. Each group consists of six tiles, requiring 127,512,000 entries each. For a givenstate, the value from each database is the sum of the number of moves needed to solveall four groups of tiles from that state. The overall heuristic is the maximum of the valuesfrom the original and reflected databases. Since there are only two different-shaped groups,a 2 × 3 block of tiles, and an irregular block surrounding the blank, we only have to storetwo different tables, with the remaining values obtained by mapping the tiles and theirpositions into one of these two tables. The heuristic values for the 2 × 3 group range from0 to 35 moves, and for the irregular group they range from 0 to 34 moves. At one byte perentry, the total amount of memory for both tables is 243 megabytes, but these tables couldbe compressed as well.Table 2 shows the initial state, length of the optimal solution, and number of nodesgenerated by IDA∗ to find the first solution to each problem instance. The initial state isrepresented by listing the tiles from left to right and top to bottom, with zero representingthe blank. In this notation, the tiles of the goal state in Fig. 1 would be listed in numericalorder. The average optimal solution length of these 50 problems is 100.78 moves. Theaverage number of nodes generated is 360,892,479,671. The program is written in C, andgenerates about 2,110,000 nodes per second on a 440 MegaHertz Sun Ultra10 workstation.The running times on individual problems range from 18 seconds to almost 23 days, withan average of two days per problem. Using the analytic results developed in [12], we canpredict that solving the Twenty-Four Puzzle with Manhattan distance alone would take anaverage of about 50,000 years per problem! The average Manhattan distance for a randomsample of 10,000 initial states is 76.078 moves, while for our disjoint database heuristic itis 81.607 moves.4.2.1. Comparison to previous resultsPreviously, the only program to find optimal solutions to the Twenty-Four Puzzle solvedthe first ten problems in Table 2 [9], and differed from this in two important respects.First, the heuristic used in [9] was much more complex. Secondly, [9] used a technique,based on finite-state machines (FSMs), to prune duplicate nodes representing the samestate arrived at via different paths in the graph [16]. FSM pruning reduced the number ofnodes generated by IDA∗ on five of the problems by a factor that ranged from 2.4 to 3.6.For this work, we did not use FSM pruning, because the technique is complex, andthe results depend on the particular FSM used, making it difficult for other researchers toreproduce the same results. Thus, we solved all 50 problems without duplicate pruning,except for eliminating the parent of a node as one of its children.Table 3 shows comparative results for the five easiest problems solved in [9], which wealso solved using the same heuristic as in [9], but without duplicate pruning. The first18R.E. Korf, A. Felner / Artificial Intelligence 134 (2002) 9–22Table 2Twenty-Four Puzzle dataNoInitial stateLengthNodes12345678910111213141516171819202122232425262728293031323314 5 9 2 18 8 23 19 12 17 15 0 10 20 4 6 11 21 1 7 24 3 16 22 1316 5 1 12 6 24 17 9 2 22 4 10 13 18 19 20 0 23 7 21 15 11 8 3 146 0 24 14 8 5 21 19 9 17 16 20 10 13 2 15 11 22 1 3 7 23 4 18 1218 14 0 9 8 3 7 19 2 15 5 12 1 13 24 23 4 21 10 20 16 22 11 6 1717 1 20 9 16 2 22 19 14 5 15 21 0 3 24 23 18 13 12 7 10 8 6 4 112 0 10 19 1 4 16 3 15 20 22 9 6 18 5 13 12 21 8 17 23 11 24 7 1421 22 15 9 24 12 16 23 2 8 5 18 17 7 10 14 13 4 0 6 20 11 3 1 197 13 11 22 12 20 1 18 21 5 0 8 14 24 19 9 4 17 16 10 23 15 3 2 63 2 17 0 14 18 22 19 15 20 9 7 10 21 16 6 24 23 8 5 1 4 11 12 1323 14 0 24 17 9 20 21 2 18 10 13 22 1 3 11 4 16 6 5 7 12 8 15 1915 11 8 18 14 3 19 16 20 5 24 2 17 4 22 10 1 13 9 21 23 7 6 12 012 23 9 18 24 22 4 0 16 13 20 3 15 6 17 8 7 11 19 1 10 2 14 5 2121 24 8 1 19 22 12 9 7 18 4 0 23 14 10 6 3 11 16 5 15 2 20 13 1724 1 17 10 15 14 3 13 8 0 22 16 20 7 21 4 12 9 2 11 5 23 6 18 1924 10 15 9 16 6 3 22 17 13 19 23 21 11 18 0 1 2 7 8 20 5 12 4 1418 24 17 11 12 10 19 15 6 1 5 21 22 9 7 3 2 16 14 4 20 23 0 8 1323 16 13 24 5 18 22 11 17 0 6 9 20 7 3 2 10 14 12 21 1 19 15 8 40 12 24 10 13 5 2 4 19 21 23 18 8 17 9 22 16 11 6 15 7 3 14 1 2016 13 6 23 9 8 3 5 24 15 22 12 21 17 1 19 10 7 11 4 18 2 14 20 04 5 1 23 21 13 2 10 18 17 15 7 0 9 3 14 11 12 19 8 6 20 24 22 1624 8 14 5 16 4 13 6 22 19 1 10 9 12 3 0 18 21 20 23 15 17 11 7 27 6 3 22 15 19 21 2 13 0 8 10 9 4 18 16 11 24 5 12 17 1 23 14 2024 11 18 7 3 17 5 1 23 15 21 8 2 4 19 14 0 16 22 6 9 13 20 12 1014 24 18 12 22 15 5 1 23 11 6 19 10 13 7 0 3 9 4 17 2 21 16 20 83 17 9 8 24 1 11 12 14 0 5 4 22 13 16 21 15 6 7 10 20 23 2 18 1922 21 15 3 14 13 9 19 24 23 16 0 7 10 18 4 11 20 8 2 1 6 5 17 129 19 8 20 2 3 14 1 24 6 13 18 7 10 17 5 22 12 21 16 15 0 23 11 417 15 7 12 8 3 4 9 21 5 16 6 19 20 1 22 24 18 11 14 23 10 2 13 010 3 6 13 1 2 20 14 18 11 15 7 5 12 9 24 17 22 4 8 21 23 19 16 08 19 7 16 12 2 13 22 14 9 11 5 6 3 18 24 0 15 10 23 1 20 4 17 2119 20 12 21 7 0 16 10 5 9 14 23 3 11 4 2 6 1 8 15 17 13 22 24 181 12 18 13 17 15 3 7 20 0 19 24 6 5 21 11 2 8 9 16 22 10 4 23 1495969798100101104108113114106109101111103961091101069210395104107811059998889299972,031,102,635211,884,984,52521,148,144,92810,991,471,9662,899,007,625103,460,814,368106,321,592,792116,202,273,7881,818,005,616,6061,519,052,821,9431,654,042,891,186624,413,663,9511,959,833,4871,283,051,362,385173,999,717,8093,803,445,934367,150,048,758987,725,030,433218,284,544,233312,016,177,684724,024,589,3353,592,980,531171,498,441,076357,290,691,483292,174,44412,397,787,39153,444,360,0332,258,006,8704,787,505,6371,634,941,42026,200,330,686428,222,50711 22 6 21 8 13 20 23 0 2 15 7 12 18 16 3 1 17 5 4 9 14 24 10 191061,062,250,612,558R.E. Korf, A. Felner / Artificial Intelligence 134 (2002) 9–2219Table 2 (continued)No3435363738394041424344454647484950Initial stateLengthNodes5 18 3 21 22 17 13 24 0 7 15 14 11 2 9 10 1 8 6 16 19 4 20 23 12102481,039,271,6612 10 24 11 22 19 0 3 8 17 15 16 6 4 23 20 18 7 9 14 13 5 12 1 212 10 1 7 16 9 0 6 12 11 3 18 22 4 13 24 20 15 8 14 21 23 17 19 523 22 5 3 9 6 18 15 10 2 21 13 19 12 20 7 0 1 16 24 17 4 14 8 1110 3 24 12 0 7 8 11 14 21 22 23 2 1 9 17 18 6 20 4 13 15 5 19 1616 24 3 14 5 18 7 6 4 2 0 15 8 10 20 13 19 9 21 11 17 12 22 23 12 17 4 13 7 12 10 3 0 16 21 24 8 5 18 20 15 19 14 9 22 11 6 1 2313 19 9 10 14 15 23 21 24 16 12 11 0 5 22 20 4 18 3 1 6 2 7 17 816 6 20 18 23 19 7 11 13 17 12 9 1 24 3 22 2 21 10 4 8 15 14 5 07 4 19 12 16 20 15 23 8 10 1 18 2 17 14 24 9 5 0 21 6 3 11 13 228 12 18 3 2 11 10 22 24 17 1 13 23 4 20 16 6 15 9 21 19 5 14 0 79 7 16 18 12 1 23 8 22 0 6 19 4 13 2 24 11 15 21 17 20 3 10 14 51 16 10 14 17 13 0 3 5 7 4 15 19 2 21 9 23 8 12 6 11 24 22 20 1821 11 10 4 16 6 13 24 7 14 1 20 9 17 0 15 2 5 8 22 3 12 18 19 232 22 21 0 23 8 14 20 12 7 16 11 3 5 1 15 4 9 24 10 13 6 19 17 182 21 3 7 0 8 5 14 18 6 12 11 23 20 10 15 17 4 9 16 13 19 24 22 123 1 12 6 16 2 20 10 21 18 14 13 17 19 22 0 15 24 3 7 4 8 5 9 11989010096104821061081049310110092107100113116,131,234,7432,582,008,9401,496,759,94438,173,507161,211,472,63365,099,57826,998,190,480245,852,754,92055,147,320,204867,106,23879,148,491,30665,675,717,51030,443,173,162555,085,543,507108,197,305,7024,156,099,168,506column gives the corresponding problem number from Table 2, the second the lengthof the optimal solution, the third the number of node generations from [9] with FSMpruning, the fourth column the number of nodes generated using the same heuristic butwithout FSM pruning, and the fifth column gives the number of nodes generated with ourdisjoint pattern database heuristic without FSM pruning. The program of [9] generatesabout 3,207,000 nodes per second without FSM pruning, compared to about 2,110,000nodes per second for our disjoint database program on the same machine. Taking thisspeed difference into account, the last column gives the speedup factor of our programover that in [9], without FSM pruning, which ranges from a factor of 1.2 to a factor of21.8. Since these comparisons are based on the easiest problems for the program of [9],they may significantly underestimate the average speedup. On the other hand, the programof [9] uses very little memory, which is the main reason it runs faster, since it has muchbetter cache performance.5. Pairwise and higher-order distancesThe main drawback of disjoint database heuristics is that they don’t capture interactionsbetween tiles in different groups of the partition. This requires a different approach,developed independently by Gasser [4] and Korf and Taylor [9]. Consider a table for a20R.E. Korf, A. Felner / Artificial Intelligence 134 (2002) 9–22Table 3Comparison to previous resultsNoLengthFSM pruningNo FSM pruningDisjoint databaseSpeedup14568959810010110818,771,430,92267,189,320,7262,031,102,63521.76483,573,198,724234,662,490,01010,991,471,96614.0468,110,532,60819,865,967,2822,899,007,625221,769,436,018745,218,119,072103,460,814,36882,203,971,683211,917,514,087116,202,273,7884.5084.7391.199sliding-tile puzzle which contains for each pair of tiles, and each possible pair of positionsthey could occupy, the number of moves required of both tiles to move them to their goalpositions. Gasser refers to this table as the 2-tile pattern database, while we call thesevalues the pairwise distances. For most pairs of tiles in most positions, their pairwisedistance will equal the sum of their Manhattan distances. For some tiles in some positionshowever, such as two tiles in a linear conflict, their pairwise distance will exceed the sumof their Manhattan distances. Given n tiles, there are O(n4) entries in the complete 2-tiledatabase, but only those pairwise distances that exceed the sum of the Manhattan distancesof the two tiles need be stored. This table is only computed once for a given goal state.Given a 2-tile database, and a state of the puzzle, we can’t simply sum the databasevalues for each pair of tiles to compute the heuristic, since each tile participates in manypairs, and this sum will grossly overestimate the optimal solution length. Rather, we mustpartition the n tiles into n/2 non-overlapping pairs, and then sum the pairwise distancesfor each of the chosen pairs. To get the most accurate admissible heuristic, we want apartition that maximizes the sum of the pairwise distances. For each state of the search, thecorresponding partition may be different, requiring this computation to be performed foreach heuristic evaluation.For a given state, define a graph where each tile is represented by a node, and there is anedge between each pair of nodes, labelled with the pairwise distance of the correspondingtiles in that state. The task is to choose a set of edges from this graph so that no two chosenedges are incident to the same node, such that the sum of the labels of the chosen edges ismaximized. This is called the maximal weighted matching problem, and can be solved inO(n3) time [15], where n is the number of nodes, or tiles in our case.This technique can obviously be extended to triples of tiles, generating a 3-tile database,or even higher-order distances. Unfortunately, for even three tiles the corresponding three-dimensional matching problem is NP-Complete [3], as is higher-order matching. For thetile puzzles, however, if we only include tiles whose pairwise or triple distances exceedthe sum of their Manhattan distances, this graph is very sparse, and the correspondingmatching problem can be solved relatively efficiently.The main advantage of this approach is that it can potentially capture more tileinteractions, compared to a disjoint database that only captures interactions between tiles inthe same group. Another advantage of this approach is its modest memory requirements.The 2- and 3-tile databases required only three megabytes of memory, compared to the500 megabytes we used for the disjoint databases. The disadvantage of this approach isR.E. Korf, A. Felner / Artificial Intelligence 134 (2002) 9–2221that computing the heuristic value of a given state requires solving a matching problem,which is much more expensive than simply adding the values for each group in a disjointdatabase.Gasser implemented the 2-tile and 3-tile pattern database heuristics for the FifteenPuzzle, and reported node expansions, but not actual running times. We performed similarexperiments on both the Fifteen and Twenty-Four Puzzles. With the 2- and 3-tile databases,it took an average of five seconds to solve a random Fifteen Puzzle problem instance,and generated an average of 700,000 nodes. This compares to 53 seconds for Manhattandistance but only 27 milliseconds for the disjoint databases, which both generated fewernodes and incurred less overhead per node. For the Twenty-Four Puzzle, the 2- and 3-tiledatabases usually generated fewer nodes than the disjoint database. Again, however, sincethis heuristic is more complex to compute, it incurred a larger constant time per node, andthus the actual running time was greater than for the disjoint databases. Since the disjointdatabase heuristics are both simpler and perform better, the details of our experiments withthe 2- and 3-tile databases are omitted here, but can be found in [2].The performance difference between the disjoint databases and the 2- and 3-tiledatabases was greater for the Fifteen Puzzle than the Twenty-Four Puzzle, probablybecause we could store half the Fifteen Puzzle tiles in a single database, but only a quarterof the Twenty-Four Puzzle tiles. For these two problems, the disjoint database heuristicsare both simpler and more effective, but they may not be for larger versions of the problemor other domains.6. Summary, conclusions, and further workWe have found optimal solutions to fifty random instances of the Twenty-Four Puzzle, aproblem with almost 1025 states. The branching factor of the problem is 2.3676 [12], andoptimal solutions average about 100 moves. We also find optimal solutions to the FifteenPuzzle in 27 milliseconds on average. This is by far the best performance on these problemsto date.To achieve this, we implemented IDA∗ with new admissible heuristic functions,based on pattern databases [1]. Rather than computing the costs of solving individualsubgoals independently, a pattern database heuristic considers the costs of solving severalsubgoals simultaneously, taking into account the interactions between them. Culbersonand Schaeffer [1] combined heuristics from different pattern databases by taking themaximum of their values. This is the most general approach, since the maximum of anytwo admissible heuristics is always another admissible heuristic.We introduced disjoint pattern databases to permit the values from different databases tobe added together, resulting in more accurate heuristic values. A disjoint pattern databasepartitions the set of subgoals into disjoint groups, and then adds together the costs ofsolving all the subgoals in each group. This requires that the groups be disjoint, and thata single operator only affect subgoals in a single group. For example, in the sliding-tilepuzzle, each operator only moves one tile. This is just as efficient as taking the maximumof different values, but much more accurate, and still admissible.22R.E. Korf, A. Felner / Artificial Intelligence 134 (2002) 9–22Pattern database heuristics are more expensive to evaluate during search, mostly dueto the latency of randomly accessing the large database in memory. This overhead is morethan compensated for by the decrease in the number of nodes generated to solve a problem.It remains to be seen how general this approach is to the discovery and implementationof admissible heuristic functions. The obvious next step is to apply it to other problems. Allcombinatorial problems involve solving multiple subgoals. This work suggests heuristicsbased on the simultaneous consideration of multiple subgoals, in such a way that theirvalues can be added together to create a more accurate admissible heuristic.AcknowledgementsThis work was supported by NSF Grant IRI-9619447. Thanks to Eitan Yarden andMoshe Malin for their work on pairwise and triple distances.References[1] J. Culberson, J. Schaeffer, Pattern databases, Computational Intelligence 14 (3) (1998) 318–334.[2] A. Felner, Improving search techniques and using them on different environments, Ph.D. Thesis, Dept. ofMathematics and Computer Science, Bar-Ilan University, Ramat-Gan, Israel, 2001. Available at http://www.cs.biu.ac.il/~felner.[3] M.R. Garey, D.S. Johnson, Computers and Intractability: A Guide to the Theory of NP-Completeness, W.H.Freeman, San Francisco, CA, 1979.[4] R. Gasser, Harnessing computational resources for efficient exhaustive search, Ph.D. Thesis, Swiss FederalInstitute of Technology, Zurich, Switzerland, 1995.[5] O. Hansson, A. Mayer, M. Yung, Criticizing solutions to relaxed models yields powerful admissibleheuristics, Information Sci. 63 (3) (1992) 207–227.[6] P.E. Hart, N.J. Nilsson, B. Raphael, A formal basis for the heuristic determination of minimum cost paths,IEEE Trans. Systems Science and Cybernetics 4 (2) (1968) 100–107.[7] W.W. Johnson, W.E. Storey, Notes on the 15 puzzle, Amer. J. Math. 2 (1879) 397–404.[8] R.E. Korf, Depth-first iterative-deepening: An optimal admissible tree search, Artificial Intelligence 27 (1)(1985) 97–109.[9] R.E. Korf, L.A. Taylor, Finding optimal solutions to the twenty-four puzzle, in: Proc. AAAI-96, Portland,OR, 1996, pp. 1202–1207.[10] R.E. Korf, Finding optimal solutions to Rubik’s Cube using pattern databases,in: Proc. AAAI-97,Providence, RI, 1997, pp. 700–705.[11] R.E. Korf, Recent progress in the design and analysis of admissible heuristic functions, in: Proc. AAAI-2000, Austin, TX, 2000, pp. 1165–1170.[12] R.E. Korf, M. Reid, S. Edelkamp, Time complexity of iterative deepening-A∗, Artificial Intelligence 129(2001) 199–218.[13] S. Loyd, Mathematical Puzzles of Sam Loyd (selected and edited by Martin Gardner), Dover, New York,1959.[14] C.H. Papadimitriou, K. Steiglitz, Combinatorial Optimization: Algorithms and Complexity, Prentice-Hall,Englewood Cliffs, NJ, 1982.[15] J. Pearl, Heuristics, Addison-Wesley, Reading, MA, 1984.[16] L. Taylor, R.E. Korf, Pruning duplicate nodes in depth-first search, in: Proc. AAAI-93 Washington, DC,1993, pp. 756–761.