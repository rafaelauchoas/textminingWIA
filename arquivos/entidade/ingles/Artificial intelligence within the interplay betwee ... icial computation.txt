Neurocomputing 410 (2020) 237–270Contents lists available at ScienceDirectNeurocomputingj o u r n a l h o m e p a g e : w w w . e l s e v i e r . c o m / l o c a t e / n e u c o m, Javier Ramírez a, Andrés Ortíz b, Francisco J. Martínez-Murcia b, Fermin Segovia a, JohnArtificial intelligence within the interplay between natural and artificialcomputation: Advances in data science, trends and applicationsJuan M. Górriz a,aa,⇑Suckling aa, Matthew Leming aa, Yu-Dong Zhang x, Jose Ramón Álvarez-Sánchez m, Guido Bologna l, PaulaBonomini z, Fernando E. Casado r, David Charte v, Francisco Charte v, Ricardo Contreras w, Alfredo Cuesta-Infante q, Richard J. Duro h, Antonio Fernández-Caballero f, Eduardo Fernández-Jover y, Pedro Gómez-Vilda o,Manuel Graña c, Francisco Herrera u, Roberto Iglesias r, Anna Lekova e, Javier de Lope d, Ezequiel López-Rubio n, Rafael Martínez-Tomás m, Miguel A. Molina-Cabello n, Antonio S. Montemayor t, Paulo Novais g,Daniel Palacios-Alonso q, Juan J. Pantrigo t, Bryson R. Payne s, Félix de la Paz López m, María AngélicaPinninghoff w, Mariano Rincón m, José Santos j, Karl Thurnhofer-Hemsi n, Athanasios Tsanas p, RamiroVarela k, Jose M. Ferrández ia Dept.of Signal Theory, Networking and Communications University of Granada, Spainb Dept.of Communications Engineering, University of Málaga, Spainc Computational Intelligence Group, University of the Basque Country, San Sebastian, Spaind Department of Artificial Intelligence Universidad Politécnica de Madrid, Spaine Institute of Robotics, Bulgarian Academy of Science, Sofia, Bulgariaf Departamento de Sistemas Informáticos, Universidad de Castilla-La Mancha, Albacete, Spaing Departamento de Informática, Universidade do Minho, Braga, Portugalh Integrated Group for Engineering Research, CITIC, Universidade da Coruna, Spaini Departamento de Electrónica, Tecnología de Computadores y Proyectos, Universidad Politécnica de Cartagena, Spainj Dept. of Computer Science, University of A Coruña, Spaink Dept. of Computer Science, University of Oviedo, Gijón, Spainl Computer Vision and Multimedia Lab, University of Geneva, Switzerlandm Dept. of Artificial Intelligence, Universidad Nacional de Educación a Distancia, Madrid, Spainn Dept. of Computer Languages and Computer Science, University of Málaga, Spaino Neuromorphic Speech Processing Lab, Center for Biomedical Technology. Universidad Politécnica de Madrid, Spainp Data Analytics Research and Technology in Healthcare Group, Usher Institute, University of Edimburgh, UKq Bioinspired Systems and Applications Group, Escuela Técnica Superior de Informática, Universidad Rey Juan Carlos, Madrid, Spainr CiTIUS, Universidad de Santiago de Compostela, Spains Mike Cottrell College of Business, University of North Georgia, Dahlonega, GA, USAt Escuela Técnica Superior de Informática, Universidad Rey Juan Carlos, Madrid, Spainu Dept. of Computer Science and Artificial Intelligence, University of Granada, Spainv Dept. of Computer Science, University of Jaen, Spainw Departamento de Ingeniería Informática y Ciencias de la Computación, Universidad de Concepción, Chilex School of Informatics, University of Leicester, LE1 7RH, UKy Instituto de Bioingeniería, Universidad Miguel Hernández, Spainz Instituto de Ingeniería Biomédica, Fac. de Ingenierïa, Universidad de Buenos Aires, Argentinaaa Dpt. Psychiatry, University of Cambridge, UKa r t i c l ei n f oa b s t r a c tArticle history:Received 31 March 2020Revised 10 May 2020Accepted 26 May 2020Available online 2 June 2020Communicated by Lei ZouArtificial intelligence and all its supporting tools, e.g. machine and deep learning in computationalintelligence-based systems, are rebuilding our society (economy, education, life-style, etc.) and promisinga new era for the social welfare state. In this paper we summarize recent advances in data science andartificial intelligence within the interplay between natural and artificial computation. A review of recentworks published in the latter field and the state the art are summarized in a comprehensive and self-⇑ Corresponding author.E-mail address: gorriz@ugr.es (J.M. Górriz).https://doi.org/10.1016/j.neucom.2020.05.0780925-2312/(cid:1) 2020 Elsevier B.V. All rights reserved.238J.M. Górriz et al. / Neurocomputing 410 (2020) 237–270contained way to provide a baseline framework for the international community in artificial intelligence.Moreover, this paper aims to provide a complete analysis and some relevant discussions of the currenttrends and insights within several theoretical and application fields covered in the essay, from theoreticalmodels in artificial intelligence and machine learning to the most prospective applications in robotics,neuroscience, brain computer interfaces, medicine and society, in general.(cid:1) 2020 Elsevier B.V. All rights reserved.Keywords:Artificial intelligence (AI)Machine learningDeep learningReinforcement learningEvolutionary computationOntologiesArtificial neural networks (ANNs)Big dataRoboticsNeuroscienceHuman–machine interactionVirtual realityEmotion recognitionComputational neuroethologyAutismDyslexiaAlzheimerParkinsonGlaucomaAI for social well-being1. IntroductionArtificial intelligence (AI) has become important in recent dec-ades because of its vast real-world applications. Examples includemedical diagnosis [1], face recognition [2], robotics [3], internetapplications [4], data mining [5], industrial applications [6], andso on.Interdisciplinary research is a hallmark of modern science.1Although different sub-fields have historically operated in segrega-tion, researchers have since found that synthesis of different areasof science gives rise to more original and efficient solutions thatare more applicable to the wider scientific community. A collabora-tion between physicians, data scientists, computer science research-ers, and engineers is required to ensure that AI-based systems andtheir applications are properly trained, operated, and regulated.These systems will provide a dual perspective, both as a method ofanalysis and as a model of synthesis. As a method of analysis, varioustheories that are formulated on the operation of certain biologicalsystems are validated via simulation through different models, with-out having to act directly on these systems. As a model of synthesis,they allow the construction of systems that will solve problems inmanner similar to biological systems.Accessibility to large datasets enables the application of com-plex data science (DS) algorithms and tools, e.g. deep learning(DL), to process huge amounts of bytes of unstructured informa-tion, allowing relevant feature extraction and recognizing high-level abstractions with increasing generalisability. In this sense,DS tools, such as machine learning (ML), have the potential to sup-port several fields of research, such as biomedicine, neuroscienceor robotics, by the automation or resolution of complex tasks intime series prediction, classification, regression, diagnostics, mon-itoring, and so on.The current essay is a vision paper resulting from the discus-the International Work-conference in the Interplaysions atbetween Naturaland Artificial Computation (IWINAC’19),[201,202] which was held on June 3–7, 2019 in Almería, Spain. Itcovers several topics within a huge field of applications by a collec-tion of works that are parcelled into eleven sections, from noveltheories and methods in AI to the most recent applications of thesetechnologiesandneuroscience.robotics, medicalimaging,society,toThe paper is structured as depicted in Fig. 1. We start the essayby introducing two theoretical (Sections 2 and 3), which are1 https://www.nature.com/articles/d41586-019-03325-6.related to computational models and architectures using severalcategorizations, and define the basis and fundamentals in DS andAI. They are able to provide prospective applications in severalfields as shown in next sections. Then, we present specific topicsin DS and AI, such as ethology, affective computing and bio-inspired systems (Sections 4–6), which are specially relevant forour aforementioned research forum. Finally, we introduce in depththe most relevant applications of these tools and techniques inrobotics (Section 7, data analysis (Section 8), neuroscience (Sec-tions 9 and 10), care and well-being (Section 12), and biomedicine(Section 11), in general. Some discussions and trends are describedin Section 13 and conclusions are presented in Section 14. A com-plete taxonomy of the paper can be found in Fig. 2.1.1. A summary of the reviewThe opening Section 2 entitled ‘‘Models: advancing in datascience” refers to formal structures with operational semanticsthat are applicable to a particular domain, which allows us to reachvalid conclusions in that domain based on data from specific cases.The clearest example is that of physical and mathematical models,which supported by a theory, allow us to infer characteristics of thestate of the system. In computing, models are stacked on top ofeach other, from the Turing machine to models that, by means ofan obviously complex operation, are able to approximate any dis-tribution function. Nowadays, the variety of models and objectivesdoes not stop growing. They are used to represent and interpret alltypes of domains, which helps to understand the increasinglyabundant data in the digital world and draw conclusions that werepreviously impossible to conceive.Due to the current relevance of the topic, DL models [7] andapplications in the areas covered in this paper are summarized inthe separated Section 3. DL comprises a series of AI methods whichperform a learning task by extracting several layers of representa-tions with successive levels of abstraction [8]. These representa-tions are usually better suited for the end objective (for instance,classification) than the original features.One source for devising new models and theories in this contextis the mere observation of the behavior of biological systems. Thisis the strict definition of Section 4, entitled ‘‘Ethology”, a disciplinewhose classical domain has been animals in the wild, but it is alsoapplied to animals in the laboratory, looking for advanced pheno-type modeling. The increasing use of quantitative sensors andsophisticated computational resources in order to achieve precisequantitative modeling of behaviors has been termed Computa-J.M. Górriz et al. / Neurocomputing 410 (2020) 237–270239Computing (AC) (Section 5). AC relates to, arises from, or intention-ally influences emotion [10].These systems based on functional aspects of human beings oranimals are beginning to be accepted as valid alternatives to conven-tional approaches in solving specific problems, as shown in Section 6.In general, inspiration from nature, which has evolved over the cen-turies, will have solutions that must be taken into account for similarproblems in order to optimize the available resources. Nonetheless,this is how bio-inspired systems emerged. In the study of bio-inspired systems converge physiology, medicine, systems modeling,microelectronics, computer science, etc. In this sense, the field ofRobotics, summarized in Section 7, is a good example of a bio-inspired system. This is mainly due to the embodiment providedby robots, which makes them much more similar to natural beingsthan the objects of study in other domains. As such, it is an areawhere just about any AI based approach can be used. Anything fromgeneral AI to very particular signal processing algorithms can beimplemented and used on robotic platforms. Recent advances in suchsignal processing algorithms in ML can also be applied to other fieldsof research such as Big Data analysis, processing and visualization inNeuroscience and other applications (Sections 8 and 9).Fig. 1. Organization of the article.tional Ethology, where a host of applications are being developed,i.e. Neuroethology that aims to look for the correlation of behaviorand neural activity, even for the identification of neural causalmechanisms. On the other hand, when computational scienceexplores how technology can understand human affect; how inter-actions between humans and technologies can be impacted byaffect; how systems can be designed to use affect to enhance capa-bilities; or how sensing and affective strategies can transformhuman and computer interaction [9], the field is named AffectivealgorithmsThe advent of the Big Data revolution has provided MLresearchers and practitioners a huge amount of data of almostany imaginable kind. This has steered ML research towards thosemethodologies and algorithms which are able to manage large vol-umes of information within reasonable computational require-ments. Moreover,thecomputational load over a computer network are the most useful,since they can be executed in the cloud [11]. The motivationsbehind these changes are multiple, since ML techniques havebecome suitable for a wide range of application fields. However,Neuroscience is a representative example in which available datais usually high dimensional, a high number of samples is notalways available, and databases are often unbalanced. In this situ-ation, ML techniques provide new opportunities to develop specificdistributethatcanFig. 2. Taxonomy of the review paper.240J.M. Górriz et al. / Neurocomputing 410 (2020) 237–270methods to extract descriptors, allowing for the creation of com-plex models from high-dimensional data while preserving general-ization capabilities. Indeed, these techniques, in combination withsophisticated brain activity scanning methods and instrumenta-tion, as shown in Section 10, allows for the translation of researchoutput into interventions to make a difference in clinical practice[12,13]. These medical applications explore diverse areas, such asneurodegenerative diseases, cardio-pathologies, glaucoma, strokesor even the genomic sequencing of DNA and RNA, among others, asshown in Section 11. The aforementioned synergy in AI has con-firmed the possibilities of controlling simple mechanical or roboticsystems using the electrophysiological activity of brain cortex cap-tured through the skull and scalp or supporting physicians in thediagnosis of several diseases (Parkinson, Amyotrophic LateralSclerosis, Alzheimer) or conditions (Autism). In the last decadesthese findings opened the door to develop computer-aided diagno-sis systems, non-invasive interfaces for the control of simpledevices as a mouse cursor, or more sophisticated devices such assupportive limb prostheses or the navigation on virtual scenarios[14]. Moreover, a variety of AI applications for personal andprofessional services is shown in Section 12, demonstrating howAI technology is addressing the needs of individuals and societyas well. Large and mid-size enterprises are intensifying the use ofML and AI in their products, taking advantage of the opportunitiesthese technologies present to perform advanced analysis on bigdata and to improve the performance of their products andservices.details). Using DL we are able to approximate any function as longas we have a dataset large enough so that its distribution functionis close to the real one. They are complex models, with a strong andcostly operation, that find their best territory in learning problemsfrom large amounts of data, and that were previously limited byextreme computing costs and availability of digitized data. Thishas changed in the last decade because they have benefited fromthe continuous improvement in technology and the huge amountsof digitized data (or having obtained them automatically, if theywere not). But despite the success, this paradigm is not problem-free [18], and, in addition to the difficulties of model explainability[19,20], there is further room for improvement, for example, in theeffectiveness and efficiency of learning mechanisms and applica-bility to smaller datasets.DL is giving such good results that the applicability to not-so-large data sets is a first-level research objective. However, obtain-ing representative datasets of a given problem is not always easy oreconomical. The concept of transfer learning has certainly helpedin this regard. It benefits from the initialization of the system overother datasets with huge amounts of data, normally obtainedthrough the internet, to overcome its lack in the applicationdomain. On the other hand, the concept of reinforcement learningbrings a completely logical proposal: instead of having to generatea priori datasets, it is proposed that the model itself collects datafrom the environment in order to optimize a certain reinforcementfunction (reinforcement that also derives from the response of theenvironment to the exit of the system) [21].2. Models: advancing in data science2.2. Ontological, statistical, hybrid and biological modelsIn AI a continuum from totally explicit to implicit models exists.The former are interpretable by an expert in the applicationdomain, because he/she sees a direct reflection of his/her ownknowledge, with a terminology and a causality that can be under-stood, close to the experience on this narrow scope of analysis. Themost obvious example is perhaps ontologies, since they are raisedwith that objective; they are consensual and formal models thatallow for the representation of the concepts and relationships ofa domain. They have been very useful to extract and share knowl-edge or to integrate data sources of different origins [15].In contrast, non-explicit models are generic models, applicableto a wide range of problems whose parameters must be adaptedto a particular domain. We say that models learn from data, whichtranslates into adjusting their internal parameters to respondprospectively, according to the patterns and recurrences found inthe dataset. They are black box models (some more than others)in the sense that the explanation of why they infer what they inferis not immediate, since knowledge derives directly from the data,not from the conceptualization of an expert. For this reason, it isnecessary to find additional mechanisms that explain the reason-ing behind how conclusions have been reached, to achieve systemsthat are reliable and, therefore, easier to deploy in sensitive areas,in which machines interact withsuch as health or security,the implicit[16,17].humansmodels through changes in the representation system that makethem more transparent, although possibly not fully explainable.This explanation is already a recognized right for the EuropeanUnion.2is possible to interpretIt2.1. A new era for artificial intelligenceThe commotion raised by the DL models has brought greatprominence to this problem (see following Section 3 for more2 The EU general data protection regulation 2016/679 (GDPR).In relation to the problems raised above, we have a clear exam-ple of explicit models in ontologies. In [22], the authors review thedifferent approaches carried out with the purpose of solving inter-operability and standardization problems in domains [15] relatedto the study of mild cognitive impairment (MCI) and other neu-rodegenerative diseases. The capacity of ontologies to addressthese problems, together with the facility for storage, retrievaland inference of information, makes them a must-have model inthe studies of the diagnosis of MCI.The extraction of knowledge from time series is a problem stud-ied in data mining. In Ref. [23] they do so by building an explicitmodel, a set of rules that are perfectly understandable to theexpert, but without resorting to him or ‘‘ad hoc” solutions. The pro-posed method creates timelines by abstraction from the time ser-ies, and from here to temporary rules using a known algorithmcalled APRIORI [24].In Ref. [25] a rule-extraction technique applied to convolutionalneural networks (CNN) is presented. A special transparent modellocated in the dense layers generates the rules. The antecedentsof the extracted rules represent responses of convolutional filtersthat make it possible to determine for each rule the covered sam-ples. With this method, it is possible to visualize the centroid ofeach rule, which produces an overview of how the network works.As an example, Fig. 3 illustrates a number of generated centroidsfor the MNIST classification problem, with each centroid coveringhundreds to thousands training samples. It is worth noting the dif-ferent patterns and the varying orientations of the class ‘‘one” digit.An example of research to complement certain models and try-ing to solve some of their problems can be found in Ref. [26]. Whilesupport vector machines (SVM) are the most successful models forsupervised learning problems, it is true that they suffer from scal-ability problems with large amounts of data. Thus, the authors pro-pose Deep SVM models that combine the highly non-linear featureprocessing of Deep Neural Networks (DNNs) with SVM loss func-tions. As the authors show, these models achieve results similarto standard SVM, but on large datasets. However, these modelsJ.M. Górriz et al. / Neurocomputing 410 (2020) 237–270241Fig. 3. Centroids generated from symbolic rules on the MNIST classificationproblem[25].are required to be further analyzed in imbalanced datasets asshown in Ref. [27]. The work shows the conditions under whicha SVM failure occurs, both theoretically and experimentally, andshow that it can be relevant even in cases of very weakly imbal-anced data. Moreover, this work depicts a guideline to avoid theSVM failure.Moreover, in Ref. [28], a combination of two models is pre-sented to construct a two-stage method for example-dependentcost binary classification problems. The first stage obtains, bytraining a Multi-Layer Perceptron (MLP) with a Bregman diver-gence [29] as surrogate cost, consistent estimates of the posteriorprobabilities that, in the second stage, will be used by a Bayesiandecision rule to solve the classification problem.Continuing with this line of hybridization or combination ofmodels, Ref. [30] proposes to develop new models to combinethe performance of ensembles with the transparency and inter-pretability of choice models. The authors explore the possibilitiesof blind or uninformed methods focusing on two aspects of theensemble building process: the data sampling strategy and theaggregation technique. The results obtained indicate the best per-formance of the bagging methods to build optimal choice-basedensembles.Much research has been carried out to emulate human cogni-tive behaviors, but mainly with parcelled models for differentcapabilities. The authors of Ref. [31] look for symbiosis withhumans through a framework of deep man–machine cooperation.They seek cognitive agents that should build goal-orienteddynamic holistic models of the involved task to support efficientdomain understanding and general learning, rather than merelysolving pattern-recognition problems. Thus, they present a cogni-tive framework for consciousness, that is mainly based on a net-work of associate cognitive digital twins, to support cognitiveactivities of symbiotic autonomous systems (SAS) (Fig. 4).Nature has always been an inspiration for creating artificialmodels that emulate or improve human abilities. In Ref. [32] theauthor studies a property of biological neural networks (BNNs),computational robustness, which is missed in the artificial NN(ANN), and that is a property that is increasingly seen as a key toevolutionary drift. The author tests the relationship between com-putational properties in ANN and the neuronal codes through insilico experiments to reach two conclusions: i) There is a relation-ship between the number of epochs needed to train a feed-forwardneural network using back-propagation and the neural code of theFig. 4. SAS human–machine cognitive cooperation [31].neural network, and ii) a relationship exists between the computa-tional robustness and the neural code of a feed-forward neuralnetwork.3. Deep learningSince DL models are implemented as ANNs where inputs andoutputs are modifiable for each problem, they can adapt to specialproblems with non-standard traits or other obstacles for commonlearners. However, this also means that, in order to be trained,numerous parameters and hyperparameters need to be optimized,which entails some challenges that are still undergoing intenseresearch. Fig. 5 depicts some architectures that may be used tobuild DL models, specifically a convolutional ANN and anautoencoder.Due to the outstanding performance that DL methods obtainedin image processing tasks, many of the applications currently indevelopment involve the treatment of images. Notwithstanding,DL models can be notably useful in other fields as automaticregressors or feature learners in addition to classifiers. The follow-ing sections review several developments and ongoing works inthe DL field, both in the theoretical aspects of DL models and in dif-ferent application fields.3.1. DL methods: Limits and challengesFrom a theoretical perspective, the ongoing developments onANNs and DL are tackling open problems in the field, as well asadvancing in treatment of learning problems which present specialdifficulties. Among the first issues we find the interpretability ofthese models and the need for strategies to build them and todesign convenient objective functions. Among the special difficul-ties, there are many complexities that can prevent traditionallearners from finding good solutions to specific problems, andsome of the following works put those in the spotlight.Interpretability is nowadays one of the main focuses in this area[33,34], since ANNs have traditionally been considered black-boxmodels. Along these lines, there are models that extract proposi-tional rules from ANNs, but are commonly limited to simple MLPs.The work in Ref. [25] further develops this approach by proposing amodel for extraction of propositional rules from a CNN. This workachieves this by approximating the fully connected layers of theCNN architecture with a Discretized Interpretable MLP after train-ing. This structure performs a discretization of its inputs via a stair-case activation function, while retaining the learned weights in theCNN. The rules that are extracted have in their antecedents theresponses of the filters in the last convolutional layer and coverseveral examples that can be summarized in a centroid. In their242J.M. Górriz et al. / Neurocomputing 410 (2020) 237–270Fig. 5. Illustrations of architectures of two possible ANNs: on the left, a convolutional ANN; on the right, an autoencoder.experiment, the authors extract a set of 1105 rules for MNIST clas-sification, achieving an accuracy just slightly inferior to the CNNitself. This set may contain too many rules to be considered inter-pretable yet, but it is a simpler model than the CNN.Autoencoders (AE) are neural network-based tools that performfeature learning [35]. These are usually applied to unsupervisedlearning problems, since they generally do not need any labelinformation from the training patterns. Instead, they learn a newfeature space where these can be projected onto and reconstructedfrom, similarly to manifold learning algorithms. However, there isno straightforward procedure to design the architecture of an AE,including the number of layers and the amount of neurons in eachlayer. There are already some proposals for automatically findingneural network architectures, but none centered on autoencoders.In Ref. [36], an evolutionary approach for architecture search isproposed and tested against an exhaustive grid search. The searchmethods based on evolutive algorithms present significantly supe-rior performance than the exhaustive version.Defining an appropriate objective function for a problem cangreatly affect the model learned by an ANN [37]. One of the com-ponents of this function may be the coding given to the possibleresponses, usually corresponding to classes in a classification prob-lem. A small experiment in Ref. [32] suggests that some codes maybe more beneficial than others when the ANN faces potential dam-ages (e.g. deleted neurons).A high number of instances can decrease the performance of atraditional learner, especially in computation time, where somemethods may be incapable of treating datasets with several hun-dred thousand instances. Support vector-based methods, whichimplicitly work with a transformation of the original feature spaceonto a higher-dimensional space, are especially hindered by thenumber of training patterns, due to the linear increase of theamount of support vectors. Although some proposals attempt toovercome this obstacle, in many cases they still struggle with largedatasets. The developments in Ref. [26] describe deep ANN modelsfor both classification and regression which leverage the loss func-tions of support vector machines and support vector regressionmodels, respectively. The results show that the performance is verysimilar to that of the traditional models, but the training timerequired to learn an ANN-based model is much shorter.Another obstacle in learning problems arises when the cost ofan erroneous prediction depends on the predicted pattern itself.This is known as an example-dependent cost [38]. This circum-stance can join other well known difficulties for classification tasks,such as class imbalance [39]. A method which adequately treatssuch a problem should take into account the per-instance cost aswell as the predominance of some classes over the rest. The workin Ref. [28] develops a novel method which couples a statisticalprocedure with a multilayer perceptron classifier, allowing torebalance the importance of each class by weighting them duringthe training phase as well as to provide a class decision based ona computation which takes example-dependent costs into account.Some problems are more complex due to the structure of theirinputs or outputs, and are commonly known as nonstandard learn-ing problems [40]. One of them is ordinal classification, wherethere is an order among output labels. The approach in Ref. [41]tackles ordinal classification from the perspective of a more tradi-tional model, reproduced by means of an ANN. More specifically, itimplements a Proportional Odds Model, a statistical techniquewhich predicts a value in a 1-dimensional space for each pattern.The resulting ANN has an output layer which extracts class proba-bilities from a single-variable projection computed in the previoushidden layer. These are then evaluated by means of the continuousversion of the Quadratic Weighted Kappa loss function. The opti-mizer uses this as the objective function which the network hasto minimize.3.2. Building DL applicationsApplications of DL models are very diverse. A large part of themfocus on image treatment, since they supposed a breakthrough inlarge image classification problems in the recent years [42]. Never-theless, DL models are also employed in scenarios where agentssuch as robots must interact with their environment and react tochanging conditions, as well as other purposes within the datascience field like semantic hashing or anomaly detection. Through-out this section, several examples of these kinds of applications aregathered and reviewed. Some of the results are illustrated in Fig. 6,where the outputs of different DL models dedicated to specificapplications are represented.Image classification applications are very commonly foundwithin the DL field, due to the potential of convolutional ANNs[46] to learn high-level features from image data using less train-able parameters than other kinds of networks. In this context,Ref. [47] proposes a CNN-based classifier which is able to identifythe level of quality of an olive oil sample: extra virgin, virgin orlampante. It is composed of three convolutional blocks and fourfully connected layers which compute the prediction. The resultingmodel achieves better accuracy than previous methods over thesame dataset, while eliminating preprocessing steps at the sametime.The work in Ref. [48] also approaches an image classificationproblem, in this case, waste classification into glass, paper, card-board, plastic, metal and general trash. This is usually tackled froma computer vision perspective, in three phases: segmentation, fea-ture extraction and classification. The objective is to reduce thisprocess using a CNN which automatically performs the necessarysteps. A range of well known CNNs are tested and compared forthe same dataset, TrashNet. These include VGG-16, VGG-19, Incep-tion, ResNet and Inception-ResNet. The ResNet model obtained thebest accuracy rate, surpassing other experiments from the state ofthe art.One problem related to image classification is image segmenta-tion, in which the model has to detect and delimitate regions inJ.M. Górriz et al. / Neurocomputing 410 (2020) 237–270243(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)red soilcotton cropgrey soildamp grey soilsoil with vegetationmixturevery damp grey soilFig. 6. Outputs from DL models for different application domains, from left to right: person detection and identification [43], white matter hyperintensity segmentation [44],2-dimensional embedding of satellite images [45].images. In Ref. [44], this circumstance arises in neurology, specifi-cally in automatic segmentation of white matter intensities inmagnetic resonance images. Instead of a standard CNN classifieras in the previous problems, segmentation can be carried out bya CNN, which means that the network does not include any denselayers, and instead it has a bidimensional output produced by con-volution or deconvolution operations. The work revolves aroundthe preprocessing techniques that can be applied to images beforefeeding them to the CNN. The experiment suggests that enhancingthe contrast, removing the skull and standardizing the featuresbenefits the learning process.Many uses of DL systems involve robots in social situations.These agents need to be sufficiently autonomous and, thus, actaccording to their environment and adequately interact withhumans. Assistant robots for elder people and other communitiesare the main focus in Ref. [43], where a person identification mem-ory system is developed by combining an object detector based onYOLO v3 [49] with a nearest neighbor clustering. This system iscapable of identifying people present in previous frames and ofincorporating new unknown individuals to its memory.When robots are involved in child tutoring, they must be able todetect their mood and basic emotions to react accordingly. In Ref.[50], a facial expression recognition model is built and integratedinto a complete system for the development of this kind of robots.The model is able to distinguish six types of emotions: anger, fear,joy, sadness, disgust and surprise, as well as an additional neutralstate. The model was validated with actual images of primaryschool children.4. EthologyEthology is the discipline of the observation of the behaviour. Itsclassical domain has been animals in the wild, but it is also appliedto animals in the laboratory, looking for advanced phenotype mod-elling. The increasing use of quantitative sensors and sophisticatedcomputational resources in order to achieve precise quantitativemodelling of behaviours has been termed Computational Ethology,where a host of applications are being developed [51]. Neuroethol-ogy aims to look for the correlation of behaviour and neural activ-ity, even for the identification of neural causal mechanisms [52,53].The integration of neural sensor readings (i.e. inserting elec-trodes in the brain) and motion capture devices allows the quanti-tative modelling in some restricted experimental environments[54]. These experimental conditions are quite difficult to be appliedto humans, for technical, ethical and ecological validity issues [55].Thus Human Computational Neuroethology (CNE) poses a newpanorama of sensing and computational challenges [56]. There isa rich literature on human motion modeling for a variety of appli-cations, ranging from medicine, sports, and artistic rendering.However, these approaches are usually rather restrictive, limitingthe ecological validity of the experiments. Thus, new sensors andalgorithms should be developed in order to achieve high motionprecision in natural settings. On the other hand, the advent ofnew wireless connected electroencephalography (EEG) devicesallows monitoring neural activity while the subject is in motion[57,58]. The high sensitivity of EEG to motion artifacts and electro-magnetic fields impedes the detection of low magnitude and noisyeffects, such as those required in brain-computer interfaces [59].4.1. State-of the artTraditionally, validation of neuroethological models has beencarried out by direct manipulation of the neural systems, such asproducing alterations in the neural circuits by genetic or chemicalmeans, and observation of the ensuing behavior. However, thesemethods are not of application to humans for self-evident ethicalreasons. Even the invasive methods that insert electrodes in thebrain tissue have to be severely limited to well justified cases.One approach to the validation of neuroethological models consistsin the confirmation of improved activity detection when using thefused information. This is a line of research where several authorshave achieved some success and will be extending the experimen-tal evidence base. The research goals in this context has to tacklewith several aspects, such as face motion recognition, body motionrecognition, and EEG signal processing.Most of the work in this area concerns animal computationalethology, which has been proposed as discipline on its own [60].Regarding human behavior modeling, there is a host of computervision based approaches as well as inertial measurement unit(IMU) based modeling (see Figs. 7 and 8) among them the newDL architectures are foremost [61]. Most of these approaches arein fact related to robotics interaction [62] instead of modelinghuman cognition and related fields of interest for CNE. There aresome timid attempts to use wireless EEG in clinical trials [63]but there is not much advance, except in very specific well knowndiseases, such as epilepsy. There are instances miscellany experi-ences, such as the monitoring of wireless EEG signal while wander-ing in an art museum [64].4.2. On the use of inertial sensor units and electroencephalographyIn general, methods at this point in time consists in the syn-chronized collection of body motion and EEG readings while thesubject is performing simple tasks. In this regard, image basedeye detection, inertial motion units, and several wireless EEG244J.M. Górriz et al. / Neurocomputing 410 (2020) 237–270broad diversity of disciplines pertinent to affective computing isa mirroring of the difficulty of describing, understanding, and mim-icking feelings.During the last two decades, important advances in sensing,tracking, analyzing, and animating human communication haveproduced increasing attraction in affective computing by human–machine interaction (HMI) researchers [68]. This trend has alsoreached the human–robot interaction (HRI) community. In fact,the astonishing advancement of (personal and service) roboticshas led to an increased demand for social robots that interactsocially with humans and other robots [69].For AC, and also related to HMI/HRI, virtual reality (VR) hasdemonstrated an increasing interest, probably because humansengage humans better than robots. Moreover, VR eases the simula-tion and assessment of spatial environments under supervised labconditions [70]. Virtual characters generate affect that give rise to amore affine interaction with humans [71].5.1. Main objectives nowadaysIn general terms, the objective of investigation in affect recogni-tion (a piece of affective computing) is to detect the emotionalstate of a person based on observables [72]. For instance, affectivespeech is conveyed through semantics and speech prosody. Proba-bly facial expressions and body gestures are the most obvious andsignificant channels for expressing affect, as most human commu-nication is non-verbal [73]. More recently, apart from propositionsbased on audio and vision, solutions relying on wearable sensorshave received greater attention. Wearables provide long-termaffect recognition supplying with insights into physiologicalaspects such as respiration, skin color, temperature, heartbeat,blood pressure, and pupil dilation [74]. Physiological signals areconsidered as a specific information channel for affective reactions.Specifically, an outstanding number of approaches are offeringhigh accuracy of stress detection using non-intrusive physiologicalsensors.AC has also encouraged the advent of novel applications inentertainment, education, marketing and health care. Perhapsone of the most significant research domain of affective computingis focused towards discovering the relation between emotions andhuman health, both mental and physical [73]. Research in AC hasalready provided significant benefits (e.g. Williams syndrome,Asperger syndrome and Parkinson disease -PD-). Affective comput-ing can also be used for personalization such as adjusting light,type of music, and room temperature by detecting a person’s emo-tional state to strengthen people’s health and well-being [75].5.2. Human–machine interaction and health-care applicationsThe works included under this area cover several aspectsrelated to AC. These topics can be described in regards to threemain aspects, namely affective computing for interaction amonghumans and machines, technologies used in AC, and affective-based health-care applications (see Fig. 9).Considering the health care applications tackled, the applicationfield faced (i) elder people with PD, exploring new paradigms ofinteraction [76], (ii) patients with deficits in facial affect recogni-tion, designing therapies based on human avatars [77], (iii) peoplewith disabilities in general, identifying the brain areas involved inprocessing emotions [78], (iv) people with visual and intellectualdisabilities, reporting the effectiveness of using a game or a conver-sation on achieving a higher self-disclosure [79], (v) dependentpeople living at home, using a flying robot the monitor facial emo-tions [80] and a wearable to detect stress [81], and, (vi) people per-forming physical rehabilitation exercises, monitored from twoFig. 7. An example of ethogram estimated using data fusion of IMU body motionestimation and wireless EEG recording.Fig. 8. Summary accuracy increase over a cohort achieved using data fusion of IMUbody motion estimation and wireless EEG recording in a cross-validationexperiment.recording devices are considered for the analysis. The system per-formance evaluation unit is the ethogram, i.e. a time series of thesubject activities carried out and detected, hence the goal is toachieve perfect ethogram recognition, but we also carry out con-ventional cross-validation experiments in order to evaluate theML approaches prior to ethogram estimation. Fig. 7 shows a recentexperimental result of this kind of neuroethogram estimationwhen we fuse EEG and IMU motion estimation. Fig. 8 shows theincrease in accuracy in 10-fold cross-validation achieved whenusing the joint data sources versus the isolated data sources.A short review of CNE was provided [65], where the main focuswas on human motion analysis and some related neural activitymodeling research works, mostly in the animal domain, givinghints how these experiments can be extended to the humandomain. Another related contribution [66] proposed DL tech-niques, specifically Long Short Term Memory (LSTM) for gait move-ment modeling and prediction, which could be combined in thefuture with neural activity modeling. Also the recognition of cogni-tive activities through eye tracking [67] could be fused with neuralactivity recognition for a more detailed modeling, and even causal-ity prediction. Finally, an experimental example is provided wherethe fusion of neural and motion information effectively achievesimproved activity recognition performance and ethogram estima-tion. This latter work is the most complete instance of the desiredexperimental and analysis setting up to date.5. Affective computingAC is a growing interdisciplinary area, participating from areasas different as psychology, physiology, engineering, sociology,mathematics, computer science, education, and linguistics. TheJ.M. Górriz et al. / Neurocomputing 410 (2020) 237–270245Fig. 9. The three main aspects involved in the special session on affective computing.carts equipped with an RGB-D camera each on a motorized circularrail [82].HRI was at the core of Ref. [83] that introduces a real-time emo-tion recognition system using a YOLO-based facial detection sys-tem and an ensemble convolutional neural network. Anotherwork benefited the field of HRI by facing a broadened understand-ing of brain emotional encoding in order to improve the capabili-ties of robots to fully engage with the user’s emotional reactions[84]. Another article introduced a framework for assisting depen-dent people at home through an autonomous unmanned flyingrobot that captures images of the dependent person’s face [80].The outcomes of another paper will help to improve HRI for pro-moting self-disclosure as the first step in a research project thataims to alleviate worrying behavior in the user group [79]. In theinteraction domain, a last paper introduced the design process offacial expressions on virtual humans to play basic emotions,grounded on the Facial Action Coding System [77].The papers have detected affect from facial cues by robotsworking in real-world scenarios [83] and speech in order to elicitstress through a set of on-line interviews, as well as to establisha standard speech corpus to assess emotions across multiple lan-guages [85]. Hence, a number of papers introduced solutions basedon the acquisition and processing of physiological signals. A coupleof papers used electrodermal activity (EDA) and heart rate variabil-ity (HRV) acquired from a wristband. One of the papers introduceda system composed of hardware, control software, signal process-ing and classification for the deployment of a wearable with a highability to discriminate among seven emotional states (neutral,fear and sadness) [86].affection, amusement, anger, disgust,Another paper described the acquisition of EDA signals and theirstorage and processing for stress detection. The classification wasundergone by using several support vector machines [81]. Otherapproaches addressed the use of EEG signals in this context. Asan example, a study of cortical asymmetries based on the spectralpower and differential entropy of the EEG signal of subjects is car-ried out [87]. Subjects were stimulated with videos of positive andnegative emotional content in order to understand the neurophys-iology of emotions, the neuronal structures involved in the pro-cessing of emotional information and the circuits by which theyact. Another work proposed a temporal analysis approach for thediscrimination of two states (high and low) of valence and arousalemotional dimensions, with the additional benefit of identifyingthe brain areas involved in processing emotions [78]. In addition,Ref. [84] took advantage of the lateralization produced in brainoscillations during emotional stimuli and the use of meaningfulfeatures related to intrinsic EEG patterns. Finally, a solution basedon a brain-computer interface (BCI) able to control events is pre-sented [76]. This mobile-BCI application in turn triggers actionsthat facilitate mental interactions.6. Bioinspired systemsBio-inspired computing methods take inspiration from natureto develop, in many cases, optimization and search algorithms ormetaheuristics, typically in order to tackle the search of optimalsolutions of complex problems in science and engineering, whichusually imply a high dimensionality of the search space.Apart from the traditional evolutionary computation methods,artificial immune systems, ant algorithms or particle swarm opti-mization,the novel bioinspired computing approaches areintended to focus on new bio-inspired solutions, such as swarmalgorithm solutions based on bee colonies, algorithms based onfirefly insect behavior, artificial algae algorithm and many more,together with their combination with local search strategies orother metaheuristics. Topics areas in this field include:(cid:1) Bio-inspired approaches based on animal behavior (Cuckoosearch, Cat swarm, Artificial Bee Colony, Bat algorithm, Wolfsearch, etc.).(cid:1) Bio-inspired approaches based on plant behavior (artificialalgae algorithm, flower pollination algorithm, PIBO, etc.).(cid:1) Bio-inspired approaches based on bacteria like BFO.(cid:1) New approaches in evolutionary computing methods.(cid:1) Combination of bio-inspired approaches with local search:strategies, memeticBaldwinianstrategies,Lamarckianalgorithms.(cid:1) Combination of the bio-inspired approaches with artificial lifemodels like cellular automata or Lindenmayer systems.(cid:1) Applications with bio-inspired approaches.6.1. Solutions in biomedicineThe inference problem of protein structure prediction can betackled with a hybrid combination between differential evolutionand a local refinement of protein structures provided by fragmentreplacements [88]. In this case, the coarse-grained protein confor-mation representation of the Rosetta environment was used. Giventhe deceptiveness of the Rosetta energy model, an evolutionarycomputing niching method, crowding, was incorporated in the246J.M. Górriz et al. / Neurocomputing 410 (2020) 237–270evolutionary algorithm with the aim to obtain optimized solutionsthat at the same time provide a set of diverse protein folds. Thus,the probability to obtain optimized conformations close to thenative structure is increased.Another bio-inspired approximation is called bacterial antibi-otic resistance algorithm [89] in which a bacteria colony representsa set of candidate solutions subjected to the presence of an antibi-otic as a pressure factor for separating good and wrong answers. Inthese terms, the classification allows having two groups: resistantand non-resistant bacteria. Then, by using genetic variation mech-anisms (conjugation, transformation, and mutation), non-resistantbacteria is expected to improve their defense capability to enhancetheir probability of survival.Finally, the Koniocortex Like Network (KLN) [90] is a novelBioinspired Artificial Neural Network that models relevant biolog-ical properties of neurons as Synaptic Directionality, Long TermPotenciation, Long Term Depression, Metaplasticity and Intrinsicplasticity, together with natural normalization of sensory inputsand Winner-Take-All competitive learning. As a result, KLN per-forms a Deeper Learning on Datasets showing several high orderproperties of biological brains as: associative memory, scalabilityand even continuous learning. KLN learning is originally unsuper-vised and its architecture is inspired in the koniocortex, the firstcortical layer receiving sensory inputs where map reorganizationand feature extraction have been identified, as is the case of thevisual cortex. This new model has shown big potential on syntheticinputs and research is now on application performance in complexproblems involving real data in comparison with state-of-artsupervised and unsupervised techniques. The early detection ofcardiovascular disease is an interesting domain addressed in Ref.[90] with KLN.6.2. Solutions in smart citiesSmart cities result from the wide adoption of information andcommunication technologies aimed at addressing challenges aris-ing from overpopulation and resources shortage. Despite theirimportant and fundamental contributions, ICT alone can hardlycope with all the challenges posed by growing demands of over-populated cities. Hence, novel approaches based on innovativeparadigms are needed. The concept of Cognitive City founded onSiemens’ Connectivism and understood as the evolution of currentsmart cities augmented with artificial intelligence,internet ofthings, and ubiquitous computing. The concept of cognitive cityas a complex system of systems resembling complex adaptive sys-tems with natural resilient capabilities is another approximation[91]. On-line scheduling is another domain. This problemaddressed in Ref. [92] arose from a charging station where thecharging periods for large fleets of electric vehicles (EV) must bescheduled under limited power and other technological con-straints. The control system of the charging station requires solvingmany instances of this problem on-line. The characteristics of theseinstances being strongly dependent on the load and restrictions ofthe charging station at a given time. The goal was to evolve smallensembles of priority rules such that for any instance of the prob-lem at least one of the rules in the ensemble has high chance toproduce a good solution. To do that, Genetic Algorithm (GA) thatevolves ensembles of rules from a large set of rules previously cal-culated by a Genetic Program (GP) were used in Ref. [92].Bio-inspired methods are often applied to structure calculationin civil engineering. One example of this was proposed in Ref. [93].In this case, the authors consider repairing bridges that crosswatercourses. It is a situation that must be resolved in a timelymanner to avoid the collapse of its structure. Its repair can meana high cost, as well as road and environmental alteration. An effec-tive solution, which minimizes this impact, is the installation of asuperstructure in the form of an arch that covers the entire lengthof the bridge. The structure is anchored to the deck of the bridge bymeans of hooks, and so it allows the arch to support the bridge.This structure must keep the original properties of the bridge, sothe magnitude of tension of the hangers and the order in whichthey are applied is essential for not to cause damage to the bridge.In Ref. [93] the authors use moth search algorithm to calculatethese tensions and the order in which they are applied. Schedulingproblems arise in an ever-increasing number of applicationdomains. Although efficient algorithms exist for a variety of suchproblems, sometimes it is necessary to satisfy hard constraints thatmake the problem unfeasible. In this situation, identifying possibleways of repairing infeasibility represents a task of utmost interest.The authors in Ref. [94] considered this scenario in the context ofjob shop scheduling with a hard makespan constraint andaddressed the problem of finding the largest possible subset ofthe jobs that can be scheduled within such constraint. A geneticalgorithm that looks for solutions in the search space defined byan efficient solution builder was proposed [94].7. RoboticsAI research in the field of robotics can sometimes become veryeclectic with extremely different approaches coexisting in order toallow robotic systems to do their thing. This eclecticism can beorganized in different ways, but two of them are more prominent.On the one hand, and focusing on robotic skill acquisition, it can beorganized into, at least, three categories in terms of how the robotacquires its competences. That is, in the lower level one could findmore classical approaches, where the robot is provided with theoperational skills it needs in terms of programs, or ANNs, that per-form the desired tasks [95].A higher level would encompass learning approaches, wherethe robots are able to learn skills in their domain, that is, theycan learn how to perform the task they are externally commandedto carry out [96–98]. Finally, in the highest or cognitive level, onecould even resort to more autonomous approaches involving moti-vational systems within cognitive architectures [99,100] that seekto allow the robot to decide what tasks it needs to perform andthen learn the appropriate skills. In this level the problem the robotwould face would be that of lifelong open-ended learning.From another, more traditional, point of view, research inrobotics is often organized with regard to categories of skillsdesired from the robot. In this categorization we can go from basiclow level skills, such as trajectory generation issues, to the acquisi-tion of particular interaction skills or to the analysis of how toachieve particular effects on the domain, including effects onhumans, through interaction with the robots. These last effectsinclude eliciting emotions or providing education to humans.7.1. Physical interaction with humansOne of the main goals of robotics is to assist people with disabil-ities [82]. In this sense, a robotic system consisting in a motorizedcircular rail that generates the motion of two carts with an RGB-Dcamera (depth sensor) can track a person’s physical rehabilitationexercises from two points of view and his/her emotional state fromone of these viewpoints. Moreover, the problem of trajectory gen-eration and planning aimed at assisting dependent people at home,can also be tackled with a quadrotor that includes a vision system[80]. The solution includes a trajectory planning algorithm thatallows the UAV (unmanned aerial vehicle) to position itself in orderto capture images of the dependent person’s face. These images arelater processed by a base station to evaluate the person’s emotionalJ.M. Górriz et al. / Neurocomputing 410 (2020) 237–270247state, together with his/her behavior, thus determining the assis-tance needed in each situation.7.2. Emotional interactionGoing up into the interaction realm, one of the next barriers inrobotics is to provide sociable robots with the ability to fullyengage in emotional interactions with users. In this line, in Ref.[83] authors propose a real-time emotion recognition system usinga YOLO-based facial detection system and an ensemble CNN. Thefield of human-robot interactions (HRI) will benefit from a broad-ened understanding of brain emotional encoding and thus,improve the capabilities of robots to fully engage with the user’semotional reactions. In Ref. [84] authors propose a methodologyfor real-time emotion estimation aimed for its use in the field ofHRI. On the other hand, and in the same line of endowing socialrobots with natural interaction abilities, Ref. [101] addresses thedevelopment of robotic dialogue skills.This use of robotic systems to try to elicit human reactions canbe one step further and into more psychological, emotionaldomains. An example is the work in Ref. [79], where the authorspresent the results of a pilot test on the effectiveness of using arobotic game or a conversation on achieving a higher self-disclosure in people with visual and intellectual disabilities. Theyimplemented an interaction process with a NAO Robot throughgames or conversation and their results indicate that during thegame-based interaction the participants used much longer self-disclosing sentences in comparison with the to be conversation-based interaction.Finally, and reaching the higher level cognitive realm, Ref. [102]studies motivation in autonomous robots. The latter work focuseson the basic structure that is necessary for bootstrapping the initialstages of multiple skill learning within the motivational engine ofthe MDB (multilevel Darwinist brain) cognitive architecture (seeFig. 10). Taking inspiration from a series of computational modelsof the use of motivations in infants, they propose an approach thatleverages two types of cognitive motivations: exploratory and pro-ficiency based. They postulate that these make up the minimumset of motivational components required to initiate the unre-warded learning of a skill toolbox that may later be used in orderto achieve operational goals.7.3. Education and social robotsRobotics have proved to be a very attractive tool for studentspecially in STEM areas that involve active exploration. Neverthe-less, learning activities with robotics kits are usually isolated fromofficial curriculum and no evaluation about the learning outcomesof students are provided. The work in Ref. [103] presents IDEE, anintegrated learning environment which uses robotics as a learningtool for a physics laboratory (see Fig. 11). Students in IDEE have toachieve certain learning goals or skills when solving physics prob-lems. On the basis of students’ skills, IDEE shows certain hints tohelp students and teachers, in supporting the students’ learningprocess.Another example of the use of robots in education is the work inRef. [50] that develops a tool to support education through socialinteraction. Authors use in their research, facial recognition ofemotional expressions, aimed at improving ARTIE, an integratedenvironment for the development of affective robot tutors. A FullCNN model has been trained with the Fer2013 dataset, and thenvalidated with another dataset containing facial images of primaryschool children, which has been compiled during computing labsessions.Social Robots is other emergent area in robotics, not only ineducation but also in several areas of interaction with humans.Ref. [43] uses the combination of CNN and statistical classifiersto create a long-term semantic memory that is capable of learningFig. 10. Motivational engine diagram of the MDB cognitive architecture [102].248J.M. Górriz et al. / Neurocomputing 410 (2020) 237–270Fig. 11. General architecture of IDEE integrated learning environment [103].online. To validate this hypothesis, the authors have implementeda long-term semantic memory in a social robot. The robot initiallyonly recognizes people, but, after interacting with different people,it is able to distinguish them from each other. The advantage oftheir approach is that the process of long-term memorization isdone autonomously without the need for offline processing. Whena Social Robot is deployed in a service environment it has to man-age a highly dynamic scenarios that provide a set of unknown cir-cumstances: objects in different places and humans walkingaround. These conditions are challenging for an autonomous robotthat needs to accomplish assistive tasks. Ref. [104] proposes theuse of a probabilistic Context Awareness System that provides aset of belief states of the environment to a symbolic plannerenabling PDDL (Planning Domain Definition Language) metrics.The Context Awareness System is composed by a DL classifier toprocess audio input from the environment, and an inference prob-abilistic module for generating symbolic knowledge. This approachdelivers a method to generate correct plans efficiently.7.4. Industrial roboticsIndustrial Robotics is, obviously, an important part of roboticsresearch, as we can see in the following contributions. Despite thatthe work in Ref. [105] is not a robotic specific contribution, naviga-tion is still an open problem in robotics. In their paper, the authorspropose a method able to provide a robust user heading as a resultof detecting the relative position of the mobile phone with respectto the user, together with a heuristic computation of the headingfrom different Euler representations. They also have performedan experimental validation of their proposal comparing it withthe Android default compass. The results confirm the good perfor-mance of this method.Drones are also an emergent area in robotics. In Ref. [106] aQdash-learning control strategy is proposed for a system consistingof a UAV lifting a damped pendulum from the ground. Thisdynamic system is highly nonlinear and thereafter, it representsa challenging task to get a smooth and precise behavior. Aerialtransportation of a pendulum in a stable way is a step forward inthe state of the art, which permits to study the delivery of differentdeformable linear objects.The deployment of Industry 4.0 will achieve great aims regard-ing production rate, control, data analysis, cost, energy consump-tion and flexibility. However, robots, machinery and knowledgeneeded could lead to a social problem for those operators whoare not prepared to face such big technology challenges. To pre-serve this emerging paradigm’s balance, researchers and develop-ers must consider using intelligent human–machine interactioncapabilities before building novelindustry deployments. Ref.[107] introduces a smart gesture control system that facilitatesmovements of a robotic arm with the aid of two wearable devices(see Fig. 12). By using this kind of control system, any workershould fit into the new paradigm where some precise, hazardousor heavy tasks incorporate robots. Furthermore, their proposal issuited to industry scenarios, since it fulfills fundamental require-ments regarding success rate and real-time control as well as highflexibility and scalability, which are key factors in Industry 4.0.the GREENPATROLAnother industrial use of robotics that have achieved someimportance in recent years is agriculture. In Ref. [108] the designand verification oflocalization subsystem isdescribed. GREENPATROL is an autonomous robot system intended tooperate in light indoor environments, such as greenhouses, detect-ing and treating pests in high-value crops such as tomato and pep-per. Their proposed localization subsystem (see Fig. 13) consists oftwo differentiate parts: (1) an absolute localization module whichuses precise positioning GNSS (global navigation satellite system)techniques in combination with the robot proprioceptive sensors(i.e. IMU and odometry) with an estimated position error, and (2)a relative localization module that takes the absolute solution asinput and combines it with the robot range readings to generatea model of the environment and to estimate the robot positionand heading inside it.Finally, transportation and logistics, an important area of worldeconomics, is represented by the work in Ref. [109]. In theirresearch, authors attempt to build a user interface for controllinga group of omnidirectional robots to realize the transportation ofconvex shape edge objects. Their method establishes a manualguidance to the robots initial positions, initializes the collectivegrasping/lifting process and finally, provides the user with a highlevel control over the velocity of the load during transportationto the required destination. The hardware and software structureof the system are described and simulation is performed to conveythe data from the robots sensors.8. Machine learning applied to big data analysis, processing andvisualizationOne of the best known applications of ML techniques to BigData is the analysis of the information coming from social net-works [110]. The general public has found with surprise that somehuman behavior tendencies can be predicted from human activityin those social networks. Other applications of ML which have aJ.M. Górriz et al. / Neurocomputing 410 (2020) 237–270249Fig. 12. Architecture of gesture control system [107].Fig. 13. GREENPATROL software architecture diagram [108].paramount social relevance include health care enhancement byexploitation of clinical data [111]. In this way, doctors and otherhealth professionals can benefit from predictors generated bysupervised learning algorithms [112].Among the myriad of methodologies which comprise ML, DL ofANN architectures stands as one of the most successful. The capa-bility of deep networks to analyze large volumes of high dimen-sional data has led to extraordinary results in image processing,computer vision, natural language processing, speech recognitionand remote sensing [113,114]. The key to these achievements isthe automated feature learning which deep networks exhibit. Thisliberates the practitioner from the need to produce a set of handmade features [8]. Therefore, the work to be completed by thehuman is reduced. Moreover, significant features are discoveredby the machine that humans may never be able to find out. In otherwords, deep networks can reach solutions to pattern recognitiontasks that humans would never come up with.Visual data analysis is often carried out with the help of a par-ticular kind of deep networks, namely CNN. They comprise convo-lutionallayers which adaptively learn convolution filters thatrecognize significant features of images and videos. This way visualinformation can be understood by the machine [115]. The initialneural layers in the architecture learn low level features like edges,while subsequent layers discover high level features and concepts,so that representations of objects parts and object types can belearned from visual data sets. CNN are instrumental in medicalimage analysis [116,117], among other visual understandingapplications.250J.M. Górriz et al. / Neurocomputing 410 (2020) 237–2708.1. Processing large datasetsThe automated processing of large volumes of georeferencedpositional data is instrumental in the analysis of complex humanbehavior. This is illustrated in Ref. [118], where a Geographic Infor-mation System (GIS) is employed as a framework to run realisticsimulations of urban environments of the city of Quito (Ecuador).The simulations model the social and public health consequencesof the abandonment of dogs. The authors propose a set of simula-tion specifications and features. Then the simulation results areanalyzed and validated, including the interactions among the rele-vant agents and the effects of those interactions. It is concludedthat a higher level of social awareness about this problem isrequired to solve it by attaining a balance among the interests ofthe intervening agents.Large image content repositories are being used in many fieldswhich has created an ongoing demand of image retrieval systems.The procedure of automatically retrieving images by the extractionof their low-level visual features (color, texture, shape proper-ties. . .) is called Content Based Image Retrieval (CBIR). A CNN forfeature extraction to address the CBIR issue has been presentedin Ref. [119]. The proposal is based on computing the class proba-bility vector of an image and employ it as a vector of representativefeatures. After that, a suitable distance measure is used to computethe dissimilarity among the test image and the images stored inthe image database from which similar images are to be retrieved.Moreover, the use of high quality medical images in large data-sets is essential for the diagnosis of diseases. One important imagemodality is magnetic resonance (MR), whose resolution in theacquisition depends on several technical and human aspects.Super-resolution is a technique to enhance the resolution of MRimages using the information of the image itself or the learned fea-tures of large image datasets, as DL based methods do. Most ofthese CNNs are based on the minimization of the residuals usingthe squared Euclidean cost function. Ref. [120] proposed a noveloptimization algorithm for CNNs based on the p-norm, where pis the exponent of the norm, which can reduce the effect of outliersand improve the convergence of the network. The use of valuesp < 2 reduces the influence of extreme values of the residual error,i.e. badly measured training samples, and both the loss functionand the final generated high-resolution image yield better out-comes than the usual squared Euclidean norm.8.2. Video surveillance systemsAn important issue in the video surveillance systems is thebackground modeling and foreground detection. The performanceof many proposals which address that problem is strongly corre-lated to the level of noise present in the video. However, the seg-mentation method proposed in Ref. [121] can reduce the effect ofa heavy Gaussian noise satisfactorily. Each video frame is orga-nized into several shifted patches (tilings) and a set of significantfeatures is extracted from each patch. A trained stacked de-noising autoencoder, which is an unsupervised DL NN, is employedfor unsupervised feature extraction due to its ability to provide rel-evant visual features.The detection of anomalous objects is another fundamental taskin video surveillance. Many DL approaches have been developedrequiring high power consumption due to the use of GPU-accelerated techniques. The DL based detection system proposedin Ref. [122] is implemented in micro-controllers achieving a lowcost surveillance system for panoramic cameras. Instead of anexhaustive scan of the full image, the decision about which win-dow of the image is analyzed at each time instant is based on aprobabilistic mixture of a uniform and a Gaussian probability dis-tributions. Thus, the uniform component represents the unin-formed fully random selection and the Gaussian helps togenerate the next window close to where an anomalous objectwas previously detected. A trained CNN was implemented in aRaspberry Pi through the Microsoft Cognitive Toolkit, providing ahigh performance detection system for security tasks.9. Machine learning in neuroscienceCurrently, data acquired in biomedical studies has singularcharacteristics that difficulties the processing in exploratory or dis-criminative analysis. Moreover, classical statistical methods notalways offer the necessary tools to cope with these difficulties inthe search, for instance, of specific disease or disorder patterns.In addition, the hybridization of different ML methods can helpto address specific difficulties or to improve the models providedby classical algorithms. On the other hand, DL-based methods aregaining popularity in the last years due to the good results pro-vided especially in the field of image processing, where classicalalternatives have been overcame.Machine learning in neuroscience covers different aspects,regarding several bio-signal modalities and techniques applied toexploratory and discriminative analysis. As an example, the appli-cation of ML methods to neuroimaging processing have allowed toimprove the diagnosis accuracy of the PD using 3D DatSCAN-SPECTimages. Its diagnosis usually relies on visual analysis of Single Pho-ton Emission Computed Tomography (SPECT) images acquiredusing 123I (cid:3) ioflupane radiotracer to detect a deficit of dopaminetransporters at the striatum. This way, PD can be differentiallydiagnosed by detecting a dopaminergic deficit in PD patients withrespect to Controls (CN) or other diseases presenting similar symp-toms. Several Computer-Aided Diagnosis (CAD) tools based on sta-tistical techniques have been developed [123,124]. Moreover, theuse of deep neural networks in the last years for image processingand classification has provided a new opportunity to improve pre-vious CAD systems based on statistical learning techniques [125–127]. In addition, ML and DL methods can be boosted by trainingthem with specific features.DL techniques, can be also used for Functional Magnetic Reso-nance Imaging (fMRI) processing to compute complex models offunctional connectivity. Moreover, DL allows to extract representa-tive features in other brain disorders that are traditionally very dif-ficult to diagnose such as the Autistic condition. Functionalconnectivity can be estimated by measurement of correlationbetween time-series of blood oxygenation level dependent (BOLD)endogenous contrast estimated from brain regions whilst in rest-ing wakefulness has been demonstrated as a reproducible mea-surement on an individual basis [128]. Additionally, the use of DLarchitectures to reveal patterns requires the use of specific tech-niques to inspect how the DL black box is working and the featuresit is learning from the input data.The use of ML techniques has revolutionized data processingproviding new and powerful tools to exploit the data in search ofcomplex patterns, which has been proved to be effective even withnoisy [129], incomplete [130] or unbalanced data [131]. However,studies that explore these techniques to reveal their limitationsand the conditions in which they are effective, provide very inter-esting information for the data processing scientific community.9.1. Processing neuroimaging studiesPreprocessing methods in neuroimaging result very importantto the performance of classification and feature extraction algo-rithms, as well as for visual inspection of the images. Thus, Ref.[132] presents a comparison between affine and non-affine meth-ods for spatial normalization of I½123(cid:4)-FP-CIT images which funda-J.M. Górriz et al. / Neurocomputing 410 (2020) 237–2702519.2. Multivariate pattern analysis in EEG signal processingClassical EEG signal processing techniques along with multi-variate pattern analysis is used in Ref. [135] to decode conflict-related neural processes associated with congruent or incongruentevents in a time–frequency resolved way and determined how dif-ferent frequency bands contribute to the overall decoding accuracyby means of a linear SVM.Novel advances related to EEG processing include [136], wherecorrelation between EEG spectrum in the typical EEG bands (Delta,Theta, Alpha, Beta and Gamma), are used to infer functional con-nectivity patterns that reveals differences between controls anddyslexic subjects. Unlike classical experiments in this area, non-interactive auditory stimuli have been used in this work. Exampleof connectivity matrices obtained with the proposed method areshown in Fig. 18. In the framework of the same research, [137] pro-vides an exploratory analysis on the differences between EEGchannels in each band, by means of the spectral coherence. Thisreveals the most relevant channels according to the difference inthe frequency response as shown in Figs. 16 and 17. Moreover, thiswork proposes the use spectral descriptors for each EEG band alongwith a one-class SVM to classify subjects into controls and dyslexic.Fig. 14. Isosurfaces computed from PPMI DatSCAN image, corresponding to anormal/control subject.10. Neuroscience applicationsmental to match equivalent areas of the brain from differentsubjects.PD diagnosis using neuroimaging is addressed in Ref. [1], whichpresents a method to classify DatSCAN images using a CNN)trained with the isosurfaces computed from the images as shownin Fig. 14. The extracted isosurfaces provide descriptive featuresto model the striatum shape. Moreover, isosurface images havebeen used as input of the CNN outperforming the classification per-formance provided by DatSCAN images and allowing the computa-tion of regions of interest by means of the CNN saliency andactivation maps.DL techniques are also used in Ref. [133] with application toautism disorder diagnosis. In this work, authors compute the func-tional connectivity as the correlation between time-series of BOLDfor different brain regions. Subsequently, the correlation matricesare used as input samples on the CNN shown in Fig. 15. The sal-iency maps obtained provide very interesting and useful informa-tion regarding the differences between typically developingcontrols and Autism.Finally, [134] presents a method for automatic analysis ofbehavioral variables of laboratory rats to describe their activity,based on ML and image analysis techniques. This work present aset of experiments to investigate whether rat strain influencesthe behavioral and physiologic measures typically used to assessstress responses.Fig. 15. Neural Network used in Ref. [133], based on BRainNetCNN.The knowledge accumulated on the cortical EEG activity hasbeen intensively used in the design of BCI, a one-way path to themoment, although the reverse way (from outer world to brain)has become also an important target for present and futureresearch. Other fields of research are the development of reducedelectrode count dry EEG interfaces not requiring from conductanceenhancing substances to be used in rehabilitation or substitutivebiomechanical structures for artificial ankles, knees, hips, wrists,elbows or shoulder joints. On the one hand, the availability of BCIshave facilitated the growth of corroborated studies in which braincognitive and/or sensory-motor activity is augmented by EEGrecords to base causative relationships which may be on the back-ground of cognitive and neuromotor human activity. In this waystudies on endocrinal control of heart function, elevated bloodpressure, chronic stress, depression and other psychophysical dis-eases affecting well-being and underlying diseases are being inves-tigated [138]. On the other hand the intensive research conductedduring the past decade has produced outstanding results in detect-ing the elementary neural processes behind fundamental humanactivity in cognitive processes as learning, decision-making, agingand neurodegeneration, among the most relevant ones [139].10.1. Brain-computer interfacesSimple BCI based on an EEG can detect alpha and beta EEGbands on Fp2 and O2 electrodes known to be associated with open(oE) or closed (cE) eye states [4,140]. The detection is based on theratio between the average power of alpha and beta bands, which iscompared with a threshold obtained from averaging both maxi-mum cE and minimum oE ratios [141]. The results show estima-tions of this threshold applying different time windows fordifferent subjects for off-line experiments. On-line ones consistingin sessions of 277 s long show good performance scores in detect-ing the oE and cE conditions. The authors propose using this simpleBCI in domotic applications where the wide-awakeness state of asubject is to be monitored, as in patients with impaired mobility.Motor imagery tasks-based BCI system finds applications fordisabled people to communicate with surrounding [142]. Themethodology used is based on two types of EEG features: on theone hand event-related synchronization-desynchronization is used252J.M. Górriz et al. / Neurocomputing 410 (2020) 237–270Fig. 16. Average activation patterns computed for 2 Hz stimulus by different bands for Controls and Dyslexic subjects.A BCI application based on the BCI2000 system in Ref. [143]focuses its attention on assessing differences in activation of bothhemispheres in stroke survivors during a motor task usuallyemployed for BCI control. To perform this undertaking, it is neces-sary to increase the knowledge about EEG changes in ipsilateraland contralateral limb movements during motor control. The studysample consisted of stroke male patients and healthy male partic-ipants and the experimentation was carried out in a single sessionwhich was divided into two sub-tasks. The authors reported that inthe affected hemisphere of stroke patients, there is a significantEvent-Related Desynchronization (ERD) in alpha and beta bandsmore marked when the using contralateral (affected) hand thanusing the ipsilateral (non-affected) hand. However, the time–fre-quency analysis of EEG shown the presence of a significant ERDin alpha and beta bands, clearly more marked than in the affectedhemisphere, without differences between hands in the unaffectedhemisphere of stroke patients. Therefore, it is possible to controlthe BCI system with signals obtained from both hemispheres,appearing significant differences between them and implying dif-ferent physiological mechanisms that might be relevant for BCIimplementation.10.2. GamificationBeyond BCI, gamification and usability techniques were consid-ered to empower the improvement of communication betweenplayer/user and Aided Communication Devices [144]. This workFig. 17. Most relevant relationships between EEG channels for Theta band,according to the features selected by the ‘1-SVM.based on relative power spectra scattering over a given period oftime; on the other hand functional connectivity estimation wasused to evaluate a weighted phase locking index from continuouswavelet transform coefficients between each two channels presentin the EEG. The results were presented in terms of plots by fre-quency bands in time and channel when conducting each motorimagery task on the scalp map.Fig. 18. Mean connectivity matrices per group and feature under the same scale.J.M. Górriz et al. / Neurocomputing 410 (2020) 237–270253focuses its attention on the use of different devices to assess thehand-wrist movement on a normative population. This approachis based on designing and development a first-person racing videogame. The From this novel methodology, biomechanical indicatorswere gathered. Non-parametric statistical methods were used toevaluate and distinguish the three different aging clusters (young,mid-age and elder people). The study involved thirteen volunteersdivided into two groups (control group - nine individuals, and con-trast group – four individuals). The first group used a lightweightdevice (smartphone), while the second group used a heavier device(tablet). The outcomes achieved were presented on a set of tablesand graphical plots. The key reportings are that the third group(elder players) obtained the highest difference with respect tothe two other groups, independently the device used. However,the device weight should be taken into account to carry out thiskind of activities. The following step is testing this methodologywith people diagnosed with PD.One of the most important issues in this topic is the connectionbetween spatial and numerical cognition as the basis of mathemat-ical cognition and academic achievement. A twofold strategy toimprove numerical skills through spatial cognition is proposed inRef. [145] on game-based learning and technology enhanced learn-ing: Velocicards and Flatlandia creatures. The basis for the study isthe approximate number system ability in humans, a cognitive sys-tem that supports the estimation of set cardinality without resour-cing to numbering or using symbols, strongly linked to spatialcognition abilities, and active since very early in life. The existenceof a strong connection between spatial and numerical cognitionand the number interval position effect can be exploited in predict-ing school achievement and success as in the development of writ-It proposes a game-based learninging and calculation skills.framework designing an educational approach which promotesspatial and numerical skills by Velocicards, an application tostrengthen numerical abilities, by selecting cards with differentcodes favoring the transition between analogical representationsand symbolic ones, helped with collection of statistics. Withinthe same framework, Flatlandia creatures are building blocks ofdifferent geometric features, helping to create links between thephysical and digital worlds stimulating mental representation ofspatial elements. See related work in Refs. [146,147].10.3. Cognitive neuroscienceInvestigations on the capacity of perception, reasoning andaction in spatial coordinates in the identification of visual and spa-tial relationships among objects, to enable subjects to interact withthe surrounding world, is crucial in Cognitive Neuroscience (CN).This understanding will allow the correction of spatial cognitionproblems by assessing visuospatial abilities, as target identifica-tion, object perception and multidimensional spatial relationshipunderstanding, with specific focusing in the visual system. Theplatform ETAN [148] for the assessment of visuospatial abilitiesby means of technology enhancement is introduced, allowing theimmediate physical interaction with external world stimuli byarms and hands using small disks detectable by a video cameratracing the tokens on a specific desk. Three types of arrangementswere simulated: normal, unilateral spatial neglect, and otherunspecific anomalous arrangements. SVM is used to classify anddiscriminate normal from abnormal dispositions.A new interesting psychophysical property of the number inter-val bisection task is the number interval position effect (NIPE). InRef. [149] a quite cognitive character to explore the NIPE in chil-dren and adults is studied. This effect manifests in the task of num-show abersystematic error bias, which is linked to the position occupied bythe number interval within a ten. To study this numerical cognitioninterval bisections where human participantseffect simple arithmetic questions are proposed to human partici-pants demanding an immediate response, as identifying the natu-ral number that divides equally a numerical series delimited bytwo natural numbers (bisection task). An artificial model is pro-posed to explain the effect, based in neuronal principles, implyingthat basic numbers are encoded in an a-modal way by distinct neu-ral groups, and that neural elaboration relies on energy transferbetween neural groups through networks provided with a proba-bilistic winner-takes-all strategy [147].Moreover, CN systems and tools for modeling and measuringcreativity is a prospective topic for the analysis of creative associ-ation [150]. The basis of the research is the Remote Associates Test(RAT) as a measure of the associative factor in creativity, summa-rized in the CreaCogs framework, proposing processes to solveassociative related tasks, creative use and object inference. In addi-tion, a visual adaptation of the RAT to integrate visual and linguis-tic performance was proposed following the methodologydescribed in Ref. [150], and two separate studies were also con-ducted to evaluate it. Correlation studies show how these cognitivecomputation methods present a statistical association between theconstruction of visual and linguistic tests to gain cross-modalstrength.Finally, other studies in CN analyse the influence of the physio-logical signals regarding cognitive states via the autonomous ner-vous system [151]. In the latter work, the methodology is basedon the estimation of the low and high frequency bands over theinterpolated pulse-to-pulse intervals, using a smart wristbandEmpatica E4. Kruskal–Wallis ANOVA, feature ranking and a multi-layer perceptron were used to assess within and between groupcomparisons (controls, slow, normal and fast breathing). In thisway, low and high frequency features of the breathing phase aresuitable for classification, although the cognitive parameters failedin producing statistical significance even though results suggest astatistical relationship between HRV and cognitive parametersduring slow and normal breathing. It can also be inferred that slowbreathing induces a relaxation state that slows down the reactivityand enhances efficiency, producing the clearest changes in theautonomous nervous system state, suggesting that breath controlcould influence the efficiency of certain cognitive tasks.10.4. Clinical neuroscienceA central paradigm in modern neuroscience is that anatomicaland functional connections between brain regions are organizedin a way such that information processing is near optimal [152].As an example, functional connectivity, which is defined as thetemporal dependency of neuronal activation patterns of anatomi-cally separated brain regions, reflects statistical dependenciesbetween distinct and distant regions of information processingneuronal populations [152].To assess connectivity, several experimental frameworks, suchas the estimation of transcraneal direct current stimulation effectson the mobility of distal limbs active in gait [153], are demon-strated to be valid. The latter technique is based on stimulatingsubjects with low levels of direct current between an anode–cath-ode fixture on the scalp, estimating the connectivity among thestimulation areas and the supplementary motor area, the primarymotor cortex, the primary somatosensory cortex and the premotorarea from EEG signals measured on the electrodes associated withthese mentioned areas is being described. The study involved eightsubjects, four of them labeled as ‘active’ ones and four of themtaken as ‘neuter’ (controls). The connectivity study was based onpartial directed coherence on the theta, alpha and beta bands[154], manifesting a differential behavior of active vs neuter sub-sets in the stronger aligned connectivity, shown on electrodes C4and Cz. Possible clinical applications of this stimulation technique254J.M. Górriz et al. / Neurocomputing 410 (2020) 237–270Fig. 19. Composition of the EEG signal from different frequencies (oscillatory activities). Five classical physiological bands are shown for the same raw EEG signal: delta (1–3 Hz); theta (46 Hz); alpha (7–13 Hz); beta (15–25 Hz); and gamma (35–45 Hz). These basic EEG bands are assumed to reflect different functional processes in the brain [155].are in impaired distal limb rehabilitation, as in gait. In the Fig. 19, itis depicted an example of the composition of the EEG signal formdifferent frequencies.Another clinical application is supporting the practice of anes-thesia in peripheral nerves, e.g. based on the visualization and pro-cessing of nerve paths in ultrasound imagery [156]. This toolallows the application of differentimage processes for theenhancement of the representations. These include diverse imagefiltering methods, as average, Gaussian or Bayesian, and what theycall a Super-Resolution tool, performing an increase in the resolu-tion by a user-adjustable factor. The authors present severalmethodologies to implement HAPAN. The system efficiency ismeasured by the average execution time of the algorithm and sim-ilarity coefficients [156].Finally, connectivity is also involved in the development andimplementation of computational models of different types ofvisual neurons [157]. The goal is to design a tool enabling the inter-face of the models with a visual neural prosthesis and creating nat-ural electrical stimulation patterns, specifically targeted to theUtah cortical visual stimulation arrays. In this sense, we need todesign and integrate models of neural function, psychophysics, sig-nal processing and neural encoding, for their application in a work-ing pipeline, leading to advance the development of cortical visualprostheses. Vision models were based on retinal processing mod-els; stimulation and control API’s, communication with the NeuralCompute Stick from Intel, and helper functions as filters on elec-trode mapping compose the software framework. The stimulationcontrol capability of the system has been tested using ganglion cellfiring responses to different light patterns deployed on a neu-rostimulator control simulator, on its turn, the retina model hasbeen defined normalizing the ganglion cell model weights on aDL model.11. Biomedical applicationsNowadays, biomedical applications are trending topics in con-temporary research. New devices, approaches, techniques or toolk-its are some advances in this research area. The main feature of thisfield is the degree of interdisciplinary between diverse profession-als. For instance, the application of medical principles joins todesign and develop of new approaches or tools that require theconjunction of engineers, physicians, mathematicians and speechtherapists, among others. Bioinformatics, biomechanics, biomateri-als, medical devices, rehabilitation engineering are only some ofthe different fields that belong to biomedical applications. Theseapplications allow advancing in health care treatment, includingmonitoring, diagnosis or even therapy [158]. When discussingbiomedical applications the areas involved are numerous anddiverse. One of the biomedical areas that has received considerableattention over the last decade is neurodegenerative disorders, suchas PD or AD. Indeed, the number of patients with PD is expected todouble in twenty years and will triple around 2050 [159]. In theFig. 20 is depicted the prevalence as the percentage of the popula-tion that is affected by the disease. Shading indicates 95% uncer-tainty intervals.On the other hand, our current life style is frantic and stressless.For this reason, heart attacks, and strokes are very common healththreats too. Since 2006 yearly, the American Heart Association(AHA) brings together the most up-to-date statistics related toheart disease, stroke, and other cardiovascular and metabolic dis-eases and presents them in its Heart Disease and Stroke StatisticalUpdate in conjunction with the Centers for Disease Control andPrevention, the National Institutes of Health, and other govern-Fig. 20. Prevalence is expressed as the percentage of the population that is affectedby the disease. Shading indicates 95% uncertainty intervals [159].J.M. Górriz et al. / Neurocomputing 410 (2020) 237–270255ment agencies due to the relevance of this kind of health problemsin USA and over the world [160].11.1. Neurodegenerative disordersPatient’s neuromotor functionality in relation to PD is assessedby the use of neuroacoustical stimulation with binaural beats andits observable effect on phonation [161]. The main approach isbased on stimulating with two kinds of signals, active or non-active. A set of acoustic features were extracted such as jitter,shimmer, biomechanical unbalance, and tremor in different bands.A cohort of 14 volunteer speakers in stages 1 and 2 of the Hoehn &Yahr Scale [162] were recruited. Each patient was submitted to twoneuroacoustical stimulations (pre and post-stimulus) with a mini-mum separation of seven days. Results from a single male speakershowed statistical relevance. Four speech recordings were usedand the segments of the vowel [a:] were analyzed. It seems thata clear positive effect was produced by neuroacoustical stimulationin the phonation neuromotor stability of the PD patients.On the other hand, information theory fundamentals and com-mon statistical tools can be applied to differentiate and score PDspeech on phonation and articulation estimates [163]. To this pur-pose, a speech corpus is divided into three groups of individuals:the first group consists of PD patients, the second group is com-posed of age-paired healthy controls, and the last group is inte-grated by mid-age normative subjects. A sustained vowel [a:]was used to assess the capability phonation stability between PDpatients and age-paired healthy controls within the same agerange, concerning a normative reference set considered the goldenstandard regarding maintained phonation. Vowel utterances by 8males and 8 females from the three groups were extracted andused in the analysis. Based on the mutual information betweentwo given probability density functions, they were able to distin-guish PD, aging healthy controls (HC) and normative subjects. Any-way, further validation including the effects of laryngeal pathologycases, which is known to strongly alter the phonation profile isrequired in future research.11.2. Heart, eyes and genomicsOne of the major clinical contexts in which algorithms forbiomedical signal processing are designed, is diagnosis. As anexample, the use of continuous wavelet transforms on the Electro-cardiography (ECG) signal is evaluated in differentiating the heartrate produced by non-ischemic events from ischemic episodes[164]. Randomly chosen patient records from an open-source data-base (Long Term ST Database) were used in the study. From thesedata, a set of episodes were selected to carry on the evaluation. Theduration of each record ranged from 48 to 4710 s, with 52 ischemicand 25 non-ischemic related episodes. This technique provided fre-quency as well as time information. The result scores were 86.64%in sensitivity and positive predictability, respectively.Another study in signal processing and diagnostics [165] pro-poses a method to automatically locate and segment the optic diskand the excavation in retinal fundus images to determine normalfrom glaucoma-affected eyes in the clinical evaluation. Theapproach is based on a fast and efficient morphological image anal-ysis and a frequency-based implementation of active contours. Thefundus images were acquired by means of a Topcon TRC-NW400non-mydriatic retinal camera. The main advance in Ref. [165]was the use of an efficient frequency-based implementation ofparametric active contours, which are time-varying curves widelyused in image processing for describing boundaries of objects.Usual applications are segmentation and tracking of structures ofinterest within the image. Two main traits, ISNT and CDR, wereconsidered. The first one explains the regular morphological shapeof disc rim thickness eye, and the second one is cup-to-disk ratiowhich is used in ophthalmology as a measurement to assess theevolution of glaucoma. The results automatically obtained werecompared with the values of CDR provided by two expert ophthal-mologists and found to be analogous.Finally, in the field of genomics [166] focuses on describingresearch on a tool for the guided and safe composition of pipelinesto treat a specific kind of sequence in RNA-proteins. Specifically,Photo-Activable-Ribonucleoside-enhanced-CLIP (PAR-CLIP) wasproposed to achieve a single-nucleotide resolution. A critical stepcalled, peak calling, is used in the analysis of PAR-CLIP sequences.This study dives into general data processing and several algo-rithms of peak calling used in PAR-CLIP sequences that helps toput together the heterogeneous pieces of the puzzle. In this sense,the research work presents BIOTHINGS, a tool that enables theseamless construction of PAR-CLIP sequence treatment pipelines.12. Care and well-being applicationsThis area of research represents a variety of AI applications forpersonal and professional services, demonstrating how artificialintelligence technology is addressing the needs of individuals andsociety. Large and mid-size enterprises are intensifying the use ofML and AI in their products, taking advantage of the opportunitiesthese technologies present to perform advanced analysis on bigdata sets and to improve the performance of their products andservices.The topics are grouped under three themes: AI in mobile devices,AI at home, and AI in education. Fig. 21 shows an overview of thesetopics. A ‘‘mobile device” is a generic term used to refer to a widerange of devices that allow people to access data and informationfrom anywhere at any time. These devices include laptops, smart-phones, tablets, wearables, etc. Most of us carry mobile devices,and thanks to better sensors and network connectivity, thesedevices are being used for an increasingly wide range of applica-tions. We will highlight three fields of application in this section:efficient scheduling for mobile computing, pedestrian absolutepositioning, known as ‘‘dead reckoning” for indoor localization,and gesture control with wearable devices for human–machineinteraction.Due to the increase in demand for ubiquitous computing andthe fact that most user requests have time constraints, real-timescheduling mechanisms must be employed. Usually, schedulingalgorithms are divided into two types: input task schedulers(scheduling the requests received from users or sensors) and out-put task schedulers (scheduling the results or services obtainedthrough the execution of input tasks). In this domain of complexreal-time systems, AI appears to be an effective approach to copingwith real-time decision making [167,168]. Several AI techniqueshave been proposed to guarantee that time and resource require-ments are met. Some of these techniques [169,170] are expectedto be the backbone upon which complex real-time systems canbe built. An architectural model that includes a high-level AI plan-ner, a low-level real-time scheduler, and an appropriate interfacebetween the two [168,171] appears to be suitable if we want toachieve real-time predictability and to cope with increasingly com-plex problem solving.The ability to track people and equipment indoors has applica-tions in many areas, such as hospital tracking of patients, visitorsor employees, or for retail stores to customize displays, collectshopping patterns, assist customers in finding products, etc. Oneof the solutions explored in the past is the double integration ofthe observed acceleration of the smartphone. However, doubleintegration rapidly accumulates errors from the high-noiseaccelerometers. Some works [172,173] focus on correcting the256J.M. Górriz et al. / Neurocomputing 410 (2020) 237–270Fig. 21. Overview of the topics covered in Care and Well-being Applications.measurements in order to reduce the accumulated error, but theseapproaches make several assumptions, such as that subjectsalways walk on a flat floor. Most existing approaches for headingestimation [174,175] using PDR assume that the misalignmentbetween a device’s forward direction and the user’s headingremains constant. This does not work when the phone is in apocket, though, since the yaw angle will change dynamically evenwhen the pedestrian is walking straight ahead. In the case of themagnetometer, the magnetic field is strongly perturbed by sur-rounding artificial fields [176].12.1. AI in mobile devicesIn the case of AI for mobile devices and mobile computing,scheduling is one of the classic problems in real-time systems.The work presented in Ref. [177] focuses on the evaluation of anAI planner in mobile broadcasting. The real-time scenario chosenfor this evaluation is based on the Adaptive Hybrid Broadcast(AHB) model [178,179].The multi-level scheduler is divided into: i) High-level sched-uler (HLS): responsible for determining the requests to be servicedfrom among all requests received and the specific data units to betransmitted for each request and ii) Low-level scheduler (LLS):responsible for generating a schedule of all the data units thatare going to be broadcast. The results show that the incorporationof AI in the real-time scheduler improves its performance, adap-tiveness and responsiveness. Next steps in this area include MLtechniques to further improve the performance of the HLS.In the context of heading estimation in walking recognition[105] proposes a novel method which combines the processing ofinertial data with ML techniques and quaternion algebra to give anaccurate estimation of the user’s heading. A robust user headingestimation is obtained whether the smartphone is carried in thehand or pocket without making any assumptions or using moreinformation than that coming from the inertial sensors of thedevice. First, using the 9-dimensional data from the 3 inertial sen-sors (accelerometer, gyroscope and magnetometer), a quaternion isestimated, which represents the attitude of the phone in theinertial-Earth reference system (independent of the device pose)applying Madgwick’s method [180]. Second, the relative positionof the device with respect to the user (hand, pocket, other) is com-puted, using a SVM that is trained using features extracted fromthe IMU. The best Euler angles are selected from the quaternion,which represent the attitude of the phone and make some correc-tions to the angles by taking into account the position of the devicewith respect to the user.The use of wearables for human–machine interaction via ges-ture recognition is a particularly important topic, specifically inthe context of service robots. In Ref. [181] a fuzzy logic controlleris proposed for controlling a mobile robot using visual and depthinformation provided by a Kinect2 device. In Ref. [182] a vision-based system along with a 3-axis accelerometer is used forhuman-robot interaction, proposing both static and dynamic ges-ture recognition modules using artificial neural networks and hid-den Markov models. In Ref. [6] two 3-axis accelerometers attachedto both wrists of an operator are used to control a robotic arm. Oneis used for launching different kinds of interactions (static ordynamic) while the other activates or deactivates the Human-Robot Interaction (HRI) system. Different methods of receivingthe human controller’s information are also proposed in the litera-ture,language[3,183,184].vision [6,181,182]and naturalincludingAs an example, in Ref. [107] presents the deployment of two dif-ferent wrist wearable devices, as shown in Ref. [6], called Con-trolaBLE and OperaBLE for the two wrists of an operator. Bothwearables are composed of a micro-controller, accelerometer,J.M. Górriz et al. / Neurocomputing 410 (2020) 237–270257gyroscope and battery, and use Bluetooth Low Energy (BLE) con-nectivity for controlling a robotic arm. A finite state machine ofpossible interactions between the wearables and different interac-tion states is then proposed. The hardware architecture is com-posed of two Raspberry Pi 2 low energy programmable boards,one in the user part of the pipeline and another in the final roboticarm activating six servos. A motion recognition algorithm calledLoMoCa (Low Motion Characterization) is also proposed and exe-cuted in the Raspberry Pi that receives the information from theBluetooth-connected wearables. Finally, commands are transferredto the second Raspberry Pi to move the robot.12.2. AI at homeRegarding the use of AI at home, Ref. [185] focused on theindoor luminance level, which is affected by natural light, artificiallighting and shading devices.A black-box method is proposedbased on a divide-and-rule strategy to determine natural illumina-tion and artificial lighting separately. Natural illumination is esti-mated by an ANN that receives an input vector with thefollowing components: date, hour, outdoor luminance, diffuseradiation, global radiation, and blind state. Artificial lighting isdetermined by a polynomial interpolation method, which managesthe voltage applied to regulate light intensity. The ANN structurewere composed of two hidden layers with 12 neurons each, anda sigmoid activation function. ANN parameter estimation wasaccomplished with a set of 57,000 measurements subdivided intotraining (75%), validation (20%) and test (5%) sets, respectively.The proposed system was validated under real conditions over aperiod of time from March to July, obtaining a relative error of1.7% on average.In the context of personalized menus [186], the system Die-t4You was originally proposed in Ref. [187], with new componentsadded this year for the generation of nutritional plans taking intoaccount user preferences and cultural factors. Diet4You is com-posed of two main blocks. The first is the Nutritional Plan Genera-tor (NPG), designed to provide a recommended nutritional plan fora given person. The second one is the Personalized Menu Planer(PMP), which is able to deal with additional restrictions, like med-ical constraints (diabetics, food allergies), personal preferences,and cultural factors. The reasoning mechanism is Case-Based Rea-soning (CBR) [188], which reuses previous menu configurations,corresponding hard constraints, and user preferences to meet apersonalized recommendation menu for a given user. The FNDDSand FPED databases offered by the USDA (United States Depart-ment of Agriculture) [189] are used as sources of knowledge forthe nutritional prescription.12.3. AI in educationFinally, regarding the third and final topic, AI in education(Fig. 21), aims to identify weaknesses in the learning progress ofstudents and to improve their lexicon of an individual as a resultof an educational process. Since a higher lexicon indicates a higherunderstanding in a domain, early detection of missing lexicon instudents is key to identifying weaknesses in their learning pro-gress. Studies on lexical availability include [190], which presentsa quantitative and a qualitative approach to lexical availability inmathematics for a specific group of students.For AI in education [191] introduced Lexmath, a platform thathelps describe and quantify a student’s lexicon in different mathe-matical subjects. This platform collects data from students usinglexical availability tests. To correctly relate students and the differ-ent Bayesian networks to be generated, three indexes are pro-posed: number of different words, relative frequency, number ofwords and number of tables of conditional probability. The methodconsists of the following steps:1. For every class, a Global Graph is created, taking into account allthe words mentioned in the class.2. For every student, a list is created containing all the words thestudent did not mention.3. A subgraph considering each word the student did not mentionis built from the global graph.4. Every subgraph is converted to a network removing edgeswhich belong to cycles, taking into account the frequency andorder for each node.5. A priori probabilities are assigned to every network, obtainingan a priori Bayesian network.6. Evidence is added to every a priori Bayesian network. Evidencecorresponds to a word the student mentioned during the test.7. A specific node is analyzed.8. Nodes are ordered in decreasing probability of appearance, andthe result is informed as a group taking into account the ID ofthe student.13. Discussion and current trendsIn this section we present some discussions related to the afore-mentioned sections and the current trends and perspectives ineach field of research.13.1. Models: Advancing in data scienceDespite the progress made, it is necessary to continue lookingfor more efficient and effective mechanisms, improved solutionsboth in performance (decrease in the failure rate) and in cost (re-sources, time, price, etc.). A possible line of action is to look forhybrid models that combine the good qualities of the base modelsto obtain more robust solutions, the ability to model and integratedata, to work with datasets with imbalances or smaller, and in gen-eral eliminating the deficiencies of the previous ones.Another possible line of action is to look for new models thathave among their starting requirements to optimize new charac-teristics, that are disruptive, and this brings new ways of address-ing the problem. Narrow AI will continue to spread in this digitalage, as the infrastructure is very advanced and it will be relativelyeasy to generate new applications.Undoubtedly, one of the main challenges for the near future isto create standard explaining tools that allow non-specialists tounderstand AI decisions. This will certainly helps to increase theacceptance of AI in society. Explainability of black box models isone of the crucial aspects that should improve, especially, in criti-cal domains. In the last three years, with the advent of XAI [33],many authors proposed various techniques in this field [20].A key to the design of new models in AI is the trade-off betweenperformance and complexity. A procedure for achieving such atrade-off favorably is to increase the model complexity, whichallows for improvement in performance, while controlling orassessing the generalizability of the system by proper statisticalmethods. Optimally, this would maximize performance and mini-mize variability of performance. However, this also depends onthe nature of the data being processed, and thus the selection ofa model architecture to achieve a given performance is a rule ofthumb, that is, one cannot expect it to be totally reliable for everyengineering and scientific application. Good examples of this factare the application of the well-known deep learning (DL) architec-tures to specific scenarios, e.g. GoogLeNet, AlexNet, LeNet, or thedevelopment of CAD systems using a fixed-complexity (i.e., linear)SVM. In the latter case, the design of the system is more focused onpreprocessing and feature extraction and selection steps rather258J.M. Górriz et al. / Neurocomputing 410 (2020) 237–270than the classification or prediction stages (unlike the DL-basedapproaches).On the other hand, open issues in fields such as systems inter-operability, security, semantic analysis of human cognition, behav-ior and organization, trust and reputation management, etc. seemto be appropriate for hybrid models where ontologies must playa fundamental role.13.2. Ethologyfor a human,Human computational neuroethology offers great challengesand opportunities. The goal is to be able to set up a neuroetholog-ical experimental capture system in almost any natural environ-menti.e. at home, at work, while easingthemselves, maximizing the ecological validity of the experimentwhile preserving measurement and analysis accuracy. This is farfrom being feasible currently, due to the still emerging wirelessEEG devices, and related devices based on nearinfraredspectroscopy.From the point of view of the applications, it is clear that suchexperimental environment would be extremely useful for the anal-ysis of a variety of neurodegenerative diseases, as well as theassessment of the impact of treatments, which actually is doneon a qualitative basis. Neuroethological research can also be intro-duced in the industry, in order to measure with precision theimpact of the workplace on the worker at the neural and posturallevels. In this regard, we are also involved in the study of sucheffects in the framework of the mechanical machining when theoperator is working numerically controlled machines.Fig. 22 illustrates this environment, where we use a wet wire-less EEG to obtain the neural signal (upper left image shows a 3Drendering of the brain activation in some specific band). The bodymotion and pose is recorded by means of depth imaging (lower leftimage of a kinect depth map), and inertial sensors (right image ofthe Rokoko avatar). If such kind of studies can be translated intoaggressive environments like the metal industry, they can be alsoimplemented in many other productive activities, helping toimprove the preventive health screening of workers, and increas-ing their productivity.Another area of great potential impact is the study of falls in theaging population, which can be associated to neural degenerativediseases, but can also be spontaneous events in healthy persons.Falls in aging people are a source of multiple complications thatdegrade the quality of life of the persons. Careful non-invasivemonitoring may serve to detect early neural signatures that wouldprevent such events, or rise early alarms. However, the greatestimpact of the neuroethological research is far from being realized.Synchronous observation of brain activity and behavior response iscalled to impact many areas of human activity.The human learning process involves many facets of brain mat-uration, plasticity and evolution in response to the external stimu-lus, which can be a teacher or a technological object, such as ananthropomorphic robot. How does the child react to such interac-tions is a matter of interest for the future of humanity, becausehow we educate our children will impact in the future state ofsociety.Another related emerging area of work is the so called mobilebrain imaging research, where much of the work done is relatedto the reproduction of conventional EEG based experiments butallowing some freedom of movement to the subject. For instance,new mobile applications are proposed to facilitate data collectionin diverse setting [192]. Interaction of walking activity and visualacuity in the increased activation of the sensorimotor cortex canbe studied with these new tools [193]. Even the measurement ofauditory brain evoked potentials while ciclying outdoors have beenreported [194].New datasets are being published in order to stimulate compu-tational research in this exciting new area [195]. Big data availabil-recentity willcomputational innovations, such as the DL architectures that haverevolutionize several industrial fields, such as machine translationand image processing in medicine as well as in other areas.application ofthe mostencouragethe13.3. Affective computingResearch in designing applications with affective capabilities isconstantly increasing. With this growth, affective computing is forsure an integral part of the development of future technologiesconcerning the human being. In recent years an important movehas been perceived towards continuous current emotion recogni-tion for real-life environments [196].Health care is probably the primary beneficiary of the futureaffective computing technologies. Some developments have helpedphysicians to understand mentally disabled patients. Thanks to thegrowth in artificial intelligence, ML and the Internet of the Things,health care applications are already benefiting from advancedFig. 22. The ongoing research on the neuroethological interactions in industry machining working environments includes inertial sensors, depth sensors, and wireless EEG.J.M. Górriz et al. / Neurocomputing 410 (2020) 237–270259patient monitoring devices that use facial and vocal coding tech-niques. The detection of different diseases and mental disorders,including stress, depression and anxiety, is a reality to date thanksto the augmenting capacities offered by advanced wearables.It is reasonable to expect that emotion detection and interactionpersonalization to better suite a person’s emotional state willbecome an integral part of HMI in a few years. This will also be astarting point of a realistic human–machine symbiosis. In thisregards, robotic devices equipped with affective computing willelevate the human-robot link to the level of human–humanrelationships.In the close future, the research in portable brain interfaces pro-viding neuroimaging will continue growing. A greater insight intothe brain mechanisms underlying the highly complex affectiveaspects of the human being have still to be discovered. Every stepin this direction will help affective computing to be a leading areain the development of novel health care applications.Further from image processing, Ref. [185] proposes an intelli-gent control system for an office whose end objective is to adaptthe artificial lighting in order to provide pleasant illumination incombination with the available natural lighting, while becomingsustainable by using only the necessary energy. The ANN usedfor this purpose only has two hidden layers since the number offeatures was relatively low, but the results using lighting data fromMarc to July suggest that the model could be effective in predictingthe available natural light.Many learning problems can be addressed by means of DLmethods due to their potential to extract abstract features fromdata. Some applications do not involve classification or detection,but put the focus on the feature extraction itself. This is the reasonwhy pure feature extraction models such as autoencoders are ver-satile and can help in other learning problems. In Ref. [45], severalof these applications of deep feature learners are presented: datavisualization, image denoising, anomaly detection and semantichashing in text documents.13.4. Bioinspired systemsIn recent years there has been a large increase of new algo-rithms with the label ‘‘bio-inspired” (see [197] for a number ofexamples). Most of the new approaches simulate or take inspira-tion from animal (in majority of cases) and plant behavior, gener-ally incorporating their adaptive mechanism in the natural worldin order to devise new search or optimization algorithms. The algo-rithms that mimic the behavior of social insects is a clear example:Artificial Bee Colony (ABC) algorithm, Genetic Bee Colony (GBC)algorithm, Firefly algorithm, Ant colony optimization, etc.The frontiers between different fields like bio-inspired comput-ing and natural computing are not clear and depend on theauthor’s definition. It is commonly accepted that bio-inspired com-puting integrates all such meta-heuristics, but also other methodswith biological inspiration such as artificial neural networks andneural networks with a stronger simulation of the biological neuralnetwork mechanisms.Bio-inspired approaches include also all the methods of thebroad field of evolutionary computing, including the methods thatfocus on swarm intelligence like Particle Swarm Optimization(PSO) and solutions based on bird flocking, bacteria foraging andfish schooling, methods in which the collective intelligence orcoordination of the group serves to obtain an emergent behaviorthat resolves a problem. Note that some of these concepts aretaken from other fields like artificial life or complex systems.Nevertheless, regardless of the particular field in which anauthor feels better to place his/her research, the researchers in thisfield or fields with bio-inspiration must be self-critical with theboom of, especially, such new metaheuristic solutions [197]. Itmust be carefully contrasted what is new and what is includedin other traditional search algorithms or what novelty is providedin a new bio-inspired metaheuristic. Besides, the proposals shouldbe competitive with other methods in the state of the art. In thissense, a key aspect of the design of evolutionary and swarm intel-ligence algorithms is studying their performance in terms of statis-tical comparisons [198].Apart from this rise of metaheuristics, bio-inspired computingwill progress in providing the dual perspective discussed in theintroduction, where bio-inspired methods not only provide newapproaches to solve problems as biological systems do (direct engi-neering), but also they can provide new knowledge about theunderlying mechanisms of their functioning (reverse engineering).Moreover, new computing paradigms, from the Map/Reduce modelthat lies underneath Big Data architectures to Ephemeral Comput-ing, Exascale Computing and Quantum Computing [199] will pro-vide a novel framework for the design and deployment of bio-inspired algorithms and optimization methods.As previously remarked, multidisciplinarity is and will continueto be a key component in this double interrelation and, hopefully,this field of research will continue as a meeting point for research-ers in all these areas.13.5. RoboticsThe use of Artificial Intelligent methods in Robotics is growingat a fast pace, and at the same time, the applications and uses ofRobotics are being introduced in more fields. The interaction withhumans is clearly where there is an exponential growth in the lateryears and it is a very promising field to produce more benefits forsociety.The human-robot interaction has different aspects to consideras shown in previous sections. First, the physical interaction byusing robots to assist disabled or elderly people to achieve a betterquality of life. Also, emotional interaction will provide more amica-ble and adaptive interactions with robots. Finally, the applicationsin education and with social robots are the more challenging onesto introduce the robots in our daily life.Of course, the other field that will feel a great grow is the indus-trial applications of robotics, where there is already many areas toimprove by the application to Robotics of recent techniques fromML (DL, CNN, etc.) and the use of new massively parallel computa-tion resources (GPUs).13.6. Machine/deep learning and big data analysisDL NNs stand as one of the most promising research fieldswithin ML in some prospective applications, e.g. neuroscience.Their commoditization has been favored by the ease of use of pre-trained networks. Nevertheless, CNNs have been already estab-lished as the standard toolfor most computer vision tasks.Nevertheless, there is still room for improvement. The integrationof deep networks into probabilistic models may allow employingalready studied robust Bayesian frameworks to enhance the accu-racy and reliability of intelligent systems based on deep neuralarchitectures.As shown in previous sections, ML, computer vision and DLtechniques provide a new arena for data processing in the neuro-sciences. Advances in these areas have allowed 1) to exploit theinformation contained in the data, 2) to fuse information from dif-ferent sources and different in nature and 3) deal with vast amountof data (Big-Data problem). The combination of them have revolu-tioned the research in many fields of science and, of course, in theneurosciences where traditionally, only classical statistical meth-ods to test differences between groups have been applied.260J.M. Górriz et al. / Neurocomputing 410 (2020) 237–270Nevertheless, ML methods and DL networks have constraintsthat restrict their scope of use. On the one hand, in the traditionalML classification workflow, specific and predefined statistical fea-tures have to be computed/extracted before they are fed into theclassifier. Additionally, a feature selection stage may help to usesimpler classifiers, avoiding the overfitting problem and maximiz-ing the classification accuracy. On the other hand, DL methodslearn specific features extracted from the data manifold, whilstthey try to improve the classifier performance. In other words, FEis indeed included into the learning stage, not being limited to aspecific FE method and being defined by the use of millions ofparameters. This provides models that can outperform statisticaland ML approaches, at the cost of the need for having large enoughdatabases the DL model can learn from. Otherwise, when the sam-ple size is limited or more precisely the ratio sample size overnumber of predictors is small, overfitting may arise, diminishingthe generalization performance of the generate model. In this case,DL methods operating in several fields also require a little helpfrom preprocessing techniques, e.g. neuroimaging.Thus, another research line consists on the development of opti-mization and self-optimization methods to refine the architecturesor even, to generate custom networks depending on the input data,its characteristics and the specific problem to be solved. There aresome research work in this direction, using evolutionary comput-ing for the improvement of the hyperparameters and the architec-ture of the neural network. Moreover, the intensive use ofcomputing resources in DL and Big-Data, makes necessary the opti-mization of the neural architectures according to the availablecomputing resources and eventually, to be energy-aware, whichconstitutes an important research line. On the other hand, thedevelopment of hybrid methods and information fusion techniquesplay an important role in the exploitation of all the available dataand to be able to learn multi-modal and complex models withenough generalization capabilities.Nowadays, the availability of large image databases (as in thecase of Autism studies or Parkinson diagnosis), along with mas-sively parallel processor architectures (such as GPUs) to composeheterogeneous systems (containing both, CPUs and GPUs) makespossible the practical use of DL architectures for exploratory anddiscriminative analyses. In fact, one of the main research lines inDL consists on the development of new methods to explore wherethe neural networks focus their attention while they learn to sep-arate classes. Furthermore, visualization methods in CNN networkscan be exploited to compute regions of interest and to rank them.Indeed, one of the most relevant tendencies in current Big Dataanalysis is the commoditization of ML models and, in particular, DLmodels.In other words, models are packaged into standardlibraries which are ready to apply by end users. As an example,two relevant methodologies for Big Data analysis are i) the one thatapproximates methods that carry out a direct fusion of models andii) the paradigm that provides an exact fusion of models [200], andboth may be found in the specialized literature and in standardMachine Learning libraries, such as Mahout or MLlib.This trend increases the importance of procedures to combineseveral already existing methods in order to enhance the perfor-mance. Therefore, advances in big data analysis will significantlybenefit from the development of meta-methods which draw onalready existing approaches, so that a wide range of base methodscan be employed with the same metamethod. This way the knowl-edge acquired by the base methods can be exploited to attain morechallenging goals.The ever-increasing diversity of kinds of available data is alsovery relevant for practical application of Big Data techniques. Clas-sic approaches were focused on the analysis of a specific data type,so that they can not be applied straightforwards to datasets whichcomprise different kinds of information. In order to overcome thisFig. 23. Hybridization of methods which process different data types.difficulty, a popular strategy consists in the combination of differ-ent approaches which process diverse information types.Hybridization of methodologies and algorithms stands as a promis-ing research line, since it is a suitable way to cope with the com-plexity of the data flows that ML is applied to. Fig. 23 representsthe hybridization concept, where different data sources are pro-cessed by methods tailored to their data types, and their outcomesare combined by the hybrid method to yield the final result.13.7. Neuroscience, biomedical and well-being applicationsThe scope of Section 10 falls within the remit of the concept ofNeuroscience Applications. Given the broad scope, we aimed toprovide an indicative summary of the research area which we can-not claim to be exhaustive or even too comprehensive. Neverthe-less the selected studies covered several hot topics which are ofparticular significance in this research field. The subsections com-prised EEG-BCI systems exploring the relationship between evokedsignals and specific tasks as gait; object handling, speaking or gam-ing, wearable devices or interfaces with application in monitoringaging or breathing; cognitive tasks improved by ML to help in theacquisition of numerical skills or creativity; and medical applica-tions as assisting in anesthesia practicing or visual interfaces.Needless to say that specific BCI systems, wearable signal acquisi-tion, cognitive assessment and validation of learning processes orassisting technologies will be quite relevant topics in the field ofneuroscience applications.In addition, Section 11 provided only a partial view into somerepresentative topics rather than attempt to be all-inclusive. Someworks were related to PD, investigating the acoustic neurostimula-tion and the instability of phonation of these subjects, whilstothers described the difference between ischemic and heart-raterelated events using the continuous wavelet transform or dealtwith a method to automatically locate and segment the optic diskand the excavation in retinal fundus images to differentiate normalfrom glaucomatous eyes in the clinical evaluation. Finally, thebiomedical applications in this Section 11 were focused on assess-ing differences in activation of both hemispheres in stroke sur-vivors during a motor task usually employed for brain-computerinterface control; and the description of a tool for the guided andsafe composition of pipelines to treat a specific kind of sequencein RNA-proteins.Moreover, in Section 12 the combination of sensors, connecteddevices, computing resources, advanced communications, andJ.M. Górriz et al. / Neurocomputing 410 (2020) 237–270261real-time interactions is leading to the creation of ubiquitous sys-tems at a scale and complexity previously unimaginable. AI appli-cations will touch almost every aspect of our lives; education,assistance at home, and mobile devices are some of the fieldsaddressed in the papers summarized in this review. The successof AI in such diverse fields requires both new and traditional arti-ficial intelligence techniques, better understanding and leverage oflarge data sets which may be heterogeneous, and the ability tobuild new models and make accurate predictions in a wide varietyof scenarios under complex conditions.14. ConclusionsAs a conclusion, we have comprehensively analyzed noveladvances in AI, DS and all their supporting tools, based on severalmodelling paradigms, such as the bio-inspired, hybrid or statisticalapproaches, and technologies, e.g. bio-electrical devices, medicalimaging, or robotics. The paper was organized in three conceptualblocks, that is, i) theoretical models and learning architecturesenhancing advances in DS and AI, ii) special thematic issues withinthe scope of AI, and iii) several applications in the research fieldscovered throughout the paper.Most of these advances were presented and discussed in theIWINAC conference, held in June, 3–7, 2019, in Almería, Spain. Inthis sense, novel insights in the understanding of the brain functionand emotions, were shown by addressing the current technologicalchallenges, i.e. the design of robust BCI-based systems for neuraldata processing and analysis, brain pattern recognition in neuro-logical diseases, interfacing with physical systems or the problemof emotional state recognition. Moreover, the basis or backgroundrequired to develop such applications, and many others in the fieldof biomedical research, were also described in the first part of theessay. From models, ontologies and hybrid bio-inspired systems, toML and DL approaches, the proposed methods allow a hugeamount of bioinspired programming strategies aimed at providingefficient computational solutions to engineering and medical prob-lems, in different applications domains such as biomedical sys-tems, big data or neuroscience.All these advances will be crucial for the new era of AI, which isrevolutionizing and reshaping our style of life and society. More-over, AI, DS and supporting fields will help in providing systematicand autonomous systems that provide useful insights, predictions,recognitions and analytical solutions from the available big data.Declaration of Competing InterestThe authors declare that they have no known competing finan-cial interests or personal relationships that could have appeared toinfluence the work reported in this paper.CRediT authorship contribution statementJuan M. Górriz: Project administration, Conceptualization,Writing - original draft, Resources. Javier Ramírez: Writing - orig-inal draft, Resources. Andrés Ortíz: Writing - original draft,Resources. Francisco J. Martínez-Murcia: Writing - original draft,Resources. Fermin Segovia: Writing - original draft, Resources.John Suckling: Writing - original draft, Resources. Matthew Lem-ing: Writing - original draft, Resources. Yu-Dong Zhang: Writing -original draft, Resources. Jose Ramón Álvarez-Sánchez: Writing -original draft, Resources. Guido Bologna: Writing - original draft,Resources. Paula Bonomini: Writing - original draft, Resources.Fernando E. Casado: Writing - original draft, Resources. DavidCharte: Writing - original draft, Resources. Francisco Charte:Writing - original draft, Resources. Ricardo Contreras: Writing -original draft, Resources. Alfredo Cuesta-Infante: Writing - origi-nal draft, Resources. Richard J. Duro: Writing - original draft,Resources. Antonio Fernández-Caballero: Writing - original draft,Resources. Eduardo Fernández-Jover: Writing - original draft,Resources. Pedro Gómez-Vilda: Writing - original draft, Resources.Manuel Graña: Writing - original draft, Resources. Francisco Her-rera: Writing - original draft, Resources. Roberto Iglesias: Writing- original draft, Resources. Anna Lekova: Writing - original draft,Resources. Javier Lope: Writing - original draft, Resources. Eze-quiel López-Rubio: Writing - original draft, Resources. RafaelMartínez Tomás: Writing - original draft, Resources. Miguel A.Molina-Cabello: Writing - original draft, Resources. Antonio S.Montemayor: Writing - original draft, Resources. Paulo Novais:Writing - original draft, Resources. Daniel Palacios-Alonso: Writ-ing - original draft, Resources. Juan J. Pantrigo: Writing - originaldraft, Resources. Bryson R. Payne: Writing - original draft,Resources. Félix la Paz López: Writing - original draft, Resources.María Angélica Pinninghoff: Writing - original draft, Resources.Mariano Rincón: Writing - original draft, Resources. José Santos:Writing - original draft, Resources. Karl Thurnhofer-Hemsi: Writ-ing - original draft, Resources. Athanasios Tsanas: Writing - orig-inal draft, Resources. Ramiro Varela: Writing - original draft,Resources. Jose M. Ferrández: Project administration, Conceptual-ization, Writing - original draft, Resources.AcknowledgmentsTIN2017-90135-R,PGC2018-098813-B-C32,The work reported here has been partially funded by many pub-lic and private bodies. Spanish Ministry of Science, projects:PSI2015-65848-R,TIN2017-85827-P,RTI2018-098913-B-I00,RTI2018-PGC2018-098813-B-C31,101114-B-I,andRTI2018-094645-B-I00;FPU program (FPU15/06512,FPU17/04154) and Juan de la Cierva (FJCI-2017–33022). Autono-mous Government of Andalusia (Spain) projects: UMA18-FEDERJA-084. Consellería de Cultura, Educación e Ordenación Univer-sitaria of Galicia: ED431C2017/12, accreditation 2016–2019,ED431G/08, ED431C2018/29, Comunidad de Madrid, Y2018/EMT-5062 and grant ED431F2018/02.RTI2018-098743-B-I00thePPMI – a public – private partnership – is funded by TheMichael J. Fox Foundation for Parkinson’s Research and fundingpartners, including Abbott, Biogen Idec, F. Hoffman-La Roche Ltd.,GE Healthcare, Genentech and Pfizer Inc.Data collection and sharing for this project was funded by theAlzheimer’s Disease Neuroimaging Initiative (ADNI) (NationalInstitutes of Health Grant U01 AG024904) and DOD ADNI (Depart-ment of Defense award number W81XWH-12-2-0012). ADNI isfunded by the National Institute on Aging, the National Instituteof Biomedical Imaging and Bioengineering, and through generouscontributions from the following: AbbVie, Alzheimer’s Association;Alzheimer’s Drug Discovery Foundation; Araclon Biotech; BioClin-ica, Inc.; Biogen; Bristol-Myers Squibb Company; CereSpir, Inc.;Eisai Inc.; Elan Pharmaceuticals, Inc.; Eli Lilly and Company; Euro-Immun; F. Hoffmann-La Roche Ltd and its affiliated companyGenentech, Inc.; Fujirebio; GE Healthcare; IXICO Ltd.; Janssen Alz-heimer Immunotherapy Research & Development, LLC.;Johnson &Johnson Pharmaceutical Research & Development LLC.; Lumosity;Lundbeck; Merck & Co., Inc.; Meso Scale Diagnostics, LLC.; NeuroRxResearch; Neurotrack Technologies; Novartis Pharmaceuticals Cor-poration; Pfizer Inc.; Piramal Imaging; Servier; Takeda Pharmaceu-tical Company; and Transition Therapeutics. The CanadianInstitutes of Health Research is providing funds to support ADNIclinical sites in Canada. Private sector contributions are facilitatedby the Foundation for the National Institutes of Health (www.fnih.org). The grantee organization is the Northern California Institutefor Research and Education, and the study is coordinated by the262J.M. Górriz et al. / Neurocomputing 410 (2020) 237–270Alzheimer’s Disease Cooperative Study at the University of Califor-nia, San Diego. ADNI data are disseminated by the Laboratory forNeuro Imaging at the University of Southern California.References[1] M. Martínez-Ibañez, A. Ortiz, J. Munilla, D. Salas-Gonzalez, J.M. Górriz, J.Ramírez,Isosurface modelling of datscan images for parkinson diseasediagnosis, in: Understanding the Brain Function and Emotions, SpringerInternational Publishing, Cham, 2019, pp. 360–368.[2] J. Wright, A. Yang, A. Ganesh, S. Sastry, Y. Ma, Robust face recognition viasparse representation, IEEE TPAMI 31 (2) (2009) 201–227.[3] M. Almagro, V. Fresno, F. de la Paz, Speech gestural interpretation by applyingword representations in robotics, Integrated Computer-Aided Engineering 26(1) (2019) 97–109.[4] F. Laport, F.J. Vazquez-Araujo, P.M. Castro, A. Dapena, Hardware and softwareforin:International Work-Conference on the Interplay Between Natural andArtificial Computation, Springer, 2019, pp. 22–31.integrating brain–computerinterface with internet ofthings,[5] O. Carugo, F. Eisenhaber, Data Mining Techniques for the Life Sciences,Methods in Molecular Biology, first ed., Humana Press, a part of SpringerScience+Business Media, 2010.[6] P. Neto, J.N. Pires, A.P. Moreira, Accelerometer-based control of an industrialrobotic arm, in: RO-MAN 2009-The 18th IEEE International Symposium onRobot and Human Interactive Communication, IEEE, 2009, pp. 1192–1197..[7] Y. Lecun, Deep learning, conference at the usi, 2015..[8] W. Liu, Z. Wang, X. Liu, N. Zeng, Y. Liu, F.E. Alsaadi, A survey of deep neuralnetwork architectures and their applications, Neurocomputing 234 (2017)11–26,http://https://doi.org/10.1016/j.neucom.2016.12.038.www.sciencedirect.com/science/article/pii/S0925231216315533.[9] S.B. Daily, MT. James, D. Cherry, J.J. Porter III, S.S. Darnell, J. Isaac, T. Roy,Affective computing: historical foundations, current applications, and futuretrends, in: Emotions and Affect in Human Factors and Human-ComputerInteraction, Elsevier, 2017, pp. 213–231..[10] R.W. Picard, Affective Computing, MIT press, 2000.[11] M. Zaharia, R. Xin, P. Wendell, T. Das, M. Armbrust, A. Dave, X. Meng, J. Rosen,S. Venkataraman, M. Franklin, A. Ghodsi, J. Gonzalez, S. Shenker, I. Stoica,Apache spark: a unified engine for big data processing, Communications ofthe ACM 59 (11) (2016) 56–65.[12] D.A. Waldman, D. Wang, V. Fenters, The added value of neuroscience methodsin organizational research, Organizational Research Methods 22 (1) (2019)223–249.[13] A.K. Triantafyllidis, A. Tsanas, Applications of machine learning in real-lifedigital health interventions: review of the literature, Journal of MedicalInternet Research 21 (4) (2019), e12286.[14] H. Plassmann, V. Venkatraman, S. Huettel, C. Yoon, Consumer neuroscience:Journal of Marketingapplications, challenges, and possible solutions,Research 52 (4) (2015) 427–435.[15] J. Blake, C. Bult, Beyond the data deluge: data integration and bioontologies,Journal of Biomedical Informatics 39 (3) (2006) 314–320.[16] F. Dosilovic, M. Brcic, N. Hlupic, Explainable artificial intelligence: a survey,in: 41stInternational Convention Proceedings, LNCS, MIPRO, SpringerInternational Publishing, 2018, pp. 210–215, https://doi.org/10.23919/MIPRO.2018.8400040.[17] B.W. Israelsen, N.R. Ahmed, I can assure you [...] that it’s going to be all right–a definition, case for, and survey of algorithmic assurances in human-autonomy trust relationships., ACM Computing Surveys, 2019, doi: 10.1145/3267338 (article no. 113)..[18] G. Marcus, Deep learning: a critical appraisal, ArXiv (2018) arXiv:abs/1801.00631..[19] M. Turek, Explainable artificialwww.darpa.mil/program/explainable-artificial-intelligence2017]..intelligence (xai), 2017, URL:https://July,[cited[20] R. Guidotti, A. Monreale, S. Ruggieri, D. Pedreschi, F. Turini, F. Giannotti, Localrule-based explanations of black box decision systems, 2018, arXiv preprintarXiv:1805.10820..[21] R.S. Sutton, A.G. Barto, Introduction to Reinforcement Learning, MIT Press,MA, Cambridge, 1998.[22] A. Gomez-Valadés, R. Martínez-Tomás, M. Rincón-Zamorano, Ontologies forearly detection of the alzheimer disease and other neurodegenerativediseases,in: From Bioinspired Systems and Biomedical Applications toMachine Learning, LNCS, vol. 11847, Springer International Publishing,2019, pp. 42–50..[23] G. Sciavicco, I. S. Eduard, A. Vaccari, Towards a general method for logical ruleextraction from time series, in: From Bioinspired Systems and BiomedicalApplications to Machine Learning, LNCS, vol. 11847, Springer InternationalPublishing, 2019, pp. 3–12..[24] R. Agrawal, T. Imielinski, A. Swami, Mining association rules between set ofitems in large databases, in: SIGMOD ’ 93: Proceedings of the 1993 ACMSIGMOD International Conference on Management of Data, 1993, pp. 207–216, https://doi.org/10.1145/170036.170072.[25] G. Bologna, Propositional rules generated at the top layers of a cnn., in: FromBioinspired Systems and Biomedical Applications to Machine Learning, LNCS,vol. 11847, Springer International Publishing, 2019, pp. 432–440..[26] D. Díaz-Vico, J. Prada, A. Omari, J. R. Dorronsoro, Deep support vectorclassification and regression, in: From Bioinspired Systems and BiomedicalApplications to Machine Learning, LNCS, vol. 11847, Springer InternationalPublishing, Cham, 2019, pp. 33–43..[27] I.A. Illan, J.M. Górriz, J. Ramirez, F.J. Martinez-Murcia, D. Castillo-Barnes, F.Segovia, D. Salas-Gonzalez, Support vector machine failure in imbalanceddatasets,in: Understanding the Brain Function and Emotions, SpringerInternational Publishing, Cham, 2019, pp. 412–419.[28] J. Mediavilla-Relaño, A. Gutierrez-López, M. Lázaro, A. R. Figueiras, Aprincipledbinaryforclassification, in: From Bioinspired Systems and Biomedical Applications toMachine Learning, LNCS, vol. 11847, Springer International Publishing, 2019,pp. 13–22..example-dependenttwo-step methodcost[29] L. Bregman, The relaxation method of finding the common point of convex setand its applications to the solution of problems in convex programing, USSRComputational Mathematics and Mathematical Physics 7 (3) (1967) 200–217.[30] A. Almonani, E. Sánchez, Uninformed methods to build optimal choice-basedensembles, in: From Bioinspired Systems and Biomedical Applications toMachine Learning, LNCS, vol. 11847, Springer International Publishing, 2019,pp. 58–65..[31] F. Fernández, Á. Sánchez, J. F. Vélez, A. B. Moreno, Symbiotic autonomoussystems with consciousness using digital twins, in: From Bioinspired Systemsand Biomedical Applications to Machine Learning, Vol. 11847 of LNCS,Springer International Publishing, 2019, pp. 23–32..[32] S. Miguel-Tomé, An experimental study on e reationships among neuralcodes and the computational properties of neural networks,in: FromBioinspired Systems and Biomedical Applications to Machine Learning,LNCS, vol. 11847, Springer International Publishing, Cham, 2019, pp. 44–57..[33] A. B. Arrieta, N. Díaz-Rodríguez, J. Del Ser, A. Bennetot, S. Tabik, A. Barbado, S.García, S. Gil-López, D. Molina, R. Benjamins, et al., Explainable artificialintelligence (XAI): Concepts,taxonomies, opportunities and challengestoward responsible AI, arXiv preprint arXiv:1910.10045. https://arxiv.org/abs/1910.10045..[34] G. Montavon, W. Samek, K.-R. Müller, Methods for interpreting andunderstanding deep neural networks, Digital Signal Processing 73 (2018)1–15.[35] D. Charte, F. Charte, S. García, M.J. del Jesus, F. Herrera, A practical tutorial onautoencoders for nonlinear feature fusion: taxonomy, models, software andguidelines, Information Fusion 44 (2018) 78–96.[36] F. Charte, A.J. Rivera, F. Martínez, M.J. del Jesus, Automating autoencoderarchitecture configuration: an evolutionary approach, in: Understanding theBrain Function and Emotions, Springer International Publishing, Cham, 2019,pp. 339–349.[37] K. Janocha, W.M. Czarnecki, On loss functions for deep neural networks inarXiv:1702.05659. https://arxiv.org/abs/preprintarXivclassification,1702.05659..[38] A.C. Bahnsen, D. Aouada, B. Ottersten, Example-dependent cost-sensitivedecision trees, Expert Systems with Applications 42 (19) (2015) 6609–6619.[39] V. López, A. Fernández, S. García, V. Palade, F. Herrera, An insight intoclassification with imbalanced data: empirical results and current trends onusing data intrinsic characteristics, Information Sciences 250 (2013) 113–141.[40] D. Charte, F. Charte, S. García, F. Herrera, A snapshot on nonstandardproblemin Artificialproblems:taxonomy,algorithm adaptations,relationships,ProgresslearningandsupervisedtransformationsIntelligence 8 (1) (2019) 1–14.[41] V.M. Vargas, P.A. Gutiérrez, C. Hervás, Deep ordinal classification based on theproportional odds model, in: International Work-Conference on the InterplayBetween Natural and Artificial Computation, Springer, 2019, pp. 441–451.[42] A. Krizhevsky, I. Sutskever, G.E. Hinton, Imagenet classification with deepInformationconvolutional neural networks,Processing Systems 25, Curran Associates Inc, 2012, pp. 1097–1105..in: Advancesin Neural[43] F. Martin-Rico, F. Gomez-Donoso, F. Escalona, M. Cazorla, J. Garcia-Rodriguez,Artificial semantic memory with autonomous learning applied to socialrobots, in: From Bioinspired Systems and Biomedical Applications to MachineLearning, Springer International Publishing, Cham, 2019, pp. 401–411.doi:10.1007/978-3-030-19651-6_39..[44] P. Duque, J.M. Cuadra, E. Jiménez, M. Rincón-Zamorano, Data preprocessingfor automatic wmh segmentation with fcnns, in: From Bioinspired Systemsand Biomedical Applications to Machine Learning, Springer InternationalPublishing, Cham, 2019, pp. 452–460, https://doi.org/10.1007/978-3-030-19651-6_44.[45] D. Charte, F. Charte, M.J. del Jesus, F. Herrera, A showcase of the use ofautoencoders in feature learning applications, in: From Bioinspired Systemsand Biomedical Applications to Machine Learning, Springer InternationalPublishing, Cham, 2019, pp. 412–421, doi: 10.1007/978-3-030-19651-6_40..[46] Y. Bengio, I. Goodfellow, A. Courville, Convolutional networks, in: DeepLearning, vol. 1, MIT Press, 2017, pp. 326–366..[47] B. Vega-Márquez, A. Carminati, N. Jurado-Campos, A. Martín-Gómez, L. Arce-Jiménez, C. Rubio-Escudero,I.A. Nepomuceno-Chamorro, Convolutionalneural networks for olive oil classification, in: From Bioinspired Systemsand Biomedical Applications to Machine Learning, Springer InternationalPublishing, Cham, 2019, pp. 137–145, https://doi.org/10.1007/978-3-030-19651-6_14.[48] V. Ruiz, Á. Sánchez, J.F. Vélez, B. Raducanu, Automatic image-based wasteclassification, in: From Bioinspired Systems and Biomedical Applications toJ.M. Górriz et al. / Neurocomputing 410 (2020) 237–270263Machine Learning, Springer International Publishing, Cham, 2019, pp. 422–431, https://doi.org/10.1007/978-3-030-19651-6_41.[49] J. Redmon, A. Farhadi, Yolov3: An incremental improvement, arXiv preprintarXiv:1804.02767. https://arxiv.org/abs/1804.02767..[50] L.-E. Imbernón Cuadrado, Á. Manjarrés Riesco, F. de la Paz López, Fer inprimary school children for affective robot tutors, in: From BioinspiredSystems and Biomedical Applications to Machine Learning, SpringerInternational Publishing, Cham, 2019, pp. 461–471. doi:10.1007/978-3-030-19651-6_45..[51] T. Fukunaga, S. Kubota, S. Oda, W. Iwasaki, Grouptracker: Video trackingsystem for multiple animals under severe occlusion, Computational Biologyand Chemistry 57 (2015) 39–45, 13th Asia Pacifi c Bioinformatics Conference,HsinChu,10.1016/j.compbiolchem.2015.02.006,URL:http://www.sciencedirect.com/science/article/pii/S1476927115000237..Taiwan,January21–232015,doi:[52] G. Hoyle, The scope of neuroethology, The Behavioral and Brain Sciences 7(367–412)..[53] J.-P. Ewert, Neuroethology: An Introduction to the NeurophysiologicalFundamentals of Behavior, Springer International Publishing, 1980.[54] D. Mobbs,J.J. Kim, Neuroethological studies of fear, anxiety, and riskydecision-making in rodents and humans, Current Opinion in BehavioralSciences 5 (2015) 8–15, neuroeconomics. doi: 10.1016/j.cobeha.2015.06.005.URL:http://www.sciencedirect.com/science/article/pii/S2352154615000832..[55] M. Brewer, Research design and issues of validity, in: H. Reis, C. e. Judd (Eds.),Handbook of Research Methods in Social and Personality Psychology,Cambridge University Press, Cambridge:, 2000..[56] M.A. Arbib, Rana computatrix to human language: towards a computationalneuroethology of language evolution, Philosophical Transactions of the RoyalSociety of London A: Mathematical, Physical and Engineering Sciences 361(1811) (2003) 2345–2379, https://doi.org/10.1098/rsta.2003.1248, arXiv:http://rsta.royalsocietypublishing.org/content/361/1811/2345.full.pdf.[57] A.C. Grant, S.G. Abdel-Baki, A. Omurtag, R. Sinert, G. Chari, S. Malhotra, J.Weedon, A.A. Fenton, S. Zehtabchi, Diagnostic accuracy of microeeg: aminiature, wireless eeg device, Epilepsy & Behavior 34 (2014) 81–85, https://doi.org/10.1016/j.yebeh.2014.03.015,URL:http://www.sciencedirect.com/science/article/pii/S1525505014000961.[58] J.W. Kam, S. Griffin, A. Shen, S. Patel, H. Hinrichs, H.-J. Heinze, L.Y. Deouell, R.T.Knight, Systematic comparison between a wireless eeg system with dryelectrodes and a wired eeg system with wet electrodes, NeuroImage 184(2019) 119–129, https://doi.org/10.1016/j.neuroimage.2018.09.012, URL:http://www.sciencedirect.com/science/article/pii/S1053811918307961.[59] W.O. Tatum, Handbook of EEG Interpretation, Demos Medical Publishing,2014.[60] D.J. Anderson, P. Perona, Toward a science of computational ethology, Neuron84 (1) (2014) 18–31.[61] J. Wang, Y. Chen, S. Hao, X. Peng, L. Hu, Deep learning for sensor-basedactivity recognition: a survey, Pattern Recognition Letters 119 (2019) 3–11.[62] M. Vrigkas, C. Nikou, I.A. Kakadiaris, A review of human activity recognitionmethods, Frontiers in Robotics and AI 2 (2015) 28.[63] E. Ratti, S. Waninger, C. Berka, G. Ruffini, A. Verma, Comparison of medicaland consumer wireless Eeg systems for use in clinical trials, Frontiers inHuman Neuroscience 11 (2017) 398.[64] J.G. Cruz-Garza, J.A. Brantley, S. Nakagome, K. Kontson, M. Megjhani, D.Robleto, J.L. Contreras-Vidal, Deployment of mobile Eeg technology in an artmuseum setting: evaluation of signal quality and usability, Frontiers inHuman Neuroscience 11 (2017) 527.[65] M. Graña, J. de Lope Asiain, A short review of some aspects of computationalneuroethology, in: International Work-Conference on the Interplay BetweenNatural and Artificial Computation, Springer, 2019, pp. 275–283.[66] R.-H.P., de Lope Asiain J., G. na M., Deep learning prediction of gait based oninertial measurements, in: Understanding the Brain Function and Emotions.IWINAC 2019, vol. 11486, Springer, 2019, pp. 275–283..[67] M. S., de Lope Asiain J., G. na M, Recognizing cognitive activities through eyetracking, in: Understanding the Brain Function and Emotions. IWINAC 2019,vol. 11486, Springer, 2019, pp. 275–283..[68] M. Pantic, L.J. Rothkrantz, Toward an affect-sensitive multimodal human-computer interaction, Proceedings of the IEEE 91 (9) (2003) 1370–1390.[69] C. Breazeal, B. Scassellati, How to build robots that make friends and influencepeople, in: Proceedings 1999 IEEE/RSJ International Conference on IntelligentRobots and Systems. Human and Environment Friendly Robots with HighIntelligence and Emotional Quotients, vol. 2, IEEE, 1999, pp. 858–863..[70] J. Marín-Morales, J.L. Higuera-Trujillo, A. Greco, J. Guixeres, C. Llinares, E.P.Scilingo, M. Alcañiz, G. Valenza, Affective computing in virtual reality:emotion recognition from brain and heartbeat dynamics using wearablesensors, Scientific Reports 8 (1) (2018) 1–15.[71] V. Vinayagamoorthy, M. Gillies, A. Steed, E. Tanguy, X. Pan, C. Loscos, M.in: EurographicsSlater, Building expression into virtual characters,Conference State of the Art Reports, 2006..[72] P. Schmidt, A. Reiss, R. Dürichen, K.V. Laerhoven, Wearable-Based AffectRecognition—A review, Sensors 19 (19) (2019) 4079.[73] A. Luneski, E. Konstantinidis, P. Bamidis, Affective medicine: a review ofaffective computing efforts in medical informatics, Methods of Information inMedicine 49 (03) (2010) 207–218.[74] R. Faria, A. Almeida, Affect recognition, in: Computational Intelligence andDecision Making. Intelligent Systems, Control nad Automation: Science andEngineering, vol. 61, Springer, 2013, pp. 355–363..[75] J.C. Castillo, Á. Castro-González, A. Fernández-Caballero, J.M. Latorre, J.M.Pastor, A. Fernández-Sotos, M.A. Salichs, Software architecture for smartthe ageing adult, Cognitiveemotion recognition and regulation ofComputation 8 (2) (2016) 357–367.[76] P. Gómez-López, F. Montero, M.T. López, Empowering Ux of Elderly Peoplewith Parkinsons´ Disease via Bci Touch, in: International Work-Conference onthe Interplay Between Natural and Artificial Computation, Springer, 2019, pp.161–170.[77] M. Á. Vicente-Querol, A. S. García, P. Fernández-Sotos, R. Rodriguez-Jimenez,A. Fernández-Caballero, Development and Validation of Basic Virtual HumanFacial Emotion Expressions,International Work-Conference on theInterplay Between Natural and Artificial Computation, Springer, 2019, pp.222–231..in:[78] J. Caicedo-Acosta, D. Cárdenas-Peña, D. Collazos-Huertas, J.I. Padilla-Buritica,G. Castaño-Duque, G. Castellanos-Dominguez, Multiple-instance lassoregularization via embedded instance selection for emotion recognition, in:International Work-Conference on the Interplay Between Natural andArtificial Computation, Springer, 2019, pp. 244–251.[79] J.-J. De Groot, E. Barakova, T. Lourens, E. van Wingerden, P. Sterkenburg,Game-based human-robot interaction promotes self-disclosure in peoplewith visual impairments and intellectual disabilities, in: Ferrández-Vicenteet al. FerrandezVicente, 2019, pp. 262–272..[80] L.M. Belmonte, R. Morales, A.S. García, E. Segura, P. Novais, A. Fernández-Caballero, Trajectory planning of a quadrotor to monitor dependent people,in: International Work-Conference on the Interplay Between Natural andArtificial Computation, Springer, 2019, pp. 212–221.[81] R. Sánchez-Reolid, A. Martínez-Rodrigo, A. Fernández-Caballero, Stressidentification from electrodermal activity by support vector machines, in:International Work-Conference on the Interplay Between Natural andArtificial Computation, Springer, 2019, pp. 202–211.[82] R. Panduro, E. Segura, L.M. Belmonte, P. Novais, J. Benet, A. Fernández-Caballero, R. Morales, Advanced trajectory generator for two carts with Rgb-Dsensor on circular rail, in: International Work-Conference on the InterplayBetween Natural and Artificial Computation, Springer, 2019, pp. 181–190.[83] N.K. Benamara, M. Val-Calvo, J.R. Álvarez-Sánchez, A. Díaz-Morcillo, J.M.F.Vicente, E. Fernández-Jover, T.B. Stambouli, Real-time emotional recognitionfor sociable robotics based on deep neural networks ensemble,in:International Work-Conference on the Interplay Between Natural andArtificial Computation, Springer, 2019, pp. 171–180.[84] M. Val-Calvo,J.R. Álvarez-Sánchez, A. Díaz-Morcillo,J.M.F. Vicente, E.Fernández-Jover, On the use of lateralization for lightweight and accuratemethodology for eeg real time emotion estimation using gaussian-processclassifier,in: International Work-Conference on the Interplay BetweenNatural and Artificial Computation, Springer, 2019, pp. 191–201.[85] D. Palacios-Alonso, C. Lázaro-Carrascosa, A. López-Arribas, G. Meléndez-Morales, A. Gómez-Rodellar, A. Loro-Álavez, V. Nieto-Lluis, V. Rodellar-Biarge,A. Tsanas, P. Gómez-Vilda, Assessing an application of spontaneous stressedspeech-emotions portal, in: International Work-Conference on the InterplayBetween Natural and Artificial Computation, Springer, 2019, pp. 149–160.[86] L. Fernández-Aguilar, A. Martínez-Rodrigo, J. Moncho-Bogani, A. Fernández-Caballero, J.M. Latorre, Emotion detection in aging adults through continuousmonitoring of electro-dermal activity and heart-rate variability,in:International Work-Conference on the Interplay Between Natural andArtificial Computation, Springer, 2019, pp. 252–261.[87] J. Sorinas, J. M. F. Vicente, E. Fernández-Jover, Brushstrokes of the emotionalbrain: cortical asymmetries for valence dimension, in: International Work-Conference on the Interplay Between Natural and Artificial Computation,Springer, 2019, pp. 232–243..[88] D. Varela, J. Santos, Crowding differential evolution for protein structurein: International Work-Conference on the Interplay Betweenprediction,Natural and Artificial Computation, Springer, 2019, pp. 193–203..[89] J. Orellana, R. Contreras, et al., Bacterial resistance algorithm. an applicationto cvrp, in: International Work-Conference on the Interplay Between Naturaland Artificial Computation, Springer, 2019, pp. 204–211.[90] S. Torres-Alegre, Y. Benchaib, J. M. F. Vicente, D. Andina, Application ofin:Koniocortex-like networksInternational Work-Conference on the Interplay Between Natural andArtificial Computation, Springer, 2019, pp. 264–273..to cardiac arrhythmiasclassification,[91] J. Machin, A. Solanas, Conceptual description of nature-inspired cognitivecities: properties and challenges, in: International Work-Conference on theInterplay Between Natural and Artificial Computation, Springer, 2019, pp.212–222.[92] F.J. Gil-Gala, R. Varela, Genetic algorithm to evolve ensembles of rules for on-line scheduling on single machine with variable capacity, in: InternationalWork-Conference on theand ArtificialComputation, Springer, 2019, pp. 223–233.Interplay Between Natural[93] Ó. Carrasco, B. Crawford, R. Soto, J. Lemus-Romani, G. Astorga, A. Salas-Fernández, Optimization of bridges reinforcements with tied-arch usingmoth search algorithm, in: International Work-Conference on the InterplayBetween Natural and Artificial Computation, Springer, 2019, pp. 244–253.[94] R. Mencía, C. Mencı’a, R. Varela, Repairing infeasibility in scheduling viain: International Work-Conference on the Interplaygenetic algorithms,Between Natural and Artificial Computation, Springer, 2019, pp. 254–263.[95] A. Shukla, H. Karki, Application of robotics in onshore oil and gas industry: areview. Part I, Robotics and Autonomous Systems 75 (2016) 490–507, https://doi.org/10.1016/j.robot.2015.09.012.264J.M. Górriz et al. / Neurocomputing 410 (2020) 237–270[96] B. Da Silva, G. Konidaris, A. Barto, Learning parameterized skills, arXivpreprint arXiv:1206.6398..[97] G. D. Konidaris, Autonomous robot skill acquisition, Ph.D. thesis, University ofhttps://Massachusetts Amherst,scholarworks.umass.edu/open_access_dissertations/384 (May 2011)..open Access Dissertations,384.[98] C. Devin, A. Gupta, T. Darrell, P. Abbeel, S. Levine, Learning modular neuralnetwork policies for multi-task and multi-robot transfer, in: 2017 IEEEInternational Conference on Robotics and Automation (ICRA), IEEE, 2017, pp.2169–2176, https://doi.org/10.1109/ICRA.2017.7989250.[99] G. Baldassarre, M. Mirolli,Intrinsically motivated learning systems: anoverview,Intrinsically MotivatedLearning in Natural and Artificial Systems, Springer, 2013, pp. 1–14, https://doi.org/10.1007/978-3-642-32375-1_1.in: G. Baldassarre, M. Mirolli (Eds.),[100] P. Langley, J.E. Laird, S. Rogers, Cognitive architectures: research issues andchallenges, Cognitive Systems Research 10 (2) (2009) 141–160.[101] M. Graña, A. Triguero, An approach to teach nao dialogue skills, in: Ferrández-Vicente et al. FerrandezVicente, 2019, pp. 301–308..[102] A. Romero, F. Bellas, J.A. Becerra, R.J. Duro, Bootstrapping autonomous skilllearning in the mdb cognitive architecture, in: Ferrández-Vicente et al.FerrandezVicente, 2019, pp. 120–129..[103] S. Orlando, F. de la Paz López, E. Gaudioso, Design and implementation of arobotics learning environment to teach physics in secondary schools, in:Ferrández-Vicente et al. FerrandezVicente, 2019, pp. 69–76..[104] J. Gines Clavero, F.J. Rodriguez, F. Martín Rico, A.M. Guerrero, V. Matellán,Using probabilistic context awareness in a deliberative planner system, in:Ferrández-Vicente et al. FerrandezVicente, 2019, pp. 157–166..[105] F. E. Casado, A. Nieto, R. Iglesias, C. V. Regueiro, S. Barro, Robust headingestimation in mobile phones, in: Ferrández-Vicente et al. FerrandezVicente,2019, pp. 180–190..[106] J. Estévez, J.M. López-Guede, Control of transitory take-off regime in thetransportation of a pendulum by a quadrotor, in: Ferrández-Vicente et al.FerrandezVicente, 2019, pp. 117–126..[107] L. Roda-Sanchez, T. Olivares, C. Garrido-Hidalgo, A. Fernández-Caballero,Gesture control wearables for human-machine interaction in industry 4.0, in:Ferrández-Vicente et al. FerrandezVicente, 2019, pp. 99–108..[108] D. Obregón, R. Arnau, M. Campo-Cossio, J.G. Arroyo-Parras, M. Pattinson, S.Tiwari, I. Lluvia, O. Rey, J. Verschoore, L. Lenza, J. Reyes, Precise positioningand heading for autonomous scouting robots in a harsh environment, in:Ferrández-Vicente et al. FerrandezVicente, 2019, pp. 82–96..[109] M. Kassawat, E. Cervera, A.P. del Pobil, Multi-robot user interface foral.tasks,Ferrández-Vicentein:etcooperativeFerrandezVicente, 2019, pp. 77–81..transportation[110] M. Kosinski, D. Stillwell, T. Graepel, Private traits and attributes arepredictable from digital records of human behavior, Proceedings of theNational Academy of Sciences of the United States of America 110 (15) (2013)5802–5805.[111] T. Murdoch, A. Detsky, The inevitable application of big data to health care,JAMA – Journal of the American Medical Association 309 (13) (2013) 1351–1352.[112] Z. Obermeyer, E. Emanuel, Predicting the future-big data, machine learning,and clinical medicine, New England Journal of Medicine 375 (13) (2016)1216–1219.[113] X.-W. Chen, X. Lin, Big data deep learning: challenges and perspectives, IEEEAccess 2 (2014) 514–525.[114] L. Zhang, L. Zhang, B. Du, Deep learning for remote sensing data: a technicaltutorial on the state of the art, IEEE Geoscience and Remote Sensing Magazine4 (2) (2016) 22–40.[115] Y. Guo, Y. Liu, A. Oerlemans, S. Lao, S. Wu, M. Lew, Deep learning for visualunderstanding: a review, Neurocomputing 187 (2016) 27–48.[116] G. Litjens, T. Kooi, B. Bejnordi, A. Setio, F. Ciompi, M. Ghafoorian, J. van derLaak, B. van Ginneken, C. Sánchez, A survey on deep learning in medicalimage analysis, Medical Image Analysis 42 (2017) 60–88.[117] P. Lakhani, B. Sundaram, Deep learning at chest radiography: automatedclassification of pulmonary tuberculosis by using convolutional neuralnetworks, Radiology 284 (2) (2017) 574–582.[118] Z. Ruiz-Chavez, J. Salvador-Meneses, C. Mejía-Astudillo, S. Diaz-Quilachamin,Analysis of dogs’s abandonment problem using georeferenced multi-agentsystems,in: From Bioinspired Systems and Biomedical Applications toMachine Learning, Springer International Publishing, Cham, 2019, pp. 297–306.[119] S. Hamreras, R. Benítez-Rochel, B. Boucheham, M.A. Molina-Cabello, E. López-Rubio, Content based image retrieval by convolutional neural networks, in:From Bioinspired Systems and Biomedical Applications to Machine Learning,Springer International Publishing, Cham, 2019, pp. 277–286.[120] K. Thurnhofer-Hemsi, E. López-Rubio, N. Roé-Vellvé, M.A. Molina-Cabello,Deep learning networks with p-norm loss layers for spatial resolutionenhancement of 3D medical images, in: From Bioinspired Systems andInternationalBiomedical ApplicationsPublishing, Cham, 2019, pp. 287–296.to Machine Learning, Springer[121] J. García-González, J.M. Ortiz-de Lazcano-Lobato, R.M. Luque-Baena, E. López-Rubio, Background modeling by shifted tilings of stacked denoisingautoencoders, in: From Bioinspired Systems and Biomedical Applications toMachine Learning, Springer International Publishing, Cham, 2019, pp. 307–316.[122] J. Benito-Picazo, E. Domínguez, E.J. Palomo, E. López-Rubio, Deep learning-based security system powered by low cost hardware and panoramiccameras,in: From Bioinspired Systems and Biomedical Applications toMachine Learning, Springer International Publishing, Cham, 2019, pp. 317–326.[123] C.R. Pereira, D.R. Pereira, F.A.d. Silva, C. Hook, S.A.T. Weber, L.A.M. Pereira, J.P.Papa, A step towards the automated diagnosis of parkinson’s disease:analyzing handwriting movements,in: 2015 IEEE 28th InternationalSymposium on Computer-Based Medical Systems, 2015, pp. 171–176, doi:10.1109/CBMS.2015.34..[124] F. Martinez-Murcia, J. Górriz, J. Ramírez, A. Ortiz, The Alzheimer’s DiseaseNeuroimaging Initiative, et al., A spherical brain mapping of MR images forthe detection of Alzheimer’s disease, Current Alzheimer Research 13 (5)(2016) 575–588.[125] A. Ortiz, F.J.M. Murcia, J. Munilla, J.M. Górriz, J. Ramírez, Label aided deepof parkinsonian syndromes,automatic diagnosisrankingNeurocomputing 330 (2019) 162–171.thefor[126] F.J. Martinez-Murcia, A. Ortiz, J.M. Górriz, J. Ramírez, F. Segovia, D. Salas-Gonzalez, D. Castillo-Barnes, I.A. Illán, A 3d convolutional neural networkapproach for the diagnosis of parkinson’s disease, in: Natural and ArtificialComputation for Biomedicine and Neuroscience, Springer InternationalPublishing, Cham, 2017, pp. 324–333.[127] F.J. Martinez-Murcia, J.M. Górriz, J. Ramírez, A. Ortiz, Convolutional neuralnetworks for neuroimaging in parkinson’s disease: Is preprocessing needed?International Journal of Neural Systems 28 (10) (2018) 1850035, exportedfrom https://app.dimensions.ai10.1142/ons0129065718500351.https://app.dimensions.ai/details/publication/pub.1105862616..2018/09/20.doi:[128] E. Finn, X. Shen, D. Scheinost, M. Rosenberg, H.Jessica, M. Chun, X.connectome fingerprinting:FunctionalPapademetris, R. Constable,Identifying individuals using patterns of brain connectivity, NatureNeuroscience 18..[129] M. Sabzekar, H. Sadoghi Yazdi, M. Naghibzadeh, Relaxed constraints supportvector machines for noisy data, Neural Computing and Applications 20 (5)(2011) 671–685.[130] T.G. Stewart, D. Zeng, M.C. Wu, Constructing support vector machines withmissing data, Wiley Interdisciplinary Reviews: Computational Statistics 10(4) (2018), e1430.[131] R. Akbani, S. Kwek, N. Japkowicz, Applying support vector machines toimbalanced datasets, in: Machine Learning: ECML 2004, Springer, BerlinHeidelberg, Berlin, Heidelberg, 2004, pp. 39–50..[132] D. Castillo-Barnes, F.J. Martinez-Murcia, F. Segovia,Illán, D. Salas-Gonzalez, J.M. Górriz, J. Ramírez, Comparison between affine and non-affine transformations applied to i[123]-fp-cit spectimages used forparkinson’s disease diagnosis, in: Understanding the Brain Function andEmotions, Springer International Publishing, Cham, 2019, pp. 379–388.[133] M. Leming, J. Suckling, Deep learning on brain images in autism: What dolarge samples reveal of its complexity?, in: Understanding the Brain Functionand Emotions, Springer International Publishing, Cham, 2019, pp 389–402.I.A.[134] K. López-de Ipiña, H. Cepeda, C. Requejo, E. Fernandez, P.M. Calvo, J.V.Lafuente, Machine learning methods for environmental-enrichment-relatedvariations in behavioral responses of laboratory rats, in: Understanding theBrain Function and Emotions, Springer International Publishing, Cham, 2019,pp. 420–427.[135] D. López-García, A. Sobrado, J.M. González-Peñalver, J.M. Górriz, M. Ruz,Multivariate pattern analysis of electroencephalography data in a demand-selection task, in: Understanding the Brain Function and Emotions, SpringerInternational Publishing, Cham, 2019, pp. 403–411.[136] F.J. Martinez-Murcia, A. Ortiz, R. Morales-Ortega, P.J. López, J.L. Luque, D.Castillo-Barnes, F. Segovia,J.M. Górriz,Periodogram connectivity of eeg signals for the detection of dyslexia, in:Understanding the Brain Function and Emotions, Springer InternationalPublishing, Cham, 2019, pp. 350–359.J. Ramirez,J. Ortega,Illan,I.A.[137] A. Ortiz, P.J. López, J.L. Luque, F.J. Martínez-Murcia, D.A. Aquino-Britez, J.Ortega, An anomaly detection approach for dyslexia diagnosis using eegsignals,in: Understanding the Brain Function and Emotions, SpringerInternational Publishing, Cham, 2019, pp. 369–378.[138] G. Kedia, L. Harris, G.-J. Lelieveld, L. Van Dillen, From the brain to the field: theapplications of social neuroscience to economics, health and law, BrainSciences 7 (8) (2017) 94.[139] M.N. Tennison, J.D. Moreno, Neuroscience, ethics, and national security: thestate of the art, PLoS Biology 10 (3)..[140] R.J. Barry, A.R. Clarke, S.J. Johnstone, C.A. Magee, J.A. Rushby, EEg differencesClinicaleyes-closedconditions,eyes-openrestingandbetweenNeurophysiology 118 (12) (2007) 2765–2773.[141] F. Laport, F.J. Vazquez-Araujo, P.M. Castro, A. Dapena, Brain-computerthings, Multidisciplinary Digital Publishinginterfaces forInstitute Proceedings 2 (18) (2018) 1179.internet of[142] L.F. Velásquez-Martínez, F. Zapata-Castaño, J.I. Padilla-Buritica, J.M.F. Vicente,G. Castellanos-Dominguez, Group differences in time-frequency relevantpatterns for user-independent bci applications,in: International Work-Conference on the Interplay Between Natural and Artificial Computation,Springer, 2019, pp. 138–145.[143] S. Ezquerro, J.A. Barios, A. Bertomeu-Motos, J. Diez, J.M. Sanchez-Aparicio, L.Donis-Barber, E. Fernández-Jover, N. Garcia-Aracil, Bihemispheric betadesynchronization during an upper-limb motor task in chronic strokein: International Work-Conference on the Interplay Betweensurvivors,Natural and Artificial Computation, Springer, 2019, pp. 371–379.J.M. Górriz et al. / Neurocomputing 410 (2020) 237–270265[144] D. Palacios-Alonso, C. Lázaro-Carrascosa, R. Mas-García, J.M.F. Vicente, A.Gómez-Rodellar, P. Gómez-Vilda, Distinguishing aging clusters and mobiledevices by hand-wrist articulation: a case of study, in: International Work-Conference on the Interplay Between Natural and Artificial Computation,Springer, 2019, pp. 11–21.[145] M. Ponticorvo, M. Schembri, O. Miglino, How to improve spatial andnumerical cognition with a game-based and technology-enhanced learningapproach,in: International Work-Conference on the Interplay BetweenNatural and Artificial Computation, Springer, 2019, pp. 32–41.[146] O. Gigliotta, M. Ponticorvo, F. Doricchi, O. Miglino, Midpoint: A tool to BuildArtificial Models of Numerical Cognition, in: International Work-Conferenceon the Interplay Between Natural and Artificial Computation, Springer, 2019,pp. 88–96..[147] F. Rotondaro, M. Ponticorvo, O. Gigliotta, M. Pinto, M. Pellegrino, S. Gazzellini,P. Dolce, O. Miglino, F. Doricchi, The Number Interval Position Effect (NipE) inthe mental bisection of numerical intervals might reflect the influence of thedecimal-number system on the Gaussian representations of numerosities: acombined developmental and computational-modeling study, Cortex 114(2019) 164–175.[148] A. Cerrato, M. Ponticorvo, O. Gigliotta, P. Bartolomeo, O. Miglino, Theassessment of visuospatial abilities with tangible interfaces and machineInternational Work-Conference on the Interplay Betweenlearning,Natural and Artificial Computation, Springer, 2019, pp. 78–87.in:[149] O. Gigliotta, M. Ponticorvo, F. Doricchi, O. Miglino, Midpoint: A tool to buildartificial models of numerical cognition, in: International Work-Conferenceon the Interplay Between Natural and Artificial Computation, Springer, 2019,pp. 88–96.[150] F.H. Zunjani, A.-M. Oltet(cid:1)eanu, Cognitive ai systems contribute to improvingcreativity modeling and measuring tools, in: International Work-Conferenceon the Interplay Between Natural and Artificial Computation, Springer, 2019,pp. 97–107.[151] M.P. Bonomini, M. Val-Calvo, A. Díaz-Morcillo, J.M.F. Vicente, E. Fernández-Jover, Autonomic modulation during a cognitive task using a wearabledevice, in: International Work-Conference on the Interplay Between Naturaland Artificial Computation, Springer, 2019, pp. 69–77.[152] E. Lang, A. Tomé, I. Keck, J. Górriz-Sáez, G. Puntonet, Brain connectivityanalysis: a short survey, Neural Computing and Applications 412512 (2012)1–21.[153] J.A. Gaxiola-Tirado, M. Rodríguez-Ugarte, E. Iáñez, M. Ortiz, D. Gutiérrez, J.M.Azorín, The effect of tdcs on eeg-based functional connectivity in gait motorInternational Work-Conference on the Interplay Betweenimagery,Natural and Artificial Computation, Springer, 2019, pp. 3–10.in:[154] M.H. Kryger, T. Roth, W.C. Dement, et al., Principles and practice of sleepmedicine, 2017..[155] A.A. Fingelkurts, A.A. Fingelkurts, C.F. Neves, Natural world physical, brainoperational, and mind phenomenal space–time, Physics of Life Reviews 7 (2)(2010) 195–249.[156] J. Hernández-Muriel, J. Mejía-Hernández, J. Echeverry-Correa, A. Orozco, D.Cárdenas-Peña, Hapan: Support tool for practicing regional anesthesia inperipheral nerves,International Work-Conference on the InterplayBetween Natural and Artificial Computation, Springer, 2019, pp. 130–137.in:[157] A. Lozano, J.S. Suárez, C. Soto-Sánchez, J. Garrigós, J.-J. Martínez, J.M.F.Vicente, E. Fernández-Jover, Neurolight alpha: interfacing computationalneural models for stimulus modulation in cortical visual neuroprostheses, in:International Work-Conference on the Interplay Between Natural andArtificial Computation, Springer, 2019, pp. 108–119.[158] J. Enderle, J. Bronzino, Introduction to Biomedical Engineering, AcademicPress, 2012.[159] E.R. Dorsey, A. Elbaz, E. Nichols, F. Abd-Allah, A. Abdelalim, J.C. Adsuar, M.G.Ansha, C. Brayne, J.-Y.J. Choi, D. Collado-Mateo, et al., Global, regional, andnational burden of Parkinson’s disease, 1990–2016: a systematic analysis forthe Global Burden of Disease Study 2016, The Lancet Neurology 17 (11)(2018) 939–953.[160] D. Mozaffarian, E.J. Benjamin, A.S. Go, D.K. Arnett, M.J. Blaha, M. Cushman, S.R. Das, S. De Ferranti, J.-P. Després, H.J. Fullerton, et al., Executive summary:heart disease and stroke statistics—2016 update: a report from the AmericanHeart Association, Circulation 133 (4) (2016) 447–454.[161] G. Gálvez-García, A. Gómez-Rodellar, D. Palacios-Alonso, G. de Arcas-Castro,P. Gómez-Vilda, Neuroacoustical stimulation of parkinson’s disease patients:a case study, in: International Work-Conference on the Interplay BetweenNatural and Artificial Computation, Springer, 2019, pp. 329–339.[162] M.M. Hoehn, M.D. Yahr, Parkinsonism: onset, progression, and mortality,Neurology 17 (5) (1967) 427, 427.[163] A. Gómez-Rodellar, D. Palacios-Alonso,J. Mekyska, A.Á.Marquina, P. Gómez-Vilda, Evaluating instability on phonation inparkinson’s disease and aging speech, in: International Work-Conferenceon the Interplay Between Natural and Artificial Computation, Springer, 2019,pp. 340–351.J.M.F. Vicente,[164] C.F. Biscay, P.D. Arini, A.I.R. Soler, M.P. Bonomini, Differentiation betweenischemic and heart rate related events using the continuous wavelettransform,in: International Work-Conference on the Interplay BetweenNatural and Artificial Computation, Springer, 2019, pp. 352–360.[165] R. Verdú-Monedero, J. Morales-Sánchez, R. Berenguer-Vidal, I. Sellés-Navarro,A. Palazón-Cabanes, Automatic measurement of isnt and cdr on retinalimages by means of a fast and efficient method based on mathematicalmorphology and active contours, in: International Work-Conference on theInterplay Between Natural and Artificial Computation, Springer, 2019, pp.361–370.[166] O. Echaniz, M. Graña, Biothings: a pipeline creation tool for par-clip sequenceanalsys, in: International Work-Conference on the Interplay Between Naturaland Artificial Computation, Springer, 2019, pp. 327–336.[167] A. Garvey, V. Lesser, A survey of research in deliberative real-time artificialintelligence, Real-Time Systems 6 (3) (1994) 317–347.[168] D.J. Musliner, E.H. Durfee, K.G. Shin, Circa: a cooperative intelligent real-timecontrol architecture, IEEE Transactions on Systems, Man, and Cybernetics 23(6) (1993) 1561–1574.[169] A.J. Garvey, V.R.Lesser, Design-to-time real-time scheduling,IEEETransactions on systems, Man, and Cybernetics 23 (6) (1993) 1491–1502.[170] S. Zilberstein, Operational rationality through compilation of anytimealgorithms, AI Magazine 16 (2) (1995) 79, 79.[171] J.A. Stankovic, The many faces of multi-level real-time scheduling,in:Proceedings Second International Workshop on Real-Time ComputingSystems and Applications, IEEE, 1995, pp. 2–5.[172] A. Solin, S. Cortes, E. Rahtu, J. Kannala, Inertial odometry on handheldsmartphones, in: 2018 21st International Conference on Information Fusion(FUSION), IEEE, 2018, pp. 1–5.[173] H. Yan, Q. Shan, Y. Furukawa, Ridi: Robust imu double integration, in:Proceedings of the European Conference on Computer Vision (ECCV), 2018,pp. 621–636.[174] J. Callmer, D. Törnqvist, F. Gustafsson, Robust heading estimation indoorsthe 16th Internationalusing convex optimization,Conference on Information Fusion, IEEE, 2013, pp. 1173–1179.in: Proceedings of[175] Z.-A. Deng, Y. Hu, J. Yu, Z. Na, Extended kalman filter for real time indoorlocalization by fusing wifi and smartphone inertial sensors, Micromachines 6(4) (2015) 523–543.[176] V. Renaudin, M. Susi, G. Lachapelle, Step length estimation using handheldinertial sensors, Sensors 12 (7) (2012) 8507–8525.[177] J. Fernandez-Conde, P. Cuenca-Jimenez, R. Toledo Moreo,Improvingscheduling performance of a real-time system by incorporation of anin: Proceedings of the 8th InternationalartificialWork-Conference on the Interplay Between Naturaland ArtificialComputation, Springer, 2019, pp. 127–136.intelligence planner,[178] J. Fernandez, K. Ramamritham, Adaptive dissemination of data in time-critical asymmetric communication environments, Mobile Networks andApplications 9 (5) (2004) 491–505.[179] J. Fernandez-Conde, D. Mozos, Pull vs. hybrid: comparing schedulingalgorithms for asymmetric time-constrained environments, in: ICWN, 2008,pp. 222–228.[180] S.O. Madgwick, A.J. Harrison, R. Vaidyanathan, Estimation of imu and margorientation using a gradient descent algorithm, in: 2011 IEEE InternationalConference on Rehabilitation Robotics, IEEE, 2011, pp. 1–7..[181] D. Zhou, M. Shi, F. Chao, C.-M. Lin, L. Yang, C. Shang, C. Zhou, Use of humangestures for controlling a mobile robot via adaptive cmac network and fuzzylogic controller, Neurocomputing 282 (2018) 218–231.[182] N. Mendes, J. Ferrer, J. Vitorino, M. Safeea, P. Neto, Human behavior and handinteraction, Procediasmart human-robotgestureManufacturing 11 (2017) 91–98.classification for[183] D.-T. Lin, D.-C. Pan, Integrating a mixed-feature model and multiclass supportvector machine for facial expression recognition, Integrated Computer-AidedEngineering 16 (1) (2009) 61–74.[184] M. Eppe, S. Trott, J. Feldman, Exploiting deep semantics and compositionalityof naturalin: 2016 IEEE/RSJInternational Conference on Intelligent Robots and Systems (IROS), IEEE,2016, pp. 731–738.language for human-robot-interaction,[185] M. Martell, M. Castilla, F. Rodriguez, M. Berenguel, An indoor illuminanceprediction model based on neural networks for visual confort and energyefficiency optimization purposes, in: Proceedings of the 8th InternationalWork-Conference on the Interplay Between Naturaland ArtificialComputation, Springer, 2019, pp. 146–157..[186] M. Sanchez-Marre, K. Gibert, B. Sevilla-Villaneva, Combining data-driven anddomain knowledge components in an intelligent assistantto buildthe 8th International Work-in: Proceedings ofpersonalized menus,Conference on the Interplay Between Natural and Artificial Computation,Springer, 2019, pp. 167–180.[187] I. Aguiló, et al., Generating complete menus from nutritional prescriptions byusing advanced cbr and real food databases, in: Recent Advances in ArtificialIntelligence Research and Development: Proceedings ofthe 20ththe Catalan Association for ArtificialInternational ConferenceIntelligence, Deltebre, Terres de L’Ebre, Spain, October 25–27, 2017, vol.300, IOS Press, 2017, p. 166..of[188] R.L. De Mantaras, D. McSherry, D. Bridge, D. Leake, B. Smyth, S. Craw, B.Faltings, M.L. Maher, M.T. Cox, K. Forbus, et al., Retrieval, reuse, revision andretention in case-based reasoning, The Knowledge Engineering Review 20 (3)(2005) 215–240.[189] D.B. Haytowitz, Information from usda’s nutrient data bank, The Journal ofNutrition 125 (7) (1995) 1952–1955.[190] P. Urzúa, K. Sáez, M.S. Echeverria, Disponibilidad léxica matemática: análisiscuantitativo y cualitativo, Revista de lingüística teórica y aplicada 44 (2)(2006) 59–76.[191] P. Salcedo, R. Contreras, et al., Computing the missing lexicon in studentsusing bayesian networks, in: International Work-Conference on the InterplayBetween Natural and Artificial Computation, Springer, 2019, pp. 109–116.266J.M. Górriz et al. / Neurocomputing 410 (2020) 237–270[192] S. Blum, S. Debener, R. Emkes, N. Volkening, S. Fudickar, M. G. Bleichner, EEgrecording and online signal processing on android: A multiapp framework forbrain-computer interfaces on smartphone, BioMed Research International..[193] A.S. Oliveira, B.R. Schlink, W.D. Hairston, P. König, D.P. Ferris, Restricted visionincreases sensorimotor cortex involvement in human walking, Journal ofNeurophysiology 118 (4) (2017) 1943–1951.[194] J.E. Scanlon, K.A. Townsend, D.L. Cormier, J.W. Kuziek, K.E. Mathewson,Taking off the training wheels: measuring auditory P3 during outdoor cyclingusing an active wet Eeg system, Brain Research 1716 (2019) 50–61.[195] J. Wagner, R. Martínez-Cancino, S. Makeig, Trial-by-trial source-resolved Eegresponses to gait task challenges predict subsequent step adaptation,Neuroimage 199 (2019) 691–703.[196] P. Tzirakis, S. Zafeiriou, B. Schuller, Real-world automatic continuous affectrecognition from audiovisual signals, in: Multimodal Behavior Analysis in theWild, Elsevier, 2019, pp. 387–406..[197] D. Molina, J. Poyatos, J. D. Ser, S. García, A. Hussain, F. Herrera, Comprehensivetaxonomies of nature- and bio-inspired optimization: Inspiration versusalgorithmic behavior, critical analysis and recommendations, ArXiv abs/2002.08136..[198] J. Carrasco, S. García, M. Rueda, S. Das, F. Herrera, Recent trends in the use ofcomparing swarm and evolutionary computingreview, Swarm andstatisticalalgorithms: practical guidelines and a criticalEvolutionary Computation 54 (2020), 100665.testsfor[199] J.D. Ser, E. Osaba, D. Molina, X.-S. Yang, S. Salcedo-Sanz, D. Camacho, S. Das, P.N. Suganthan, C.A.C. Coello, F. Herrera, Bio-inspired computation: where westand and what’s next, Swarm and Evolutionary Computation 48 (2019) 220–250..[200] S. Ramírez-Gallego, A. Fernández, S. García, M. Chen, F. Herrera, Big data:Tutorial and guidelines on information and process fusion for analyticsalgorithms with mapreduce, Information Fusion 42 (2018) 51–61.[201] J.M. Ferrández-Vicente, J.R. Álvarez-Sánchez, F. de la Paz-López, J. Toledo-Moreo, H. Adeli (Eds.), Understanding the Brain Function and Emotions,Lecture Notes in Computer Science, IWINAC 2019, vol. 11486, Springer,Cham, 2019.[202] J.M. Ferrández-Vicente, J.R. Álvarez-Sánchez, F. de la Paz-López, J. Toledo-Moreo, H. Adeli(Eds.), From Bioinspired Systems and BiomedicalApplications to Machine Learning, Lecture Notes in Computer Science,IWINAC 2019, vol. 11487, Springer, Cham, 2019.J.M. Górriz received the B.Sc. degree in physics, the B.Sc.degree in electronic engineering from the University ofGranada, Spain, in 2000 and 2001, respectively, the Ph.D. degree from the University of Cádiz, Spain, in 2003,and the Ph.D. degree from the University of Granada in2006. He is currently a Full Professor with the Depart-ment of Signal Theory, Networking and Communica-tions, University of Granada and Visiting Professor atthe University of Cambridge, UK. He has co-authoredover 400 technical journals and conference papers inthese areas. His current interests include statisticalsignal processing and its application to biosignal andmedical image processing. He received the National Academy of Engineering Medalin 2015. He has served as an Editor for several journals and books.J. Ramírez received the M.A.Sc. degree in electronicengineering and the Ph.D. degree in electronic engi-neering from the University of Granada in 1998 and2001, respectively. He is currently a Full Professor withthe Department of Signal Theory, Networking andCommunications, University of Granada, Spain. He hasauthored over 130 manuscripts in international journalsand 200 papers in international conferences. Hisresearch interest includes signal processing, machinelearning, and biomedical applications, including brainimage analysis. He has co-edited several special issuesin the Current Alzheimer Research, the Frontiers inComputational Neuroscience, the Journal of Alzheimer’s Disease and Frontiers inAging Neuroscience. He has served as Reviewer for several international journalsand conferences and as a member of the Technical Committee of a number ofinternational conference in his field of research.Andrés Ortiz received the B.Sc. degree in Physics(1998), the M.Sc. degree in electronics (2000) and thePh.D. degree in Computer Science in 2008 all from theUniversity of Granada. He then earned the Ph.D. degreefrom the University of Cádiz, Spain (2012). From 2000 to2005 he was working as Networks and Systems Engi-neer with Telefónica, Madrid, Spain, where his workareas were high performance computing and networkperformance analysis. Currently he is an Associate Pro-fessor at the Department of Communication Engineer-ing of the University of Malaga. His research interestsinclude intelligence systems, statistical signal process-ing with biomedical applications and high performance computing. He has coau-thored more than 120 technical journal and conference papers and leaded differentresearch projects in these areas. He currently leads the ‘‘Biomedical signal pro-cessing, computational intelligence and communications security” (BioSiP) group atthe University of Málaga, and co-directs the CINEMA Computacional NeuroscicenceLaboratory. He has served as editor and reviewer for several international journalsand conferences.F.J. Martinez-Murcia received the Engineering degreein telecommunications engineering in 2010, the M.Sc.degree in computer and network engineering in 2011,and the Ph.D. degree from the University of Granada in2017. He has co-authored papers in high-impact jour-nals. He is currently a Post-Doctoral Fellow with theUniversity of Granada. His research interests include instatistical neuroimage processing and its application toneurology and psychiatry and in data visualization andcommunication.Fermín Segovia received the B.Sc. degree in ComputerScience and the Master degree in Computer Engineeringand Networks from the University of Granada (Spain) in2006 and 2009 respectively. In 2011, he obtained thePhD. degree from the same University. From 2012 to2014, he developed his research activity at the Cyclo-tron Research Centre (University of Liége, Belgium) andworked on the applications of multiple kernel learningapproaches to neuroimaging data. Since 2015 he isbased at the Department of Signal Theory, Telematicsand Communications (University of Granada, Spain). Hismain research interests include neuroimage processingand biomedical applications.J. Suckling has over 250 peer-reviewed articles inmedical image processing and psychiatric neuroimag-ing, including large-scale multicentre studies of autismspectrum condition, psychosis, drug addiction, andaffective disorders. He has been involved in imagingresearch for over 25 years,initially with PositronEmission Tomography in the monitoring of tumorsduring chemotherapy, and in the implementation ofimage reconstruction techniques for over scannergeometries. His current interests include the neurobio-logical and neurodevelopmental bases for child andadolescent psychiatry with specific involvement of newneuroimaging techniques as primary outcome variables for studies of braindevelopment and maturation, characterization of psychopathologies, and for clin-ical trials of investigational medical products.J.M. Górriz et al. / Neurocomputing 410 (2020) 237–270267Matt Leming received his B.S. and M.S. degrees inComputer Science from the University of North Carolinaat Chapel Hill in 2016. He is currently a PhD student atCambridge University, supported by a Gates Scholar-ship. His research focuses on the application of deeplearning models to study whole-brain MRI classifica-tion.Prof. Yu-Dong Zhang received his BE in 2004, andMPhil in 2007, from Nanjing University of Aeronauticsand Astronautics. He received the PhD degree fromSoutheast University in 2010. He worked as a postdocfrom 2010 to 2012 with Columbia University, USA; andas an assistant research scientist from 2012 to 2013with Research Foundation of Mental Hygiene (RFMH),USA. He served as a full professor from 2013 to 2017with Nanjing Normal University. Now he serves asProfessor with Department of Informatics, University ofLeicester, UK. Prof. Zhang is the fellow of IET (FIET). Hewas included in ‘‘Most Cited Chinese researchers(Computer Science)” by Elsevier from 2014 to 2018. He was the 2019 recipient of‘‘Highly Cited Researcher” by Web of Science. He has conducted many successfulindustrial projects and academic grants from NSFC, NIH, Royal Society, EPSRC, MRC,and British Council.José Ramón Álvarez-Sánchez received his B.Sc. and M.Sc. degrees in Physics from Univ. Complutense deMadrid, Spain, in 1988, and his Ph.D. degree in Physicsfrom Univ. Nacional de Educación a Distancia, Madrid,Spain, in 1997. He is currently an associate professor atthe Artificial Intelligence Department of Univ. Nacionalde Educación a Distancia, Spain. His main researchinterests include artificial neural networks and mobilerobotics.Guido Bologna is Senior Lecturer at the University ofApplied Science of Geneva, Switzerland. He received aPh.D. from the University of Geneva in 1998, with theArtificial Intelligence group. Subsequently, he worked asa Postdoc at the Queensland University of Technology,Brisbane; at the National University of Singapore and atthe Swiss Institute of Bioinformatics. He has authored orco-authored about 100 full papers in refereed journals,books and conferences. His current research interests,concern transparent machine learning models.María Paula Bonomini received a M.S. degree in Bio-engineering from the National University of Entre Ríos,Argentina. In 2010, she obtained the PhD degree inBioengineering from the University Miguel Hernandezof Elche, Spain. Since 2013, she has been a ResearchScientist of the National Councilfor Scientific andTechnical Research (CONICET) and carries out her workin the Argentine Institute of Mathematics ‘‘Alberto P.Calderón”. She is also Assistant Professor of Signals andImages in Biomedicine at the Engineering Faculty fromthe Buenos Aires University (UBA). Her research inter-ests involve biomedical signal processing.Fernando E. Casado received his B.S. degree in Com-puter Engineering from the University of Santiago deCompostela (2017), and his M.S. degree in ArtificialIntelligence Research from Menéndez Pelayo Interna-tional University (2018). He is currently a Ph.D. studentat CiTIUS (Research Center for Intelligent Technologies),University of Santiago de Compostela. His researchinterests are focused on the field of machine learning.Specifically, he works on the development of real-time,federated, and continual learning strategies applicableto societies of devices.David Charte received his B.Sc degrees in Mathematicsand Computer Science (2017), and M.Sc. degree in DataScience and Computer Engineering (2018) from theUniversity of Granada (Spain). He is currently a PhDstudent with the Department of Computer Science andArtificialIntelligence at this same university. He iscoauthor of 5 JCR papers and several pieces of softwarefor Data Science. His research interests include deepfeature learning techniques and their applications,model interpretability and fairness.Francisco Charte. T. Eng. Computer Science (2008) andB. Eng. Computer Science (2010) from the Universidadde Jaén, with Extraordinary Award in both degrees and1st National Award for Excellence in Academic Perfor-mance from the MECD (2010). M.Sc. Soft Computing andComputational Intelligence (2011) and PhD from theUniversidad de Granada (2015). He is currently anAssistant Professor with the Computer Science Dept.,Universidad de Jaén, Spain. He is the author of morethan 120 books, including the title ‘‘Multilabel Classifi-cation. Problem analysis, metrics and techniques” pub-lished by Springer, as well as author of more than 20 JCRresearch papers and 25 contributions to international conferences. His mainresearch interests include multilabel learning, imbalanced and high-dimensionalityproblems and representation learning through deep learning techniques.Ricardo Contreras is an associate professor in theDepartment of Computer Science at the University ofConcepción. His research focuses on artificial intelli-gence and evolutionary computation. His currentresearch interests include bio-inspired system for solv-ing optimization problems. Contreras received an MScin computer science from Pontifical Catholic University,Rio de Janeiro, Brazil.Alfredo Cuesta-Infante is currently Visiting Professorat Univ. Rey Juan Carlos in the Department ComputerScience, and member of the High-Performance Compu-tation and Optimization research group in that Univ. Hereceived his M.Sc. degree in Physics (Univ. Complutensede Madrid, UCM) and his Ph.D. in Computer Science(Univ. Nacional de Educación a Distancia, UNED). He hasbeen visiting faculty at Univ. of New Mexico (UNM) andat Massachusetts Institute of Technology (MIT). Hisresearch interests include Machine Learning, ComputerVision and Copula theory.268J.M. Górriz et al. / Neurocomputing 410 (2020) 237–270Richard J. Duro received a M.S. degree in Physics fromthe University of Santiago de Compostela, Spain,in1989, and a PhD in Physics from the same University in1992. He is currently a Full Professor in the Departmentof Computer Science and head of the Integrated Groupfor Engineering Research at the University of A Coruña.His research interests include higher order neural net-work structures, signal processing and autonomous andevolutionary robotics.Antonio Fernández-Caballero received his M.Sc.inComputer Science from Universidad Politécnica deMadrid, Spain, in 1993, and his Ph.D. from the Depart-ment of Artificial Intelligence at Universidad Nacionalde Educación a Distancia, Spain, in 2001. He is FullProfessor in the Department of Computer Science atUniversidad de Castilla-La Mancha. He is head of then&aIS (natural and artificialInteraction Systems)research group belonging to the Albacete ResearchInstitute of Informatics. His research interests are inImage Processing, Cognitive Vision, Mobile Robotics,Affective Computing and Intelligent Agents. AntonioFernández-Caballero is Associate Editor of Pattern Recognition Letters, Topic Editor-in-Chief for Vision Systems of International Journal of Advanced Robotic Systems,and Specialty Chief Editor for Robot and Machine Vision of Frontiers in Robotics andAI, among other editorship tasks. He has authored more than 370 peer-reviewedpapers.E. Fernandez received a M.D. degree from the Univer-sity of Alicante (1986) and a Ph.D. in Neuroscience in1990. He has been visiting professor at the University ofUtah (USA), Oldenburg (Germany), Beth Israel andHarvard Medical School (USA) and University of Vienna(Austria) and is currently Full Professor of CellularBiology, Director of the Research Chair in Retinitis Pig-mentosa Bidons Egara, Director of the Neural Engi-neering Division of the Bioengineering Institute of theUniversity Miguel Hernández and CIBER BBN (Spain)and Adjunct Professor at the John Moran Eye Center.University of Utah (USA). He is a qualified MD whocombines biomedicine (molecular and cellular biology, biochemistry, anatomy,physiology and regenerative medicine) with the physical sciences (mathematics,physics and applied chemistry) and engineering to develop new treatments anddevices that can be applied to enhance the life of people that are affected by visualimpairments more effectively. He is also trying to better understand brain plasticityin blind subjects and working on the development of new therapeutic approachesfor retinal degenerative diseases.(MSc.Dr. Gómez Vilda was born at Burgo de Osma (Soria),Spain. He received the degrees of CommunicationsEngineerlevel), Universidad Politécnica deMadrid (1978), and Ph.D. in Computer Science, Univer-sidad Politécnica de Madrid (1983). His professional andacademic activities can be summarized as 1976–77:Scholarship from Nuclear Studies Center, NuclearEnergy Board, Spain; 1977–78: I+D Engineer, NORTRONElectronics; 1978–82: Assistant Teacher; 1982–88, and1988–till now: Full Professor, Facultad de Informática,Universidad Politécnica de Madrid. His research linesare: Signal Processing, Speech Recognition, Biome-chanical System Modeling, Bioengineering, Bioinformatics, Pattern Recognition,Neural Networks, Speech Perception and Production, Neuromorphic Brain Model-ing, Forensic Sciences, and Neurological Disease Monitoring. Prof. Gómez-Vilda isauthor or co-author of 340 publications, including book chapters and journal arti-cles with international referencing in ISBN and/or ISSN, and 120 conferences andlectures in different institutions and scenarios. Among other merits he was Ful-bright Scholar (1981–82), and is member of IEEE, Life Sciences Systems andApplications Technical Committee, International Speech Communication Associa-tion (ISCA), and European Association of Signal Processing (EURASIP). He is alsoscientific reviewer of IEEE Transactions on Circuits and Sistems, Neural Networks,Speech and Audio and Signal Processing, Speech Communication, the Journal of theAcoustical Society of America, Neurocomputing, Cognitive Computation, Computersin Medicine and Biology, Biomedical Signal Processing and Control, Electronic Let-ters, and Signal Processing Letters.Manuel Graña Romay received the M.Sc. and Ph.D.degrees in Computer Science from Universidad del PaisVasco (UPV/EHU), Donostia, Spain, in 1982 and 1989,respectively. His current position is a Full Professor(Catedrático de Universidad) with the Computer Scienceand Artificial Intelligence Department of the Universi-dad del Pais Vasco (UPV/EHU) since 1998, where heacted as head of department in the period 2005–2007.He is the head of the Computational Intelligence Group(Grupo de Inteligencia Computational), which has beenrecognized as excellent research group by the BasqueGovernment with continuous specific funding since2005, last grant for the period 2019–2021. The research group has carried out over30 national funded research projects, three European Commission funded projects,and some private company research contracts. The research works in the groupspread over a great variety of topics, including applications of artificial intelligenceand computational intelligence to linked multicomponent robotic systems, rein-forcement learning, medical image in the neurosciences, multimodal human com-puter interaction, remote sensing image processing, content based image retrieval,lattice computing, semantic modeling, data processing, classification, and datamining. He has been advisor for over 35 PhD Thesis, editor of more than 20 books ofproceedings and collections of works on monographic topics, editor of more than 15special issues in journals, and co-author of more than 200 journal papers (ISIindexed journals). He is associated editor of Neurocomputing, Information Fusion,Computational Intelligence and Neurosciences, Frontiers in Big Data, Journal ofMathematical Imaging and Vision.Francisco Herrera (SM’15) received his M.Sc. in Math-ematics in 1988 and Ph.D. in Mathematics in 1991, bothfrom the University of Granada, Spain. He is a Professorin the Department of Computer Science and ArtificialIntelligence at the University of Granada and Director ofthe Andalusian Research Institute in Data Science andComputational Intelligence (DaSCI). He’s an academi-cian in the Royal Academy of Engineering (Spain). Hehas been the supervisor of 50 Ph.D. students. He haspublished more than 500 journal papers, receiving morethan 82,000 citations (Scholar Google, H-index 140). Hehas been selected as a Highly Cited Researcher (in thefields of Computer Science and Engineering, respectively, 2014 to present, ClarivateAnalytics). He currently acts as Editor in Chief of the international journal ‘‘Infor-mation Fusion” (Elsevier). He acts as editorial member of a dozen of journals. Hereceived the several honors and awards, among others: ECCAI Fellow 2009, IFSAFellow 2013, 2010 Spanish National Award on Computer Science ARITMEL to the‘‘Spanish Engineer on Computer Science”, International Cajastur ‘‘Mamdani” Prizefor Soft Computing (Fourth Edition, 2010), IEEE Transactions on Fuzzy SystemOutstanding 2008 and 2012 Paper, 2011 Lotfi A. Zadeh Prize Best paper Award (IFSAAssociation), 2013 AEPIA Award to a scientific career in Artificial Intelligence, 2014XV Andalucía Research Prize Maimónides, 2017 Andalucía Medal (by the regionalgovernment of Andalucía), 2018 ‘‘Granada: Science and Innovation City” award. Hiscurrent research interests include among others, Computational Intelligence (in-cluding fuzzy modeling, computing with words, evolutionary algorithms and deeplearning), information fusion and decision making, and data science (including datapreprocessing, prediction, singular problems, and big data).Roberto Iglesias received the B.S. and Ph.D. degrees inPhysics from the University of Santiago de Compostela,Spain, in 1996 and 2003, respectively. He is currently anAssociated Professor in the Department of Electronicsand Computer Science at the University of Santiago deCompostela, Spain. He is a researcher at the ResearchCentre on Intelligent Technologies, and coordinator ofthe Robotics degree, both at the University of Santiagode Compostela. His research interests focus on controland navigation in mobile robotics, continual learningand adaptation applied to mobile robots and intelligentdevices.J.M. Górriz et al. / Neurocomputing 410 (2020) 237–270269Anna Lekova has received M.Sc. and Ph.D. degrees fromthe Technical University, Sofia, Bulgaria in 1989 andin Computer Science. As the1995, respectively, allacademic record, she was awarded PhD in the field ofComputing in CAD/CAM systemsfrom TechnicalUniversity – Sofia. She is currently a Professor in theInstitute of Robotics, Bulgarian Academy of Sciences(BAS) and a Head of ‘‘Interactive Robotics and ControlSystems” Department. She has (co)authored more than90 scientific research articles in indexed journals, ref-ereed conferences and books. Her research interestsBrain-Robotics,includeComputer Interfaces (BCI), Neuroscience computing by Fuzzy Logic, EvolvingClustering and Internet-of-Things (IoT).InteractiveEEG-basedJavier de Lope (SM’94, M’98) received the MSc inComputer Science from the Universidad Politécnica deMadrid in 1994 and the PhD degree at the same uni-versity in 1998. Currently, he is Associate Professor inthe Department of Artificial Intelligence at the Univer-sidad Politécnica de Madrid and senior researcher in theComputational Cognitive Robotics Group. His currentresearch interest is centered on the discipline of Com-putational Neuroethology where he is proposing novelmethods and tools to estimate the physical and cogni-tive activities in human beings by using several types ofsensors like RGB-D cameras and EEG devices. In the pasthe has lead of R&D projects for developing industrial robotics mechanisms whichfollow the guidelines of multi-robot systems and reconfigurable robotics, and healso worked on projects related to the autonomous coordination and languageemergence in robot teams, the computer-aided automatic driving by means ofexternal cameras and range sensors and the design and control of humanoid robotsand unmanned flying vehicles.Ezequiel López-Rubio (born 1976) received his MScand PhD (honors) degrees in Computer Engineeringfrom the University of Málaga, Spain, in 1999 and 2002,respectively. He joined the Department of ComputerLanguages and Computer Science, University of Málaga,in 2000, where he is currently a Full Professor of Com-puter Science and Artificial Intelligence. His technicalinterests are in deep learning, pattern recognition,image processing and computer vision.Rafael Martínez-Tomás received her degree in Physicsfrom the University of Valencia, Spain, in 1983, andreceived her Ph.D. from the Department of ArtificialIntelligence of the National University for DistanceEducation, Spain, in 2000. He is currently Full Professorwith the Department of Artificial Intelligence of theNational University for Distance Education, Spain. Hisresearch interests are in knowledge engineering,semantic web and semantic technologies, and semanticrecognition of human behavior, publishing researchpapers related to these areas in various internationaljournals and in major international conferences.Miguel A. Molina-Cabello received his MSc and PhDdegrees in Computer Engineering from the University ofMalaga, Spain,in 2015 and 2018. He joined theDepartment of Computer Languages and ComputerScience, University of Malaga, in 2015, where he has ateaching and researching position. He also keeps pur-suing research activities in collaboration with otherUniversities. His technicalinterests are in visualsurveillance, image/video processing, computer vision,neural networks and pattern recognition.Dr. Antonio S. Montemayor received his MS degree inApplied Physics at Universidad Autónoma de Madrid in1999 and Ph.D. at Universidad Rey Juan Carlos in 2006.He is currently Associate Professor at Universidad ReyJuan Carlos and principalinvestigator of the CAPOresearch group at URJC. His research interests includesoft computing, computer vision, GPU computing, deeplearning,image and video processing and real-timeimplementations.Paulo Novais is Full Professor of Computer Science atthe Department of Informatics, in the School of Engi-neering of the Universidade do Minho (Portugal) and aresearcher at the ALGORITMI Centre, where he is theLeader of the research group ISlab – Synthetic Intelli-gence lab –, and the coordinator of the research line inComputer Science and Technology (CST). His mainresearch aim is to make systems a little more smart,intelligent and also reliable. He is the co-author of over350 book chapters,journal papers, conference andworkshop papers and books. He is the president ofAPPIA (the Portuguese Association for Artificial Intelli-gence) since 2016; Senior member of the IEEE (Institute of Electrical and ElectronicsEngineers); Member of the IFIP (International Federation for Information Process-ing) – TC 12 Artificial Intelligence.Daniel Palacios-Alonso was born in Madrid, Spain. Hereceived the B.S. and M.S. degrees in Computer Sciencefrom Universidad Politécnica de Madrid (UPM), in 2009and the Ph.D. degree in Advanced Computation from thesame University, in 2017. He worked as a Team Leaderin a technological consulting firm for 5 years. Since2013, he is a member of the Neuromorphic SpeechProcessing Laboratory at the Center for BiomedicalTechnology. Nowadays, he works as an assistant pro-fessor at Universidad Rey Juan Carlos (URJC). Moreover,he is currently the Head of the Bioinspired Systems andApplications Group (SA-BIO). His research interestsinclude the stress and emotional states, neurodegenerative diseases such asParkinson, ALS, Alzheimer’s, among others, artificial vision, pattern recognition, andbiomedical signal processing. He is a reviewer of national and international jour-nals.Juan J. Pantrigo is currently an associate professor atUniversidad Rey Juan Carlos and member of CAPOresearch group in the Department of Computer Science.He received his M.Sc. degree in fundamental physicsfrom Universidad de Extremadura in 1998 and his Ph.D.from Universidad Rey Juan Carlos in 2005. His researchinterests include high-dimensional space-state trackingproblems, computer vision, heuristic optimization,machine learning and hybrid approaches.Dr. Bryson Payne is a nationally-recognized cybercoach, best-selling author, TEDx speaker, and thefounding Director of the Center for Cyber OperationsEducation at the University of North Georgia, an NSA-DHS Center for Academic Excellence in Cyber Defense.270J.M. Górriz et al. / Neurocomputing 410 (2020) 237–270Dr Athanasios Tsanas (‘Thanasis’), BSc, BEng, MSc,DPhil (Oxon), SMIEEE, FHEA, FRSM. Thanasis studiedEngineering for his undergraduate and MSc degrees andcompleted a PhD in Applied Mathematics attheUniversity of Oxford (2012). He continued working atthe University of Oxford as a Research Fellow inBiomedical Engineering and Applied Mathematics(2012–2016), Stipendiary Lecturer in Engineering Sci-ence (2014–2016), and Lecturer in Statistical ResearchMethods (2016–2019). He joined the Usher Institute,Edinburgh Medical School, University of Edinburgh inJanuary 2017 as a tenure-track Assistant/Associate Prof.in Data Science (tenured a year early, in December 2019). He received the AndrewGoudie award (top PhD student across all disciplines, St. Cross College, University ofOxford, 2011), the EPSRC Doctoral Prize award (2012) as one of only 8 Oxford PhDstudents across 11 departments, the young scientist award (MAVEBA, 2013), theEPSRC Statistics and Machine Learning award (2015), and won a ‘Best revieweraward’ from the IEEE Journal of Biomedical Health Informatics (2015). He leads thedevelopment and delivery of the ‘Clinical Decision Support and Actionable DataAnalytics’ theme in the NHS Digital Academy, a £6m innovative leadership pro-gramme jointly delivered with Imperial College annually training approximately100 NHS established and aspiring CIOs and CCIOs. He sits on the Editorial Boards ofJMIR Mental Health and JMIR mHealth and uHealth. He is a Senior Member of IEEE,a Fellow of the Higher Education Academy, and a Fellow of the Royal Society ofMedicine.Ramiro Varela received a M.S. degree in Physics fromthe University of Santiago de Compostela, Spain, in1984, and a PhD in Computer Science from theUniversity of Oviedo, Spain, in 1995. He is Professor ofComputer Science and Artificial Intelligence with theDepartment of Computer Science of the University ofOviedo and member of the intelligent Scheduling andOptimization (iScOp)research team. His researchinterests include Metaheuristics, Combinatorial Opti-mization and Scheduling problems.José Manuel Ferrández Vicente was born in Elche,Spain. He received the M.Sc. degree in Computer Sciencein 1995, and the Ph.D. in Computer Science in 1998, allof them from the Universidad Politécnica de Madrid,Spain. He is currently Full Professor at the Departmentof Electronics, Computer Technology and Projects at theUniversidad Politécnica de Cartagena and Head of theElectronic Design and Signal Processing Research Groupat the same University. Nowadays he is Vicepresidentfor Internationalization, Research, and Innovation, andGeneral Chairman at the International Workconferenceon the Interplay between Natural and Artificial Com-putation (IWINAC). His research interests include bioinspired processing, neuro-morphic engineering and emotional technologies.F. de la Paz received the B-Sc. degree in Physics fromthe Universidad Complutense de Madrid, Spain, in 1995and the PhD degree from Universidad Nacional deEducación a Distancia (UNED), Spain in 2003. He iscurrently Associate Profesor with the Department ofArtificial Intelligence of Universidad Nacional de Edu-cación a Distancia (UNED). He as co-authored severaltechnical papers and conference papers in Robotics.Also, he is co-organizer of the biennial IWINAC meetingsand editor of these conference proceedings. His currentinterest includes Autonomous Robots, Social Robotics,Human-Robot interaction and applications of roboticsin education.M. Angélica Pinninghoff J. is an associate professor inthe Department of Computer Science at the Universityof Concepción. Her research interests include artificialintelligence, evolutionary computation, and intelligentoptimization. Her current work includes image pro-cessing, in particular biological images, as a mechanismforinterpretation. Pinninghoffreceived an MSc in computer science from the Univer-sity of Concepción.improvingimagesMariano Rincón received his Ph.D. in Physics from theNational University for Distance Education (UNED) inMadrid (Spain) in 2003. He currently holds the positionof Associate Professor in the Department of ArtificialIntelligence at UNED. His research lies primarily withinthe fields of machine learning, computer visión andknowledge modelling for image understanding analysis.The fields of application are mainly neuroimaging andvideo surveillance, where interesting problems arisewhen dealing with multidimensional and multispectralimages (2D + t, 3D, 4D, etc.), and also the interpretationof images from an artistic point of view, which present ahigh subjectivity worthy of being modeled.Jose Santos Reyes received the MS degree in Physics(specialization in Electronics) from the University ofSantiago de Compostela, Spain, in 1989, and the PhDdegree from the same university in 1996 (specializationin Artificial Intelligence). He is Full Professor in theDepartment of Computer Science at the University of ACoruña, Spain. His research interests include artificiallife, neural computation, evolutionary computation andautonomous robotics, with the focus on computationalbiology in the last years, applying all the knowledgeacquired in the other research lines to the computa-tional modeling of biological problems.Karl Thurnhofer-Hemsi (born 1990) received his B.Sc.in Computer Engineering and his M.Sc. in Mathematicsdegrees from the University of Málaga, Spain, in 2014.He joined the Medical and Health Research Center of theUniversity of Málaga in 2015. He is currently a Ph.D.candidate at the Department of Computer Languagesand Computer Science, University of Málaga. His tech-nical interests are in medical image analysis, patternrecognition, image processing and deep learning.