Artificial Intelligence 174 (2010) 245–269Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintConformant plans and beyond: Principles and complexityBlai BonetDepartamento de Computación, Universidad Simón Bolívar, Caracas 89000, Venezuelaa r t i c l ei n f oa b s t r a c tArticle history:Received 16 September 2008Received in revised form 29 October 2009Accepted 29 October 2009Available online 3 November 2009Keywords:PlanningComplexity of planningPartially-observable planningNon-deterministic planningModal logicConformant planning is used to refer to planning for unobservable problems whosesolutions, like classical planning, are linear sequences of operators called linear plans.The term ‘conformant’ is automatically associated with both the unobservable planningmodel and with linear plans, mainly because the only possible solutions for unobservableproblems are linear plans. In this paper we show that linear plans are not only meaningfulfor unobservable problems but also for partially-observable problems. In such case, theexecution of a linear plan generates observations from the environment which must becollected by the agent during the execution of the plan and used at the end in order todetermine whether the goal had been achieved or not; this is the typical case in problemsof diagnosis in which all the actions are knowledge-gathering actions.Thus, there are substantial differences about linear plans for the case of unobservableor fully-observable problems, and for the case of partially-observable problems: whilelinear plans for the former model must conform with properties in state space, linearplans for partially-observable problems must conform with properties in belief space.This differences surface when the problems are allowed to express epistemic goals andconditions using modal logic, and place the plan-existence decision problem in differentcomplexity classes.Linear plans is one extreme point in a discrete spectrum of solution forms for planningproblems. The other extreme point is contingent plans in which there is a branch point forevery possible observation at each time step, and thus the number of branch points is notbounded a priori. In the middle of the spectrum, there are plans with a bounded numberof branch points. Thus, linear plans are plans with zero branch points and contingent plansare plans with unbounded number of branch points.In this work, we lay down foundations and principles for the general treatment of linearplans and plans of bounded branching, and provide exact complexity results for noveldecision problems. We also show that linear plans for partially-observable problems arenot only of theoretical interest since some challenging real-life problems can be dealt withthem.© 2009 Elsevier B.V. All rights reserved.1. IntroductionConsider the game of Mastermind which is a two-person code-breaking game played by the codemaker and the code-breaker. The game begins when the codemaker chooses a secret code, made of 4 pegs colored from 6 available colors(repetitions allowed), and the task of the codebreaker is to discover the code by questioning the codemaker and assessinghis answers. Each question, called a guess, is also a sequence of 4 colored pegs that is answered by the codemaker withtwo tokens of information: first the number of exact matches in the guess, i.e. the number of pegs of the right color andE-mail address: bonet@ldc.usb.ve.0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2009.11.001246B. Bonet / Artificial Intelligence 174 (2010) 245–269Fig. 1. Optimal contingent plan for Mastermind with 3 pegs and 3 colors.in the right position, and second the number of near matches in the guess, i.e. the number of pegs of the right color butin wrong position. The codebreaker wins if he can discover the secret code in at most 10 guesses, otherwise the codemakerwins. This popular game has captivated the attention of millions of people [60] including some renowned mathematicians[14,18,37,38].The game proceeds in guess-and-answer stages in which a guess may depend on the information acquired during theprevious stages. A winning strategy for Mastermind can be depicted as a tree whose nodes are the subsets of the possiblesecret codes at a given stage. For example, the root node is the set of 64 = 1296 possible secret codes since, at the beginning,the codebreaker has no information whatsoever. Each internal node of the tree is labeled with the guess to be done in casethe game reaches that stage, and for each possible answer to the guess, there is a child node that corresponds to the subsetof secret codes compatible with the answer. The leaves of the tree are nodes that correspond to singletons since theserepresent stages of the game at which the codebreaker has discovered the secret code.Fig. 1, for example, depicts an optimal strategy for a game of Mastermind with 3 pegs and 3 colors. Although the labelson the edges that tell the possible answers to the guesses are not shown, the important thing to note is the form of thesolution, i.e. its tree structure.The game of Mastermind can be cast as a non-deterministic planning problem with partial observability, and hencesolutions can be obtained with planners that perform search in belief space. Indeed, subsets of possible states (secret codesin Mastermind) are called belief states, and solutions like Fig. 1 are called contingent plans in belief space or contingentplans with partial observability. In general, if b is a belief state in the solution graph, o is an operator applicable at b, andz1, . . . , zn are the possible observations obtainable after the application of the operator o at b, then the children of b in thesolution graph are the beliefs bz1o denotes the belief that results after applying o at b and observing zi .o where bzio , . . . , bznThere are natural variations of the game such as the ones that result by increasing the number of colors in the secretcode or the number of available colors to choose from. However, there is a more interesting variation that is known asstatic Mastermind [14,23]. In this variation, the codebreaker is asked to give ahead a linear sequence of guesses such thatthe secret code can be determined from the answers upon such guesses. For example, for a game with 3 pegs and 3 colors,the sequence(cid:3)(cid:2)guess(2, 0, 0), guess(2, 1, 0), guess(2, 2, 1)σ =is guaranteed to succeed independently of the chosen secret code. Moreover, its length is minimum among all such se-quences, and hence corresponds to an optimal sequence. Also observe that the length of σ is greater than or equal to thelength of any branch in the optimal contingent plan in Fig. 1; this is not a coincidence since the sequence σ must discoverthe secret code independently of its value.We call a sequence like σ a linear or conformant plan for a partially-observable problem. Linear plans had beenstudied before in the context of unobservable planning by the name of conformant planning [16,21,24,30,57]. Unlikepartially-observable problems like Mastermind, unobservable problems only admit linear plans as solutions, since underthe hypothesis of null observability, the decision maker has no available input on which to base his decisions. In unobserv-able problems, a linear plan generates a collection of trajectories that result from the uncertainty in the initial state and thenon-determinism in the actions of the problem. A linear plan is a valid plan when each trajectory that starts at an initialstate ends in a goal state. This is the reason for the name ‘conformant’ as it means that the trajectories generated by theplan conform with the goal of the problem.B. Bonet / Artificial Intelligence 174 (2010) 245–269247Until now, linear plans had been only generally considered for unobservable planning problems. However, as the ex-ample of Mastermind shows, it also makes sense to consider linear plans for problems with partial observability (andalso for problems with full observability). Hence, we think that the term ‘conformant’ has been improperly used torefer to two different things: a class of solutions, namely linear plans, and to the class of unobservable planning prob-lems.In fully-observable domains, a linear plan does not make use of the information available at each time step as the plandetermines the actions to do at each step independently of contingencies. Thus, this case is essentially the same as theunobservable one and, from now on, we treat unobservable problems as non-deterministic fully-observable problems forwhich only linear plans are acceptable. In partially-observable domains, a linear plan also dictates the actions to do ateach time step, without deviating from a unique line of execution, yet there is an important difference with respect to theformer case as now the decision maker must collect the observations generated during the application of the plan in orderto achieve the goal at the end of the plan.There are substantial differences between the cases of linear plans for fully-observable and partially-observable domains.The first important difference is about the guarantees offered by such a plan. In the former case, the agent has the guaran-tee that the last state after the application of the plan will be a goal state. In the latter case however, as illustrated in theexample of Mastermind, the agent has the guarantee that after applying the plan and collecting the observations generatedalong, he will have enough information to achieve the goal, e.g., computing the secret code in Mastermind. Hence, while con-formance in fully-observable domains is about the compliance of a set trajectories in state space, conformance for partially-observabledomains is about the compliance of a set of trajectories in belief space.The second important difference appears when studying the computational complexity of decision problems for bothnotions of conformance: checking the existence of a linear plan for a fully-observable or unobservable problem is known tobe EXPSPACE-complete [27], while checking the existence of a linear plan for a partially-observable problem will be shownto be 2EXPSPACE-complete. This is an important difference since these two complexity classes are known to be differentand hence a 2EXPSPACE-complete problem cannot be reduced in polynomial time to an EXPSPACE-complete problem.It seems that linear plans have not been considered so far for partially-observable problems because the standard rep-resentation languages are not able to express epistemic goals and conditions. Indeed, a problem like Mastermind cannot beexpressed in such languages as they do not allow to express goals such as ‘to know the color of the pegs’. Thus, in orderto do a proper study of linear plans, we extend the standard propositional language used in planning with a simple modaloperator that can express such goals.Linear plans is one extreme point in a discrete spectrum of solution forms. The other extreme point is contingent plansin which there is a branch point for every possible observation received at each time step, and thus the number of branchpoint is not bounded a priori. In the middle of the spectrum, there are plans with a bounded number of branch points; e.g.,plans with at most 1 branch point, plans with at most 2 branch points, and so on. Linear plans are plans with no branchpoints whereas contingent plans are plans with unbounded number of branch points.The idea of having plans with a bounded number of branches is not new. Meuleau and Smith [45] considered plans ofbounded branching. Their work seems to be the first explicit and general treatment of the subject in the area of automatedplanning. Although their formulation is correct for the fully-observable case, it misses important aspects of the partially-observable case.Linear plans and plans of bounded branching are also of practical interest. Meuleau and Smith list three practical reasonsof why such plans are of interest for NASA: (1) plans must be simple enough so that humans can easily display, under-stand and be able to modify them, (2) plans may be subject to detailed analysis of resource consumptions, dissipation ofenergy, etc. and thus be simple for performing such analyses, and (3) rovers and voyagers have limited communicationbandwidth, computational resources and storage on board so simple plans are preferred to more complex ones. In areasrelated to medicine, for example, there are the so-called “diagnostic-test sequences” which can be thought as linear plansfor a partially-observable domain. A diagnostic-test sequence is a predetermined set of tests that are performed during agiven procedure or on a given sample even if the results of some of the tests end up not being used. For example, whenperforming blood tests, medical doctors order the so-called blood profiles that consist of a suite of tests to be performed ona single sample of blood. Diagnostic-test sequences exist for two main reasons: a blood sample must be processed within atime frame and thus tests cannot wait for the results of previous tests, and it is not ethically accepted to disturb a patientmultiple times by taking one blood sample per test. The situation becomes more dramatic as more invasive procedures arerequired. The design of diagnostic-test sequences is a relevant area in medicine.Problems involving rovers also provide real-life and vivid examples of situations that are meaningful to model aspartially-observable problems on which to compute linear plans. Indeed, consider a rover in a remote location with thegoal of performing scientific tests to determine the presence of a chemical compound. Further, assume that the vehicle haslimited capabilities for performing tests, and for analyzing and communicating the results of the tests. In particular, it maybe the case that the robot does not have enough computational resources to update its belief state with the results of thetests, nor to send the observations to the base in order to receive new instructions at each time step. In this case, one isinterested in computing a linear plan with the property that upon the results from the tests, collected and transmitted backto the base, a team of experts, provided with enough time and resources, would be able to detect the presence or absenceof the compound. Thus, knowing from advance that the robot is not able to properly maintain a belief state, there is no248B. Bonet / Artificial Intelligence 174 (2010) 245–269Table 1Complexity results for fully-observable planning problems. Each cell contains the class for which the corresponding problem iscomplete and a reference for the result. The last two problems are only defined for problems with no modal formulae; this isindicated with the subscript ‘PL’.Problemplan-fo-contplan-fo-linearplan-fo-branch(k)plan-fo-branchplan-fo-branch-lenPL(k)plan-fo-branch-lenPLWithout modal formulaeWith modal formulaeEXP [53]EXPSPACE [27]EXPSPACE (new)EXPSPACE (new)Σ P2k+2 (new)PSPACE (new)EXP (new)EXPSPACE (new)EXPSPACE (new)EXPSPACE (new)n/an/aneed to model the computational limitations of the robot. Instead, one can just focus on modeling the essential parts of thetask and on obtaining a linear plan.In this paper we study linear plans and plans of bounded branching for fully-observable and partially-observable planningproblems. We extend the standard propositional language for planning with a modal operator that permits the specificationof epistemic goals and preconditions, and perform a thorough complexity analysis on novel decision problems related to theexistence of different forms of solutions.The paper is organized as follows. First, we provide a summary of the complexity results in the following subsectionfor the convenience of the reader. Then, the propositional modal logic, the planning language and definitions of plans,some examples, and the decision problems are presented in Section 2 through Section 5. These sections are written for ageneral audience that has some knowledge on representation languages and automated planning. The following sectionshowever, from Section 6 through Section 10, are more technical as they contain the proofs of the complexity results:Section 6 contains inclusion results, Section 7 describes regular expressions with exponentiation and non-deterministicfinite automata with counters that are the main tool for showing hardness results, Section 8 shows how counters of double-exponential capacity can be encoded using belief states, and Sections 9 and 10 contain the hardness results and specialcases for plans of polynomial length for problems with no modal formulae. Section 11 concludes with a brief discussion.This paper contains and extends results from the article appeared in the proceedings of the 16th International Conf. onAutomated Planning and Scheduling 2006 [5]. This revised extension includes improved proofs, new decision problems, andfixes some errors.1.1. Summary of complexity resultsWe study the computational complexity of a number of decision problems for planning with full and partial observability,with and without modal formulae, and with restrictions on the number of branch points and the length of the solutions.The decision problems also depend on the type of the solution: either contingent, linear or a solution with a boundednumber of branch points. For example, the decision problem plan-fo-cont deals with the existence of contingent plansfor fully-observable planning problems, while plan-po-branch(k) deals with the existence of plans with at most k branchpoints for partially-observable planning problems. Some of the decision problems are standard, others are extensions ofstandard ones by considering modal formulae, and others are novel.Table 1 depicts exact complexity results of decision problems for fully-observable problems. Each row in the table corre-sponds to a type of decision problem and the columns indicate whether the problem is allowed to have modal formulae ornot. For example, the cell in the first row and column corresponds to the problem of checking the existence of a contingentplan for fully-observable problems with no modal formulae. Rintanen [53] showed that this problem is EXP-complete. Thesecond column of the first row contains the same decision problem but for problems that may have modal formulae; in thiscase, the decision problem is new but its complexity is the same. In this table, cont refers to contingent, branch(k) refersto at most k branch points, branch refers to problems whose instances are pairs (cid:2)P , k(cid:3) where P is a planning problem andk is an integer written in binary that bounds the number of branch points, and the subscript PL refers to a class of problemsthat have no modal formulae (defined in Section 10). Precise definitions for the decision problems are given in Sections 5and 10. Complexity results for partially-observable problems are shown in Table 2.As we can see, there are novel decision problems and interesting complexity results. Among them, the completenessresult for 2EXPSPACE (in Table 2) shows that computing linear plans for partially-observable problems is quite challenging.It is worth noticing that although this result is new, it is not unexpected given the known results for fully-observableproblems. Indeed, for fully-observable problems, we know that checking the existence of a contingent plan is EXP-completewhile EXPSPACE-complete for a linear plan. Thus, since checking the existence of a contingent plan for partially-observableproblems is 2EXP-complete [53], it is not surprising that the complexity rises to 2EXPSPACE when checking the existence ofa linear plan.B. Bonet / Artificial Intelligence 174 (2010) 245–269249Table 2Complexity results for partially-observable planning problems. Each cell contains the class for which the corresponding problemis complete and a reference for the result. The last two problems are only defined for problems with no modal formulae; this isindicated with the subscript ‘PL’.Problemplan-po-contplan-po-linearplan-po-branch(k)plan-po-branchplan-po-branch-lenPL(k)plan-po-branch-lenPLWithout modal formulaeWith modal formulae2EXP [53]EXPSPACE (new)EXPSPACE (new)EXPSPACE (new)Σ P2k+2 (new)PSPACE (new)2EXP (new)2EXPSPACE (new)2EXPSPACE (new)2EXPSPACE (new)n/an/a2. Propositional modal logicWe use a simple propositional modal language that extends propositional logic with a unary modal operator (cid:2) (‘box’).Well-formed formulae (wffs) are build up recursively from propositions and the propositional constant falsum (‘⊥’) usingthe following rules:– a proposition p is a wff,– ⊥ is a wff,– if ϕ is a wff, then ¬ϕ is a wff,– if ϕ and ψ are wffs, then ϕ ∨ ψ is a wff, and– if ϕ is a wff, then (cid:2)ϕ is a wff.Conjunctions, implications, bi-implications and the constant true (‘(cid:6)’) refer to the standard abbreviations: ϕ ∧ ψ := ¬(¬ϕ ∨¬ψ), ϕ → ψ := ¬ϕ ∨ ψ , ϕ ↔ ψ := (ϕ → ψ) ∧ (ψ → ϕ), and (cid:6) := ¬⊥. We also consider the dual operator ♦ (‘diamond’) ofthe operator (cid:2) defined by the abbreviation ♦ϕ := ¬(cid:2)¬ϕ.States are interpretations of the propositional symbols. We interchangeably denote states as interpretations and as thesubsets of propositions that they make true. Belief states refer to collection of states and are often represented as subsets ofsubsets of propositions. As it is standard in modal logic [4,34] and theories for reasoning about knowledge [19], the seman-tics of modal formulae is given in terms of Kripke models and frames. In our case, we are only interested in interpretingformulae with respect to belief states and thus provide the semantics in terms of pairs (b, s), where b is a belief state ands is a state, using structural induction as follows:– (b, s) (cid:4) p iff p ∈ s,– (b, s) (cid:4) ⊥ never,– (b, s) (cid:4) ¬ϕ iff not (b, s) (cid:4) ϕ,– (b, s) (cid:4) ϕ ∨ ψ iff (b, s) (cid:4) ϕ or (b, s) (cid:4) ψ , and– (b, s) (cid:4) (cid:2)ϕ iff (b, s(cid:11)) (cid:4) ϕ for all s(cid:11) ∈ b.A formula ϕ is globally true in belief state b, written as b (cid:4) ϕ, if it is satisfied at all states; i.e. (b, s) (cid:4) ϕ for all s ∈ b. Thisnotion of interpretation is a specialization of the standard Kripke semantics for modal logic in which the set of nodes (inthe frame) is the belief state b, and the accessibility relation (in the frame) is a universal relation over nodes; i.e., everynode is related to each other. A frame of this type is in turn a special case of frames with an accessibility relation thatis an equivalence relation. A sound and complete axiomatization for this class of frames is the system S5, yet we will beonly concerned with being able to interpret formulae at the model-theoretic level with respect to belief states. The readerinterested in a thorough treatment of modal logic is referred to the work of Blackburn, de Rijke, and Venema [4].From a computational perspective, we are interested in how to decide whether b (cid:4) ϕ for a given belief state b and wff ϕ,and what is the cost of doing it. It turns out that for our purposes it suffices to know that such decision can be computedin polynomial space in the size of the belief state and ϕ. Indeed, a simple recursive algorithm that tests ‘(b, s) (cid:4) ϕ’ bydecomposing ϕ into sub-formulae can be used to test b (cid:4) ϕ. Such an algorithm only needs to store a stack of depth O (|ϕ|).Modal logic is more expressive than propositional logic as it permits, for example, to express preconditions for actionsor goals of the form ‘know ϕ’, which holds when all states in the belief state agree on the interpretation of ϕ, and ‘possiblyϕ’ which holds when some state in the belief state satisfies ϕ. Indeed,‘know ϕ’ can be defined as an abbreviation of(cid:2)ϕ ∨ (cid:2)¬ϕ while ‘possibly ϕ’ can be defined as an abbreviation of ♦ϕ.Example: Goal for the game of MastermindLater we provide a complete formulation of the game of Mastermind in which the secret code is represented usingpropositions si, j that are true in a state s when the ith peg is of color j. In Mastermind the goal is to reach a belief statein which the interpretations of all propositions denoting the secret code are known to the codebreaker. Hence, the goal isdefined with the formula1(cid:2)i, j(cid:2)3((cid:2)si, j ∨ (cid:2)¬si, j) for a game of Mastermind with 3 pegs and 3 colors.(cid:4)250B. Bonet / Artificial Intelligence 174 (2010) 245–2693. Planning problems, belief states and plansWe consider planning problems defined by tuples of the form P = (cid:2)D, I, G, O , Z (cid:3) where D is a set of propositionalsymbols (fluents), I is a propositional formula without modalities that defines the initial states, G is a propositional formulathat defines the goal states, O is a set of operators, and Z ⊆ D is the subset of observable fluents. Operators are pairs (cid:2)ϕ, α(cid:3)where ϕ, called the precondition, is a propositional formula and α is an effect defined as follows:– (cid:6) is the null or empty effect,– p and ¬p are atomic effects for p ∈ D,– if α1, . . . , αn are effects, then (α1 ∧ · · · ∧ αn) is a parallel effect,– if α1, . . . , αn are effects, then (α1 ⊕ · · · ⊕ αn) is a non-deterministic effect, and– if ϕ is a formula and α is an effect, then (ϕ (cid:2) α) is a conditional effect where ϕ and α are called the condition andeffect of the conditional effect.Both preconditions and conditions may contain modal operators. However, there is an important difference in how they areevaluated since the former are evaluated at belief states while the latter at states within a belief state. This is the standardsemantics in planning for conditional operators as it makes possible for an effect to trigger at some states and not at othersin the same belief state.As said before, states for the planning problem are valuations for the propositions in D and belief states are subsets offor beliefs states. An operator o = (cid:2)ϕ, α(cid:3) is applicable at the beliefstates; their maximum number is 2state b iff b (cid:4) ϕ; in such case the states that result from the application of α at each state s ∈ b is the belief statefor states and 22|D||D|Res(o, b) def=(cid:6)Appl(cid:5)s∈bEff (α|b, s), s(cid:7),where Eff (α|b, s) is the set of atomic effects induced by α given (b, s), and Appl(E, s) is the set of states that result from theapplication of the atomic effects E on state s. If the operator is not applicable the result is undefined. The set Eff (α|b, s) ofatomic effects is defined as– Eff ((cid:6)|b, s) def= {∅},– Eff ((cid:7)|b, s) def= {{(cid:7)}} for literal (cid:7),(cid:8)– Eff (α1 ∧ · · · ∧ αn|b, s) def= {i=1 E i: E i ∈ Eff (αi|b, s)},n– Eff (α1 ⊕ · · · ⊕ αn|b, s) def=i=1 Eff (αi|b, s), and– Eff (ϕ (cid:2) α|b, s) def= Eff (α|b, s) if (b, s) (cid:4) ϕ, and Eff (ϕ (cid:2) α|b, s) def= {∅} otherwise.(cid:8)nObserve that the effects are calculated with respect to a belief and state. In particular, the condition ϕ of the effect ‘ϕ (cid:2) α’is evaluated with respect to the pair (b, s) instead of the belief b. Thus, it is possible that a conditional effect triggers atsome state but not at other in the same belief. Finally, the application of a set E of atomic effects on a state s is defined as(cid:9)Appl(E, s) def=(cid:11)e ∪ s: e ∈ E, s(cid:11) = s \(cid:5)(cid:10){p, ¬p},p∈prop(e)where prop(e) is the set of propositions mentioned in the effect e.For example, consider the fluents {min, m1, m0}, the formula ϕ = min ∧m0 ∧ ♦(min ∧¬m0), the effect α = ϕ (cid:2) ¬ min, andthe belief b = {s1 = {m1}, s2 = {min, m0}, s3 = {min}}. Then,– (b, s1) (cid:2) ϕ since min /∈ s1, hence Eff (α|b, s1) = {∅};– (b, s2) (cid:4) ϕ since {min, m0} ⊆ s2 and (b, s3) (cid:4) min ∧¬m0, hence Eff (α|b, s2) = {{¬ min}};– (b, s3) (cid:2) ϕ since m0 /∈ s3, hence Eff (α|b, s3) = {∅}.Thus, Res((cid:2)(cid:6), α(cid:3), b) = Appl({∅}, s1) ∪ Appl({{¬ min}}, s2) ∪ Appl({∅}, s3) = {s1, {m0}, s3}.Different classes of models are obtained by controlling the parameters in a problem P = (cid:2)D, I, G, O , Z (cid:3). If there are nonon-deterministic effects, and I determines a unique state, P is an ADL problem [50], or a STRIPS problem [20] if thereare no conditional effects and G and all preconditions are conjunctions of atoms. If the set of observables equals D then Pis a fully-observable non-deterministic planning problem, which can be thought of as a non-deterministic Markov DecisionProcess (MDP) [3,52]; in this case, we drop Z from the notation and write P = (cid:2)D, I, G, O (cid:3). If Z (cid:16)= D then P is a contingentplanning problem, which can be thought of as a non-deterministic Partially Observable MDP [6,35].The form of valid plans varies with the nature of the problem. For ADL and unobservable problems, a plan is a linearsequence of operators that achieves the goal no matter what is the initial state and the non-determinism involved, and henceplans can be recovered by search in state space for ADL problems [7,28,31] and search in belief space for linear plans forB. Bonet / Artificial Intelligence 174 (2010) 245–269251unobservable problems [6,10,30,47,54]. Contingent plans are functions that map states into operators for MDPs, and beliefstates into operators for POMDPs. In these cases, a valid plan can be obtained by different means: dynamic programmingover state space or belief space [3,12,52,58], AND/OR search in state or belief space [8,9,26], and other techniques as well[29,33,43]. For fully-observable and partially-observable problems, we also consider linear plans and plans with a boundednumber of branch points as defined next.3.1. PlansA goal belief state is a belief state that satisfies the goal formula, i.e. b (cid:4) G. If o is an applicable operator at b, we let bodenote the belief state Res(o, b) that results from the application of o at b. The function Res(o, b) is extended over sequencesof operators by Res((cid:2)(cid:3), b) def= b and Res((cid:2)o1, . . . , on(cid:3), b) def= Res(on, Res((cid:2)o1, . . . , on−1(cid:3), b)), with the proviso that each operatorin the sequence is applicable at the corresponding belief, or else the result is undefined.Let P = (cid:2)D, I, G, O (cid:3) be a fully-observable problem and bI the initial belief state; i.e., bI(cid:2)o1, . . . , on(cid:3) of operators is said to be a linear or conformant plan for P iff Res(π , bI ) is a goal belief.def= {s: s (cid:4) I}. A sequence π =A plan with bounded branching for P is a tree that is defined with respect to the initial belief. We define plans ofbounded branching as follows. A 0-plan for belief b is an applicable sequence of operators that maps b into a goal belief;e.g., a 0-plan for bI is a linear plan for bI . In general, a k-plan for b is a labeled and directed tree T = (cid:2)V , E, r, (cid:7)(cid:3) wherer ∈ V is the root node and (cid:7) is a labeling function that maps nodes n into operator sequences (cid:7)(n) and edges e into states(cid:7)(e) such that:– the height of T is less than or equal to k,– for each node n, the function (cid:7)(n, ·) is one-to-one, i.e. (cid:7)(n, n– the sequence of operators (cid:7)(r) is applicable at b,– the subset of states {(cid:7)(r, n): (r, n) ∈ E} is equal to Res((cid:7)(r), b), and– for each edge (r, n), the subtree rooted at n is a (k − 1)-plan for the singleton {(cid:7)(r, n)}.(cid:11)(cid:11)) implies n(cid:11)) = (cid:7)(n, n(cid:11) = n(cid:11)(cid:11),In words, the label of the root denotes the sequence of operators to apply at the initial belief b which results in the subsetof states Res((cid:7)(r), b). Then, the agent ‘observes’ the world and determines that the current state is some s in Res((cid:7)(r), b). Bythe fourth condition, there is a child n of r such that (cid:7)(r, n) = s, and thus the subtree rooted at n is a (k − 1)-plan for thesingleton belief state {s}. In particular, when n is a leaf of the tree, (cid:7)(n) is a linear plan for the singleton {s}.These conditions characterize valid plans with at most k branch points for fully-observable problems: a plan with at mostk branch points is a k-plan for bI . A plan with no bounds on branching is just a tree of arbitrary height, and a contingentplan is a plan with no bounds on branching in which each sequence (cid:7)(n) of operators contains only one operator.At first sight, it may appear that constraints on the number of branch points translate into constraints on the amountof information that an agent needs to store in order to execute the plan. This however is not true because our plans, withor without constraints on the number of branch points, deal with complete belief states and hence no information aboutthe world is lost. Although there is a close connection between the length of a plan and the information requirements forit, this dependency is not direct. If the agent keeps a history of the actions taken and the observations received, then theinformation requirement is proportional to the length of the plan. However, if the agent maintains a belief state, he does|D|) bitsnot need to store the history but to update the belief state at each time step and thus the requirement is O (|D|2since this is the number of bits needed to store a belief (see below). In summary, neither the number of branch points in aplan nor its length determines the information requirements for the execution of the plan. Plans that constraint the amountof information usually take the form of finite-state controllers: the information requirement for a finite-state controllersis equal to the log of the number of states in the controller. Proposals that consider finite-state controllers for partiallyobservable domains had been studied elsewhere [1,25,42,44,51].Obviously, k-plans are acyclic plans that have a worst-case termination horizon. In this paper, we do not deal with cyclicor iterative plans that can be constructed either by using structured languages [39,40] or as functions that map states (orbeliefs) into actions [2,6,15]. Cyclic plans are challenging to interpret as often it is not clear what is the role of the actions’non-deterministic effects [55]. Also, it is not completely clear how to define cyclic plans of bounded branching, specially forpartially-observable problems.3.1.1. Partially-observable domainsIn partially-observable domains, the application of an operator o is accompanied by an observation z. This observationis the feedback that the agent receives from the environment, and depends on both the operator and the state that resultsdef= {s ∈ bo: s (cid:4) z}.after applying o. The feedback z is used by the agent to update its current belief b into the new belief bzoIf the belief state b faithfully represents the possible current state of the system, then the set of observations that maydef= {z ∈ Terms(Z ): ∃s[s ∈ bo ∧ s (cid:4) z]} where Terms(Z ) denote allbe obtained after the application of o at b is the set Z obcomplete terms over the fluents Z . If there is more than one possible observation, the agent must consider more than onepossible next belief state after the application of the operator and hence branching in belief space occurs.252B. Bonet / Artificial Intelligence 174 (2010) 245–269Just like the case of fully-observable problems, the execution of a linear plan π = (cid:2)o1, . . . , on(cid:3) may generate differenttrajectories. These trajectories are not over states but over belief states and thus we are forced to consider collections ofdef= Res(oi, B i), for 1 (cid:5) i (cid:5) n,belief states instead of collections of states. Let B 1 be a collection of belief states and define B i+1where(cid:11)Res(o, B) def=o: b ∈ B, z ∈ Z o{bzundefinedb}if o is applicable at each b ∈ B,otherwise.The sequence π is said to be applicable on B 1 if no B i is undefined. In this case, we let Res(π , B 1) def= Bn+1.If π is such that Res(π , B) is a collection of goal belief states, we say that π is a 0-plan or linear plan for the collection B.A k-plan for a collection B is defined similarly as before: it is a labeled and directed tree T = (cid:2)V , E, r, (cid:7)(cid:3) where r is the rootnode and (cid:7) is a labeling function that maps nodes n into sequence of operators (cid:7)(n) and edges e into belief states (cid:7)(e) suchthat:– the height of T is less than or equal to k,– for each node n, the function (cid:7)(n, ·) is one-to-one,– the sequence of operators (cid:7)(r) is applicable at B,– the collection of beliefs {(cid:7)(r, n): (r, n) ∈ E} is equal to Res((cid:7)(r), B), and– for each edge (r, n), the subtree rooted at n is a (k − 1)-plan for the singleton {(cid:7)(r, n)}.That is, the label of the root denotes the sequence of operators to apply at the collection B which results in the collectionRes((cid:7)(r), B). Then, after the application of the sequence, the agents calculate the current belief using all the informationgathered during the application of the sequence (i.e. the feedback received by the agent). This belief b is a member ofRes((cid:7)(r), B). By the fourth condition, the tree contains a child n of r such that (cid:7)(r, n) = b and thus the subtree rooted at nis a (k − 1)-plan for the singleton collection {b}. In particular, when n is a leaf of the tree, the sequence (cid:7)(n) is a linear planfor the singleton {b}.These conditions characterize valid plans with at most k branch points for partially-observable problems: a plan withat most k branch points is a k-plan for the collection {bI }. A plan with no bounds on branching for a partially-observableproblem is a tree of arbitrary height, and a contingent plan is a plan with no bounds on branching in which each sequence(cid:7)(n) of operators contains only one operator.4. ExamplesWe present two examples of partially-observable problems in which linear solutions are interesting and meaningful. Thefirst problem is the game of Mastermind and the second one is related to a rover that must perform a number of tests inorder to determine the presence of a chemical compound on the Martian surface.4.1. The game of MastermindWe provide a formalization for the game of Mastermind with 3 pegs and 3 colors; the case of more pegs and colors issimilar. We use the propositions {si, j: 1 (cid:5) i (cid:5) 3, 1 (cid:5) j (cid:5) 3} to denote the secret code with si, j being true iff the peg i isof color j. For simplicity, we denote the number of exact and near matches of a guess in unary using the fluents {x1, x2, x3}and {n1, n2, n3} respectively. The propositions si, j must be hidden as the codebreaker does not know their value while theother propositions must be observable as these provide the feedback for the guesses.The initial situations correspond to all possible combinations of secret codes. Such combinations translate into all booleanassignments for the si, j that assign a color for each peg and that forbid two different colors to be assigned to the same peg.For the observable propositions we assume, without loss of generality, that they are all false at the initial situation. Hence,(cid:12)def=I(si,1 ∨ si,2 ∨ si,3) ∧(cid:12)(¬si, j ∨ ¬si,k) ∧1(cid:2)i(cid:2)31(cid:2)i(cid:2)3, 1(cid:2) j<k(cid:2)3(cid:12)1(cid:2)i(cid:2)3(¬xi ∧ ¬ni).The goal of the game is to reach a ‘state of knowledge’ in which the secret code is known to the codebreaker. In thestandard formulation of the game, the game ends when the codebreaker makes a guess that exactly matches the secretcode. In our formulation however the game ends when the codebreaker discovers the secret code. These two formulationsare not the same since it is possible to discover the secret code without making a guess that has 3 exact matches. In ourformulation, the goal is(cid:12)def=G1(cid:2)i, j(cid:2)3((cid:2)si, j ∨ (cid:2)¬si, j)as it says that the truth-value for the si, j is known to the codebreaker; i.e. the secret code is known.B. Bonet / Artificial Intelligence 174 (2010) 245–269253In the standard formulation, the goal can be defined as observing three exact matches that happens when the code-breaker makes a guess that exactly matches the secret code. However, such goal formula only works for computingcontingent plans for Mastermind and not for computing linear plans.Some problems involving knowledge can be translated into problems where the notion of knowledge is moved down tothe syntactic level thus removing the need for a modal operator. These translations implement operators that manipulatethe knowledge at the syntactic level using standard rules of inference such as the ones in the axiomatization S5. However,these approaches often increase the size of the translation by an exponential factor. Recently, Palacios and Geffner [48]gave sound and complete translations for computing conformant plans for unobservable problems into classical planningproblems, but with a worst-case exponential increase in size.We continue with the formulation of Mastermind for which it only remains to define the operators. Since the secret codedoes not change during the game, the operators do not modify it; they just return information via the observable fluents. Inorder to simplify the coding, we let fluents ni to count the number of near plus exact matches in the guess. For example,if the code is (cid:2)1, 2, 1(cid:3) and the guess is (cid:2)2, 1, 1(cid:3), then the feedback is (x, n) = (1, 3) as the first ‘1’ and the ‘2’ in the guessare near matches and the second ‘1’ in the guess is an exact match. This variation of the game is equivalent to the originalone because the amount of the information returned by each action is the same. Mastermind has ‘guess(c1, c2, c3)’ for eachguess of the form (cid:2)c1, c2, c3(cid:3) with ci ∈ {1, 2, 3}. The operators have empty precondition and the following conditional effects:(cid:15)(cid:13)si,ci(cid:2) x1∧¬(cid:14)(cid:15)si,ci(cid:2) ¬x1∧(cid:13) (cid:14)(cid:15)(cid:13)si,ci∧ s j,c j(cid:2) x2∧¬(cid:15)si,ci∧ s j,c j(cid:2) ¬x2(cid:14)1(cid:2)i< j(cid:2)3(cid:13) (cid:14)1(cid:2)i(cid:2)3(cid:13) (cid:14)1(cid:2)i, j(cid:2)31(cid:2)i(cid:2)3(cid:13) (cid:12)(cid:15)(cid:13)si,ci(cid:2) x3∧¬1(cid:2)i< j(cid:2)3(cid:12)si,ci(cid:15)(cid:2) ¬x3,∧(cid:15)si,c j(cid:2) n1∧¬(cid:13)∧¬(cid:13)∧¬1(cid:2)i(cid:2)3(cid:13)(cid:14)1(cid:2)i(cid:2)3(cid:15)(cid:13) (cid:14)si,c j(cid:2) ¬n1∧(cid:14)(cid:15)si,ck∧ s j,cl(cid:2) n21(cid:2)i, j(cid:2)3(cid:14)(cid:14)1(cid:2)i< j(cid:2)31(cid:2)k,l(cid:2)3(cid:15)(cid:13) (cid:12)si,ck∧ s j,cl(cid:2) ¬n2∧(cid:14)(cid:15)si,c j(cid:2) n31(cid:2)i< j(cid:2)3(cid:12)1(cid:2)k,l(cid:2)3(cid:14)si,c j1(cid:2)i(cid:2)31(cid:2) j(cid:2)3(cid:15)(cid:2) ¬n3.1(cid:2)i(cid:2)31(cid:2) j(cid:2)3The first six conditional effects compute the number of exact matches in unary, and the last six compute the number ofexact plus near matches in unary.4.2. The Mars RoverWe present an abstract formulation of an autonomous rover that must perform a set of experiments in order to ascertainthe presence of some chemical compound on the Martian surface. The rover has no capabilities to perform in-depth anal-ysis of samples. Thus an experiment consists in collecting a sample, performing some measurements on the sample, andtransmitting back to Earth the results of the measurements.The state of the system is specified using two different sets of fluents. First, feature fluents { f 1, . . . , fn} that denote thepresence or absence of n features on the surface of the planet, and second, power fluents {p1, . . . , pm} that denote theremaining power in the batteries of the rover. The power fluents measure the remaining power in unary; initially the roverhas m power units and each experiment consumes one unit.For simplicity, we assume that each experiment returns one bit of information whose truth-value only depends on thecurrent but unknown state of the environment. Thus, we assume that for each experiment ‘testi ’ there is a formula ϕi , overthe feature fluents, that defines the information bit.The Mars Rover problem is a partially-observable planning problem P = (cid:2)D, I, G, O , Z (cid:3) whereD = { f 1, . . . , fn} ∪ {p1, . . . , pm} ∪ {bit},I =pi ∧ ¬bit,(cid:12)1(cid:2)i(cid:2)m(cid:12)G =1(cid:2)i(cid:2)n((cid:2) f i ∨ (cid:2)¬ f i),O = {test1, . . . , test(cid:7)},Z = {bit}254B. Bonet / Artificial Intelligence 174 (2010) 245–269in which the goal is to be certain about presence/absence of each feature f i . The initial states correspond to all the 2ninterpretations for the features. The operators require and consume one unit of energy, and set or clear the information bitdepending on whether the formula ϕi is true or false; i.e., for 1 (cid:5) i (cid:5) (cid:7),(cid:16)testi =p1 ∨ · · · ∨ pm, (ϕi (cid:2) bit) ∧ (¬ϕi (cid:2) ¬bit) ∧(cid:17)(¬p1 ∧ · · · ∧ ¬p j−1 ∧ p j (cid:2) ¬p j).(cid:12)1(cid:2) j(cid:2)mWe consider two classes of solutions (plans) for the Mars Rover and how each class translates into assumptions on thecapabilities of the rover. Solutions in the first class have no constraints on the number of branch points and hence they arecontingent plans for the problem. This class corresponds to a rover that has sufficient capabilities to perform the filteringoperation on belief states and thus able to update its belief state with the result of each test. In this setting, the plan isa contingent plan that generates a sequence of tests able to discover the exact configuration of features on the Martiansurface.Solutions in the second class have no branch points and thus are linear sequences of tests. This class corresponds to arover that has no capabilities whatsoever to perform belief filtering. Therefore, the task of the rover is to perform all test inthe sequence and then transmit the results back to Earth. The results are then analyzed by a team of human experts thatdetermine, from the unique and fixed sequence of results, the exact configuration of features on the Martian surface.In this example, the details about the capabilities of the rover are abstracted away from the representation of the prob-lem, yet such details are not lost as they got translated into requirements on the form of the solutions. Thus, if the rover is ableto process the results of the experiments, we look for contingent plans, but if the robot is unable to do so, we then look forlinear plans.Examples like this one show that the proposed language and novel planning problems are not only of pure theoreticalinterest, since they are related to very relevant and difficult real-life problems.5. Complexity and decision problemsWe only consider Turing Machines (TM) with semi-infinite tapes that halt on all inputs. We use DTM, NTM and ATM todenote deterministic, non-deterministic and alternating TMs respectively. We consider the standard complexity classes P(polynomial time), PSPACE (polynomial space), EXP (exponential time), EXPSPACE (exponential space), 2EXP (double-exponential time), 2EXPSPACE (double-exponential space), and their non-deterministic variants. The non-deterministic spaceclasses are equal to the deterministic ones [56], and thus closed under complementation, e.g. NEXPSPACE = EXPSPACE =coEXPSPACE.One can define the class of languages recognized by ATMs that start at an existential state, make at most n − 1 alterna-tions, and operate in polynomial time. Such class is denoted by Σ Pn if the initial state is universal. The union of allthese classes form the Polynomial-Time Hierarchy (PH) [59] which can also be defined via oracles [62]. The following arestandard facts [17,49,56]:n or Π P• P ⊆ Σ Pn• The following problem, called satk, is complete for Σ P⊆ PSPACE for all 0 (cid:5) n < m (hierarchy theorem).⊆ Σ Pm∩ Π Pm∪ Π PnQ xk)Φ, where Q is ∀ or ∃ whether k is even or odd. Is Ψ a valid formula?k : Given a quantified boolean formula (QBF) Ψ = (∃x1∀x2 · · ·• The following problem, called qbf, is complete for PSPACE: Given a QBF Ψ = (∃x1∀x2 · · · Q xk)Ψ , where Q is ∀ or ∃whether k is even or odd. Is Ψ a valid formula?Observe that k is a fixed constant in the problem satk (not part of the input), while for qbf the number of quantifiers isvariable. Thus, the problem qbf cannot be reduced to a unique satk problem (unless PH collapses to such level).5.1. Decision problemsThe standard methodology is to cast decision problems for planning as languages. For example, the problem of decidingwhether a given STRIPS planning problem has a valid plan correspond to the languageplan-strips def=(cid:18)(cid:19)(cid:2)P (cid:3): P is a STRIPS problem that has a planwhere (cid:2)P (cid:3) is a suitable encoding of P . The length of P is defined as the length of its encoding. The following list contains themain decision problems considered in this article (we abbreviate ‘fully-observable planning problem’ as FOP and ‘partially-observable planning problem’ as POP):• plan-adl def= {(cid:2)P (cid:3): P is an ADL planning problem (and hence FOP) that has a plan},• plan-fo-cont def= {(cid:2)P (cid:3): P is a FOP that has a plan},• plan-fo-linear def= {(cid:2)P (cid:3): P is a FOP that has linear plan},• plan-fo-branch(k) def= {(cid:2)P (cid:3): P is a FOP that has a k-plan},B. Bonet / Artificial Intelligence 174 (2010) 245–269255• plan-fo-branch def= {(cid:2)P , k(cid:3): P is a FOP that has a k-plan and k is written in binary},• plan-po-cont def= {(cid:2)P (cid:3): P is a POP hat has a plan},• plan-po-linear def= {(cid:2)P (cid:3): P is a POP that has linear plan},• plan-po-branch(k) def= {(cid:2)P (cid:3): P is a POP that has a k-plan},• plan-po-branch def= {(cid:2)P , k(cid:3): P is a POP that has a k-plan and k is written in binary}.Observe that plan-fo-branch(k) and plan-po-branch(k) represent collections of problems, one per each value of k. Theproblems plan-fo-branch and plan-po-branch represent languages made of pairs (cid:2)P , k(cid:3) where P is a planning problem andk is an integer written in binary. plan-fo-branch(k) and plan-fo-linear can be reduced in a direct way to plan-fo-branch,and thus their complexity is no more than the complexity of the latter. Similarly, for plan-po-branch(k), plan-po-linearand plan-po-branch.Tight complexity bounds for plan-strips, plan-adl, plan-fo-cont, plan-fo-linear and plan-po-cont are known. Indeed,plan-strips and plan-adl are PSPACE-complete [11], plan-fo-cont is EXP-complete [53],1 plan-fo-linear is EXPSPACE-complete [27], and plan-po-cont is 2EXP-complete [53] (the last two results are for problems with no modal formulae). Theproblems plan-fo-branch(k), plan-fo-branch, plan-po-branch(k), plan-po-branch and plan-po-linear are novel. The firsttwo problems will be shown to be EXPSPACE-complete while the latter three will be shown to be 2EXPSPACE-complete.As defined, plan-strips, plan-adl and plan-fo-cont include problems with modal formulae. However, since in theseproblems the state of the system is known at each time point, the modalities play no role and they can be removedwithout changing the problems; thus, their complexity results remain valid. The results that need to be revised are thosefor plan-fo-linear and plan-po-cont with modalities. As we will see, the complexity results of Haslum and Jonsson [27]and Rintanen [53] also remain valid for these classes.6. Inclusion resultsWe first revise the complexity of plan-fo-linear and plan-po-cont for problems with modal formulae, and then provideinclusion results for plan-fo-branch(k), plan-fo-branch, plan-po-branch(k), plan-po-branch and plan-po-linear.Observe that with n propositional symbols, there are at most 2n planning states and hence a set of states can be repre-sented in exponential space with n2n bits, i.e. at most 2n states each taking space n. Also, recall that the truth of a modalformula can be decided in polynomial space in the size of the formula.The cases for plan-fo-linear and plan-po-cont are essentially the same as when there are no modalities: the onlychange is that it may be necessary to test the validity of a modal formulae, yet this can be done within the resources usedby the algorithm.For plan-fo-linear, the existence of a plan can be decided in non-deterministic exponential space with a TM that onlystores a single belief state and a counter. The machine starts with the initial belief state and the counter initialized to zero.Then, the machine enters a loop in which non-deterministically chooses an applicable operator, applies it and cycles untilthe current belief becomes a goal belief or after reaching 22noperators andchecking the validity of modal formulae requires polynomial space, the TM correctly decides the existence of a plan andworks in exponential space. Observe that the machine does not compute a plan, it just decides if a plan exists.steps. Since a valid plan must have at most 22nTheorem 1. plan-fo-linear is in EXPSPACE. Since completeness holds for the restricted case of problems without modalities, plan-fo-linear is EXPSPACE-complete.plan-po-cont can be solved with an ATM using exponential space for which the accepting computation trees correspondto contingent plans (the proof is a special case of the proof of Theorem 3 given below). Since ATMs with exponential spacebounds can be simulated with DTMs with double-exponential time bounds [13], we haveTheorem 2. plan-po-cont is in 2EXP. Since completeness holds for the restricted case of problems without modalities, plan-po-contis 2EXP-complete.The inclusion of plan-fo-branch in EXPSPACE is shown with an ATM that makes at most k alternations. Note that eachbranch point in the plan corresponds to fully observing the current state of the system and then planning thereafter. Sincea different plan must be found for each possible state, the branch can be simulated with a transition from a universal state.A final simulation of the ATM with a DTM shows the inclusion in EXPSPACE.Theorem 3. plan-fo-branch is in EXPSPACE. Hence, plan-fo-branch(k) is in EXPSPACE.1 The complexity remains EXP-complete even for testing the existence of plans that reach the goal with probability (cid:3) t for probabilistic problems withfull observability [41].256B. Bonet / Artificial Intelligence 174 (2010) 245–269Proof. Consider the input (cid:2)P , k(cid:3), where P = (cid:2)D, I, G, O (cid:3) is a fully-observable planning problem and k is a bound on thenumber of branch points written in binary. Let |D| = n. The following ATM decides if there is a k-plan for P :if K = 0 then REJECT;K := K − 1;∀-branch: for each s ∈ b do b := {s};goto 2;M: on input (cid:2)P , k(cid:3)1. K := k; b := {s: I (cid:4) s}; steps := 0;2. if b (cid:4) G then ACCEPT;3. ∃-branch: choose either APPLY or BRANCH;4. if BRANCH then5.6.7.8.9. else if APPLY thenif steps = 22n∃-branch: choose operator a = (cid:2)ϕ, α(cid:3) such that b (cid:4) ϕ;b := Res(a, b);steps := steps + 1;goto 2;then REJECT;10.11.12.13.14.15. endThe ATM is in EXPSPACE since there are at most 2n states so a subset of states can be stored in O (n2n) bits, the counterssteps and K require O (2n + log K ) bits, and the tests in lines 2 and 11 can be done in polynomial space. Use now Borodin’sTheorem (Appendix A) to conclude that M can be transformed into a DTM with an exponential space bound. (cid:3)The same idea works for the inclusion of plan-po-branch in 2EXPSPACE except that this time collections of belief statesare stored instead of belief states, and thus the ATM requires O (n2n22n) bits.Theorem 4. plan-po-branch is in 2EXPSPACE. Hence, plan-po-branch(k) and plan-po-linear are in 2EXPSPACE.Proof. Consider the input (cid:2)P , k(cid:3), where P = (cid:2)D, I, G, O , Z (cid:3) is a partially-observable planning problem and k is a bound onthe number of branch points written in binary. The following ATM decides if there is a k-plan for P :if K = 0 then REJECT;K := K − 1;∀-branch: for each b ∈ B do B := {b};goto 2.M: on input (cid:2)P , k(cid:3)1. K := k; B := {{s: I (cid:4) s}}; steps := 0;2. if b (cid:4) G for all b ∈ B then ACCEPT;3. ∃-branch: choose either APPLY or BRANCH;4. if BRANCH then5.6.7.8.9. else if APPLY thenif steps = 222n∃-branch: choose operator a = (cid:2)ϕ, α(cid:3) such that b (cid:4) ϕ for all b ∈ B;B := Res(a, B);steps := steps + 1;goto 2.then REJECT;10.11.12.13.14.15. endSince there are at most 2n states and 22nbits andthe ATM has a double-exponential space bound. As before, Borodin’s Theorem implies that M can be transformed into aDTM with a double-exponential space bound. (cid:3)subsets of states, a collection B of belief states can be stored in n2n22nFor hardness results, we follow the work of Haslum and Jonsson [27] and use regular expressions with exponentiationand the corresponding non-deterministic finite automata with counters. Automata provide a fruitful approach for hardnessresults as it is easy to simulate their behavior with planning problems.7. Regular expressions and automataRegular expressions with exponentiation (REE) extend regular expressions with an operation of exponentiation of theform α ↑ k where α is a regular expression (with exponentiation) and k is a positive integer written in binary. The expressionB. Bonet / Artificial Intelligence 174 (2010) 245–269257Fig. 2. Non-deterministic finite automaton with counters for α ↑ k.α ↑ k denotes the language α · · · α where α is repeated k times. A REE can be transformed into a regular expression withoutexponentiation by replacing each subexpression α ↑ k by the concatenation of k copies of α. This transformation howeverincreases the length of the expression exponentially; e.g. the length of α ↑ k is 1 + |α|(cid:21)log k(cid:22) while the length of α · · · α isk|α|. As usual, the length |α| is defined as the number of symbols in it.Regular expressions with exponentiation are typically used to establish intractability results for EXPSPACE and beyond.The main tool utilized is the following classical result about REEs; we refer to the version that appears in Sipser’s book [56],yet also consult Hopcroft and Ullman [32] or the source [46].Theorem 5. Let α be a REE over alphabet Σ . Checking whether α = Σ ∗is EXPSPACE-hard.Proof sketch. Given a language A ∈ EXPSPACE decided by a DTM with an exponential-space bound s(n) = 2nk, we showa polynomial-time reduction f that on input ω of length n produces a REE f (ω) = α such that M accepts ω iff α = Σ ∗where the alphabet Σ only depends on M and |α| is polynomial in n.The idea is to let α denote all invalid or non-rejecting computation histories of M on ω. A rejecting computation historyof M on ω is a sequence of configurations (snapshots) of M in which the first configuration is the initial configuration of Mon ω, the last configuration is a rejecting configuration, and each configuration in the sequence follows from the precedingone from a single step of M. The REE α is defined to denote all strings that either do not begin with the initial configurationof M on ω, do not contain a rejecting configuration, or have a configuration that does not follow from the preceding one[56, pp. 344–347]. The size of α not counting the exponents is O (n log n), and counting the exponents is O (nk) since allexponents in α are in the set {1, . . . , n + 1, 2nk − n − 2, 2nk − 2, 2nk }. By construction, M accepts ω iff there is no rejectingcomputation history of M on ω (since M is deterministic) iff α denotes all strings over its alphabet. (cid:3)The computational models that correspond to regular expressions are deterministic and non-deterministic finite au-tomata. In the presence of exponents, the automata need to be extended with counters. We define a class of non-deterministic finite automata with counters (NFACs) that is simple yet sufficient for our needs; we could use the moregeneral NFACs of Haslum and Jonsson at the cost of getting more complex proofs.An NFAC is a non-deterministic finite automaton augmented with a set C of counters of bounded capacity. Each counterc ∈ C corresponds to a sub-expression of the form α ↑ k that is implemented with five states entryc , testc , continuec , exitcand loopc , and a capacity bound boundc . These elements are specific to the counter and thus are subscripted accordingly.We call the states in {entryc, testc, continuec, loopc, exitc: c ∈ C} as cstates and denote the latter set as cstates.The automaton for counter c associated with α ↑ k is shown in Fig. 2. The operation of the automaton is as follows.Initially, the counter is set to zero. Upon visiting entryc the counter is initialized to boundc and an (cid:13)-transition is madeto testc ; this is the only transition from entryc . In testc , the machine makes an (cid:13)-transition to either continuec or exitcdepending on whether c > 0 or not; these are the only transitions from testc and into continuec and exitc . In continuec , themachine makes an (cid:13)-transition to the initial state of α, and an (cid:13)-transition from the final state of α is made into loopc .Upon visiting loopc , the machine decrements the counter c and makes an (cid:13)-transition to testc ; the only transitions to testcare either from entryc or loopc .Formally, an NFAC M = (cid:2)Q , Σ, δ, q0, F , C(cid:3) consists of a set Q of states, an input alphabet Σ , a transition function δ : Q ×Σ → 2Q , an initial state q0 ∈ Q , a subset F ⊆ Q of accepting (final) states, and a set of counters C . Each counter has fivestates associated with it as described above. The language L(M) recognized by M is the set of words in Σ ∗that inducea path from the initial state q0 into an accepting state, the size of M is |M| def= |δ| +(cid:21)log boundc(cid:22), and the relationbetween REEs and NFACs is the following.c∈C(cid:20)Theorem 6. For each REE α there is an NFAC Mα of polynomial size in |α| such that ω ∈ α iff ω ∈ L(Mα). Conversely, for each NFACM there is a REE αM of polynomial size in |M| such that ω ∈ L(M) iff ω ∈ αM .Proof. Direct. Left to the reader. (cid:3)258B. Bonet / Artificial Intelligence 174 (2010) 245–269From now on we assume complete automata. An automaton M is complete if δ(q, a) is non-empty for all q ∈ Q anda ∈ Σ ∪ {(cid:13)}. A non-complete automaton can be easily transformed into a complete one by adding a non-accepting state qsinksuch that δ(q, a) = {qsink} for all (q, a) with δ(q, a) = ∅, and δ(qsink, a) = {qsink} for all a ∈ Σ ∪ {(cid:13)}. Furthermore, we assumewithout loss of generality, that there is exactly one transition from the states exitc into non-sink states which is labeledwith (cid:13).A configuration (snapshot) for M is a pair θ = (cid:2)q, ν(cid:3) such that q ∈ Q specifies the current state of M and ν : C → N spec-ifies the current value for each counter in M. A configuration is accepting if its state is accepting. The initial configurationof the automaton is the pair θ0 = (cid:2)q0, ν0(cid:3) where ν0(c) = 0 for all c ∈ C .The transition function δ can be extended into a function ˆδ that maps configurations and words in Σ ∗configurations such that θ (cid:11) ∈ ˆδ(θ, ω) iff the configuration θ (cid:11)including (cid:13)-transitions) (the details are in Appendix B). Thus, L(M) def= {ω ∈ Σ ∗tion}.into subsets ofcan be reached from θ through a path labeled with ω (perhaps: ˆδ(θ0, ω) contains an accepting configura-7.1. The proof of Haslum and JonssonThe EXPSPACE-hardness for conformant planning of fully-observable problems is established with a reduction from theto the problem of checking if a fully-observable planning problem has a conformant plan, andproblem of checking α (cid:16)= Σ ∗then using the fact that EXPSPACE is closed under complementation.Indeed, let α be a REE over alphabet Σ and M = (cid:2)Q , Σ, δ, q0, F , C(cid:3) an NFAC that recognizes α. The idea is to constructa planning problem P that simulates the extended transition function ˆδ. The states of the planning problem represent theconfigurations of M and thus can be denoted by [q, ν] for configuration (cid:2)q, ν(cid:3). The initial belief for P corresponds to thesingleton {[q0, ν0]}, and there are (non-deterministic) operators oa for each a ∈ Σ ∪ {(cid:13)}. The construction guarantees thatfor every pair of configurations (cid:2)q, ν(cid:3) and (cid:2)q(cid:11), ν(cid:11)(cid:3),(cid:21)q(cid:11), ν(cid:11)(cid:22)(cid:6)∈ Resπpadoa1πpadoa2πpad · · · πpadoan πpad,[q, ν](cid:18)(cid:19)(cid:7)(cid:2)qiff(cid:3)(cid:6)(cid:11), ν(cid:11)∈ ˆδ(cid:2)q, ν(cid:3), a1 · · · an,(cid:7)where πpad is a fixed sequence of o(cid:13) operators.If the goal is defined as being in a non-accepting configuration, then P has a valid linear plan iff α (cid:16)= Σ ∗. The keyissue for constructing P is that a counter of exponential capacity requires a polynomial number of bits and thus can berepresented with a polynomial number of fluents.In our case, we aim to show that deciding the existence of a linear plan for a partially-observable problems is 2EXPSPACE-hard, yet a direct simulation of NFACs with counters of double-exponential capacity does not work since it requires aplanning problem with an exponential number of fluents. However, more compact encodings of counters can be achievedwhen collections of belief states instead of just belief states are considered.8. Compact representation of countersLet c be a counter of exponential size, and hence of double-exponential capacity, with bits ci for 0 (cid:5) i < 2n, and let Pbe a planning problem with n propositional “markers” mc,k for 0 (cid:5) k < n (often simply denoted by mk when c is clear fromcontext). We will show how to encode a value for c as a collection of subsets of markers.To illustrate the idea, observe that a value for c can be represented as the collection of positions for the 1-bits in thebinary expansion of c; i.e. by the set {i: ci = 1}. For example, the value 72 = 01001000bin is represented by the set {3, 6}since the 1-bits in the binary expansion of 72 are the third and the sixth bit (the least-significant, the rightmost, is thezeroth bit). This representation cannot be used directly since there is an exponential number of positions. However, if eachposition is further represented in binary using the markers, then the value of a counter can be represented with a collectionof subsets of markers. In the example, the value 72 is represented by the collection {{m0, m1}, {m1, m2}} since 3 = 20 + 21and 6 = 21 + 22. In general, the value of a counter is represented by the following collection of subsets of markers:(cid:18)(cid:18)bc =mc,k: (kth bit in ibin) = 1: ci = 1.(cid:19)(cid:19)For example, the collection {∅} represents the value c = 1 = 00000001bin since the unique 1-bit is in position 0,{{m0}, {m2}} represents the value c = 18 = 00010010bin since the positions of the 1-bits are {1, 4} that written in binaryare {001bin, 100bin}, and {∅, {m0, m1, m2}} represents the value c = 129 = 10000001bin since the positions of the 1-bits are{0, 7} = {000bin, 111bin}.In addition to the propositional markers, we use a proposition ‘ Ac ’ that indicates whether a subset of markers is activefor counter c in a given representation; when c is clear from context, we just write A. Non-active subsets are ignored whenperforming operations on c yet their existence alleviates the complexity of some operations. Hence, for example, the valuec = 72 is represented by the belief {{m0, m1, A}, {m1, m2, A}}. From now on, we use the notation c ∼ b to denote that thecounter c is represented by the belief state b.8.1. Arithmetic on countersIn order to simulate NFACs with planning problems, we need to perform simple arithmetics on counters such as com-parisons and decrement operations.B. Bonet / Artificial Intelligence 174 (2010) 245–269259Let c be a counter and b a belief state such that c ∼ b. Then, c = 0 iff there is no active state in b, and c > 0 iff there is atleast one active state. These two conditions are written in propositional modal logic as ¬ Ac and ♦ Ac which are abbreviatedas ‘c = 0’ and ‘c > 0’ respectively. Notice that Ac cannot be used to test c > 0 since the former holds iff each state in b isactive. As we will see, the decrement operation may render some active states s ∈ b inactive.The decrement operation must subtract one from the value of the counter. For example, it must change the value72 = 01001000bin represented by b72 = {{m0, m1, A}, {m1, m2, A}} into the value 71 = 01000111bin represented by b71 ={{ A}, {m0, A}, {m1, A}, {m1, m2, A}}. That is, the subset {m0, m1, A} needs to be replaced by the subsets { A}, {m0, A} and{m1, A}. The general principle involved is to replace the subset for the least-significant 1-bit (the first 1 from right to leftin c’s binary expansion) with the subsets that represent all bits of less significant value. We thus need to first identify thesubset to replace and then to generate the replacement subsets.For the first task, we consider a sequence of effects that progressively isolate the active subsets that represent the least-significant 1-bit. At the beginning, all active subsets are flagged with the proposition ‘minc ’ using the effect Ac (cid:2) minc . Then,for k = n to k = 0, effects that filter out flagged subsets that are dominated with respect to the mk marker are applied insuccession. These effects have the formflagcdef= Ac (cid:2) minc,(cid:6)def=minc ∧mc,n−1 ∧ ♦(cid:6)minc ∧¬mc,n−1(cid:7)(cid:7)(cid:2) ¬ minc,filterc,n−1...filterc,0def=(cid:6)minc ∧mc,0 ∧ ♦(cid:6)minc ∧¬mc,0(cid:7)(cid:7)(cid:2) ¬ minc .In the example, if we apply the succession of effects (cid:2)flag, filter2, filter1, filter0{m1, m2, A}} in which the subset to replace is the one flagged with min.(cid:3) to b72, we obtain the belief {{m0, m1, A, min},Once the subset to replace is identified, the replacements are generated by processing each marker in parallel. In theexample, the least-significant corresponds to {m0, m1, A}. The decrement operation must clear this bit and turn on the 2nd,1st and 0th bits since 72 = 01001000bin is converted into 71 = 01000111bin. Thus, this state must be replaced by { A},{m0, A} and {m1, A}.The replacement effect processes each marker mk non-deterministically from k = 0 to k = n. The non-determinism isutilized to implement the parallel execution of individual effects, one per marker, whose results are then joined together.The effects are defined as:• clear the flagged status,• if no marker holds, then invalidate the state,• if mk holds, then clear mk and non-deterministically flip each marker m j for 0 (cid:5) j < k.In the example, the state s = {m0, m1, A, min} needs to be replaced. Since m2 does not hold in s, its processing generatesnothing. The processing of m1 clears m1 and flips m0 generating { A} and {m0, A}, The processing of m0 clears m0 and flipsnothing generating {m1, A}. Therefore, the overall effect is the collection {{ A}, {m0, A}, {m1, A}}.Let us illustrate this further with a decrement on b71 = {{ A}, {m0, A}, {m1, A}, {m1, m2, A}}. After the identification effects,the belief is transformed into {{ A, min}, {m0, A}, {m1, A}, {m1, m2, A}} so the subset to replace is { A, min} which correspondsto the least-significant 1-bit. Because this state satisfies no marker, the effect of the replacement is to invalidate the state byclearing the fluent A. Hence, the belief transforms into {∅, {m0, A}, {m1, A}, {m1, m2, A}} that represents 70 = 01000110binsince the empty subset is non-active.The decrement operation is implemented by the following sequence of n + 2 operatorsdecrement(c) def=(cid:2)(cid:2)(cid:6), flagc(cid:3), (cid:2)(cid:6), filterc,n−1(cid:3), . . . , (cid:2)(cid:6), filterc,0(cid:3), (cid:2)(cid:6), replacec(cid:3)(cid:3),where the replacec effect is(cid:23)(cid:24)¬ minc ∧minc ∧(cid:25)(cid:26)(cid:23)(cid:24)¬mc,k(cid:2) ¬ Ac∧minc ∧(cid:25)(cid:26)mc,k(cid:2)n−1(cid:14)k=0n−1(cid:12)k=0(cid:23)(cid:24)n−1(cid:27)mc,k (cid:2) ¬mc,k ∧k−1(cid:12)k=0j=0(cid:25)(cid:26)(mc, j ⊕ ¬mc, j).The subsequence of the first n + 1 operators is called the identification stage and the last operator is called the replacementstage. The correctness of the arithmetic operations are summarized in the following result.Theorem 7. Let c be a counter and b a belief state such that c ∼ b. Then,(a) c = 0 iff b (cid:4) ¬ Ac ,(b) c = 1 iff b (cid:4) ♦ Ac ∧ ( Ac →(cid:4)nk=0¬mc,k),260B. Bonet / Artificial Intelligence 174 (2010) 245–269(c) c > 1 iff b (cid:4) ♦( Ac ∧(d) if c = 0, then c ∼ Res(decrement(c), b),(e) if c > 0, then c − 1 ∼ Res(decrement(c), b).(cid:28)nk=0 mc,k),Proof. Claims (a)–(c) are direct. For (d), if c = 0 then no state is flagged since none is active. Therefore, replacec has noeffect on b.For (e), we first show that the identification stage is correct. That is, the states that remain flagged after the identificationcorrespond to the least-significant 1-bit of c. The correctness of the identification is a direct consequence of the followingfacts:– After applying flagc , all active states are flagged.– After applying filterc,k, all flagged states agree on the interpretation of markers mc,(cid:7) for (cid:7) (cid:6) k. This is true for k = n − 1. Assumethat is true for k + 1. Then, after filterc,k is applied, all resulting states satisfy mc,k or all resulting states satisfy ¬mc,k.– At the end, all flagged states agree on the interpretation of all markers. Direct by previous fact.– At the end, there is at least one flagged state. Since c > 0, there is some active state that is initially flagged. Suppose thatthere are no flagged states at the end, and let k be the integer such that the input belief b to filterc,k has some flagged(cid:11) ∈ b such thatstates, and its output has none. Then, it must be the case that for each flagged s ∈ b there is a flagged smc,k ∈ s and mc,k /∈ s. But then, filterc,k cannot clear the flag of scontradicting the choice of k.(cid:11)(cid:11)– There is a flagged state that corresponds to the least-significant 1-bit. Suppose this is not true. Then, since the state s for the(cid:11)least-significant 1-bit is initially flagged, there is k such that filterc,k clears the flag in s, and thus there is a flagged ssuch that mc,k ∈ s and mc,k /∈ s. Since all states before applying filterc,k agree on the interpretation of markers mc,(cid:7), for(cid:7) > k, then scorresponds to a less significant 1-bit than s contradicting the choice of s.(cid:11)(cid:11)We now show that the replacement stage is correct. Let b = {s1, . . . , sp, s} be the input belief to replacec where s is the(cid:11)}flagged state that represents the least-significant 1-bit. We must show that replacec generates a belief {s1, . . . , sp, sq(cid:11)in which the states si represent all bits of lesser significance than s. We consider two cases whether s represents the 0thbit or other bit. In the first case, s has no markers. Then, replacec clears the active fluent and thus decrements the counterby one unit.(cid:11)1, . . . , sSuppose now that s contains the markers {mi1 , . . . , mi(cid:7)} for some 0 (cid:5) i1 < · · · < i(cid:7) < n. The bits of less significance thans are in correspondence with the subsets in{mik+1 , . . . , mi(cid:7)} ∪ C : C ∈ ℘(cid:6){m0, m1, . . . , mik−1}(cid:7)(cid:19),(cid:7)(cid:5)(cid:18)k=1(1)where ℘ ( A) denotes the power set of A. We show that replacec generates these subsets only. Since s satisfies somea∈ A(a ⊕ ¬a)marker, we only need to consider the second conditional effect. Notice that for any subset A the effectik−1ik−1j=0 (m j ⊕ ¬m j) generatesj=0 (m j ⊕ ¬m j) generates ℘ ({m0, . . . , mik−1}) and thus ¬mikgenerates ℘ ( A). Therefore,{{mik+1 , . . . , m(cid:7)} ∪ C : C ∈ ℘ ({m0, . . . , mik−1})} when applied at s. Finish by observing that the second conditional effect(cid:4)translates intoik−1j=0 (m j ⊕ ¬m j)] when applied at s. (cid:3)(cid:29)(cid:7)k=1[¬mik(cid:4)(cid:4)(cid:4)∧∧The problem of identifying the subset of markers that correspond to the least-significant bit is related to the problem ofselecting the preferred state in the belief state with respect to a lexicographic preference order defined with the markersmi : a state s is preferred over state sagree on theiff there is k such that s makes true mk and sinterpretation of all markers m(cid:7) for (cid:7) > k. There is no modality-free formula ϕ that selects the preferred state in a beliefstate, i.e. s (cid:4) ϕ iff s is preferred in b, nor we know of a short (polynomially long) modal formula able to do so. This is themain reason for performing the identification stage during the decrement operation on counters.does not, and s and s(cid:11)(cid:11)(cid:11)We finish this section by noticing that multiple counters can be simultaneously encoded as cross-products of subsetsof markers. Since the markers, the active fluents and the min fluents are all tagged with the counters, we can performarithmetic operations on different counters simultaneously.The compact encoding of counters and their arithmetic operations are the main tools needed to show the lower boundson the complexity of decision problems.9. Hardness resultsThe EXPSPACE-hardness of plan-fo-branch(k) is shown by giving polynomial-time reductions from plan-fo-branch(k)to plan-fo-branch(k + 1) for all k (cid:6) 0. Since plan-fo-branch(0) is EXPSPACE-hard [27], then plan-fo-branch(k) isalso EXPSPACE-hard for all k (cid:6) 0. This result together with the inclusion results establish exact complexity bounds forplan-fo-branch(k).B. Bonet / Artificial Intelligence 174 (2010) 245–269261Theorem 8. For k (cid:6) 0, plan-fo-branch(k) is polynomial-time reducible to plan-fo-branch(k + 1). Therefore, plan-fo-branch(k)and plan-fo-branch are EXPSPACE-complete.Proof. Let P = (cid:2)D, I, G, O (cid:3) be a planning problem with full observability. We need to construct a fully-observable problemP(cid:11)(cid:3) such that P has a k-plan iff Phas a (k + 1)-plan. The problem Pis defined as follows:(cid:11) = (cid:2)D(cid:11), O(cid:11), G(cid:11), I(cid:11)(cid:11)I(cid:11) = D ∪ {p, q1, q2, r},D(cid:11) = I ∧ ¬p ∧ ¬q1 ∧ ¬q2 ∧ ¬r,(cid:11) = r,G(cid:18)(cid:11) =(cid:2)¬p ∧ ϕ, α(cid:3): (cid:2)ϕ, α(cid:3) ∈ OO(cid:19)(cid:18)o1 =(cid:3)(cid:2)¬p ∧ G, p ∧ (q1 ⊕ q2)(cid:19), o2 = (cid:2)p ∧ q1, r(cid:3), o3 = (cid:2)p ∧ q2, r(cid:3),∪where p, q1, q2 and r are new propositional symbols, and o1, o2 and o3 are new operators. Clearly, the problem Pconstructed from P in polynomial time.(cid:11)We claim that P has a k-plan iff Phas a (k + 1)-plan. Indeed, let π be a k-plan for P . That is, π makes at most kobservations along each branch, and each branch finishes at a state that satisfies G. If at the end of each branch, we applyoperator o1 followed with an observation, to separate the states that satisfy q1 from the ones that satisfy q2, and finallyapply o2 and o3 depending on whether q1 or q2 is satisfied, then we have a (k + 1)-plan for Pmust be o2 or o3. Thus, the secondto last operator must be o1. After o1 is applied, there are states that satisfy q1 and states that satisfy q2. Therefore, π (cid:11)must make a branch (observation) after the application of o1 in order to separate these states. Since the precondition of o1includes the goal G of P , then the branches of π (cid:11)up to the application of o1 form k-plan for P . (cid:3). The last operator along a branch in π (cid:11)be a (k + 1)-plan for PConversely, let π (cid:11).(cid:11)(cid:11)(cid:11)can beWe now show the 2EXPSPACE-hardness result for partially-observable domains. The proof idea is similar to the one usedby Haslum and Jonsson except that we need to deal with counters of double-exponential capacity. Let us first revise theproof of Theorem 5 (cf., e.g., [56]). Given a DTM M with an exponential-space bound e(n) = 2p(n), with p(n) = nk, and aof size n, let α = α(M, ω) be a REE of polynomial length in |M| + n such that M accepts ω iff α = Σ ∗word ω ∈ Σ ∗.If the space bound is replaced with a double-exponential space bound, α remains the same except that the exponentsin α change from exponential to double-exponential. Indeed, for the space bound e(n), the exponents in α are among{1, . . . , n + 1, 2nk − n − 2, 2nk − 2, 2nk }, while for a space bound of the form d(n) = 22p(n), the exponents are among {1, . . . , n +1, 22nk}. Thus, for double-exponential space bounds, counters of double-exponential capacity must beused.− n − 2, 22nk− 2, 22nkTheorem 9. plan-po-linear is 2EXPSPACE-hard. Hence, plan-po-linear and plan-po-branch are 2EXPSPACE-complete.Proof. Let M be a DTM with a double-exponential space bound d(n) = 22p(n), where p(n) = nk is a polynomial in n, andω ∈ Σ ∗be an input word for M of length n. Consider the REE α = α(M, ω) given in the proof of Theorem 5 but for the spacebound d(n). The size of α is exponential yet, if the sizes of the exponents are not accounted for, |α| is polynomial in |M| + n.Let Mα = (cid:2)Q , Σ, δ, q0, F , C(cid:3) be the NFAC for α in which |δ| is polynomial in |M| + n while(cid:21)log boundc(cid:22) is exponential.We are going to construct, in polynomial time, a planning problem P with partial observability such that its linear planssimulate the NFAC. The main idea is to encode the configurations of Mα as the belief states of P as described in Section 8. Theconstruction will guarantee that L(Mα) (cid:16)= Σ ∗iff P hasa valid linear plan. Since 2EXPSPACE is closed under complementation, then plan-po-linear is 2EXPSPACE-hard.iff P has a valid linear plan. Therefore, M rejects ω iff L(Mα) (cid:16)= Σ ∗c∈C(cid:20)From the NFAC Mα = (cid:2)Q , Σ, δ, q0, F , C(cid:3), define the planning problem P = (cid:2)D, I, G, O , Z (cid:3) as follows. The fluents in P isthe collection of symbols for:– representing the state of the machine: {q: q ∈ Q },– representing the value of counters: { Ac, minc, mc,k: c ∈ C, 0 (cid:5) k (cid:5) p(n)}, and– the execution mode: {normal, initc, decc,k, flagc, filterc,(cid:7), replacec: c ∈ C, 0 (cid:5) k (cid:5) n + 2, 0 (cid:5) (cid:7) (cid:5) p(n)}.The observable symbols are just the symbols for the state of the machine, i.e. Z = {q: q ∈ Q }. The reason for this is thatsince belief states represent configurations of the machine, each belief state must make one and only one such symbol true.Making them observable, forces the beliefs in the collection B to satisfy this property. Each symbol has a precise role whichwill become clear as we describe the construction of P .The descriptions I and G reflect the initial and non-accepting configurations respectively:(cid:12)(cid:18)¬p: p ∈ D \ {q0, normal}(cid:19),def= q0 ∧ normal ∧(cid:14)def= normal ∧IGq.q /∈F262B. Bonet / Artificial Intelligence 174 (2010) 245–269Formula I encodes the initial configuration of Mα with state q0 and the value of all counters set to 0 (since all active fluentsare off). Formula G encodes all non-accepting configurations in which the state of Mα is not in F . The symbol normal isused to express that the current belief states faithfully represent the possible configurations of Mα . It is turned off wheneversome transformation involving more than one operator, e.g. when decreasing the value of a counter, is being applied, andrestored when the transformation finishes.The planning operators are divided in two classes O = {oa: a ∈ Σ ∗ ∪ {(cid:13)}} ∪ {oinit, oset, odec}. Operators in the first classimplement the transition function δ while operators in the second class implement arithmetic operations on counters.Operators in the first class execute in normal mode and all have the format(cid:17)(cid:7)(cid:6)q (cid:2) α(q, a)normal,(cid:12)(cid:16),oa =q∈Qwhere α(q, a) is the effect associated to state q on input a ∈ Σ ∪ {(cid:13)}. For states q ∈ Q \ cstates, these areα(q, a) def=⎩(cid:29)⎧⎨(cid:6) ⊕(cid:29)q(cid:11)∈δ(q,a)\{q}(¬q ∧ qq(cid:11)∈δ(q,a)(¬q ∧ q(cid:29)(cid:11))(cid:6) ⊕q(cid:11)∈δ(q,(cid:13))(¬q ∧ q(cid:11))(cid:11))if a (cid:16)= (cid:13), q ∈ δ(q, a),if a (cid:16)= (cid:13), q /∈ δ(q, a),if a = (cid:13),where (cid:6) is the empty or null effect, used in cases when the transition may leave the state of the automata unchanged.As seen in the previous section, some arithmetic operations are implemented as sequences of operators. We enforcesuch sequences with a change on the execution mode obtained by deleting the fluent normal. Arithmetic operations canonly occur for transitions on the cstates associated with the counters. In states testc , there are (cid:13)-transitions to the statescontinuec and exitc depending on whether the counter is greater than or equal to zero. In states continuec and exitc , there are(cid:13)-transitions to the unique states in δ(continuec, (cid:13)) and δ(exitc, (cid:13)) respectively. And, in states loopc , there is an (cid:13)-transitionto the state testc and the counter is decremented. Furthermore, all transitions in cstates on a symbol a ∈ Σ lead to the sinknode. These effects are the following:(cid:21)(cid:22)¬testc ∧ (c > 0 (cid:2) continuec) ∧ (c = 0 (cid:2) exitc),α(testc, (cid:13)) def= (cid:6) ⊕α(continuec, (cid:13)) def= (cid:6) ⊕α(loopc, (cid:13)) def= (cid:6) ⊕ [¬loopcα(exitc, (cid:13)) def= (cid:6) ⊕α(q, a) def= ¬q ∧ qsink,(cid:21)(cid:22)(cid:21)¬continuec ∧ δ(continuec, (cid:13)),∧ testc ∧ ¬normal ∧ decc,1],(cid:22)¬exitc ∧ δ(exitc, (cid:13)),for q ∈ cstates, a ∈ Σ.The effect for loopc changes the execution mode from normal to decc,1 in order to decrement the counter c by one unitthrough a sequence of operators. The mode decc,1 is an instance of the more general execution mode decc,k which performsa decrement of the counter c by k units. The operators and effects that implement the decrement operations are:(cid:16)def=odectrue,(cid:17)decc,k (cid:2) βdec(c, k),(cid:12)c,kβdec(c, k) def= ¬decc,k ∧ rdecc,k−1 ∧ flagc,βdec(c, 0) def= ¬decc,0 ∧ normal,(cid:12)(cid:16)def=oflagtrue,flagc(cid:16)ofilterdef=true,c(cid:12)c,kfilterc,k(cid:2) (¬flagc∧ filterc,p(n)(cid:17)(cid:2) βfilter(c, k),(cid:17)∧ flagc),βfilter(c, k) def= ¬filterc,kβfilter(c, 0) def= ¬filterc,0(cid:16)(cid:12)oreplacedef=true,∧ filterc,k−1∧ replacec∧ filterc,k,∧ filterc,0,(replacec∧ rdecc,k) (cid:2) (¬replacec(cid:17)∧ decc,k ∧ replacec).c,kWe claim that once the fluent decc,k becomes true in a belief state b, the only way to resume normal execution mode isto perform an appropriate sequence of odec, oflag, ofilter and oreplace operators so that the value of the counter c denoted byb is decremented by k units. Indeed, once decc,k is true and normal is false, odec is the only operator that has an effect. ItsB. Bonet / Artificial Intelligence 174 (2010) 245–269263effect is to clear decc,k and set the fluents rdecc,k−1 and flagc ; the first will force a new application of odec while the secondinitiates the decrement operation on the counter c. Once flagc is true, the only operator that has an effect is oflag whichperforms the flag effect (cf., Section 8), clears flagc and sets filterc,p(n). At this stage, the operator ofilter must be appliedp(n) + 1 times thus performing the sequence of effects filterc,p(n), filterc,p(n)−1, . . . , filterc,0; the (n + 1)st application clearsfilterc,0 and sets replacec to force the application of oreplace. The operator oreplace applies the effect replacec and changes thefluent rdecc,k by decc,k in order to force additional decrement operations. At the end, the last operator odec changes thefluent decc,0 by normal and the normal execution mode resumes. Observe that when normal becomes true, it becomes trueat all belief states and that the state of the automata is the one when the normal fluent was deleted; e.g. testc in the caseof α(loopc, (cid:13)).There is just one last thing to do which is define the (cid:13)-transitions for the states entryc that initialize the value of thecounters to c = boundc and change state to testc . In general we cannot set a counter of double-exponential capacity to anarbitrary value using operators of polynomial size. However, the exponents to consider are among {1, . . . , n + 1, 22p(n) − n −2, 22p(n) − 2, 22p(n) } and such values can be set with operators of polynomial size. Indeed, let us begin with the effect(cid:13)α(entryc, (cid:13)) def= (cid:6) ⊕¬entryc∧ testc ∧ ¬normal ∧ initc ∧ Ac ∧(cid:15)(cid:12)k¬mc,kthat sets the active fluent and clears all markers for c, changes the execution mode from normal to initc , and sets thestate of the automata to be testc once normal execution mode is restored. As before, the initialization for some values mayinvolve several operators and this is the reason for the change of execution mode. Once in initc mode, the initialization isdone with the operator(cid:12)(cid:16)def=oinittrue,c(cid:17)initc (cid:2) βinit(c).The effect βinit(c) depends on the counter c. Let us partition the counters into those with at most exponential capacity,denoted by Ce , and those with double-exponential capacity denoted by Cd. A counter c ∈ Ce has at most a polynomialnumber of 1-bits, thus it can be directly initialized with the effectβinit(c) def= ¬initc ∧ normal ∧(cid:27)(cid:11)(cid:12)(cid:18)(cid:6)kth bit of [i]bit(cid:7)(cid:19)(cid:6):= 1ith bit of [boundc]bit(cid:7)= 1mc,k:!that creates one state for each 1-bit in the target value for the counter c, and sets the markers appropriately. For counters inand then decremented 22p(n) − boundc times (which is a polynomial number of times)c ∈ Cd, the value is first set to 22p(n)to reach the target value boundc . The value 22p(n)corresponds to the unique bit mc,p(n) and the decrements are forced bysetting the execution mode to the appropriate decc,k:βinit(c) def= ¬initc ∧ decc,22p(n) −boundc∧ mc,p(n).For example, to set the counter c to the value 22p(n) − n − 2, the counter is first set to the value 22p(n)and then decrementedn + 2 times. Double-exponential counters have initial values among {22p(n) − n − 2, 22p(n) − 2, 22p(n) } and thus the number ofeffects of type βdec(c, k) and βfilter(c, k) is polynomial.In this case, a configuration (cid:2)q, ν(cid:3) for Mα is represented by a belief state denoted as {q, ν}. The construction of P isfaithful in the sense that for any pair of configurations (cid:2)q, ν(cid:3) and (cid:2)q(cid:19)(cid:7)(cid:19)(cid:18)(cid:18)q(cid:11), ν(cid:11)(cid:6)∈ Res(cid:11), ν(cid:11)(cid:3) for Mα ,∈ ˆδ, ν(cid:11)(cid:11)(cid:2)qiff(cid:3)(cid:6)πpadoa1πpadoa2πpad · · · πpadoan πpad,{q, ν}where ˆδ is the extended transition function for the NFAC Mα (see Appendix B). The subsequence πpad is a long enoughsequence of operators in {o(cid:13) , odec, oflag, ofilter, oreplace, oinit} that guarantees the belief states are always updated with respectto the NFAC. Indeed, it suffices to define πpad as 2N , N = |Q | × Πc∈C (1 + boundc), repetitions of (cid:2)o(cid:13) , oinit, oflag, πfilter, oreplace(cid:3)where πfilter is a sequence of 1 + p(n) repetitions of ofilter. Therefore, P has a valid linear plan iff L(Mα) (cid:16)= Σ ∗iff M rejects ω.Since 2EXPSPACE is closed under complementation, we have that plan-po-linear is 2EXPSPACE-hard. (cid:3)(cid:2)q, ν(cid:3), a1 · · · an,(cid:7)Finally, combining the simulation of counters of double-exponential capacity with reductions among partially-observableproblems, as done in Theorem 8, we obtainTheorem 10. For every k (cid:6) 0, plan-po-branch(k) is 2EXPSPACE-hard. Hence, plan-po-branch(k) and plan-po-branch are2EXPSPACE-complete.10. Problems without modal formulae and polynomial plansTurner [61] studies the complexity of deciding the existence of plans of polynomial length using quantified booleanformulae (QBFs). He shows that deciding the existence of linear plans of polynomial length for fully-observable problems264B. Bonet / Artificial Intelligence 174 (2010) 245–269is in Σ P3 , and that deciding the existence of contingent plans of polynomial length is PSPACE-complete for problems witheither full or partial observability. However, Turner uses a different representation language which is based on factored rela-tions between states. With our representation language, in which the applicability of the actions can be decided efficiently,Turner results translate into a Σ P2 completeness for checking the existence of linear plans for fully-observable problems.Following the ideas of Turner, we study the complexity of checking the existence of plans of polynomial length forproblems with no modal formulae and the complexity of checking the existence of linear plans, of arbitrary length, forproblems with no modal formulae. Partially-observable problems with no modal formulae are currently predominant inautomated planning and thus important to consider as a special case.10.1. Plans of polynomial length for problems without modal formulaeLet us begin with a formal definition of the decision problems considered. Let q(n) be a polynomial. A class P of planningproblems has valid plans of polynomial length (modulo q) iff each problem P in P has a valid plan of length at most q(|P |);recall that the length of a branching plan is its height. Since q is fixed, we should consider decision problems with respectto q. However, we can remove this dependency by defining the following decision problems:• plan-fo-branch-lenPL(k) def= {(cid:2)P , 1N (cid:3): P is a FOP[PL] with a k-plan of length at most N},def= {(cid:2)P , 1N , 1k(cid:3): P is a FOP[PL] with a k-plan of length at most N},• plan-fo-branch-lenPL• plan-po-branch-lenPL(k) def= {(cid:2)P , 1N (cid:3): P is a POP[PL] with a k-plan of length at most N},def= {(cid:2)P , 1N , 1k(cid:3): P is a POP[PL] with a k-plan of length at most N},• plan-po-branch-lenPLwhere FOP[PL] and POP[PL] denote the class of planning problem with full observability and no modal formulae and withpartial observability and no modal formulae respectively. Observe that the integers N and k are written in unary.Thus, for example, if we need to check whether a problem P in FOP[PL] has a valid k-plan of length q(|P |), then it isenough to check whether (cid:2)P , 1q(|P |)(cid:3) ∈ plan-fo-branch-lenPL(k). Therefore, a function that on input (cid:2)P (cid:3) outputs (cid:2)P , 1q(|P |)(cid:3)is a polynomial-time reduction from the problem of deciding the existence of a k-plan of polynomial length (modulo q) toplan-fo-branch-lenPL(k).We show that plan-fo-branch-lenPL(k) and plan-po-branch-lenPL(k) are both Σ P2k+2-complete, and that plan-fo-branch-lenPL and plan-po-branch-lenPL are both PSPACE-complete.Consider a fully-observable problem P = (cid:2)D, I, G, O (cid:3) with no modal formulae, a fixed planning horizon N and integer k.As it is usual in SAT-based approaches for planning [36], we encode problem P into a propositional theory whose proposi-tions refer to the operators and fluents in P tagged with time indices. We use propositions ft to denote the truth value offluent f at time t, and propositions ot to denote the application of operators at time t. There are more efficient translationsthat use (cid:21)log |O |(cid:22) propositions to represent the operators, yet we will not dive into such tedious details.We use the formula preo( f 1), with free variables among the fluents f tagged at time 1, to denote the precondition ofthe operator o, and the formula dyno( f 1, f 2), with free variables among the fluents tagged at times 1 and 2, to denote theeffects of the operator o. For example, if o = (cid:2)p, q(cid:3) then preo = p1 and dyno =f (cid:16)=q( f 2 ≡ f 1) ∧ q2. These low-level formulaeare collected into the following formulae(cid:4)(cid:12)Ψpre(o1, f 1) =o∈OΨdyn(o1, f 1, f 2) =(cid:6)(cid:7)o1 = o ⇒ preco( f 1)(cid:12),(cid:6)(cid:7)o1 = o ⇒ dyno( f 1, f 2)o∈Othat have free variables among operators at time 1 and fluents at time 1 and 2. The notation Ψpre(ot, ft) andΨdyn(ot, ft, ft+1) refers to the substitution of propositions o1,ft and ft+1 respectively. Finally, let Itand Gt refer to the formulae for the initial and goal situations tagged at time t.f 1 and f 2 by ot ,We now describe how the decision problem for P is encoded using QBFs. As an example, let us begin with a formula thattells whether there is a linear plan of length 1 for P . That is, one action that when applied at every initial state generates agoal state. This formula is(∃o1∀ f 1 f 2)(cid:7)I1 ⇒ Ψpre(o1, f 1)I1 ∧ Ψdyn(o1, f 1, f 2) ⇒ G 2(cid:7)(cid:22)(cid:21)(cid:6)∧(cid:6)since I1 ⇒ Ψpre(o1, f 1) is valid only when o1 is applicable at each initial state, and I1 ∧ Ψdyn(o1, f 1, f 2) ⇒ G 2 is valid onlywhen each state that result from the application of o1 is a goal state.Likewise, the following formula tells whether there is a plan that makes one observation whose first segment have twooperators and the second one operator:(∃o1o2∀ f 1 f 2 f 3∃o3∀ f 4)(cid:7)I1 ⇒ Ψpre(o1, f 1)(cid:7)I1 ∧ Ψdyn(o1, f 1, f 2) ⇒ Ψpre(o2, f 2)(cid:21)(cid:6)∧(cid:6)B. Bonet / Artificial Intelligence 174 (2010) 245–269265(cid:6)(cid:6)(cid:7)I1 ∧ Ψdyn(o1, f 1, f 2) ∧ Ψdyn(o2, f 2, f 3) ⇒ Ψpre(o3, f 3)I1 ∧ Ψdyn(o1, f 1, f 2) ∧ Ψdyn(o2, f 2, f 3) ∧ Ψdyn(o3, f 3, f 4) ⇒ G 4∧∧(cid:7)(cid:22).If we assume the existence of no-ops, this formula also determines the existence of a 1-plan with a first segment of lengthat most 2 and a second segment of length at most 1, and also determines the existence of a linear plan of length at most 2.If we want to check for the existence of a linear plan of length at most N, we use(∃o1 · · · oN ∀ f 1 · · · f N+1)(cid:7)I1 ⇒ Ψpre(o1, f 1)(cid:7)I1 ∧ Ψdyn(o1, f 1, f 2) ⇒ Ψpre(o2, f 2)(cid:21)(cid:6)∧(cid:6)· · ·(cid:6)∧∧(cid:6)(cid:7)I1 ∧ Ψdyn(o1, f 1, f 2) ∧ · · · ∧ Ψdyn(oN−1, f N−1, f N ) ⇒ Ψpre(oN , f N )I1 ∧ Ψdyn(o1, f 1, f 2) ∧ · · · ∧ Ψdyn(oN , f N , f N+1) ⇒ G N+1(cid:7)(cid:22).In general, when we want to check for the existence of a k-plan of length at most N, we usePlanFO(k, N) = (∃o1 · · · oN ∀ f 1 · · · f N+1 · · · ∃okN+1 · · · o(k+1)N ∀ fkN+2 · · · f(k+1)N+1)[Ψ ∧ Φ],where the formula Ψ (o1, . . . , o(k+1)N , f 1, . . . , f(k+1)N+1) is a conjunction of implications as in the examples, and Φ(o1, . . . ,o(k+1)N ) verifies that the number of non-no-op operators is less than or equal to N by using additional propositions in order tohave polynomial size in k and N.Theorem 11. For k (cid:6) 0, plan-fo-branch-lenPL(k) is Σ P2k+2-complete.inclusion, note that PlanFO(k, N) has 2k + 2 alternations. Hence, given an instanceinProof. Forplan-fo-branch-lenPL(k), where k is constant, construct in polynomial time the formula PlanFO(k, N) and then call adecision algorithm for Σ P(cid:2)P , 1N (cid:3)It remains to show hardness. We show for k = 1 since the proof for general k is similar. Consider a formula Φ =(∃x1∀ y1∃x2∀ y2)Ψ . We need to construct a fully-observable problem P , with size polynomial in |Φ|, such that P has a valid1-plan iff Φ is valid. Since Φ has 4 quantifiers, this implies hardness for Σ P4 .2k+2 problems.Without loss of generality, assume that xi and yi have two boolean variables each, say x11x22)Ψ . The problem P has two propositions x(∃x1and whether it has been set or not, and one proposition yji for each x1 y22 y2∀ y1∀ y12x2∃x1211i , x2i , so that Φ =jji and si -variable that denote their truth valueji -variable that denotes their truth value. The initial(cid:4)∧ Ψ respectively. The operators are:i and y1i , y2and goal states for P are defined by Idef=ji for each ydef=ji , and G¬xji∧ ¬sjii, j∧ ¬ y(cid:4)(cid:6)(cid:6)(cid:6)(cid:6)setsetsetsetx11, Tx21, Tx12, Tx22, T(cid:7)(cid:7)(cid:7)(cid:7)def=def=def=def=(cid:2)¬s1"1, s11(cid:3),∧ x11¬s21∧ s11, s21∧ x21∧(cid:2)¬s12"∧ s21, s12(cid:3),∧ x12¬s22∧ s12, s22∧ x22∧#(cid:7)#(cid:7),,yj1⊕ ¬ yj1yj2⊕ ¬ yj22(cid:12)(cid:6)j=12(cid:12)(cid:6)j=1(cid:7)(cid:7)(cid:7)(cid:7)(cid:6)(cid:6)(cid:6)(cid:6)setsetsetsetx11, Fx21, Fx12, Fx22, Fjii, j s(cid:2)def=(cid:3),∧ ¬x111, s11¬s1"def=¬s21∧ s11, s21∧ ¬x21∧def=def=(cid:2)¬s12"∧ s21, s12(cid:3),∧ ¬x12¬s22∧ s12, s22∧ ¬x22∧#(cid:7),#(cid:7).yj1⊕ ¬ yj1yj2⊕ ¬ yj22(cid:12)(cid:6)j=12(cid:12)(cid:6)j=1We claim that Φ is valid iff P has a valid 1-plan. The necessity is direct. For the sufficiency, assume that P has a valid1-plan. By construction, the operators need to be applied in order to set the values for x12. Let us consider the4 possible positions for the branch point (observation):2 and x21, x11, x2Case 1: before x1the y’s. Since the plan is valid, this means that Φ(cid:11) = (∃x11 is set. Since this is the only branch point, the value for the x’s are set without observing the values for2x22)Ψ is valid. Clearly, Φ(cid:11) ⇒ Φ.∀ y11. This case is similar to the previous one, and corresponds to the same Φ(cid:11)1 is set but before x2formula as2 y21 y11 y21x21x12Case 2: after x1the operators set(x11, ·) do not set values for y’s.Case 3: after x21 is set but before x12. Since the operators for x21 non-deterministically set the value for the y1’s, and thevalue for xj2 can depend on the value for previous variables, we have that Ψ is valid.Case 4: after x12 is set but before x22 might depend on these values. Since the plan is valid, this means that Φ(cid:11) = (∃x12 does not depend on the values for the y1’s, yet the2)Ψ∃x221 y22 y2∀ y1∀ y11x11x22. This means that the value for x112value of x2is valid. Clearly, Φ(cid:11) ⇒ Φ.In all cases, Φ is valid, and the theorem holds. (cid:3)266B. Bonet / Artificial Intelligence 174 (2010) 245–269Theorem 12. plan-fo-branch-lenPL is PSPACE-complete.Proof. The problem of deciding the validity of QBFs is PSPACE-complete. Given an input (cid:2)P , 1N , 1k(cid:3) construct the formulaPlanFO(k, N) in polynomial time, since N and k are written in unary, and feed it to a QBF solver: P has a k-plan of lengthat most N iff the formula is valid. Therefore, plan-fo-branch-lenPL is reduced to qbf and we have the inclusion.For hardness, let Φ be a QBF starting with an existential quantifier with 2k + 2 alternations and N existential variables.Construct a problem P as in the proof of Theorem 11. Then, Φ is valid iff (cid:2)P , 1N , 1k(cid:3) ∈ plan-fo-branch-lenPL. If Φ does notstart with an existential quantifier, or the number of alternations is not even and at least 2, then add dummy variables andquantifiers. (cid:3)Let P = (cid:2)D, I, G, O , Z (cid:3) be a planning problem with partial observability and no modal formulae. The fluent symbols arethe observable and unobservablepartitioned into observables Z and unobservables D \ Z . Let us denote with f Zfluents at time t. The existence of a linear plan of length at most N can be decided with a QBF of the form:t and f Ut(cid:6)∃o1 · · · oN ∀ f Z1· · · f ZN+1∀ f U1· · · f UN+1[Ψ ],(cid:7)where Ψ tells whether the sequence o1 · · · oN is a valid plan. Likewise, the existence of a 1-plan of length at most N can bedecided with:(cid:6)(cid:7)∃o1 · · · oN ∀ f Z1· · · f ZN+1∃oN+1 · · · o2N ∀ f ZN+1· · · f Z2N+1∀ f U1· · · f U2N+1[Ψ ∧ Φ],where Ψ is as before and Φ(o1, . . . , o2N ) verifies that the number of non-no-op operators is less than or equal to N. Ingeneral, the existence of a k-plan of length N can be decided with the QBFPlanPO(k, N) =∃o1 · · · oN ∀ f Z1· · · f ZN+1· · · ∃okN+1 · · · o(k+1)N ∀ f ZkN+2· · · f U(k+1)N+1[Ψ ∧ Φ].(cid:6)(cid:7)As for the case of fully-observable problems, it is not difficult to show the following results.Theorem 13. For k (cid:6) 0, plan-po-branch-lenPL(k) is Σ P2k+2-complete. plan-po-branch-lenPL is PSPACE-complete.Proof. The inclusion is shown as before. For hardness, note that fully-observable problems are special instances of partially-observable problems. (cid:3)10.2. Plans for problems without modal formulaeLet B be a subset of belief states, as defined in Section 3, and o an operator. By definition, o is applicable at B if itis applicable in all b ∈ B. Therefore, since o contains no modalities, o is applicable in B iff it is applicable in all states in(cid:8)b∈B b. Similarly, B is a goal set if all b ∈ B are goal beliefs, and thus, since there are no modalities, B is a goal set iff(cid:8)b∈B b is a goal belief. In summary, the existence of a linear plan for problems with no modalities can be established byconsidering belief states instead of subsets of belief states, and similarly for plans of bounded branching.2Theorem 14. Deciding the existence of a linear plan, without restrictions on its length, for planning problems with no modalities isEXPSPACE-complete. Similarly, deciding the existence of a plan of bounded branching, without restrictions on its length, for planningproblem with no modalities is EXPSPACE-complete.We think that this result is the main reason why linear plans had been only considered for problems with no ob-servability. When there are no modal formulae involved, the requirements of conformance for the fully-observable andthe partially-observable cases collapse. However, when modal formulae are allowed, both requirements become provabledifferent since, by the space hierarchy theorems [56], EXPSPACE is different from 2EXPSPACE.11. DiscussionThe term ‘conformant’ had been used to refer to unobservable planning problems and their linear solutions. In this work,we have shown that linear plans are also meaningful for partially-observable problems, and thus conformance should bethought as a property on the plans, namely linearity, and not as a property of the models.Conformant and contingent plans are the extreme points of a discrete spectrum of solution forms that also containsplans of bounded branching. We have derived exact complexity results for checking the existence of linear plans and plansof bounded branching for fully-observable and partially-observable domains. We also considered special classes of problems2 Interestingly, De Giacomo and Vardi [22] give an EXPSPACE-completeness result for deciding the existence of linear plans for partially-observableproblems in which the actions are deterministic and the goal is specified with a Büchi automaton on observation traces. However, this class of problemsdoes not explicitly accomodate modal operators of the type studied in this work.B. Bonet / Artificial Intelligence 174 (2010) 245–269267such as plans for problems without modal formulae, and plans of polynomial length. Interestingly, when the problems haveno modal formulae, the complexity of checking the existence of plans for fully-observable and partially-observable problemscoincide.An issue that remains open is the role of cyclic plans and whether it makes sense to talk about bounded branching insuch cases. At first sight, we could say that a simple plan that cycles over a sequence of actions is a linear plan. However,even understanding cyclic plans for non-deterministic tasks is sometimes difficult [55], and thus we are not ready yet totalk about cyclic linear plans or cyclic plans of bounded branching.Another interesting technical question that is not answered is to determine the complexity of deciding the existence ofpolynomial plans for problems with modal formulae. In this case, it does not seem that a direct reduction from such aproblem to the problem of deciding the validity of a (bounded) QBF would exist. The reason is that the validity of modalformulae must be tested multiple times in the former problem where each test is NP-hard.One interesting point raised by the reviewers is whether there is a real need to consider modal operators in a planninglanguage. Currently, there is no an established consensus on this issue. Some researches think that the current languageswithout modal operators are enough, others that the languages must be extended with explicit notions of knowledge. Oneof the strongest arguments against the inclusion of modal operators is that current planning systems are able to modelcertain notions of knowledge if “things” are “encoded” in a proper manner. Although this is partially true, I think thereare plenty of examples on which the current languages are simply not expressive enough or for which a translation to amodality-free language would be of exponential size. This is an interesting discussion that I hope it would be clarified inthe years to come as our understanding of knowledge and its dynamics increases.On the practical side, we have not dealt with the problem of computing plans efficiently. Meuleau and Smith [45] proposean algorithm that works for computing plans of bounded branching for fully-observable problems but not for computingsuch plans for partially-observable problems. We believe that algorithms based on heuristic search and the use of methodsto compactly represent sets of states such as BDDs might work for partially-observable problems.AcknowledgementsThanks to the anonymous reviewers and the editor for interesting and challenging comments that resulted in an im-proved paper. Also, thanks to Patrik Haslum and Héctor Geffner for interesting discussions on early drafts.Appendix A. Borodin’s TheoremThe following theorem is attributed to A. Borodin in the seminal work of Chandra, Kozen and Stockmeyer [13]. It is ageneralization for ATMs of Savitch’s Theorem.Theorem 15. If M is an s(n)-space bounded and a(n)-alternation bounded ATM with s(n) (cid:6) log n, then M ∈ DSPACE(a(n)s(n) +s(n)2).Appendix B. Extension of the transition function for NFACs(cid:7)(cid:6)δ⎩def=⎧⎨(cid:11), ν(cid:3): q(cid:2)q, ν(cid:3), a(cid:11) ∈ δ(q, a)}Given an NFAC M = (cid:2)Q , Σ, δ, q0, F , C(cid:3), we show how to construct the extended transition function ˆδ that maps configu-rations of M and words into subsets of configurations. Recall that a snapshot of M is a tuple (cid:2)q, ν(cid:3) where q is a state and νa function that maps counters to values. First, let us extend δ into a function that receives pairs (cid:2)θ, a(cid:3) where θ is a snapshotand a ∈ Σ ∪ {(cid:13)} as follows:{(cid:2)q{(cid:2)testc, ν[c = boundc](cid:3)}{(cid:2)testc, ν[c = ν(c) − 1](cid:3)}if q /∈ {entryc, loopc} or a (cid:16)= (cid:13),if q = entryc and a = (cid:13), andif q = loopc and a = (cid:13),where the function ν[c = v] is like ν except that ν[c = v](c) = v. Note that the numbers of configurations is bounded fromabove by |Q | × Πc∈C (1 + boundc).This transition function is further extended into a function ˆδ defined from snapshots and words in Σ ∗into subsets ofsnapshots. Our goal is that ˆδ((cid:2)q, ν(cid:3), ω) is the collection of snapshots that can be reached from (cid:2)q, ν(cid:3) along a path labeled ω,perhaps including edges labeled (cid:13). Thus, it will be important to compute the subset of snapshots reachable from a givenone using (cid:13) transitions only. This subset, denoted by (cid:13)-CLOSURE((cid:2)q, ν(cid:3)), is equivalent to the collection of snapshots thatcan be reached from (cid:2)q, ν(cid:3) through (cid:13)-paths; an (cid:13)-path is a path made only of (cid:13) transitions. Furthermore, we naturally let(cid:13)-CLOSURE(S), where S is a set of configurations, beθ∈S (cid:13)-CLOSURE(θ). The function ˆδ is defined as:(cid:8)1. ˆδ((cid:2)q, ν(cid:3), (cid:13)) def= (cid:13)-CLOSURE((cid:2)q, ν(cid:3)).2. For ω ∈ Σ ∗and a ∈ Σ , ˆδ(θ, ωa) def= (cid:13)-CLOSURE(S) where S = {θ (cid:11): for some θ (cid:11)(cid:11) ∈ ˆδ(θ, ω), θ (cid:11) ∈ δ(θ (cid:11)(cid:11), a)}.If θ0 = (cid:2)q0, 0(cid:3) is the initial configuration, the language L(M) is {ω ∈ Σ ∗: for some (cid:2)q, ν(cid:3) ∈ ˆδ(θ0, ω), q ∈ F }.268ReferencesB. Bonet / Artificial Intelligence 174 (2010) 245–269[1] D. Bernstein, E. Hansen, S. Zilberstein, Bounded policy iteration for decentralized POMDPs, in: L.P. Kaelbling, A. Saffiottiiba (Eds.), Proc. 19th Int. JointConf. on Artificial Intelligence, Edinburgh, Scotland, Professional Book Center, 2005, pp. 1287–1292.[2] P. Bertoli, A. Cimatti, M. Roveri, P. Traverso, Strong planning under partial observability, Artificial Intelligence 170 (4–5) (2006) 337–384.[3] D. Bertsekas, Dynamic Programming and Optimal Control (2 vols), Athena Scientific, 1995.[4] P. Blackburn, M. de Rijke, Y. Venema, Modal Logic, Cambridge University Press, 2002.[5] B. Bonet, Bounded branching and modalities in non-deterministic planning, in: D. Long, S. Smith, D. Borrajo, L. McCluskey (Eds.), Proc. 16th Int. Conf.on Automated Planning and Scheduling, Ambleside, UK, AAAI Press, 2006, pp. 42–51.[6] B. Bonet, H. Geffner, Planning with incomplete information as heuristic search in belief space, in: S. Chien, S. Kambhampati, C. Knoblock (Eds.), Proc.6th Int. Conf. on Artificial Intelligence Planning and Scheduling, Breckenridge, CO, AAAI Press, 2000, pp. 52–61.[7] B. Bonet, H. Geffner, Planning as heuristic search, Artificial Intelligence 129 (1–2) (2001) 5–33.[8] B. Bonet, H. Geffner, Faster heuristic search algorithms for planning with uncertainty and full feedback, in: G. Gottlob (Ed.), Proc. 18th Int. Joint Conf.on Artificial Intelligence, Acapulco, Mexico, Morgan Kaufmann, 2003, pp. 1233–1238.[9] B. Bonet, H. Geffner, An algorithm better than AO*?, in: M. Veloso, S. Kambhampati (Eds.), Proc. 20th National Conf. on Artificial Intelligence, Pittsburgh,PA, AAAI Press/MIT Press, 2005, pp. 1343–1348.[10] D. Bryce, S. Kambhampati, D.E. Smith, Planning graph heuristics for belief space search, J. Artificial Intelligence Res. 26 (2006) 35–99.[11] T. Bylander, The computational complexity of propositional STRIPS planning, Artificial Intelligence 69 (1994) 165–204.[12] A.R. Cassandra, M. Littman, L.P. Kaelbling, Acting optimally in partially observable stochastic domains, in: B. Hayes-Roth, R. Korf (Eds.), Proc. 12thNational Conf. on Artificial Intelligence, Seattle, WA, AAAI Press/MIT Press, 1994, pp. 1023–1028.[13] A. Chandra, D. Kozen, L.J. Stockmeyer, Alternation, J. ACM 28 (1) (1981) 114–133.[14] V. Chvatal, Mastermind, Combinatorica 3 (3–4) (1983) 325–329.[15] A. Cimatti, M. Pistore, M. Roveri, P. Traverso, Weak, strong, and strong cyclic planning via symbolic model checking, Artificial Intelligence 147 (2003)35–84.[16] A. Cimatti, M. Roveri, P. Bertoli, Conformant planning via symbolic model checking and heuristic search, Artificial Intelligence 159 (2004) 127–206.[17] D. Du, K. Ko, Theory of Computational Complexity, Wiley–Interscience, New York, NY, 2000.[18] P. Erdös, C. Ranyi, On two problems in information theory, Magyar Tud. Akad. Mat. Kut. Int. Közl. 8 (1963) 229–242.[19] R. Fagin, J. Halpern, Y. Moses, M. Vardi, Reasoning about Knowledge, MIT Press, 1995.[20] R. Fikes, N. Nilsson, STRIPS: A new approach to the application of theorem proving to problem solving, Artificial Intelligence 1 (1971) 27–120.[21] G. De Giacomo, Y. Lespérance, H.J. Levesque, S. Sardiña, On the semantics of deliberation in indigolog: From theory to implementation, Ann. Math.Artif. Intell. 41 (1–2) (2004) 256–299.[22] G. De Giacomo, M.Y. Vardi, Automata-theoretic approach to planning for temporally extended goals, in: S. Biundo, M. Fox (Eds.), Proc. 5th EuropeanConf. on Planning, Durham, UK, in: Lecture Notes in Comput. Sci., vol. 1809, Springer, 1999, pp. 226–238.[23] W. Goddard, Static Mastermind, J. Combin. Math. Combin. Comput. 47 (2003) 225–236.[24] R.P. Goldman, M.S. Boddy, Expressive planning and explicit knowledge, in: B. Drabble (Ed.), Proc. 3rd Int. Conf. on Artificial Intelligence PlanningSystems, Edinburgh, Scotland, AAAI Press, 1996, pp. 110–117.[25] E. Hansen, Solving POMDPs by searching in policy space, in: G. Cooper, S. Moral (Eds.), Proc. 14th Conf. on Uncertainty in Artificial Intelligence,Madison, WI, Morgan Kaufmann, 1998, pp. 211–219.[26] E. Hansen, S. Zilberstein, LAO*: A heuristic search algorithm that finds solutions with loops, Artificial Intelligence 129 (2001) 35–62.[27] P. Haslum, P. Jonsson, Some results on the complexity of planning with incomplete information, in: S. Biundo, M. Fox (Eds.), Proc. 5th European Conf.on Planning, Durham, UK, in: Lecture Notes in Comput. Sci., vol. 1809, Springer, 1999, pp. 308–318.[28] M. Helmert, The fast downward planning system, J. Artificial Intelligence Res. 26 (2006) 191–246.[29] J. Hoffmann, R. Brafman, Contingent planning via heuristic forward search with implicit belief states, in: S. Biundo, K. Myers, K. Rajan (Eds.), Proc. 15thInt. Conf. on Automated Planning and Scheduling, Monterey, CA, Morgan Kaufmann, 2005, pp. 71–80.[30] J. Hoffmann, R. Brafman, Conformant planning via heuristic forward search: A new approach, Artificial Intelligence 170 (2006) 507–541.[31] J. Hoffmann, B. Nebel, The FF planning system: Fast plan generation through heuristic search, J. Artificial Intelligence Res. 14 (2001) 253–302.[32] J. Hopcroft, J. Ullman, Introduction to Automata Theory, Languages, and Computation, Addison–Wesley, 1979.[33] J. Huang, Combining knowledge compilation and search for conformant probabilistic planning, in: D. Long, S. Smith, D. Borrajo, L. McCluskey (Eds.),Proc. 16th Int. Conf. on Automated Planning and Scheduling, Lake District, UK, AAAI Press, 2006, pp. 253–262.[34] G.E. Hughes, M.J. Cresswell, A New Introduction to Modal Logic, Routledge, 1996.[35] L.P. Kaelbling, M. Littman, A.R. Cassandra, Planning and acting in partially observable stochastic domains, Artificial Intelligence 101 (1999) 99–134.[36] H. Kautz, B. Selman, Pushing the envelope: Planning, propositional logic, and stochastic search, in: W. Clanceyuiba, D. Weld (Eds.), Proc. 13th NationalConf. on Artificial Intelligence, Portland, OR, AAAI Press/MIT Press, 1996, pp. 1194–1201.[37] D.E. Knuth, The computer as a Master Mind, J. Recreational Mathematics 9 (1976–1977) 1–6.[38] M. Koyama, T. Lai, An optimal Mastermind strategy, J. Recreational Mathematics 25 (1993) 251–256.[39] H.J. Levesque, What is planning in the presence of sensing, in: W. Clancey, D. Weld (Eds.), Proc. 13th National Conf. on Artificial Intelligence, Portland,OR, AAAI Press/MIT Press, 1996, pp. 1139–1146.[40] H.J. Levesque, Planning with loops, in: L.P. Kaelbling, A. Saffiotti (Eds.), Proc. 19th Int. Joint Conf. on Artificial Intelligence, Edinburgh, Scotland, Profes-sional Book Center, 2005, pp. 509–515.[41] M. Littman, Probabilistic propositional planning: Representations and complexity, in: B. Kuipers, B. Webber (Eds.), Proc. 14th National Conf. on ArtificialIntelligence, Providence, RI, AAAI Press/MIT Press, 1997, pp. 748–754.[42] C. Lusena, T. Li, S. Sittinger, C. Wells, J. Goldsmith, My brain is full: When more memory helps, in: K. Laskey, H. Prade (Eds.), Proc. 15th Conf. onUncertainty in Artificial Intelligence, Stockholm, Sweden, Morgan Kaufmann, 1999, pp. 374–381.[43] S. Majercik, M. Littman, Maxplan: A new approach to probabilistic planning, in: R. Simmons, M. Veloso, S. Smith (Eds.), Proc. 4th Int. Conf. on ArtificialIntelligence Planning Systems, Pittsburgh, PA, AAAI Press, 1998, pp. 86–93.[44] N. Meuleau, L. Peshkin, K. Kim, L.P. Kaelbling, Learning finite-state controllers for partially observable environments, in: K. Laskey, H. Prade (Eds.), Proc.15th Conf. on Uncertainty in Artificial Intelligence, Stockholm, Sweden, Morgan Kaufmann, 1999, pp. 427–436.[45] N. Meuleau, D. Smith, Optimal limited contingency planning, in: C. Meek, U. Kjaerulff (Eds.), Proc. 19th Conf. on Uncertainty in Artificial Intelligence,Acapulco, Mexico, Morgan Kaufmann, 2003, pp. 417–426.[46] A.R. Meyer, L.J. Stockmeyer, The equivalence problem of regular expressions with squaring requires exponential space, in: Proc. 13th Annual IEEESymposium on Switching and Automata Theory, 1973, pp. 125–129.[47] H. Palacios, B. Bonet, A. Darwiche, H. Geffner, Pruning conformant plans by counting models on compiled d-DNNF representations, in: S. Biundo,K. Myers, K. Rajan (Eds.), Proc. 15th Int. Conf. on Automated Planning and Scheduling, Monterey, CA, AAAI Press, 2005, pp. 141–150.[48] H. Palacios, H. Geffner, From conformant into classical planning: Efficient translations that may be efficient too, in: M. Boddy, M. Fox, S. Thiébaux(Eds.), Proc. 17th Int. Conf. on Automated Planning and Scheduling, Providence, RI, AAAI Press, 2007.B. Bonet / Artificial Intelligence 174 (2010) 245–269269[49] C.H. Papadimitriou, Computational Complexity, Addison–Wesley, 1993.[50] E. Pednault, ADL: Exploring the middle ground between strips and the situation calculus, in: R. Brachman, H.J. Levesque, R. Reiter (Eds.), Proc. 1st Int.Conf. on Principles of Knowledge Representation and Reasoning, Toronto, Canada, Morgan Kaufmann, 1989, pp. 324–332.[51] P. Poupart, C. Boutilier, Bounded finite state controllers, in: Advances in Neural Information Processing Systems 16 [NIPS 2003], Vancouver, Canada,MIT Press, 2003.[52] M. Puterman, Markov Decision Processes – Discrete Stochastic Dynamic Programming, John Wiley and Sons, Inc., 1994.[53] J. Rintanen, Complexity of planning with partial observability, in: S. Zilberstein, S. Koenig, J. Koehler (Eds.), Proc. 14th Int. Conf. on Automated Planningand Scheduling, Whistler, Canada, AAAI Press, 2004, pp. 345–354.[54] J. Rintanen, Distance estimates for planning in the discrete belief space, in: D.L. McGuinness, G. Ferguson (Eds.), Proc. 19th National Conf. on ArtificialIntelligence, San Jose, CA, AAAI Press/MIT Press, 2004, pp. 525–530.[55] S. Sardiña, G. De Giacomo, Y. Lespérance, H.J. Levesque, On the limits of planning over belief states under strict uncertainty, in: P. Doherty, J. Mylopou-los, C.A. Welty (Eds.), Proc. 10th Int. Conf. on Principles of Knowledge Representation and Reasoning, Lake District, UK, AAAI Press, 2006, pp. 463–471.[56] M. Sipser, Introduction to Theory of Computation, second ed., Thomson Course Technology, Boston, MA, 2005.[57] D. Smith, D. Weld, Conformant graphplan, in: J. Mostow, C. Rich (Eds.), Proc. 15th National Conf. on Artificial Intelligence, Madison, WI, AAAI Press/MITPress, 1998, pp. 889–896.[58] E. Sondik, The optimal control of partially observable Markov decision processes over the infinite horizon: Discounted costs, Oper. Res. 26 (2) (1978).[59] L.J. Stockmeyer, The polynomial time hierarchy, Theoret. Comput. Sci. 3 (1977) 1–22.[60] Time, And now, Master Mind, Time 106 (22) (December 1, 1975) 73.[61] H. Turner, Polynomial-length planning spans the polynomial hierarchy, in: S. Flesca, I. Giovambattista (Eds.), Proc. 8th European Conf. on Logics inArtificial Intelligence, Cosenza, Italy, in: Lecture Notes in Comput. Sci., vol. 2424, Springer, 2002, pp. 111–124.[62] A.C.-C. Yao, Separating the polynomial-time hierarchy by oracles, in: Proc. 26th Annual Symp. on Foundations of Computer Science, Portland, OR, IEEEPress, 1985, pp. 1–10.