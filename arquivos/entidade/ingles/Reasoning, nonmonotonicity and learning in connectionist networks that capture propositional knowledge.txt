Artificial Intelligence 77 (1995) 203-247 Artificial Intelligence Reasoning, connectionist nonmonotonicity and learning in networks that capture propositional knowledge * Gadi Pinkas Amdocs Inc., 1161 Des Peres Rd., Suite 170, St Louis. MO 63131, USA Received March 1992; revised January 1994 Abstract The paper presents a connectionist framework that is capable of representing and learning propo- sitional knowledge. An extended version of propositional calculus is developed and is demonstrated to be useful for nonmonotonic reasoning, dealing with conflicting beliefs and for coping with in- consistency generated by unreliable knowledge sources. Formulas of the extended calculus are proved to be equivalent in a very strong sense to symmetric networks (like Hopfield networks and Boltzmann machines), and efficient algorithms are given for translating back and forth between the two forms of knowledge representation. A fast learning procedure is presented that allows symmetric networks to learn representations of unknown logic formulas by looking at examples. A connectionist inference engine is then sketched whose knowledge is either compiled from a symbolic representation or learned inductively from training examples. Experiments with large scale randomly generated formulas suggest that the parallel local search that is executed by the networks is extremely fast on average. Finally, it is shown that the extended logic can be used as a high-level specification language for connectionist networks, into which several recent symbolic systems may be mapped. The paper demonstrates how a rigorous bridge can be constructed that ties together the (sometimes opposing) connectionist and symbolic approaches. 1. Intmduction seem Humans to be able to reason about the surrounding world from a noisy and incomplete knowledge with remarkably high speed. They are astoundingly good at infer- ring useful and reliable information even from conflicting beliefs and from a knowledge that is self-contradicting and sometimes even erroneous. *The work was supported by NSF grant: R-9008012. 0004-3702/95/$09.50 @ 1995 Elsevier Science B.V. All rights reserved SSDIOOO4-3702(94)00032-V 204 C;. Pinh.~/Art@xd Intelligence 77 (1995) 203-247 than a decade now that AI has realized that the analysis of such It has been more reasoning mechanisms systems have been proposed as formal models for this kind of reasoning. Some well known examples logic 1531. are circumscription task. As a result, many nonmonotonic 1321 and default is a major Research in nonmonotonic reasoning has tried to understand the basic mechanisms and the rationale behind our intuition when dealing with incomplete description of the world. Recent nonmonotonic systems are quite successful (for examples computational to new situations, symbolic deal with exceptions (351. in capturing our intuitions see [ IO, 621). Most systems, however, are still plagued with intractable themselves complexity, intuitions. The to to be able to revise is too rigid and specialized to develop personal is too constrained to rules or with the fuzzy or approximate aspects of knowledge their knowledge to noise and inflexibility sensitivity to adjust approach and and link. They can provide us with a fast, noise- to learn may be used to dynamically change the system’s performance and to accelerate to achieve Connectionist representation in traditional, systems may be the missing tolerant, adaptive platform, and their ability the knowledge base, robustness in familiar situations. While scientists powerful knowledge erful learning mechanisms cognitive tems learning find efficient symbolic computations fuzzy, heuristic naturally are mapped and adaptive capabilities that have sufficient and adjusting. “Clearly, learning procedures like compositionality expressive power, This article concentrates symbolic AI were concentrating systems, connectionists were concentrating and adaptation mechanisms. Connectionism was criticized and systematicity, which are essential tasks and are easy for symbolic approaches that perform [8]. We would fast and on development of on pow- for lacking for high-level like to have sys- that are capable of is to [ 161, Once the hope is that the approach will be more the ultimate goal for both scientific approaches for representationally powerful systems” into the connectionist platform, of the connectionist integrated with the expressive but rigid symbolic approach. ’ on the somewhat neglected problem of symbolic knowl- that can it studies networks networks. edge representation represent and learn unrestricted propositional’ One big difference between connectionist in connectionist In particular rules. and to reason with it. Connectionist and the control mechanism should be included networks and symbolic knowledge to process the information represen- expressed networks have no such inter- in the knowledge that that is representation to find a connectionist as well as the procedural knowledge systems need an interpreter is that symbolic tations in the representation, preter. The interpreter that is being represented. We strive therefore is capable of representing needed for controlling the information, the reasoning process. the different connectionist models, Among I choose to consider metric matrix of weights. This family of models Boltzmann machines [ 171, harmony theory includes Hopfield networks field theory [63], mean those with a sym- [20,21 J, [ 151, and other ’ Following Marvin Minsky’s call for synthesizing the symbolic and connectionist approaches ( 35 I ? The approach can be extended to represent predicate logic as well I43 1. G. Pit&us/Artificial Intelligence 77 (1995) 203-247 205 for selecting symmetric connection& networks (SCNs) are the variations. The reasons following: (1) [7]; networks by energy can be characterized networks were used the networks’ behavior functions which make to express and approximate symmetric easier to specify symmetric [221i3 symmetric [42] ; therefore works power if we restrict ourselves recent, successful, heuristic and may be seen as sequential variations of the symmetric paradigm. net- they are quite powerful, and we will not lose expressive case. 4 networks are capable of representing [ 33,571 have very similar structure a large set of asymmetric “hard” problems to the symmetric repair techniques it (2) (3) (4) Ideally, we would like a wide range of logical however, we will be satisfied even paradigms will be mapped. Also, that is capable of describing language networks; connectionist nonmonotonic formal, declarative in a network. Such high-level, declarative and “programming” level of abstraction implementation. My purpose of connectionist between high-level in this article formalisms it would be beneficial the knowledge to be representable in if only some but general if we had a encapsulated language may then be used for specification It may be used also as an intermediate and their low-level neural cognitive processes networks. is to show that ( 1) propositional knowledge in any (3) SCNs can formulas by looking at examples of truth nonmonotonic that is encapsulated logic; (4) SCNs can be used as inference mechanisms (2) any knowledge of unknown propositional in SCNs; can be captured naturally SCN can be described by an extended version of propositional learn representations assignments that are able of capturing both the information as the procedural SCNs can be compared satisfiability. knowledge used for control; and finally, (5) algorithms to the best-known the formulas; that satisfy embedded favorably in the logic formulas as well the algorithm used by logic for propositional and The paper and the energy paradigm is organized its proof the usefulness connectionist in the following way: Section 2 presents penalty theory. The section demonstrates In Section 3, symmetric reasoning. logic, its of the new networks are is reviewed. Section 4 defines equivalence between between penalty and proves a strong equivalence logic in SCNs logic. Section 5 sketches a semantics logic for nonmonotonic introduced forms of knowledge logic formulas and SCNs. It shows how to represent sentences of penalty and how every SCN may be described using connectionist inference engine a learning algorithm formulas performance of the approach. Section 8 discusses discussed. Section 6 discusses of unknown propositional inductively. Section 7 reports experiments that enables SCNs to learn representations related work, and Section 9 concludes. that uses the representation that were performed to evaluate the representation the extended s The TSP experiments of Hopfield and Tank [22] were criticized by Wilson and Pawley [67]; however, to the Hopfield architecture, provided better of the energy function as well as modifications later formulations and more encouraging results 4 Sometimes an asymmetric may consider not to restrict ourselves [ 2,23,39]. form of a symmetric network will perform better; therefore, for efficiency, we to the symmetric case. 206 G. Pinkus/Art#cial Intelligence 77 (1995) 203-247 2. Penalty logic 1’11 extend propositional calculus in order to make it useful for nonmonotonic Later, this calculus will be mapped reason- into SCNs, the logic and the networks will be revealed. ing and for coping with inconsistency. and a strong relationship The extended calculus between is capable of expressing a variety of interpretations, etc.. by adding a real positive number of knowledge, penalty may be assigned or “likelihoods” represent “certainties” as in [ 111. When entropy constraints may represent a measure of reliability the penalties penalties explicitly. 5 I do not insist on a particular use or interpretation since the intention into which many could be reduced strength of belief, reliability of sources to every belief. This the numbers may as in [ 6,611, priorities as in [ 3,291 or maximal the knowledge a penalty [ 5 I]. Note that some of these systems compute the is to develop a general framework (possibly with a variety of interpretations). of the penalties, logicist systems information, while other systems (penalty) for example, sources are unreliable, let the user specify from less explicit 2.1. Extending propositional calculus Definition 2.1. A penalty (I, is a finite set of pairs. Each pair is composed of a real positive number, called penalty, and a standard i.e., @ = {(pi, 40;) 1 pi E lR+, pi is propositional a WFF, i= formula, called assumption logic well formed (or belief); (PLOFF) formula n}. that are in $ (denoted by 24~l) is &, = {pi j (pi, pi) E $}. I,..., The set of the beliefs Example 2.2. The Nixon diamond can be stated as: 1000 N + R Nixon is a republican 1000 N--tQ Nixon is also a quaker 10 R--t7P republicans tend not to be pacifist 10 Q-P quakers tend to be pacifist 3000 N the person we reason about is Nixon An illustration The set of the beliefs of the example is shown in Fig. I. is inconsistent; however, the penalties in the example in each proposition. High penalty like the one that states that Nixon reflect the strength with which we believe in this is is a republican. We is the one as is not usually part of our knowledge base and we would like to example given to strict logic rules (facts), cannot allow strict facts to be defeated. The last fact (N) states that Nixon we reason about. This fact receives evidence. The evidence “jump” (corrigible) (“tend temporary rules tend not to be pacifist. Lower penalties are given to “defeasible” like the one that states that republicans the highest penalty of all since once it is given. The evidence in this case is considered but very certain it is considered to be” rules), to conclusions (infallible). s The penalties may be acquired by learning; thus, subjective intuition is captured. G. Pinkas/Art@ial Intelligence 77 (1995) 203-247 201 Fig. I. An illustration of the Nixon diamond as an inheritance network: nodes represent atomic propositions; the numbers are the penalties. is a republican, we tend to believe this “jumping” to conclusion is blocked, that the person is not if we know that that to the rule. For example, we wouldn’t like to conclude is also a republican, or if it was explicitly mentioned is not pacifist. Clearly, we would that Nixon (Q) ; however, we would not like to conclude like to conclude is no adequate reason to believe either is both a anything in P or in (by default) is an exception When we know that somebody ; however, pacifist the person a quaker that the person republican about -P; therefore P is considered is pacifist, (R) and a quaker the pacifism of Nixon. There if the person If we want to express ambiguous. the belief that religious ideas are stronger the penalty than political affilia- for Q + P to 15; tions in influencing the penalty leaving one’s pacifism, for R -+ TP unchanged then we may increase (10). Example 2.3. 1000 N + R Nixon is a republican 1000 N-Q Nixon is also a quaker 10 15 R+yP Q-P 3000N republican tend not to be pacifist quakers tend to be pacifist the person we reason about is Nixon. In the revised set of assumptions, we have two competing arguments. One argument supports Nixon competition disagreeing is not ambiguous (the winning argument [ 301) . the pacifism of Nixon while the other supports in this case, since argument is stronger and the argument its negation. The pacifism of the that supports P wins the to defeat therefore manages 2.2. Model theory There are many ways to interpret I shall give one such interpretation the penalties and the assumptions that is convenient yet general. in our formalism. Given a knowledge base Cc, = {(pi, pi)}, the PLOFF 9 determines set of all possible models (truth assignments of n atomic propositions). a ranking over the This ranking 208 G. Pinkas/Artijicial Intelligence 77 (1995) 203-247 that satisfy that models are “better” than models or “goodness” we tend that are violated. Two models to be “equally good”. Even [ 601 ). By specifying @. we mean informally assumptions to associate with possible models of the reflects “normality” that satisfy many world (see “important” fewer or less important assumptions. Every two models may always be compared by looking at the assumptions (in Q) considered but the sum of the penalties of both sets is the same, then the two sets of assumptions models are “equally good”. A model is more “normal” than another model if the sum of the penalties of the violated assumptions of the first is less than the sum of the penalties violated by the second. For further motivation see [6,11]. that violate if the models violate different or intersecting the same set of assumptions for summing the penalties (or “better”) are This interpretation of the penalties to all the possible models. The ranking induces a ranking function function that assigns a real value the is called that is induced (rank) violation rank of 4: that assigns rank to each of the truth assignments. The Vrunk+ for a truth assignment Definition 2.4. The violation mnk of a PLOFF I,+ is the function a real-valued 2 is computed by summing the assignment; i.e.. Vrunkk (2) = ci&i,, p,. ’ of Cc, that are violated by for the assumptions the penalties (Vrank,) the preferred Definition 2.5. The models models of @; i.e., {.? / miny{ Vrunk+ (y3 } = Vrank* (2)). The set of all preferred models is denoted by rl/,. the Vrankg function are called that minimize Definition 2.6. Let p, 9 be PLOFFs, a PLOFF all the preferred models of 4/, are also the preferred models of p; i.e., r, C r+,. I& semantically entails 40 (rC, k (D) iff Note that a sentence @ therefore entails (o iff any model that minimizes the violation rank of $, also minimizes the violation rank of 9. In the Nixon example, there are only two preferred models: (N, R, Q, -P>. Examples of some valid conclusions these conclusions ambiguous, since P holds in one preferred model while 1P holds in the other. are satisfied by all the preferred models). The pacifism of Nixon (N, R, Q, P) and are therefore N, R A Q, etc. (since is 2.3. Merging PLOFFs, evidence and background knowledge The operator merge (6) in the metalanguage, propositional logic. It allows us to combine plays the role of A (AND) two PLOFFs simply by merging in classic them. Definition 2.7. The merge operation (6) is defined: lcIl ii $2 = (rcII - rcI2) u ($2 - $1) U { (2Pi, Vi) 1 (pi9 Pi) E @I fl442). ’ A Score (a number) is actually computed by the function hank. This score is later used to determine the relative rank of the truth assignment. G. Pit&as/Artificial Intelligence 77 (1995) 203-247 The meaning of a merge of two or more PLOPPs appropriate Vrank functions. The reader may check that is simply obtained by adding Vrank *b = Vrank$ + Vrank$, . The merge operation therefore allows us an incremental update of the knowledge. 209 the Later, after the equivalence of networks and logic formulas that this property allows one to add (delete) adding network all over again when some updates occur. the relevant energy (deleting) terms. There a PLOPF is established, we’ll see to an existing network only by the new is no need to re-compute Nonmonotonic systems “jump” to conclusions based on a given evidence, those conclusions the knowledge based on a new evidence. from which we want to reason, may retract decompose and “evidence” be an easy way to combine evidence with it. In our formalism, is simply done by merging functions. ranking [ 10,491. The background knowledge is relatively the evidence and the background or adding It is therefore convenient into “background” knowledge fixed, and there should the evidence the two together combining and later to Definition 2.8. Let t,b, e, q~ be PLOFPs. Evidence e entails C+Y with respect to a back- ground knowledge $ (e +* cp), iff $ 6 e b 9. The consequence relation induced by (I, is the set of all pairs (e,cp) such that e b’ (p. One special case of this definition is when the evidence is strict; is never defeated, is certain. This special case is very useful, and indeed, evidence (e.g., validity of the evidence the set Z& should be consistent should be higher practically than any other combination and the penalties infinite). and the agent draws conclusions that are assigned [ lo] ) . To represent a strict evidence e in penalty in most reasoning i.e., its validity the systems based on the absolute logic, to the assumptions of background beliefs (the penalties are Definition 2.9. Strict evidence consistent beliefs). and cc represents a large penalty (larger than any combination of background is a PLOFF e = {(co, ei)} such that the set U, = {ei} is Example 2.10. In the Nixon diamond the following beliefs are considered background: 1000 N --+ R Nixon is a republican. 1000 N -+ Q Nixon is also a quaker. 10 R-+yP republicans tend not to be pacifist. 10 Q-P quakers tend to be pacifist. The fact (3000, N) is strict evidence Another example of strict evidence that triggers for example that triggers is (3000, -Q) the conclusion of Q A R. the conclusion TN. Penalty new evidence logic is nonmonotonic since sometimes conclusions is added. In the example, when there is an evidence need to be retracted when is a that someone 210 G. Pinkos/Artificial Intelligence 77 (1995) 203-247 quaker the conclusion that Nixon is that someone, we need to retract the conclusion. is that he or she is also pacifist. If in addition, we add the evidence Loyal to the goal of being as genera1 as possible, 1’11 not restrict the evidence strict. Such generalization is a phenomenon evidence when noisy, our agent may “not believe highly reliable the evidence its own eyes” facts of the background knowledge. is obtained via sensory devices is not mere encountered formality, in many practical to being and has its direct uses. Defeasible For example, and redundant conflicts with some applications. that are unreliable, if the evidence As with evidence, follows, or is ambiguous. Penalty need not be strict. Most symbolic conclusions as a strict proposition treat a that either follows from the background knowledge, or to be stated as (with penalties). Thus, such conclusions may arrive for example as queries via conclusion its negation PLOFFs noisy channels. The query we wish to prove may therefore be redundant exactly as the evidence and the background knowledge. Thus, self-contradicting, background it (by definition) evidence knowledge are also preferred models of the query. and unreliable itself may be iff all the preferred models of the logic allows conclusions yet we prove the query systems 2.4. Proof theory A sound and complete proof theory can be shown for penalty is based solely on syntactic considerations, process in penalty logic. and gives a clarifying logic. This proof theory look on the reasoning Instead of ranking we can rank consistent consistent all the preferred consistent subsets the models and using the “best” models for the reasoning process, subsets of the assumptions of $, and use the “best” (preferred) to perform deduction. A conclusion is made in the proof theory iff subsets entail it. Definition 2.11. A set T is called a theory of a PLOFF Cc, iff T is a consistent subset of the assumptions i.e., the set T C: ZA, has at least one satisfying model. in $; Definition 2.12. The penalty function of a theory T of @ is the function obtained by summing i.e., penabti CT) = Cv,E(~d,-~) P;. the penalties of the assumptions in @ that are not included in T; A ranking is therefore induced by $ over the set of theories of (CI. This ranking is computed by summing the penalties of the missing assumptions. Definition 2.13. A preferred function of q+; i.e., The set of the preferred mins{penal& (S) 1 S is a theory of $} T is a theory of $}. theory of y3 is a theory T that minimizes the penalty theories of 9 is T$ = {T / penalty+(T) = Definition 2.14. Let rc/, q be PLOFFs, q, and let Tq = {T/} the set of all preferred let T+ = {E} the set of all preferred theories of 4p. We say the @ entails7 theories of rp ’ Note that the deductive closure of preferred definition of entailment in penalty logic resembles theories roughly resemble “extensions” therefore entailment by intersection of all extensions. (as in [ 531). The G. Pinkus/Art#cial Intelligence 77 (1995) 203-247 211 (denoted by $ b rp) iff all the preferred the disjunction of all the preferred theories of rp; i.e., theories c of $ entail (in the classical sense) As a special case, consider the case where the conclusion sp is strict (rp is a consistent rp iff every preferred theory of sense of entailment. propositional well formed formula). A PLOPS $ entails Cc, entails cp in the classical In the Nixon example, there are 25 - 2 non-empty If we rank each of the consistent beliefs, we get that the preferred T2=(N,N+Q,N+R,R only one belief + -IP}. These preferred IO) is missing in (/I (of strength the assumptions set); however, subsets where at least one belief of $ is missing. the penalties of the missing theories are TI = {N, N --+ Q, N + R, Q + P} and theories are each ranked 10 since subsets by summing in each such theory. are conflicting (inconsistent consistent Each of the two preferred neither P nor 1P can be concluded, The reasoning process can be intuitively subsets. The subsets entailed only We’ll need if all the winners conclude the next two lemmas theories entails since the obvious conclusions the two preferred understood as a competition (like N, Q A R) , but theories agree on neither. among consistent that win are those theories with minimal penalty. A conclusion is it independently. to show that the proof theory is sound and com- plete. Lemma 2.15. Let T C L& be a consistent subset of the assumptions in +. The subset T is maximal-consistent ’ in $ if every model that satisfies T has a violation rank if x’ b T then equal to the penalty of T; i.e., T is a maximal-consistent subset iff (VZ) penalty+ (T) = Vranke (2). If T is a maximal-consistent the assumptions such assumptions Proof. out of T are also (otherwise Also, every assumption Therefore, assumptions missing penalty+ (T) = Vranke (2). in T is equal if T is a maximal-consistent subset of +, in @ that are left that are violated by any model x’ that satisfies T the assumptions are consistent with T and therefore T is not maximal). that is violated by a model x’ that satisfies T cannot be in T. then for every model x’ of T, the set of violated by I Therefore to the set of assumptions subset then Assume that every model x’ that satisfies T has Vranke (2) = penalty@ (T) . If T is not into T and rank of x’ must in T subsumes not violated that maximal-consistent there is an assumption have a model x’ satisfying both T and the new assumption. The violation be lower than the penalty of T since the set of assumptions not included the set of assumptions by 3, i.e., Vrank,+ (2) < penalye( penalty* (T) = Vranke (2). violated by x’ and contains at least one assumption This is a contradiction with the assumption in @ that can be included 0 8 A subset T is maximal-consistent of the set. consistency if no other assumption of $ can be added to T while still preserving the 212 G. Pinka.s/Ar/(ficiul Intrllipm 77 (1995) 203-247 The reader may observe that any preferred the penalty of a preferred of LIti and therefore satisfying models. This allows us to use a proof-theoretic instead of the model-theoretic theory of I& is a maximal-consistent theory is equal to the violation function ranking subset rank of its (pen&+) ( Vrmk, function the relationship ). between preferred models and preferred The next lemma establishes theories. Lemma preferred 2.16. A model xf is u preferred model of a PLOFF Cc, iff model 2 satisfies some theory of $. then Proof. If x’ is a preferred model of ti composed of all assumptions violated by x’ are exactly penaltyti(T). such that penalty+ (T’) < penal&,(T). have Vrunk+ (q) = penaltyd, (T’), and we conclude But if T is not a preferred those that are not included it minimizes Vranke. Let T be the set that are that Vrunk,,, (2) = theory T’ .v’ that satisfy T’ theory By Lemma 2.15, the models then there exists a preferred in T, we deduce in Q that are satisfied by X: Since the assumptions that Vrunk, (q) = penaltyti CT’) < penalty,,, ( T) = Vrank$ (2) This is a contradiction to the minimality of Vrunk( 2). If .? is a model of a preferred theory T of c// then T minimizes By Lemma 2.15, Vrank,( 2) = penalty~(T). the penalty function and is maximal-consistent. preferred model of Ic, then there must be a preferred model Vrank, (2). Let T’ the set of all assumptions penaltJti (T’) = Vrank, (7). since the set of assumptions the set of the assumptions If x’ is not a .v’ such that Vrank$ (j’) < of fl satisfied by j? The set T’ has to violated by .v’ is equal in T’. Therefore, not included penalty~ ( T’ ) = Vrunk,,, ( j7 < Vrunk$ ( 2) = penalty$ (T) , in contradiction to the minimality of penalty$ (T). U Theorem 2.17. The proof procedure is sound and complete; i.e., $ b p iff 1+4 I- p. Proof. If I) b rp then every preferred model of $ is also a preferred model of p. Based theory T of @ on lemma 2.16, every preferred model of 4 satisfies every preferred model of t,4 and also satisfies some preferred satisfies lemma 2.16 every model the disjunction theory T of Cc, is also a preferred model of 9 and therefore that satisfies a preferred theories of p; i.e., T I- VTiETq T/. We conclude satisfies theory of p. Therefore, theories of p. From of the preferred of the preferred some preferred the disjunction therefor that I+!J /- C,D. If IJ I- p then every model that satisfies a preferred theory T of @ also satisfies a theory T’ of 9. From lemma 2.16, a model that satisfies T’ is also a preferred preferred model of cp and therefore, every model Based on lemma 2.16 every preferred model T of rC, satisfies some preferred of $ and therefore is a preferred model of p (l-e c r,), We therefore conclude that satisfies T is also a preferred model of cp. theory that *kP 0 G. Pinkas/Artificial Intelligence 77 (1995) 203-247 213 This sound and complete proof mechanism theories in the knowledge base and for defeasible of competing for both is useful reasoning. For ex- (since we assume that only a minority of the observations and only a minority of the assumptions dealing with inconsistency ample, when we detect inconsistency, we usually want to adopt a theory with maximum cardinality In- logic, when all the penalties are one, the theories that win have maximal deed, in penalty is defeated. Thus, minimum penalty cardinality of the maximal means maximum cardinality sources. For theories can be used to decide between defeasible conflicting set of arguments A:! if A1 is supported by a “better” that support A:! (see a set of arguments Al defeats a conflicting theory than all the theories systems). principle which reasoning, sets of arguments. is useful when coping with noisy knowledge logic is therefore a generalization for a discussion on argument the notion of conflicting cardinality. Penalty are erroneous). Intuitively, [ 30,621 Example 2.18. Two levels of blocking (from [ 31) : 1 10 meeting I usually go to the Monday meeting. sick + (lmeeting) If I’m sick I usually don’t go to the meeting. 100 cold-only -+ meeting If I have only a cold then I tend go to the meeting. 1000 cold-only -+ sick If I have a cold it means I’m sick. all the assumptions are consistent, the first assumption). However, given that falsify “meeting” and “cold-only”, than the competing first assumption and we can infer that the evidence since the second (the only theory that then is the theory that does not is drawn despite the first assumption). If we include the evidence “cold-only” that previously won loses now, and the new winner the second assumption. As a result, the conclusion “meeting” evidence, is true (from Without any additional that “meeting” “sick” is true, we prefer theories assumption has greater penalty wins does not include the theory include the fact that “sick” is also concluded. 3. Symmetric models and energy functions This section reviews symmetric paradigm. Later, we’ll show the relationship connectionist models and the energy minimization logic. this paradigm and penalty between 3.1. What are symmetric networks? (SCN) network connectionist A symmetric is characterized by a weighted undirected graph whose nodes represent processing units and whose arcs represent weighted con- (see Fig. 2). There are two kinds of arcs: pairwise arcs that link two nodes, nections a and monadic (a threshold with weighted connection in reverse sign) given can be stored the a symmetric matrix whose diagonal a bias to a single unit. The weights of the connections is zero. The value of the i, j position within to a single node. A pairwise arc represents arcs that are each attached (wi,j), while a monadic arc represents 214 G. Pinhs/Artijicd Intelligence 77 (1995) 203-247 the output of unit i into unit since the weight from unit i to unit j is equal to the weight that directs the weight of the connection matrix represents j. The matrix is symmetric, from unit j to unit i (i.e., w ,,,, = w,,,, ). An SCN may be viewed as searching called the energy. Each unit asynchronously adjust its activation value, so that energy decreases gradually. reaches equilibrium, computes settling on either a local or a global minimum. for a global minimum of some quadratic function the gradient 9 of the function and lo The network eventually There is a direct mapping between these networks and the quadratic energy functions the appropriate the network function they minimize. Given a function, we can construct and given a network, we can generate variables of the function map into nodes in the graph: hidden variables are mapped hidden units and visible variables are mapped by symmetric energy (which term of the form: -0x;. it, that is minimized. The into into visible units. Each node is connected to unit j by a weight w iff the i has a nonzero bias 8 a a term of the form viewed as the threshold -WX;Xj. A unit -0) function is sometimes arcs to other units. Unit that tries to minimize iff the energy i is connected includes includes function A network is fully specified by its energy function and for the remainder of this paper, functions” will them. The terms “networks” and “energy between I will not distinguish be used interchangeably. Fig. 2. A symmettic +5T+W+S-N-R network that represents the function E = 2RN - 2NT - XT - 2WT - WN 3.2. Activation functions Each unit in the network computes an activation value as follows. The unit first computes neighbors, which is the gradient of the energy function with reverse sign the weighted sum of the inputs (Xi) between zero and one from its it receives net, = -- = ‘) The weighted sum of the inputs minus the threshold is actually the partial derivative -dE/dX;, where E is the energy ‘(’ In the stochastic models, noise is introduced and the energy may not be decreasing all the times. function. G. Pinkas/Art@cial Intelligence 77 (199.5) 203-247 215 The sum is then used as the input for some activation nondecreasing) function F (usually nonlinear and Xi = F(neti), whose task is to change connectionist models may have different viewed, Some of the most popular symmetric models are described the activation value according activation as performing therefore, a form of gradient descent on the energy in the following landscape. subsections. to the energy steepness. Different functions. The network may be 3.2.1. The discrete Hopfield model The discrete Hopfield model are either zero or one. The activation [20] uses binary-valued function F is units whose activation values Xi = 1, 0, ifWti>O, otherwise. This model searches the corners of the hyper-cube corresponding the units. The discrete Hopfield model finds a local minimum very quickly;” many to escape to the possible values of however, this local minimum will be a shallow one, and the network will not be able to a deeper minimum. times 3.2.2. The analog model of Hopjield and Tank [21] In Hopfield and Tank networks the activation values are continuous between zero and one and the search takes place in the interior of the hyper-cube. By beginning the network has better near the center of the cube and searching using gradient descent, chances of finding a global minimum. There are no guarantees that a global minimum will be found, but good results have been reported for their implementation Tank use an analog circuit slightly: had to be modified for several problems. Hopfield and function and, therefore the energy where Ri is the input resistance to unit i, g(s) is the sigmoidal function with gain A 1 g(s) = ~ 1 + e2As ’ is the inverse of g. At high (infinite) and g-’ lie at the corners of the search space in the same locations as those of the discrete Hopfield model. The discrete and analog models collapse, into one at infinite gain. gain the minima therefore, ’ ’ Fast on average but exponential in worst case [ 241. 216 G. Pinkus/Artijiciul Intelligence 77 (1995) 203-247 3.2.3. Boltzmann machines The Boltzmann machine important difference starting energy gradient neti is used to determine in a high temperature is that the activation [ 171 has binary units as in the discrete Hopfield model. The is annealed it down to a lower temperature. The that a unit adopts the one state: rule is stochastic and the system and slowly cooling the probability P(X,=l)= ’ 1 + e-net,lT ’ where T is the temperature more likely not decrease monotonically with a frequency minima but concentrating Boltzmann machine minimum schedules. at the same is found can time, exploring (spending more theoretically [9]; however. of the annealing. With this stochastic is to adopt low energy states as the temperature cools down. The energy does it will go uphill randomly, It can, therefore, search several at high temperature that is decreasing with the temperature. a wide range of possibilities as in the previous models; rule, the network instead, time) on deeper minima be run long enough temperature. A at lower that a global to guarantee it is not easy to find such “sure” annealing in practice An annealing schedule can be designed time resources, we can make the system obtain thus providing an “any-time” minimum may be found and the probability to lit a given time quota. Given a bound on its lowest temperature within the bound, to find a global at the end of such time quota; however, as more time is given, deeper minima of finding a global solution answer. The system is not guaranteed increases. 3.2.4. Deterministic Boltzmann machines-mean jield theory A mean field method suggested by Peterson and Hartman [38] appears to reduce the time excessive The method unit to be one and encoding in Boltzmann machines is based on deterministically that is wasted on the stochastic hill climbing. the probability of a Boltzmann approximating this probability in the activation function: X, = tanh F ( 1 times faster than the stochastic process is not stochastic. Peterson is performed field annealing Mean but the process lo-30 that somewhat better results mean field annealing may be designed a desired any-time property. similarly to the annealing in Boltzmann machines, and Anderson to be in Boltzmann machines and also reported (deeper minima) were found. As in Boltzmann machines, thus providing us with to fit the time resources, this procedure found 3.2.5. Heuristic repair methods Recently, repair methods based on local search have been proposed search problems. The distributions [33,57]. of problems techniques were shown such as constraint to be successful satisfaction, n-queen, for NP-hard for large scale (hard) scheduling and 3-SAT In these methods, the distance between the function is being minimized the current state and a goal is measured and using local search. Each of the variables of the problem G. Pinkas/Artifcial Intelligence 77 (1995) 203-247 217 is checked change as the distance the connectionist Heuristic for the effect of changing the distance that reduces its value on the distance the most is executed. When the energy function function. Usually, the is taken as a sequential variation of function, heuristic repair may be considered algorithm implemented in symmetric networks. repair methods can be used therefore function the formalism proposed sum of (weighted (atomic and the problem variables are the nodes of the networks is the high-order energy function to implement in this article. The distance violated constraints) propositions). 3.3. High-order energy functions To represent order connections how to convert High-order arbitrary logic formulas, a network will need the power of either high- or hidden units. This section reviews high-order networks, and shows networks by introducing new hidden units. con- networks have sigma-pi units (pairwise) them into standard connectionist nections. Symmetric networks can be easily extended Naturally, such networks may be viewed as minimizing [ 551 with multiplicative to handle high-order connections. functions high-order energy [561. A k-order energy function sum of products, with product denoted by: is a function E : (0, 1)” -+ R that can be expressed as is terms of up to k variables. A k-order energy function E’(x~,...,x,) = c 1 (il<iz<~..<it<n --Wil,...,itXil f ’ ’ -%k Quadratic order case: energy functions (or second-order functions) are special cases of the high- c -WijXiXj 1 <i<j<n + C -WiXi. i(n In the high-order model each node is assigned a sigma-pi unit that updates value by first computing the activation value accordingly: the partial derivative of the energy function its activation and then update W = -a = dE wil.....i....& c I,“‘l”‘lk ,<j<kij2i rI \.. Xij 9 Ui = F(tM?ti), where ai = F(neti) to extend. is the standard update In the discrete Hopfield model rule that is unique for example, F(neti) to the model we wish = 1 if neti > 0, and 21x G. Pinkn.s/Artr$ciul lntellr~~ence 77 (1995) 203-247 (see Fig. 3) is a hyper-graph, where k- F(rret;) = 0 otherwise. A high-order network are translated k nodes. The arcs are not directed order is the same for every node that is part of the arc) and the weight of an arc (the weight is determined by the weight of the corresponding (with an opposite sign). As in the quadratic case, there is a translation back and forth between k- and symmetric high-order networks with k-order sigma-pi units. order energy hyper-arcs connecting term in the energy functions function Fig. 3. A cubic network u cubic hyper-arc that represents I:‘ = NSW + 2RN ~- WN + W + S - R - N using sigma-pi units and (it is equivalent to the network of Fig. 2. without the hidden unit T). We can arbitrarily divide the variables of an energy function variables and hidden variables. The hidden variables correspond the network, and the visible variables correspond with both hidden and visible variables I the visible variables and Trepresents the hidden variables. to the visible units. An energy function is denoted usually as a function E(x’, <), where into two sets: visible to the hidden units of of zeros and ones to the visible variables is called a visible is reached, are considered state. as the represents An assignment The values of the visible units after an equilibrium “answer” of the network. Later in this article, ables are viewed as atomic propositions: 9s “false”. I’ll interpret visible states as truth assignments: the visible vari- “1” is interpreted as “true” and “0” is interpreted We call the set of minimizing vectors projected onto the visible variables, “the visible solutions” of the minimization problem; i.e.. 1-T / (S)E(.f,t) =min{E(J,r:)}}. I’.: like Boltzmann machines, harmony for a global minimum ‘* of the corresponding Models searching or spurious memories may exist. In general however, local minima are considered undesirable phenomena, article will ignore any meaningful theory, mean field theory, may be viewed as energy functions. Local minima to be in the performance of the network. This they will not represent that are not global, and usually and cause a degradation local minima knowledge. I2 Several global minima may also exist. all with the same energy level. < ED I’ll show now an algorithm G. Pinkm/ArtQicial Intelligence 77 (1995) 203-247 219 Definition 3.1. Let E be a symmetric ? designates function: ErunkE(Z) =miny{E(x’,y3}. the hidden variables. The characteristic network with energy function E(x’, 8, where is the function of the network is the energy level obtained when the hidden units are free The ErunkE function defines state values, and ErunkE units and it is also independent may be many possible networks with the same characteristic uses the characteristic the energy of all visible states. The energy of a visible the state the visible units are clamped with is reached. This of the hidden topology of the original network. There function. The next section to show equivalence between different networks. to settle so that a minimum the network’s behavior: it is independent of the exact characterizes function function 3.4. The equivalence between high-order networks and low-order networks The following We call two energy functions subsection is a review of results reported strongly equivalent, in [40]. if their corresponding characteristic functions are equal up to a constant difference; i.e: El M E2 iff ErunkE, = (Erunk) that are strongly equivalent not only have the same set of global Erunke, + c. Networks minima, but also have a very similar energy the same ordering on the visible states; i.e., if st and s2 are visible states then “the same ordering” means that Et(st) iff Ez(s1) <I&(Q). and induce landscape to convert any high-order network into a strongly equiv- alent low-order one, with additional hidden units. In addition, any energy function with into a strongly equivalent, hidden variables some or all of the hidden units. These algorithms network by eliminating trade power of sigma-pi units the computational versa. As a result we’ll see that the expressive power of high-order networks as that of low-order networks with hidden units. higher-order allow us to simple units and vice is the same can be converted for additional (possibly) Readers who are not interested now to the next subsection. They may keep in mind only that the constructions directions are possible. in the technical details of the constructions may skip for both Theorem 3.2. Any k-order term (w nt, Xi), with NEGATIVE coe$ficient w, can be replaced by terms: cf_, 2wXiT the quadratic energy function with one additional hidden variable T. Any k-order term (w nt, Xi), with POSITIVE coefJicient w, can be replaced by the terms: - (2k - 1) wT generating a strongly equivalent w!Xi- [$2wXiT) +2WXkT+(2k_3)WT, generating a strongly equivalent energy function of om’er k - 1 with one additional hidden variable T. 220 G. Pinkas/Artijzciul lntelli~ence 77 (I 99.5) 203-247 The proof appears in [ 44 1. Example 3.3. The following can be converted T and T’. term XYZU. It into a quadratic energy function using two additional hidden variables is a 4-order energy function with a 4-order -XY + XYZU =-XY+XZ-2XT-2W-2Z7+2UT+5T ~5 -XY+XY-2XT’- 2YT’+2ZT’+3T’-2XT-2IT-2ZT +2UT + 5T =-2XT’-2kTT’+2ZT’+3T’-2X7--2YT_2ZT+2UT+5T. The symmetric transformation, nating any subset of the variables, eliminating only hidden variables). from low-order is also possible into high-order functions (of course we are interesting by elimi- in To eliminate T, bring the energy function to the form: E = E’ + oldterm, where oldterm = (C:=, wi @_, X., )T. Consider all assignments S for the variables ( X = Xi, . . Xi, ) in oldterm (not including T), such that 0s = C,F=, w,, ni, xl, < 0. Let “Xi, “. if S(X,,) = 1. “( 1 - Xi, )“, ifS(Xi,) =O. L;. = i it is the expression 0 in S. The expression $=, Li therefore determines “X,” or “( 1 - X,)” depending whether the variable is assigned 1 or the state S, and the expression the disjunction represents new function E’ + newterm, T. of all the states that cause a reduction in the total energy. The to E’ + oldterm and does not include is therefore equivalent Example 3.4. Let T be the hidden variable to be eliminated, then: ABfTAC-TA+2TB-T=AB+T(AC-A+2B- I). The following assignments for (A. B, C) cause p to be less then zero: P(O.O,O, = ~ 13 P(O.0. P(l,O,O, = --2, I ) = ~~ 13 P(l.O.l, = ~~ 1. The new term equals: G. Pinkm/ArtiJcial Intelligence 77 (199.5) 203-247 221 -(I--A)(l-B)(l-C) -(l-A)(l-B)C -2A(l -B)(l -C) -A(1 -B)C =-ABC+AB+AC-A+B-1. Therefore: AB+TAC-TA+2TB-T =--ABC+2AB+AC-A+B. 4. The equivalence between penalty logic and energy minimization This section defines equivalence between different forms of knowledge representation to show the relationships (that use ranked-models between penalty logic and SCNs. semantics), and use this definition 4.1. Reasoning with ranking functions A ranking to every model “normality” function over a set of models is a function that assigns a real value (rank) in the set. The ranking of a model may be considered as a grade for the or the “goodness” of the model. As we saw in previous function ErankE. Similarly, function for a global minimum may be viewed ranking and therefore characterizes subsection, every ranking function. function every SCN E is characterized is equal by the ranking energy some SCN. I3 The search performed by the SCN the thus as a search for a model to some high-order that minimizes Penalty resentations mechanism logic formulas, of ranking independently classical functions. logic WI%, It may be useful and SCNs may be interpreted as rep- to define our reasoning therefore of the knowledge representation form: Definition 4.1. Let W = (0, 1)” be the set of models defined over a set of n atomic propositions. A ranking function k : W -+ R is a function into reals. a A ranking large positive number). A preferred model x’ of a ranking that minimizes k; i.e., k(T) = mina{k(y’)}. function k is strict iff the domain of k is (0, oo} (where 00 represents function k is a model that maps models The set of preferred models of k is denoted rk. Definition 4.2. Let f, k, e be ranking rf. f k+ebf. is entailed from the background knowledge k using functions. f is entailed from k (k k f) iff rk C iff the evidence e (e bk f) The consequence relation induced by k is the set of all pairs {(e, f) ( e /=” f}. The model-based reasoning mechanism consistent with the above definitions defined logic if Vranke is taken as the ranking for penalty in Section 2 is function. IR There is no guarantee however, is polynomial in n (the number of visible variables). that the the size of the network that represents an arbitrary ranking function 222 G. Pinkas/Art@ciul Intelligence 77 (I 995) 203-247 4.2. Calculi to describe ranking functions in a rank- Our next step is to describe symbolically ing function. This subsection defines several function and shows their equivalence. Sentences of such languages are interpreted using ranked- models semantics, representation into another are allowed if some basic properties are preserved. the knowledge languages from one knowledge that is encapsulated and transformations for describing ranking The following representation definitions and its meaning. establish the relationship between a form of knowledge for each sentence of the language L. The function m(s) function is a triple Definition 4.3. A calculus of possible models and m : L -+ {k 1 k is a ranking a ranking the interpretation of s (x’ b s) entails sentence m( s’). Similarly, is interpreted as the addition of their corresponding s’ (s k s’) if the ranking of a background of the sentence a combination iff x’ is a preferred model of the ranking (C, m(), M), where L is a language, M is a set that assigns is called s. Let s, s’, e, k E L; a model x’ is a preferred model s is a function function} function m(s). A sentence the ranking sentence with an evidence entails function sentence i.e., e kk s iff ranking functions; function m(s) (m(e) + m(k)) b m(s). The consequence relation of k is the set of all pairs {(e, s) 1 e b’ s}. Both classic predicate logic and propositional logic can be viewed as calculi whose languages describe strict ranking functions. Example 4.4. Propositional propositional well formed H,( x’) ) ) , given a formula s (03 represents a large positive teristic function of the WFFs and is recursively defined as: is (L, m( ), (0, I}“), where L is the language of (oo( 1 - real). H,( x’) is the charac- and m(s) outputs the function formulas calculus (WFFs) X,9 1 -H,(X), if s = X, is an atomic proposition, if s = -G’, H,(T) = K,(g) x H,&), if s = 31 A ~2, H,,,(% + H,,(X) - Hs, (2) x H,&), if s = st V 3-2. The reader may easily observe, function that do not satisfy it. that returns 0 for truth assignments that any propositional WFF describes a strict ranking that satisfy the WFF, and OCR for assignments Example 4.5. Penalty logic is a calculus (Cc,, m, (0, 1)“) such that m( +) = Vrcmk+. Definition 4.6. Let s E LI and s’ E 1s~ be sentences of two (possibly different) (L, m, M) and (L’, m’, M); we define three kinds of equivalence relations between calculi them: G. Pinkas/Arbjkial Inrelligence 77 (1995) 203-247 223 to s’ (s MS s’) iff their corresponding ranking i.e., m(s) = m’(s’) + c. We call functions this or s-equivalence. to s’ (s ~9 s’ > iff their associated ranking i.e., VT, y’, m(s) this equivalence “preference functions (if+) < m(s) induce iff (y3 or preserving” (1) (2) (3) “magnitude preserving” s is strongly equivalent are equal, up to a constant difference; equivalence s is p-equivalent the same ordering over the set of models; m’( s’) (x’) < m’( s’) (~3. We call p-equivalence. s is weakly equivalent have equivalence the same sets of satisfying models; “minima preserving” to s’ (s MW s’) iff their corresponding ranking i.e., Tmcs) = Tmr(st). We call functions this or w-equivalence. Observations. ( 1) If two background sentences are strongly equivalent, sentences iff (m’( s’) +m’( e) ) 1 m’(c) e, the two corresponding s zS s’ then for every evidence m(c) have the same meaning (e.g., Boltzmann machine, that sometimes induced consequence [5] ), since entail the same set of conclusions; then for any given evidence i.e., if k c, (m(s) + m(e)) e and every conclusion . Therefore, relation. is associated with two strongly equivalent i.e., In addition, the ranking sentences the probabilistic is preserved function sentences entail (2) If two background the two sentences and s xp s’, then for every conclusion m’(c) If two sentences same set of direct conclusions; guarantee . We can’t guarantee this property (3) the same set of conclusions; are p-equivalent, then for every strict evidence e, = (0, co} iff (m’( s’) + e) k i.e., if dam(e) c, (m(s) + e) b m(c) this property for any non-strict evidence. s, s’ are weakly equivalent, then i.e., m(s) b m(c) the two sentences the iff m’( s’) b m’(c). We can’t entail to hold once we try to add evidence. The reader may easily observe that if two sentences are strongly equivalent then they are also p-equivalent If all we want and if they are p-equivalent they are also weakly equivalent. is to preserve the set of conclusions achievable the minima strict evidence preserving” “preference If however, we would like to be able to combine to perform transformations knowledge, we may use transformations which only preserve alence). formed knowledge, we need need “magnitude bine any evidence or give probabilistic Most of our transformations (strongly means same (up to a constant difference). We define now an equivalence Strong equivalence functions equivalent). that the ranking two calculi. between preserving” (strong equivalence) to our transformed in the reminder of this paper are “magnitude interpretation of two forms of knowledge from a piece of (weak equiv- to our trans- transformations. We if we want to com- knowledge. preserving” representation that are induced by either these representations are the Definition 4.7. A calculus Cl = (C, (0, l}“, m) is (s-/p-/w-) equivalent to a calculus 224 G. Pmku.s/ArtiJzcicd Inteilqenc~e 77 (I 995) 203-247 C’ = (L’, (0, I}“, m’) iff for every s E L there exists an (s-/p-/w-) s E L. and for every s’ E C’ there exists an (s-/p-/w-) equivalent equivalent s’ E C’ We thus can use the language C to represent every ranking the language C’, and vice versa. In the sections calculi and show that all of them describe function that is repre- to come, I shall present the knowledge embedded sentable using several equivalent in SCNs. 3.3. Some examples qf equivalent calculi of’ energy functions). Example 4.8 (The calculus to describe energy functions as sum-of-products ing ranking where {E} products, and m(E) = ErankE. Two special cases are of particular of quadratic variables. functions. The calculus qf energy functions is the set of all strings and the calculus of high-order that was used for describ- ({E}, (0, l}“, m( )), functions written as sum-of- the calculus functions with no hidden The algebraic notation can be viewed as a language is therefore representing functions interest: energy energy into strongly equivalent functions with hidden variables those hidden variables. We may therefore conclude In Section 3.4, algorithms were given that ( 1) convert high-order energy functions to i4 low-order ones with additional hidden variables, and (2) convert higher-order strongly equivalent energy that the calculus of ones without to the calculus of high-order energy functions with no hidden units is strongly equivalent functions. Thus. we can use the language of high-order energy functions with quadratic no hidden units to describe any symmetric connectionist (SCN) with arbitrary number of hidden units and vice versa. Note also that the calculus of SCNs, whose language describes graphs, weights and thresholds, is of course also strongly equivalent to the calculus of quadratic energy functions. (possibly) network calculus calculus). Example 4.9 (Propositional propositional is a weak equivalence. The energy function E, algorithm: (1) is equivalent In 1401, I showed to quadratic energy minimization. is obtained that the satisfiability I claim of that this the following from 9 using each of at most of subformulas, is done by adding additional hidden atomic propositions, three and the new propositions. For into a conjunction the WFF Is This Convert variables. “naming” binary subexpressions of the formula using example,(((AVB)VlC)~(DVE))isconvertedinto(T,ttAVB)A(T2H T,VX)A(T2-DVE). the result Assuming C,i H7Ps, 3 where H, Convert low-order procedure of Section 3.4. is of the form A, pi,, the energy function is the characteristic function defined in the result the cubic terms to quadratic ones using a high-order to is computed in Example 4.4. to be (2) (3) - _ ” In these papers we were concerned only with weak equivalence, but it is easily shown that strong equivalence holds. I5 In contrast to the familiar MAT. connectives in a subformula are not limited to disjunctions of literals. G. Pin!uzs/Art$cial Intelligence 77 (1995) 203-247 225 The global minima of the energy calculus and can be used as a high-level ( 1) the algorithm exist: of the WFF. Propositional quadratic energy functions However, function equivalence the same set of satisfying models, neither evidence can be added nor the probabilistic interpretation function are exactly equal to the satisfying models to the calculus of is therefore weakly equivalent to describe SCNs. language [40] ) that converts an energy the function have to a satisfiable WFF may generate an exponentially the WFF and the energy long WFF; and (2) two limitations that although is preserved. It means is weak. (in 4.4. The equivalence of penalty logic and SCNs This section shows that penalty logic formula can be represented efficiently by a penalty logic formula. logic and SCNs are strongly equivalent: Every penalty in an SCN and every SCN can be described eficiently When a PLOFF $ is strongly equivalent to a network described by an energy function E then: ( 1) The set of global minima of E is equal exactly to the set of the preferred models of cp. (2) Both knowledge representations induce than s’ iff ErunkE(s) < ErankE(s’) the same order on the possible mod- iff VrankJ, (s) < i.e., s is “better” els; Vrunk+ (s’) . (3) Knowledge update can be done by merging The equivalent operation to the energy new PLOFF network with a new piece of knowledge is cumulative. An addition (subtracting) in the energy space is adding to the knowledge base the new PLOFF with the existing one. terms of the the old one. The update of a representing the energy (deletion) function is therefore modular and simple. 4.4.1. Representing penalty logic using SCNs Theorem 4.10. For every PLOFF Cc, = {(pi, (pi) 1 i = 1, . , . , n} there exists a strongly i.e., there exist a constant c such that equivalent quadratic energy function E(x’, ?); Vranke = ErankE + c. The size of the network that is generated by E is of the same order as the length of (I/; i.e., the number of symbols in J/. the following procedure: Construction. We can construct E from rC, using (1) Start with an empty set of assumptions $‘. For every pair (pi, cp) in +, create a new hidden variable Ti, “name” cpi using Ti cf (pi and add the pairs (co, 7;: ++ pi) to and (pi, Ti) into $‘. The penalty 00 represents a real value that is large enough force the to be satisfied. The original penalty pi causes 7;:‘s to compete with each other; while that if c then pi also holds. (CI’ is therefore strongly holds (among equivalent as hidden variables. (2) Construct to J/ and the Ti’S may be considered the energy function ci OOE~~~, - cj pjTj, where Eq is the function the high penalty 00 guarantees the “naming” the winning constraint theories) generated by the algorithm described in Example 4.9. 226 C. Pinkas/Ari@ciul Intelligence 77 (I 995) 203-247 Proof. To show Vranke = ErankE + c: If the hidden units T in E are free to settle to a minimum, the minimum value c, of this function by setting 7;: to true if (pi is satisfied, and to false if p, is violated. Therefore, then for any clamping of the visible variables, EOO~+++,, always obtains ErankE (I) = e ‘:‘-~P,=~C,--&;+ c p; FI +v, FI !=I -(Ib,) pI + c = Vrank& - c. 0 =c 7ti+$q I function independently to the energy The “naming” of the first step that will contribute if the number of variables as a whole will not have the atomicity we expect. Thus, in an is needed only assumption C,D~ is greater than three. If this is the case and we do not “name” pi, then the second step of the algorithm might generate more then one “triple”. Each triple will have of the other triples, a penalty and the constraint the ranking that will be generated will not be the one we wished. The high penalty we use function for the “naming” to always find solutions constraints. Once we guarantee needed number of variables guarantees whole (with zero penalty) or it is not satisfied of one constraint into more preserved. is generated. Thus, either the constraint is p,); then one “triple” does not happen, and are satisfied, all that is the the energy function is to make the 7;‘s compete as if they were the original assumptions. When is satisfied as a i.e., the splitting the atomicity is less or equal to three, the way we construct that all the “naming” that only one triple (and the penalty the “naming” that satisfy the system constraints causes is The network that is generated a search for a preferred to the sound and complete proof theory, it can also be seen as can be seen as performing theory of I+!J; i.e., the T,‘s that win the competition correspond model of 9. According searching to the assumptions for a preferred in the preferred theory found. In the following example the assumptions have less than four variables, thus “naming” is not needed. Example 4.11 (The Nixon diamond case of Example 2.2). The PLOFF converted is: that is to be 9 = {(300O,N),(1000,N ---t Q), (1000, N + R), (10,Q + P), (10, R + 4’)). No “naming” is needed, so 9’ = 9. Each of the pairs is converted to an energy function: 1000 N --f R 1000(E,NvR) = lOOO( N - NR), 1000 N--tQ 1000(&h,“Q) = lOOO( N - NQ), 10 R + TP 10(E_R~+) = lO(RP), IO Q-P lO(~F,~vp) = lO(Q - QP), 3000 N 3000( EN) = 3000(-N). G. Pinkas/Art@cial Intelligence 77 (1995) 203-247 227 Summing the energy terms together: E = -1OOONQ - 1OOONR + 1ORP - 1OQP - lOOON + 1OQ. The corresponding network appears in Fig. 4. Fig. 4. The network that represents the Nixon diamond example. It corresponds to the energy function: E = -10001VQ - IOOONR + 1ORP - 1OQP - lOOON + 1OQ. Example 4.12. Converting case with “naming” have less than four variables). the “meeting” example, we first show in Table 1 the general purposes only, since the assumptions (it is used for demonstration The energy function we get by summing the energy of the assumptions is: 1000T&M - lOOOT3CM - 1oooT4cs - 2000T*M + 1OOOr,s + lOOOT2M +2OOOT3C - lOOOT3M + 2OOOT4C - lOOOT4S + 1OOOM - 2000C + 999rt -201 OT2 - 1 lOOT3 - 2OOOT4. It is shown as a cubic symmetric the assumptions Fig. 5(b). Since we can generate a simpler CipiE,, = 1(-M) (strongly in Fig. 5(a) and as a quadratic network network in in our example have less than three variables each, function of from the energy equivalent) network + lOO(C - CM) + lOOO(C - CS) (see Fig. 5(c)). Table 1 Example 4.12: general case Penalty WFF &+(x3 1000 1000 1000 1000 1 10 100 1000 Tl - meeting T2 +-+ (sick + ( 7 meeting) ) ( cold-only + meeting) T3 - lOOO(T~ - 2TlM + M) lOOO(T2SM - 2T2 - S - M + T2S + T2M) lOOO( -T3 - C + 2T3C + M - T3M - T3CM) T4 ++ (cold-only -+ sick) lOOO( -T4 - C + 2T4C + S - T4S - T4CS) Tl T2 T3 T4 -lTl -1OT2 -1OOT3 - 1 OOOT4 228 G. Pinkus/Artijicul /nfelii~mcu 77 (1995) 203-247 -10 s 1000 M 4 1 100 -21 Fig. 5. Equivalent (a) cubic; (b) quadratic: and (c) quadratic for the simple conversion (no naming). Ihr the meeting example symmetric networks (the numbers in the circles are thresholds): it is possible theories), Once preferred our definition of entailment. A construction it is possible to generate a network that searches for preferred models to construct a network that will reason according (or to in Section 5. of such network is described 4.4.2. Representing SCNs us penalty logic ,formulas This subsection shows that it is possible logic formula. The motivation here to describe efficiently is to demonstrate and compact language for specification of symmetric that penalty any network by a is net- connectionist logic penalty an efficient works. Theorem 4.13. Eve? energy function E is strongly equivalent there exists a constant c such that ErunkE = Vrank$ + c. to some PLOFF $; i.e., (1) (2) function: Eliminate hidden variables of Section 3.4. The energy of-products function form and Construction. The following algorithm generates a strongly equivalent PLOFF from an energy (if’ any) from the energy function, using the algorithm (with no hidden variables) is converted into a PLOFF is now brought into a sum- in the following way: Let E(.?) = I:‘:, w,, nii, x’!,, be the energy function. We construct a PLOFF that The formula (network). The size of the formula (linear in the number of connections). is generated is strongly equivalent energy is in the order of the size of the original to the original function network G. Pi&as/Artificial Intelligence 77 (1995) 203-247 229 Proof. To show Vrank* = ErankE + c: Vrank+ (2) = c -wi + c Wl w,<OA~(~~/jX,,,) WWx’~-(/\ c =- c Wi + c Wi + w;<O/+l( A x,,, ) Wi + c W W/>OAx’!F( A x,,, ) X/# )) w;<o w,m+/j x,,, c wrmm/1 WI x/,, I =CwinXi,,+cwlnX~,,-cwi Wi<O It wr>O n WI 40 = ErankE + c. 0 Example 4.14. Looking at the network of Fig. 4, we would like to describe as a PLOFF. The energy function is: this network E = - 1OOOh’Q - 1OOONR + 1ORP - 1OQP - IOOON + 1OQ. The negative terms are: (IOOOJVAQ), (1000,N~R), (lO,QAP), (1000,N). The positive terms are: (10,lR v +), (10, -Q). The final PLOFF is therefore: (lOOO,Nr\Q), (lOOO,NAR), (lO,QAP), (lOOO,N), (10,~RV+‘), (10,-Q). Note that as it is usually however, very meaningful; the case with reverse-compilation, it is clear that a compact description the formula we get is not exists for every network. 5. A connectionist inference engine Suppose a background PLOFF 9, an evidence PLOFP e, and a query which is a like to construct a connectionist to ( 1) tC, u e k (p; (2) (I, U e k (-I(P) ; or (3) network standard (strict) answer one of the possible both @ p 40 and $ F (740) logic WFF 9. We would three answers: (“ambiguous”). engine our connectionist Intuitively, is built from two subnetworks, each of which is to find a satisfying model to search trying is biased for a preferred model which satisfies also p, whereas to search for a preferred model which satisfies ~rp. If two such models exist, then we is biased the second subnetwork for rl, ; e. The first subnetwork conclude also satisfies p, we conclude that 40 is “ambiguous” (@ 6 e entails neither 50 nor -a). If no preferred model that @ U e k up, and if no model also satisfies asp, we 230 Table 2 fi U*’ U{(C (QUERYP U{(E,(QMRY~ G. Pinkas/Artijiciul Intelligence 77 (1995) 203-247 searches for a preferred model of Cc, that satisfies also P searches for a preferred model of 1+4 that satisfies also YP - PI)} -+ (+‘)I)} bias @ to search for a model that satisfies P bias I// to search for a model that satisfies ( YP’) U{(E, (P A ,P’) + AMBfGUOUSp)} if two satisfying models exist conclude “AA4BIGCKlUS” that do not agree on P, we U{(.s, (P ++ P’) + ( -AMB/CUOUSp))} if despite models we conclude NOT ambiguous. the bias we are unable to find two such satisfying that $ U e b p. For simplicity conclude conjunction atomic proposition. Later we’ll describe a general solution. (atomic propositions let us first assume of literals or their negation) that the evidence e is a strict and that 9 is a single To implement rl/’ by naming this its copy intuition we first need all the atomic propositions to duplicate our background knowledge A using A’. For in a query, we then add two more is used to initiate a query P; clamped by the user, when he or she inquires about P. The unit the answer of the system. It will be set to TRUE if we can Cc, and create each atomic proposition P that might participate propositions: “QUERYp” and “AMBIGUOUS~“. QUERYp it will be externally “AMBIGUOUSp” conclude neither Our inference that +G entails P nor that 9 entails 7P. engine can be therefore described (in the language of penalty represents logic) as in Table 2 Using network the algorithm of Theorem 4.10, we generate that is generated for the Nixon example is shown in Fig. 6. the corresponding network. The two similar subnetwork: One for a preferred model that satisfies the query and the other searches for a preferred model the falsifies for the Nixon diamond case: the two rings represents Fig. 6. Inference network searches the query. To initiate a query about P the user externally clamps the unit QUERYp. This causes a small positive bias E to be sent to unit P and a small negative bias --E to be sent to P’. Each of the two subnetworks Cc, and r+V, searches for a global minimum (a satisfying model) of the original PLOFF. The bias (E) is small enough so it does not introduce new global minima for each of the subnetworks. It may however, constrain the set of G. Pinkas/Artijcial Intelligence 77 (1995) 203-247 231 that also satisfies If a satisfying model then the set of global minima the bias exists, global minima. is in the new set of global minima of +. The new set of global minima preferred models of I#J that also satisfy the query. If no preferred model also satisfies query for one of those models. therefore then this model is the set of all the is unaffected by the bias and the network searches succeeds, we conclude “AMBIGUOUS”, models agree on the same truth value for the query. The “AMBIGUOUS” is then set to “false”, and the answer whether $ b p or whether in the unit P. If P is “true” models. Similarly, the bias rules. that all the satisfying proposition ti b ~rp can be found is $ b 5p since P holds in all satisfying otherwise we conclude that satisfy also then the answer to find models The network If it tries if P is false, we conclude is a strict conjunction that + /= ~4p. of literals, the evidence network simply by clamping When background a new evidence evigence 9 U e U {(co, P ++ p)} and by querying about P, a new atomic proposition. the user may add it to the the appropriate atomic propositions whenever an arbitrary for case we need e and an arbitrary query (D: We do this by building to combine an inference network is observed. the general In and schedule time. Since the problem if it manages time. However, attempts to find a global minimum is certain take exponential The network that was generated converges that will always give us the correct answer instances find a global minimum. An annealing search. A slow enough annealing the correct answer, but it might we will probably not find an algorithm polynomial the problem are continuously knowledge representation with the time complexity not sacrificed. The inference mechanism time resources with the accuracy of the answer. Only limited and we wish to stop the search when this limit is reached. The annealing be planned process. Although as more time resources are given. to to the correct answer l6 like in [ 171 may be used for such therefore is NP-hard, in of in AI, they use is usually in this section, as in [ 51, trades the time resources are given, schedule can is always given at the end of the its guess [45] ). Traditionally of the language [ 281, ” and the accuracy of the answer to accelerate being made (see for example the expressiveness the answer may be incorrect, systems they allow is able to improve and an answer to fit the time for special the system the search limitation, described trades 6. Learning propositional formulas So far, we have seen that networks can be compiled shows incrementally much of the appeal of connectionist models This section and develop compiling Assume the satisfying formulas. the network truth assignments a representation tries to learn an unknown of 4p. For simplicity, that SCNs can learn unknown propositional is their ability that is equal to learn from logic formulas. However, from examples. inductively, formulas to the ones constructed by formula p by looking at the set of to that the formula let us assume I6 There are also other techniques for improving the chances to escape from local minima [ 15,211. I7 Connectionist systems like [ 591 and [ 191 trade expressiveness with time complexity. 232 G. Pinkus/Artificial lnrelligence 77 (1995) 203-247 is a satisfiable WFF. The task of the network in such learn a way that at the end of the learning process to the one obtained by translating 40 into E,. Clearly, by doing so, the set of global minima of the energy function is equal to the set of satisfying models of (o (r,) which is the training set. is to update function its weights is equal the energy We may to be stored as memories, look at the process as learning of associative memories: Given a set of that those vectors are the satisfying models like to construct a network such that the global formula, we would assuming function are exactly equal to the vectors presented. that will be described uses high-order units (hyper-arcs) that it is always possible to convert the hyper-arcs I8 ; however, the into pairwise by adding hidden units (see Section 3.4). vectors of some unknown minima of its energy The algorithm reader should remember connections Definition 6.1. A k-CNF where each clause proposition or a negated is a WFF that is formed as a conjunction (AND) of clauses, (OR) of up to k literals. A literal is either an atomic is a disjunction (7) atomic proposition. For example the first contains (A V 1B) A (-A V -C V D) is a 3-CNF that is composed of two clauses: two literals and the second contains three. I shall present now a new learning order arcs) and a fast learning algorithm truth assignments realities the unknown that satisfy After each presentation the network that satisfy the formula. These truth assignments rule for symmetric (possibly high- connections that learns an unknown k-CNF formula from the the possible represent rule; they are called also examples or presentations. is guaranteed to have a set of global minima is updated, and the corresponding that is exactly equal seen so far. Therefore, assuming we know the k of the unknown the desired network is generated after a single scan over the training energy func- to the set k- tion of presentations CNF formula, set. Note that every formula can be brought in theory though, when k is too large. I9 for every set of presentations into a k-CNF form; thus, the algorithm works formula (p. It is not practical and for any unknown 6.1. A learning rule for high-order symmetric connections , x,) Let an instantiation introduced by clamping of the visible units XI.. , such that x; t (0, 1). A presentation . ,X, be a vector of zeros and ones of the visible .5 = (XI, rule units, soon to be described for the update of the weight of a single l-order hyper- arc: It is composed of two parts: the first checks whether an arc should be updated as a result of the current presentation, while the second part updates the visible units Xi with the values xi. The learning is an instantiation is responsible the weight. Ix The memories network searches I9 Fortunately, in such network are content-addressable: to complete the rest of the bits. given partial description of a stored vector, the expert domains are regulated by relatively short rules and therefore small k is sufficient. G. Pinkas/Art@cial Intelligence 77 (1995) 203-247 233 if they are seen for the first time *O A new combination 6. I. I. Checking whether to update the arc The idea is that certain bit patterns in the training set, causes arcs that connect units some weights the training is updated updated. A hyper-arc and the rest of the units of the pattern are not active; not in the arc should be zero instantiated. if it connects units involved set should cause an updating of in to be in the new pattern that are i.e., units of the pattern in this bit combination of k bits that participate 6.1.2. Updating The procedure the weight to update a weight (once it has been determined that the arc needs to be updated) may be viewed as an extension of the Hebbian If the number of zero units that participate otherwise familiar (both active or both inactive) the weight; (odd), decrease. For the special case of a pairwise connection, we get the if the two units have the same activation value rule for high-order connections: the weight otherwise. rule that increases is even, increase in the hyper-arc and decreases the weight 61.3. The k-clause Let Arc = {Xi,, Given a presentation learning rule (formally) . . . , Xii} be an Z-order arc. x’ = (x1, . . . , x, ) that instantiates the visible units to O/ 1 values, iff there exists a new k-bit pattern P = (Xi, = xi,, . . . , Xi, = the l-order arc Arc is updated Xi, 9 X,jl = 0, . . . 7 9 Xjk_1 = 0) that has never been seen in one of the earlier presentations, and that includes zero-instantiated. the number of zero units in Arc is even (including (- 1) if the number of zeros is odd. the units of Arc, such that the rest of the units (Xj, , . . . , Xjh_, ) are (+l ) if If this condition holds, then the weight of Arc is incremented the all ones case), and is decremented Example 6.2. Given updates: the presentation ABC = 011, a 2-clause rule causes the following l The weight of arc AB is updated by Nan = - 1, since the 2-bit combination l The weight of BC (A = 0, B = 1) is new and the arc contains an odd number of zeros. is updated by n ~c = +l, 1, C = 1) is new to the arc and the arc contains no zeros (even). since the 2-bit combination (B = l The bias of unit B (which the 2-bit combination since zero-units (A = 0) and the arc B includes no zeros (even). is updated by An = +l, is the singleton A = 0, B = 1 is new to the arc B, it is extended using arc {B}) The bias of A is not updated since adding a zero unit. In a similar way, the arc AC is decremented C is incremented it cannot be extended the bias B). (like into a 2-bit combination by (like AB), and the bias *” This is a one-shot i.e., multiple occurrences learning, the probability presentation or a hundred learning: once a pattern is seen, it is captured completely of the same pattern do not provide us with more information. that a bit combination repetitions generate the same representation. is irrelevant occurs to the rule we want and is not needed any longer; to Bayesian to learn. A single In contrast 234 G. Pirrkus/Arrrjicml lnrelligence 77 (I 995) 203-247 6.2. Learning k-CNF to start connections an example appears, example. The network, however, does not grow linearly with the presentations, the weights change so that the global minima as more examples are being presented. Each time the new includes regularities of the presentations). the presentations that satisfy some unknown cpq then the algorithm generates a network whose global minima are is qf the k-CNF f ormula, and whose energy function are truth assignments the set of presentations Theorem 6.3. v k-CNF formula exactly equal E,. The network is generated after u single pass over the presentations. Proof. Only a sketch of the proof is given: The proof is based on showing that the algorithm is equivalent to Valiant’s algorithm [ 681. Valiant’s algorithm starts with a list of clauses for learning k-CNF all possible k-clauses over n atomic propositions. For every presentation signment clauses the unknown k-CNF from the list that are not satisfied by the example. in every step, (positive example) It can be proved the conjunction that satisfies that is a formula these presentations. Therefore, when all the examples are seen, the k-CNF formula has been learned. is consistent with all the presentations seen so far and exactly of the clauses in the list that that consists of of a truth as- the algorithm eliminates First. we need to show that the initial conjunction of all possible k-clauses can be by a network with zero weights represented Later, we show that the clause elimination performed after each presentation. (the initialization step is equivalent step of our algorithm). to the set of weight updates An energy function of zero (or any constant energy function) are contradictions or tautologies the same number of clauses. The initial conjunction algorithm the zero weights) is exactly such formula and therefore, represents that have the property list. The next step is to show that the set of weight updates performed by the k-clause the desired rule after one presentation in Valiant’s algorithm corresponds if it is a disjunction to Valiant’s elimination step. A clause is eliminated represents that that every model satisfies exactly in Valiant’s (with of all possible clauses the starting point of our algorithm formulas G. Pinkas/Artijcial Intelligence 77 (1995) 203-247 235 by the example ofsomek-bitpatternP=(Xi,=l,..., instantiated is performed of the network are the energy by adding: Xinl=l,I;,=O ,..., $,=O),wheretheXi,‘sare in the energy space by deleting to one, and the Yi,,‘s to zero. An elimination the energy of a clause c terms of E,. Since the weights terms with reverse signs, the weights are actually updated If the number of zeros the units Xi!‘s in the pattern The arcs that are updated as a result of this addition, contain P that are instantiated with ones, while the rest of units are zeros (in P but not in the in the arc is odd, the sign of the term n Xi, fl c, that arc). If the number of zeros corresponds therefore is even, the sign is positive and the weight if there exists a new bit combination in the arc (if any), while to the arc is negative and the weight is decremented. the rest of the bits of the combination is incremented. An arc is updated P, whose one’s are included the arc) are all zeros. (outside 0 Example 6.4. Learning truth assignments: the XOR formula ABC l {011,101,000, (A $ B) H C, looking at the four satisfying 110). We need a 3-clause rule since we cannot express our formula in less than 3-CNF. The patterns we look for are therefore 3-bit combinations (the presentations themselves). Given the presentation ABC = 011: nABc = - 1 (odd number of zeros) ; ABC = +1 (even number of zeros) ; Given n ABC = -1 (odd); n~c = +l (even); Given ABC = 000: n*Bc = -1; &c = +1; n,, = +1; &B = +1; n* = -1; & = -1; nc=-1; Given ABC = 110: &Bc -1; A,JB +1; 236 G. Pinkas/Artijicial Intelligence 77 (1995) 203-247 (a) Co) Fig. 7. The network high-order network; for XOR (A e B) - C that was constructed is the quadratic equivalent with one hidden unit H. (b) by the learning algorithm: (a) is the k-clause learning well. If the network passes another cycle of learning begins. rule for an entire cycle and then to test whether the network performs stops; otherwise, k is increased and the test, the algorithm 62.2. A general scheme for learning k-CNF when k is unknown first */ rule on all the examples of the training set; if the network performs sufficiently well, stop; learning ( 1) k = 1; /* try monomials (2) Activate k-clause (3) TEST: (4) k=k+l; (5) Goto (2). One approach to the TEST (line 3 of the above scheme) is discussed (PAC) in [ 141 and In learning. correct” approximately time a network whose chances to Valiant’s notion of “probably is related this model, positive and negative examples are given from some arbitrary distribution. The task is to find in polynomial (on the same distribution) would necessary are also less than 6. The approach guarantees that only polynomial there are exponential approach to have an error rate larger than E are less than S, for arbitrary small E and 8. We to use k larger than of the algorithm and if time number of satisfying models). that is not PAC motivated but similar the above conditions in n, 1 /S, 1 /E, even like also to make sure that the probability in [ 141 satisfies (polynomial is needed in style Another given a complete examples). The the network unnecessary training task is to generate a network set that contains all the satisfying assignments that performs well to be e-bad large k, is also less than 6). is less than a), and that is compact (the probability is when we are (only positive of of using (the probability As in the PAC case, the test in this case is also a sequence of samples of the network tests whether to a wrong global allows up to m errors out of r checks. 2’ If the number it fails and k is increased. A to behavior; each of the checks minimum. The test procedure of errors full discussion literature on learning is less than m then the test succeeds, otherwise, is too lengthly, and the reader is referred theory and approximation the network converges of these testing theory. ** techniques 2’ m and r are computed 22 The paper does not carry any contributions the testing phase of step three of the general from the epsilon-delta learning scheme. bounds using Chemoff bounds. to these techniques. related I only suggest their adaptation for G. Pinkas/Artifcial Intelligence 77 (1995) 203-247 237 7. Experimental results Experiments have been made on randomly that were generated were conjunctions have managed to find satisfying solutions generated propositional of 3-variable clauses formulas. The (3-SAT). 23 The to large scale 3-SAT problems speed. Performance [57] are provided. comparison of several symmetric models and the formulas simulations with remarkable GSAT algorithm 7.1. Simulations I have machines three tried and mean field networks.24 types of algorithms inspired from Hopfield networks, Boltzmann 7.1.1. The Hopjield version is found: tries or until a solution Perform MAXTRIES In each try: set the values of the units l Randomly l Perform Hopfield cycles until either MAXCYCLES is found or until MAXCONST continuous reducing A Hopfield cycle that asynchronously solution without the energy. is one (zeros and ones). (each unit is updated only once) by randomly updated selected before cycles have been executed, a cycles have been performed updates all the units to be selecting a unit that has not been that need in this cycle, and updating its value in the following way: l If neti > 0, the unit becomes one; l If neti < 0, the unit becomes zero; l If neti = 0, the unit value is flipped. 7.1.2. The Boltzmann version tries or until a solution is found: Do until MAXT In each try: l Assign l Anneal (zero/one) random to the units. the system, starting with temp=l until cycle; values temp=O: temp by l/TEMPSTEPS. - Perform a Boltzmann - Reduce When CLES continuous the temperature tries have been performed,2’ cycles could not reduce the energy. is zero, Hopfield cycles are executed until either MAXCY- a solution has been found, or MAXCONST l If MAXTRIES tries have not been executed and a solution hasn’t been another annealing slows). begins with TEMPSTBPS=TEMPSTEPS+DELTAT found, (annealing 27 3-SAT problems are convenient for a benchmark because performance results of several other algorithms am available to compare. 24 William Chen assisted me during the experiments both with ideas and with the programming. 25 The number of cycles includes those executed during the annealing. 23x G. Pinkus/Artificd Intelli~encc 77 (1995) 203-247 A Boltzmann cycle is an asynchronous in random order but only once). which is a function of net; and the temperature flipping (every unit is visited update of all the units their value stochastically with a probability (see Section 3.2.3). 7.1.3. The mean field version As in the Boltzmann version, the simulator is slower); however, the first annealing cycles (see Section 3.2.4). while the rest of the annealings tries MAXTRIES annealings time is done using mean field theory are done using (each the annealing (MFT) Boltzmann cycles. 26 A MFT cycle is an asynchronous in random order , and each unit in its turn updates update of all the units (as in Boltzmann cycle). The its own activation units are selected value using the activation function for MET. 7.2. The experiments Random 3-SAT formulas of II variables and m clauses were generated in the following way : l Generate i.e., zero/one to be generated will be satisfied by this assignment. truth assignment; a random vector of n bits. The formula l Starting with an empty formula, until m clauses are added: - Randomly generate a 3-variable clause - If the clause is new and is satisfied by the assignment, (selection of 3 out of n variables). then add the new clause to the formula. conducted, a ratio of 4.3 between In the experiments number of variables fiability problems 100, 120 and 200 variables, and only 50 formulas were generated variables. The parameters used for the simulations (m/n) was kept. This ratio was found formulas were generated the number of clauses and the to generate “hard” satis- for each of 50, 70, for 300, 400 and 500 appear in Table 3. One hundred [34].” During the final stages of experiments2* local search for satisfiability similar networks became known are executed. arc performed In each flipped is selected until to us [ 13,571. In each try a random tither a solution flip, only one of the variables randomly among two recent algorithms that perform a very and may be seen as sequential variations of Hopfield tries is generated and variable “flips” flips were performed. [57], maximum MAXTRIES is found or MAXTRIES truth assignment In GSAT is selected to be the variables which when flipped cause the largest for flipping. The variable xi Trying more MFT cycles is not a good strategy because MFf 27 The way we generate the formulas is different from I34 1. Our generator forces the formulas to be satisfiable, whereas in I34 1, random formulas are generated that are not forced to be satisfiable and later the Davis-Putnam algorithm 141 (which is used to eliminate the unsatisfiable formulas. Our approach is based on resolution) seems to make the distribution generated easier than that of [ 34) Nevertheless, the comparisons to GSAT are still valid since all experiments were conducted with the same set (B. Selman, private communication). is deterministic. of formulas. It remains to be seen whether similar results happen in unforced distributions. 2X Our experimental design, which began after the presentation of the connectionist approach in the AAAI Spring Symposium of 1991, had a different idea for random generation of satisfiability problems. We changed our benchmark design to meet the ratio reported in [ 34 1. G. Pinkas/Art@cial Intelligence 77 (1995) 203-247 239 m MAXTBIES MAXCYCLES MAXCONST TBMPSTBPS DELTAT 215 301 430 516 860 1275 1700 2150 50 50 100 250 500 2000 2500 3000 250 350 500 600 200 6000 8000 10000 20 20 60 60 60 120 170 200 8 11 15 14 28 35 50 77 m 215 301 430 516 860 1275 1700 2150 GSAT 268.22 436.43 1095.35 1374.47 4817 8771.8 16247 50664 Hopfield Boltzmann 24.64 33.37 69.43 49.99 85.92 105.2 154.32 297.82 24.04 28.36 83.89 59.04 88.39 101.68 129.14 233.54 1 I I 1 2 5 5 5 MFf 18.73 13.14 55.59 33.05 46.78 55.92 106.26 152.06 Table 3 n 50 70 100 120 200 300 400 500 Table 4 n 50 70 100 120 200 300 400 500 (largest reported for satisfiability the approaches. in satisfied clauses better than the Davis-Putnam absolute gradient). GSAT has been increase perform significantly popular algorithms of comparing satisfied clauses are flipped. The algorithm of [ 131 was not directly us because of its close similarity comparison with GSAT, parameters were taken from the experiments (MAXCONST, TEMPSTEPS of the problem. 3o No fine tuning of these parameters was done. to algorithm which is one of the most [4]. We have implemented GSAT for the purpose the number of by to the Hopfield version.29 For the purpose of fair and MAXCYCLES in [ 571. The rest of the parameters for n, m and the MAXTRIES [ 131, all the variables which and DELTAT) were intuitively taken according implemented to the size the values reported increase In Table 4 gives the average number of cycles in which each of the algorithms found a solution. Table 5 shows the percentage of experiments in which each of the algorithms managed to find a solution in the first trial. The reader should note that the comparison with GSAT is based on parallel execution. to run on parallel time. The number of flips in a cycle was not counted A cycle (a GSAT flip or a single update of all the units) architecture and to take a constant is assumed 2g The difference the algorithm 3(’ The TEMPSTEPS Hopfield had in a successful try. fails is not truly random. is that in [ 131 nodes are visited in a predefined order, and the vector that is generated when parameter was taken to be approximately 0.75 of the average number of cycles which 240 Table S G. Pinktrs/Arti$ciul Intelligence 77 (I 995) 203-247 V1 21s 301 330 5 I 6 860 1275 1700 2150 GSAT Hopfield Boltzmann 69% 61% 68% 65% 66% 74% 80% 66% 81% 83% 70%’ 71% 83% 90% 88%’ 86% MFT 94% 94% 93% 87% 96% 96% 94% 92% since all the flips in a cycle are done in one parallel step (constant that GSAT was not designed very different had we measured for parallel execution; flips and not cycles. the comparison time). j’ Note also could have been For parallel execution, the connectionist approaches are clearly leading. Not surpris- ingly, MFT has the best performance for first-hit. 8. Related work and discussion 8. I. Connectimist approuches Derthick functions “mundane” [5] observed that weighted at his reduction logical constraints and used them to implement reasoning is never skeptical. The system described to energy there are however, several basic differences: (which he called “certain- those constraints translated a subset of the language KL- in this paper has some similarities with his system. (Derthick uses different en- logic (1) and no hidden units), likely single model; his and literature that is described here can be implemented with like Hopfield net- architectures to take advantage of the hardware for these are given so that every network is given ties”) can be used in massively parallel architecture. Derthick into special energy functions ONE. The approach described Looking from ergy functions Derthick’s system closer (see Section 8.2). standard works or Boltzmann machines. implementations networks. can be described as a PLOFF and not just the reverse. (4) A learning algorithm that achieves low-order units, using relatively well-studied therefore algorithms It is possible as well as of the learning (3) Formal proofs of two-way equivalence in this paper systems, described is more cautious in recent is based on finding a most to symbolic nonmonotonic from direct compilation. that were developed the same networks (2) The system that are obtained in its behavior Another connectionist nonmonotonic reasoning based on maximum I use standard is different; likelihood low-level is that of Shastri [ 581. It uses evidential system to reason in inheritance networks. My approach to connectionist models and am not restricted time for a cycle I’ Constant time for parallel GSAT cycles in a constant average time with a suitable parallel architecture. is certainly is not so obvious. 1 conjecture, however, true for the parallel connection& approaches: however, a constant that a GSAT cycle can be computed G. Pinkas/Art@cial Intelligence 77 (1995) 203-247 241 networks.32 inheritance time complexity, whereas and guaranteed; trades correctness with however, is guaranteed to work and has a polynomial Shastri’s system the system described here tries to solve an intractable problem is not i.e., a correct solution (a global minimum) time; This article shares with [ 1,19,59,65] the chance of finding one improves as more time is given. the implementationalist [ 481. These small subsets of predicate calculus by either spreading activation or motivation implement considerations, systems by rule firing. The expressive power of these mechanisms and tractability structures, of attacking constraint, however, can be extended is limited by performance complex In this article I had no intention to show how to represent any propositional and how networks can cope naturally with conflicting beliefs. The technique and multi-place predicates. rather, I intended and they all stress the problems of representing syntax sensitivity these problems; first-order predicate calculus further for representing [ 431. We may look at penalty logic as one of the layers of abstraction of high-level logic may be seen as a first level of abstraction cognitive processes and low-level neural that is higher than that are needed implemen- implementation the language described (see [l] for a nice discussion on the multi-span approach). in this paper we can map several of the systems mentioned them into symmetric networks (possibly by logic, and then compile between descriptions tations. Thus, penalty the neural Using above into penalty sacrificing efficiency) [ 421. 8.2. Symbolic systems is along semantics is a binary [26] or Pearl rational consequence results about the relationship in preferential semantics [27], Lehmann between to our paradigm: A strict consequence the lines of work done to systems with preferential and Magidor [60], and that use ranked models, [ 371. 33 Lehmann relations and (induced relation between a strict evidence and a strict conclusion. logic Penalty is related in particular like those of Lehmann and Magidor’s ranked models can be applied by a PLOFF $) It is therefore strict WFFs. Lehmann satisfies certain conditions rational strong conclusion is implementable in a symmetric network. Also, any symmetric network may be viewed as implementing some rational consequence relation. We can therefore be sure that every implementation of our connectionist a set of pairs Rg = {(p’, 40) 1 p’ /=’ cp}, where both p’ and 40 are relation as one that is function. As a result, we may conclude a rather and Magidor defined a rational consequence for our system: Every rational consequence iff it is defined by some ranking induces a rational consequence rules), and proved that a consequence (inference inference relation. relation relation relation engine Iogic is not based on Bayes semantics. On the surface, Penalty of preferential it based on Cox axioms. However, systems based on preferential It was developed using it does not compute probabilities the notion nor does have been discovered between semantics and systems based on epsilon semantics 34 that tight relationships reasoning. 32 We can easily extend our approach as predicates with free variables. Those variables are bound by the user during query M These systems are related in turn to probabilistic reasoning 34 In e’psflon semantics probabilities approach zero or one. to handle time. inheritance networks by looking at the atomic propositions (Bayes systems) by means of epsilon semantics. 242 G. Pin!as/Arrtj?ciul Intelligence 77 (1995) 203-247 that can be reduced directly [ 121 which actually computes are based on the Bayesian approach interpretation) Pearl based on maximal entropy considerations system uses the same ranking the penalties of violated beliefs. (based on probabilistic [ 10-121. One such system to penalty the penalties from a given conditional logic is that of Goldszmidt and knowledge (the user does not specify any penalty). The i.e., summing in this article; function as the one described Penalty logic has some similarities with systems that are based on priorities [ 31 is based on levels of reliability. Brewka’s (approximately) logic can be mapped using our architecture, such as that of Poole into penalty [50] to beliefs). One such system for propositional large enough penalties. Systems can also be implemented generated automatically. Another system where the user does specify that several nice properties hold (e.g. specificity). Penalty priority systems by assigning priority system such as system Z+ will also be entailed by the approximating base. However, logic knowledge system may be drawn decisively as bolder considered and as in that is based on priorities than those which are based on priorities some conclusions logic. in penalty scaled penalties. 35 Every conclusion the penalties, but there is a “ghost” (less cautious) (given system logic by selecting (with strict specificity) [ 111, the penalties can be [ 121 is system Z+ them so that changes that is entailed that are ambiguous In this sense penalty in a penalty in a priority logic can be [47]. [ 121. We are given are birds and penguins (like Z+) will not be able to conclude the wings” case the do that For example consider defaults: birds the “penguins and fly; birds have wings; penguins logic can only approximate following not fly. Many systems based on priorities penguins have wings. Penalty i.e., that penguins do have wings despite for this intuitive deduction is that penalty to be more “normal” not fly but have wings also have no wings don’t have such fine preference. (as in [ 1 I]). Priority-based logic in contrast will conclude according to our intuition; the fact that penguins do not fly. The reason the models where penguins do logic considers than models where penguins do not fly and they system will be ambiguous since (Nixon is also a football For another example the Nixon case (Example ‘P) 2.2) when we add to it: consider fans fan and football (1000,/V 4 FF) and (10,FF + systems will still be skeptical about tend not to be pacifist). Most other nonmonotonic -P P [ 10,26,30,37,64]. since supporting P than the two assumptions supporting 1P. In this particular case however, we can correct this behavior by changing that the penalty learns, may adjust and nonmonotonic Our system boldly, and in contrast with intuition, like our system its own intuition by two). Further, a network for Q ---f P (multiplying the one assumption and thus develop autonomously the penalties it is better to defeat behavior. decides Because we do not allow for arbitrary partial orders [ 10,601 of the models, are other fundamental ranked-models are cases where the intuition semantics) s6 problematic examples where our system boldly concludes, while other systems are skeptical tell us that skepticism is the right behavior). there (and all systems with (these ‘5 The penalties are scaled so that there penalty of a higher priority. 76 Hector Geffner (private communication is no subset of low-priority assumptions whose sum exceeds the ) G. Pinkm/Art$cial Intelligence 77 (1995) 203-247 243 The following possible wish: to prove is an example that no ranking for which we have clear function exists that induces intuition; it is nevertheless, the intuitive behavior we Example 8.1. Assume The intuition we have states that: the following defeasible rules: A + D, B -+ TD and C -+ TD. l Given A, C, D we should conclude -B; therefore, rank( ABCD) < rank( ABCD). l Given A, B, C we should conclude that D is ambiguous; therefore, rank( ABCD) = rank(ABCD). l Given A, C, D we should conclude that B is ambiguous; therefore, rank( ABC6) = rank( ABCD). l Given A, B, C we should conclude that D is ambiguous; therefore, rank( ABCD) = rank( ABCD). This is a contradiction by the examples cannot be implemented by any ranked model. since runk( ABCD) < runk( ABCD). Thus, the intuition as stated 9. Conclusions The main contributions tions for a connectionist propositional knowledge; knowledge (3) demonstrating large scale, randomly generated 3-SAT problems. penalty I have representation mechanisms: (experimentally) of this paper are: ( 1) the development inference (2) rigorously of theoretical founda- and learning two (sometime opposing) that is capable of representing engine relating and unifying connectionist logic; the efficiency of the algorithm used by SCNs for networks and propositional lines these Along its sentences reasoning and inconsistency therefore and penalty logic It is possible functions. and SCNs. Penalty introduced logic and showed mappings logic may be used as a framework between for defeasible handling. Several systems can be mapped into this paradigm are given, that (usually) matches our intuition. as ranking cannot be expressed the right penalties that some intuitions behavior settings of the penalties. When suggest features a nonmonotonic to show, though, serves two purposes: logic and symmetric networks is ( 1) we can translate a logic into an equivalent network (this serves the basic construction A strong equivalence between sentences of penalty formally proved. This two-way equivalence sentence of penalty of our inference oscillating be used as a specification clarifying network) language engine) look at the dynamics of such networks. can be described by penalty (at higher ; (2) any symmetric network non- (and also any asymmetric logic sentences. The logic may thus and gives another level of abstraction), 244 G. Plnkas/Artijiciul Inrelligence 77 (I 99.5) 203-247 energy functions; (2) high-order logic; and finally Several equivalent high-level functions with no hidden units; energy tional (4) penalty to describe any SCN and every sentence of such languages SCN; however, penalty languages. Algorithms inference languages can be used to describe SCNs: ( 1) quadratic (3) proposi- are expressive enough into an than the other are given for translating between any two of the languages above. that is capable of answering whether a query the global minima that make it more attractive logic. All these languages logic has properties can be translated is constructed the formula is clamped, engine An follows of the network correspond exactly (knowledge) or not. When a query to the correct answers. The engine can obtain it inductively its knowledge formula or by in time (in the length of the size of the training set) providing k is a small constant. algorithm from examples. Any unknown R-CNF formula can be learned either by compiling to be equivalent to a powerful a symbolic is shown algorithm symbolic learning linear learning The developed within the PAC paradigm. Revision of the knowledge and adding new evidence are easy tasks if we use penalty the (or deleting) to to the PLOFF is simply computing the energy the existing knowledge. Thus, a local change function of the new PLOFF and the network: adding that describes then adding a PLOFF (deleting) terms logic to describe energy the function describing the network The mappings given exceeds their potential expressive languages I have implemented on a Boltzmann machine minimum. exist. The technique are evidence problems or in connectionist the approach. (e.g., n-queens is translated in this paper are limited the propositional (like first-order predicate several nonmonotonic to a local change in the network. to propositional knowledge; however, case, and allows also for higher-level more logic) to be represented [ 431. I have not noticed any problems with local minima although simulator, toy problems (like Nixon, Penguins, and the network managed etc.) to always find a global they definitely scales well for large randomly generated 3-SAT problems and there repair methods provide good results to other NP-hard [ 361) repair speed to [ 39,45,46] may add additional [ 331). Advances in heuristic techniques energy minimization (e.g., (e.g., that similar heuristic The ability of these networks to learn and make adjustments in the energy landscape, may provide a new research direction. Learning algorithms may be used to speed up the local minima and widening global minima. 37 network convergence in this article may be used If such research to build networks to satisfaction accelerate the techniques fast symbolic their own speed with time. described constraint time, by eliminating and are able is successful, that perform Acknowledgment Thanks to Jon Doyle, Hector Geffner, Sally Goldman, Dan Kimura, Stan Kwasny, Fritz Lehmann, Ron Loui, Judea Pearl and Dave Touretzky for helpful discussions. 37 Similar techniques have been tried for improving local search [ 36 1, G. Pinkas/Arttficial Intelligence 77 (1995) 203-247 24s References I I] J.A. Branden, Encoding complex symbolic data structures with some unusual connection&t techniques, in: J.A. Branden and J.B. Pollack, eds., Advances in Connectionist and Neural Computation Theory 1 : High-level connectionist models ( Ablex, New York, 199 1) I21 R.D. Brandt, Y. Wang, A.J. Laub and SK. Mitra, Alternative networks in: Proceedings IEEE International Conference for solving Traveling Salesman on Neural problem Networks, San Diego, CA ( 1988). list matching and the problem, I31 G. Brewka, Preferred sub-theories: an extended logical framework for default reasoning, in: Proceedings IJCAI-89, Detroit, MI (1989) 1043-1048. 141 M. Davis and H. Putnam, A computing procedure 151 M. Dcrthick, Mundane reasoning by parallel constraint for quantification satisfaction, theory, J. ACM 7 ( 1960) 201-215. Ph.D. Thesis, CMU-CS-88-182, Carnegie Mellon University, Pittsburgh, PA ( 1988). I61 M. Derthick, Mundane reasoning by parallel constraint satisfaction, Artif Intell. 46 (I-2) (1990) 107-157. 17 I J.A Feldman, Energy and the behavior of connectionist models, Technical Report TR-155, Computer Science Department, University of Rochester, Rochester, NY ( 1985). IS] J.A. Fodor and Z.W. Pylyshyn, Connectionism and cognitive architecture: a critical analysis, Cognition 28 (1988) 3-71. 191 S. Geman and D. Geman, Stochastic relaxation, Gibbs distributions and the Bayesian restoration of images, IEEE Trans. Pattern Anal. Mach. Intell. 6 (1984) 721-741. 1 101 H. Geffner, Defeasible reasoning: causal and conditional theories, Ph.D. Thesis, Department of Computer Science, University of California, Los Angeles, CA ( 1989). I I 11 M. Goldszmidt, P Morris and J. Pearl, A maximum entropy approach to nonmonotonic reasoning, in: Proceedings AAAI-90, Boston, MA (1990) 646-652. [ 121 M. Goldszmidt and J. Pearl, System Z+: a formalism Proceedings AAAI-91, Anaheim, CA ( 1991) 399-404. for reasoning with variable-strength defaults, in: local search for large satisfiability problem, SIGART Bull. 3 (1) ( 1992) 8-12. I 131 J. Gu, Efficient [ 141 D. Haussler, M. Keams, N. Littlestone and M. Warmuth, Equivalence Inf Cotnpur. (to appear); also in: Proceedings Workshop on Computational Learning Theory for polynomial of models leamibility, ( 1988) 42-55; also Technical Report UCSC-CRL-88-06 (1988). [ 15 I G.E. Hinton, Deterministic Boltzmann learning performs steepest descent in weight space, Neural Comput. 1 (1) 1161 G.E. Hinton, Preface (1989). to the Special Issue on Connectionist Symbol Processing, Art$ Intell. 46 ( 1990) 1-4. [ 17 I G.E. Hinton and T.J. Sejnowski, Learning and re-learning in Boltzman Machines, in: J.L. McClelland, D.E. Rumelhart and the PDP Research Group, eds., Parallel Distributed Processing: Explorations in the Microstructure of Cognition 1 (MIT Press, Cambridge, MA, 1986) 282-317. [ 181 S. Hiilldobler, A structured connectionist unification algorithm, in: Proceedings AAAI-90, Boston, MA ( 1990) ; also ICSI Technical Report TR-90-0 12 ( 1990). 1 191 S. Hiilldobler, CHCL, a connectionist limited resources, using inference system for Horn logic based on connection method and International Computer Science Institute TR-90-042 ( 1990). 1201 J.J. Hopfield, Neural networks and physical Proc. Nat. Acad. Sci. 79 (1982) 2554-2558. systems with emergent collective computational abilities, [ 211 J.J. Hopfield, Neurons with graded response have collective two-state neurons, Proc. Nat. Acad. Sci. 81 ( 1984) 3088-3092. of decisions [ 221 J.J. Hopfield and D.W. Tank, Neural computation computational properties like those of in optimization problems, Viol. Cybern. 52 144-152. 1231 A.B. Kahng, Traveling salesman heuristics and embedding dimension in the Hopfield model, in: Proceedings International Joint Conference on Neural Nehvorks ( 1989) 513-520. (241 S. Kasif, S. Banerjee, A. Delcher and G. Sullivan, Some results on the computationrd of networks, Technical Report JHUCS-89-10, Department of Computer Science, complexity symmetric Johns Hopkins University, Baltimore, MD (1989). connectionist 246 G. Pinkas/Art$ciul Intelligence 77 (1995) 203-247 I25 1 T.E. Lang and M.G. Dyer, High-level inferencing connectionist network, Connection Ser. 1 (2) ( 1989) 181-217. I26 1 D. Lehmann, What does a conditional knowledge base entail?, in: Proceedings Inrernutionul Conference on Knowledge Representution und Reusoning, Toronto, Ont. (1989) 212-222. [ 27 1 D. Lehmann and M. Magidor, Rational logics and their models: a study in cumulative logic, Technical Report TR-86-16, Leibnitz Center for Computer Science, Hebrew University, Jerusalem, 1281 H.J. Levesque, A fundamental tradeoff in knowledge representation and reasoning, Israel ( 1988). in: Proceedings CSCSI-84, London, Ont. (1984) 141-152. I29 I V. Lifschitz, Computing I30 I R.P. Loui, Defeat among arguments: 131 I J. McCarthy, Programs with commonsense, Press, Cambridge. MA, 1968) 403-4 18. circumscription, in: Proceedings IJCAI-85, Los Angeles, CA ( 1985). a system of defeasible inference, Cornput. Well. 3 (3) ( 1987). in: M. Minski, ed., Semantic information Processing (MIT I32 1 J. McCarthy, Circumscription-a I33 1 S. Minton, M.D. Johnson and A.B. Phillips, Solving form of nonmonotonic problems using a heuristic repair method, large scale constraint in: Proceedings AAAI-90, Boston, MA (1990) satisfaction and scheduling 17-24. reasoning, Arfif: fntell. 13 ( 1980) 27-39. I34 1 D. Mitchell, B. Selman and H.J. Levesque, Hard and easy distribution of SAT problems, in: Proceedings AAAI-92, San Jose, CA (1992) 459-465. [ 35 1 M. Minsky, Logical versus analogical, symbolic versus connectionist, neat versus scruffy, AI Mug. 12 (2) (1991). [ 36 I P. Morris, The breakout method for escaping from local minima, in: Proceedings AAAI-93, Wasington, DC (1993) 40-4.5. I37 ] J. Pearl, System Z: a natural ordering of defaults with tractable applications to nonmonotonic reasoning, in: Proceedings Theoreticul Aspects of Reasoning about Knowledge, Pacific Grove, CA ( 1990) 12 1- 135, learning algorithm, Neural Networks 2 I38 I C. Peterson and E. Hartman, Explorations of mean field theory (6) (1989). [ 39 I C. Peterson and B. Siiderberg, A new method for mapping optimization problems onto neural networks. In Int. .I. Neurul Syst. 1 (1989) 3-22. 1401 G. Pinkas, Energy minimization calculus. Neurul Cornput. 3 (2) ( 1991); also in: D.S. Touretzky, J.L. Elman, T.J. Sejnowski and G.E. Hinton, eds., Proceedings of the 1990 Connectionist Models Summer School (Morgan Kaufmann, San Mateo, CA, 1990). and the satistiability of propositional I41 I G. Pinkas, Propositional non-monotonic reasoning and inconsistency in symmetric neural networks, in: Proceedings IJCAI-9I, Sydney, Australia ( 199 I ). I42 I G. Pinkas, Converting binary threshold networks into symmetric networks, Technical Report WUCS-9 i- 3 1, Computer Science Department, Washington University, St. Louis, MO ( 1991). I43 1 G. Pinkas, Constructing proofs in symmetric networks, in: J.E. Moody, 1.J. Hanson and RI? Lipman, Advunces in Neural Information Processing Systems IV ( 1992) 2 17-224. I44 I G. Pinkas, Logical inference in symmetric connectionist networks, Doctoral Thesis, Washington University, St. Louis, MO ( 1992). I45 1 G. Pinkas and R. Dechter, A new improved connectionist in: Proceedings AAAI-92, San Jose. CA ( 1992) 434-439. activation function for energy minimization,, I46 I G. Pinkas and R. Dechter, On improving connectionist I47 I G. Pinkas and R. Loui, Reasoning energy minimization, a taxonomy of principles .I. AI Research (to appear), for resolving conflicts, in: Proceedings Third International Conference on Principles of Knowledge Representation und Reasoning, Cambridge, MA ( 1992). from inconsistency: I48 I S. Pinker and A. Prince, On language and connectionism: analysis of a parallel distributed processing model of language acquisition, Cognition 28 ( 1988) 73- 193. I49 I D. Poole, On the comparison of theories: preferring the most specific explanation, in: Proceedings fJCAf-85, Los Angeles, CA (1985) 144-147. for default reasoning, Art@ Infell. 36 ( 1988) 27-47. from inconsistent premises, Theory Decision 1 ( 1970) 179-2 17. framework I SO I D. Poole, A logical I 5 I I N. Rescher and R. Manor, On inference I52 I N. Rescher, Plausible Reasoning (Van Gorcum, 1976). IS3 I R. Reiter, A logic for default reasoning, Art$ IS4 I J.A. Robinson, A machine-oriented 23-41. Infell. 13 (1980) 81-132. logic based on the resolution principle, J. ACM 12 ( I ) ( 1965) G. Pinkas/Arttjkial Intelligence 77 (1995) 203-247 247 1551 D.E. Rumelhatt, G.E Hinton and J.L. McClelland, A general framework for parallel distributed processing, in: J.L. McClelland, D.E. Rumelhart and the PDP Research Group, eds., Parallel Distributed Processing: Explorarions in rhe Microstructure of Cognition 1 (MIT Press, Cambridge, MA, 1986). 1561 T.J. Sejnowski, Higher-order Boltzman machines, neural networks for computing, Proc. Amer. Inst. Phys. 151, Snowbird, UT (1986) 39-84. 1571 B. Selman, H.J. Levesque and D. Mitchell, A new method for solving hard satisfiability problems, in: Proceedings AAAI-92, San Jose, CA ( 1992) 440-446. I581 L. Shastri, Semantic Networks An Evidential Formulation and Its Connection& Realization (Pitman, London, 1988). I591 L. Shastri and V. Ajjanagadde, A step toward modeling reflexive reasoning, Behav. Brain Sci. 16 (3) ( 1993) 477-494. 1601 Y. Shoham, Reasoning about Change (MIT Press, Cambridge, MA, 1988). [ 6 I] E.H. Shortliffe, Computer-Based Medical Consultation, MYCIN (Elsevier, New York, 1976). [ 621 Cl. Simari and R.P. Loui , Mathematics of defeasible reasoning and its implementation, Artif: Intell. 53 (1992) 125-157. [63 1 P. Smolensky, Information processing in dynamic systems: foundations of harmony theory, in: J.L. McClelland, D.E. Rumelhart and the PDP Research Group, eds., Parallel Distributed Processing: Explorations in the Microstructure of Cognition 1 (MIT Press, Cambridge, MA, 1986). [ 641 D.S. Touretzky, The Mathemafics of Inheritance Systems (F’itman, London, 1986). I65 1 D.S. Touretzky and G.E. Hinton A distributed connectionist production system, Cognirive Science 12 (3) (1988) 423-466. 1661 R.J. Williams, The logic of activation functions, in: J.L. McClelland, D.E. Rumelhart and the PDP Research Group, eds., Parallel Distribufed Processing: Explorations in the Microstructure of Cognition 1 (MIT Press, Cambridge, MA, 1986). 167 1 G.V. Wilson and G.S. Pawley, On the stability of the travelling salesman problem algorithm of Hopfield and Tank, Biol. Cybern. 58 (1988) 63-70. I68 ] L.G. Valiant, A theory of the learnable, Commun. ACM 27 (1984) 1134-l 142. 