Atiticial Intelligence 78 ( 1995) 461-505 Artificial Intelligence An active vision architecture representations based on iconic * Rajesh P.N. Rao, Dana H. Ballard Department of Computer Science, University of Rochestes Rochester: NY 14627, USA Received July 1994; revised March 1995 Abstract Active vision systems have the capability of continuously interacting with the environment. The rapidly changing environment of such systems means that it is attractive to replace static representations with visual routines that compute information on demand. Such routines place a premium on image data structures that are easily computed and used. The purpose of this paper is to propose a general active vision architecture based on efficiently computable iconic representations. This architecture employs two primary visual routines, one for identifying the visual image near the fovea (object identification), and another for locating a stored prototype on the retina (object location). This design allows complex visual behaviors to be obtained by composing these two routines with different parameters. The iconic representations are comprised of high-dimensional feature vectors obtained from the responses of an ensemble of Gaussian derivative spatial filters at a number of orientations and scales. These representations are stored in two separate memories. One memory is indexed by image coordinates while the other is indexed by object coordinates. Object location matches a localized set of model features with image features at all possible retinal locations. Object identification matches a fovea1 set of image features with all possible model features. We present experimental results for a near real-time implementation of these routines on a pipeline image processor and suggest relatively simple strategies for tackling the problems of occlusions and scale variations. We also discuss two additional visual routines, one for top-down fovea1 targeting using log-polar sensors and another for looming detection, which are facilitated by the proposed architecture. *This work is supported by NSF research grant no. CDA-8822724, NIH/PHS research grant no. 1 R24 RR06853, and a grant from the Human Science Frontiers Program. 0004-3702/95/!@9.50 @ 1995 Elsevier Science B.V. All rights reserved SSDIOOO4-3702(95)00026-7 462 R.F!N. Rue. D.H. Ballmd/Artificd Intelligence 78 (1995) 461-505 1. Introduction Vision in humans is not a passive open-loop image analysis task but rather one interaction with the world. This interaction that involves a continuous frequent use of saccades. These discrete eye movements, which can by the relatively achieve speeds of up to 700” per second, occur at the rate of about three per second. Experiments related to the subject’s momentary problem solving strategy have shown that saccades are intimately [ 6,23,73 1. is characterized The central role of eye movements in computer vision aimed at elucidating in human vision has inspired an extensive modeling of binocular called the technical advantages systems capable of similar movements. The effort has been variously effort camera active. animate, 741. Such models real-time video powerful and yet cheap hardware require task-oriented, dynamic, inexact or behavioral vision [ 2,4,5,22,55,66, the enormous data rates associated with images. Only recently has this become possible with the availability of the ability to handle for real-time image processing. to process Much work in passive vision, such as analysis of photographs of visual scenes, has the contents of the scene. Such that reconstruct is typically does not change and therefore the image quickly other than that of economy. However, tasks in real reconstruction. For taken advantage of extensive models a strategy has worked as the venue no pressing need in active vision systems which exploit eye movements time. the input image changes much too frequently example, Recent experiments image between the need for expensive in human vision, fixations between saccades usually that the complexity of information is limited reconstruction last only 300 milliseconds. to to avoid of the visual world. is thus tremendous to allow elaborate to solve complex [ 271. There from image saccades incentive retained indicate there information An alternative to reconstruction and a strategy which we feel is especially attractive from on demand. thereby necessitating representations for spanning is that of composing task-specific behaviors [ 771 that compute that vision is functional, simple set of visual routines is based on the hypothesis in the context of active vision systems a relatively Such a strategy the existence of a mechanism 161. A primary motivation that most natural human behaviors of workspace. Thus, visual they were initially that operate directly on the optic array in image coordinates. Such routines retinotopically representations are required of the fact ranges that the as when programs require only that can be computed quickly and which to variations the same viewing conditions task-directed for visual routines comes from an appreciation number of behaviors, one can assume the space of task-dependent remembered. This allows targets will be imaged to be only moderately are very stereotyped the use of simple in approximately for a significant indexed visual and occur in limited insensitive for visual routines comes from biological that the primate visual cortex is roughly organized in the parietal and temporal to new target eyes Additional motivation which seem to suggest specialized modules complementary currently a succession of location and identification cognitive goal. This observation of directing functions (located in the viewing direction. studies subserving [48,50,78] into separate the two lobes) the locations can be thought of as solving in the process of meeting a larger of visual and analyzing subtasks suggests a useful hierarchical decomposition foveated area. In such a setting, eye movements R.P.N. Rao. D.H. Ballard/Art@cial Intelligence 78 (1995) 461-505 463 decomposition Table 1 A hierarchical behaviors “Where” behaviors, which (adapted image component can be viewed as arising related of visual behaviors from solving of the simpler “What” and in turn rely on the more primitive ability of comparing a single model with a single from [ 51) interpretation. Visual problem task-specific composition sequential to scene Image components One Many Stored models One Many Comparing image component. a single model with a single Recovering whose location the identity of an object is currently being fixated. Identification: Location: Finding a known object in the current image. General visual computation. in scene interpretation, or the general problem of relating to external objects (Table 1) . The “What” component corresponds of a foveated point and the “Where” component a point of interest in the current problems of location and identification image. ’ This decreases problem enormously. In the location task, only one model internal to the problem to the to the the complexity of the is present and corresponds reduction task, only one location is present. Both location and identification image component in turn rely on the more primitive to compare a single model with and can be regarded as being composed of a sequence of comparisons. Complex visual behaviors can then be viewed as arising task-specific sequential compositions of the simpler “What” and “Where” ability involved behaviors models of identification problem of locating complementary interpretation in the identification behaviors a single such elementary from different behaviors. as shown the visual image near The purpose of this paper is to propose an active vision architecture of visual behaviors discussed above. The architecture decomposition routines, one for identifying based on the uses the fovea, and another a stored prototype on the retina. The two routines are subserved by two as side of the figure. The other is indexed by object location retinal identification hierarchical two visual for locating separate memories depicted by the box on the left-hand coordinates matches a localized locations. The result matches a fovea1 set of image the model coordinates of the best match. representation set of model is the image coordinates as depicted by the box on the right-hand features with all possible model is indexed by image coordinates of the best match. Object side of the figure. Object features at all possible in Fig. 1. One memory features. The result is features with image of the architecture The central iconic vector comprised of the responses of different order derivatives of Gaussian are steerable [ 251) at a range of orientations is a high-dimensional feature filters (which and scales. Such a feature vector serves as ’ An important distinction for biological modelers that our processes use solely “Where” does not imply Our location likewise uses both areas but the result is nominally routine uses both areas but the result is nominally to note in this context the infero-temporal and parietal cortices is that our use of “What” and respectively. routine in the parietal cortex. Our identification in the infero-temporal cortex. 1531 to describe small visual templates ’ Our use of the term iconic is analogous to its use by Nakayama which constitute visual memory. R.P.N. Rae. D.H. Ballard/Arf$icial Intelligence 78 (1995) 461-505 Image Image in Feature Space - Object in Feature Space Where What Memory indexed by Image Coordinates 1 pare Fovea in Feature Space IZ Objects in Feature Space I. The proposed active vision architecture. iconic representation. locations. The result is the location of the object from binocular vergence. Fig. common at similar a depth term obtained matched against a data base of iconic models, also encoded the object’s (Upper) To locate an object, The architecture uses two primary visual its features are matched against routines and a retinal features in retinal coordinates. This may be augmented by (Lower) To identify an object, the features near the fovea are in terms of features. The result is decision as to identity. R.PN. Rae, D.H. Ballard/Artificial Intelligence 78 (1995) 461-505 465 iconic large number of measurements point. In its most general form, the n-element in this paper, 9 basis filters were used at 5 octave-separated in the image an effective photometric description of the local intensity variations present region about a scene/object feature vector is comprised of the responses of m oriented basis filters at k different scales (n = m x k) ; for the experiments scales index for the local image patch near a given object point, to yield a 45-element at an image point makes its characteristic The relatively spaces vector practically (Section 2.1). In Section 3.1, we describe a simple normalization that makes invariant the view vector. For rotations about axes other the vector than the success of the descriptors depends on their moderate view the viewing axis, insensitivity. Our experiments rotations of up to 2.5’ at radial distances of 5 feet or more from the focal point. More drastic rotations are handled by storing feature vectors from different views as described in Section 4.5.1. unique due to the orthogonality that the filters are insensitive to three-dimensional in high-dimensional to rotations procedure inherent indicate about iconic of objects representations While multiscale (Section 4.2) ; experimental tasks (Table 2), their utility filters have previously been applied representations near a scene point; in active vision systems has remained their usefulness to fill this void by demonstrating a number of important visual behaviors. We first describe visual routines to solve localization in realistic scenes are presented also allow an active vision strategy the method, described early vision unexplored. This paper helps cilitating employ identification (Section 4.1) and object for these routines with complex objects The multiscale iconic partial occlusion scription of the occluder vision achieving Section 4.8 illustrates how the multiscale exploited leads naturally jects. Finally, Section 5 touches on the issue of incorporating the current and summarizes comparisons with some recently proposed object descriptions. to solve a multitude of classical largely in fa- that the two primary problems of object results in Section 4.5. for handling in Section 4.6, uses a de- in the form of a template which can be obtained via active for sensors. can be further in the scale of an object. The solution of a reflex for detection of looming ob- into color including iconic the use of the representation top-down guidance of the fovea during visual search using important aspects of our approach recognition in a method log-polar systems. Section 4.7 describes structure of the representation the problem of variations that also employ implementation representation to a simple information to handle strategies 2. Iconic representations The purpose of a representation medium features with an object that makes behaviors [ 51. The representation must (b) provide enough facilitate imply the development that the visual features comprising of visuo-motor information concerning in active vision systems is simply it especially to “as- to easy (a) allow fast execution of the various visual scene points, algorithms. The above re- the representation must first of all In for directing gaze at required learning in real time rather than be the result of elaborate multi-stage processes. the representation must be rich and robust enough to allow proper functioning sociate execute” routines, and (c) quirements be computable addition, 466 R.P.N. Rae, D.H. Ballard/Arti$ciul Intelligence 78 (1995) 461-505 in both internal and external channels. Finally, the representa- in the presence of noise tion must take into account scales and orientations. Our representation the responses of steerable Gaussian derivative scales into a single high-dimensional the fact that elementary achieves iconic feature vector. scene features occur at a variety of the above objectives by assembling filters at a number of orientations and 2.1. The favorable properties of high-dimensional vectors of high-dimensional demonstrates a sparse distributed memory the usefulness system the human memory system the normal distribution with mean n/2 and standard deviation the binomial distribution the advantages in many ways. the first to realize In [ 361, he convincingly in formulating Pentti Kanerva was among vectors as a representation medium. of high-dimensional binary vectors that mimics By using approximate vector and all other vectors of the space (0, 1 }” (for large n), most of the vectors (or “indifferent”) in other words, most of the vectors given vector, with only a minute qf an object of interest to considerable objects. As a result, when a specific class of similar vectors, vector approaches one of the vectors from the class only slightly in the form of a high-dimensional it is confused with the vectorial in the space are orthogonal lie at approximately noise before trying fraction closer or further away. Thus, a representation vector can be subjected of other to rapidly as the to determine whether a particular vector belongs that it does increases the likelihood representation to of the Hamming distances between an arbitrary it is easy to show that to any given vector; from a the mean distance n/2 fi/2 [ 71. The same result holds true for non-binary vectors such as the iconic representations in this paper. The components of these iconic feature vectors . , 127) and span an extremely presented implementation belong vector space consisting and m the number of basis tances measured between in Fig. 5(a)) distribution Most of the points of this space lie within indifferent thus effectively in our current to the set A = { - 128, large of Anlxk = 25645 points where k is the number of scales used of dis- in this space (marked by a “+” scene. This other unrelated points of distances has a mean p = 0.037 with a standard deviation u = 0.263. two standard deviations of the mean and are feature vector for a given model point filters per scale. Fig. 5(c) to the given model point. in terms of correlations and those for 220,268 (correlation E 0.0) the 45dimensional (i.e. normalized the distribution dot products) in a natural shows 2.2. The link to visual memor) There has been recent evidence [24] of the redundancy that aims to minimize suggest a close relationship between in an associative distributed memory. in the visual environment by producing the number of simultaneously that the primate visual system takes advantage coding a sparse distributed active cells. This finding seems to storage the goal of visual coding and subsequent Summarizing his views on the sensory interface with memory, Kanerva notes [36, p, 1191: R.PN. Rae, D.H. Ballard/Artijicial Inrelligence 78 (1995) 461-505 467 together The memory works with features and creates chunking things those internal objects transform small perturbations raw input from the world into features that are similar of objects. to match objects of the world, by internal objects and individuals in terms of those features. In order for the system’s sensors must invariant over that are relatively and concludes by asserting that . . artificial intelligence methods need to be augmented with mathematical and statistical methods of dealing with representations in high-dimensional spaces. visual iconic incoming time retain storage since representations and at the same in the environment to minor disturbances vectors. Hypothetically, could consist of these for vision-related memory In this regard, representations properties of high-dimensional the lines suggested by Kanerva. Stored stored representations may iconic this activation would be mediated by specific visual in the form of iconic feature vectors may be considered they are both relatively the the visual in a distributed manner then be activated they routines. an effective medium invariant attractive matching memories along by either are associatively “Visual perception” then becomes memory. The visual memory would form part of a larger memory holding sensori-motor programs the design of anthropomorphic modest start in establishing memory for indexing explored. and visual associative (see also [63] ) where the idea of using iconic feature vectors is for a wide range of behaviors. Such a memory may play a crucial into a visual memory based on Kanerva’s systems capable of complex visuo-motor a link between visual representations in behaviors. A sparse distributed memory signals or by other synonymous with is made in [64] this activation for the agent representations to which linked; role of 2.3. Basis functions from natural images Unlike random collections of pixels, images of natural scenes are characterized by a high degree of statistical to be highly correlated owing tend a pixel-wise representation some form of redundancy reduction regularity. For instance, pixel values in a given neighborhood to the morphological consistency of objects obtained from a camera of objects. Thus, and is highly redundant is desirable. The optimal linear method (in the mean squared error sense) expansion PCA generates for reducing redundancy via Principal Component a set of orthogonal components of the input data form a set of orthogonal in the order of decreasing variance. The eigenvectors (see (PCA) known as eigenvectors transform or eigenvector [ 1.51 for an introduction). is the Karhunen-Lo&e Analysis axes of projections distribution basis functions input distribution but due to the statistics of natural m of eigenvectors Thus, by using only the first m dominant eigenvectors computational axes) for representing are required inputs, considerable (m < n) account for projecting it is usually or principal to completely the input. Given n input images, all n eigenvectors of the in principle image set the case that only a small number images, in the input data. (or orthogonal for almost all of the variance as basis functions the input represent savings can be achieved. 468 R.P.N. Rue, D.H. Ballrrd/Arti~ciul Intelligence 78 (1995) 461-505 Table 2 The trend from variational methods towards the use of filters for solving specific problems in computer vision Computing methodology Problem being solved Calculus of variations Filters at single scale Filters at multiple scales Optic flow Shape from shading Brightness edge detection Curved line grouping Optic flow Shape from shading Texture segmentation Stereo correspondence Scene interpretation Biometric signatures References 1321 1331 I IO,31 I I45,51] I l,30,801 158,591 140,461 135,381 I ~~,~21 1191 for solving the general problem of object [ 761 employed PCA to synthesize Recent work by Turk and Pentland strategy with the vectors obtained by projecting the eigenvectors of a training set of face images; face recognition was achieved by using input face images [51] have used a similar and pose estimation. of the eigenvectors when new faces/objects (“eigenfaces”) a template-matching along a small number of eigenfaces. Murase and Nayar approach Both these methods to ask what the results of PCA would be if one are encountered. were to take the above process to its limit i.e. to perform PCA on a set of arbitrary natural stimuli. Hancock et al. [ 291 shed images containing introduced by Sanger some light on this interesting question by using a neural network [ 671 to extract images. the first few principal They discovered that regardless of the scale of analysis, the eigenvectors obtained were vem close approximations of different oriented derivative-of-Gaussian operators. a variety of natural and man-made of an ensemble of natural It is therefore natural require recomputation components recognition 2.4. lconic representations from Gaussian derivative jilters There has been a recent surge of interest in the use of multiscale spatio-temporal filters analysis and as computing machinery for proto-visual problems which had previously been tackled by variational methods. This historic is depicted for solving complex vision-related in Table 2. trend filters. By employing Here, we focus on the class of Gaussian derivative of these linear spatial filters at a variety of orientations tation of an image region can be obtained. This iconic representation the ideal of strict view invariance. are only relatively image color as a measure of surface albedo obtained by using Gaussian derivative are tolerant an ensemble and scales, an iconic represen- on image features are judged useful even if they is in view. One example of such a feature feature vectors like color in that they Instead, to variations [ 70,71 I. The photometric filters behave very much to modest variations compromises insensitive in view. The choice of Gaussian by the underlying belief derivative is motivated that these filters form an ideal set of natural basis functions in our iconic representation filters R.EN. Rao, D.H. Ballard/Artificial Intelligence 78 (1995) 461-505 469 for general-purpose object recognition. Part of the rationale for this belief stems from the fact that these basis functions are obtained as a result of applying the principle of dimensionality-reduction as embodied by PCA (see previous section) to large collections of images containing a plethora of elementary features from natural as well as man-made structures rather than just the training images of particular objects or faces as was the case for the basis functions used in [ 5 1,761. Further support for this belief comes from the observation that correlation filters generated by principal component expansion are statistically optimal in the sense that they maximize signal-to-noise ratio and yield much techniques (see, sharper correlation peaks than traditional raw image cross-correlation for instance, [ 431) . Indeed, Canny [ 131 has shown the first- and second-order Gaussian derivatives to be close to optimal for detecting the elementary features of edges and bars respectively. Finally, the Gaussian derivatives filters allow strategies for rotation normalization in the image plane because they are known to be steerable [ 251. 2.4.1. Steerable filters Steerable filters are a set of oriented basis filters that have the important property that the response of a filter at an arbitrary orientation can be synthesized from linear combinations of the basis filters. It is well known [ 251 that using a circularly symmetric Gaussian function in Cartesian coordinates (with scale and normalization factors set to 1 here for notational convenience), G( & y) = e-(x2+?‘*), (1) we can define two first-order basis filters q and Gy12 as: q = -$G(x,~) = _2xe-(x2+y2) and n/2 G, = +, y) = _2ye-_(x2+?‘2), such that the directional derivative in an arbitrary direction 6 can be synthesized as: Gy = cos(B)G(: + sin(B)GT’2. Higher-order filters at arbitrary orientations can be synthesized analogous to the first- order case by using basis functions denoted by: G$, n = 1,2,3, en = 0,. ..,h/(n+ l), k= l,..., n, (5) where n denotes the order of the filter and 8, the orientation of the filter. Fig. 2 shows these filters for a particular scale. Different interpolation functions are needed to steer the different order Gaussian filters, as shown by Freeman and Adelson [ 251. The number of interpolation functions that are needed for steering is one more than the filter order. So, for example, the first-order filters can be steered with two interpolation functions 470 R.PN. Rm, D.H. &dlurd/Artificiu/ Intelligence 78 (1995) 461-505 Fig. 2. The impulse response of nine oriented Gausstan derivative basis filters of up to the third-order here at an arbitrary regions denote negative magnitude.) used in the form of 8 x 8 kernels for convolutions with a five-level (shown regions denote positive magnitude while darker (Section 4.4). discrete versions of these filters are (a) Gt ; ( b) G? ; (c) Gq. (Bright low-pass pyramid of the input image. In our implementation scale). given basis measurements three functions given basis measurements at 0” and 90”, the second-order filters can be steered with at 0”. 60°, and 120”, and so on. In particular, where the first-order interpolants (,n = 1) are given by, k,,(B) = [cos(6 - (i- I)%-/2)], I = 1.2. For II = 2, we have k;?(8) = i[l +2cos(2(0- (i -- I)5-/3))). i= 1,2,3, and for n = 3, ki3(B)=~[2cos(8-(i- l,~/4)+2cos(3(8-(i-1)~/4))1, i= 1,2,3.4. (7) (8) (9) R.F?N. Rao, D.H. Ballard/Art@cial Intelligence 78 (1995) 461-505 471 3. The multiscale iconic index The feature in our architecture filters of up to index used steerability of up to this order, at least nine basis filters need third order. For maintaining section. Larger numbers of basis filters could to be used as described be used in order to counter the effects of noise but for the purposes of this paper, we retain the minimal basis set of nine filters. The response of an image patch I centered at uses Gaussian derivative in the previous (x0, yc) to a particular basis filter Gp the filter: is obtained by convolving the image patch with = II Gfbo JJ -x,yo -y)Z(x,y)dxdy. (10) in nine This results Further information independent regarding photometric measurements the image region centered at that image point is obtained by using the filters at different per scale, there are 9 x k total measurements where k is the number of scales. For the experiments, five different scales were used, for a total of forty-five measurements image scales. Since there are nine measurements at each image point. per point. The different so the responses, for example, responses at different scales are sensitive to the width of the templates, in, the easiest way to do this is to divide by the filter energy defined as: across scales, have to be normalized. As shown to be comparable [46], ei = JJ C$x,y)*dxdy, i= 1,2,3. Now define point the normalized in the image as the vector response of a set of filters to the area surrounding (11) a specific r = ( ri,.j,k > 9 i= 1,2,3, j=l,..., i+l, k=smin ,..., smax, (12) ri,,j,k denotes where denoting The iconic local intensity variations present filters were applied. the response of a filter with the number of filters per order, and k denoting i denoting the order of the filter, j the number of different scales. serves as a photometric description of the the in the image region near the image point at which index r thus obtained effectively 3.1. Rotation normalization and view insensitivity An attractive property of Gaussian derivative In this section, we exploit object the scale remains First, select indexes described above invariant relatively unchanged). the orientation this property filters is their steerability to obtain a simple method for making (Section 2.4.1) . the iconic the viewing axis (assuming to rotations about strategy responses, for two reasons: ( 1) the orientation these filter responses are usually and (2) can be computed directly the most stable. of the first-order filters as a reference. This is a good from the filter 472 R.t? N. Rue. D. H. Ballard/Artificial Intelligence 78 (I 99s) 461-505 Before Normalization I ,,,.’ _ll.,~_.,,ll.,,..~llll ,“‘11111,‘,‘. I11 I ._I, II I’ I I +‘ll l.,,llll,.‘,, IIII,. ,,,‘11 (cl After Normalization ,..,h. . ..ll.. _.LII,, ,,LII ,I(,‘-“‘.[ I ,,..I1 1. _,A., I I I I I I _,,,ll, ,,‘, II ,,,I’&, ‘I (b) (4 Fig. 3. Rotation normalization. the filter response histograms normalization; bars proportional smallest between scale responses in the order of increasing (a) A test image; for corresponding (d) the response histograms after normalization. (c) in the two images before responses are represented by upward to the response magnitude and negative ones by proportional downward bars with the nine in points near the elephant’s mouth rotated 38’ counterclockwise; largest ones at the end and the intermediate at the beginning, scale.) the same the nine (Positive image scales (b) Given a vector of raw filter responses, the current orientation can then be computed as: The filter responses are then rotated using the steering (horizontal) the normalized responses: to obtain itl . c ri.y ,!A;‘; ( cf + $ ) 3 rj,i k = ;‘=I (13) formulae to a canonical direction (14) i= 1,2.3. j= I . . . . . i+ 1, k=smin ,..., Smax. Instead invariant Note that this normalization makes duced with rotation direction. components. Another additional properties of the existing volutions as given by Eq. ( 14). Fig. 3 illustrates feature of the normalization the filters capture convolutions since the variations the matching process more powerful templates. The latter sacrifice variability than that pro- in the angular it in their process is that it can be done without the interpolation in angle, and preserve is linear; filters allow it to be carried out with a single basis set of con- It the rotation normalization procedure. the operation of convolution R.FW. Rao, D.H. Ballard/Artijicial Intelligence 78 (1995) 461-50.5 473 Fig. 4. Tolerance to modest view variations. (a) A point on the original image; (b) the same point correctly located by the algorithm in a second image with a 22.5” 3D rotation; (c) an unrelated point in the rotated image for the purpose of comparison; (d) the 45 filter responses (in the form of response histograms) for the point in (a) (top), the point in (b) (middle) and the point in (c) (bottom). is clear that the procedure has rendered to be almost vectors of the same point the two relatively uncorrelated model response identical. renders Rotations importantly, about an image plane axis are ameliorated the multiscale filters caused by the geometric effect of change the filter responses on a large number of responses responses of a few individual position. More so that there invariant. This fact is illustrated in the example shown scheme would be to make use of learned geometric distortion estimates such as the one proposed by Kass [39] the relative weighting of each filter as a adjust function of its sensitivity profile. Drastic rotations are handled by storing feature vectors in Section 4.5.1. from different views as described in two ways. First, the reliance in the index robust in viewing by a cosine envelope, the responses will be effectively in Fig. 4. A more complicated range of rotations to dynamically are dominated is a useful to changes for which 414 R.l?N. Rua. D.H. Bullurd/Arrijic~ul lnrelligence 78 (1995) 461-505 Table 3 Sensitivity of the match value figures shown are the average of the results for three pairs of corresponding to the length of the iconic vector points (= number of scales used x nine). The Number of filters Rank of matching point Difference in distance 9 18 27 36 45 18.3 4.3 I 3 I I 3.1.1. The importance of multiple scales -8.1 -6.3 1.0 5.6 IO.8 iconic responses at multiple representations. The use of filter of the perspicuity the superiority of mul- distances between from images these tested as a function of the number of scales used. Table 3 shows confirm the Euclidean in 2D rotated and unrotated to experimentally over single scale ones, points the iconic tiscale the response vectors for corresponding Fig. 3 were results. scales greatly enhances representations In order With less than three scales. the matching point is not the best point selected. However, the distance the is not the best shows to improve with with three or more scales it is ranked measures used in the match of the best and second-best point matching point the distance that even after the matching point additional that of the matching point. This column the best. The third column compares is that of the best minus is the best, its perspicuity first. In the case where the matching point in the case where is ranked continues scales. To further illustrate the greater perspicuity offered by multiscale vectors, we computed (indicated by a “+“) in a natural scene and all other points this time in terms of correlations, between a model response vector for a (Fig. 5(a) ). from scales are used (Fig. 5(c) ) than when only a single scale is used (Fig. 5(b) ) the distances, given point It can be seen that a much sharper correlation peak is achieved when responses multiple to form the iconic representations. greater the number of points located close 936 candidate points still remained model point) In particular, as many as 3011 points had a correlation templates whereas scales was only 39, most of them being to 0.94, in the single scale case whereas only one point (the than 0.90 with the model point in the case of single scale to the model point. When in the case of multiple threshold was raised in the multiple the correlation scale case. remained 3.2. /conic object representations The filter response vectors described tions of image patches centered at individual to learn a representation two principle of the currently from which model response vectors can be extracted. issues need to be addressed: foveated object, and (b) in the previous sections serve as iconic descrip- scene points. For the active vision system of a given model object of interest with a set of such vectors, segmentation (a) some form of figure-ground location of suitable points within the object R.fTN. Rao, D.H. Ballard/Art@cial Intelligence 78 (1995) 461-505 between single scale and multiple Fig. 5. A comparison table image and a selected point (indicated by a “+“) on a model object on the table. The distribution of distances the response vector for the selected model point and all other points in the (in terms of correlations) scene (c). Using responses (b) and multiple scale vectors and a sharper peak near the indifference from multiple scales distance of 0.0; only one point in the multiple scale case (c) whereas 936 candidate points fell in this category between is shown below for single scale response vectors (five in this case) than 0.94 in the single scale case (b). (the model point) had a correlation greater in greater perspicuity (a) Shows a dining templates. results iconic scale The problem of figure-ground than the general segmen- tation problem especially when active vision systems are being used (as in our case). in reasonably One possible cluttered strategy which has been shown to yield satisfactory is much simpler segmentation is the use of stereo in conjunction with a technique is a simple nonlinear [ 171. The zero disparity in other words, filter that have nonzero disparity; such as zero dis- filter that image image it only passes parity suppresses filtering features results scenes 476 R.P.N. Rao, D.H. Ballard/Artijicial Intelligence 78 (199.5) 461-505 Object I Fixation Point on Object of _+------. Interest Robot Horopter (Zero Disparity Region) Vergence Angle Right Pan Angle Left Camera Right Camera f Common Tilt Angle at the fixation distance with zero or close to zero stereo disparity. for zero disparity filtering. The robot horopter is the region of space the In the figure, the same locations on the left and right image planes thereby negative and positive respectively to approximately in the horopter while points on the triangle and square possess filter passes energy only in the robot horopter, in this case, points corresponding the required segmentation. The relative the pan and tilt angles of the binocular head and adjusting location of the horopter can be the vergence angle (see Fig. 6. Top view of the camera geometry located approximately points on the pentagon project falling disparity. The zero disparity to the pentagon, changed by manipulating [ 17 I for more details). thereby achieving is well-suited to perform the necessary of an object amidst a cluttered background. Fig. 6 illustrates technique the implementation in a hypothetical of the zero disparity problem to the figure-ground et al. [28] who use stereo range about the fixation point and input segmentation to extract figure- the scene with three filter can be to is similar that lie to an features these features for the filtering in the horopter. Such a filter energy ground segmentation binocular camera geometry objects. Further details regarding in [ 171. This approach found the one proposed by Grimson within a narrow disparity recognition alignment-based based matching within a predefined disparity in our case, stereo matching themselves system. Like Coombs, Grimson et al. use edge-operator- the cameras whereas the response vectors range for aligning can be carried out by simply using [ 35,381 or a subset of the responses. an approximate boundary of the object has been determined, a small number and the responses of these points can strategies were the object. For the experiments, this boundary two different Assuming of points can be chosen within be used to represent tested: R.PN. Rao. D.H. Ballard/ArtQicial Intelligence 78 (1995) 461-505 477 l Pick the object centroid and each of the points lying on the intersections of radial radii centered on the cen- from the lying within a specified distance increasing circles of exponentially lines with concentric troid as shown in Fig. 9(c). Only points approximate object boundary of the region near other object regions as well. As described satisfactorily in our object objects. the centroid while at the same are used. This method ensures a dense representation time information including of this strategy performed indexing experiments with a model data base of twenty in Section 45.1, l Pick a sparse number of salient points within using the filter responses within determined we used with an estimate of its spectral power square of point’s response vector magnitude: the relatively simple strategy of associating the object region. the object. Saliency can be readily In our experiments, saliency of an object point energy) as given by the (or photometric i&k i= 1,2,3, j= l,..., i+l, k=smin,...,smax. (15) salient is deemed if its photometric A point threshold T which can be computed based on, for instance, dard deviation of the energy associated with points within method was used for selecting object points tion 4.5.2. energy is greater than an arbitrary the mean and stan- the object region. This in Sec- in the location experiments A particularly of the above centroids of the most salient advantages intend to explore (though as yet untested) is to utilize a combination promising strategy two strategies: points are picked of both of the above methods with minimal computational from concentric regions of the object. Such a strategy would combine circles centered at the the overhead. We the use of this technique in future implementations. 3.3. The role of multichannel visual analysis by Gaussian derivatives While our choice of using Gaussian derivative filters for obtaining iconic descriptions may at first seem arbitrary, these filters which make objects. there exist a number of interesting properties that accrue to them especially suited for the purposes of indexing arbitrary 3.3.1. Principal components of natural images As mentioned eigenvectors introduced by Sanger in Section 2.3, the different oriented derivative-of-Gaussian have been shown by Hancock et al. [ 291 (see also [ 631) to be close approximations the dominant network of an ensemble of natural the first few principal patches of sizes 32 x 32, 64 x 64, and 128 x 128 (windowed the distortions set of 40 natural operators to images. In particular, Hancock et al. used a neural to extract image to avoid from a images. Random by a Gaussian to the network caused by square windows) were used as input [ 671 for principal component components of natural analysis images. (PCA) 418 R.P.N. Rue. D.H. Ballurd/Artificial Intelligence 7X (1995) 461-505 the first dominant derivative of a Gaussian, Regardless of the scale of analysis, an approximation of the zeroth-order bias of the input signals. The second and third resembled first-order derivative-of-Gaussians closely approximated resembling Gaussian derivatives of orders less than 4 accounted inputs. of the variance other higher-order Gaussian in a test set of 10,000 randomly chosen the vertical and horizontal respectively. The fourth, fifth, and sixth components derivatives. These six eigenvectors eigenvector was found for approximately 80% to be the DC representing in order to reduce in our representation, we implicitly Thus, by employing Gaussian derivatives some of the virtues of dimensionality-reduction zeroth-order derivative orders higher correlated orthogonal basis functions at the second and third orders in order to preserve to interpolate invariance steerability retain offered by PCA. We however omit the dependence; we also do not use to be highly tend incorporate non- the ability by using the outputs of the higher-order filters filters [ 421. We additionally to the outputs of lower-order to arbitrary orientations in Section 3. I. than 3 since as described illumination to achieve rotational and 3.3.2. Neurophysiologicul corre1ate.s Gaussian derivatives were used by Young to model primate cortical field that the different order receptive (such as Gabor the best suggested the different mathematical [ 831. An extensive of the Gaussian analysis of these profiles revealed provided functions) profiles derivatives functions IO were reported but the most abundant 4. It is interesting to note that traditional differential order derivatives description be able to handle complex as an example of such an image description. fit among in the literature. Orders as great as than to be of order less less algorithms use much (usually only first or second order) ; the abundant use of higher- richer edge maps in order to can be regarded ones were found image processing in the primate visual systems points than those provided by traditional to the need for a much scenes. The multiscale filter representation of image regions structure 3.3.3. Mathenzuticul properties A number of mathematical properties, as elucidated in [ 4 1,421, help justify some ot the choices made in our representation: l The responses obtained by applying series expansion of the retinal the different order Gaussian filters at a point an image patch centered at that point and form the terms of a truncated to a degree function can in a manner in terms of sinusoidal basis functions. Such the in terms of Gaussian derivative basis functions has been termed the scale of the Gaussian. by a linear combination In general, of Gaussian an arbitrary derivatives function blurred to Fourier series expansion illuminance on characterize Taylor dependent be approximated analogous an expansion Gram-Charlier series. l The nth derivative of the blurred the blurred nth derivative of the function equals function which in turn equals the convolution of the function with the nth derivative of the blurring Gaussian computing the filters may be interpreted naturally “fuzzy derivatives”. kernel. Thus as R.PN. Rao, D.H. Ballard/Artijicial Intelligence 78 (1995) 461-505 419 l Mixed partial derivatives, which were incidently ously absent among primate the other oriented receptive filters yield a complete basis [41]. field profiles, are in fact unnecessary found by Young to be conspicu- since of offset Gaussians the Gaussian derivative model, a number of other functions [26] or difference receptive l Besides functions of cortical however order derivative of a Gaussian modulated by a Gaussian the difference implementation field profiles. The need to search for the “ideal” is somewhat obviated by the fact that the asymptotic is just a sine (odd order) or cosine envelope, in other words, a Gabor function. of Gaussians model can be looked upon as simply of the Gaussian derivative operator [ 831. such as Gabor have been proposed as models filter model form for a very high- (even order) In addition, a hardware l The spatial description in spectral description portion of the retinal agrees with system image via a set of bandpass the classical neurophysiological in terms of “spatial frequency channels” understanding [ 12,211. in terms of partial blurred derivatives terms of a local Fourier decomposition is equivalent to a of a windowed spatial filters. This observation of the primate visual also have the property The Gaussian derivatives as filters” to some of the most significant elementary visual stimuli. For example, to optimal for to be close are known [ 131. This may not be surprising in light of the the principal components of natural image patches “matched the first- and second-order Gaussian derivatives detecting edges and bars respectively fact that these derivatives approximate comprised of different elementary that they approximately visual features. function Image the scant information may be located incorporation often unwarranted render of responses choices features such as bars and edges are usually present at a multitude of scales; the scales at which features of interest an especially tricky one. The the need to make a priori and the problem of scale selection scales avoids usually available regarding from multiple regarding The presence of elementary the need for filters that can detect features across a continuum of orientations. The isotropic Laplacian of Gaussian may seem to be the most obvious choice in this case as suggested [ 131 support the use of oriented filters. by Marr The fact that Gaussian derivatives are not only easy to compute but also easily steered to different orientations (see Section 2.4.1) make them an especially desirable choice [ 471 but signal-to-noise in our representation. using relatively ratio arguments interpolation functions toward simple point the scale of visual analysis. features at a variety of orientations The representation immunity. No single viewing conditions of nearly traditional independent representations in the form of a long vector of responses has considerable filter can be expected to produce noise the same response under varying from a large collection than it much more robust but the representation combines information image measurements, thereby making that rely on fewer image measurements. 4. Visual routines The normalized multiscale natures of the photometric filter response vectors surrounding distributions (or “zip-codes” [ 71) serve as sig- various points within an object. 480 R.P.N. Rao, D.H. Ballurd/Artijiclal Intelligence 78 (1995) 461-505 in visual routines formed by a set of such multiscale The iconic object descriptions can be readily embedded location problems. space can be matched against stored model vectors of different objects. (from problem, matched against point. filter response vectors and object localized point in In the location can be the entire image described as a collection of such vectors, one for every to solve the object problem, vectors from a single a single model vector a particular object) In the identification the set describing identification In order to compare the response vector r-’ from an image point and the response used is required. One commonly vector rm from a model object, a similarity metric (SSD) metric: metric is the sum of squared distances dl,,, = 118 -P/l*. For most of the experiments (or correlation) dot-product however, we chose to use the related metric of normalized of two vectors: din, = ri p Ikill IPII (17) primarily because volutions on video-rate normalization contrast changes caused by varying by vector length helps the dot-product operation can be efficiently implemented image processors such as the Datacube MV2OO. In addition, using con- the to global to make the matching process resilient lighting conditions. 4. I. Object identiJication In the general case, more than one model object can share the same iconic (represented index. Let that have rm as part of the set of models by their labels) M( rm) denote their set of response vectors. The identification ( 1) First obtain, algorithm proceeds as follows: for each chosen response vector r’ on the image of the object to be identified, is used as the distance metric), where T is a prechosen the model response vectors P such that dint 2 T (assuming correlation threshold. (2) For each model ML, initialize (3) For each rm from step ( 1) and each model Mi E M( Pm), set the “evidence” array E( Mi) to 0. E(M;) := E(Mi) + 1. (4) Output In other words, the outcome of the identification the model label M such that E(M) = max{E(Mi)}. algorithm the winner. The threshold T can be determined the model obtaining forward voting process, with deemed [65] where Kanerva’s the above routine sparse distributed memory model [ 361. is realized in a slightly modified is determined by a straight- the largest number of votes being in form in the context of experimentally as described R.PN. Rao, D.H. Ballard/Artijcial Intelligence 78 (1995) 461-505 481 4.2. Object location The location being matched in the current routine crucially depends on the fact that only a single model object to an image at any instant. Let us denote image as is this model that is to be located M={P,m=l,..., VImax}. (18) The (1) (2) location algorithm Assuming vector rm representing in its most general form proceeds as follows: that the distance metric being used is correlation, some model point m, create a distance for each response image I,,* defined by I,(X,Y) =min[P&,Imaxl, (19) (x, y), where dim is computed between for the point /I is a suitably chosen scaling constant brightest spot in the image). Find the best match point Imnx is the maximum the model vector rm and the image vector $ intensity value and image the possible (this makes the best matching point (xb,,, yb,,) in the image for each m using the relation (xb,,,Yb,) ==gmax{h(-&Y)}. (3) Construct a binary “salience” image S(x, y) where S(x,y) = 1, 0, if C&Y) E {(Xb,,,yb,)}. m= 1,. . .,mmax, otherwise. (4) Output the location of the object in the current image as (Xb, yb) where (Xb,Yb) =*gmm{S(x,y) *B(&Y)} (20) (21) (22) and B is an appropriate blurring or local averaging known in active vision environments. function whose size is usually For the sake of convenience rithms, we present our results applying the blurring operation. and clarity in terms of the distance in understanding the performance of the algo- image rather than the results after 4.3. A simple visual task using visual routines in Fig. 7(a)) Fig. 7 illustrates in a naive visual/motor the use of the visual routines task involving replication of patterns of square blocks located on one part of a large board onto another target pattern part of the board. Suppose gaze is first fixed on an initial (marked by a involves an implicit “What” “+” (this there occurs operation). When gaze has been shifted to a different point as shown in (b), the problem of moving gaze back to the previously the “Where” problem, which can be tackled using the location algorithm discussed above to obtain a best match point and its feature vector memorized foveated point. But this is simply in (c) as the brightest point in the distance image). (shown Fig. 7. Solving a simple visual task using the What/Where routines. (a) representation the original is stored in short-term nretnory (“What”). image” the “distance (“Where”). location (b) A new (arbitrary) is computed: Initial gaze location whose iconic gaze point. (c) To get back to the location the brightest spot represents whose iconic feature vector is closest to that of the original gaze point. (d) Location of best match is marked and an oculo-motor command (obtained, for instance. using a learned motor map I62 I ) can be executed to foveatc that point. Gaze can then be transferred by issuing an appropriate oculo-motor map 1621. to the retinal position marked by “+” command using, for instance, (as shown in (d) ) a learned motor 3.3. Implementc~ticm of tlw ~kul routines and location algorithms in the previous the identification implemented to a Datacube MaxVideorM MV200 pipeline Both have been Rochester binocular head with two movable color CCD cameras input servo-motor controls control each camera’s pan angle, use of a binocular head allows ground segmentation respectively. sections described using an active vision system comprised of the University of (Fig. 8) that provide system. A single two separate motors vergence control. The for figure- filtering in Section 3.2 and Section 4.6 platform while independent for strategies such as zero disparity and occluder detection as described the tilt of the two-camera thereby providing image processing The MV200 is comprised of a single image analysis capabilities. Of particular integrated 6U VME circuit board capable of a to our work interest wide range of frame-rate here is its ability to perform convolutions at frame-rate (30 per second). Both the location and identification algorithms for location, for all the points computations: vectors response vector in memory. Our implementation distance computations correlation since from a given model vector must be compared image while in the current the image must be compared greatly optimizes require a large number of distance to the response in the case of identification, a to all the model vectors stored for is this step by using convolutions two vectors i.e. normalized dot product of the two vectors. the similarity metric used for comparing We briefly describe here strategy can be applied Given a live input nine convolutions the implementation for the identification algorithm. A similar in [65]. image the MV200 executes using nine different 8 x 8 discrete Gaussian derivative kernels on algorithm as well, as described (of size 512 x 480) from the camera, of the location R.PN. Rao, D.H. Ballard/Artificial Intelligence 78 (1995) 461-505 483 Visual Processing within the Datacube MV200 System Convolutions withNine Basis Filters I I ; ’ Low-Pass Filtered Pyramid ________________-__________________________________~--__--_---__----_-, 1 Best Match Location Motor Map /T / l- / (Pan,Tilt) Values for Binocular Head Fig. 8. Implementation diagram for the location algorithm. filtered in the current five-level pyramid of the image to obtain image; these vectors are stored the training phase, filter responses located within the segmented are extracted object according in a “memory the response vectors for surface” S. for each of the sparse number in to the criteria described a low-pass all points During of points Section 3.2. During the location phase, a model response vector is loaded into the 8 x 8 convolution for thresholds surface S containing the response vectors the point whose response vector achieved the model vector was chosen as the location of the model point the closest vectors can be selected by simply at individual kernel and convolved with the memory each point of the input image; the results of the convolution For the experiments, with image. The final step involves a foveation or centering of the selected point; commands using a motor map and a variant of Kohonen’s to [ 621 for more details. A summary of the current algorithm can be found thresholding to obtain candidate match points. the highest correlation in the input the motor by the system by is referred of the location is similar and this foveation were learned autonomously is given in Fig. 8. The diagram for the identification rule. The reader implementation for achieving algorithm in [ 651. learning 484 R.P.N. Rue. D.H. Uailard/Artijiciul Intelligence 78 (1995) 461-505 4.5. Experimental results results This section contains experimental above. The former was tested using a well-known and loca- object data 20 complex 3D objects. The latter was tested under a wide range of to of the algorithm was tion routines described base containing viewing conditions ranging distortions due to clutter and minor occlusions; also tested on a cluttered 3D scene as function of camera displacement. caused by object/camera motion from image variations for both the object the performance identification 4.5.1. Object We tested identification the identification results in used reflectance from uniform object data base algorithm on the Columbia to model geometrically. The ranging that are hard [51 J by Murase and Nayar and which accompanies from Columbia. The data base contains 3D objects exhibiting originally software package variety of properties textural properties itself was realized within on Kanerva’s a convenient terms of response vectors) a number of specific advantages indexing capacity over sequential memory, and anthropomorphic can be found in [ 64,651 is used). that was the SLAM a wide to complex algorithm the framework of an associative model of visual memory based [ 361. This form of memory provides (in (given by a binary vector label) and offers stored views, constant possibly greater storage learning behavior. Further details form of the memory model sparse distributed memory model platform time (due to a constant number of storage locations), the association between an object’s appearance and simple shapes identification (see also [ 631 where a topographic such as interpolation and its identity for learning between increments images of each object (imaged at 5” rotational Fig. 9(a) shows the 20 3D objects in the data base for a given pose. The data base in for brightness at a size of 128 x 128 contains 72 presegmented pose), each image X-bit quantized and normalized pixels. During in pose were used to extract response vectors for storage are shown of objects corresponding testing set size was thus 720 images, The recognition results are summarized object centroid was used per object, 70% of the test cases were successfully Addition of more points per object was achieved when 25 points were used to describe each object. the training phase. 36 canonical views of each object at IO” increments twelve of these images selected the the same as the training set size (Fig. 9(d) ). in Fig. 9(e). Even when only one point at the in memory; the indexing scheme, we randomly that lie exactly recognized. rate until 100% accuracy in Fig. 9(b). For testing to poses the training poses; the recognition in between increased 4.5.2. Object location results Location performance was tested using live camera input from the binocular head. All the Rochester Robotics and Vision Laboratory, each image salient model points on a wide variety of 3D objects. For the experiments, images were obtained within containing objects were picked according to the saliency criterion discussed in Section 3.2. Effect of object and camera motion We first tested location performance in the presence of object and camera movements. In the first experiment, the wrist of the Unimate Puma Robot Arm was chosen as R.PN. Rao, D.H. Ballard/Artificial Inklligence 78 (1995) 461-505 485 (a) (b) l- 0.9 B m I% 0.6 0.5. 0.4- .e .s 8 0 8 g 0.3- 0.2 0.1 01 1 Total Number of 9 17 25 Number of Points per Object Cd) (e) Fig. 9. Identification results. (a) The 20 objects used in the experiment. (b) For each object, 36 images were used at 10’ rotational increments in pose to represent the entire pose space. Nine of these images for a particular model object are shown in the figure. (c) For a given object in a particular pose, response vectors were selected for the points of intersections of radial lines with concentric circles of exponentially increasing radii centered on the object centroid. (d) summarizes the experimental parameters. Random images were selected for testing the indexing method from the 720 images in the testing set. (e) Recognition rate (fraction of test images correctly recognized) plotted as a function of number of points used per object for identification. All test cases were successfully recognized when 25 points were used as indicated in (c) to characterize an object. 486 R.PN. Rue. D. H. Bulhrd/ArtiJcrul Inrelli~ence 78 (1995) 461-505 Cd) in the presence of object and camera motion. Fig. IO. Location (a) The wrist of the robot arm was chosen as the model object and the response vector from a salient point (marked by “+“) on its tip was stored for future comparisons. two discrete vertical movements of the arm. (d) and (e) show the results after two movements of the binocular head. the results of the location algorithm on images obtained after (b) and (c) show R.I?N. Rao, D.H. Ballard/Artificial Intelligence 78 (1995) 461-505 487 (4 (b) (cl Fig. 11. Object location in the presence of perspective distortions and background variations. (a) The response vector for a salient point near the centroid of the model object was used for the experiment. (b) and (c) show the results of running the location algorithm on two images obtained after varying amounts of motion of the model object. the model response vector for a salient point on the tip of the wrist was used for location. Figs. 10(b) (marked by a and joint of the arm show the images obtained after two movements of the vertical points best matching for a 10’ horizontal found by the algorithm. The experiment followed by a 20’ the algorithm was the model with a sufficiently high degree of accuracy as indicated by the camera movement and a 10” vertical movement. (Fig. In both cases, IO(d)) in Fig. 10(a)) the model object and “+” 10(c) and the corresponding was repeated horizontal movement able to locate figures. In a second experiment, we checked for the effects of perspective distortions changing background the response vector from a salient point near its centroid as shown caused by object motion. The model object was represented and by in Fig. 11 (a). The 488 R.t?N. Rue, D.H. Bullard/ArtiJzcial Intelligence 78 (1995) 461-505 (a) (b) response vectors were used location Fig. 12. Object whose location clutter/occlusions algorithm on images obtained after were introduced. in the presence of scene clutter and minor occlusions. (b) and the salient points the output of the the model object was moved and varying amounts of scene (a) shows (c) show the model object. to characterize two figures below show the images obtained after horizontal motion of the same object; for the two images are the closest matching points shown marked by a “+“. the located despite variations caused by changes In both cases, the object was successfully in perspective and different backgrounds. found by the location algorithm Effect of clutter and minor occlusions In order to verify a white can of paint model object. Three salient points Fig. 12(a)) were used to form the object’s moved to a different the location algorithm’s thinner with textured markings near its centroid was used as the in iconic representation. The object was then location and significant clutter was introduced. As can be seen from to clutter and minor occlusions, locations within in different the object resilience (shown R.f?N. Rao, D.H. Ballard/Artificial Intelligence 78 (1995) 461-505 489 Fig. 12(b), points. We also introduced corresponding points the location algorithm was able to find close matches noise in the form of occlusions near the model object; found by the location routine are shown in Fig. 12(c). for all three model the Location performance location The algorithm’s for the experiment performance was measured for a given set of objects in caused by varying degrees of camera and each was represented a scene as a function of the image distortions movements. Fifteen objects were selected by a single salient point as shown the cameras of the binocular head placed at a distance of approximately the objects. For each model object, saccades of varying amplitudes was run function of saccade amplitude. All objects were successfully than 16”; the location algorithm of 16O and 20”. in Fig. 13(a). The objects were imaged by one of five feet from the binocular head was made to execute horizontal the location algorithm located all but one of the fifteen objects for amplitudes rate plotted as a less to obtain new images on which the model object. Fig. 13(b) located for amplitudes the location to locate shows 4.6. Handling partial occlusions representations be treated as noise as illustrated iconic object The essentially section; however, done since can be tolerated simply as noise. for larger occlusions, the occluder will usually distort are robust to minor occlusions in some of the experiments the recognition algorithms will fail if nothing the filter responses in larger amounts since these can in the previous is than Interestingly, segmentation of this result (shown as dark horizontal bands of noise in the figure); humans have a similar problem. Fig. 14 shows the experimental the picket fence. The results show that identification [ 541 to test subjects’ ability designed by Nakayama and Shimojo presence of negative and positive occlusion cues. In one instance, a picket fence is behind the latter case. One interpretation figure-ground in Fig. 14(b)), observation Suppose are automatically forms the inspiration that an active imaging system segmented for our solution away from [ 81. setup faces in the to identify the face is painted on in the other, it in improved is that the early visual system performs (as the object of interest. This is used. As a consequence we can assume that [ 171. As described the occluder can be detected by a method such as disparity in Section 3.2, disparity image energy filtering only in the horopter. Ideally one can create a template T( X, y) such that T( X, y) = 1 for the existence of such a material template in the horopter and T(x, y) = 0 otherwise. We assume for our subsequent is a way of creating a filter that passes in such a way that the occluders, whenever positive is markedly calculations. filtering 4.6.1. Occlusion algorithm The filter responses are the responses intensities the image the responses and filter functions. As the functions must be used to do this [ 3.51. near every point can be reconstructed for a set of basis functions. As a consequence combining a pseudo-inverse are not orthogonal, by appropriately K.PN. Kao. D.H. 61~11urd/Art@~~t~/ lnrelligence 7R (1995) 461-505 0.8’ t 0.21 0.1 j 4 lrnage Displacement (in degrees ot saccade amplitude) Fig. 13. Location performance. (a) Indicate? the salient points chosen to represent the fifteen model objects used for the experiment. (b) shows the success rate of the location algorithm as a function of horizontal camera movement in degrees. Apart from one object (for camera movements of 16” and 20’). each of the fifteen objects was correctly located in each of the new images obtained after the different amounts of camera movements. R.P.N. Rao. D.H. Ballard/Arl@cial Intelligence 78 (1995) 461-505 491 Fig. 14. The role of stereo disparity in human recognition performance. The figure (from [56] ) shows a simple rendition of typical stimuli used by Nakayama and Shimojo in their experiments to judge recognition performance in the presence of negative (a) and positive (b) occlusions in the form of dark horizontal bands of noise. In all cases, subjects recognized faces with higher accuracy in situation (b) than in situation (a). Any spatial filter with a finite impulse response can be represented as an p x 1 vector in the support of the filter and i = 1,. , . , n, n being I$, where p = number of pixels the number of basis filters used in the iconic representation. A set of such filters can be stacked side by side to form a p x n matrix F. For an image patch as an p x 1 vector I, the n x 1 response vector is represented r = FTI. Applying singular value decomposition [ 691 to FT results in FT = lJsWT, (23) (24) , .Z is an n x p diagonal matrix, and VT is a p x p where U is an n x n orthogonal matrix orthogonal matrix. We can now reconstruct an image patch given a response vector r by using the relation I’ = VZ’UTr, (25) denotes a p x n diagonal matrix whose diagonal entries are the multiplicative where 2-l inverses of the corresponding Note that the matrix VZIUT diagonal entries of 2. is independent be precomputed a p x n precomputed matrix by an n x 1 vector. This ability and stored. Reconstruction then merely of the response vector and hence can of the local the multiplication to reconstruct involves 492 R.P.N. Rae, D.H. Bullurd/Artijictal Intelligence 78 (1995) 461-505 (4 (e> IS. A test of the occlusion algorithm. Fig. structed patch of the left eye (unmasked); (brightest comparing point the unoccluded in the image) by using responses (a) The original (d) responses the distance from image; the occluded (b) image showing the masked eye patch; image; the left eye correctly the recon- located the result of directly (e) (c) from (c) with those from the occluded image. the stored prototype allows intensities responses. For every point, using the occluding masked reconstructed system and can be compared by differencing the following the reconstructed algorithm template. A similar process is done to the incoming to be made comparable image intensities to the occluded image are appropriately masked image. Thus the image and the masked input image are now in the same coordinate their filter responses. This is formalized in for occlusion near a point (x0, ya) : R.P.N. Rao, D.H. Ballard/Artijicial Intelligence 78 (199s) 461-505 493 ( 1) Use model response vector to reconstruct in the image do: (2) For every point (x, y) the local image patch, Z/(X,-,, yo). y) for all (x,y) in a local domain of appro- I”( X, y) = T(x,y)Z(x, Compute priate size. Compute new filter responses Compare compute d( x’, y’) . f” from I”. those with the filter responses f computed from Z’(xa, ya)T(xa, yo) to (3) The sought after point the occlusion is given by argmind(x’, algorithm, we created a face image similar y’). in spirit is shown in Fig. 15(e). to the previous point, to the size and relative the occlusion if the raw filter responses then, as they are not comparable, To demonstrate that of Fig. 14. Fig. 15 shows the results of using image. Just to make the obvious point, are compared not correct. This computation the algorithm interest, we ran the algorithm on a simple of increasing a test point near correctly point was occluded as given by the brightest points Figs. 16(d) and 16(f). The original point remained among matches, than 60% of the area centered at the test point to algorithm on the face image in the occluded is In order to test the sensitivity of to a point of in the presence in the region of the end of the spatula’s handle. A unique best matching point was found when 20% or even 40% of the image patch centered at the selected images of for the only contender, when the occluder occupied more (Figs. 16(g) and 16(h)). location of the occluder with respect table top scene (Fig. 16(a)) in the form of vertical dark bands of noise in the respective distance the possible candidates it was no longer the best match occlusion though 4.7. Using iconic representations with space-variant sensors sensors There has been in active vision realize they the interest for tasks such as visual search and object recent in the use of space-variant tracking load on that needs to be processed, the active vision [ 751. Such sensors system. One popular and good visual acuity; the amount of information need for wide field-of-view systems the simultaneous decrease class of space-variant computational sensors are fog-polar sensors which have a small area near the optical axis of greatly increased a as one moves radially outward. These sensors gradual retina where one are inspired by similar finds both a peripheral symmetric area centralis characterized by its greater density of receptors and a disproportionate representation acuity, region of gradually decreasing acuity and a circularly [ 141. The peripheral and movement. fovea) in resolution in addition, reducing in the human and primate resolution logarithmic coupled with a peripheral though of low visual in the optic nerve is more sensitive to light intensity (the falloff that witnesses structures thereby region, region found for discrimination The existence of a region optimized a region geared towards detection in the outer region a strategy however necessitates in the periphery is addressed by both bottom-up periphery surrounded by thus allows the image of an object of interest detected to be placed on the more analytic center for closer scrutiny. Such location issue from the form or color. to determine which the “where-to-look-next” strategies such as search for a particular to foveate next. In the case of humans, such as motion or salience clues the existence of methods as well as top-down and recognition strategies K.PN. Rtro. D.H. Bolltrrd/Artrjicxzl Inrelli~ence 78 (1995) 461-505 (a> (4 (h) lo. Sensitivity to degree of occlusion. Fig. test point at the tip of the spatula’s handle: selected point occluded and (d) distance image); to 40% of image patch; (g) and (h) best match to 60%. (e) and (f) correct point is still the unique best match (brightest point) when occlusion is no longer unique when the degree of occlusion (a) Unoccluded table top scene and (b) reconstructed (c) partially occluded image showing the test point correctly patch of a scene with 20% of the image patch near (brightest point in the is increased is increased located R.t?N. Rao, D.H. Ballard/Art@cial Intelligence 78 (1995) 461-505 495 alerting cues such as motion have recently been incorporated While bottom-up active vision systems down cues for fovea1 redirection the use of color in [ 72]>, even though from the low-resolution use information to initiate “capture saccades” has remained relatively unexplored [ 521, the possibility of using (an exception that humans have the ability it is well known periphery in guiding visual search [ 16 3. in some top- is to In Section 4.2, we illustrated fovea1 targeting using a uniform with sensors exhibiting failure. However, exploited to obtain a modified the multiscale Consider the use of the location algorithm in achieving sensor. Using the same characteristics will obviously top-down location algorithm in result resolution nonuniform resolution structure of the response vectors can be effectively location algorithm [ 611. first the case when the scale of the object in radial resolution turns in foveated regions as they the periphery. The filter responses usually vary smoothly between scales; the two response vectors of the between is fixed. Then if the sensor causes an effective to some other minor distortions) of previously reduction the decrease away from the object, scale (in addition move towards it is thus possible imaged at different same point on an object strategy. That is, in addition compare scale matching a model vector directly as in the location algorithm, response vector are also compared with the model step can be carried out using, for instance, to establish a correspondence scales by using a simple to comparing interpolated response vector interpolate-and- an image vector and versions of the image interpolation (the [ 601) . radial basis functions In the case where the scale of the object increase extent the scale of the object itself changes, the increase or decrease is matched to a certain extent by the corresponding in decrease or the in resolution of the sensor. The degree of this match effectively modulates to which scale matching will have to be done. image strategy is illustrated scale matching original rate (geometric) The use of the interpolate-and-compare in Fig. 17. The sequence of “cortical in conjunction with (a) images” (f) in Cartesian coordinates were obtained by passing appropriate portions of a [ 8 11, with an effective through a log-polar mapping resolution image per pixel of the of 1.075 pixels of the original space by a circle) this (in the the response vectors; in scale in, the location space variant sensors through uniform radial drop-off new image. The resulting variant towards example, obvious can be clearly algorithm the scale matching to the next scale) and comparing the appropriate its utility as an effective sensor the right. simply correlation from a point (g) shifting the response vectors as a function of changes routine for foveating peripheral targets. strategy of interpolating the effect of moving (marked by a “+“> scale correction in the fovea seen. Once a log-polar is factored (indicated illustrates simulates sequence between retains 4.8. Routines for scale invariance and looming detection in a dynamic environment, scale changes in the projection for instance, by motion of the camera towards or away from that the location and identification in scale but larger scale changes distort of an object a recognition mechanism must in an image the object. Our can handle the filter responses algorithms In order to be successful to handle the ability have caused, experiments up to 5-10% variations causing the algorithms seem to indicate to fail. coordinates sensor. (a) in Cartesian (indicated by a circle) obtained by movement of the sensor from a point (marked by a “+“) Fig. 17. Using response vectors with a log-polar images” the fovea1 region shifting response histograms by one scale) to maximize correlation with the initial model response vector as the point moves towards in scale implies the sensor. The obvious correlation between vectors as a function of changes in. algorithm will still work on peripheral in (in this case, for each new response vector for the original model point in order the periphery of that the location the right. (g) shows the interpolation targets once the scale correction the sequence of “cortical (f) represent is factored required towards through R.F!N. Rao, D.H. Ballard/Artificial Intelligence 78 (1995) 461-505 497 GO 0) cc> Scale 1 Scale 2 Scale 3 Scale 4 Scale 5 (4 lII.,I..I llllll..lllll. ,,IIII I,,,, III, I,,,, Scale I Scale 2 Scale 3 scale 4 Scale 5 (b) changes in scale. the process of interpolating amounts Fig. 18. Handling depicts simple case, between vectors as a function of changes still work in the presence of scale changes once the scale corrections have been applied. (for response histograms in scale that is evident (b), and (c) are images of an object at three different scales. the point marked by “+“) (a), response vectors to the right by one scale. The correlation that the visual routines will (d) In this in (d) ensures across scales. interpolation to shifting this problem can be tackled are usually known by the active vision system, and the dimensions in at least three ways. First, since the approx- However, of imate distances the viewed object are usually small compared the scale can be actively adjusted prior to the matching process by using, for instance, zoom lenses. Sec- ond, a strategy such as that used by Murase and Nayar [ 5 1 ] for scale normalization by size can be adopted subsampling though the image of an object to a canonical to the viewing distance, or oversampling this might the most feasible that was introduce noise or other distortions due to the sampling process. is the interpolate in Section 4.7. The use of this procedure in Fig. 18, where strategy introduced is illustrated scale changes for handling interpolation Perhaps scale variations compare method handling simple shift of response vectors as a function of changes visual routines will still work to the right. The correlation between in scale that is clearly seen in Fig. 18(d) ensures in the presence of scale variations once amounts and for to a response vectors that the the necessary scale correction % change procedure 3D environment if desired. gets factored from thus be used in estimating in. Note the original model in scale and could that this strategy also yields scale as a by-product the approximate of the matching in the current distance from the point Visual looming, or the expansion of the projection of an approaching object in the is an important in texture density cue in the human the relative change reflex for obstacle avoidance this problem. At any given point, strategy used above suggests a natural and extremely [9]. Numerous [ 551, measuring optic flow via correlation [ 341 have been explored. The simple strategy the camera, those at a finer looming detection can be achieved by comparing, using scale from points near the center of gaze from ; [44] ) retina, approaches such as using flow field divergence [ 31. and computing scale matching for tackling the filter responses at a coarse scale at time t -+ At will roughly match scale from time t. Thus, interpolation, one frame to response vectors extracted from the same points in the successive this procedure can the best match) yielding the efficacy of these visual routines future research. induced by motion of the object. Experimentally for looming and time-to-contact in Fig. 19. The time-to-contact by measuring (amount of interpolation evaluating is illustrated likewise be estimated the response vectors extracted remains a topic for (or time-to-collision the scale change is approaching if an object frame(s) 5. Conclusion WC have shown that an architecture that uses two banks of iconic filter vectors can form the core of an active vision system. Such an architecture allows the construction of looming a number of useful visual routines such as object location, object identification, detection and fovea1 targeting using log-polar sensors. The architecture has a number of favorable properties l Ir allows functiorzal upplicatiorz. The proposed architecture divides of achieving complex problem solving behaviors the complementary to considerable context of simple information since task-directed on demand economy in lieu of scene reconstruction. it allows programs or visual routines iconic behaviors of location and identification the general related to scene interpretation that make it especially attractive: task into (Section 1). This leads to be used in the [77] which compute feature vectors l It benefits ,fronz the favoruble nzatching properties that accrue to high-dimensional toward \sectors. The iconic descriptions used in the architecture exploit the tendency in orthogonality inherent (see Section 2.1). This and external channels the presence of noise property allows in the context of a sparse distributed memory them [ 36 ] that facilitates visual learning and offers a number of specific advantages over conventional modes of storage for visual memory in high-dimensional in internal to be used spaces to achieve accurate [ 63,641. indexing l It is well-suited for general-purpose object descriptions which are obtained by projecting given by various derivative of Gaussian components of arbitrary natural images as described object indexing. The architecture employs image patches along the axes filters which are known to form the principal in Section 3.3.1. In addition, R.P.N. Rae. D.H. Ballard/Artificial Intelligence 78 (1995) 461-505 499 (b) (4 (e) I \ iconic representations Fig. 19. Using effect of a looming object. across scales for determining shows (g) best partial matches. to detect (a)-(f) looming. the suggested procedure show a sequence of images simulating for interpolating and comparing the responses so0 K.P.N. Hao. D.H. Ba/ltrrd/Arfificial Intelli+yuze 78 (I 995) 461-505 that principal it is known are statistically optimal sharper correlation peaks than traditional cross-correlation in that they maximize component expansion signal-to-noise filters that ratio and yield much [ 431. techniques generates correlation real-time in terms of photometric implementations. The models used in the architecture encode these can be computed much more than geometrical models. This wasn’t possible until memory and corre- that the availability of pipeline image processors codes; l It facilitates objects directly efficiently lation became cheap. In particular. can perform convolutions of photometric recognition at frame-rate has made possible real-time implementations architectures such as the one proposed here. Some of the above properties are also shared by some recently proposed object recog- dichotomy was used by Swain and Ballard in feature vectors have recently been used by Mel [49] and problem, detectors. He argues that multiple objects can is resolved exclusively with the object [ 711. Object representations identification [ 791. Mel, who is concerned features, whereas we propose active vision system which provides identification local features. Two other schemes employing nition schemes. The location/identification in their work on indexing objects using color histograms the form of high-dimensional Viola uses color conjoined with edge/curvature be handled with additional by an encompassing segmentation. Viola also focuses on object “complex” tions are those of Daugman 2D Gabor wavelets uses in a scheme for personal iris recognition rather also used by Buhmann are used in an elastic graph-matching appears tractable path of decomposing with an encompassing segmentation. PCA-based et al. to form composite [ 191 and Buhmann than recognition to generate basis long 256-byte “iris codes” for a human eye which he identity verification; he is however solely concerned with of arbitrary objects. Gabor-based wavelets are feature detectors called “jets,” which like Mel, their emphasis the relatively more for recognition; strategy to be on image interpretation where as our approach follows the problem active vision system into its location/identification the necessary that provides components figure-ground that this problem the necessary and uses an index based on filter-based vector representa- et al. [ 111. Daugman used multiscale figure-ground [76] since rotation normalization includes non-orthogonal [51 1 for pose estimation these allow an extremely have been used by Turk and Pentland implicit use of PCA and its role in our representation in that our representation simple functions and by Murase and Nayar recognition, representation makes from the above two approaches ponents similar ones for the above recent evidence suggesting necessarily all orthogonal image patches at multiple load constant and allows efficient strategies scales affords simple algorithms obtained we use fixed basis the active vision system by exposing concerned solely with the development do not have to be recomputed upon the introduction approaches. for face and recognition. Our is different com- procedure while there has also been in natural scenes are not are based on PCA of the computational for active sensing while the use of multiple sensing. Finally, after the process of PCA to its limit to a variety of images during an initial phase of the basis functions. As a result, the functions two approaches that the directions of high-variance 1241. In addition, our basis functions scales-the for scale invariance and space-variant of new objects as in the above two use of image patches keeps are not at all obvious; functions is taken R.F!N. Rao, D.H. Ballard/Artificial Intelligence 78 (1995) 461-505 501 in routine) is identifying determination of the centroid of the currently foveated object the approximate foveated object using for the routines described from segmentation in many cases a currently object boundary. Our current method (at least in the case of the identification there are certainly lesser significance from the paper. template the circular is required due to tendency of object boundary lying within relies using stereo (as illustrated by [70], or texture 1461. In a form of to implement issue problematic of some form of figure-ground to be highly correlated. Also, exact determination the feature vectors are extracted only since A potentially the assumption segmentation. While cases where segmentation may be extremely crude, the issue assumes in light of the fact that even crude segmentation the background will suffice For example, when strategy, only approximate of nearby points is not essential a specified distance on figure-ground is not possible, Murase and Nayar the latter case, pre-attentive A second Our routines mentioned exploited relative employing brute-force time in the current be further optimized, comparing the advent of real-time feature extraction of such objections. The strategies can be employed in their recognition time. but as that can be readily the though search, is still able to compute best match locations close to real on the Datacube MV200. The algorithm can however search strategy when in the image region currently being foveated. segmentation issue involving using stereo. In cases where segmentation above, for both importance to be addressed iconic are clearly computation-intensive color can be used image processing hardware for instance, by employing in terms of computation is that of feasibility alternate [51] the filter responses indexing purposes such as motion a course-to-fine implementation representations the multiscale (Section 4), from points considerably themselves algorithm system), location lessens and raises retinal approach for vectors to representing Our view-based locations potentially fail when extremely allows an extremely in conjunction with in a single memory. Kanerva independent Kanerva memories the question of scalability: large model bases of objects are used and arbitrary It is however not hard to see that the use of more than one vector the to be will the method 3D pose is allowed? per object different locations handled. To see this, let M = 1000 represent available to be about 5% of M i.e. 50 items. If k = 25 distinct vectors are used per object as we did is (0.05M)k = 5025 in Section 4.5.1, (say which in practice 99.99%) and factoring out the number of different views per object the (6.3 x 1033), three principal left with an extremely by the much system. large number. Even after ruling out a significant proportion (say 36 x 36 x 36 along large number that will probably be ever encountered the number of physical address of the possible combinations than the number of objects the capacity of the memory the number of potentially large number of objects axes), we are still to be encountered as being unlikely is an extremely [37] estimates distinguishable objects larger from An ongoing effort involves mation. The Gaussian derivative images natural surround mechanisms representation responses the augmentation of the filter responses with color infor- filters were obtained as a result of PCA of achromatic planes yields center- iconic representation with such in the R-G-B [ 201. Thus, a spatio-chromatic the current in the spatial plane. Using PCA in an opponent color space from a variety of color-opponent Gaussian center-surround mechanisms can be obtained by simply augmenting filter responses of locations. objects so2 R.PN. Rrro. D.H. Btrllurd/Arrijicicd Infelligence 7i3 (1995) 461-505 as, for instance, applied to the red/green channels at different scales. those obtained by subtracting responses of zeroth-order Gaussian filters Other directions for future research include motion-based segmentation tion of objects, use of motorized zoom lenses for scale interpolation, utility of temporal from localized PCA along based on the outputs of spatio-temporal the temporal axis. representations and exploring and recogni- the filters derived Acknowledgments We would like to thank the referees of the journal Artificial for their the quality incisive criticisms and detailed comments which greatly helped in improving to of the paper. Thanks are also due to Mary Hayhoe and Peter Lennie for useful pointers the literature, Shree Nayar for access to the Columbia object data base, Randal Nelson, Lambert Wixson and Greg Zelinsky for three of the images used in the experiments, some of the first routines on the Datacube MV200 Garbis Salgian for help regarding system, Jim Vallino for discussions during the MV200, and Lambert Wixson the early stages of this work. for implementing Intelligence References E.H. Adelson and J. Bergen. Spatiotemporal R~rr. 2 (2) ( 1985) 284-299. J. Aloimonos. A. Bandopadhay N. Ancona and T. Poggio. Optic flow from ID correlation: application AI Memo 1375, MIT AI Lab. Cambridge, MA ( 1993). R. Bajcsy, Active perception, D.H. Ballard, Animate vision, A@ /EEE 76 ( 1988) 996-1005. in: Proc. energy models for the perception of motion, J. Opr. Snc. and I. Weiss, Active vision, Inr. J. Cornput. Vision 1 (4) ( 1988) 333-3.56. to a simple time-to-crash detector, Intell. 48 ( 1991) 57-86. 16 I D.H. Ballard, M.M. Hayhoe and P.K. Pook, Deictic codes for the embodiment of cognition, Technical for the study of Brain and Behavior, University of Rochester, Report 95. I, National Resource Laboratory Rochester, NY ( 1995). 17 1 D.H. Ballard Proceedings and L.E. Wixson, Object recognition using steerable filters at multiple scales, in: IEEE Workshop on &ulifurive Vision ( 1993) [ 8 I D.H. Ballard and R.P.N. Rao, Seeing behind occlusions, in: Proceedings Third Europeun Conference on Computer Vision (ECCV), Stockholm, Sweden ( 1994) 274-285. I9 1 PJ. Beek, Perception-action coupling in the young infant: An appraisal of von Hofsten’s research in: Mofor Develq,rnent in Children: Aspect.7 of Coordination and Control ( Martinus-Nijhoff, programme, Dordrecht, Netherlands, Inferring 110 III I T.O. Binford, I J.M. Buhmann, M. Lades and C. von der Malsburg, Size and distortion in: Proc. graph matching, Intel/. 17 ( 1981) 20.5-244. IEEE 1986) surfaces I87- 196. from images, nrrij. Interna/ionnl Conference on Neural Networks II, San invariant object recognition by hierarchical Diego, CA (1990) 41 l-416. 112 I EW. Campbell and J.G. Robson, Application of Fourier analysis to the visibility of gratings, J. Physiol. (fond.) 197 (1968) 551-566. 113 I J.F. Canny, A computational ( 1986) 679-698. II4 [ IS I R.H.S. Carpenter, Movements I C. Chatfield and A.J. Collins. 1980). approach to edge detection, IEEE Trans. Puttern Anrtl. Much. Intell. 8 (!/ the Eye.7 (Pion, London, 1988). fnrroduction to Multivariate Analysis (Chapman and Hall, New York, RPN. Rao, D.H. Ballard/Artificial Intelligence 78 (1995) 461-505 503 I 161 K.M. Cohen, The development of strategies of visual search, in: Eye Movements: Cognition and Visual Perception (Lawrence Erlbaum, Hillsdale, NJ, 198 1) 27 l-288. ] 171 D.J. Coombs, Real-time gaze holding in binocular robot vision, Ph.D. Thesis, Technical Report 415, University of Rochester, Computer Science Department, Rochester, NY ( 1992). [ 181 J.G. Daugman, Two-dimensional analysis of cortical receptive field profiles, Vision Res. 20 ( 1980) 447-456. [ 191 J.G. Daugman, High confidence visual recognition of persons by a test of statistical independence, IEEE Trans. Pattern Analysis and Machine Intelligence 15 ( I 1) ( 1993) 1148- 116 1. 1201 J.B. Derrico and Cl. Buchsbaum, A computational model of spatiochromatic image coding in early vision, J. Visual Commun. Image Representation 2 (1) (1991) 31-38. I21 I R.L. De Valois and K.K. De Valois, Spatial vision (Oxford University Press, New York, 1988). 1221 E.D. Dickmanns, An integrated to feature based dynamic vision, approach in: Proceedings Conference on Computer Vision and Pattern Recognition ( 1988) 820-825. I23 ] K. Eberhard, M. Tanenhaus, M. Spivey-Knowlton reference: evidence establishing Sentence Processing Conference, Tucson, AZ ( 1995). for rapid incremental processing, and J. Sedivy, Investigating time course of the in: Proceedings Eight Annual CUNY 124) D.J. Field, What [ 25 1 W.T. Freeman and E.H. Adelson, The design and use of steerable is the goal of sensory coding? Neural Comput. 6 (1994) 559-601. filters, IEEE Trans. Pattern Anal. Mach. Intell. 13 (9) (1991) 891-906. [ 261 D. Gabor, Theory of communication, 1271 J. Grimes and G. McConkie, On the insensitivity J. IEE 93 ( 1946) 429-459. of the human visual system to image changes made during saccades, in: K. Akins, ed., Problems in Perception (Oxford University Press, Oxford, 1995). 1281 W.E.L. Grimson, A. Lakshmi Ratan, PA. O’Donnell and G. Klanderman, An active visual attention system to play “Where’s Waldo”, in: Proceedings ARPA Image Understanding Workshop ( 1994). 1291 P.J.B. Hancock, R.J. Baddeley and L.S. Smith, The principal components of natural images, Nerwork 3 (1992) 61-70. [ 301 D. Heeger, Optic flow using spatiotemporal [ 311 B.K.P. Horn, The Binford-Horn filters, Inf. J. Compur. Vision 1 (4) (1987) 279-302. linefinder, AI Technical Report 285, MIT AI Lab, Cambridge, MA (1971). [32] B.K.P. Horn and B.G. Schunck, Determining 1331 K. Ikeuchi and B.K.P. Horn, Numerical flow, Artif Intell. 17 (1981) 185-203. shape from shading and occluding boundaries, Arrtf Intell. 17 optical (1981) 141-184. [34] K. Joarder and D. Raviv, A new method to calculate looming for autonomous obstacle avoidance, in: Proceedings Conference on Computer Vision and Pattern Recognition ( 1994). [ 351 D.G. Jones and J. Malik, A computational framework of linear spatial filters, in: Proceedings Second European Conference on Computer Vision, Genova, (1992). stereo correspondence for determining from a set Italy [ 361 P. Kanerva, Sparse Distributed Memory (Bradford Books, Cambridge, MA, 1988). 1371 P Kanerva, Sparse distributed memory and related models, in: M.H. Hassoun, ed., Associative Neural Memories (Oxford University Press, New York, 1993) 50-76. [ 38 I M. Kass, Computing visual correspondence, in: Proceedings Image Understanding Workshop ( 1983 ) 54-60. [ 39 I M. Kass, Linear [40] H. Knuttson image features in stereopsis, Int. J. Comput. Vision ( 1988) 357-368. quadrature two-dimensional and G.H. Granlund, Texture analysis using in: IEEE Workshop on Computer Architecture for Pattern Analysis and Image Database Management ( 1983) 206-213. filters, [ 4 1 I J.J. Koenderink, Operational [ 421 J.J. Koenderink and A.J. van Doom, Representation significance of receptive field assemblies, Biol. Cybern. 58 ( 1988 ) 163- 17 1. in the visual system, Biol. Cybern. of local geometry 55 ( 1987) 367-375. 1431 V.K. Kumar, D. Casasent and H. Murakami, Principal-component imagery for statistical pattern recognition correlators, Optical Eng. 21 (1) (1982) 43-47. (44 1 D.N. Lee, A theory of visual control of braking based on information about time-to-collision, Perception 5 ( 1976) 437-459. 504 R.PN. Rae. D.H. Bullard/Artijzcial Intelligence 78 (1995) 461-505 [ 4.5 1 J. Malik and Z. Gigus, A model for curvilinear segregation, fnvesf. Ophthalmol. Vis. Sci. (Supplement) 32 (4) (1991) 715. I46 1 J. Malik and t? Perona, A computational model of texture segmentation, in: Proceedings Conference on Computer Vision and Pattern Recognition ( 1989) 326-332. I47 1 D. Marr, Vision: A Computational Investigation into the Human Representation and Processing of Visual I/!fi,rmation ( W.H. Freeman, San Francisco, CA, 1982) I48 ] J.H.R. Maunsell and W.T. Newsome, Visual processing in monkey extrastriate cortex, Ann. Rev. Neurosci. 10 (1987) 363-401. [ 49 1 B. Mel, A neurally-inspired approach to 3-D visual object recognition, Presentation at Telluride Workshop on Neuromorphic Engineering, Telluride, CO ( 1994). [ SO 1 M. Mishkin and T. Appenzeller, The anatomy of memory, Sci. American 15 I 1 H. Murase and S.K. Nayar, Visual Comput. vision 14 ( 1995) S-24. learning and recognition ( 1987) 80-89. of 3D objects from appearance, Inr. J. 152 1 D.W. Murray, K.J. Bradshaw. P.F. McLauchlan. I.D. Reid and P.M. Sharkey, Driving saccade to pursuit using image motion, fnr. J. Cornput. Vision (submitted). I S3 1 K. Nakayama, The iconic bottleneck and the tenuous ed., Vision: Coding and Eficiency link between early visual processing and perception, (Cambridge University Press, New York, 1990) in: C. Blakemore, 41 l-422. 154 1 K. Nakayama and S. Shimojo. Towards a neural understanding of visual surface representation, in: T. Sejnowski, E.R. Kandel, C.F. Stevens and J.D. Watson, eds., Proceedings Cold Spring Harbor Symposium on Quantitafive Biology 55: The Bruin ( 1990) I 5.5 1 R.C. Nelson and J. Aloimonos. Using flow field divergence for obstacle avoidance in visual navigation, IEEE Trans. Pattern Anal. Mach. Intel/. 11 ( IO) ( 1989) I 102-l 106. I 56 1 M. Nitzberg, 0. Mumford and T. Shiota. FilterinK, Segmentation and Deprh (Springer-Verlag. New York, 1993). I 57 I P. Parent and S. Zuckcr, Trace inference, curvature consistency, and curve detection, IEEE Trans. Pattern Anal. Much. Infell. 11 (8) (1989) 823-839. IS8 1 A.P. Pentland, Shape information from shading: a theory of human perception, in: Proceedings 2nd Inrernational Cwzference on Computer Vision. Tampa. FL ( 1988) 404-4 12. 159 I A.P Pentland, From 2-D images to 3-D models, in: K.N. Leibovic, ed., Science of Vision (Springer- Verlag, New York, 1990) 422-438. I60 I T. Poggio and E Girosi, Networks 161 1 R.t?N. Rao, Top-down gaze for approximation and learning, Pram. /EEE 78 ( 1990) 1481-1497. targeting for space-variant active vision, in: Proceedings ARPA lmuge Understanding Workshop, Monterey, CA ( 1994) lO49- 1058. I62 I R.P.N. Rao and D.H. Ballard, Learning saccadic eye movements using multiscale Tesauro, D.S. Touretzky and T.K. Leen. eds., Advances (MIT Press, Cambridge. MA, 199.5) in Neural information spatial filters, in: G. Processing Systems 7 [ 6.1 I R.PN. Rao and D.H. Ballard. Natural basis functions and topographic memory for face recognition, in: Proceedings IJCAI-95. Montrkal, Que. ( 1995) I 64 1 R.P.N. Rao and D.H. Ballard, Object indexing using an iconic sparse distributed memory, in: Proceedings lnternutional Corzference on Computer Vision (ICCV) ( 1995). [ 65 1 R.P.N. Rao and D.H. Ballard, Object indexing using an iconic sparse distributed memory, Technical Report S.59, Department of Computer Science, University of Rochester, Rochester, NY ( 1995). I66 1 R.D. Rimey and CM. Brown, Task-oriented vision with multiple bayes nets, Technical Report 398, Computer Science Department, University of Rochester, Rochester, NY ( I99 I ). learning in a single-layer linear feedforward neural network, Neurul I67 I T.D. Sanger, Optimal unsupervised Nerworks 2 ( 1989) 459-473. I68 I D.G. Stork and H.R. Wilson. Do Gabor functions provide appropriate descriptions of visual cortical receptive fields? J. Opr. Sot. Am. A 7 ( 8) ( 1990) 1362-1373. I69 I G. Strang, Lineur Algebra and irs Applications (Harcourt Brace Jovanovich, San Diego. CA, 3rd. ed., 1988). 1701 M.J. Swain, Color indexing, Techmcal Report 360, University of Rochester, Computer Science Department, Rochester, NY ( 1990). I71 I M.J. Swain and D.H. Ballard, Color indexing, /rlr. .I Comput. Vision 7 (1991) I l-32. RPN. Rao, D.H. Ballard/ArttJicial Intelligence 78 (1995) 461-505 505 1721 M.J. Swain, R.E. Kahn and D.H. Ballard, Low resolution cues for guiding saccadic eye movements, in: Proceedings Conference on Computer Vision and Pattern Recognition ( 1992). Integration 1731 M. Tanenhaus, M. Spivey-Knowlton, and J. Sedivy, K. Eberhard of visual and linguistic information 1741 W.B. Thompson, in spoken language comprehension, Science (to appear). Inexact vision, in: Proceedings Workshop on Motion, Representation, and Analysis (1986) 15-22. [ 751 M. Tistarelh and G. Sandini, Dynamic aspects (1992) 108-129. Image Understanding 56 (1) in active vision, Comput. Vision, Graph. Image Process. [76] M. Turk and AI? Pentland, Eigenfaces [ 77 1 S. Ullman, Visual routines, Cognition 18 ( 1984) 97-160. 1781 L. Ungerleider and M. Mishkin, Two cortical visual systems, for recognition, J. Cognitive Neurosci. 3 ( 1) (1991) 71-86. in: D. Ingle, M. Goodale and R. Mansfield, eds., Analysis of Visual Behavior (MIT Press, Cambridge, MA, 1982) 549-585. I79 I F! Viola, Feature-based recognition of objects, in: Proceedings AAAI Fall Symposium on Learning and Computer Vision (1993). 1801 J.W. Weber and J. Malik, Robust computation of optical flow in a multi-scale differential framework, Technical Report 709, Department California at Berkeley ( 1992). of Electrical Engineering and Computer Science, University of 1811 C.F.R. Weiman and G. Chaikin. Logarithmic spiral grids for image processing and display, Comput. Graph. Image Process. 11 (1979) 197-226. [ 821 L. Wiskott and C. von der Malsburg, A neural system for the recognition of partially occluded objects in cluttered scenes: a pilot study, in: IJPRAI 7 (1993) 935-948. I83 1 R.A. Young, The Gaussian derivative theory of spatial vision: Analysis of cortical cell receptive field line-weighting profiles, General Motors Research Publication GMR-4920 ( 1985). 