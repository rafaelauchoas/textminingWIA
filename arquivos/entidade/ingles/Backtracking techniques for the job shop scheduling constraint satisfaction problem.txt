Artificial Intelligence 76 (1995) 455-480 Artificial Intelligence Backtracking techniques for the job shop scheduling constraint satisfaction problem* Norman Sadeh*, Katia Sycara, Yalin Xiong 5000 Forbes Avenue, The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA 15213-3891, USA Received June 1993; revised May 1994 Abstract This paper studies a version of the job shop scheduling problem in which some start that improve time windows ordering heuristics In this paper, we combine techniques and variable/value time windows). This problem (CSP). A popular method for solving this type of problems that cannot be completed without violating some constraints). (i.e. earliest/latest operations have to be scheduled within non-relaxable is a well-known NP-complete Constraint possible Satisfaction Problem involves using depth-first backtrack search. In our earlier work, we focused on the development of consistency enforcing the these techniques with new efficiency of this search procedure. look-back schemes that help the search procedure recover from so-called deadend search states (i.e. partial solutions (1) More specifically, we successively describe and de- Dynamic Consistency Enforcement termines how far to backtrack by selectively enforcing higher levels of consistency among (2) Learning Ordering From Failure variables participating dynamically modifies based on earlier conflicts, and (3) Zncomplete Backjumping Heuristic abandons areas of the search space efforts. These schemes are shown to (1) that appear further (2) enable our that could not be solved otherwise due to excessive system to efficiently solve problems computation than other look-back schemes advocated cost, and (3) be more effective at solving job shop scheduling problems in these critical subproblems, the order the average complexity of the backtrack search procedure, to require excessive computational identifies critical subproblems in which variables three “intelligent” in the literature. backtracking dynamically instantiated schemes: reduce are l This research was supported, in part, by the Defense Advanced Research Projects Agency under contract #F30602-91-F-0016, and in part by grants from McDonnell Aircraft Company and Digital Equipment Corporation * Corresponding author. 0004-3702/95/$09.50 SSDZ 0004-3702(95)00078-6 0 1995 Elsevier Science B.V. All rights reserved 456 N. Sadeh et al. I Artificial Intelligence 76 (1995) 455-480 1. Introduction This paper is concerned with the design of recovery schemes for incremental scheduling approaches sions in order to complete that sometimes require undoing earlier scheduling deci- the construction of a feasible schedule. that have for operations (e.g. earliest possible start to be scheduled within non-relaxable Job shop scheduling deals with the allocation of resources over time to perform a collection of tasks. The job shop scheduling model studied in this paper further allows time possible finish time windows). windows is a well-known NP-complete Constraint Satisfaction Problem This problem (CSP) in which some operations shifts, in which time windows are determined by spacecraft mission scheduling problems, astronomical rescheduling prob- lems, in which a small set of operations need to be rescheduled without revising the schedule of other operations, to be performed within one or several events over which we have no control, include factory scheduling problems, Instances of this problem time/latest factory have [lo]. etc. through One approach this approach, assignment of a reservation scheduling problems can be solved to solving CSPs is to use depth-first backtrack search [2,12,26]. the iterative Using to be scheduled next (i.e. variable selection) and the selection of an operation If in the tentative that cannot be is reached process of constructing a schedule, a partial solution completed without violating some of the problem constraints, one or several earlier assignments need to be undone. This process of undoing earlier assign- ments is referred the efficiency of the search to come up with a solution. While the procedure and increases the time required worst-case complexity of backtrack search to several is exponential, reduce its average-case complexity have been proposed techniques [6]: to as backtracking. to that operation. in the literature It deteriorates (i.e. value) in search time. techniques prune in a global solution that cannot participate the amount of consistency enforced the search space is [16]. There in each Consistency- enforcing schemes: These from alternatives generally a tradeoff between search state’ and the savings achieved Variable/value ordering heuristics: These heuristics help judiciously decide to instantiate next and which value to assign to that variable which variable [2, 6, 8, 13, 17, 181. By first instantiating difficult variables, the system increases the current partial solution without backtracking [S, 13, 181. Good value ordering heuristics reduce backtracking by selecting values solutions Look-buck enforcing average, very effective at reducing backtracking, While it is possible to design consistency that are, on to impossible [4,7,11,24]: and variable/value heuristics it is generally its chances of completing in a large number of that are expected schemes schemes to participate ordering [6,18]. 1 A search state is associated with each partial solution. Each search state defines a new CSP whose variables are the variables that have not yet been instantiated and whose constraints are the initial problem constraints along with constraints reflecting current assignments. N. Sadeh et al. I Artijicial Intelligence 76 (1995) 455-480 457 efficiently guarantee backtrack-free to help the system recover from deadend states and, if possible, past mistakes. search. Look-back schemes are designed learn from earlier work, we focused on the development techniques and variable/value of efficient consistency In our enforcing ordering heuristics for job shop schedul- ing CSPs [8, 18, 20-23, 251. In this paper, we combine these techniques with new look-back the average complexity of the search procedure. They also enable our system to efficiently that could not be efficiently solved otherwise. Finally, experimen- solve problems tal results that these techniques are more effective at solving job shop scheduling problems schemes. These schemes are shown than other to further indicate reduce look-back schemes advocated to strategy goes back in the literature. the most to The search values is said recovery states. When simplest deadend the variable. This strategy the source of the current deadend recently instantiated variable with at least one alternative value left, and assigns one of the is known as chronological remaining backtracking. Often is not the most recent assignment but an earlier one. Because it typically modifies assignments that have to no impact on the conflict at hand, chronological backtracking often returns to be thrashing. similar deadend this happens, Thrashing can be reduced using backjumping schemes that attempt to backtrack all the way to one of the variables at the source of the conflict [ll]. Search efficiency can be further improved by learning from past mistakes. For instance, a system can record earlier conflicts in the form of new constraints it from repeating earlier mistakes [7,24]. Dependency-directed technique though dependency-directed search states that need to be explored, exponential worst-case complexity of its constraint recording component time and space). Simpler techniques have also been developed the dependency-directed amount of book-keeping required by full-blown backjumping by assuming that any two variables directly connected by a constraint may have been assigned conflicting values [4].* Nth-order deep and shallow learning reduce the constraint by only recording complexity of dependency-directed recording conflicts involving N or fewer variables [4]. is a [24]. Al- the number of reduce this scheme is often impractical due to the (both in that will prevent backtracking that approximate reduces and constraint can greatly both backjumping backtracking. incorporating backtracking backtracking Graph-bused backjumping recording Graph-bused backjumping works best on CSPs with sparse constraint graphs [4]. Instead, constraint job shop scheduling problems have highly interconnected graphs. Furthermore graph-based backjumping does not increase search efficiency when used in combination with forward checking [13] mechanisms or stronger consistency enforcing mechanisms such as those entailed by job shop scheduling [18]. Our experiments suggest that Nth-order deep and shallow learning problems techniques to job shop these techniques use constraint size as the scheduling problems. This is because search efficiency when applied fail to improve often * Two variables are said to be “connected” by a constraint if they both participate in that constraint. 458 N. Sadeh et al. I Artificial Intelligence 76 (1995) 455-480 to decide whether or not record earlier failures. When they limit to small-size conflicts, they fail to record some important constraints. only criterion themselves When they do not, their complexities become prohibitive. techniques that have yielded good three look-back Instead, this paper presents results on job shop scheduling problems: (1) Dynamic Consistency Enforcement (DCE): a selective dependency-directed scheme that dynamically focuses its effort on critical resource subproblems; (2) Learning Ordering From Failure (LOFF): an adaptive scheme that suggests new variable orderings based on earlier conflicts; (3) Incomplete Backjumping Heuristic (IBH): a scheme that gives up searching areas of the search space that require in scheduling includes Related work Nth-order that of Badie et al. whose system learning which a minimum set is heuristically selected as the source of the conflict [l]. implements a variation of deep that of Prosser and Burke who use [3], and scheduling problems in to solve one-machine shallow learning too much work. The remainder of this paper is organized as follows. Section 2 provides a more the backtrack search in this study. Sections 4, 5 and 6 successively describe each results the contributions of this paper. formal definition of the job shop CSP. Section 3 describes procedure considered of the three backtracking are presented in Section 7. Section 8 summarizes in this study. Experimental schemes developed 2. The job shop constraint satisfaction problem The job shop scheduling problem {.i,, . . . , j,} on a set of resources RES = {R,, set of operations O’= {O:, . . . , Ob,} to be scheduled according routing FORE 0.;). jobs J = . . . , R,}. Each job jl consists of a to a process (e.g. 0: BE- that specifies a partial ordering among these operations scheduling a set of requires In the lob shop CSP studied in this paper, each job j, has a release date rd, and a due date dd, between which all its operations have to be performed. Each operation Of has a fixed duration duf and a variable start time stf. The domain of is initially constrained by the release and possible start times of each operation due dates of the job to which the operation belongs. the model allows for additional unary constraints the set of admissible restrict thereby defining one or several time windows within start times of each operation, which an operation has to be carried out (e.g. one or several shifts in factory In order to be successfully executed, each operation Of requires pf scheduling). different for (e.g. a milling machine and a machinist) Rfj (1 s j Gpf), from which to choose, each of which there may be a pool of physical resources .Rij G RES (e.g. one or several milling machines). If necessary, that further resources More formally, the problem can be defined as follows: N. Sadeh et al. I Artificial Intelligence 76 (1995) 455-480 459 Variables A vector of variables qr), which consists of: is associated with each operation, Of (1 s 1 G n, 1 c i c and (1) the start time, sti, of the operation, (2) its resource requirements, Rf, (1 <j <of). Constraints The non-unary constraints of the problem are of two types: (1) Precedence constraints defined by the process routings translate inequalities of the type: stf + duf <stj (i.e. Of BEFORE Of). into linear (2) Capacity constraints at a time operation (VP ‘fq R; +R:& v stf + du: =Z stj v stj + duf G stf . These constraints ply express that, unless they use different resources, Of cannot overlap.3 into disjunctive to only one constraints of the form: sim- two operations 0: and that restrict translate the use of each resource Additionally, our model can accommodate unary constraints that restrict the set of possible values of individual variables. These constraints due dates and release dates, between which all operations performed. More generally, the model can accommodate constraint restricts that further Time is assumed discrete, the set of possible start times of an operation. i.e. operation start times and end times can only take integer values and each resource requirement Rij has to be selected from a set of resource alternatives, Oij c RES. include non-relaxable in a job need to be any type of unary Objective In the job shop CSP studied in this paper, feasible solution as fast as possible. Notice simply minimizing time spent by the system deciding which search state to explore next. is to come up with a from the number of search states visited. It also accounts for the that this objective the objective is different Example Fig. 1 depicts a simple job shop scheduling problem with four requirement with a single possible value. jobs J = { jI, j2, j3, j4} and four resources RES = {R,, R,, R,, R4}. In this example, each operation has a single resource It is further assumed that all jobs are released at time 0 and have to be completed by is required by the time 20. Please note that none of these simplifying assumptions release and due dates, techniques for operations each of these requirements. Note also that the problem we have just defined is time 3 and the infeasible. None of the operations on resource R, can start before to complete sum of durations of these operations to be discussed: can have several resource jobs can have different and several alternatives it is impossible is 18. Hence, requirements, 3 These constraints have to be generalized when dealing with resources of capacity larger than one. 460 N. Sadeh et al. I Artificial Intelligence 76 (1995) 455-480 I \ \ \ j20f3R, , ’ \ b’ \ H ‘-K f .’ \ / . , v -\ ’ \ ‘\ \ \, , . -I \ 0: \ 5 R, ” \ -. , -. \ \ \ .\ l’ ( /= j , 0: 4 R, ------ - capacity constraint precedence constraint Fig. 1. A simple problem with four jobs. Each node is labeled by the operation duration and the resource it requires. that it represents, its time 21. As we will see, this observation in the form of a simple consistency checking rule. However, complexity can easily be these operations before as operationalized of the number of operations applying this simple rule to all possible subsets of operations on a given resource quickly becomes prohibitive, hence the need to be more selective in applying such checks. Additionally, is feasible, hence the need to also rely on more complex mechanisms, as described below. passing such a check to schedule grows, is no guarantee that a problem the exponential 3. The search procedure A depth-first backtrack is interleaved with the application of consistency enforcing mechanisms and vari- states, as able/value described to steer clear of deadend ordering heuristics search procedure in which search is considered, that attempt in Fig. 2. Specifically, search starts in a state where all operations procedure still have to be scheduled. The BASIC-DEPTH-FIRST scheduling operations one by one. Each time an operation search state is created propagation procedure) of unscheduled operations. Next, an operation reservation is first applied to update is selected in which a consistency enforcing procedure is selected for that operation. The procedure goes on, recursively to be scheduled and a is scheduled, a new (or constraint the set of possible reservations proceeds by incrementally N. Sadeh et al. I Artificial Intelligence 76 (1995) 455-480 461 Procdur. BASIC-MPTE-?IRST 0 . 0 Than solution found, STOP. If UUSCEED-OP LMi CONFLICT - FALSE Call COIUSTRAINT-PROPAGATION If CONFLICT - FALSE l’hmn Begin Lot OP Let RmsaIarIrw+REsEnv(oP) - limt of possible romrvatiorm . OPER-SRLBCTION (UWSCEED-OP) for OP ordarad hourimtic (bomt rasarvatione fir&) according to the value or&ring Lat RRSERV - Pop firat rwarvation Push (OP,RESBRV) onto SCRQDLE R-m 0P from OtiSCHED-0P Call BASIC-DRPTR-FIRST 0 in RQURIIpIWa-RILSERV(OP) znd El00 Call SIMPLB-BACRTRACK 0 End If End Procoduro Procodura If s-m SIMPLZ-BACKTRACX ( ) ra Than L*t rJO-soLDTIow - TRW and STOP. the last (operation, remonmtion) R-m and Let OP be the operation in that pair Inert 0P in WSCRBD-OP If REIuxtmao-REsERv(oP) # 0 pair pu8had onto SCEZDULB Than Bogin RRSBRV - Pop first ramrvation Push (OP,RBSERV) onto SCEELXJLE in R?3tkIHIWO-RESERV(OP) Ramova OP from UXSCRSD-OP Call BASIC-DEPTR-FIRST () End Else Call SIMPLE-BACRTRACR () End If End Procodura Begin Program Lot scRRDvLE = 0 Let WSCRED-OP 0;” 1 - [o:,...o~,,o~,...o~~...o;,. Lat NO-SOLtJTIOU . FALSI Call BASIC-DEPTH-FIRST0 If HO-SOLDTIOW I FUSE Than PRINT-SOLuTIObl Elm PRINT "Infeasible Problem" End If End Program Fig. 2. Basic depth-first backtrack search procedure. is detected. calling itself, until either all operations are successfully scheduled or an inconsis- In the latter case, the procedure needs to undo tency (or conflict) in Fig. 2, SIMPLE- earlier decisions or backtrack. The backtracking mechanism that systematically BACKTRACK, procedure goes back to the most recently scheduled operation and tries alternative reserva- is left, the procedure goes tions for that operation. back to the next most recently scheduled operation and so on. If the procedure returns the problem to the initial search state (i.e. is infeasible. the state with an empty schedule), is a chronological If no alternative backtracking reservation 462 N. Sadeh et al. / Artificial Intelligence 76 (1995) 455-480 The default consistency enforcing mechanisms heuristics used in our study are the ones described which have been [18,23], are briefly described below. compared favorably and variable/value ordering in [18]. These mechanisms, against a number of other heuristics Consistency enforcing procedure The consistency enforcing procedure we use combines three consistency mechanisms: (1) (2) in each search state, a pair of earliest/latest is maintained using a longest path procedure constraints: Consistency with respect that possible Consistency with respect to precedence to precedence constraints incrementally updates, start times for each unscheduled operation. Essentially, as in PERT/CPM [14], earliest start time constraints are propagated downstream within the (Fig. 3). job whereas latest start time constraints are propagated upstream The complexity of this simple propagation mechanism in the number of precedence In the absence of capacity constraints, constraints. the procedure sufficient Forward consistency checks with respect to capacity constraints: Enforcing consistency with respect to capacity constraints is more difficult due to the to disjunctive nature of these constraints. Whenever a resource an operation over some time interval, a “forward checking” mechanism [13] checks the set of remaining possible reservations of other operations requiring that would conflict with the new assignment, as first proposed can be shown to guarantee decomposability that same resource, and removes to guarantee backtrack-free in [15] (see Fig. 4). those reservations is allocated is linear [5], i.e. it is search [ 181. Before propagation j, 0: 3 R, ro94 [09=-l r0,151 Downstream Propagation j, oi3R, [09=-l r7,151 Upstream Propagation + precedence constraint Fig. 3. Consistency with respect to precedence constraints. N. Sadeh et al. I Artificial Intelligence 76 (1995) 45.5-480 463 Before propagation: [ 7,151 After propagatfon: [ lo,15 ] scheduled to start at time 6 m-w_ -_ capacity constraint Fig. 4. Forward consistency checks with respect to capacity constraints. operations enforcing mechanism (3) Additional consistency checks with respect to capacity constraints: Addition- that no two intervals. An in Fig. 5, where two operations ally, our default consistency unscheduled example of such a situation the availability of requiring their respective overlapping latest start times and earliest finish times ([lstf,eftf] and [lstj,eftj]). This additional consistency mechanism has been shown to often increase search efficiency, while only resulting 0: time intervals, namely and O:, the intervals between require overlapping is illustrated in minor computational overheads the same resource, resource/time rely on checks [18]. I est : ’ I 1st: est! I 1st’ J I I efl; eft’ J ’ IftF ’ Ift’ J c time earliest possible reservation latest possible reservation B time interval absolutely required by the operation, whatever Its start time Fig. 5. Detecting situations where two unscheduled operations conflict. requiring the same resource are in 464 N. Sadeh et al. I Artificial Intelligence 76 (1995) 45.5-480 Variable/value ordering heuristics The default variable/value ordering heuristics used by our search procedure are the Operation Resource Reliance (ORR) variable ordering heuristic and Filtered in [Ml. The ORR Survivable Schedules (FSS) value ordering heuristic described by first scheduling variable ordering heuristic aims at reducing backtracking difficult operations, namely operations whose resource requirements are expected to conflict with those of other operations. The FSS value ordering heuristic least constraining value ordering heuristic. tracking by selecting reservations number of schedules. is a reduce back- to be compatible with a large that are expected It attempts to further reported to outperform time. Nevertheless, These default heuristics have been several other schemes described in the literature, both generic CSP heuristics and specialized heuristics designed for similar scheduling problems [18,23]. They seem to provide the efforts spent enforcing consistency, ordering a good compromise between variables, or ranking assignments for a variable and the actual savings obtained in search these efficient procedures and, hence, search. schemes that help the system recover from deadend states. We show that, when the default consistency enforcing mechanisms and/or variable ordering heuristics are not sufficient to look-back mechanisms can be devised that modify these steer clear of deadends, schemes so as to avoid repeating past mistakes (i.e. so as to avoid reaching similar deadend states). The remainder of this paper describes new backtracking are not sufficient to guarantee backtrack-free the job shop CSP is NP-complete 4. Dynamic Consistency Enforcement (DCE) Backtracking at hand. Consequently, is generally an indication to deal with the subproblems that the default consistency enforcing ordering heuristics used by the search procedure scheme and/or variable/value are insufficient if search keeps on relying on the same default mechanisms after reaching a deadend state, it is likely to start thrashing. Experiments in which search always used the same set of consistency enforcing procedures and variable/value ordering heuristics, clearly illustrated Search in these experi- ments exhibited a dual behavior. The vast majority of the problems fell in either that were solved with no backtracking of two categories: a category of problems whatsoever that caused the search procedure (by far the largest category) and a category of problems this phenomenon. in [18,23], to thrash. reported a complete Theoretically, thrashing could be eliminated by enforcing each search state. Clearly, such an approach performing identifying one or a few small subproblems the conflict, (2) determining how far to backtrack by enforcing among information in to involves (1) heuristically that are likely to be at the source of full consistency conflict is full consistency is impractical as it would amount for possible reuse in future backtracking episodes. This approach search. Instead, our approach in these small subproblems, and (3) recording the variables N. Sadeh et al. I Artificial Intelligence 76 (1995) 455-480 465 dynamically this expected in the context of a backtracking (DCE). Given a deadend technique to be at the source of the current deadend. DCE scheme called Dynamic Consis- state and a history of earlier episodes within the same search space (i.e. while working on the resource then in a chronological order, until a search state is operationalized tency Enforcement backtracking same problem), subproblems backtracks, undoing assignments reached, within which consistency has been fully restored subproblem lems). Experimental checking for consistency from deadends. The remainder of this section further describes this heuristic. in each critical resource in these subprob- in Section 7 suggest that often, by selectively in small resource subproblems, DCE can quickly recover the mechanics of (i.e. consistency with respect to capacity constraints results reported small critical identifies 4.1. Identifying critical resource subproblems (PCS) episodes in the current Set of operations is created and maintained are provided For each capacity constraint violation among operations The critical resource subproblems used by DCE consist of groups of operations conflict along with groups of critical operations participating the same resources. involving identified during earlier backtracking identified by the default Below, we refer to the group of (unscheduled) operations left as the consistency enforcing mechanism as having no possible reservations to restore (see Fig. 6). In order Partial Conjkting consistency, the search procedure needs to at least go back to a search state in which each PCS operation has one or more possible reservationsP DCE attempts to identify such additional operations by maintaining a group of critical resource identified during earlier backtracking episodes. Below, we refer to subproblems (FDG). Details this data structure as the Former Dangerous Groups of operations in Section 4.3. on how this data structure in PCS, DCE checks subproblems. A the FDG to a capacity constraint resource violation in that resource subproblem were involved in a capacity constraint violation on the same resource if two and over a “close” at the end of this resource conflicts are “close”. two conflicts were considered close if the distance separating paper, them was not than twice the average operation duration. Related critical subproblems greater identified by inspecting are then merged with corre- in PCS to form a new set of one or more critical resource sponding operations subproblems, which we refer to as the Dangerous Group of operations for in subgroups of resource the conflict at hand. Like FDG, DG for the same resource over close subproblems consisting of operations contending that are un- or overlapping subproblem in PCS if, in an earlier backtracking episode, operations time interval. A system parameter intervals. While backtracking, the FDG data structure is used to determine In the experiments data structure and retrieves is considered is organized all related operations in FDG resource reported related (DG) time 4 Clearly, this is not guaranteed to be sufficient, as other operations may also contribute to the conflict. 466 N. Sadeh et al. I Artificial Intelligence 76 (1995) 455-480 Procodurm DEPTH-FIRST-WITR-DCR () If UNSCRBD-OP = 0 Then 8olution found, STOP. Let PCS - 0 Call CONSTRAINT-PROPAGATIOU, which places all oparationm with no remaining rmservations in PCs If PCS - 0 Then Bogin Let OP = OPBR-SBLBCTION Lat RRHRINING-RRSRRV(OP) (UNSCERD-OP) = list of possible reeorvationa for OP orderad according houriatic (best roservatioas to the value ordering first) Let IuzSERv = Pop first raaorvation in RBM&ININQ-RBSz8RV(OP) Pumh (OP,RRSRRV) onto SCHlLDuLE Remavo OP from UNSCEED-OP Call DEPTH-FIRST-WITR-DCE 0 End Begin Else Let DO be the mot of conmolidatad resource mbproblama obtained subproblenu in PCS with related remurce by merging mbproblrrrm in FDO rmource Call DCE-BACATRACX (DO) End End If Bad Procedure Procedure DCE-BJUXTRACX (DO) If SCRBDDLE = 0 Then Lat NO-SOLUTION - TRUE and STOP. Remove thm last (operation, romrvation) and Let OP be the operation in that pair Insert OP in DNSCRRD-OP and in W Let CONFLICT - FALSR For each remurea s&problem pair punhod onto SCRBDULB in DO, prune the set of remaining rmsorvations of each operation in that mbproblom with rampact to capacity conmtrainta. In the procam, is found to have no poamiblo rasorvations left then atop anforcing consistency and Let CONFLICT . TRUE by enforcing full consistency if an operation If CONFLICT = FALSE Then Begin RRSLRV = Pop first rosorvation in RBMRINING-RBSBRV(OP) Pumh (OP,RRSERV) onto SCRZDULB Ramova OP from UNSCEBD-OP UPDATE-FW(W) Call DBPTA-FIRST-WITS-DCE 0 End Blaa Call DCE-BACKTRACK (DQ) Bad If End Procedure Begin Program Lot scmm = 0 Lot FW = (z Let NO-SOLIJTION = FUSE Let DNSCRBD-OP = (0;,...0;~,0~,...0~*..,0;,...0~") Call DEPTH-FIRST-WITH-DCEO If NO-SOLUTION . FALSE Than PRINT-SOLUTION Else PRINT "Infeasible Problem" End If End Program Fig. 6. DCE procedure. N. Sadeh et al. I Artificial Intelligence 76 (1995) 455-480 467 scheduled subproblems or by creating new resource subproblems. in DG, either by being added inserted are to existing resource 4.2. Backtracking while selectively enforcing consistency Once the initial DG has been identified, DCE backtracks, undoing assignments full consistency with respect in each of the resource subproblems is in DG to capacity in DG. As long as conflicts are to backtrack and unscheduled operations are restoring to to a consistent search state, it is not always a sufficient one. In other the effectiveness of DCE critically depends on its ability to heuristically in a chronological order, until it reaches a search state in which consistency restored within each of the resource subproblems defined by operations (see Fig. 6). This is done by enforcing constraints detected, inserted subproblems consistency within each of these resource subproblems backtrack words, focus on the right resource subproblems. the procedure continues into existing or new resource is a necessary condition in DG. While is enforced in DG becomes too large, k-consistency Because full consistency checking can be expensive on large subproblems, if a resource subproblem instead of full consistency, where k is a parameter of the system [9]. In the experiments reported at the end of this paper, k was set to 4. At the end of the backtracking episode, DG has maximum size, call it DG,,,. Assuming that the procedure was to contain all the able to backtrack operations at the origin of the deadend is then saved for later use in the FDG data structure. Additional details regarding the management If a related backtracking of this data structure are provided episode is later encountered by the system, DG,,, can be retrieved and combined with the PCS of this new episode. is expected and often more. DG,,, to a consistent search state, DG,,, in the next subsection. 4.3. Storing information about past backtracking episodes The purpose of the Former Dangerous Groups of operations (FDG) main- tained by the system is to help determine more efficiently and more precisely the scope of each deadend by focusing on critical resource subproblems. Each group for the of operations allocation of a same resource. Accordingly, whenever, a conflict is detected that involves some of the operations in one group, the backtracking procedure checks for consistency among all operations in FDG consists of operations that are in high contention in that group. The groups of operations obtained at the end of previous backtracking episodes ever a backtracking episode in FDG are build from the Dangerous Groups (DGs) Indeed, when- to contain all the is completed, DG,,, is expected (DG,,,). ’ Note that DCE is not expected to be very effective at recovering from complex conflicts involving interactions between multiple resource subproblems. A heuristic which is often more effective for these complex conflicts is described 6 Clearly, while this is not guaranteed, experimental results suggest that this is often the case. in Section 6. 468 N. Sadeh et al. I Artificial Intelligence 76 (1995) 455-480 conflicting operations at the origin of this episode. Generally, DG,,, may involve one or several resource subproblems requiring the same resource). Each one of these subproblems is merged with related subproblems currently stored in FDG. separately added to the data structure. Finally, as operations are scheduled, are removed If there is no related group in FDG, the new group is they (i.e. groups of operations from FDG. 4.4. An example require Fig. 7 illustrates (no prior backtracking the behavior of DCE on to capacity constraints between from FDG. Another conflict is detected the same resource. At this point, DCE enforces is initially empty The procedure unschedules in Fig. 1. After scheduling operations 0: and 0; on resource R,, the small scheduling problem the introduced left. Given that procedure detects that operation 0: has no possible reservations episode), we the FDG data structure have PCS = DG = (0:). the most recently scheduled operation, namely Oi, and inserts it in DG together with operation 0:) as both full of these operations consistency with respect two operations7 these and finds that, after consistency checking, the operations still admit some possible reservations. This marks the end of the first backtracking episode. The procedure for possible reuse, then schedules operation 0: at saves the current DG in FDG, is its next best available start time,’ namely start time 6. In the process, 0: removed in this new search state, which marks the beginning of a second backtracking episode. This time the consistency left (i.e. enforcing procedure the group of PCS = (0:)). it un- dangerous schedules operation 0 :, DCE enforces full consistency’ with respect to capacity in DG = { Ot, Oi, O:}. When it finds that the current search state is constraints thereby returning still inconsistent, DCE proceeds and unschedules operation 0:) In this search state, full to the root search state with DG = {O:, Oi, O:, Ol}. in DG consistency with respect three that the problem indicates search states to find that the problem is infeasible. In contrast, a total of 50 search for the same small problem, when relying on the SIMPLE- states BACKTRACK procedure outlined in Fig. 2. The example also shows how the use of the Formerly Dangerous Groups (FDG) of operations helps the system identify the procedure critical resource would not detect an inconsistency when it comes back to depth 1 in the second backtracking episode, as it would only check for consistency between 0: and Oz. to capacity constraints is infeasible. finds that operation 0: has no possible reservations operations, DG = { 0:) 0 i} . A ccordingly, In total, the system only generates If it was not for this mechanism, the system adds operation between operations Using FDG, subproblems. time, when is required this 0: to to 2-consistency or arc-consistency, given that there are only two operations ’ This is equivalent [9]. ’ Actually, start time 6 is not the start time picked by our reservation ordering heuristic. The system was manually forced to pick this value to make the example more interesting. 9 This time the system enforces 3-consistency, given that there are three operations in DC. N. Sadeh et al. I Artijkial Intelligence 76 (1995) 455-480 469 >> Depth: 0, Numbor of statos vioitodr 0, FDG=(ZI 0; is scheduled betweon 14 and 20 on Rp >> Depth: 1, Number of stat.6 visited: 1, FDG=0 0; is scheduled between 9 and 14 on R, >> Depth: 2, Number of statea visited: 2, FDG=IZ) conflict detected: 0: has no possible reservations left: PCS=DG=( [O;]) [Beginning of first backtracking episode1 0; is unscheduled >> Depth: 1, Number of states visited: 2, FDG=0 3 2 DG=l [03’021 1 Full consistency checking with respect to capacity constraints in DC: Remaining possible start time8: 0;: (3,4,5,6) 0;: (8,9,10,11) FDG= ([O~,O~]) [End of first backtracking e~isod~l 0; is scheduled between 6 and 11 OP R2 . . Depth: 2, Number of states visited: 3, FDG=([Oi]) Conflict detected: 0: has no possible reeervations left: PCS={ [O;]], DG=( [O;,O;]) [Beginning of second backtracking episode] 0; is uaschoduled >> Depth: 1, Number of states visited: 3, FDG=([O:]) DG=W;,O;,O~ll Full consistency checking with respect to capacity constraints in DC: Conflict detected 0; is unscheduled >> Depth: 0, slumber of states visited: 3, FDG=([O:]] DG=l [02,02,03.021 I2 3 4 I pull consistency checking with respect to capacity constraints in DC: Conflict detectad Infeasible Problem [End of second backtracking episode] Fig. 7. An edited trace illustrating the DCE procedure. More generally, experimental in important results computation time. increases results presented in search efficiency and important in Section 7 show that DCE often in reductions 4.5. Additional ‘watch dog’ consistency checks Because groups of operations our system further performs simple “watch dog” checks on these dynamic groups of operations. likely deadend candidates, in FDG are 470 N. Sadeh et al. I Artificial Intelligence 76 (1995) 455-480 More specifically, for each group G of operations in FDG, a rough check to see if the resource can still accommodate the group. This is done using redundant constraints of the form: the system performs in all the operations Max(lstf f duf, Of E G) - Min(estf, Of E G) 2 2 OfEG duf , where estf and 1st: are respectively in the current search state. the earliest and latest possible start times of Of Whenever such a constraint is violated, an inconsistency has been detected. these checks enable to catch inconsistencies Though very simple and inexpensive, involving that would not be immediately detected by large groups of operations the default consistency mechanisms. Clearly, some inconsistencies can still escape these rough checks. While backtracking, the same “watch dog” checks can be used prior full consistency with respect enforcing resource subproblems in the second backtracking instance, sufficient to detect where DG = {[Oi, Oz, O:]}, inconsistencies in DG. This can significantly reduce computation to capacity constraints to in the critical time. For in Fig. 7, these simple checks are at depth 1 and 0. For example, at depth 1, episode Max(lstf + duj, Of E DG) - Min(estf, 0: E DG) = 14 - 3 = 11 , while duf= 12. 2 OfEDG 5. Learning Ordering From Failures (LOFF) Often, participating reaching a deadend state is also an indication that the default variable for dealing with the subproblem at hand. Typically, ordering was not adequate the operations to schedule than the ones selected by the default variable ordering heuristic. In other in the words, it is often a good idea to first schedule the operations participating conflict is an that was just resolved. Learning Ordering From Failure (LOFF) adaptive procedure in the presence of conflicts. the default variable ordering to be more difficult in the deadend that overrides turn out After recovering from a deadend, namely after backtracking all the way to an apparently consistent search state, LOFF uses the Partial Conflicting Set (PCS) of the order in which operations will be rescheduled and the deadend to reorganize make sure that operations first. This is done using a in the PCS are scheduled in PCS are pushed in descending order of quasi-stack, Qs, on which operations domain size, i.e. PCS operations with a large number of remaining are pushed first on the quasi-stack. When the quasi-stack uses its default variable ordering heuristic, as described reservations is empty, the procedure in Section 3. However, N. Sadeh et al. I Artificial Intelligence 76 (1995) 455-480 471 when Qs contains some operations, ations, the ones on operations with the smallest number of remaining reservations. top of the quasi-stack, the procedure starting with first schedules namely these oper- those Qs If a candidate operation for a second time, it is pushed again on Qs as if it had a smaller domain. This orders operations based on the recency of the conflict in which they were last involved and based on their number of remaining reservations. is already in Qs, i.e. if it is encountered 6. An Incomplete Backjumping Heuristic focusing to reduce identifying shallow/deep the complexity of Traditional backtrack focus on smaller conflicts, (DCE) procedure described search procedures only undo decisions to be inconsistent. Proving that an assignment its effort on small critical subproblems. Because the only effective way to deal with more complex conflicts learning attempt backtracking by either simplifying that have been is inconsistent with others proven can be very expensive, especially when dealing with large conflicts. Graph-based backjumping and Nth-order plexity of full-blown dependency-directed process of identifying constraint graph) or restricting Dynamic Consistency Enforcement aims at reducing dynamically techniques complex conflicts involving a large number of variables.” that heuristics simply because heuristic described longer complete and may fail to find solutions name of Incomplete Backjumping Heuristic (IBH). Texture measures such as the ones described the com- the inconsistent decisions (e.g. based on the topology of the the size of the conflicts that can be detected. The in Section 6 also the source of a conflict by these they all have problems dealing with more It might in fact turn out is by using that undo decisions not because they have been proven inconsistent but taken in the is no the in [S] could be used to estimate the tightness of different search states, for instance, by estimating the number of global solutions compatible with each search state. Clearly, a search state whose is loosely partial solution constrained, whereas one compatible with a small number of global solutions is leading to much tighter search states would be tightly constrained. Assignments prime candidates is suspected. The (IBH) used in this study is simpler and, yet, Incomplete Backjumping Heurhtic often seems to be sufficient. Whenever this heuristic backjumps all the way to the first search state and simply tries and next best value the first operation (i.e. reservation) the search selected be for the critical operation the variable ordering heuristic). is compatible with a large number of global solutions they appear overly restrictive. This is the approach to be undone when a complex conflict the resulting search procedure to feasible problems, hence the system starts thrashing, in this section. Clearly, in that state (i.e. IBH considers that ‘°Clearly, illustrated are some conflicts there involving by the watch dog checks described large numbers in Section 4. of variables that are easy to catch, as 472 N. Sadeh et al. I Artificial Intelligence 76 (1995) 455-480 procedure is thrashing, and hence that it is facing a complex conflict, when more than 8 assignments had to be undone since the last time the system was thrashing or since the procedure began, if no thrashing occurred earlier; 8 is a parameter of the procedure. 7. Empirical evaluation This section reports of the look-back schemes presented the results of empirical studies conducted performance reports performance on a suite of 60 benchmark problems introduced is followed by a more detailed study comparing look-back second-order compare LOFF with that of an incomplete procedure combining all three of the look-back schemes presented to assess the in this paper. The first study in [18]. This the performance of the first two that of Finally, we relying on DCE & (DCE & LOFF) against backtracking. the performance of the complete search procedure in this paper (DCE & LOFF & IBH). introduced learning [4] and chronological schemes deep in this paper 7.1. Performance evaluation on a first suite of problems first introduced in [18]. In the experiments A first set of experiments was run on a testsuite of 60 job shop scheduling problems in [18], the default variable and value ordering heuristics used in our study (i.e. the ORR and FSS heuristics described a variety of other in Section 3) were shown to outperform though they still failed to solve 8 out of the variable/value 60 problems. that the combina- (DCE & LOFF & IBH) can efficiently tion of our three solve all 60 problems ordering combinations, In contrast, the results presented below indicate in the testsuite. techniques look-back reported Specifically, requires scheduling (five operations the testsuite consists of six groups of ten problems each. Each ten jobs on five resources and involves a total of 50 routing per in which it has to visit each one of the five resources. This number of (one or two in these experiments) which are always visited the same number of steps. The six groups of problems were obtained by problem operations specifying a sequence sequence varies from one job to another, except for a predetermined bottleneck after varying job has a linear process two parameters: job). Each resources (1) the number of a priori bottlenecks (BTNK): one (BZ’NK = 1) or two (BTNK = 2), and (2) the spread (SP) of the release and due dates between which each job has to The SP parameter utilization be scheduled: wide (SP = W), narrow (SP = N), or null (SP = 0). and the operation durations have been adjusted so that remains close to 100% over most of the span of each In these problems, each operation had slightly over 100 possible start bottleneck problem. N. Sadeh et al. I Artificial Intelligence 76 (1995) 455-480 413 times (i.e. values) after application of the consistency enforcing in the initial search state. Additional details on these problems can be found in [HI.” techniques Table 1 compares (1) the basic depth-first procedure described the performance of the following two procedures: relying on chronological enforcing Section 3 (this is also the procedure backtracking and variable/value techniques in Fig. 2, namely a procedure the default consistency in and on ordering heuristics described to perform best in [Ml); reported Table 1 Comparison of chronological backtracking and DCE & LOFP & IBH on six sets of ten job shop problems Chronological DCE & LOPP & IBH SP=W BTNK = 1 SP=W BTNK=2 SP=N BTNK= 1 SP=N BTNK=2 SP=O BTNK = 1 SP=O BTNK = 2 Overall performance Search efficiency # experiments solved (out of 10) CPU seconds Search efficiency # experiments solved (out of 10) CPU seconds Search efficiency # experiments solved (out of 10) CPU seconds Search efficiency # experiments solved (out of 10) CPU seconds Search efficiency # experiments solved (out of 10) CPU seconds Search efficiency # experiments solved (out of 10) CPU seconds Search efficiency # experiments solved (out of 60) CPU seconds 0.96 10 88.5 0.99 10 93 0.78 8 331.5 0.87 9 184 0.73 7 475 0.82 8 300.5 0.86 52 245.5 0.96 10 90.5 0.99 10 95 0.91 10 106 0.93 10 119.5 0.88 10 134.5 0.84 10 226.5 0.92 60 128.7 I1 The problems are also accessible via anonymous ftp to cimdd.cimds.ri.cmu.edu, found in /usr/sadeh/public/csp_test_suite. the directory. where they can be file details the content of the various files in A README 474 N. Sadeh et al. I Artificial Intelligence 76 (1995) 455-480 (2) the same procedure schemes presented enhanced with the DCE, LOFF and IBH look-back in this paper. For each of the 60 problems, search was stopped in each problem category if it required more than 500 three is reported along search states. Performance dimensions: (1) Search eficiency: the average ratio of the number of operations scheduled over the total number of search states that were explored. absence of backtracking, operation, and hence search efficiency only one search state is equal to 1. is generated to be In the for each (2) Number of experiments solved in less than 500 search states. (3) CPU seconds: this is the average CPU time required this time was approximated to solve a problem. When a solution could not be found, as the CPU time taken to explore 500 search states (this approximation was only used for chronological backtracking, since DCE & LOFF & IBH solved all problems). All CPU times were obtained on a DECstation 5000 running Knowledge Craft on top of Allegro Common Lisp. Experimentation with a variation of the system written would run about 30 times faster if reimplemented that the search procedure in this language [19]. in C indicates in approximately The results indicate scheme and, on average, proved that DCE & LOFF & IBH consistently outperformed the scheme in terms of CPU time, search efficiency and chronological backtracking (SP = W), both techniques number of problems solved. On the easier problems the same amount of time. On the more solved all 20 problems (SP = N and SP = 0), DCE & LOFF & IBH clearly dominated difficult problems In particular, on problems with SP = 0 and BTNK = chronological backtracking. than the chronological 1, DCE & LOFF & IBH solved 40% more problems to be 3.5 times faster. Overall, backtracking while chronological backtracking failed to solve 8 problems out of 60, DCE & LOFF & IBH efficiently solved all 60 problems, and, on average, was almost backtracking. Had we not twice as fast as the procedure with chronological stopped the after 500 search states, backtracking procedure speedup achieved by DCE & LOFF & IBH would be even more significant. In for which the chronological procedure was fact, based on a couple of problems that allowed to expand a larger number of search states, it appears that problems are not solved to be solved (with chronological backtracking). in 500 states often require the chronological thousands more 7.2. Further evaluation To look-back evaluate our in the testsuite, namely schemes, we picked the category further the most difficult problem category for which the default consistency enforcing procedure ordering heuristics are least (SP = 0) and generated an additional 80 scheduling problems, 40 with effective BTNK = 1 and 40 with BTNK = 2. The SP = 0 problem category was also the most difficult one for all the other combinations of variable and value ordering to problems in which heuristics tested in the study reported in [18]. It corresponds and variable/value N. Sadeh et al. I Artificial Intelligence 76 (1995) 455-480 415 all jobs are released at a common date and need to be completed by a common due date. Among the resulting 80 problems, we only report performance on those problems to guarantee search.” This leaves 16 scheduling problems with one bottleneck backtrack-free (SP = 0 and BTNK = l), and 15 with two bottlenecks schemes were not sufficient (SP = 0 and BTNK = 2). the default for which of three complete backtracking Below, we successively report the results of two studies. The first one compares the performance schemes: chronological back- tracking, second-order deep learning, and the procedure combining the DCE and the complete search LOFF backtracking heuristicsi procedure using DCE and LOFF with the incomplete search procedure combining DCE, LOFF and IBH. The second study compares The results of the first study comparing chronological backtracking, order deep learning [4] and the DCE & LOFF procedures advocated and 5 are summarized in Tables 2 and 3. The results reported here were obtained using a search limit of 500 nodes and a time limit of 1800 seconds (except for deep to 36,000 seconds14). All CPU learning, for which the time limit was increased second- in Sections 4 Table 2 Results of one-bottleneck 1800sec (except deep learning); node limit: 500) experiments. (S: solved; F: failure; S*: proved infeasible; time limit: Exp. No. 1 2 3 4 5 6 I 8 9 10 11 12 13 14 15 16 Chronological DCE & LOFF Deep learning No. of nodes 500 500 74 69 500 500 500 500 53 500 500 500 51 500 500 500 CPU (set) 1427 1587 148 152 1407 1469 1555 1705 108 1529 1460 1694 109 1762 1798 1584 Result No. of nodes F F S S F F F F S F F F s F F F 122 500 63 52 65 500 59 41 53 500 85 500 51 63 69 500 CPU (set) 1232 1212 117 120 134 1486 130 145 102 1536 1800 1131 81 138 142 1183 Result No. of Nodes S* F s s s F s S” s F F F s S S F 500 500 25 69 500 500 500 500 53 500 500 500 51 500 500 65 CPU (set) 5756 5834 36000 391 11762 8789 9681 9560 122 9114 14611 21283 88 18934 9600 36000 Result F F F S F F F F S F F F S F F F that do not require backtracking r* Clearly, performance on problems backtracking schemes never get invoked, and hence CPU time remains unchanged. I3 Besides to assess the benefits of using DCE and LOFF separately. These experiments show that both techniques contribute to the improvements I4 This was motivated by the fact that our implementation of deep learning may not be optimal. reported below, additional experiments were performed is of no interest, since our the experiments in this section. reported 476 N. Sadeh et al. I Artificial Intelligence 76 (1995) 455-480 times reported below were obtained on a DECstation 5000 running Knowledge indicated above, comparison Craft on top of Allegro Common Lisp. As already between C and Knowledge Craft implementations of similar variable and value that the code would run about 30 times faster in C indicates ordering heuristics [191. those problems, backtracking chronological On the one-bottleneck in the zebra problem, where over chronological backtracking either to the fact that the constraints than solved only 4 problems out of 16 (see Table 2). Interestingly enough, deep learning showed no improvement in the number of problems solved or in CPU time. As a matter of fact, deep learning was even too slow to find solutions to some of the problems solved by chronological backtracking. This in job shop scheduling are more tightly is attributed interacting of deep the improvement [4]. On the learning over chronological backtracking was originally ascertained other hand, DCE & LOFF solved 10 problems out of 16 (2 out of these 10 infeasible). As expected, by focusing on a problems were successfully proven is able to discover small number of critical subproblems, DCE & LOFF larger learning, while requiring only a more useful conflicts fraction of the time. Another observation fewer that chronological search states than chronological backtracking took backtracking solved. However, slightly more CPU time, due to the higher level of consistency enforcement. for the problems each of the DCE & LOFF expansions deep is that DCE & LOFF expanded than second-order Results for the set of two-bottleneck problems are reported results are observed here again: deep backtracking chronological in Table 3. Similar over and seems significantly slower. The difference be- shows no improvement learning Table 3 Results of two-bottleneck 1800 set (36,000 set for deep learning); node limit: 500) experiments. (S: solved; F: failure; S*: proved infeasible; time limit: Exp. No. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 Chronological DCE & LOFF Deep learning No. of nodes 500 500 84 56 51 500 500 52 500 500 66 56 54 500 500 CPU (set) 1139 1444 175 123 101 1531 1775 102 1634 1676 163 139 129 1676 1522 Result No. of nodes F F s S s F F s F F S s S F F 113 425 109 56 51 321 500 52 247 91 59 58 52 346 324 CPU (set) 1800 1800 202 112 113 1800 1357 115 974 1800 104 104 91 1800 1800 Result No. of Nodes F F s s s F F s s F s s s F F 18 115 84 56 13 328 500 33 500 26 66 58 54 500 296 CPU (set) 36000 36000 811 213 36000 36000 2793 36000 1519 36000 2240 281 28900 9031 36000 Result F F S S F F F F F F S S S F F N. Sadeh et al. I Artificial Intelligence 76 (1995) 455-480 477 tween chronological backtracking and DCE & LOFF is not as impressive as in the first set of experiments. As can be seen in Table 3, chronological backtracking solved 7 out of 15 problems, whereas DCE & LOFF solved 8. On the problems and DCE & LOFF, DCE & LOFF solved by both chronological backtracking turned out to be slightly faster overall. These less impressive results suggest that the presence of multiple bottlenecks often introduces more complex conflicts. in the following subsection suggest that in this case incomplete Results presented such as the one entailed by the IBH heuristic are often backtracking procedures much more effective. 7.3. Complete versus incomplete search procedures Tables 4 and 5 compare the performance of the complete search procedure in combination with the IBH heuristic described search procedure using in Section 6. problems and 8 problems, DCE & LOFF combined with IBH solved 14 based on DCE & LOFF against that of an incomplete DCE & LOFF While DCE & LOFF could only solve 10 out of 16 one-bottleneck out 15 two-bottleneck problems. The only one-bot- one-bottleneck that were not solved by DCE & LOFF & IBH are the two tleneck problems problems identified as infeasible by the complete procedure with DCE & LOFF (see Table 2). This is hardly a surprise. While the addition of IBH to DCE & LOFF enables the search procedure it also infeasible problems can no longer be makes to solve a larger number of problems, (i.e. and 13 two-bottleneck the procedure incomplete problems Table 4 Results of one-bottleneck 1800sec: node limit: 500) experiments (S: solved; F: failure; S*; proved infeasible; time limit: Exp. No. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 DCE & LOFF DCE & LOFF & IBH No. of nodes 122 500 63 52 65 500 59 41 53 500 85 500 51 63 69 500 CPU (sed 1232 1212 117 120 134 1486 130 145 108 1536 1800 1131 81 138 142 1183 Result No. of nodes S* F S S S F S S* S F F F S S S F 350 203 63 52 65 127 59 457 53 67 74 164 51 63 69 156 CPU bed 1800 1124 123 116 144 424 125 1800 100 170 170 616 92 149 158 524 Result F S S S S S S F S S S S S S S S 478 N. Sadeh et al. I Artificial Intelligence 76 (1995) 455-480 Table 5 Results of two-bottleneck 1800sec; node limit: 500) experiments (S: solved; F: failure; S*; proved infeasible; time limit: Exp. No. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 DCE & LOFF DCE & LOFF & IBH No. of nodes 113 425 109 56 51 321 500 52 247 91 59 58 52 346 324 CPU (set) 1800 1800 202 112 113 1800 1357 115 974 1800 104 104 91 1800 1800 Result No. of nodes F F S S S F F S S F S S S F F 151 371 95 56 51 420 159 52 423 440 59 58 52 239 73 CPU (set) 456 1780 210 108 97 1800 534 96 1705 1800 113 112 102 512 195 Result S S S S S F S S S F S S S S S identified). Additional experiments backtracking DCE & LOFF & IBH, indicating that both IBH and DCE & LOFF contribute the performance results that were not as good as those obtained by to combining IBH with a simple chronological improvement observed in Tables 4 and 5. scheme produced Results on two-bottleneck problems of IBH is particularly effective on these problems. This is attributed that two-bottleneck assignments participating difficult assignments seems more effective at solving these problems. (see Table 5) also suggest that the impact to the fact the in these more complex conflicts might simply be too it can undo Instead, IBH scheme. that are not provably wrong but simply appear overly restrictive, problems give rise to more complex conflicts. Identifying for any exact backtracking because 8. Concluding remarks We CSP: (1) (2) (3) have presented three look-back techniques for the job shop scheduling (DCE) , a heuristic Dynamic Consistency Enforcement focuses on restoring consistency within small critical subproblems, Learning Ordering From Failure (LOFF), order Incomplete Backjumping Heuristic (IBH) which, when thrashing occurs, can undo assignments inconsistent but appear overly restrictive. in which variables are instantiated based on earlier conflicts, and that are not provably that modifies a technique that dynamically the N. Sadeh et al. I Artificial Intelligence 76 (1995) 455-480 479 The significance of this research is twofold: techniques transportation, (e.g. manufacturing, (1) Job shop scheduling problems with non-relaxable space, time windows have multiple applications health care, etc.). We have shown that our look-back heuristics combined with reduce powerful that we had previously developed search, and (ii) enable the average complexity of backtrack this search that could not be solved otherwise procedure requirements. While the results reported due to excessive computational in finding a feasible require this study were obtained on problems in this paper can also be schedule, used on optimization such as the Just-In-Time that schemes presented job shop scheduling problems described versions of the scheduling problem, to efficiently solve problems the backtracking (i) further in [19]. (2) This research also points these in the literature. to shortcomings of dependency-directed back- com- tracking schemes advocated earlier In particular, parison with second-order deep learning indicates that this technique failed to improve performance on our set of job shop scheduling problems. More techniques often appear generally, Nth-order deep and shallow learning inadequate when applied they to job shop scheduling problems because size to decide whether or not to record earlier rely solely on constraint failures. When to small-size conflicts, they often fail to record some important constraints; when they consider larger conflicts, complexity becomes prohibitive. A more general weakness of traditional backtracking schemes has to do with the fact that they never undo assignments unless they can be proven to be at the source of the conflict. When dealing with large complex conflicts, proving can be very suggest that, when thrashing cannot expensive. easily be avoided, idea to use incomplete backjumping heuristics that undo decisions simply because they appear overly restrictive. Instead, our experiments it is often a better should be undone their computational that a particular limit themselves assignment techniques References [l] C. Badie, G. Bel, E. Bensana and G. Verfaillie, Operations to solve scheduling problems, research and artificial intelligence in: Proceedings First International Conference on cooperation Expert Planning Systems (1990). [2] J.R. Bitner and E.M. Reingold, Backtrack programming techniques, Commun. ACM 18 (11) (1975) 651-655. [3] P. Burke and P. Prosser, A distributed scheduling, Technical Report AISL-42, Department Strathclyde, Glasgow, Scotland (1989). asynchronous system and reactive of Computer Science, University of for predictive (41 R. Dechter, Enhancement schemes for constraint processing: backjumping, learning, and cutset decomposition, Artif. Intell. 41 (1989) 273-312. [5] R. Dechter and I. Meiri, Experimental techniques in: Proceedings of ZJCAZ-89, Detroit, MI (1989) 271-277. evaluation of preprocessing satisfaction problems, in constraint [6] R. Dechter and J. Pearl, Network-based heuristics for constraint satisfaction problems, Artif. Zntell. 34 (1) (1988) l-38. 480 N. Sadeh et al. 1 Artificial Intelligence 76 (1995) 455-480 [7] J. Doyle, A truth maintenance [8] MS. Fox, N. Sadeh and C. Baykan, Constrained heuristic search, system, Artif. Zntell. 12 (3) (1979) 231-272. in: Proceedings IJCAI-89, Detroit, MI (1989) 309-315. [9] E.C. Freuder, A sufficient condition for backtrack-free search, J. ACM 29 (1) (1982) 24-32. [lo] M.R. Garey and D.S. Johnson, Computers and Intractability: A Guide to the Theory of NP-Completeness (Freeman, San Francisco, CA, 1979). [ll] J. Gaschnig, Performance measurement and analysis of certain search algorithms, Technical Report CMU-CS-79-124, Computer Science Department, Carnegie Mellon University, Pitts- burgh, PA (1979). [12] S.W. Golomb and L.D. Baumert, Backtrack programming, [13] R.M. Haralick and G. L. Elliott, Increasing problems, Artif. Zntell. 14 (3) (1980) 263-313. J. ACM 12 (4) (1965) 516-524. tree search efficiency for constraint satisfaction [14] L.A. Johnson and D.C. Montgomery, Operations Research in Production Planning, Scheduling, and Inventory Control (Wiley, New York, 1974). [15] C. Le Pape and S.F. Smith, Management of temporal constraints for factory scheduling, Technical Report, The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA (1987); in: in Information Systems, Paris, France Proceedings Working Conference on Temporal Aspects (1987). [16] A.K. Mackworth and E.C. Freuder, The complexity of some polynomial network consistency algorithms for constraint satisfaction problems, Artif. Intell. 25 (1) (1985) 65-74. [17] P.W. Purdom Jr, Search rearrangement backtracking and polynomial average time, Artif. Intell. 21 (1983) 117-133. [18] N. Sadeh, Look-ahead techniques for micro-opportunistic job shop scheduling. Ph.D. Thesis, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA (1991). [19] N. Sadeh, Micro-opportunistic in: M.S. Fox and M. Zweben, eds., Intelligent Scheduling (Morgan Kaufmann, San Mateo, CA, 1994) Chapter the MICRO-BOSS factory scheduler, scheduling: [20] k. Sadeh and M.S. Fox, Preference constraint graphs, propagation Technical Report CMU-CS-88-193, Comuter Science Department, Carnegie Mellon University, Pittsburgh, PA (1988); also: Robotics Institute Technical Report CMU-RI-TR-89-2. in temporal/capacity [21] N. Sadeh and M.S. Fox, Focus of attention in an activity-based scheduler, in: Proceedings NASA Conference on Space Telerobotics (1989). [22] N. Sadeh and M.S. Fox, Variable and value ordering heuristics job-shop in: Proceedings Fourth International Conference on Expert Systems in Production and scheduling, Operations Management, Hilton Head Island, SC (1990) 134-144. for activity-based [23] N. Sadeh and M.S. Fox, Variable and value ordering heuristics for hard constraint satisfaction to job shop scheduling, Technical Report CMU-RI-TR-91-23, The problems: an application Robotics Institute, Carnegie Mellon University, Pittsburgh, PA (1992). [24] R. Stallman and G. Sussman, Forward reasoning and dependency-directed circuit analysis, Artif. Intell. 9 (1977) 135-196. system for computer-aided backtracking in a [25] K. Sycara, S. Roth, N. Sadeh and MS. Fox, Distributed constrained heuristic search, IEEE Trans. Syst. Man Cybern. 21 (6) (1991). [26] R.J. Walker, An enumerative in: R. Bellman and M. Hall, eds., Combinatorial Analysis, Proceedings Symposium on Applied Mathematics (AMS, Providence, RI, 1960) 91-94, Chapter 7. for a class of combinatorial problems, technique 