Artificial Intelligence 228 (2015) 129–152Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintConfidence-based reasoning in stochastic constraint programming ✩Roberto Rossi a,∗a Business School, University of Edinburgh, United Kingdomb Department of Computer Science, Taif University, Taif, Saudi Arabiac Department of Management, Cankaya University, Ankara, Turkeyd Insight Centre for Data Analytics, University College Cork, Ireland, Brahim Hnich b, S. Armagan Tarim c,d,1, Steven Prestwich d,1a r t i c l e i n f oa b s t r a c tArticle history:Received 7 November 2014Received in revised form 5 July 2015Accepted 8 July 2015Available online 15 July 2015Keywords:Confidence-based reasoningStochastic constraint programmingSampled SCSP(α, ϑ)-solution(α, ϑ)-solution setConfidence interval analysisGlobal chance constraint1. IntroductionIn this work we introduce a novel approach, based on sampling, for finding assignments that are likely to be solutions to stochastic constraint satisfaction problems and constraint optimisation problems. Our approach reduces the size of the original problem being analysed; by solving this reduced problem, with a given confidence probability, we obtain assignments that satisfy the chance constraints in the original model within prescribed error tolerance thresholds. To achieve this, we blend concepts from stochastic constraint programming and statistics. We discuss both exact and approximate variants of our method. The framework we introduce can be immediately employed in concert with existing approaches for solving stochastic constraint programs. A thorough computational study on a number of stochastic combinatorial optimisation problems demonstrates the effectiveness of our approach.© 2015 Elsevier B.V. All rights reserved.The stochastic constraint satisfaction/optimisation framework introduced in [2,3] constitutes an expressive declarative formalism for modelling problems of decision making under uncertainty. A stochastic constraint satisfaction problem (SCSP), alongside decision variables, features random variables, which follow some probability distribution and can be used to model uncertainty. Relationships over subsets of random and decision variables can be expressed in a declarative manner via stochastic constraints. The fact that a given relationship over subsets of random and decision variables should be satisfied according to a prescribed probability can be expressed by means of chance constraints. Finally, since problems of decision making under uncertainly are sequential in nature, the modeller can define a stage structure, that is a sequence of decision stages, in each of which a subset of all possible decisions are taken and a subset of all possible random variables are observed. A solution to an SCSP can be represented in general by means of a policy tree, which records feasible or optimal decisions associated with each possible set of random variable realisations.✩This work is an extended version of [1].* Corresponding author at: Business School, University of Edinburgh, 29 Buccleuch place, EH8 9JS, Edinburgh, UK. Tel.: +44 (0)131 6515239; fax: +44 (0)131 650 8077.E-mail addresses: roberto.rossi@ed.ac.uk (R. Rossi), hnich.brahim@gmail.com (B. Hnich), armtar@yahoo.com (S.A. Tarim), s.prestwich@cs.ucc.ie(S. Prestwich).1 This publication has emanated from research supported in part by a research grant from Science Foundation Ireland (SFI) under Grant Number SFI/12/RC/2289.http://dx.doi.org/10.1016/j.artint.2015.07.0040004-3702/© 2015 Elsevier B.V. All rights reserved.130R. Rossi et al. / Artificial Intelligence 228 (2015) 129–152As shown in [3, Theorem 1], solving SCSPs is a computationally hard task. Even trivial instances with a dozen of decision and random variables require a computational effort out of reach even for the most advanced hardware/software combina-tion. This is due to the fact that the size of the policy tree grows exponentially in the number of random variables in the model and in the size of their support. Furthermore, a major limitation of all existing complete SCSPs solution methods, such as [3] and [4], is the fact that they assume the support of random variables is finite, otherwise a solution cannot be expressed as a finite policy tree. In practice, however, it is often the case that random variables either range over continu-ous supports or have a very large number (possibly infinite) of values in their domain. To date, no general purpose method exists for solving large-scale SCSPs, or SCSPs featuring random variables with continuous or discrete infinite support; for the sake of brevity we shall name this latter class of SCSPs “infinite SCSPs.”The main contribution of this paper is to propose a framework for solving large-scale or infinite SCSPs. More specifically, we argue that in solving large-scale or infinite SCSPs, one should not consider the ultimate feasible/optimal solution, which in some cases may even be impossible to represent; rather, the decision maker should aim for a solution that she “suffi-ciently trusts,” which she may claim to be optimal or feasible with a given confidence level, and for which a certain degree of error may be tolerated. In order to obtain such a solution, the decision maker should only look at a possibly limited number of samples drawn from the random variables in the model. In other words, she should try to “estimate” the quality of this solution.Our approach has several analogies with established techniques in statistics. When a survey is conducted on a sample population — e.g. an electoral poll — a statistician typically associates a certain confidence level with the results obtained from the chosen sample population. For instance, one may claim that there is a 90% chance that the actual mean being estimated is within a given interval. We argue that the very same approach may be adopted in stochastic decision making. If the infinite or large-scale m-stage SCSP does not admit any closed form solution and is complex enough to rule out any chance of obtaining an exact solution, we suggest that — as is done in statistics — one may introduce a confidence level α and a tolerated estimation error ±ϑ . The decision maker, instead of looking for an exact solution, may then aim to “estimate” — according to the chosen α and ϑ — whether the actual satisfaction probability guaranteed by an assignment is greater than or equal to the given target value for each of the chance constraints in the model. By choosing given values for α and ϑ the set of solutions may vary. For this reason we will introduce a new notion of solution that is parameterised by these two parameters and that we call an (α, ϑ)-solution. Intuitively, as α tends to 1 and ϑ tends to 0 the set of (α, ϑ)-solutions will converge to the set of actual solutions to the original stochastic constraint satisfaction problem, which we therefore rename (1, 0)-solutions. One should note that an approach of this kind has been recently advocated in [5, Chap. 4].In this work, we make the following contributions to the stochastic constraint programming literature:• we discuss how to obtain compact instances of infinite or large-scale stochastic constraint programs via sampling: we call these instances “sampled SCSPs;”• we introduce the concepts of (α, ϑ)-solution and of (α, ϑ)-solution set; and show how to compute a priori the mini-mum sample size that guarantees the attainment of such classes of solutions;• we show how the above tools can be employed in order to find approximate solutions to infinite or large-scale stochas-tic constraint satisfaction/optimisation problems that cannot be solved by existing exact approaches in the stochastic constraint programming literature;• we conduct a thorough computational study on three well-known stochastic combinatorial problems to validate our theoretical framework and assess its effectiveness, efficiency, and scalability.This work is structured as follows: in Section 2 we introduce the relevant formal background in constraint programming, stochastic constraint programming, and confidence interval analysis; in Section 3 we introduce sampled SCSPs; in Section 4we discuss properties of the solutions of sampled SCSPs and formally introduce (α, ϑ)-solutions; in Section 5 we introduce (α, ϑ)-solution sets; in Section 6 we extend our discussion to stochastic constraint optimisation problems; in Section 7 we discuss connections with established techniques in statistics; in Section 8 we present our computational study; in Section 9we discuss related works; finally, in Section 10 we draw conclusions and discuss future research directions.2. Formal backgroundWe now introduce the relevant background in constraint programming, stochastic constraint programming, and confi-dence interval analysis.2.1. Constraint programmingA Constraint Satisfaction Problem (CSP) [6] consists of a set of decision variables, each with a finite domain of values, and a set of constraints specifying allowed combinations of values for some variables. A solution to a CSP is an assignment of variables to values in their respective domains such that all of the constraints are satisfied. Constraint solvers typically explore partial assignments enforcing a local consistency property. A constraint c is generalised arc consistent (GAC) if and only if when a variable is assigned any of the values in its domain, there exist compatible values in the domains of all the R. Rossi et al. / Artificial Intelligence 228 (2015) 129–152131other variables of c. In order to enforce a local consistency property on a constraint c during search, we employ filtering algorithms that remove inconsistent values from the domains of the variables of c. These filtering algorithms are repeatedly called until no more values are pruned. This process is called constraint propagation.2.2. Stochastic constraint programmingThe following definitions are based on [4,7]. An m-stage stochastic constraint satisfaction problem (SCSP) [2] is a 7-tuple (cid:3)V , S, D, P , C, β, L(cid:4), where V is a set of decision variables and S is a set of random variables, D is a function mapping each element of V (respectively, S) to a domain (respectively, support) of potential values. In classical SCSPs both decision variable domains and random variable supports are assumed to be finite. P is a function mapping each element of S to a probability distribution for its associated support. To keep the discussion focused, without loss of generality, we assume that this probability distribution is not influenced by the decisions made; extensions to the SCP framework that deal with decision-dependent probabilities are discussed in [8]. C is a set of constraints over a non-empty subset of decision variables and a subset of random variables. If a constraint constrains only decision variables, then we call it a deterministic constraint; if it constrains both decision and random variables, then we call it a stochastic constraint. β is a function mapping each stochastic constraint h ∈ C to βh, which is a threshold value in the interval (0, 1]. If this threshold is strictly less than 1, then the stochastic constraint is a chance constraint. L = [(cid:3)V 1, S1(cid:4), . . . , (cid:3)V i, S i(cid:4), . . . , (cid:3)V m, Sm(cid:4)] is a list of decision stages such that each V i ⊆ V , each S i ⊆ S, the V i form a partition of V , and the S i form a partition of S.To solve an m-stage SCSP an assignment to the variables in V 1 must be found such that, given random values for S1, assignments can be found for V 2 such that, given random values for S2, . . ., assignments can be found for V m so that, given random values for Sm, the deterministic constraints are satisfied and the stochastic constraints are satisfied in the fraction of all possible scenarios specified by function β. Under the assumption that random variable supports are finite, the solution of an m-stage SCSP is, in general, represented by means of a policy tree [3]. The arcs in such a policy tree represent values observed for random variables whereas nodes at each level represent the decisions associated with the different stages. We call the policy tree of an m-stage SCSP that is a solution a satisfying policy tree.Let S denote the space of policy trees that are solutions to an SCSP. We may be interested in finding a policy tree s ∈ Sthat maximises the value of a given objective function f (·) over a subset of stochastic variables and a non-empty subset of decision variables. A stochastic constraint optimisation problem (SCOP) is then defined in general as maxs∈S f (s).In order to simplify the presentation, we assume without loss of generality, that each V i = {xi} and each S i = {si} are singleton sets. All the results can be easily extended in order to consider |V i | > 1 and |S i| > 1 (see [4]). Intuitively, if S i comprises more than one random variable, it is always possible to aggregate these variables into a single multivariate random variable [9] by convolving them. If V i comprises more than one decision variable, in the following discussion the term decision variable should be interpreted as a set of decision variables. Let S = {s1, s2, . . . , sm} be the set of all random variables and V = {x1, x2, . . . , xm} be the set of all decision variables.(cid:2)Let p be a path from the root node of the policy tree to a leaf. Let (cid:5) denote the set of all distinct paths of a policy tree. For each p ∈ (cid:5), we denote by arcs(p) the sequence of all the arcs in p whereas nodes(p) denotes the sequence of all nodes in p. We denote by (cid:6) = {arcs(p)|p ∈ (cid:5)} the set of all scenarios of the policy tree. The probability of ω ∈ (cid:6) is given i=1 Pr{si = ¯si|si−1 = ¯si−1, . . . , s1 = ¯s1}, where Pr{si = ¯si|si−1 = ¯si−1, . . . , s1 = ¯s1} is the probability that random by Pr{ω} =variable si takes value ¯si , given a set of realisations for random variables si−1, . . . , s1 already observed.Now consider a constraint h ∈ C with a specified threshold level βh. Consider a policy tree T for the SCSP and a path p ∈ T . Let h↓p be the deterministic constraint obtained by substituting the random variables in h with the corresponding values (¯si ) assigned to these random variables in arcs(p). Let ¯h↓p be the resulting tuple obtained by substituting the decision variables in h↓p by the values (¯xi ) assigned to the corresponding decision variables in nodes(p). We say that h is satisfied wrt to a given policy tree T iffm(cid:3)Pr{arcs(p)} ≥β h.p∈(cid:5):¯h↓p∈h↓pDefinition 1. Given an m-stage SCSP P and a policy tree T , T is a satisfying policy tree to P iff every constraint of P is satisfied wrt T .Example 1. Let us consider the two-stage SCSP in Fig. 2, whose stage structure is L = [(cid:3)V 1, S1(cid:4), (cid:3)V 2, S2(cid:4)]; V 1 = {x1} and S1 = {s1}, V 2 = {x2} and S2 = {s2}. Random variable s1 may take two possible values, 5 and 4, each with probability 0.5;random variable s2 may also take two possible values, 3 and 4, each with probability 0.5. The domain of x1 is {1, . . . , 4}, the domain of x2 is {3, . . . , 6}. There are two chance constraints2 in C , Pr{c1 : s1x1 + s2x2 ≥ 30} ≥ 0.75 and Pr{c2 : s2x1 =12} ≥ 0.5. In this case, the decision variable x1 must be set to a unique value before random variables are observed, while decision variable x2 takes a value that depends on the observed value of the random variable s1. A possible solution to 2 In what follows, for convenience, we denote a chance constraint by using the notation “Pr{(cid:3)cons(cid:4)} ≥ β”, meaning that constraint (cid:3)cons(cid:4), constraining decision and random variables, should be satisfied with probability greater than or equal to β.132R. Rossi et al. / Artificial Intelligence 228 (2015) 129–152Fig. 1. Policy tree for the SCSP in Example 1.Constraints:(1) Pr{s1x1 + s2x2 ≥ 30} ≥ 0.75(2) Pr{s2x1 = 12} ≥ 0.5Decision variables:x1 ∈ {1, 2, 3, 4}x2 ∈ {3, 4, 5, 6}Random variables:s1 ∈ {4(0.5), 5(0.5)}s1 ∈ {3(0.5), 4(0.5)}Stage structure:V 1 = {x1}, V 2 = {x2}L = [(cid:3)V 1, S1(cid:4), (cid:3)V 2, S2(cid:4)]S1 = {s1}, S2 = {s2}Fig. 2. The two-stage SCSP in Example 1.this SCSP is the satisfying policy tree shown in Fig. 1 in which x1 = 3, x12to decision variable x2, if random variable s1 takes value 5, and x2variable s1 takes value 4.= 4 and x22= 6, where x12 is the value assigned 2 is the value assigned to decision variable x2, if random As Example 1 shows, a solution to an SCSP is not simply an assignment of the decision variables to values, but it is instead a satisfying policy tree.It is worth noting that asking individual constraints to be satisfied according to their probability thresholds is different from asking a conjunction of constraints to be satisfied according to a prescribed probability threshold. Informally speaking, in Example 1we simply state that c1 : s1x1 + s2x2 ≥ 30 should hold true with probability β1 = 0.75, i.e. in at least 75% of the scenarios. If c2 : s2x1 = 12 holds true or not in those very same scenarios is not a matter of concern, as long as c2 holds true in at least 50% of the scenarios — not necessarily the same as those in which c1 holds true. Essentially, in Example 1 we do not state anything about the conjunction c3 : (s1x1 + s2x2 ≥ 30) ∧(s2x1 = 12). If we want to state something about this conjunction, we need to post a specific chance constraint c3 with its own satisfaction threshold β3. Assuming β3 = 0.5, we may for instance require the conjunction c3 to hold true in at least 50% of the scenarios, i.e. Pr{c3 : (s1x1 + s2x2 ≥ 30) ∧ (s2x1 = 12)} ≥ 0.5. Incidentally, the policy tree presented in Fig. 1 also satisfies this constraint.A practical example that further clarifies this discussion is found in inventory control. It is customary in inventory control problems to enforce service level constraints such asPr{It ≥ 0} ≥ αt = 1, . . . , Nwhere N represents the length of the planning horizon and It is the inventory level at the end of period t. The above set of constraints means that the probability of stocking out in a given period should be less than 1 − α; regardless what happens in other periods. A more restrictive service level requirement would beN(cid:4)Pr{t=1It ≥ 0} ≥ αThis latter restriction means that the probability of stocking out in at least one of the N periods should be less than 1 − α.R. Rossi et al. / Artificial Intelligence 228 (2015) 129–1521332.3. Confidence interval analysisConfidence interval analysis is a well established technique in statistics. Informally, confidence intervals are a useful tool for computing, from a given set of experimental results, a range of values that, with a certain confidence level (or confidence probability), will cover the actual value of a parameter that is being estimated. Consider a discrete random variable that follows a Bernoulli distribution. Accordingly, such a variable may produce only two outcomes, i.e. “yes” and “no”, with probability q and 1 − q, respectively. Let us assume that the value q — the “yes” probability — is unknown. Obviously, if we observe the outcome of a Bernoulli trial once, the data collected will not reveal much about the value of q. Nevertheless, in practice, we may be interested in “estimating” q, by repeatedly observing the behaviour of the random variable in a sequence of Bernoulli trials. This problem is well-known in statistics and both exact and approximate techniques are available for performing this estimation [10,11]. The estimation produced by the methods available in the literature typically does not come as a point estimate, rather it consists of an interval of values computed from a set of representative samples for the quantity being estimated. This interval is known as “confidence interval” and consists of a range of values that, with a certain confidence probability α, covers the actual value of the parameter that is being estimated.A method that is commonly classified as the “exact confidence intervals” for the Binomial distribution has been intro-duced by Clopper and Pearson in [10]. This method uses the Binomial cumulative distribution function (CDF) in order to build the interval from the data observed. The Clopper–Pearson interval is a symmetric two-sided confidence interval. It can be however also expressed as a single-sided interval. Clopper–Pearson single-sided intervals can be written as (plb, 1) and (0, pub) whereplb = min{q| Pr{bin(N; q) ≥ X} ≥ 1 − α},pub = max{q| Pr{bin(N; q) ≤ X} ≥ 1 − α},X is the number of successes (or “yes” events) observed in the sample, bin(N; q) is a binomial random variable with Ntrials and probability of success q and α is the confidence probability. Note that we assume plb = 0 when X = 0 and that pub = 1 when X = N.Because of the close relationship between Binomial distribution and the Beta distribution, the Clopper–Pearson interval is sometimes presented in an alternative format that uses percentiles from the beta distribution [12]:plb = 1 − betapub = 1 − beta−1(α, N − X + 1, X),−1(1 − α, N − X, X + 1),where beta−1 denotes the inverse Beta distribution. This form can be efficiently evaluated by existing algorithms.An interesting property of confidence intervals related to the estimation of the “success” probability associated with a Bernoulli trial consists in the fact that, given a confidence probability, it is possible to derive mathematically, by performing a worst case analysis, the minimum number of samples that should be observed in order to produce a confidence interval of a given size.Therefore, for a given confidence probability α, it is possible to determine the minimum number of samples that should be considered in order to achieve a margin of error of ±ϑ in the estimation of the “success” probability of a Bernoulli trial. This computation plays a central role in our novel approach. In fact, intuitively estimating the satisfaction probability of a chance constraint is equivalent to estimating the “success” probability of the associated Bernoulli trial.3. Sampled SCSPsConsider an SCSP P over a set S of stochastic variables. Assume that stochastic variables are defined on continuous supports or discrete supports comprising a large or infinite number of values. Solving the original SCSP clearly poses a hard combinatorial challenge, in fact the policy tree comprises a number of scenarios that is exponential in the size of stochastic variable domains. Since the policy tree may comprise an infinite number of scenarios, the computational problem may even be undecidable in general.In this section we discuss how to sample a more compact SCSP, which comprises at most N scenarios, out of the original problem. We shall call this new problem (cid:5)PN or “sampled SCSP” over N scenarios. Intuitively, a sampled SCSP is a reduced version of the original problem the solution of which is a policy tree that comprises a bounded number of paths sampled out of the original policy tree. In the following sections we will discuss under which conditions the solution to a sampled SCSP (cid:5)PN is, according to a certain confidence probability and within prescribed error tolerance thresholds, likely to be also a solution to the original SCSP P .We shall here discuss how to employ Simple Random Sampling [13] to obtain a sampled SCSP from the original prob-lem. Of course, more advanced stratified sampling techniques may be used in order to reduce variance and improve the effectiveness of the approach. Nevertheless, due to the large number of topics already covered in this work, we leave this discussion as future work.Consider a complete realisation, ¯s1, . . . , ¯sm, for the stochastic variables in S obtained by sampling a value from the support D(si) of each of the stochastic variables si ∈ S according to its probability distribution P (si). From the definition 134R. Rossi et al. / Artificial Intelligence 228 (2015) 129–152Fig. 3. Reduced policy tree for the sampled SCSP in Example 2; dashed arcs are those that have not been observed in the sample.of policy tree it is clear that there always exists a path associated with this realisation. In other words, this realisationcorresponds to one of the scenarios comprised in the policy tree.Generate N independent sets of random variable realisations{¯s11, . . . , ¯s1m}, {¯s21, . . . , ¯s2m}, . . . , {¯sN1 , . . . , ¯sNm},where ¯siis the realised value for random variable j observed in the i-th set of realisations. Recall that T denotes the jcomplete, and possibly infinite, policy tree for P . Let a reduced policy tree (cid:5)T for P be a policy tree that comprises only arc labellings observed in the former N complete realisations (without repetitions).Let (cid:5)(cid:5) denote the reduced set of distinct paths in (cid:5)T . The probability associated with each path p ∈ (cid:5)(cid:5), i.e. Pr{arcs(p)}, is simply set equal to the frequency of occurrence of such a path in the above N realisations. Of course, (cid:5)T represents a policy tree for a different SCSP than the one we started with. We call this new problem the sampled SCSP (cid:5)PN .Now consider a chance constraint h ∈ C with a specified threshold level βh, a policy tree (cid:5)T for the sampled SCSP (cid:5)PNand a path p ∈ T . We say that h is satisfied wrt to a given policy tree (cid:5)T iff(cid:3)Pr{arcs(p)} ≥β h.p∈(cid:5)(cid:5):¯h↓p∈h↓pExample 2. Let us consider the two-stage SCSP P discussed in Example 1. We set N = 3 and we derive a sampled SCSP (cid:5)PN . By using simple random sampling we draw the following three complete realisations for random variables in P :{¯s11= 4, ¯s22= 5, ¯s12= 5, ¯s32= 4}, {¯s21= 4}, {¯s31= 4}.A possible solution to the sampled SCSP (cid:5)PN is the satisfying policy tree shown in Fig. 3, in which x1 = 3, x1= 6, = 4 and x22where x12 is the value assigned to decision variable x2, if stochastic variable s1 takes value 5, and x22 is the value assigned to decision variable x2, if stochastic variable s1 takes value 4. The above policy tree has two paths sampled out of the original tree: p1 has an associated probability of 2/3, since we observed two occurrences of the scenario associated with this path over the 3 complete realisations sampled for the random variables; p2 has an associated probability of 1/3, since we observed a single occurrence of the scenario associated with this path over the 3 complete realisations sampled for the random variables. Paths that were not observed in the sampled realisations have an associated probability equal to zero and are not considered.2It should be noted that every policy tree (cid:5)T for a sampled SCSP (cid:5)P can be employed as a (partial) policy tree for the original SCSP P . Nevertheless, by sampling we lose completeness. If at stage i in P we observe, for a given random variable, a realised value that is not comprised in (cid:5)T , it will be of course impossible to determine the correct decisions for subsequent stages. By taking a conservative point of view, this means that all paths in the corresponding subtree will never be satisfied. In multi-stage SCSPs, and especially in those including random variables with continuous support, this prevents the direct use of the approach that will be discussed in this work. In fact, if random variable supports are continuous, there is only an infinitesimal probability of observing a given set of realisations. In this case, it is therefore essential to adopt a “rolling horizon” approach [14] in order to reduce the original multi-stage SCSPs to a sequence of multi-stage sampled SCSPs. Under this strategy, our aim is to fix decisions at stage one, and make sure that compatible values exist for decision variables that appear, for subsequent stages, in (cid:5)T . Future decisions are not fixed because, after observing the realised values for random variables at stage one, the problem is solved again by taking into account new available information; decision variables that were previously associated with stage two become stage one decisions. The original problem is thus reduced to a sequence of multi-stage sampled SCSPs. We will apply this technique to handle the two-stage problem discussed in Section 8.2: the stochastic multiprocessor scheduling problem with release time and deadlines.R. Rossi et al. / Artificial Intelligence 228 (2015) 129–1521354. (α, ϑ )-solutionsWe will now characterise the probability that the solution of a sampled SCSPs (cid:5)PN over N scenarios, which may be computed by using any of the existing approaches discussed in [3,4], is a solution to the original single-stage SCSP P .These results are also applicable to multi-stage problems, provided that a rolling horizon approach is adopted and that the aim is to characterise the probability that stage one decisions of a sampled SCSPs (cid:5)PN over N scenarios are consistent with respect to the original SCSP P .We will firstly discuss how to compute N such that, if a given policy tree T satisfies a chance constraint h in the sampled SCSPs (cid:5)PN , it also satisfies the same chance constraint in the original SCSP P with probability α. Since a policy tree T in (cid:5)PN by definition only comprises a subset (cid:5)(cid:5) of all the paths that constitute a policy tree for the original SCSP P , this policy tree, in order to satisfy h in the original SCSP P , must clearly provide a sufficient satisfaction probability regardless of the scenarios that have been ignored by the sampling process.Consider a confidence probability α and a margin of error of ±ϑ ; The number of scenarios N for the sampled SCSP depends on ϑ , α and also β, which we recall is the target satisfaction probability of chance constraint h.Definition 2. N is computed as the minimum value for which− β, β − pβlb) ≤ ϑ,max(pβubβlb and pwhere pround(β N) “successes” in N trials; round() approximates the value to the nearest integer.3βub are the single-sided Clopper–Pearson confidence interval bounds for a confidence probability α, and Definition 3. Any policy tree T , which can be proved to satisfy h in P with probability α, satisfies h in P with probability α if it satisfies h in (cid:5)PN . Conversely, any policy tree T , which can be proved not to satisfy h in P with probability α, does not satisfy h in P with probability α, if it does not satisfy h in (cid:5)PN .Proposition 1. A policy tree T can be proved to satisfy h in P with probability α if the actual satisfaction probability δ > β provided T can by T wrt h is such that δ ≥ pbe proved to not satisfy h in P with probability α.ub. Conversely, if the actual satisfaction probability δ < β provided by T wrt h is such that δ ≤ pβlbββub. Since pβub= max{q| Pr{bin(N; q) ≤ round(β N)} ≥ 1 − α, it is clear that Pr{bin(N; δ) ≤ round(β N)} < 1 − α. Proof. Let δ ≥ pThis means that⎧⎪⎨(cid:3)Pr⎪⎩p∈(cid:5)(cid:5):¯h↓p∈h↓pPr{arcs(p)} ≤ β⎫⎪⎬⎪⎭< 1 − α,where we recall that (cid:5)(cid:5) is the set of paths in the sampled SCSP (cid:5)PN . This implies⎫⎪⎬⎧⎪⎨(cid:3)Pr⎪⎩p∈(cid:5)(cid:5):¯h↓p∈h↓pPr{arcs(p)} ≥ β≥ α.⎪⎭Therefore, by using the test(cid:3)Pr{arcs(p)} ≥β,p∈(cid:5)(cid:5):¯h↓p∈h↓pa policy tree T can be proved to satisfy h in P with probability α.βlbConversely, let δ ≤ pβlb. Since p= min{q| Pr{bin(N; q) ≥ round(β N)} ≥ 1 − α, it is clear thatPr{bin(N; δ) ≥ round(β N)} < 1 − α.This means that⎧⎪⎨(cid:3)Pr⎪⎩p∈(cid:5)(cid:5):¯h↓p∈h↓pPr{arcs(p)} ≥ β⎫⎪⎬⎪⎭< 1 − α,3 This is justified by the fact that the Clopper–Pearson interval is, in fact, a step function — see [10], p. 405 — since the Binomial is a discrete probability distribution.136R. Rossi et al. / Artificial Intelligence 228 (2015) 129–152Fig. 4. Probability density function of the convolution of two independently non-identically distributed uniform random variables r1 and r2.which implies⎧⎪⎨(cid:3)Pr⎪⎩p∈(cid:5)(cid:5):¯h↓p∈h↓pPr{arcs(p)} ≤β⎫⎪⎬⎪⎭≥ α.Therefore, by using the test(cid:3)Pr{arcs(p)} ≤β,p∈(cid:5)(cid:5):¯h↓p∈h↓pa policy tree T can be proved to not satisfy h in P with probability α. (cid:2)Proposition 2. Any policy tree T which provides a satisfaction probability δ ≥ β + ϑ wrt h in P can be proved to satisfy h in P with probability α. Any policy tree T which provides a satisfaction probability δ ≤ β − ϑ wrt h in P can be proved to not satisfy h in Pwith probability α.Proof. This directly follows from Definition 2 and Proposition 1. (cid:2)Proposition 3. Any policy tree T which cannot be proved to satisfy or not to satisfy h in P with probability α, can be either proved to satisfy h in P with probability γ , where γ is a probability ranging in [0.5, α), if it satisfies h in (cid:5)PN , or not to satisfy h in P with probability γ , where γ is a probability ranging in [0.5, α), if it does not satisfies h in (cid:5)PN .Proof. Consider the two limiting cases. (i) The actual satisfaction probability δ provided by T wrt h in P is exactly equal to β. Since the sample mean, used to estimate the satisfaction probability out of the N samples considered, is an unbiased estimator of δ, it will overestimate β with probability 0.5 and, similarly, it will underestimate β with probability 0.5; this sets the lower bound for γ . (ii) The actual satisfaction probability δ provided by T wrt h in P is exactly equal to β + ϑ . From the proof of Proposition 1 it immediately follows that, in this case, γ = α, and also that, if δ < β + ϑ then γ < α; this sets the upper bound for γ . (cid:2)Definition 4. An (α, ϑ)-solution to an SCSP P is a policy tree (cid:5)T that at least with probability α provides for every chance constraint hi in P with satisfaction threshold βi a satisfaction probability greater than or equal to βi − ϑ .It is apparent that ϑ may be interpreted as a parameter that the user can set in order to define a “region of indifference”, i.e. β ± ϑ , for the satisfaction probability. In such a region, we assume that assignments can be safely misclassified with probability greater than α and that satisfaction probabilities remain in an acceptable range.Example 3. Consider the single-stage SCSP P = (cid:3)V , S, D, P , C, β, L(cid:4), where V = { X1, X2}, S = {r1, r2}, D( X1) = D( X2) ={0, 1}, D(r1) = (0, 100), P (r1) = uniform(0, 100), D(r2) = (0, 300), P (r2) = uniform(0, 300), C = {c : C1 ≥ X1r1 + X2r2}, βc = 0.5, and L = [(cid:3)V , S(cid:4)]. C1 = 185 is a constant. This problem comprises random variables defined on a continuous sup-port and it cannot be solved by existing complete approaches to SCSPs. If we set α = 0.95 and ϑ = 0.05, from Definition 2we compute the number of samples N = 290 required to guarantee that any solution to the sampled SCSP (cid:5)P over N samples is an (α, ϑ)-solution for P .Furthermore, the simple structure of the constraint c considered in P allows us to perform some further analysis. Con-sider the assignment X1 = 1 and X2 = 1. A simple reasoning on the convolution of two independently non-identically distributed uniform random variables (see [15]) immediately suggests that this assignment is indeed inconsistent. r1 and r2R. Rossi et al. / Artificial Intelligence 228 (2015) 129–152137Fig. 5. Feasible region for the SCSP in Example 1; the dashed line denotes the true boundary of constraint c. The upper solid line demarcates the set of solutions providing a satisfaction probability of at least β − ϑ ; the lower solid line demarcate the set of solutions providing a satisfaction probability of at least β + ϑ .are two independently non-identically distributed uniform random variables. The distribution that results from their convo-lution is shown in Fig. 4. This distribution is shaped like a trapezoid. Clearly, since the area for the whole figure must be equal to 1, the area of each of the two rectangle triangles at the side of the trapezoid must be equal to 1/6. Consequently, the area of the internal rectangle must be equal to 2/3. It is easy to see that the cumulative distribution function for value ∗(15/100) = 0.05, the 0.45 quantile of the inverse cumulative distribution 200 returns a probability of 0.5. Then, since 1/3function which results from convolving r1 and r2 is exactly equal to C1 = 185. Therefore, since the satisfaction probability provided by the assignment X1 = 1 and X2 = 1 is equal to βc − ϑ = 0.45 (Fig. 5), this assignment will be correctly classified as inconsistent with probability α, when the sample size is set to N = 290.Let h1, . . . , hk be k chance constraints in an SCSP P . Let (cid:5)P be a sampled SCSP over N samples, where N is the number of samples required to guarantee a confidence level α and an error tolerance threshold ϑ for each constraint hi considered independently, according to Definition 2.Proposition 4. Let (cid:5)T be a policy tree that is a solution to (cid:5)P. Then (cid:5)T is an (α, ϑ)-solution for P .Proof. Consider a chance constraint hi . Let βi be the respective satisfaction threshold. By definition, the probability that a solution (cid:5)T to (cid:5)P provides a service level less or equal to βi − ϑ for hi in P is less than or equal to 1 − α. Therefore (cid:5)T is an (α, ϑ)-solution. Now consider a pair of chance constraints (cid:3)hi, h j(cid:4) with satisfaction thresholds βi , β j , respectively. The probability pi j that a solution (cid:5)T to (cid:5)P provides a service level less or equal to βi − ϑ for hi and to β j − ϑ for h j in P is less than or equal to (1 − α)2, in fact we must misclassify both the constraints in order to accept such a solution. Even a single constraint correctly classified will make (cid:5)T inconsistent w.r.t. (cid:5)P . The case in which constraints are misclassified independently from each other represents a worst-case reasoning. If constraints are perfectly positively correlated, i.e. if one is misclassified then all other constraints are also misclassified, then pi j is (1 − α); if constraints are perfectly negatively correlated, i.e. if one is misclassified then no other constraint is misclassified, pi j becomes 0. This reasoning can be gener-alised to k chance constraints, for which the probability becomes (1 − α)k. Noting that (1 − α)k < . . . < (1 − α)2 < (1 − α)and that 1 − (1 − α)k ≥ α the probability 1 − α that a solution is misclassified in a model comprising a single constraint represents an upper bound for the probability that a solution (cid:5)T to (cid:5)P does not provide a satisfaction probability within the required tolerance threshold for one or more constraints in a generic model P . By rephrasing, the probability that a solution (cid:5)T provides a satisfaction probability greater than or equal to βi − ϑ for each constraint hi is greater than or equal to α. Hence, by Definition 4, (cid:5)T is an (α, ϑ)-solution for P . (cid:2)5. (α, ϑ )-solution setConsider policy tree T , chance constraint h, and the indicator random variable(cid:14)(cid:13)1p∈(cid:5)(cid:5):¯h↓p∈h↓pPr{arcs(p)} ≥β0 otherwiseτ =representing the test discussed in Definition 3. If the actual satisfaction probability δ provided by a policy tree T with respect to constraint h in P is exactly equal to β − ϑ , τ takes value 1 with probability 1 − α.To motivate the following discussion, we introduce the following example.138R. Rossi et al. / Artificial Intelligence 228 (2015) 129–152Example 4. Consider once more Example 3 and assume that D( X1) = D( X2) = (0, 5); i.e. decision variables are defined on continuous domains spanning from 0 to 5. Assignments ( X1 = 4.1, X2 = 0) and ( X1 = 0, X2 = 1.37) lie on the upper solid line shown in Fig. 5. Each of these two assignments provides a satisfaction probability of exactly β − ϑ with respect to constraint c in the original problem P . From the discussion in Section 4 it follows that each of these two assignments is recognised as infeasible with probability α if N = 290. However, since r1 and r1 are independent the probability that these two assignments are both recognised as infeasible is only α2. We next discuss how to address the issue of correctly classifying multiple policy trees according to a prescribed confidence level α.We introduce the following definition.Definition 5. An (α, ϑ)-solution set to an SCSP P is a set of policy trees. All policy trees in this set simultaneously provide, with probability at least α, a satisfaction probability greater than or equal to βi − ϑ for every chance constraint hi in Pwith satisfaction threshold βi .Consider an SCSP and T policy trees T1, . . . , TT for which the actual satisfaction probability δ with respect to h in Pis less than or equal to β − ϑ . Let τ1 . . . , τT be the associated random variables, each of which according to Proposition 4takes value 1 with probability less than or equal to 1 − α. Although we have fully characterised the marginal probability distribution of a test τi involving a single policy tree Ti , we have not characterised yet the joint probability among tests carried out on a set of T policy trees.Proposition 5. The probability that τ1, . . . , τT are all equal to 0 is at least 1 − T (1 − α).Proof. A worst-case reasoning can be carried out by considering the case in which events τi = 1 and τ j = 1 are mutually exclusive for all i, j = 1, . . . , T , i (cid:11)= j; of course it is still true that Pr{τi = 1} = Pr{τ j = 1} ≤ 1 − α. The probability that τ1, . . . , τT are all equal to 0 is then easily seen to be 1 − T (1 − α). If events are not mutually exclusive, this probability is greater than or equal to 1 − T (1 − α), e.g. in the case of T independent tests it would be 1 − (1 − α)T ≥ 1 − T (1 − α). (cid:2)Of course, it is not possible to know the value of T a priori, as this would require solving the SCSP. However, for a given chance constraint h, T is clearly less than or equal to the cardinality Ah of the assignment space constrained by h. Ah can be computed as the cartesian product of the domains of the decision variables in the policy tree that are constrained by h. Since the property discussed in Proposition 5 applies to each chance constraint h ∈ C , to compute an (α, ϑ)-solution set we may introduce the following Bonferroni’s correction [16], which is free of correlation and distribution assumptions, while computing N.Definition 6. N is computed as the minimum value for whichmax(pβub− β, β − pβlb) ≤ ϑ,where pub are the single-sided Clopper–Pearson confidence interval bounds for a confidence probability (cid:5)α, whereββlb and p(cid:5)α = 1 − 1 − α(cid:14)h∈C Ah,and round(β N) “successes” in N trials.Proposition 6. A set of policy trees that are solutions to (cid:5)P for a sample size N computed as discussed in Definition 6 is an (α, ϑ)-solution set for P .Proof. Bonferroni’s correction, introduced in Definition 6, ensures that, for every chance constraint h in C , the probability τ1, . . . , τT are all equal to 0 simultaneously is at least α. (cid:2)= βc2Example 5. Consider the following SCSP P = (cid:3)V , S, D, P , C, βc, L(cid:4), where V = { X1, X2}, S = {r1, r2}, D( X1) = D( X2) ={0, 0.01, 0.02, . . . , 24.99, 25}, D(r1) = (0, 10), P (r1) = uniform(0, 10), D(r2) = (0, 30), P (r2) = uniform(0, 30), D(r3) =(0, 15), P (r3) = uniform(0, 15), D(r4) = (0, 20), P (r2) = uniform(0, 20), C = {c1 : C1 ≥ X1r1 + X2r2, c2 : C2 ≥ X1r3 + X2r4}, = 0.7, and L = [(cid:3)V , S(cid:4)]. C1 = 245 and C2 = 215 are constants. We set α = 0.9 and ϑ = 0.05. We computed ana-βc1lytically the true boundaries of c1 and c2 (see [15,17]), each of which is denoted by a dashed line in Figs. 6 and 7. We also computed confidence bands around these two dashed lines. The upper confidence band is the set of solutions that provide a satisfaction probability of exactly βi − ϑ ; the lower confidence band is the set of solutions that provide a satisfaction probability of exactly βi + ϑ . We apply Definition 6 to compute the number of samples N = 2848 required to obtain an (α, ϑ)-solution set to P , which is shown in Fig. 6.R. Rossi et al. / Artificial Intelligence 228 (2015) 129–152139Fig. 6. An (α, ϑ)-solution set for Example 5 computed for N = 2848 samples.Fig. 7. An approximate (α, ϑ)-solution set for Example 6 computed for N = 348 samples.5.1. Approximating (α, ϑ )-solution setsBonferroni’s correction is known to be conservative. In particular, as we have seen, this correction assumes events τi = 1and τ j = 1 are mutually exclusive for all i, j = 1, . . . , T , i (cid:11)= j. In other words, we are assuming that assignment misclassi-fications are mutually exclusive. In practice, in an SCSP sets of assignments are often misclassified together depending on random variables realisations. For this reason a correction such as the one introduced in Definition 6 will generally be too conservative and will lead to a sample size much larger than the one strictly needed to obtain an (α, ϑ)-solution set. This fact is well known in statistics and a number of adjusted corrections have been proposed to account for correlated errors [see e.g. 18,19].In what follows, we shall therefore adopt a less conservative approximate correction strategy. To the best of our knowl-edge no similar correction has been discussed in the literature. In our computational study (Section 8) we will demonstrate the effectiveness of this technique. Of course, the investigation of other less conservative and possibly exact correction strategies, ideally borrowed from established results in statistics, is an interesting direction for future research.Consider the general case in which constraint h constrains all m random variables in S.Lemma 1. Given realisations {¯s11, . . . , ¯s2min the k-th set of realisations, τi is a deterministic test.1, . . . , ¯s1}, {¯s2m}, . . ., {¯sN1 , . . . , ¯sNm}, where ¯skj is the realised value for random variable j observed Proposition 7. τi is a function of random variables s1, . . . , sm and of N.Proof. Immediately follows from Lemma 1 and from the fact that s1j , . . . , sNj are N i.i.d. random variables. (cid:2)Proposition 8. The probability that at least one of τ1, . . . , τT takes value 1 is uniquely determined by the probability distributions of s1, . . . , sm and the number of samples N.Proof. Follows from the definition of τ , Lemma 1 and Proposition 7. (cid:2)140R. Rossi et al. / Artificial Intelligence 228 (2015) 129–152In practice, this means that assignment misclassifications in a sampled SCSP, e.g. events τi = 1 and τ j = 1, depend on re-alisations of one or more random variables s1, . . . , sm; note that m is generally much smaller than T . Since the multivariate random variable {τ1, . . . , τT } is a (deterministic) function of the multivariate random variable {s1, . . . , sm} and of N (Propo-sition 7), and since in the previous section we have fully characterised the marginal probability distribution of a test τi , the probability that τ1, . . . , τT are all equal to 0 is approximately bounded from below by 1 − m(1 − α); i.e. we correct for at most m mutually exclusive misclassifications induced by random variables s1, . . . , sm and we assume that all remaining misclassifications depend on one or more of these. Once more we introduce a correction for each chance constraint h ∈ C . Let mh be the number of random variables constrained by h, to compute an approximate (α, ϑ)-solution set we introduce the following correction while computing N.Definition 7. N is computed as the minimum value for whichmax(pβub− β, β − pβlb) ≤ ϑ,where pub are the single-sided Clopper–Pearson confidence interval bounds for a confidence probability (cid:5)α, whereββlb and p(cid:5)α = 1 − 1 − α(cid:14)h∈C mh,and round(β N) “successes” in N trials.A set of policy trees that are solutions to (cid:5)P for a sample size N computed as discussed in Definition 7 is an approximate (α, ϑ)-solution set for P .Example 6. Consider once more the SCSP in Example 5. We apply Definition 7 to compute the number of samples N = 348required to obtain an approximate (α, ϑ)-solution set to P , which is shown in Fig. 7; note that there are two constraints each of which constrains two random variables. To assess the quality of this approximation, we generated 1000 different instances and analytically inspected, for each of them, if the (α, ϑ)-solution set generated was fully contained within the upper confidence band in Fig. 7; the result of this simulation study revealed that the (α, ϑ)-solution set was not fully contained within the upper confidence band with probability 0.894, 0.95 confidence interval (0.873, 0.912); this misclassi-fication rate is in line with the prescribed α. Finally, it is worth noting that the random boundary of an (α, ϑ)-solution set remains within the channel identified by the two solid confidence bands with probability at least 1 − 2(1 − α).6. Stochastic constraint optimisation problemsThe concepts introduced in Sections 4 and 5 can be employed to approximate optimal solutions to sampled SCOPs. In this setting, we must distinguish two possible cases: the case in which the objective function is deterministic and that in which the objective function is stochastic. If the objective function is deterministic, it is possible to exploit the results in Section 5 to obtain a confidence interval for the cost/profit of an optimal plan. Without loss of generality, we discuss the case in which our aim is to maximise a deterministic objective function f of the decision variables in V . Consider an SCOP P = (cid:3)V , S, D, P , C, βc, L, f (cid:4). Choose α and ϑ and construct two new SCOPs: Plb = (cid:3)V , S, D, P , C, β 1c , L, f (cid:4), where for all c ∈ C , β 1c= βc + ϑ ; and Pub = (cid:3)V , S, D, P , C, β 2c , L, f (cid:4), where for all c ∈ C , β 2= βc − ϑ .cProposition 9. An (α, ϑ)-solution set to Plb underestimates the true optimal profit with probability greater or equal to α; an (α, ϑ)-solution set to Pub overestimates the true optimal profit with probability greater or equal to α.Proof. The proof follows from Definition 5. (cid:2)Proposition 9 can be exploited to generate a confidence interval for the true optimal profit via a binomial reasoning. We solve M independently generated instances of Plb and store the optimal profit obtained for each of these instances into an array Klb sorted in ascending order; we solve M independently generated instances of Pub and store the optimal profit −1(M, α) be the inverse cumulative obtained for each of these instances into an array K ub sorted in ascending order. Let bindistribution of a binomial distribution with M trials and a success probability α; let klb be the (1 − α)/2-quantile of this −1(M, 1 − α). With confidence α element at position klb of distribution; finally, let kub be the 1 − (1 − α)/2-quantile of binKlb is a lower bound and element at position kub + 1 of Kub is an upper bound to the true optimal cost.4Example 7. We transform the SCSP in Example 5 into two SCOPs Plb and Pub that maximise the objective function f ( X1, X2) = X1 + 2 X2. In other words, we assume the profit per unit of X1 is 1 and the profit per unit of X2 is 2. By 4 Elements of K i are indexed as follows: 1, . . . , |K i |. Note that in statistics the kth-smallest value of a statistical sample is known as kth order statistic [20].R. Rossi et al. / Artificial Intelligence 228 (2015) 129–152141Table 1Type I and Type II errors in statistics.Reject H0Fail to reject H0H0 is trueH0 is falseType I error(false positive)Correct outcome(true negative)Correct outcome(true positive)Type II error(false negative)choosing M = 20 we obtain the α confidence interval (282, 304) for the true optimal profit 293; if we reduce ϑ to 0.01 the interval shrinks considerably to (290, 295).If the objective function is stochastic there is no unique way to proceed. For instance, based on the available samples one may derive standard confidence intervals for the expected value of a stochastic expression based on the Student’s t distribution and then compare solutions or partial assignments by comparing upper or lower limits of these intervals. The decision maker must of course choose a suitable confidence level α associated with this estimation. An example of a filtering algorithm that may be employed in such context is discussed in Appendix A. This algorithm is designed to handle the situation in which the objective is to minimise/maximise the expected value of some expression involving decision and random variables. Different algorithms must be designed if the objective involves a different operator, e.g. variance. Our algorithm distinguishes the case in which we are trying to determine an upper or a lower bound for the expected cost of an optimal solution. It then exploits the sampling distribution (i.e. Student’s t distribution) of the expected total profit/cost and filters values based on upper/lower confidence limits obtained via this distribution. For instance, if our aim is to determine an upper bound for the optimal profit (problem type Pub), our algorithm will simply compare the upper confidence limits of the expected profit of two assignments and retain the assignment with the highest upper confidence limit. We will make use of this propagator to solve the models discussed in Section 8.Finally, one should note that an alternative strategy may instead compare not only the upper confidence limits, but the whole intervals. An assignment would then provide a lower/higher profit than another if and only if their profit confidence intervals do not overlap. However, due to the complexity of the filtering logic that would be required in this case, we prefer to leave this discussion as future work.7. Connections with statisticsTo better understand the concepts just introduced, it is worth discussing the connection between the approach intro-duced and hypothesis testing in statistical analysis. Let us assume that our null hypothesis (H 0), in statistical sense, is that an assignment is feasible. According to classical hypothesis testing we may have four cases, as illustrated in Table 1. We may have a feasible assignment at hand (H 0 true) and we may incorrectly filter it (Type I error); or we may be operating on an infeasible assignment (H0 false) and we may fail to reject it (Type II error).In clinical trials or quality control, it is key to control the rate of Type I errors. It is undesirable to put under treatment a healthy a patient or to discard a functioning expensive machine. However, there are cases in which controlling Type II errors is essential. For example, aerospace engineers would prefer to scrap a functioning electronic circuit than to use one that is actually broken on a spacecraft; in such a situation a Type I error raises the budget, but a Type II error would put at risk the entire mission. In general, minimising Type I and Type II errors is not a simple matter. If one tries to reduce the rate of occurrence for Type I errors, the direct consequence is typically an increase in the observed rate for Type II errors and vice-versa. So in practice, one tries to control either Type I or Type II errors and, if the rate of the type that is not controlled is too high, then one increases the sample size.In our specific case it is clearly essential to control the rate of Type II errors, which are more delicate than Type I errors. Making a Type II error means retaining an infeasible assignment, which is what we want to avoid as much as possible. Making a Type I error means discarding a feasible solution, which may impact optimality for an optimisation problem, or may lead to an empty solution space. Since our approach is essentially a heuristic, it is clear that both these issues — a poor solution quality or an empty solution space — are acceptable and should be dealt with by increasing the number of samples.8. Computational experienceThe aim of this section is to provide numerical insights on the theoretical framework introduced and particularly on the concept of (α, ϑ )-solution set and on its applications to find approximate solution to SCSPs and SCOPs. In our numerical study we will consider three well-known problems: the static stochastic knapsack (Section 8.1), the stochastic multiprocessor scheduling problem with release time and deadlines (Section 8.2), and the static stochastic lot-sizing problem (Section 8.3). The first and the third problems are single-stage, while the second is two-stage. In Section 8.4 we will generate approximate (α, ϑ )-solution sets using Definition 7 for the first two problems and show numerically that, with probability greater than or equal to α, the approach we discussed generates solution sets that satisfy chance constraints in the model with a margin of 142R. Rossi et al. / Artificial Intelligence 228 (2015) 129–152Constraints:(1) Pr{sk(2) Pr{sk1x1 + . . . + sk1x1 + . . . + skN xN ≤ C k} ≥ βN xN ≥ C k} ≥ βDecision variables:xi ∈ {0, . . . , D}Random variables:← Poisson(λki )skiStage structure:V 1 = {x1, . . . , xN }S1 = {s11, . . . , skL = [(cid:3)V 1, S1(cid:4)]n, . . . , sGN}k = 1, . . . , Lk = L + 1, . . . , Gi = 1, . . . , Ni = 1, . . . , N; k = 1, . . . , GFig. 8. The static stochastic multiple knapsack as an SCSP.error ϑ . In Section 8.5 we will numerically illustrate that the upper and lower profit/cost bounds obtained with the approach outlined in Section 6 comply with the prescribed confidence level α. We will also show the behaviour of the optimality gap as a function of the chosen error threshold ϑ and number M of independently generated instances of Plb and Pub. Finally, in Section 8.6 we will investigate computational efficiency and scalability. All our experiments were performed by using Choco [21] on an Intel Xeon(r) CPU @ 3.50 Ghz with 16 GB of RAM.8.1. Static stochastic knapsackThe knapsack problem [22] is a well-known combinatorial optimisation problem. The decision maker is given a set of objects each of which is associated with a weight and a profit. The aim is then to select a subset of these objects that fit into a given capacity and bring the maximum profit. There are several possible stochastic variants of the knapsack problem. Stochastic versions of the knapsack problem can be classified into static or dynamic. In the static stochastic knapsack problem, see e.g. [23], object weights and/or profits are random and the decision maker must choose, before observing any of their weights/profits, a subset of these objects that maximises a given objective, e.g. the expected profit, while meeting a restriction, e.g. a chance constraint, on the given capacity. Conversely, in the dynamic stochastic knapsack, see e.g. [24], the decision maker selects an object and immediately observes its weight and/or profit; based on this information she can then decide whether to select or not other objects.In our computational study we will consider the SCSP presented in Fig. 8, i.e. a static stochastic multiple knapsack (SSMKP). In this problem we have a set of N types of objects; there are D objects of type i available. Each object of type i is associated random “coefficients” ski that appear in the context of G chance constraints — this set of coefficients is generally denoted as stochastic technology matrix [25]; without loss of generality, these coefficients follow a Poisson distribution with mean λki .5 The first L of these chance constraints are of type (1), i.e. they can be seen as “capacity restrictions” with respect to a target capacity Ck, and they should be satisfied with probability β. In the context of the first L chance constraints skirepresents the “weight” of item i in chance constraint k. The remaining G–L chance constraints are of type (2), i.e. they can be seen as “minimum production requirements” with respect to a target level Ck , and again they should be satisfied with probability β. In the context of the remaining G–L chance constraints ski represents the “production contribution” of item iin chance constraint k.Our aim is to determine the feasible region of the problem, i.e. the set of assignments that satisfy constraints (1) and (2).We will also consider an optimisation version of the problem (Fig. 9) in which our aim is to determine what subset of the N objects in the problem maximises the expected total profit while satisfying all chance constraints. For each object i, we therefore introduce a random “profit” pi , which follows a Poisson distribution with mean πi ; once more the choice of the distribution is made without loss of generality.8.2. Stochastic multiprocessor scheduling problem with release time and deadlinesWe consider a multiprocessor scheduling problem (MPSP, see [27], p. 238). The problem consists in finding a feasible schedule to process a set of K orders (or jobs) using m processors, where m ≤ P . Processing an order k can only begin after the release date rk and must be completed at the latest by the due date dk . Order k requires a certain capacity ck— expressed in terms of the number of processors — to be processed. The processing time of order k is tk. The problem just described is well known in scheduling and it is fully deterministic and can easily and compactly be modelled using thecumulative constraint [28]. Let the height of a task k be ck. This constraint considers a set of tasks and enforces that at each point in time the total height of the set of tasks that overlap that point does not exceed a given limit m. A task k5 For a discussion on statistic stochastic knapsack problems with Poisson resource requirements see e.g. [26].R. Rossi et al. / Artificial Intelligence 228 (2015) 129–152143Objective:(1) max E[p1x1 + . . . + p N xN ]Constraints:(2) Pr{sk1x1 + . . . + skN xN ≤ C k} ≥ βDecision variables:xi ∈ {0, . . . , D}Random variables:← Poisson(λkski )ipi ← Poisson(πi )Stage structure:V 1 = {x1, . . . , xN }S1 = {s11, . . . , skL = [(cid:3)V 1, S1(cid:4)]n, . . . , sLN}k = 1, . . . , Li = 1, . . . , Ni = 1, . . . , N; k = 1, . . . , Li = 1, . . . , NFig. 9. The static stochastic multiple knapsack as an SCOP.Constraints:(1) Pr {cumulative(s, e, t, c, m)} ≥ βDecision variables:sk ∈ {rk, . . . , dk},ek ∈ {rk, . . . , dk},Stochastic variables:tk → Poisson(λk)Stage structure:V 1 = {s1, s2, . . . , sK }V 2 = {e1, e2, . . . , e K }L = [(cid:3)V 1, S1(cid:4), (cid:3)V 2, S2(cid:4)]S1 = {t1, t2 . . . , t K }S2 = {}∀k ∈ 1, . . . , K∀k ∈ 1, . . . , K∀k ∈ 1, . . . , KFig. 10. An SCSP for the stochastic multiprocessor scheduling problem with release time and deadlines.overlaps a point i if and only if its origin sk is less than or equal to i, and its end ek is strictly greater than i. This constraint also imposes, for each task k, the constraint sk+tk=ek.However, in reality, some parameters of this problem are uncertain in nature. Jobs may take longer than expected, some processors may break down and become unavailable, the release and due dates may be delayed, etc. In order to better model this problem a number of stochastic generalisations may be considered such as uncertain release date rk; uncertain due date dk; uncertain processing capacity ck; uncertain processing time tk; and uncertain number m of available processors; and every possible combination stemming from these cases.We will consider the following stochastic constraint programming formulation of the stochastic multiprocessor schedul-ing problem (SMPSP), in which only processing time tk for order k is uncertain; this is shown in Fig. 10. In this model, decision variables sk and ek denote the start time and the completion time of each job k, respectively. The processing time tk of each job k is modelled as a Poisson distributed random variable with mean λk . In contrast to the problem presented in Section 8.1, this model is a two-stage SCSP. In the first stage, we decide on the start time of each job then we observe the realisation of the processing time. In the second stage the completion times are decided. Under this stage structure, constraint (1) enforces that the probability of not exceeding the given deadline for each job and the number of available processors m stays above the specified threshold β. More specifically, this constraint is a global chance constraint embed-ding a well-known global constraint: the cumulative constraint [28]. This constraint can be filtered using the general purpose method discussed in [4].In our computational study we will also consider an optimisation version of the above problem in which we aim to minimise the latest start time.8.3. Static stochastic lot-sizingThe last problem we will consider in our computational study is the single-item stochastic lot-sizing problem introduced in [29]. A SCOP for this problem is shown in Fig. 11. The decision maker faces a finite horizon of T periods and a random demand dt in each period; which, without loss of generality, we will consider Poisson distributed with mean λt . There is a fixed cost a for placing an order of size 0 < Q t ≤ C in period t. An order placed in period t is delivered immediately at the beginning of the period, before demand occurs. Binary decision variable δt is set to zero if no order is placed (3). There 144R. Rossi et al. / Artificial Intelligence 228 (2015) 129–152Objective:(1) min E[(cid:14)Nt=1(aδt + h(cid:14)tj=1(Q t − dt ))]Constraints:(cid:14)(2) Pr{t(3) δt = 0 (cid:15)⇒ Q t = 0j=1(Q t − dt ) ≥ 0} ≥ βDecision variables:δt ∈ {0, 1}Q t ∈ {0, . . . , C}Random variables:dt ← Poisson(λt )Stage structure:V 1 = {Q 1, . . . , Q T , δ1, . . . , δT }S1 = {d1, . . . , dT }L = [(cid:3)V 1, S1(cid:4)]t = 1, . . . , Tt = 1, . . . , Tt = 1, . . . , Tt = 1, . . . , Tt = 1, . . . , TFig. 11. The stochastic lot-sizing problem in [29] as an SCOP (static uncertainty strategy).is a holding cost h charged on items that are carried over from one period to the next. Finally, the decision maker must comply with a service level restriction (2) stating that the net inventory at the end of each period should be nonnegative with probability at least β. The aim is to meet these service level restrictions while minimising the expected total cost (1).The authors in [29] describe a range of control policies that can be used to control such a system. In our study, we will adopt the static uncertainty policy, which fixes all Q t and δt at the beginning of the planning horizon, before demand is observed. Note that other strategies discussed in [29], i.e. dynamic uncertainty and static-dynamic uncertainty, can be easily captured by modifying the stage structure of the SCOP. In what follows, we shall refer to this problem as the static stochastic lot-sizing problem (SSLSP).8.4. FeasibilityIn Section 5 we introduced the notion of approximate (α, ϑ )-solution set. We will now present a computational analysis for the SCSPs presented in Sections 8.1 and 8.2 demonstrating that, with probability α, our approach generates solution sets that satisfy chance constraints in the model with a margin of error ϑ .We considered thirty randomly generated small instances of the single stage problem in Fig. 8 in which N = 2, L = 2, G = 3, D = 250 and β = 0.7. Means λki of random variables in the model were integer numbers uniformly distributed between 10 and 20 for constraints (1) and between 20 and 30 for constraints (2). Right hand side constants C k were integer numbers uniformly distributed between 1500 and 2000 for constraints (1) and between 2500 and 3000 for constraints (2). We fixed α = 0.9 and ϑ = 0.2; according to Definition 7 this choice led to a sample size of 31.We also considered thirty randomly generated small instances of the two stage problem in Fig. 10 in which K = 2 and β = 0.6; rk and dk, which represent job k release time and deadline, were set to 0 and 4, respectively. Capacity requirements ck were generated as integer numbers uniformly distributed between 1 and 2. Finally, expected task durations λk were generated as uniformly distributed numbers between 1 and 3; the maximum number of processors P was set to 3. We fixed α = 0.9 and ϑ = 0.35, this choice led to a sample size of 6.Instances were small since in our analysis we generated the complete set of feasible assignments of the respective sampled SCSP, i.e. an (α, ϑ)-solution set, which for the two-stage problem in Fig. 10 was generally extremely large, in the order of tens of thousands of solutions. Feasibility of each of these assignment with respect to the original SCSP was then assessed via Monte Carlo simulation; the number of simulation runs was set in such a way as to guarantee a margin of error of ϑ/10 with a confidence level of 0.9 — so that the Monte Carlo simulation error is an order of magnitude smaller than the approximation error associated with the (α, ϑ )-solution set obtained.To numerically investigate if those computed are effectively (α, ϑ)-solution sets, for each of the above sixty instances, we repeatedly solved 1000 sampled SCSPs and computed the frequency of event e: “all feasible assignments of the sampled SCSP are feasible with respect to the original SCSP within the given tolerance threshold ϑ .” In Fig. 12, for both problems and for each instance, we report the frequency of event e and the associated confidence intervals (confidence level of 0.95). These frequencies, are in line with the claim that those computed are (α, ϑ)-solution sets, for the given α = 0.9. Note that our aim is to control Type-II errors (an infeasible assignment regarded as feasible), and not Type-I errors (a discarded and yet feasible assignment); for this reason if the sampled SCSP admitted no solution, this was regarded as a degenerate case in which all feasible assignments (i.e. none) of the sampled SCSP were feasible with respect to the original SCSP within the given tolerance threshold ϑ . Finally, it is worth observing that some of the frequencies observed in Fig. 12 are strictly greater than the prescribed value α. This is due to the fact that only assignments providing a satisfaction probability of exactly β − ϑ are correctly classified as infeasible with probability α. However, given the discrete nature of the assignment space, it is likely that instances may not feature any such assignment. Assignments providing a satisfaction probability R. Rossi et al. / Artificial Intelligence 228 (2015) 129–152145Fig. 12. Frequency of event “all feasible assignments of the sampled SCSP are feasible with respect to the original SCSP within the given tolerance threshold ϑ ” over 1000 sampled SCSPs; together with the frequency, we report the associated confidence interval (confidence level of 0.95).strictly less than β − ϑ are correctly classified as infeasible with probability strictly greater than α. In addition to this, when a model features multiple chance constraints, Bonferroni’s correction, which is free of correlation and distribution assumptions, might generate a conservative — i.e. strictly larger than needed — sample size.8.5. OptimalityWe considered fifty randomly generated small instances of the problem in Fig. 9 (SSMKP) in which N = 10, L = 2, D = 1and β = 0.9. Means λki of random variables in the model were integer numbers uniformly distributed between 10 and 20 for constraints (1). Right hand side constants C k were integer numbers uniformly distributed between 100 and 200 for constraints (1). Means πi were all set to 10.We also considered fifty randomly generated small instances of the problem in Fig. 11 (SSLSP) in which T = 5, h = 1, i of Poisson demand in each period t = 1, . . . , T were integer numbers uniformly a = 10, C = 100, and β = 0.9. Means λtdistributed between 5 and 10.We fixed α = 0.9, ϑ = 0.05 and M = 10; recall that M is the number of independently generated instances of Plb and Pub used for computing profit/cost upper and lower bounds as illustrated in Section 6. This led to a sample size of 209 for the SSMKP and of 370 for the SSLSP (Definition 7).Due to the small size of the SSMKP instances, we managed to obtain optimal solutions by exhaustive enumeration, i.e. we generated all possible assignment and then checked feasibility and expected total profit of each of them via Monte Carlo simulation. The number of Monte Carlo runs was set to guarantee a margin of error of ϑ/10 with a confidence level of 0.9, in such a way as to ensure an approximation error negligible with respect to the chosen ϑ . SSLSP instances can be solved to optimality by using a deterministic equivalent mixed integer linear programming model [30]. In our analysis, we can therefore compare results obtained with our approach against the true optimal solutions.In Fig. 13, for each instance, we plotted upper and lower bound obtained for its optimal profit (SSMKP) or cost (SSLSP). For clarity, the interval has been normalised by using the profit/cost of the true optimal solution as a normalisation factor, so that value one in the graph denotes the true optimal profit/cost. The confidence level achieved by using our approach is generally higher than the prescribed α. In fact, despite α being set to 0.9, over the hundred instances analysed, the cost confidence interval did not cover the true optimal cost only in one case (SSMKP, instance 21). This is due to the conservative nature of our approach, as already discussed in Section 8.4.We believe the fluctuations in the size of optimality gaps observed in Fig. 13 for the SSMKP may be related to the fact that this problem features 0–1 integer variables. Depending on the specific instance being solved, different sets of samples may lead to assignments in which “high value” objects belonging to the true optimal solution of the problem are not selected. This may lead to larger optimality gaps than those observed for other instances in which the optimal solution is less sensitive to random fluctuations produced by the sampling process.Finally, we included in the analysis randomly generated instances of the SMPSP formulated as an SCOP in which the objective is to minimise the latest start time. In these instances K = 5 and β = 0.6; rk and dk, which represent job k release time and deadline, were all set to 0 and 20, respectively. Capacity requirements ck where generated as integer numbers uni-formly distributed between 1 and 3. Expected task durations λk were generated as uniformly distributed numbers between 1 and 5; the maximum number of processors P was set to 5.In Fig. 14 we analysed the behaviour of the optimality gap when α = 0.9, M = 10 and ϑ varies. The sample size ranges as follows: from 209 (ϑ = 0.05) to 5838 (ϑ = 0.01) for the SSMKP; from 370 (ϑ = 0.05) to 6350 (ϑ = 0.01) for the SSLSP; and from 14 (ϑ = 0.3) to 114 (ϑ = 0.1) for the SMPSP. For each value of ϑ considered, we solved 50 different instances of the SSMKP, SSLSP and SMPSP, and we computed the average optimality gap over this pool of instances. The average optimality gap for the SSMKP and the SSLSP is reported in percentage of the true optimal solution. For the case of the SMPSP unfortunately we were not able to compute the true optimal plan, therefore we reported the optimality gap in absolute terms; since we are minimising the latest start time, we expressed the optimality gap in expected number of 146R. Rossi et al. / Artificial Intelligence 228 (2015) 129–152Fig. 13. Normalised profit/cost upper and lower bounds for fifty SSMKP and SSLSP instances; a value of 1 denotes the true optimal profit/cost.Fig. 14. Average optimality gap for different values of ϑ .Fig. 15. Average optimality gap for different values of M.periods. Note that since α and ϑ are linked to the number of samples generated by the relation in Definition 7, similar plots may be obtained by varying α and keeping ϑ fixed.In Fig. 15 we carried out a similar analysis by keeping ϑ fixed to 0.05 (SSMKP, SSLSP) and to 0.3 (SSMKP) and by varying M.8.6. Computational efficiencyIn this section we reflect on the computational complexity and on the scalability of our approach.8.6.1. Computational complexityThe computational complexity of SCSPs has been discussed in several works [2–4]; in particular we direct the interested reader to [31,32], which provide comprehensive overviews on the complexity of stochastic programs.Multi-stage stochastic programming with discretely distributed decision-dependent random variables is PSPACE-hard [32]; the result follows from the PSPACE-hardness of the problem “decision-making under uncertainty” in [33]. SCSPs are PSPACE-complete in general if random variables are defined on discrete supports [3]. However, as pointed out in [32], R. Rossi et al. / Artificial Intelligence 228 (2015) 129–152147Table 2SSMKP. Larger instances comprising N = 20 objects.InstanceOptimality gap %Runtime (hours)12345678910Mean0.490.660.570.710.530.510.500.550.440.700.571.650.981.200.651.772.182.220.772.630.801.49Table 3SMPSP. Larger instances comprising K = 10 jobs.InstanceLatest start timeRuntime (hours)LB13141113171718131317UB1516121421192014142012345678910Mean1.500.680.723.200.313.279.080.430.1611.113.05the complexity of the “standard” multi-stage stochastic programming problem, in which distributions are independent of decisions taken in earlier stages, remains open; the authors in [32] conjecture that this is also PSPACE-hard.The advantage of sampled SCSPs over generic SCSPs is that sampled SCSPs always comprise a finite number of scenarios whose number is determined by Definition 7, which establishes a relationship among α, ϑ , and N. A decision maker is then free to fix a pair of these values and to derive the remaining one. In principle, one may fix a priori the number of samples N — rather than the confidence level α or the error threshold ϑ — and sacrifice precision for efficiency. This will not make the sampled SCSP fixed-parameter tractable in general — in [4] the authors proved that maintaining GAC on a global chance constraint can be intractable even when maintaining GAC on the corresponding deterministic version of that constraint is tractable — but it may reduce its complexity from PSPACE to NP-hard.8.6.2. ScalabilityTo illustrate the scalability of our approach with respect to other state-of-the-art approaches to SCSPs we employ, once more, the SSMKP. Note that this problem is similar to the one discussed in [4, Section 8.3]. In Section 9.4 of the same work, it was discussed that — for this class of problems — even when profits and weights of the objects are defined on a support that comprises only two values, a scenario-based formulation would end up comprising 220 scenarios and a solver such as Choco would run out of memory. It was then shown that the complete approach discussed in that work could solve an instance comprising 10 objects in about an hour on average.We fixed α = 0.9, ϑ = 0.01 and M = 10. We solved ten instances of the SSMKP randomly generated as discussed in Section 8.5, but now comprising N = 20 rather than ten objects; this led to a sample size of 6916. In Table 2 we report the optimality gap and the runtime for each of these instances as well as the runtime in hours.Finally, we fixed α = 0.9, ϑ = 0.1 and M = 10, and we solved larger instances of the SMPSP formulated as an SCOP. These instances comprise ten jobs (i.e. K = 10). rk and dk were now set to 0 and 30, respectively; this led to a sample size of 142. In Table 3 we report upper and lower bound for the latest start time associated with each of these instances, as well as and the runtime in hours.It is clear that it would be impossible to directly use the approach in [4] to model these SSMKP instances, as random variables follow a Poisson distribution and therefore have infinite values in their support. Even if one discretises these supports, e.g. by reducing them to only two values, the resulting SCSP would feature millions of scenarios.However, one may argue that, in the case of the SSMKP, we are analysing a problem that could be analysed by brute force. In other words, one may as well generate all 220 possible assignments for the decision variables and then analytically check the feasibility of each. Unfortunately, it is clear that this is not possible for the two-stage SMPSP just analysed, which features a much larger search space.148R. Rossi et al. / Artificial Intelligence 228 (2015) 129–152These results therefore demonstrate that the discussion in this work provides a viable means for scaling up the approach in [4].9. Related worksConfidence-based optimisation was originally introduced in [34]. In this work, the authors discuss an application of this methodology in the context of a well-known stochastic inventory control problem. Our work extends the discussion presented there to generic SCSPs and SCOPs by introducing a more general notion of confidence-based reasoning based on two novel concepts: (α, ϑ )-solutions and (α, ϑ )-solution sets. In the context of stochastic modelling and optimisation, as discussed, these tools can be employed to find approximate solutions that possess given statistical properties.9.1. Related works in stochastic programmingIn operations research, and particularly in stochastic programming, the state-of-the-art technique that applies sampling in combinatorial optimisation is the sample average approximation (SAA) method [23]. This is a Monte Carlo simulation-based approach to stochastic discrete optimisation problem. This method replaces the actual distribution of random variables in the combinatorial problem of interest by an empirical distribution obtained via sampling. The obtained “sample average optimisation problem” is then solved and the procedure is repeated multiple times until a given termination criterion is satisfied. The authors in [23] focus on stochastic programs with expected value objectives and discuss convergence rate and stopping rules. In [35] the authors extend their analysis to two-stage stochastic programs with integer recourse; for this latter class of problems [36] carry out a post-hoc computationally intensive analysis of the quality of solutions obtained via SAA. Extensions to problems with expected value constraints, e.g. conditional value-at-risk constraints, were discussed in [37]. However, none of these works investigated the case in which the problem of interest include chance constraints. As [38] remarks, there are formulations of stochastic programming problems that incorporate expectations of penalised constraints in the objective function as a penalty terms. These problems can be solved efficiently since they simply require continuous variables for modelling penalties and they do not require any additional binary variable. However, this modelling approach does not address the issue of finding or approximating feasible or optimal solutions to a chance constrained problem [39, p. 950].SAA methods for problems comprising a single chance constraint were discussed in [40–42]. In [40] the authors sum-marise convergence properties (Section 2.1) and post-hoc solution validation strategies (Section 2.2). They remark that “based on this [convergence] analysis, we can compute a priori the sample size required in the SAA problem so that it produces a feasible solution to the true problem with high probability (typically such estimates of a required sample size are quite conservative).” The convergence analysis the authors refer to was originally conducted in [41] and it shows asymptotical convergence properties based on inequalities such as Chernoff’s [43] or Hoeffding’s [44], which are known to be conservative bounds. Their analysis is conducted under the assumption that the feasible region is finite, since the sample size determined via the aforementioned convergence properties grows linearly in the size of the feasible region [41, p. 683]. Extensions of the analysis in [41] to the case of multiple chance constraints were illustrated in [38]. This latter work is similar to those just discussed, since once more the analysis is based on the above inequalities and the sample size depends on the size of the feasible region. More recently, [45] investigated the relations between chance constrained and penalty function problems under discrete distributions. This analysis extended a number of previous works that analysed this relation under continuous distribution. However, the authors explicitly remark that “our goal is not to show that the penalty problems are able to generate optimal values and solutions of chance constrained problems.” Instead they compare the problems with focus on asymptotic equivalence of optimal values and corresponding convergence of optimal solutions.After surveying the existing literature on SAA, the first important remark is that in none of the above works can we find concepts that resemble those of (α, ϑ )-solution and (α, ϑ )-solution set, which are unique to confidence-based reason-ing [34]. This is a subtle conceptual difference that should not be overlooked. The aim of SAA is to find an assignment that, with prescribed confidence probability α, is a solution to the original problem; see e.g. [42, Section 3.1]. In other words, in SAA the decision maker does not fix any a priori tolerated estimation error ϑ . To ensure that the solution of the sampled problem is feasible with respect to the original problem with sufficiently high probability, in SAA the threshold β associated with chance constraints in the sampled problem is increased by a factor ϑ , which however is not explicitly interpreted as an error tolerance threshold in a statistical sense, although in practice it is used as such. In [42, p. 407], the authors point out that, for a fixed α and for a given threshold β, “it is not clear what the best choices for the sample size and ϑ are,” since they believe this is a problem-dependent issue that should be addressed numerically. This statement demonstrates the aforementioned fundamental difference. By introducing the two concepts of (α, ϑ )-solution and (α, ϑ )-solution set, we suggest that a decision maker may — in line with established practices in statistics — interpret ϑ as an error tolerance threshold and fix a priori, together with the confidence level α, either the sample size (on the basis of the available ob-servations) or ϑ (on the basis of the estimation error that can be tolerated); finally, the parameter that has not been fixed should be derived via the analysis we presented. In summary, the difference lies in the interpretation. Confidence-based reasoning aims to find a solution that, with confidence α, satisfies the chance constraints in the original problem within the given error tolerance ϑ . In addition to this important semantic difference, we should mention that our analysis is based on R. Rossi et al. / Artificial Intelligence 228 (2015) 129–152149the exact Clopper–Pearson confidence interval, and not on conservative bounds such as Chernoff’s or Hoeffding’s inequali-ties. Finally, our approximation strategy for (α, ϑ )-solution sets leads to a sample size (Definition 7) that is independent of the number of assignments in the feasible region; a major difference from all other methods surveyed so far.To contrast our approach with respect to other existing state-of-the-art approaches, one may consider the stochastic vehicle routing problem with time windows discussed in [38, Section 4]. It is possible to apply our analysis to the instances discussed in [38, Table 1], by converting the parameters used in SAA and setting the confidence level α = 0.99, the error threshold ϑ = 0.05 and the chance constraint thresholds β = 0.95. For the instances with 10 customer orders, the sample size prescribed by our approach is 429 for the model with a single chance constraint and 490 for the model with three chance constraints. For the instances with 50 customer orders, the sample size prescribed by our approach is 608 for the model with a single chance constraint and 669 for the model with three chance constraints. Not only are these sample sizes orders of magnitude smaller than the ones suggested in [38], which range from 200 thousand up to 32 million; but most importantly they do not depend on the number of vessels used or the size of the time windows; in fact, according to Definition 7, they only depend on the number of random variables and chance constraints in the model. Of course, as the authors in [38] remark, finding an exact solution to a scenario-based model with 32 million scenarios is unrealistic. For this reason, they suggest to adopt heuristic solution methods, e.g. tabu search. As demonstrated in our computational study, our approximate (α, ϑ )-solution sets represent a viable alternative to the use of heuristics on instances featuring very large sample sizes.9.2. Related works in constraint programmingA detailed discussion on hybrid CP/AI/OR approaches for decision making under uncertainty can be found in [46,47]. We direct the reader to these two references for further details on existing works in this research area. We next briefly survey key relevant references. Efforts that try to extend classical CSP framework to incorporate uncertainty have been influenced by works that originated in different fields, namely chance-constrained programming [48] and stochastic programming [49]. To the best of our knowledge the first work that tries to create a bridge between Stochastic Programming and Constraint Pro-gramming is by Benoist et al. [50]. Search and consistency strategies, namely a backtracking algorithm, a forward checking procedure [2] and an arc-consistency [51] algorithm have been proposed for SCSPs. A scenario-based approach for building up constraint programming models of SCSPs was proposed by Tarim et al. [3]. In the same work a fully featured language — Stochastic OPL — for modelling SCSPs was also proposed. In [52] the authors introduce new algorithms for solving multi-objective stochastic problems are proposed. Global chance constraints were introduced first in [53], and bring together the reasoning power of global constraints from CP and the expressive power of chance constraints from SP. A general purpose approach for filtering global chance constraints is proposed in [4,7]. This approach is able to reuse existing propagators available for the respective deterministic global constraint which corresponds to a given global chance constraint when all the random variables are replaced by constant parameters. In [54] the authors discuss some possible strategies to perform cost-based filtering for certain classes of SCOPs. These strategies exploit well-known inequalities borrowed from SP and used to compute valid bounds for any given SCOP that respects some mild assumptions. Unfortunately, the above approaches op-erate under the assumption that the number of scenarios must be finite, otherwise a solution cannot be expressed as a finite number of possible decisions. Furthermore, these approaches do not scale well. Even problems having a limited num-ber of stochastic variables with large support immediately produce policy trees whose size makes impractical the use of a complete method. In [3] the authors employed sampling in order to reduce the number of scenarios considered for a given stochastic constraint program and produce a solution in reasonable time. Nevertheless, this approach does not provide any optimality/feasibility guarantee for the solution produced. Heuristic approaches such as the one in [55], in which a neural network is employed in order to encode a policy function, suffer from the same limitation and from lack of modularity. Stochastic sampling in the context of Stochastic Boolean Satisfiability was discussed in [56]; forward sampling [50] and sample aggregation [57] are two other techniques that have been employed to solve SCSPs. Nevertheless, none of these approaches introduce a concept that resembles that of (α, ϑ )-solution. Probably, the work discussed in [58] represents the closest attempt to provide some sort of guarantees for a stochastic constraint satisfaction problem. Nevertheless, this work is focused on a specific problem — a two-stage stochastic matching problem — and it does not propose a generic approach for solving SCSPs. Finally, another closely related work is [59], which discusses sample-based approaches to job shop scheduling with probabilistic durations; however, like in the previous case, the approach proposed is focused on a specific problem and not on solving generic SCSPs.10. ConclusionsWe proposed a framework for exploiting sampling in order to solve SCSPs that include random variables over a continu-ous or very large discrete support. Our framework is based on a number of novel concepts: sampled SCSPs, (α, ϑ)-solutions and (α, ϑ)-solution sets. We employed statistical estimation to determine if a given assignment is consistent with respect to a given set of chance constraints. As in statistical estimation, the quality of our estimate is determined via confidence interval analysis.In contrast to existing approaches based on sampling, we provide likelihood guarantees for the quality of the solutions found. In fact, we explicitly state a confidence probability α that bounds the probability of exceeding a given error tolerance 150R. Rossi et al. / Artificial Intelligence 228 (2015) 129–152threshold ϑ in our estimation. By properly choosing the estimation error ϑ and the confidence probability α it is possible to generate compact sampled SCSPs that can be effectively solved by existing solution methods. We also extended the reasoning to SCOPs and demonstrated how to produce statistical upper and lower bounds for the value of the optimal solution.We demonstrated our approach on a number of SCSPs and SCOPs: the static stochastic knapsack problem, a stochastic multiprocessor scheduling problem, and a stochastic lot-sizing problem. Our computational study demonstrates the effec-tiveness of our approach.We conclude by briefly discussing a number of suggestions for future work.Online stochastic optimisation A promising direction is that of exploring synergies with online stochastic optimisation [50]. In particular, we suspect that our approach may be used to enhance the results in [57,60–62] by ensuring a better control of the solution quality obtained at each step of the online process.Sampling strategies A key open issue is related to the fact that simple random sampling [63] is a relatively naive strategy for selecting samples. The use of more refined sampling strategies — for instance a stratified sampling technique such as Latin Hypercube Sampling [64] — may of course reduce the number of samples required to produce an (α, ϑ )-solution. Nevertheless, further research is required in order to clarify how stratified sampling can be effectively employed in this context.Confidence intervals The Clopper–Pearson interval is an exact interval since it is based directly on the binomial distribution rather than any approximation to the binomial distribution. This interval, however, can be conservative because of the discrete nature of the binomial distribution, as pointed out by Neyman [65]. For example, the true coverage rate of a 95% Clopper–Pearson interval may be well above 95%, depending on n and q. Thus the interval may be wider than it needs to be to achieve 95% confidence. In contrast, it is worth noting that other approximate confidence bounds may be narrower than their nominal confidence width, i.e., the “normal approximation interval,” also known as Wald confidence interval, the Wilson Interval, the Agresti–Coull Interval, etc, may in fact achieve a confidence level that is lower than the nominal one [11]. Future research may investigate the application of approximate intervals in the context of sample-based constraint solving. The performance of each of these approximate intervals have been thoroughly analysed in the existing body of literature. The advantage is that approximate intervals may lead to smaller sample sets and therefore to more compact sampled SCSPs.Computational complexity Finally, an interesting computational complexity questions remains open about the complexity of the standard multi-stage stochastic constraint programs.AcknowledgementsThe authors would like to thank the Associate Editor and the anonymous reviewers for commenting on our drafts and providing insightful remarks.Appendix A. Filtering strategy for constraint expressions involving expected valuesWe discuss a filtering strategy for handling constraint expressions involving expected values in sampled SCSPs. This filtering strategy can be employed, in concert with the approach discussed in Section 6, to deal with the case in which the objective function is stochastic. Consider a constraint x = E[(cid:3)exp(cid:4)], where E[] denotes the expectation operator and x is a real valued decision variable, whose domain is stored as an interval with real valued upper and lower bounds. Techniques for handling propagation and search involving real valued decision variables are discussed in [66]. A filtering algorithm that enforces bounds consistency on this constraint is shown in Algorithm 1. It should be noted that the approach discussed in Section 6 distinguishes two cases: the one in which our aim is to underestimates the true optimal profit (SCOP Plb) and that in which our aim is to overestimates the true optimal profit (SCOP Pub). The type of problem (Plb or Pub) which the propagator belongs to must be specified as an input parameter “type” that influences propagation. The algorithm constructs two arrays: U and L. U lists, for each scenario, an upper bound for the expected value of (cid:3)exp(cid:4), L lists, for each scenario, a lower bound for the expected value of (cid:3)exp(cid:4). Then it exploits the Student’s t distribution with |(cid:5)| − 1 degrees of freedom (StudentT(|(cid:5)| − 1)) to determine upper and lower confidence limits for the expected value of (cid:3)exp(cid:4) at the prescribed −1confidence level α. Note that CDF(α) denotes the inverse cumulative distribution function of t; mean( X) and std( X)tdenote the mean and the standard deviation of the elements in X , respectively. The algorithm operates by exploiting the structure (cid:5) of the policy tree; therefore it takes implicitly into account the stage structure of the problem while computing the expected value of a given expression and it will correctly evaluate expected values both in a single or multi-stage case. Finally, it is worth remarking that this constraint is closely related to the Student’s t test constraint discussed in [67].R. Rossi et al. / Artificial Intelligence 228 (2015) 129–152151Algorithm 1: Filtering expected values in sampled SCSPs.type; (cid:3)exp(cid:4); T ; x; α.input :output: Bound consistent x.beginU ← {}; L ← {};for each p ∈ (cid:5) doU ← U ∪ Sup((cid:3)exp(cid:4)↓p );L ← L ∪ Inf((cid:3)exp(cid:4)↓p );t ← StudentT(|(cid:5)| − 1);if type = Plb then−1(1 − (1 − α)/2) · std(U )/Sup(x) ← mean(U ) − CDF√t−1(1 − (1 − α)/2) · std(L)/Inf(x) ← mean(L) − CDFtelse if type=Pub then−1(1 − (1 − α)/2) · std(U )/Sup(x) ← mean(U ) + CDF√t−1(1 − (1 − α)/2) · std(L)/Inf(x) ← mean(L) + CDFt√|(cid:5)|;|(cid:5)|;√|(cid:5)|;|(cid:5)|;References(2001) 17–41.[1] R. Rossi, B. Hnich, S.A. Tarim, S. Prestwich, Finding (α, ϑ )-solutions via sampled SCSP, in: T. Walsh (Ed.), Proceedings of the 22nd International Joint Conference on Artificial Intelligence, IJCAI 2011, July 16–22, Barcelona, Spain, AAAI Press, 2011, pp. 2172–2177.[2] T. Walsh, Stochastic constraint programming, in: F. van Harmelen (Ed.), European Conference on Artificial Intelligence, Proceedings, ECAI’2002, IOS Press, 2002, pp. 111–115.[3] S.A. Tarim, S. Manandhar, T. Walsh, Stochastic constraint programming: a scenario-based approach, Constraints 11 (2006) 53–80.[4] B. Hnich, R. Rossi, S.A. Tarim, S. Prestwich, Filtering algorithms for global chance constraints, Artif. Intell. 189 (2012) 69–94.[5] D. Costantini, Verso una rappresentazione probabilistica del mondo, Maria Margherita Bulgarini, Firenze, 2014.[6] F. Rossi, P. van Beek, T. Walsh, Handbook of Constraint Programming (Foundations of Artificial Intelligence), Elsevier Science Inc., New York, NY, USA, 2006.[7] B. Hnich, R. Rossi, S.A. Tarim, S.D. Prestwich, Synthesizing filtering algorithms for global chance-constraints, in: I.P. Gent (Ed.), 15th International Conference on Principles and Practice of Constraint Programming, Proceedings, CP 2009, Lisbon, Portugal, September 20–24, 2009, in: Lect. Notes Comput. Sci., vol. 5732, Springer, 2009, pp. 439–453.[8] S.D. Prestwich, S.A. Tarim, R. Rossi, B. Hnich, Hybrid metaheuristics for stochastic constraint programming, Constraints 20 (2015) 57–76.[9] H. Jeffreys, Theory of Probability, Clarendon Press, Oxford, UK, 1961.[10] C.J. Clopper, E.S. Pearson, The use of confidence or fiducial limits illustrated in the case of the binomial, Biometrika 26 (1934) 404–413.[11] A. Agresti, B.A. Coull, Approximate is better than “exact” for interval estimation of binomial proportions, Am. Stat. 52 (1998) 119–126.[12] M. Evans, N. Hastings, B. Peacock, Statistical Distributions, Wiley, New York, 2000.[13] I.C.G. Upton, Oxford Dictionary of Statistics, Oxford University Press, Oxford, UK, 2002.[14] S. Sethi, G. Sorger, A theory of rolling horizon decision making, Ann. Oper. Res. 29 (1991) 387–416.[15] S. Sadooghi-Alvandi, A. Nematollahi, R. Habibi, On the distribution of the sum of independent uniform random variables, Stat. Pap. 50 (2009) 171–175.[16] R.G. Miller, Simultaneous Statistical Inference, Springer-Verlag Berlin and Heidelberg GmbH & Co. K, 1981.[17] F. Killmann, E. von Collani, A note on the convolution of the uniform and related distributions and their use in quality control, Econ. Qual. Control 16 [18] E.L. Lehmann, J.P. Romano, Generalizations of the familywise error rate, Ann. Stat. 33 (2005) 1138–1154.[19] C.E. Smith, R.A. Cribbie, Multiplicity control in structural equation modeling: incorporating parameter dependencies, Struct. Equ. Model. 20 (2013) 79–85.[20] H.A. David, H.N. Nagaraja, Order Statistics, 3rd ed., Wiley-Interscience, 2003.[21] F. Laburthe, the OCRE project team, Choco: implementing a CP kernel, Technical report, Bouygues e-Lab, France, 1994.[22] S. Martello, P. Toth, Knapsack Problems: Algorithms and Computer Implementations, John Wiley & Sons, Inc., New York, NY, USA, 1990.[23] A.J. Kleywegt, A. Shapiro, T. Homem-De-Mello, The sample average approximation method for stochastic discrete optimization, SIAM J. Optim. 12 (2001) 479–502.[24] A.J. Kleywegt, J.D. Papastavrou, The dynamic and stochastic knapsack problem, Oper. Res. 46 (1998) 17–35.[25] P. Kall, J. Mayer, Stochastic Linear Programming: Models, Theory and Computation, 2nd ed., Internat. Ser. Oper. Res. Management Sci., Springer, 2011.[26] S. A˘gralı, J. Geunes, A single-resource allocation problem with Poisson resource requirements, Optim. Lett. 3 (2009) 559–571.[27] M.R. Garey, D.S. Johnson, Computers and Intractability: A Guide to the Theory of NP-Completeness, W.H. Freeman, 1979.[28] A. Aggoun, N. Beldiceanu, Extending chip in order to solve complex scheduling and placement problems, Math. Comput. Model. 17 (1993) 57–73.[29] J.H. Bookbinder, J.Y. Tan, Strategies for the probabilistic lot-sizing problem with service-level constraints, Manag. Sci. 34 (1988) 1096–1108.[30] V. Vargas, An optimal solution for the stochastic version of the Wagner–Whitin dynamic lot-size model, Eur. J. Oper. Res. 198 (2009) 447–451.[31] H.B. Hunt, M.V. Marathe, R.E. Stearns, Complexity and approximability of quantified and stochastic constraint satisfaction problems, Electron. Notes Discrete Math. 9 (2001) 217–230.[32] M. Dyer, L. Stougie, Computational complexity of stochastic programming problems, Math. Program. 106 (2006) 423–432.[33] C.H. Papadimitriou, Games against nature, J. Comput. Syst. Sci. 31 (1985) 288–301.[34] R. Rossi, S. Prestwich, S.A. Tarim, B. Hnich, Confidence-based optimisation for the newsvendor problem under binomial, Poisson and exponential demand, Eur. J. Oper. Res. 239 (2014) 674–684.[35] S. Ahmed, A. Shapiro, E. Shapiro, The sample average approximation method for stochastic programs with integer recourse, SIAM J. Optim. 12 (2002) [36] J. Linderoth, A. Shapiro, S. Wright, The empirical behavior of sampling methods for stochastic programming, Ann. Oper. Res. 142 (2006) 215–241.[37] W. Wang, S. Ahmed, Sample average approximation of expected value constrained stochastic programs, Oper. Res. Lett. 36 (2008) 515–519.[38] M. Branda, Sample approximation technique for mixed-integer stochastic programming problems with several chance constraints, Oper. Res. Lett. 40 479–502.(2012) 207–211.[39] M. Branda, Stochastic programming problems with generalized integrated chance constraints, Optimization 61 (2012) 949–968.(2008) 490–517.152R. Rossi et al. / Artificial Intelligence 228 (2015) 129–152[40] S. Ahmed, A. Shapiro, Solving chance-constrained stochastic programs via sampling and integer programming, in: Z.-L. Chen, S. Raghavan (Eds.), Tuto-rials in Operations Research, INFORMS, 2008, pp. 261–269.[41] J. Luedtke, S. Ahmed, A sample approximation approach for optimization with probabilistic constraints, SIAM J. Optim. 19 (2008) 674–699.[42] B.K. Pagnoncelli, S. Ahmed, A. Shapiro, Sample average approximation method for chance constrained programming: theory and applications, J. Optim. Theory Appl. 142 (2009) 399–416.[43] H. Chernoff, A measure of asymptotic efficiency for tests of a hypothesis based on the sum of observations, Ann. Math. Stat. 23 (1952).[44] W. Hoeffding, Probability inequalities for sums of bounded random variables, J. Am. Stat. Assoc. 58 (1963) 13–30.[45] M. Branda, On relations between chance constrained and penalty function problems under discrete distributions, Math. Methods Oper. Res. 77 (2013) 265–277.pp. 729–753 (Chapter 21).[46] K.N. Brown, I. Miguel, Uncertainty and change, in: F. Rossi, P. van Beek, T. Walsh (Eds.), Handbook of Constraint Programming, Elsevier, 2006, [47] B. Hnich, R. Rossi, S.A. Tarim, S. Prestwich, A survey on CP-AI-OR hybrids for decision making under uncertainty, in: P. van Hentenryck, M. Milano (Eds.), Hybrid Optimization, in: Springer Optim. Appl., vol. 45, Springer New York, New York, NY, 2011, pp. 227–270.[48] A. Charnes, W.W. Cooper, Deterministic equivalents for optimizing and satisficing under chance constraints, Oper. Res. 11 (1963) 18–39.[49] J.R. Birge, F. Louveaux, Introduction to Stochastic Programming, Springer Verlag, New York, 1997.[50] T. Benoist, E. Bourreau, Y. Caseau, B. Rottembourg, Towards stochastic constraint programming: a study of online multi-choice knapsack with deadlines, in: T. Walsh (Ed.), Principles and Practice of Constraint Programming, Proceedings, CP 2001, in: Lect. Notes Comput. Sci., vol. 2239, Springer, 2001, pp. 61–76.[51] T. Balafoutis, K. Stergiou, Algorithms for stochastic CSPs, in: F. Benhamou (Ed.), Principles and Practice of Constraint Programming, Proceedings, CP 2006, [52] L. Bordeaux, H. Samulowitz, On the stochastic constraint satisfaction framework, in: SAC ’07: Proceedings of the 2007 ACM Symposium on Applied in: Lect. Notes Comput. Sci., vol. 4204, Springer, 2006, pp. 44–58.Computing, ACM, New York, NY, USA, 2007, pp. 316–320.[53] R. Rossi, S.A. Tarim, B. Hnich, S.D. Prestwich, A global chance-constraint for stochastic inventory systems under service level constraints, Constraints 13 [54] R. Rossi, S.A. Tarim, B. Hnich, S.D. Prestwich, Cost-based domain filtering for stochastic constraint programming, in: P.J. Stuckey (Ed.), 14th International Conference on Principles and Practice of Constraint Programming, Proceedings, CP 2008, Sydney, Australia, September 14–18, 2008, in: Lect. Notes Comput. Sci., vol. 5202, Springer, 2008, pp. 235–250.[55] S.D. Prestwich, S.A. Tarim, R. Rossi, B. Hnich, Evolving parameterised policies for stochastic constraint programming, in: I.P. Gent (Ed.), 15th International Conference on Principles and Practice of Constraint Programming, Proceedings, CP 2009, Lisbon, Portugal, September 20–24, 2009, in: Lect. Notes Comput. Sci., vol. 5732, Springer, 2009, pp. 684–691.[56] M.L. Littman, S.M. Majercik, T. Pitassi, Stochastic boolean satisfiability, J. Autom. Reason. 27 (2001) 251–296.[57] P. van Hentenryck, R. Bent, Y. Vergados, Online stochastic reservation systems, in: J.C. Beck, B.M. Smith (Eds.), Third International Conference on Integration of AI and OR Techniques in Constraint Programming for Combinatorial Optimization Problems, Proceedings, CPAIOR 2006, Cork, Ireland, May 31–June 2, 2006, in: Lect. Notes Comput. Sci., vol. 3990, Springer, 2006, pp. 212–227.[58] I. Katriel, C. Kenyon-Mathieu, E. Upfal, Commitment under uncertainty: two-stage stochastic matching problems, in: L. Arge, C. Cachin, T. Jurdzinski, A. Tarlecki (Eds.), 34th International Colloquium on Automata, Languages and Programming, Proceedings, ICALP 2007, Wroclaw, Poland, July 9–13, 2007, in: Lect. Notes Comput. Sci., vol. 4596, Springer, 2007, pp. 171–182.[59] J.C. Beck, N. Wilson, Proactive algorithms for job shop scheduling with probabilistic durations, J. Artif. Intell. Res. 28 (2007) 183–232.[60] L. Michel, P.V. Hentenryck, Iterative relaxations for iterative flattening in cumulative scheduling, in: S. Zilberstein, J. Koehler, S. Koenig (Eds.), Proceed-ings of the Fourteenth International Conference on Automated Planning and Scheduling, ICAPS 2004, Whistler, British Columbia, Canada, June 3–7, 2004, AAAI, 2004, pp. 200–208.[61] R. Bent, P.V. Hentenryck, Regrets only! online stochastic optimization under time constraints, in: Proceedings of the Nineteenth National Conference on Artificial Intelligence, Sixteenth Conference on Innovative Applications of Artificial Intelligence, July 25–29, 2004, San Jose, California, USA, 2004, pp. 501–506.[62] R. Bent, I. Katriel, P.V. Hentenryck, Sub-optimality approximations, in: P. van Beek (Ed.), 11th International Conference on Principles and Practice of Constraint Programming, Proceedings, CP 2005, Sitges, Spain, October 1–5, 2005, in: Lect. Notes Comput. Sci., vol. 3709, Springer, 2005, pp. 122–136.[63] D.S. Yates, D.S. Starnes, D.S. Moore, The Practice of Statistics, W.H. Freeman & Co, 2002.[64] M.D. McKay, R.J. Beckman, W.J. Conover, A comparison of three methods for selecting values of input variables in the analysis of output from a computer code, Technometrics 21 (1979) 239–245.[65] J. Neyman, On the problem of confidence limits, Ann. Math. Stat. 6 (1935) 111–116.[66] F. Benhamou, L. Granvilliers, Continuous and interval constraints, in: F. Rossi, P. van Beek, T. Walsh (Eds.), Handbook of Constraint Programming, Elsevier, 2006, p. 569.[67] R. Rossi, S.D. Prestwich, S.A. Tarim, Statistical constraints, in: T. Schaub, G. Friedrich, B. O’Sullivan (Eds.), ECAI 2014 – 21st European Conference on Artificial Intelligence, Including Prestigious Applications of Intelligent Systems, PAIS 2014, Prague, Czech Republic, 18–22 August 2014, in: Front. Artif. Intell. Appl., vol. 263, IOS Press, 2014, pp. 777–782.