Artificial Intelligence 171 (2007) 73–106www.elsevier.com/locate/artintAND/OR search spaces for graphical modelsRina Dechter, Robert Mateescu ∗Donald Bren School of Information and Computer Science, University of California, Irvine, CA 92697-3425, USAReceived 10 October 2005; received in revised form 8 November 2006; accepted 9 November 2006Available online 17 January 2007AbstractThe paper introduces an AND/OR search space perspective for graphical models that include probabilistic networks (directedor undirected) and constraint networks. In contrast to the traditional (OR) search space view, the AND/OR search tree displayssome of the independencies present in the graphical model explicitly and may sometimes reduce the search space exponentially.Indeed, most algorithmic advances in search-based constraint processing and probabilistic inference can be viewed as searchingan AND/OR search tree or graph. Familiar parameters such as the depth of a spanning tree, treewidth and pathwidth are shown toplay a key role in characterizing the effect of AND/OR search graphs vs. the traditional OR search graphs. We compare memoryintensive AND/OR graph search with inference methods, and place various existing algorithms within the AND/OR search space.© 2006 Elsevier B.V. All rights reserved.Keywords: Search; AND/OR search; Decomposition; Graphical models; Bayesian networks; Constraint networks1. IntroductionBayesian networks, constraint networks, Markov random fields and influence diagrams, commonly referred to asgraphical models, are all languages for knowledge representation that use graphs to capture conditional independen-cies between variables. These independencies allow both the concise representation of knowledge and the use ofefficient graph-based algorithms for query processing. Algorithms for processing graphical models fall into two gen-eral types: inference-based and search-based. Inference-based algorithms (e.g., Variable Elimination, Tree Clustering)are better at exploiting the independencies captured by the underlying graphical model. They provide a superior worstcase time guarantee, as they are time exponential in the treewidth of the graph. Unfortunately, any method that is time-exponential in the treewidth is also space exponential in the treewidth or separator width and, therefore, not practicalfor models with large treewidth.Search-based algorithms (e.g., depth-first branch-and-bound, best-first search) traverse the model’s search spacewhere each path represents a partial or full solution. The linear structure of search spaces does not retain the inde-pendencies represented in the underlying graphical models and, therefore, search-based algorithms may not be nearlyas effective as inference-based algorithms in using this information. On the other hand, the space requirements ofsearch-based algorithms may be much less severe than those of inference-based algorithms and they can accommo-* Corresponding author.E-mail addresses: dechter@ics.uci.edu (R. Dechter), mateescu@ics.uci.edu (R. Mateescu).0004-3702/$ – see front matter © 2006 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2006.11.00374R. Dechter, R. Mateescu / Artificial Intelligence 171 (2007) 73–106date a wide spectrum of space-bounded algorithms, from linear space to treewidth bounded space. In addition, searchmethods require only an implicit, generative, specification of the functional relationship (given in a procedural orfunctional form) while inference schemes often rely on an explicit tabular representation over the (discrete) variables.For these reasons, search-based algorithms are the only choice available for models with large treewidth and withimplicit representation.In this paper we propose to use the well-known idea of an AND/OR search space, originally developed for heuristicsearch [1], to generate search procedures that take advantage of information encoded in the graphical model. Wedemonstrate how the independencies captured by the graphical model may be used to yield AND/OR search treesthat are exponentially smaller than the standard search tree (that can be thought of as an OR tree). Specifically, weshow that the size of the AND/OR search tree is bounded exponentially by the depth of a spanning pseudo tree overthe graphical model. Subsequently, we move from AND/OR search trees to AND/OR search graphs. Algorithms thatexplore the search graph involve controlled memory management that allows improving their time-performance byincreasing their use of memory. The transition from a search tree to a search graph in AND/OR representations alsoyields significant savings compared to the same transition in the original OR space. In particular, we show that thesize of the minimal AND/OR graph is bounded exponentially by the treewidth, while for OR graphs it is boundedexponentially by the pathwidth.Our idea of the AND/OR search space is inspired by search advances introduced sporadically in the past threedecades for constraint satisfaction and more recently for probabilistic inference and for optimization tasks. Specif-ically, it resembles pseudo tree rearrangement [2,3], briefly introduced two decades ago, which was adapted sub-sequently for distributed constraint satisfaction [4,5] and more recently in [6], and was also shown to be related tograph-based backjumping [7]. This work was extended in [8] and more recently applied to optimization tasks [9]. An-other version that can be viewed as exploring the AND/OR graphs was presented recently for constraint satisfaction[10] and for optimization [11]. Similar principles were introduced recently for probabilistic inference (in algorithmRecursive Conditioning [12] as well as in Value Elimination [13,14]) and currently provide the backbones of the mostadvanced SAT solvers [15]. An important contribution of this paper is in showing that all these seemingly differentideas can be cast as simple traversal of AND/OR search spaces. We will also elaborate on the relationship betweenthis scheme and Variable Elimination [16]. We will discuss the relationship with Ordered Binary Decision Diagrams(OBDD) [17], disjunctive Decomposable Negational Normal Forms (d-DNNF) and their extension to arithmetic cir-cuits for Bayesian networks [18,19], as well as with the recent work in [20–23].The structure of the paper is as follows. Section 2 contains preliminary notations and definitions. Section 3 de-scribes graphical models. Section 4 introduces the AND/OR search tree that can be traversed by a linear space searchalgorithm. Section 5 presents the AND/OR search graph that can be traversed by memory intensive search algorithms.Section 6 shows how to use the AND/OR graphs to solve a reasoning problem, and gives the AND/OR search algo-rithm for counting and belief updating. Section 7 is dedicated to a detailed comparison of AND/OR search and othernew algorithmic advances in graphical models as well as compilation schemes. Finally, Section 8 provides concludingremarks. All the proofs are given in an appendix at the end.2. PreliminariesNotations. A reasoning problem is defined in terms of a set of variables taking values on finite domains and aset of functions defined over these variables. We denote variables or subsets of variables by uppercase letters (e.g.,X, Y, Z, S, R . . .) and values of variables by lower case letters (e.g., x, y, z, s). An assignment (X1 = x1, . . . , Xn = xn)can be abbreviated as x = ((cid:3)X1, x1(cid:4), . . . , (cid:3)Xn, xn(cid:4)) or x = (x1, . . . , xn). For a subset of variables Y , DY denotes theCartesian product of the domains of variables in Y . xY and x[Y ] are both used as the projection of x = (x1, . . . , xn)over a subset Y . We will also denote by Y = y (or y for short) the assignment of values to variables in Y from theirrespective domains. We denote functions by letters f , g, h etc., and the scope (set of arguments) of the function f byscope(f ).Definition 1 (functional operators). Given a function h defined over a subset of variables S, where X ∈ S, func-X h) are defined over U = S − {X} as follows: For every U = u, and denoting bytions (minX h), (maxX h), and ((u, x) the extension of tuple u by assignment X = x, (minX h)(u) = minx h(u, x), (maxX h)(u) = maxx h(u, x), and(cid:2)(cid:2)x h(u, x). Given a set of functions h1, . . . , hk defined over the subsets S1, . . . , Sk, the product func-(X h)(u) =(cid:2)R. Dechter, R. Mateescu / Artificial Intelligence 171 (2007) 73–10675(cid:2)tion, Πj hj , and summation function,and (j hj )(u) =j hj (uSj ).(cid:2)(cid:2)j hj , are defined over U =(cid:3)j Sj . For every U = u, (Πj hj )(u) = Πj hj (uSj ),Definition 2 (graph concepts). A directed graph is a pair G = {V , E}, where V = {X1, . . . , Xn} is a set of vertices,and E = {(Xi, Xj ) | Xi, Xj ∈ V } is the set of edges (arcs). If (Xi, Xj ) ∈ E, we say that Xi points to Xj . The degreeof a variable is the number of arcs incident to it. For each variable Xi , pa(Xi) or pai , is the set of variables pointingto Xi in G, while the set of child vertices of Xi , denoted ch(Xi), comprises the variables that Xi points to. The familyof Xi , Fi , includes Xi and its parent variables. A directed graph is acyclic if it has no directed cycles. An undirectedgraph is defined similarly to a directed graph, but there is no directionality associated with the edges.Definition 3 (induced width). An ordered graph is a pair (G, d) where G is an undirected graph, and d = X1, . . . , Xnis an ordering of the nodes. The width of a node is the number of the node’s neighbors that precede it in the ordering.The width of an ordering d, is the maximum width over all nodes. The induced width of an ordered graph, w∗(d),is the width of the induced ordered graph obtained as follows: nodes are processed from last to first; when node Xis processed, all its preceding neighbors are connected. The induced width of a graph, denoted by w∗, is the minimalinduced width over all its orderings.Definition 4 (hypergraph). A hypergraph is a pair H = (X, S), where S = {S1, . . . , St } is a set of subsets of V calledhyperedges.Definition 5 (tree decomposition). A tree decomposition of a hypergraph H = (X, S) is a tree T = (V , E) (V is theset of nodes, also called “clusters”, and E is the set of edges) together with a labeling function χ that associates witheach vertex v ∈ V a set χ(v) ⊆ X satisfying:1. For each Si ∈ S there exists a vertex v ∈ V such that Si ⊆ χ(v);2. (running intersection property) For each Xi ∈ X, the set {v ∈ V | Xi ∈ χ(v)} induces a connected subtree of T .Definition 6 (treewidth, pathwidth). The width of a tree decomposition of a hypergraph is the size of its largest clusterminus 1 (maxv |χ(v)| − 1). The treewidth of a hypergraph is the minimum width along all possible tree decomposi-tions. The pathwidth is the treewidth over the restricted class of chain decompositions.It is easy to see that given an induced graph, the set of maximal cliques (also called clusters) provide a tree decom-position of the graph, namely the clusters can be connected in a tree structure that satisfies the running intersectionproperty. It is well known that the induced width of a graph is identical to its treewidth [24]. For various relationshipsbetween these and other graph parameters see [25–27].2.1. AND/OR search graphsAND/OR search spaces. An AND/OR state space representation of a problem is defined by a 4-tuple (cid:3)S, O, Sg, s0(cid:4).S is a set of states which can be either OR or AND states (the OR states represent alternative ways for solving theproblem while the AND states often represent problem decomposition into subproblems, all of which need to besolved). O is a set of operators. An OR operator transforms an OR state into another state, and an AND operatortransforms an AND state into a set of states. There is a set of goal states Sg ⊆ S and a start node s0 ∈ S. Exampleproblem domains modeled by AND/OR graphs are two-player games, parsing sentences and Tower of Hanoi [1].The AND/OR state space model induces an explicit AND/OR search graph. Each state is a node and its child nodesare those obtained by applicable AND or OR operators. The search graph includes a start node. The terminal nodes(having no child nodes) are marked as Solved (S), or Unsolved (U).A solution subtree of an AND/OR search graph G is a subtree which: (1) contains the start node s0; (2) if n in thesubtree is an OR node then it contains one of its child nodes in G and if n is an AND node it contains all its childrenin G; (3) all its terminal nodes are “Solved” (S). AND/OR graphs can have a cost associated with each arc, and thecost of a solution subtree is a function (e.g., sum-cost) of the arcs included in the solution subtree. In this case we may76R. Dechter, R. Mateescu / Artificial Intelligence 171 (2007) 73–106seek a solution subtree with optimal (maximum or minimum) cost. Other tasks that enumerate all solution subtrees(e.g., counting solutions) can also be defined.3. Graphical modelsGraphical models include constraint networks defined by relations of allowed tuples, (directed or undirected) prob-abilistic networks, defined by conditional probability tables over subsets of variables, cost networks defined by costfunctions and influence diagrams which include both probabilistic functions and cost functions (i.e., utilities) [28].Each graphical model comes with its typical queries, such as finding a solution, or an optimal one (over constraintnetworks), finding the most probable assignment or updating the posterior probabilities given evidence, posed overprobabilistic networks, or finding optimal solutions for cost networks. The task for influence diagrams is to choosea sequence of actions that maximizes the expected utility. Markov random fields are the undirected counterparts ofprobabilistic networks. They are defined by a collection of probabilistic functions called potentials, over arbitrary sub-sets of variables. The framework presented in this paper is applicable across all graphical models that have discretevariables, however we will draw most of our examples from constraint networks and directed probabilistic networks.In general, a graphical model is defined by a collection of functions F , over a set of variables X, conveyingprobabilistic, deterministic or preferential information, whose structure is captured by a graph.Definition 7 (graphical models). A graphical model R is a 4-tuple, R = (cid:3)X, D, F, ⊗(cid:4), where:(1) X = {X1, . . . , Xn} is a set of variables;(2) D = {D1, . . . , Dn} is the set of their respective finite domains of values;(3) F = {f1, . . . , fr } is a set of real-valued functions each defined over a subset of variables Si ⊆ X, called its scope,and sometimes denoted by scope(fi);(cid:2)(cid:4)(cid:5)i fi ∈ {i fi,i fi, (cid:2)i fi} is a combination operator.1(4)The graphical model represents the combination of all its functions:(cid:4)ri=1 fi .Next, we introduce the notion of universal graphical model which is defined by a single function.Definition 8 (universal equivalent graphical model). Given a graphical model R = (cid:3)X, D, F, ⊗(cid:4), the universal equiv-alent graphical model of R is u(R) = (cid:3)X, D, F = {(cid:4)ri=1 fi}, ⊗(cid:4).Two graphical models are equivalent if they have the same universal model.Definition 9 (cost of a full and a partial assignment). Given a graphical model R, the cost of a full assignmentx = (x1, . . . , xn) is defined by c(x) =f ∈F f (x[scope(f )]). Given a subset of variables Y ⊆ X, the cost of a partialassignment y is the combination of all the functions whose scopes are included in Y (FY ) evaluated at the assignedvalues. Namely, c(y) =f (y[scope(f )]).(cid:4)(cid:4)f ∈FYWe can restrict a graphical model by conditioning on a partial assignment.Definition 10 (conditioned graphical model). Given a graphical model R = (cid:3)X, D, F, ⊗(cid:4) and given a partial assign-ment Y = y, Y ⊂ X, the conditioned graphical model is R|y = (cid:3)X, D|y, F |y, ⊗(cid:4), where D|y = {Di ∈ D, Xi /∈ Y } andF |y = {f |Y =y, f ∈ F , and scope(f ) (cid:9)⊆ Y }.Consistency. For most graphical models, the functions range has a special value “0” that is absorbing relative tothe combination operator (e.g., multiplication). Combining anything with “0” yields a “0”. The “0” value expressesthe notion of inconsistent assignments. It is a primary concept in constraint networks but can also be defined relativeto other graphical models that have a “0” element.1 The combination operator can also be defined axiomatically [29].R. Dechter, R. Mateescu / Artificial Intelligence 171 (2007) 73–10677Definition 11 (consistent partial assignment, solution). Given a graphical model having a “0” element, a partialassignment is consistent if its cost is non-zero. A solution is a consistent assignment to all the variables.Flat functions. Each function in a graphical model having a “0” element expresses implicitly a constraint. Theflat constraint of function fi is a constraint Ri over its scope that includes all and only the consistent tuples. In thispaper, when we talk about a constraint network, we refer also to the flat constraint network that can be extracted fromthe general graphical model. When all the full assignments are consistent we say that the graphical model is strictlypositive.Unless otherwise noted, we assume that functions are expressed in a tabular explicit form, having an entry forevery combination of values from the domains of their variables. Therefore, the specification of such functions isexponential in their scope size (the base of the exponent is the maximum domain size). Relations, or clauses, can beexpressed as functions as well, associating a value of “0” or “1” for each tuple, depending on whether or not the tupleis in the relation (or satisfies a clause). The combination operator takes a set of functions and generates a new functionwhose scope is the union of the input functions scopes.Definition 12 (primal graph). The primal graph of a graphical model is an undirected graph that has variables as itsvertices and an edge connects any two variables that appear in the scope of the same function.Reasoning problems, queries. There are various queries/tasks that can be posed over graphical models. We referto all as reasoning problems. In general, a reasoning problem is a function from the graphical model to some set ofelements, most commonly, the real numbers. We need one more functional operator, marginalization, to express mostof the common queries.Definition 13 (reasoning problem). A reasoning problem over a graphical model is defined by a marginalizationoperator and a set of subsets. It is therefore a triplet, P = (cid:3)R, ⇓Y , {Z1, . . . , Zt }(cid:4), where R = (cid:3)X, D, F, ⊗(cid:4) is agraphical model and Z = {Z1, . . . , Zt } is a set of subsets of variables of X. If S is the scope of function f and Y ⊆ X,⇓Y f ∈ { maxS−Y f }, is a marginalization operator. P can be viewed as a vector function over thescopes Z1, . . . , Zt . The reasoning problem is to compute PZ1,...,Zt (R):S−Y f, min(cid:5)Y f,S−Y f,(cid:2)PZ1,...,Zt (R) =⇓Z1(cid:6)r(cid:7)i=1fi, . . . , ⇓Ztr(cid:7)i=1(cid:8)fi.We will focus primarily on reasoning problems defined by Z = ∅. The marginalization operator is sometimescalled an elimination operator because it removes some arguments from the input function’s scope. Specifically, ⇓Y fis defined on Y . It therefore removes variables S − Y from f ’s scope, S. Note that hereis the relational projectionoperator and unlike the rest of the marginalization operators the convention is that it is defined by the set of variablesthat are not eliminated.(cid:5)We next elaborate on the two popular graphical models of constraint networks and belief networks which will bethe primary focus of this paper.3.1. Constraint networksConstraint networks is a framework for formulating real world problems, such as scheduling and design, planningand diagnosis, and many more as a set of constraints between variables. For example, one approach to formulatinga scheduling problem as a constraint satisfaction problem (CSP) is to create a variable for each resource and timeslice. Values of variables would be the tasks that need to be scheduled. Assigning a task to a particular variable(corresponding to a resource at some time slice) means that this resource starts executing the given task at the specifiedtime. Various physical constraints (such as that a given job takes a certain amount of time to execute, or that a task canbe executed at most once) can be modeled as constraints between variables. The constraint satisfaction task is to findan assignment of values to all the variables that does not violate any constraints, or else to conclude that the problemis inconsistent. Other tasks are finding all solutions and counting the solutions.78R. Dechter, R. Mateescu / Artificial Intelligence 171 (2007) 73–106Definition 14 (constraint network). A constraint network (CN) is defined by a 4-tuple, (cid:3)X, D, C, (cid:2)(cid:4), where X is aset of variables X = {X1, . . . , Xn}, associated with a set of discrete-valued domains, D = {D1, . . . , Dn}, and a set ofconstraints C = {C1, . . . , Cr }. Each constraint Ci is a pair (Si, Ri), where Ri is a relation Ri ⊆ DSi defined on a subsetof variables Si ⊆ X. The relation denotes all compatible tuples of DSi allowed by the constraint. The combinationoperator, (cid:2), is join. The primal graph of a constraint network is called a constraint graph. A solution is an assignmentof values to all the variables x = (x1, . . . , xn), xi ∈ Di , such that ∀Ci ∈ C, xSi∈ Ri . The constraint network representsits set of solutions, (cid:2)i Ci .Constraint satisfaction is a reasoning problem P = (cid:3)R, Π, Z = ∅(cid:4), where R = (cid:3)X, D, C, (cid:2)(cid:4) is a constraint net-work, and the marginalization operator is the projection operator Π . Namely, for constraint satisfaction Z = ∅, and(cid:2)⇓Y is ΠY . So the task is to find ⇓∅i fi which corresponds to enumerating all solutions. When thecombination operator is a product over the cost-based representation of the relations, and the marginalization op-erator is logical summation we get 1 if the constraint problem has a solution and “0” otherwise. For counting, themarginalization operator is summation and Z = ∅ too.i fi = ΠX(cid:4)An immediate extension of constraint networks are cost networks where the set of functions are real-valued costfunctions, and the primary task is optimization.(cid:4), whereDefinition 15 (cost network, combinatorial optimization). A cost network is defined by a 4-tuple, (cid:3)X, D, C,X is a set of variables X = {X1, . . . , Xn}, associated with a set of discrete-valued domains, D = {D1, . . . , Dn}, anda set of cost functions C = {C1, . . . , Cr }. Each Ci is a real-valued function defined on a subset of variables Si ⊆ X.The combination operator, is. The reasoning problem is to find a minimum or maximum cost solution which isexpressed via the marginalization operator of maximization or minimization, and Z = ∅.(cid:2)(cid:2)A task such as MAX-CSP: finding a solution that satisfies the maximum number of constraints (when the problemis inconsistent), can be defined by treating each relation as a cost function that assigns “0” to consistent tuples and “1”otherwise. Then the combination operator is summation and the marginalization operator is minimization. Namely,the task is to find ⇓∅(cid:4)(cid:2)i fi = minXi fi .3.2. Propositional satisfiabilityA special case of a CSP is the propositional satisfiability problem (SAT). A formula ϕ in conjunctive normalform (CNF) is a conjunction of clauses α1, . . . , αt where a clause is a disjunction of literals (propositions or theirnegations). For example, α = (P ∨ ¬Q ∨ ¬R) is a clause, where P , Q and R are propositions, and P , ¬Q and ¬Rare literals. The SAT problem requires deciding whether a given CNF theory has a model, i.e., a truth-assignment toits propositions that does not violate any clause.Propositional satisfiability (SAT) can be defined as a CSP, where propositions correspond to variables, domains are{0, 1}, and constraints are represented by clauses, for example the clause (¬A ∨ B) is the relation (or function) overits propositional variables that allows all tuples over (A, B) except (A = 1, B = 0).3.3. Belief networksBelief networks [30] provide a formalism for reasoning about partial beliefs under conditions of uncertainty. Theyare defined by a directed acyclic graph over vertices representing random variables of interest (e.g., the temperatureof a device, the gender of a patient, a feature of an object, the occurrence of an event). The arcs signify the existenceof direct causal influences between linked variables quantified by conditional probabilities that are attached to eachcluster of parents-child vertices in the network.Definition 16 (belief networks). A belief network (BN) is a graphical model P = (cid:3)X, D, PG,(cid:4), where X ={X1, . . . , Xn} is a set of variables over multi-valued domains D = {D1, . . . , Dn}. Given a directed acyclic graphG over X as nodes, PG = {Pi}, where Pi = {P (Xi|pa(Xi))} are conditional probability tables (CPTs for short) as-sociated with each Xi , where pa(Xi) are the parents of Xi in the acyclic graph G. A belief network represents a(cid:5)R. Dechter, R. Mateescu / Artificial Intelligence 171 (2007) 73–10679probability distribution over X, P (x1, . . . , xn) =variables.(cid:5)ni=1 P (xi|xpa(Xi )). An evidence set e is an instantiated subset ofWhen formulated as a graphical model, functions in F denote conditional probability tables and the scopes of thesefunctions are determined by the directed acyclic graph G: each function fi ranges over variable Xi and its parentsin G. The combination operator isj . The primal graph of a belief network is called a moral graph. It connectsany two variables appearing in the same CPT.(cid:4)(cid:5)=jDefinition 17 (belief updating). Given a belief network and evidence e, the belief updating task is to compute theposterior marginal probability of variable Xi , conditioned on the evidence. Namely,Bel(Xi = xi) = α(cid:9)n(cid:10)P (xk, e|xpak ),{(x1,...,xi−1,xi+1,...,xn)|E=e,Xi =xi }k=1where α is a normalization constant. In this case, the marginalization operator is ⇓Y =∀Xi, ⇓Xik Pk. The query of finding the probability of the evidence is defined by Z = ∅.X−Y , and Zi = {Xi}. Namely,k fk =(cid:4)(cid:2)(cid:5){X−Xi |Xi =xi }(cid:2)Definition 18 (most probable explanation). The most probable explanation (MPE) task is to find a complete assign-ment which agrees with the evidence, and which has the highest probability among all such assignments. Namely, tofind an assignment (xo1 , . . . , xon) such thatn(cid:10)P (xo1 , . . . , xon) = maxx1,...,xnP (xk, e|xpak ).k=1As a reasoning problem, an MPE task is to find ⇓∅max and Z = ∅.(cid:4)i fi = maxX(cid:5)i Pi . Namely, the marginalization operator isMarkov networks are graphical models very similar to belief networks. The only difference is that the set of prob-abilistic functions Pi , called potentials, can be defined over any subset of variables. An important reasoning task forMarkov networks is to find the partition function which is defined by the marginalization operator of summation,where Z = ∅.4. AND/OR search trees for graphical modelsWe will next present the AND/OR search space for a general graphical model starting with an example of aconstraint network.Example 19. Consider the simple tree graphical model (i.e., the primal graph is a tree) in Fig. 1(a), over domains{1, 2, 3}, which represents a graph-coloring problem. Namely, each node should be assigned a value such that adjacentnodes have different values. Once variable X is assigned the value 1, the search space it roots can be decomposedinto two independent subproblems, one that is rooted at Y and one that is rooted at Z, both of which need to besolved independently. Indeed, given X = 1, the two search subspaces do not interact. The same decomposition canbe associated with the other assignments to X, (cid:3)X, 2(cid:4) and (cid:3)X, 3(cid:4). Applying the decomposition along the tree (inFig. 1(a) yields the AND/OR search tree in Fig. 1(c). In the AND/OR space a full assignment to all the variablesis not a path but a subtree. For comparison, the traditional OR search tree is depicted in Fig. 1(b). Clearly, the sizeof the AND/OR search space is smaller than that of the regular OR space. The OR search space has 3 · 27 nodeswhile the AND/OR has 3 · 25 (compare 1(b) with 1(c)). If k is the domain size, a balanced binary tree with n nodeshas an OR search tree of size O(kn). The AND/OR search tree, whose pseudo tree has depth O(log2 n), has sizeO((2k)log2 n) = O(n · klog2 n) = O(n1+log2 k). When k = 2, this becomes O(n2).The AND/OR space is not restricted to tree graphical models. It only has to be guided by a backbone tree whichspans the original primal graph of the graphical model in a particular way. We will define the AND/OR search spacerelative to a depth-first search tree (DFS tree) of the primal graph first, and will generalize to a broader class ofbackbone spanning trees subsequently. For completeness sake we define DFS spanning tree, next.80R. Dechter, R. Mateescu / Artificial Intelligence 171 (2007) 73–106Fig. 1. OR vs. AND/OR search trees; note the connector for AND arcs.Definition 20 (DFS spanning tree). Given a DFS traversal ordering of an undirected graph G = (V , E), d =X1, . . . , Xn, the DFS spanning tree T of G is defined as the tree rooted at the first node, X1, which includes only thetraversed arcs of G. Namely, T = (V , E(cid:14)), where E(cid:14) = {(Xi, Xj ) | Xj traversed from Xi}.We are now ready to define the notion of AND/OR search tree for a graphical model.Definition 21 (AND/OR search tree). Given a graphical model R = (cid:3)X, D, F, ⊗(cid:4), its primal graph G and a backboneDFS tree T of G, the associated AND/OR search tree, denoted ST (R), has alternating levels of AND and OR nodes.The OR nodes are labeled Xi and correspond to the variables. The AND nodes are labeled (cid:3)Xi, xi(cid:4) (or simply xi )and correspond to the value assignments in the domains of the variables. The structure of the AND/OR search treeis based on the underlying backbone tree T . The root of the AND/OR search tree is an OR node labeled by the rootof T . A path from the root of the search tree ST (R) to a node n is denoted by πn. If n is labeled Xi or xi the pathwill be denoted πn(Xi) or πn(xi), respectively. The assignment sequence along path πn, denoted asgn(πn) is the setof value assignments associated with the sequence of AND nodes along πn:(cid:12)(cid:11)πn(Xi)(cid:11)(cid:12)πn(xi)(cid:13)(cid:14)=;(cid:3)X1, x1(cid:4), (cid:3)X2, x2(cid:4), . . . , (cid:3)Xi−1, xi−1(cid:4)(cid:14)(cid:13)(cid:3)X1, x1(cid:4), (cid:3)X2, x2(cid:4), . . . , (cid:3)Xi, xi(cid:4).=asgnasgnThe set of variables associated with OR nodes along path πn is denoted by var(πn): var(πn(Xi)) = {X1, . . . , Xi−1},var(πn(xi)) = {X1, . . . , Xi}. The exact parent-child relationships between nodes in the search space are defined asfollows:(1) An OR node, n, labeled by Xi has a child AND node, m, labeled (cid:3)Xi, xi(cid:4) iff (cid:3)Xi, xi(cid:4) is consistent with theassignment asgn(πn). Consistency is defined relative to the flat constraints.(2) An AND node m, labeled (cid:3)Xi, xi(cid:4) has a child OR node r labeled Y , iff Y is a child of X in the backbone tree T .Each OR arc, emanating from an OR to an AND node is associated with a weight to be defined shortly (seeDefinition 26).Clearly, if a node n is labeled Xi (OR node) or xi (AND node), var(πn) is the set of variables mentioned on thepath from the root to Xi in the backbone tree, denoted by pathT (Xi).22 When the AND/OR tree is extended to dynamic variable orderings the set of variables along different paths may vary.R. Dechter, R. Mateescu / Artificial Intelligence 171 (2007) 73–10681A solution subtree is defined in the usual way:Definition 22 (solution subtree). A solution subtree of an AND/OR search tree contains the root node. For every ORnodes it contains one of its child nodes and for each of its AND nodes it contains all its child nodes, and all its leafnodes are consistent.Example 23. In the example of Fig. 1(a), T is the DFS tree which is the tree rooted at X, and accordingly the root ORnode of the AND/OR tree in 1(c) is X. Its child nodes are labeled (cid:3)X, 1(cid:4), (cid:3)X, 2(cid:4), (cid:3)X, 3(cid:4) (only the values are noted inthe figure), which are AND nodes. From each of these AND nodes emanate two OR nodes, Y and Z, since these arethe child nodes of X in the DFS tree of 1(a). The descendants of Y along the path from the root, ((cid:3)X, 1(cid:4)), are (cid:3)Y, 2(cid:4)and (cid:3)Y, 3(cid:4) only, since (cid:3)Y, 1(cid:4) is inconsistent with (cid:3)X, 1(cid:4). In the next level, from each node (cid:3)Y, y(cid:4) emanate OR nodeslabeled T and R and from (cid:3)Z, z(cid:4) emanate nodes labeled L and M as dictated by the DFS tree. In 1(c) a solution treeis highlighted.4.1. Weights of OR-AND arcsThe arcs in AND/OR trees are associated with weights w that are defined based on the graphical model’s functionsand combination operator. The simplest case is that of constraint networks.Definition 24 (arc weight for constraint networks). Given an AND/OR tree ST (R) of a constraint network R, eachterminal node is assumed to have a single, dummy, outgoing arc. The outgoing arc of a terminal AND node alwayshas the weight “1” (namely it is consistent and thus solved). An outgoing arc of a terminal OR node has weight “0”,(there is no consistent value assignment). The weight of any internal OR to AND arc is “1”. The arcs from AND toOR nodes have no weight.We next define arc weights for any graphical model using the notion of buckets of functions.Definition 25 (buckets relative to a backbone tree). Given a graphical model R = (cid:3)X, D, F, ⊗(cid:4) and a backbone tree T ,the bucket of Xi relative to T , denoted BT (Xi), is the set of functions whose scopes contain Xi and are included inpathT (Xi), which is the set of variables from the root to Xi in T . Namely,BT (Xi) =(cid:13)(cid:14)f ∈ F | Xi ∈ scope(f ) and scope(f ) ⊆ pathT (Xi).Definition 26 (OR-to-AND weights). Given an AND/OR tree ST (R), of a graphical model R,the weightw(n,m)(Xi, xi) of arc (n, m), where Xi labels n and xi labels m, is the combination of all the functions in BT (Xi)(cid:4)assigned by values along πm. Formally, w(n,m)(Xi, xi) =f ∈BT (Xi ) f (asgn(πm)[scope(f )]).Definition 27 (weight of a solution subtree). Given a weighted AND/OR tree ST (R), of a graphical model R, andgiven a solution subtree t having OR-to-AND set of arcs arcs(t), the weight of t is defined by w(t) =e∈arcs(t) w(e).(cid:4)Example 28. Fig. 2 shows a belief network, a DFS tree that drives its weighted AND/OR search tree, and a portion ofthe AND/OR search tree with the appropriate weights on the arcs expressed symbolically. In this case the bucket ofE contains the function P (E|A, B), and the bucket of C contains two functions, P (C|A) and P (D|B, C). Note thatP (D|B, C) belongs neither to the bucket of B nor to the bucket of D, but it is contained in the bucket of C, which isthe last variable in its scope to be instantiated in a path from the root of the tree. We see indeed that the weights on thearcs from the OR node E and any of its AND value assignments include only the instantiated function P (E|A, B),while the weights on the arcs connecting C to its AND child nodes are the products of the two functions in its bucketinstantiated appropriately. Fig. 3 shows a constraint network with four relations, a backbone DFS tree and a portionof the AND/OR search tree with weights on the arcs. Note that the complex weights would reduce to “0” and “1” inthis case. However, since we use the convention that arcs appear in the search tree only if they represent a consistentextension of a partial solution, we will not see arcs having zero weights.82R. Dechter, R. Mateescu / Artificial Intelligence 171 (2007) 73–106Fig. 2. Arc weights for probabilistic networks.4.2. Properties of AND/OR search treeFig. 3. Arc weights for constraint networks.Any DFS tree T of a graph G has the property that the arcs of G which are not in T are back-arcs. Namely, theyconnect a node to one of its ancestors in the backbone tree. This ensures that the scope of each function in F will befully assigned on some path in T , a property that is essential for the validity of the AND/OR search tree.Theorem 29 (correctness). Given a graphical model R having a primal graph G and a DFS spanning tree T of G,its weighted AND/OR search tree ST (R) is sound and complete, namely: 1) there is a one-to-one correspondencebetween solution subtrees of ST (R) and solutions of R; 2) the weight of any solution tree equals the cost of the fullsolution it denotes; namely, if t is a solution tree of ST (R) which denotes a solution x = (x1, . . . , xn) then c(x) = w(t).The virtue of an AND/OR search tree representation is that its size may be far smaller than the traditional ORsearch tree. The size of an AND/OR search tree depends on the depth of its backbone DFS tree T . Therefore, DFStrees of smaller depth should be preferred to drive the AND/OR search tree. An AND/OR search tree becomes an ORsearch tree when its DFS tree is a chain.Theorem 30 (size bounds of AND/OR search tree). Given a graphical model R, with domains size bounded by k,and a DFS spanning tree T having depth m and l leaves, the size of its AND/OR search tree ST (R) is O(l · km) (andtherefore also O(nkm) and O((bk)m) when b bounds the branching degree of T and n is the number of variables).In contrast the size of its OR search tree along any ordering is O(kn). The above bounds are tight and realizable forfully consistent graphical models. Namely, one whose all full assignments are consistent.Table 1 demonstrates the size saving of AND/OR vs. OR search spaces for 5 random networks having 20 bivaluedvariables, 18 CPTs with 2 parents per child and 2 root nodes, when all the assignments are consistent (remember thatthis is the case when the probability distribution is strictly positive). The size of the OR space is the full binary treeR. Dechter, R. Mateescu / Artificial Intelligence 171 (2007) 73–10683Table 1OR vs. AND/OR search size, 20 nodesTreewidthHeight5455610910109OR spaceTime (sec.)3.1543.1353.1243.1253.124Nodes2,097,1512,097,1512,097,1512,097,1512,097,151AND/OR spaceTime (sec.)AND nodesOR nodes0.030.010.030.020.0210,4945,1028,9267,8066,3185,2472,5514,4633,9033,159Fig. 4. (a) A graph; (b) a DFS tree T1; (c) a pseudo tree T2; (d) a chain pseudo tree T3.of depth 20. The size of the full AND/OR space varies based on the backbone DFS tree. We can give a better analyticbound on the search space size by spelling out the depth mi of each leaf node Li in T .(cid:2)Proposition 31. Given a graphical model R, with domains size bounded by k, and a backbone spanning tree Thaving L = {L1, . . . , Ll} leaves, where depth of leaf Li is mi , then the size of its full AND/OR search tree ST (R)lk=1 kmi ). Alternatively, we can use the exact domain sizes for each variable yielding an even more accurateis O(expression O(Lk∈L Π{Xj |Xj ∈pathT (Lk)}|D(Xj )|).(cid:2)4.3. From DFS trees to pseudo treesThere is a larger class of trees that can be used as backbones for AND/OR search trees, called pseudo trees [2].They have the above mentioned back-arc property.Definition 32 (pseudo tree, extended graph). Given an undirected graph G = (V , E), a directed rooted tree T =(V , E(cid:14)) defined on all its nodes is a pseudo tree if any arc of G which is not included in E(cid:14) is a back-arc in T , namelyit connects a node in T to an ancestor in T . The arcs in E(cid:14) may not all be included in E. Given a pseudo tree T of G,the extended graph of G relative to T is defined as GT = (V , E ∪ E(cid:14)).Clearly, any DFS tree and any chain of a graph are pseudo trees.Example 33. Consider the graph G displayed in Fig. 4(a). Ordering d1 = (1, 2, 3, 4, 7, 5, 6) is a DFS ordering of aDFS tree T1 having the smallest DFS tree depth of 3 (Fig. 4(b)). The tree T2 in Fig. 4(c) is a pseudo tree and has a treedepth of 2 only. The two tree-arcs (1, 3) and (1, 5) are not in G. Tree T3 in Fig. 4(d), is a chain. The extended graphsGT1 , GT2 and GT3 are presented in Fig. 4(b), (c), (d) when we ignore directionality and include the dotted arcs.It is easy to see that the weighted AND/OR search tree is well defined when the backbone trees is a pseudo tree.Namely, the properties of soundness and completeness hold and the size bounds are extendable.84R. Dechter, R. Mateescu / Artificial Intelligence 171 (2007) 73–106Fig. 5. AND/OR search tree along pseudo trees T1 and T2.Theorem 34 (properties of AND/OR search trees). Given a graphical model R and a backbone pseudo tree T , itsweighted AND/OR search tree ST (R) is sound and complete, and its size is O(l · km), where m is the depth of thepseudo tree, l bounds its number of leaves, and k bounds the domain size.Example 35. Fig. 5 shows the AND/OR search trees along the pseudo trees T1 and T2 from Fig. 4. Here the domainsof the variables are {a, b, c} and the constraints are universal. The AND/OR search tree based on T2 is smaller, becauseT2 has a smaller depth than T1.Finding good pseudo trees. Finding a pseudo tree or a DFS tree of minimal depth is known to be NP-complete.However various greedy heuristics are available. For example, pseudo trees can be obtained by generating a heuristi-cally good induced graph along an ordering d and then traversing the induced graph depth-first, breaking ties in favorof earlier variables [8]. For more information see [31,32].The definition of buckets relative to a backbone tree extends to pseudo trees as well, and this allows the definitionsof weights for an AND/OR tree based on a pseudo tree. Next we define the notion of a bucket tree and show that itcorresponds to a pseudo tree. This relationship will be used to make additional connections between various graphparameters.Definition 36 (bucket tree [33]). Given a graphical model, its primal graph G and an ordering d, the bucket tree of Galong d is defined as follows. Let G∗d be the induced graph of G along d. Each variable X has an associated bucket,denoted by BX, that contains X and its earlier neighbors in the induced graph G∗d (similar to Definition 25). Thenodes of the bucket tree are the n buckets. Each node BX points to BY (BY is the parent of BX) if Y is the latest earlierneighbor of X in G∗d .The following relationship between the treewidth and the depth of pseudo trees is known [8,26]. Given a treedecomposition of a primal graph G having n nodes, whose treewidth is w∗, there exists a pseudo tree T of G whosedepth, m, satisfies: m (cid:2) w∗ · log n. It can also be shown that any bucket tree [33] yields a pseudo tree and that amin-depth bucket tree yields min-depth pseudo trees. The depth of a bucket tree was also called elimination depthin [26].In summary,Proposition 37. [8,26] The minimal depth m over all pseudo trees satisfies m (cid:2) w∗ · log n, where w∗ is the treewidthof the primal graph of the graphical model.R. Dechter, R. Mateescu / Artificial Intelligence 171 (2007) 73–10685Table 2Average depth of pseudo trees vs. DFS trees; 100 instances of each random modelModel (DAG)(N = 50, P = 2, C = 48)(N = 50, P = 3, C = 47)(N = 50, P = 4, C = 46)(N = 100, P = 2, C = 98)(N = 100, P = 3, C = 97)(N = 100, P = 4, C = 96)Width9.516.120.918.331.040.3Pseudo tree depthDFS tree depth16.8223.3428.3127.5941.1250.5336.0340.6043.1972.3680.4786.54Fig. 6. AND/OR search tree and backtrack-free tree.Therefore,Theorem 38. A graphical model that has treewidth w∗ has an AND/OR search tree whose size is O(n · k(w∗·log n)),where k bounds the domain size and n is the number of variables.For illustration, Table 2 shows the effect of DFS spanning trees against pseudo trees, both generated using brute-force heuristics over randomly generated graphs, where N is the number of variables, P is the number of variables inthe scope of a function and C is the number of functions.4.4. Pruning inconsistent subtrees for the flat constraint networksMost advanced constraint processing algorithms incorporate no-good learning, and constraint propagation duringsearch, or use variable elimination algorithms such as adaptive-consistency and directional resolution [34], generatingall relevant no-goods, prior to search. Such schemes can be viewed as compiling a representation that would yield apruned search tree. We next define the backtrack-free AND/OR search tree.Definition 39 (backtrack-free AND/OR search tree). Given an AND/OR search tree ST (R), the backtrack-freeAND/OR search tree of R based on T , denoted BFT (R), is obtained by pruning from ST (R) all inconsistent subtrees,namely all nodes that root no consistent partial solution.Example 40. Consider 5 variables X, Y, Z, T , R over domains {2, 3, 5}, where the constraints are: X divides Y andZ, and Y divides T and R. The constraint graph and the AND/OR search tree relative to the DFS tree rooted at X,are given in Fig. 6(a). In 6(b) we present the ST (R) search space whose nodes’ consistency statuses (which will laterwill be referred to as values) are already evaluated having value “1” if consistent and “0” otherwise. We also highlight86R. Dechter, R. Mateescu / Artificial Intelligence 171 (2007) 73–106two solution subtrees; one depicted by solid lines and one by dotted lines. Part (c) presents BFT (R), where all nodesthat do not root a consistent solution are pruned.If we traverse the backtrack-free AND/OR search tree we can find a solution subtree without encounteringany dead-ends. Some constraint networks specifications yield a backtrack-free search space. Others can be madebacktrack-free by massaging their representation using constraint propagation algorithms before or during search.In particular, it is well known that variable elimination algorithms such as adaptive-consistency [35] and directionalresolution [36], applied in a reversed order of d (where d is the DFS order of the pseudo tree), compile a constraintspecification (resp., a Boolean CNF formula) that has a backtrack-free search space. Assuming that the reader isfamiliar with variable elimination algorithms [16], we define:Definition 41 (directional extension [35,36]). Let R be a constraint problem and let d be a DFS traversal orderingof a backbone pseudo tree of its primal graph. We denote by Ed (R) the constraint network (resp., the CNF formula)compiled by adaptive-consistency (resp., directional resolution) in reversed order of d.Proposition 42. Given a Constraint network R, the AND/OR search tree of the directional extension Ed (R), when d isa DFS ordering of T , is identical to the backtrack-free AND/OR search tree of R based on T . Namely ST (Ed (R)) =BFT (R).Example 43. In Example 40, if we apply adaptive-consistency in reverse order of X, Y, T , R, Z, the algorithm willremove the values 3, 5 from the domains of both X and Z yielding a tighter constraint network R(cid:14). The AND/ORsearch tree in Fig. 6(c) is both ST (R(cid:14)) and BFT (R).Proposition 42 emphasizes the significance of no-good learning [37] for deciding inconsistency or for findinga single solution. These techniques are known as clause learning in SAT solvers, first introduced by [38] and arecurrently used in most advanced solvers [39]. Namely, when we apply no-good learning we explore the search spacewhose many inconsistent subtrees are pruned. For counting however, and for other relevant tasks, pruning inconsistentsubtrees and searching the backtrack-free search tree yields a partial help only, as we elaborate later.5. AND/OR search graphsIt is often the case that a search space that is a tree can become a graph if identical nodes are merged, becauseidentical nodes root identical search subspaces, and correspond to identical reasoning subproblems. Any two nodesthat root identical weighted subtrees can be merged, reducing the size search graph. For example, in Fig. 1(c), thesearch trees below any appearance of (cid:3)Y, 2(cid:4) are all identical, and therefore can be merged.Sometimes, two nodes may not root identical subtrees, but they could still root search subspaces that correspond toequivalent subproblems. Nodes that root equivalent subproblems having the same universal model (see Definition 8)even though the weighted subtrees may not be identical, can be unified, yielding an even smaller search graph, as wewill show.We next formalize the notions of merging and unifying nodes and define the minimal AND/OR search graph.5.1. Minimal AND/OR search graphsAn AND/OR search tree can also be viewed as a data structure that defines a universal graphical model (seeDefinition 8), defined by the weights of its set of solution subtrees (see Definition 22).Definition 44 (universal graphical model of AND/OR search trees). Given a weighted AND/OR search tree G over aset of variables X and domains D, its universal graphical model, denoted by U (G), is defined by its set of solutions asfollows: if t is a solution subtree and x = asgn(t) is the assignment tuple associated with t, then define u(x) = w(t);otherwise u(x) = 0.R. Dechter, R. Mateescu / Artificial Intelligence 171 (2007) 73–10687Fig. 7. Merge vs. unify operators.A graphical model R is equivalent to its AND/OR search tree, ST (R), which means that u(R) is identical toU (ST (R)). We will next define sound merge operations that transform AND/OR search trees into graphs that preserveequivalence.Definition 45 (merge). Assume a given weighted AND/OR search graph S(cid:14)T (R) can be the AND/OR searchtree ST (R)), and assume two paths π1 = πn1(xi) and π2 = πn2(xi) ending by AND nodes at level i having the samelabel xi . Nodes n1 and n2 can be merged iff the weighted search subgraphs rooted at n1 and n2 are identical. Themerge operator, merge(n1, n2), redirects all the arcs going into n2 into n1 and removes n2 and its subgraph. It thustransforms S(cid:14)T into a smaller graph. When we merge AND nodes only we call the operation AND-merge. The samereasoning can be applied to OR nodes, and we call the operation OR-merge.T (R) (S(cid:14)We next define the semantic notion of unifiable nodes, as opposed to the syntactic definition of merge.Definition 46 (unify). Given a weighted AND/OR search graph G for a graphical model R and given two paths πn1and πn2 having the same label on nodes n1 and n2, then n1 and n2 are unifiable, iff they root equivalent conditionedsubproblems (Definition 10). Namely, if R|asgn(π1) = R|asgn(π2).Example 47. Let’s follow the example in Fig. 7 to clarify the difference between merge and unify. We have a graphicalmodel defined by two functions (e.g., cost functions) over three variables. The search tree given in Fig. 7(c) cannotbe reduced to a graph by merge, because of the different arc weights. However, the two OR nodes labeled A rootequivalent conditioned subproblems (the cost of each individual solution is given at the leaves). Therefore, the nodeslabeled A can be unified, but they cannot be recognized as identical by the merge operator.Proposition 48 (minimal graph). Given a weighted AND/OR search graph G based on pseudo tree T :(1) The merge operator has a unique fix point, called the merge minimal AND/OR search graph and denoted byM mergeT(G).(2) The unify operator has a unique fix point, called the unify minimal AND/OR search graph and denoted byM unifyT(G).(3) Any two nodes n1 and n2 of G that can be merged can also be unified.Definition 49 (minimal AND/OR search graph). The unify minimal AND/OR search graph of R relative to T willalso be simply called the minimal AND/OR search graph and be denoted by MT (R).When T is a chain pseudo tree, the above definitions are applicable to the traditional OR search tree as well.However, we may not be able to reach the same compression as in some AND/OR cases, because of the linearstructure imposed by the OR search tree.88R. Dechter, R. Mateescu / Artificial Intelligence 171 (2007) 73–106Fig. 8. OR search tree for the tree problem inFig. 1(a).Fig. 9. The minimal OR search graph of thetree graphical model in Fig. 1(a).Fig. 10. AND/OR search tree for the tree problem inFig. 1(a).Fig. 11. The minimal AND/OR search graph of the tree graphicalmodel in Fig. 1(a).Example 50. The smallest OR search graph of the graph-coloring problem in Fig. 1(a) is given in Fig. 9 along theDFS order X, Y, T , R, Z, L, M. The smallest AND/OR graph of the same problem along the DFS tree is given inFig. 11. We see that some variable-value pairs (AND nodes) must be repeated in Fig. 9 while in the AND/OR casethey appear just once. In particular, the subgraph below the paths ((cid:3)X, 1(cid:4), (cid:3)Y, 2(cid:4)) and ((cid:3)X, 3(cid:4), (cid:3)Y, 2(cid:4)) in the OR treecannot be merged at (cid:3)Y, 2(cid:4). You can now compare all four search space representations side by side in Figs. 8–11.Note that in the case of constraint networks we can accommodate an even more general definition of merging oftwo AND nodes that are assigned different values from their domain, or two OR nodes labeled by different variables,as long as they root identical subgraphs. In that case the merged node should be labeled by the disjunction of the twoassignments (this is similar to interchangeable values [23]).5.2. Building AND/OR search graphsIn this subsection we will discuss practical algorithms for generating compact AND/OR search graphs of a givengraphical model. In particular we will identify effective rules for recognizing unifiable nodes, aiming towards the min-imal AND/OR search graph as much as computational resources allow. The rules allow generating a small AND/ORR. Dechter, R. Mateescu / Artificial Intelligence 171 (2007) 73–10689graph called the context minimal graph without creating the whole search tree ST first. We focus first on AND/ORsearch graphs of graphical models having no cycles, called tree models (i.e., the primal graph is a tree).5.2.1. Building AND/OR search graphs for tree models and tree decompositionsConsider again the graph in Fig. 1(a) and its AND/OR search tree in Fig. 1(c) representing a constraint network.Observe that at level 3, node (cid:3)Y, 1(cid:4) appears twice, (and so are (cid:3)Y, 2(cid:4) and (cid:3)Y, 3(cid:4)). Clearly however, the subtrees rooted ateach of these two AND nodes are identical and we can reason that they can be merged because any specific assignmentto Y uniquely determines its rooted subtree. Indeed, the AND/OR search graph in Fig. 11 is equivalent to the AND/ORsearch tree in Fig. 10 (same as Fig. 1(c)).Definition 51 (explicit AND/OR graphs for constraints tree models). Given a tree model constraint network and thepseudo tree T identical to its primal graph, the explicit AND/OR search graph of the tree model relative to T isobtained from ST by merging all AND nodes having the same label (cid:3)X, x(cid:4).Proposition 52. Given a rooted tree model T : (1) Its explicit AND/OR search graph is equivalent to ST . (2) The size ofthe explicit AND/OR search graph is O(nk). (3) For some tree models the explicit AND/OR search graph is minimal.The notion of explicit AND/OR search graph for a tree model is extendable to any general graphical models thatare trees. The only difference is that the arcs have weights. Thus, we need to show that merged nodes via the rule indefinition 51 root identical weighted AND/OR trees.Proposition 53. Given a general graphical model whose graph is a tree T , its explicit AND/OR search graph isequivalent to ST , and its size is O(nk).Next, the question is how to identify efficiently mergeable nodes for general non-tree graphical models. A guidingidea is to transform a graphical model into a tree decomposition first, and then apply the explicit AND/OR graphconstruction to the resulting tree decomposition. The next paragraph sketches this intuition.A tree decomposition [33] (see Definition 5) of a graphical model partitions the functions into clusters. Each clustercorresponds to a subproblem that has a set of solutions and the clusters interact in a tree-like manner. Once we have atree decomposition of a graphical model, it can be viewed as a regular (meta) tree model where each cluster is a nodeand its domain is the cross product of the domains of variables in the cluster. The constraint between two adjacentnodes in the tree decomposition is equality over the common variables. For more details about tree decompositionssee [33]. For the meta-tree model the explicit AND/OR search graph is well defined: the OR nodes are the scopesof clusters in the tree decomposition and the AND nodes, are their possible value assignments. Since the graphicalmodel is converted into a tree, its explicit AND/OR search graph is well defined and we can bound its size.Theorem 54. Given a tree decomposition of a graphical model, whose domain sizes are bounded by k, the explicitAND/OR search graph implied by the tree decomposition has a size of O(rkw∗), where r is the number of clusters inthe tree decomposition and w∗ is the size of the largest cluster.The tree decomposition can guide an algorithm for generating an AND/OR search graph whose size is boundedexponentially by the induced width, which we will refer to in the next section as the context minimal graph.While the idea of explicit AND/OR graph based on a tree decomposition can be extended to any graphical model,it is somewhat cumbersome. Instead, in the next section we propose a more direct approach for generating the contextminimal graph.5.2.2. The context based AND/OR graphWe will now present a generative rule for merging nodes in the AND/OR search graph that yields the size boundsuggested above. We will need the notion of induced width of a pseudo tree of G for bounding the size of the AND/ORsearch graphs. We denote by dDFS(T ) a linear DFS ordering of a tree T .Definition 55 (induced width of a pseudo tree). The induced width of G relative to the pseudo tree T , wT (G), is theinduced width along the dDFS(T ) ordering of the extended graph of G relative to T , denoted GT .90R. Dechter, R. Mateescu / Artificial Intelligence 171 (2007) 73–106Proposition 56. (1) The minimal induced width of G over all pseudo trees is identical to the induced width (treewidth),w∗, of G. (2) The minimal induced width restricted to chain pseudo trees is identical to its pathwidth, pw∗.Example 57. In Fig. 4(b), the induced graph of G relative to T1 contains also the induced arcs (1, 3) and (1, 5) andits induced width is 2. GT2 is already triangulated (no need to add induced arcs) and its induced width is 2 as well.GT3 has the added arc (4, 7) and when ordered it will have the additional induced arcs (1, 5) and (1, 3), yieldinginduced width 2 as well.We will now provide definitions that will allow us to identify nodes that can be merged in an AND/OR graph.The idea is to find a minimal set of variable assignments from the current path that will always generate the sameconditioned subproblem, regardless of the assignments that are not included in this minimal set. Since the current pathfor an OR node Xi and an AND node (cid:3)Xi, xi(cid:4) differ by the assignment of Xi to xi (Definition 2), the minimal set ofassignments that we want to identify will be different for Xi and for (cid:3)Xi, xi(cid:4). In the following two definitions ancestorsand descendants are with respect to the pseudo tree T , while connection is with respect to the primal graph G.Definition 58 (parents). Given a primal graph G and a pseudo tree T of a reasoning problem P, the parents of an ORnode Xi , denoted by pai or paXi , are the ancestors of Xi that have connections in G to Xi or to descendants of Xi .Definition 59 (parent-separators). Given a primal graph G and a pseudo tree T of a reasoning problem P, the parent-separators of Xi (or of (cid:3)Xi, xi(cid:4)), denoted by pasi or pasXi , are formed by Xi and its ancestors that have connectionsin G to descendants of Xi .It follows from these definitions that the parents of Xi , pai , separate in the primal graph G (and also in the extendedgraph GT and in the induced extended graph GT ∗) the ancestors (in T ) of Xi , from Xi and its descendants (in T ).Similarly, the parent-separators of Xi , pasi , separate the ancestors of Xi from its descendants. It is also easy to see thateach variable Xi and its parents pai form a clique in the induced graph GT ∗. The following proposition establishesthe relationship between pai and pasi .Proposition 60.(1) If Y is the single child of X in T , then pasX(2) If X has children Y1, . . . , Yk in T , then pasX= paY .(cid:3)k=i=1 paYi .Theorem 61 (context based merge). Given GT ∗graph, ending with two nodes, n1 and n2., let πn1 and πn2 be any two partial paths in an AND/OR search(1) If n1 and n2 are AND nodes annotated by (cid:3)Xi, xi(cid:4) andasgn(πn1 )[pasXi] = asgn(πn2 )[pasXi](1)then the AND/OR search subgraphs rooted by n1 and n2 are equivalent and n1 and n2 can be merged.asgn(πni )[pasXi] is called the AND context of ni .(2) If n1 and n2 are OR nodes annotated by Xi andasgn(πn1 )[paXi] = asgn(πn2 )[paXi](2)then the AND/OR search subgraphs rooted by n1 and n2 are equivalent and n1 and n2 can be merged.asgn(πni )[paXi] is called the OR context of ni .Example 62. For the balanced tree in Fig. 1 consider the chain pseudo tree d = (X, Y, T , R, Z, L, M). Namely thechain has arcs {(X, Y ), (Y, T ), (T , R), (R, Z), (Z, L), (L, M)} and the extended graph also includes the arcs (Y, T ),(Z, X) and (M, Z). The parent-separators of T along d are XY T (since the induced graph has the arc (T , X)), of Rare XR, for Z they are Z and for M they are M. Indeed in the first 3 levels of the OR search graph in Fig. 9 there areR. Dechter, R. Mateescu / Artificial Intelligence 171 (2007) 73–10691no merged nodes. In contrast, if we consider the AND/OR ordering along the DFS tree, the parent-separators of everynode are the node itself, yielding a single appearance of each AND node having the same assignment annotation inthe minimal AND/OR graph.Definition 63 (context minimal AND/OR search graph). The AND/OR search graph of R based on the backbone treeT that is closed under context-based merge operator is called context minimal AND/OR search graph and is denotedby CT (R).We should note that we can in general merge nodes based both on AND and OR contexts. However, Proposition60 shows that doing just one of them renders the other unnecessary (up to some small constant factor). In practice, wewould recommend just the OR context based merging, because it has a slight (albeit by a small constant factor) spaceadvantage. In the examples that we give in this paper, CT (R) refers to an AND/OR search graph for which either theAND context based or OR context based merging was performed exhaustively.Example 64. Consider the example given in Fig. 12(a). The OR context of each node in the pseudo tree is given insquare brackets. The context minimal AND/OR search graph (based on OR merging) is given in Fig. 12(b).Since the number of nodes in the context minimal AND/OR search graph cannot exceed the number of differentcontexts, we can bound the size of the context minimal graph.Theorem 65. Given a graphical model R, its primal graph G, and a pseudo tree T having induced width w = wT (G),the size of the context minimal AND/OR search graph based on T , CT (R), is O(n · kw), when k bounds the domainsize.Note that the criterion in Eqs. (1) and (2) is cautious. First, the real number of assignments over context variablesincludes only consistent assignments. Second, we have already seen (Example 7) that there exist nodes that can beunified but not merged. Here we give an example that shows that contexts can not identify all the nodes that can bemerged. There could be paths whose contexts are not identical, yet they might root identical subgraphs.Example 66. Let’s return to the example of the Bayesian network given in Fig. 12(a), where P (D|B, C) is given inthe table, and the OR-context of each node in the pseudo tree is given in square brackets. Fig. 12(b) shows the contextFig. 12. Context minimal vs. minimal AND/OR graphs.92R. Dechter, R. Mateescu / Artificial Intelligence 171 (2007) 73–106minimal graph. However, we can see that P (D = 0|B = 0, C = 0) = P (D = 0|B = 1, C = 0) = x and P (D = 1|B =0, C = 0) = P (D = 1|B = 1, C = 0) = y. This allows the merging of the corresponding OR nodes labeled with D,and Fig. 12(c) shows the merge minimal graph.The context based merge offers a powerful way of bounding the search complexity:Theorem 67. The context minimal AND/OR search graph CT of a graphical model having a backbone tree withbounded treewidth w can be generated in time and space O(nkw).Since the unify minimal AND/OR graph M unifyare subsets ofCT , both are bounded by O(n · kw), where w = wT (G). Since minT {wT (G)} is equal to the treewidth w∗ and sinceminT ∈chains{wT (G)} is equal to the pathwidth pw∗, we get:Corollary 68. Given a graphical model R, there exists a backbone tree T such that the unify minimal, merge minimaland context minimal AND/OR search graphs of R are bounded exponentially by the treewidth of the primal graph.The unify, merge and context minimal OR search graphs can be bounded exponentially by the pathwidth only.and the merge minimal AND/OR graph M mergeTT5.2.3. More on OR vs. AND/ORIt is well known [26] that for any graph w∗ (cid:2) pw∗ (cid:2) w∗ · log n. It is easy to place m∗ (the minimal depth overpseudo trees) in that relation yielding w∗ (cid:2) pw∗ (cid:2) m∗ (cid:2) w∗ · log n. It is also possible to show that there exist primalgraphs for which the upper bound on pathwidth is attained, that is pw∗ = O(w∗ · log n).Consider a complete binary tree of depth m. In this case, w∗ = 1, m∗ = m, and it is also known [40,41] that:Theorem 69. [41] If T is a binary tree of depth m then pw∗(T ) (cid:3) m2 .Theorem 69 shows that for graphical models having a bounded tree width w, the minimal AND/OR graph isbounded by O(nkw) while the minimal OR graph is bounded by O(nkw·log n). Therefore, even when caching, the useof an AND/OR vs. an OR search space can yield a substantial saving.Remark 70. We have seen that AND/OR trees are characterized by the depth of the pseudo trees while minimalAND/OR graphs are characterized by their induced width. It turns out however that sometimes a pseudo tree that isoptimal relative to w is far from optimal for m and vice versa. For example a primal graph model that is a chain hasa pseudo tree having m1 = n and w1 = 1 on one hand, and another pseudo tree that is balanced having m2 = log nand w2 = log n. There is no single pseudo tree having both w = 1 and m = log n for a chain. Thus, if we plan tohave linear space search we should pick one kind of a backbone pseudo tree, while if we plan to search a graph, andtherefore cache some nodes, another pseudo tree should be used.5.3. On the canonicity and generation of the minimal AND/OR graphWe showed that the merge minimal AND/OR graph is unique for a given graphical model, given a backbone pseudotree (Proposition 48). In general, it subsumes the minimal AND/OR graph, and sometimes can be identical to it. Forconstraint networks we will now prove a more significant property of uniqueness relative to all equivalent graphicalmodels given a backbone tree. We will prove this notion relative to backtrack-free search graphs which are capturedby the notion of strongly minimal AND/OR graph. Remember that any graphical model can have an associated flatconstraint network.Definition 71 (strongly minimal AND/OR graph3). A strongly minimal AND/OR graph of R relative to a pseudo treeT is the minimal AND/OR graph, MT (R), that is backtrack-free (i.e., any partial assignment in the graph leads to asolution), denoted by M ∗T (R). The strongly (backtrack-free) context minimal graph is denoted C∗T (R).3 The minimal graph is built by lumping together “unifiable” nodes, which are those that root equivalent subproblems. Therefore, at each level(corresponding to one variable), all the nodes that root inconsistent subproblems will be unified. If we eliminate the redundant nodes, the minimalgraph is already backtrack free.R. Dechter, R. Mateescu / Artificial Intelligence 171 (2007) 73–106935.3.1. Canonicity of strongly minimal AND/OR search graphsWe briefly discuss here the canonicity of the strongly minimal graph, focusing on constraint networks. Given twoequivalent constraint networks representing the same set of solutions, where each may have a different constraintgraph, are their strongly minimal AND/OR search graphs identical?The above question is not well defined however, because an AND/OR graph for R is defined only with respect toa backbone pseudo tree. We can have two equivalent constraint networks having two different graphs where a pseudotree for one graph may not be a pseudo tree for the other. Consider, for example a constraint network having threevariables: X, Y and Z and equality constraints. The following networks, R1 = {RXY = (X = Y ), RY Z = (Y = Z)}and R2 = {RXZ = (X = Z), RY Z = (Y = Z)} and R3 = {RXY = (X = Y ), RY Z = (Y = Z), RXZ = (X = Z)} areequivalent. However, T1 = (X ← Y → Z) is a pseudo tree for R1, but not for R2 neither for R3. We ask therefore adifferent question: given two equivalent constraint networks and given a backbone tree that is a pseudo tree for both,is the strongly minimal AND/OR graph relative to T unique?We will answer this question positively quite straightforwardly. We first show that equivalent networks that sharea backbone tree have identical backtrack-free AND/OR search trees. Since the backtrack-free search trees uniquelydetermine their strongly minimal graph the claim follows.Definition 72 (shared pseudo trees). Given a collection of graphs on the same set of nodes, we say that the graphsshare a tree T , if T is a pseudo tree of each of these graphs. A set of graphical models defined over the same set ofvariables share a tree T , iff their respective primal graphs share T .Proposition 73. (1) If R1 and R2 are two equivalent constraint networks that share T , then BFT (R1) = BFT (R2)(see Definition 39). (2) If R1 and R2 are two equivalent graphical models (not necessarily constraint networks) thatshare T , then BFT (R1) = BFT (R2) as AND/OR search trees although their arcs may not have identical weights.Theorem 74. If R1 and R2 are two equivalent constraint networks that share T , then M ∗T (R1) = M ∗T (R2).Theorem 74 implies that M ∗T is a canonical representation of a constraint network R relative to T .Generating the strongly minimal AND/OR graphsFrom the above discussion we see that several methods for generating the canonical AND/OR graph of a givengraphical model, or a given AND/OR graph may emerge. The method we focused on in this paper is to generate thecontext minimal AND/OR graph first. Then we can process this graph from leaves to root, while computing the valueof nodes, and additional nodes can be unified or pruned (if their value is “0”).There is another approach that is based on processing the functions in a variable elimination style, when viewingthe pseudo tree as a bucket tree or a cluster tree. The original functions can be expressed as AND/OR graphs andthey will be combined pairwise until an AND/OR graph is generated. This phase allows computing the value of eachnode (see Section 6) and therefore allows for unification. Subsequently a forward phase will allow generating thebacktrack-free representation as well as allow computing the full values associated with each node. The full details ofthis approach are out of the scope of the current paper. For initial work restricted to constraint networks see [42].5.4. Merging and pruning: Orthogonal conceptsNotice that the notion of minimality is orthogonal to that of pruning inconsistent subtrees (yielding the backtrack-free search space). We can merge two identical subtrees whose root value is “0” but still keep their common subtree.However, since our convention is that we don’t keep inconsistent subtrees we should completely prune them, irrespec-tive of them rooting identical or non-identical subtrees. Therefore, we can have a minimal search graph that is notbacktrack-free as well as a non-minimal search graph (e.g., a tree) that is backtrack-free.When the search space is backtrack-free and if we seek a single solution, the size of the minimal AND/OR searchgraph and its being OR vs. AND/OR are both irrelevant. It will, however, affect a traversal algorithm that counts allsolutions or computes an optimal solution as was often observed [43]. For counting and for optimization tasks, even94R. Dechter, R. Mateescu / Artificial Intelligence 171 (2007) 73–106Fig. 13. AND/OR trees.Fig. 14. AND/OR graphs.Fig. 15. (a) A constraint graph; (b) a spanning tree; (c) a dynamic AND/OR tree.when we record all no-goods and cache all nodes by context, the impact of the AND/OR graph search vs. the ORgraph search can still be significant.Example 75. Consider the graph problem in Fig. 6(a) when we add the value 4 to the domains of X and Z. Fig. 13(a)gives the full AND/OR search tree and Fig. 13(b) gives the backtrack-free search tree. Fig. 14(a) gives the contextminimal but unpruned search graph and Fig. 14(b) gives the minimal and pruned search graph.5.5. Using dynamic variable orderingThe AND/OR search tree we defined uses a fixed variable ordering. It is known that exploring the search space ina dynamic variable ordering is highly beneficial. AND/OR search trees for graphical models can also be modified toallow dynamic variable ordering. A dynamic AND/OR tree that allows varied variable ordering has to satisfy that forevery subtree rooted by the current path π , any arc of the primal graph that appears as a cross-arc (not a back-arc) inthe subtree must be “inactive” conditioned on π .Example 76. Consider the propositional formula X → A ∨ C and X → B ∨ C. The constraint graph is given inFig. 15(a) and a DFS tree in 15(b). However, the constraint subproblem conditioned on (cid:3)X, 0(cid:4), has no real constraintR. Dechter, R. Mateescu / Artificial Intelligence 171 (2007) 73–10695between A, B, C, so the effective spanning tree below (cid:3)X, 0(cid:4) is {(cid:3)X, 0(cid:4) → A, (cid:3)X, 0(cid:4) → B, (cid:3)X, 0(cid:4) → C}, yielding theAND/OR search tree in Fig. 15(c). Note that while there is an arc between A and C in the constraint graph, the arc isnot active when X is assigned the value 0.Clearly, the constraint graph conditioned on any partial assignment can only be sparser than the original graphand therefore may yield a smaller AND/OR search tree than with fixed ordering. In practice, after each new valueassignment, the conditional constraint graph can be assessed as follows. For any constraint over the current variable X,if the current assignment (cid:3)X, x(cid:4) does not make the constraint active then the corresponding arcs can be removed fromthe graph. Then, a pseudo tree of the resulting graph is generated, its first variable is selected, and search continues.A full investigation of dynamic orderings is outside the scope of the current paper.6. Solving reasoning problems6.1. Value functions of reasoning problemsAs we described earlier, there are a variety of reasoning problems over weighted graphical models. For constraintnetworks, the most popular tasks are to decide if the problem is consistent, to find a single solution or to countsolutions. If there is a cost function defined we may also seek an optimal solution. The primary tasks over probabilisticnetworks are belief updating, finding the probability of the evidence and finding the most likely tuple given theevidence. Each of these reasoning problems can be expressed as finding the value of some nodes in the weightedAND/OR search space where different tasks call for different value definitions. For example, for the task of findinga solution to a constraint network, the value of every node is either “1” or “0”. The value “1” means that the subtreerooted at the node is consistent and “0” otherwise. Therefore, the value of the root node answers the consistency query.For solutions-counting the value function of each node is the number of solutions rooted at that node.Definition 77 (value function for consistency and counting). Given a weighted AND/OR tree ST (R) of a constraintnetwork: The value of a node (AND or OR) for deciding consistency is “1” if it roots a consistent subproblem and “0”otherwise; The value of a node (AND or OR) for counting solutions is the number of solutions in its subtree.It is easy to see that the value of nodes in the search graph can be computed recursively from leaves to root.Proposition 78 (recursive value computation). (1) For the consistency task the value of AND leaves is their labels andthe value of OR leaves is “0” (they are inconsistent). An internal OR node is labeled “1” if one of its successor nodesis “1” and an internal AND node has value “1” iff all its successor OR nodes have value “1”.(2) The counting values of leaf AND nodes are “1” and of leaf OR nodes are “0”. The counting value of an internalOR node is the sum of the counting values of all its child nodes. The counting value of an internal AND node is theproduct of the counting values of all its child nodes.We can now generalize to any reasoning problem, focusing on the simplified case when Z = ∅, namely when themarginalization has to be applied to all the variables. This special case captures most tasks of interest. We will startwith the recursive definition.Definition 79 (recursive definition of values). The value function of a reasoning problem P = (cid:3)R, ⇓Y , Z(cid:4), whereR = (cid:3)X, D, F, ⊗(cid:4) and Z = ∅, is defined as follows: the value of leaf AND nodes is “1” and of leaf OR nodes is “0”.The value of an internal OR node is obtained by combining the value of each AND child node with the weight (seeDefinition 26) on its incoming arc and then marginalizing over all AND children. The value of an AND node is thecombination of the values of its OR children. Formally, if children(n) denotes the children of node n in the AND/ORsearch graph, then:(cid:7)v(n) =v(n(cid:14)),if n = (cid:3)Y, y(cid:4) is an AND node,n(cid:14)∈children(n)v(n) =⇓X−({Y }∪children(n))(cid:11)w(n,n(cid:14)) ⊗ v(n(cid:14)(cid:12)n(cid:14)∈children(n),)if n = Y is an OR node.96R. Dechter, R. Mateescu / Artificial Intelligence 171 (2007) 73–106The following proposition states that given a reasoning task, computing the value of the root node solves the givenreasoning problem.Proposition 80. Let P = (cid:3)R, ⇓Y , Z(cid:4), where R = (cid:3)X, D, F, ⊗(cid:4) and Z = ∅, and let X1 be the root node in anyAND/OR search graph S(cid:14)(cid:4)ri=1 fi when v is defined in Definition 79.T (R). Then v(X1) =⇓∅Search algorithms that traverse the AND/OR search space can compute the value of the root node yielding the an-swer to the problem. The following section discusses such algorithms. Algorithms that traverse the weighted AND/ORsearch tree in a depth-first manner or a breadth-first manner are guaranteed to have a time bound exponential in thedepth of the pseudo tree of the graphical model. Depth-first searches can be accomplished using either linear spaceonly, or context based caching, bounded exponentially by the treewidth of the pseudo tree. Depth-first search is ananytime scheme and can, if terminated, provide an approximate solution for some tasks such as optimization. The nextsubsection presents typical depth-first algorithms that search AND/OR trees and graphs. We use solution counting asan example for a constraint query and the probability of evidence as an example for a probabilistic reasoning query.The algorithms compute the value of each node. For application of these ideas for combinatorial optimization tasks,such as MPE, see [31].6.2. Algorithm AND/OR tree search and graph searchAlgorithm 1 presents the basic depth-first traversal of the AND/OR search tree (or graph, if caching is used) forcounting the number of solutions of a constraint network, AO-COUNTING (or for probability of evidence for beliefnetworks, AO-BELIEF-UPDATING).The context based caching is done based on tables. We exemplify with OR caching. For each variable Xi , a tableis reserved in memory for each possible assignment to its parent set pai . Initially each entry has a predefined value, inour case “−1”. The fringe of the search is maintained on a stack called OPEN. The current node is denoted by n, itsparent by p, and the current path by πn. The children of the current node are denoted by successors(n).The algorithm is based on two mutually recursive steps: EXPAND and PROPAGATE, which call each other (orthemselves) until the search terminates.Since we only use OR caching, before expanding an OR node, its cache table is checked (line 6). If the same contextwas encountered before, it is retrieved from cache, and successors(n) is set to the empty set, which will trigger thePROPAGATE step.If a node is not found in cache, it is expanded in the usual way, depending on whether it is an AND or OR node(lines 10–17). The only difference between counting and belief updating is line 12 vs. line 13. For counting, the valueof a consistent AND node is initialized to 1 (line 12), while for belief updating, it is initialized to the bucket value forthe current assignment (line 13). As long as the current node is not a dead-end and still has unevaluated successors,one of its successors is chosen (which is also the top node on OPEN), and the expansion step is repeated.The bottom up propagation of values is triggered when a node has an empty set of successors (note that as eachsuccessor is evaluated, it is removed from the set of successors in line 31). This means that all its children have beenevaluated, and its final value can now be computed. If the current node is the root, then the search terminates with itsvalue (line 20). If it is an OR node, its value is saved in cache before propagating it up (line 22). If n is OR, then itsparent p is AND and p updates its value by multiplication with the value of n (line 24). If the newly updated valueof p is 0 (line 25), then p is a dead-end, and none of its other successors needs to be evaluated. An AND node npropagates its value to its parent p in a similar way, only by summation (line 30). Finally, the current node n is setto its parent p (line 32), because n was completely evaluated. The search continues either with a propagation step (ifconditions are met) or with an expansion step.6.3. General AND-OR search—AO(i)General AND/OR algorithms for evaluating the value of a root node for any reasoning problem using tree or graphAND/OR search are identical to the above algorithms when product is replaced by the combination operator andR. Dechter, R. Mateescu / Artificial Intelligence 171 (2007) 73–10697Algorithm 1. AO-counting/AO-belief-updating.summation is replaced by the marginalization operator. We can view the AND/OR tree algorithm (which we willdenote AOT) and the AND/OR graph algorithm (denoted AOG) as two extreme cases in a parameterized collection ofalgorithms that trade space for time via a controlling parameter i. We denote this class of algorithms as AO(i) wherei determines the size of contexts that the algorithm caches. Algorithm AO(i) records nodes whose context size is i orsmaller (the test in line 22 needs to be a bit more elaborate and check if the context size is smaller than i). Thus AO(0)is identical to AOT, while AO(w) is identical to AOG, where w is the induced width of the used backbone tree. Forany intermediate i we get an intermediate level of caching, which is space exponential in i and whose execution timewill increase as i decreases.6.4. ComplexityFrom Theorems 34 and 38 we can conclude that:Theorem 81. For any reasoning problem, AOT runs in linear space and time O(nkm), when m is the depth of thepseudo tree of its graphical model and k is the maximum domain size. If the primal graph has a tree decompositionwith treewidth w∗, there exists a pseudo tree T for which AOT is O(nkw∗·log n).98R. Dechter, R. Mateescu / Artificial Intelligence 171 (2007) 73–106Obviously, the algorithm for constraint satisfaction, that would terminate early with first solution, would potentiallybe much faster than the rest of the AOT algorithms, in practice.Based on Theorem 65 we get complexity bounds for graph searching algorithms.Theorem 82. For any reasoning problem, the complexity of algorithm AOG is time and space O(nkw), where w isthe induced width of the pseudo tree and k is the maximum domain size.Thus the complexity of AOG can be time and space exponential in the treewidth, while the complexity of anyalgorithm searching the OR space can be time and space exponential in its pathwidth. The space complexity can oftenbe less than exponential in the treewidth. This is similar to the well known space complexity of tree decompositionschemes which can operate in space exponential only in the size of the cluster separators, rather than exponential inthe cluster size. It is also similar to the dead caches concept presented in [12,32]. Intuitively, a node that has only oneincoming arc will only be traversed once by search, and therefore its value does not need to be cached, because it willnever be used again. For context based caching, such nodes can be recognized based only on the parents (or parentseparators) sets.Definition 83 (dead cache). If X is the parent of Y in T , and paX⊂ paY , then paY is a dead cache.Given a pseudo tree T , the induced graph along T can generate a tree decomposition based on the maximal cliques.The maximum separator size of the tree decomposition is the separator size of T .Proposition 84. The space complexity of graph-caching algorithms can be reduced to being exponential in the sepa-rator’s size only, while still being time exponential in the treewidth, if dead caches are not recorded.7. AND/OR search spaces and other schemes7.1. Relationship with Variable EliminationA comparison between Variable Elimination and memory intensive AND/OR search appears in [44]. That papershows that Variable Elimination can be understood as bottom up layer by layer traversal of the context minimalAND/OR search graph. If the graphical model is strictly positive (has no determinism), then context based AND/ORsearch and Variable Elimination are essentially identical. When determinism is present, they may differ, becausethey traverse the AND/OR graph in different directions and encounter determinism (and can take advantage of it)differently. Therefore, for graphical models with no determinism, there is no principled difference between memory-intensive AND/OR search with fixed variable ordering and inference beyond: (1) different direction of exploring acommon search space (top down for search vs. bottom up for inference); (2) different assumption of control strategy(depth-first for search and breadth-first for inference).Another interesting observation is that many known advanced algorithms for constraint processing and satisfiabilitycan be explained as traversing the AND/OR search tree, e.g. graph based backjumping [3,8,37]. For more details werefer the reader to [44].7.2. Relationship with BTD (backtracking with tree-decomposition)BTD [10] is a memory intensive method for solving constraint satisfaction problems, which combines searchtechniques with the notion of tree decomposition. This mixed approach can in fact be viewed as searching an AND/ORgraph, whose backbone pseudo tree is defined by and structured along the tree decomposition. What is defined in [10]as structural goods, that is parts of the search space that would not be visited again as soon as their consistency isknown, corresponds precisely to the decomposition of the AND/OR space at the level of AND nodes, which rootindependent subproblems. Not surprisingly, the time and space guarantees of BTD are the same as those of AND/ORgraph search. An optimization version of the algorithm is presented in [11].R. Dechter, R. Mateescu / Artificial Intelligence 171 (2007) 73–10699Fig. 16. Dtrees and AND/OR pseudo-trees.7.3. Relationship with Recursive ConditioningRecursive Conditioning (RC) [12] is based on the divide and conquer paradigm. Rather than instantiating variablesto obtain a tree structured network like the cycle cutset scheme, RC instantiates variables with the purpose of breakingthe network into independent subproblems, on which it can recurse using the same technique. The computation isdriven by a data-structure called dtree, which is a full binary tree, the leaves of which correspond to the networkCPTs.It can be shown that RC explores an AND/OR space. Let’s start with the example in Fig. 16, which shows:(a) a belief network; (b) and (c), two dtrees and the corresponding pseudo-trees for the AND/OR search. The dtreesalso show the variables that are instantiated at some of the internal nodes. The pseudo-trees can be generated fromthe static ordering of RC dictated by the dtree. This ensures that whenever RC splits the problem into independentsubproblems, the same happens in the AND/OR space. It can also be shown that the context of the nodes in RC, asdefined in [12] is identical to that in AND/OR.7.4. Relationship with Value EliminationValue Elimination [13] is a recently developed algorithm for Bayesian inference. It was already explained in [13]that, under static variable ordering, there is a strong relation between Value Elimination and Variable Elimination.From our paragraph on the relation between AND/OR search and Variable Elimination we can derive the connectionbetween Value Elimination and AND/OR search, under static orderings. But we can also analyze the connectiondirectly. Given a static ordering d for Value Elimination, we can show that it actually traverses an AND/OR space.The pseudo-tree underlying the AND/OR search graph traversal by Value Elimination can be constructed as the buckettree in reversed d. However, the traversal of the AND/OR space will be controlled by d, advancing the frontier in ahybrid depth or breadth-first manner.The most important part to analyze is the management of goods. When Value Elimination computes a factor at aleaf node, it backs up the value to the deepest node in the dependency set Dset. The Dset is identical to the contextin the AND/OR space. For clarity reasons, we chose to have the AND/OR algorithm back up the value to its parent inthe pseudo-tree, which may be different than the deepest variable in the context. We can however accommodate thepropagation of the value like in Value Elimination, and maintain bookkeeping of the summation set Sset, and thiswould amount to a constant factor saving. Value Elimination continues by unionizing Dsets and Ssets whenevervalues are propagated, and this is identical to computing the context of the corresponding node in the AND/OR space(which is in fact the induced ancestor set of graph-based backjumping [45]).In the presence of determinism, any backjumping strategy and nogood learning used by Value Elimination can alsobe performed in the AND/OR space. Context specific structure that can be used by Value Elimination, can also beused in AND/OR. Dynamic variable orderings can also be used in AND/OR spaces, but in this paper we limit thediscussion to static orderings.100R. Dechter, R. Mateescu / Artificial Intelligence 171 (2007) 73–1067.5. Relationship with case-factor diagramsCase-Factor Diagrams (CFD) were introduced in [20] and represent a probabilistic formalism subsuming Markovrandom fields of bounded treewidth and probabilistic context free grammars. Case-factor diagrams are based on avariant of BDDs (binary decision diagram [17]) with both zero suppression and “factor nodes”. Factor nodes areanalogous to the AND nodes in an AND/OR search space. A case-factor diagram can be viewed as an AND/ORsearch space in which each outgoing arc from an OR node is explicitly labeled with an assignment of a value to avariable. Zero suppression is used to fix the value of variables not mentioned in a given solution. Zero suppressionallows the formalism to concisely represent probabilistic context free grammars as functions from variable-valueassignments to log probabilities (or energies).7.6. AND/OR-search graphs and compilationThe authors have proposed in [42] the compilation of constraint networks into AND/OR Multi-Valued DecisionDiagrams (AOMDDs). This is essentially the strongly minimal AND/OR graph representation of a constraint networkwith redundant variables removed for conciseness. An algorithm that achieves this is structurally similar to VariableElimination. It uses a bottom up traversal of a bucket tree, and at each node an APPLY operator is used to combineall the AOMDDs of the bucket into another AOMDD. The APPLY is similar to the OBDD apply operator [17], butis adapted for AND/OR structures. Essentially, the AOMDD extends an OBDD (or a multi-valued decision diagram)with an AND/OR structure.7.6.1. Relationship with d-DNNFAn AND/OR structure restricted to propositional theories is very similar to d-DNNF [18]. One can show a one-to-one linear translation from an AND/OR bi-valued tree of a propositional CNF theory into a d-DNNF. The AND/ORstructure is more restrictive allowing disjunction only on the variable’s value while in d-DNNF disjunction is allowedon more complex expressions; see [46] for implications of this distinction. The AND/OR search graph is built on topof a graphical model and can be viewed as a compiled scheme of a CNF into an AND/OR structure. Since an AND/ORsearch can be expressed as a d-DNNF, the construction via pseudo tree yields a scheme for d-DNNF compilation. Inother words, given a CNF theory, the algorithm can be applied using a pseudo tree to yield an AND/OR graph, whichcan be transformed in linear time and space into a d-DNNF.Conversely, given a d-DNNF that is specialized to variable-based disjunction for OR nodes, it is easy to createan AND/OR graph or a tree that is equivalent having a polynomially equivalent size. The AND/OR search graph forprobabilistic networks is also closely related to algebraic circuits of probabilistic networks [19] which is an extensionof d-DNNF to this domain.7.6.2. Relationship with OBDDsThe notion of minimal OR search graphs is also similar to the known concept of Ordered Binary Decision Diagrams(OBDD) in the literature of hardware and software design and verification The properties of OBDDs were studiedextensively in the past two decades [17,47].It is well known that the size of the minimal OBDD is bounded exponentially by the pathwidth of the CNF’s primalgraph and that the OBDD is unique for a fixed variable ordering. Our notion of backtrack-free minimal AND/ORsearch graphs, if applied to CNFs, resembles tree BDDs [48]. Minimal AND/OR graphs are also related to Graph-driven BDDs (called G-FBDD) [49,50] in that they are based on a partial order expressed in a directed graph. Still,a G-FBDD has an OR structure, whose ordering is restricted to some partial orders, but not an AND/OR structure.For example, the OBDD based on a DFS ordering of a pseudo tree is a G-FBDD. Some other relationships betweengraphical model compilation and OBDDs were studied in [18].In summary, putting OBDDs within our terminology, an OBDD representation of a CNF formula is a stronglyminimal OR search graph where redundant nodes are removed.7.6.3. Relationship with tree-driven automataFargier and Vilarem [21] proposed the compilation of CSPs into tree-driven automata, which have many similaritiesto the work in [42]. In particular, the compiled tree-automata proposed there is essentially the same as the AND/ORR. Dechter, R. Mateescu / Artificial Intelligence 171 (2007) 73–106101multi-valued decision diagram. Their main focus is the transition from linear automata to tree automata (similar tothat from OR to AND/OR), and the possible savings for tree-structured networks and hyper-trees of constraints dueto decomposition. Their compilation approach is guided by a tree-decomposition while ours is guided by a variable-elimination based algorithms. And, it is well known that Variable Elimination and cluster-tree decomposition are, inprinciple, the same [24].7.7. Relationship with disjoint support decompositionThe work on Disjoint Support Decompositions (DSD) [22] was proposed in the area of design automation [51],as an enhancement for BDDs aimed at exploiting function decomposition. The main common aspect of DSD andAOMDD [42] is that both approaches show how structure decomposition can be exploited in a BDD-like represen-tation. DSD is focused on Boolean functions and can exploit more refined structural information that is inherent toBoolean functions. In contrast, AOMDDs assume only the structure conveyed in the constraint graph, and are thereforemore broadly applicable to any constraint expression and also to graphical models in general. They allow a simplerand higher level exposition that yields graph-based bounds on the overall size of the generated AOMDD.7.7.1. Relationship with semi-ring BDDsIn recent work [23] OBDDs were extended to semi-ring BDDs. The semi-ring treatment is restricted to the ORsearch spaces, but allows dynamic variable ordering. It is otherwise very similar in aim and scope to our stronglyminimal AND/OR graphs. When restricting the strongly minimal AND/OR graphs to OR graphs only, the two areclosely related, except that we express BDDs using the Shenoy–Shafer axiomatization that is centered on the twooperation of combination and marginalization rather then on the semi-ring formulation. Minimality in the formulationin [23] is more general allowing merging nodes having different values and therefore can capture symmetries (calledinterchangeability).8. ConclusionsThe primary contribution of this paper is in viewing search for graphical models in the context of AND/OR searchspaces rather than OR spaces. We introduced the AND/OR search tree, and showed that its size can be boundedexponentially by the depth of its pseudo tree over the graphical model. This implies exponential savings for any linearspace algorithms traversing the AND/OR search tree. Specifically, if the graphical model has treewidth w∗, the depthof the pseudo tree is O(w∗ · log n).The AND/OR search tree was extended into a graph by merging identical subtrees. We showed that the size ofthe minimal AND/OR search graph is exponential in the treewidth while the size of the minimal OR search graphis exponential in the pathwidth. Since for some graphs the difference between treewidth and pathwidth is substantial(e.g., balanced pseudo trees) the AND/OR representation implies substantial time and space savings for memory in-tensive algorithms traversing the AND/OR graph. Searching the AND/OR search graph can be implemented by goodscaching during search, while no-good recording is interpreted as pruning portions of the search space independent ofit being a tree or a graph, an OR or an AND/OR. For finding a single solution, pruning the search space is the mostsignificant action. For counting and probabilistic inference, using AND/OR graphs can be of much help even on topof no-good recording.We observe that many known advanced algorithms for constraint processing and satisfiability can be explainedas traversing the AND/OR search tree (e.g., backjumping [3,8,37]). Also, recent algorithms in probabilistic reason-ing such as Recursive Conditioning [12] and Value Elimination [13] can operate in linear space and can be viewedas searching the AND/OR search tree. In their memory intensive mode, these algorithms were noted to search theAND/OR graph, having similar time and space complexities. Also, as noted, recent work [10] proposes search guidedby a tree decomposition either for constraint satisfaction or optimization, and is searching the AND/OR search graph,whose pseudo tree is constructed along the tree decomposition.102R. Dechter, R. Mateescu / Artificial Intelligence 171 (2007) 73–106AcknowledgementsThis work was supported in part by the NSF grant IIS-0412854 and by the MURI ONR award N00014-00-1-0617.Appendix A. ProofsProof of Theorem 29 (correctness). 1) By definition, all the arcs of ST (R) are consistent. Therefore, any solutiontree of ST (R) denotes a solution for R whose assignments are all the labels of the AND nodes in the solution tree.Also, by definition of the AND/OR tree, every solution of R must corresponds to a solution subtree in ST (R). 2) Byconstruction, the arcs in every solution tree have weights such that each function of F contributes to one and only oneweight via the combination operator. Since the total weight of the tree is derived by combination, it yields the cost ofa solution.Proof of Theorem 30 (size bounds of AND/OR search tree). Let p be an arbitrary directed path in the DFS tree Tthat starts with the root and ends with a leaf. This path induces an OR search subtree which is included in the AND/ORsearch tree ST , and its size is O(km), when m bounds the path length. The DFS tree T is covered by l such directedpaths, whose lengths are bounded by m. The union of their individual search trees covers the whole AND/OR searchtree ST , where every distinct full path in the AND/OR tree appears exactly once, and therefore, the size of theAND/OR search tree is bounded by O(l · km). Since l (cid:2) n and l (cid:2) bm, it concludes the proof.Proof of Proposition 31. The proof is similar to that of Theorem 30, only each node contributes with its actualdomain size rather than the maximal one, and each path to a leaf in T contributes with its actual depth, rather than themaximal one.Proof of Theorem 34 (properties of AND/OR search trees). All the arguments in the proof of Theorem 29 carryimmediately to AND/OR search spaces that are defined relative to a pseudo tree. Likewise, the bound size argumentin the proof of Theorem 30 holds relative to the depth of the more general pseudo tree.Proof of Proposition 42. First, we should note that if T is a pseudo tree of R and if d is a DFS ordering of T ,then T is also a pseudo tree of Ed (R) and therefore ST (Ed (R)) is a faithful representation of Ed (R). Ed (R) isequivalent to R, therefore ST (Ed (R)) is a supergraph of BFT (R). We only need to show that ST (Ed (R)) doesnot contain any dead-ends, in other words any consistent partial assignment must be extendable to a solution of R.Adaptive consistency makes Ed (R) strongly directional w∗(d) consistent, where w∗(d) is the induced width of Ralong ordering d [35]. It follows from this that either R is inconsistent, in which case the proposition is triviallysatisfied, both trees being empty, or else any consistent partial assignment in ST (Ed (R)) can be extended to the nextvariable in d, and therefore no dead-end is encountered.Proof of Proposition 48 (minimal graph). (1) All we need to show is that the merge operator is not dependent onthe order of applying the operator. Mergeable nodes can only appear at the same level in the AND/OR graph. Lookingat the initial AND/OR graph, before the merge operator is applied, we can identify all the mergeable nodes per level.We prove the proposition by showing that if two nodes are initially mergeable, then they must end up merged after theoperator is applied exhaustively to the graph. This can be shown by induction over the level where the nodes appear.Base case: If the two nodes appear at the leaf level (level 0), then it is obvious that the exhaustive merge has tomerge them at some point.Inductive step: Suppose our claim is true for nodes up to level k and two nodes n1 and n2 at level k + 1 areinitially identified as mergeable. This implies that, initially, their corresponding children are identified as mergeable.These children are at level k, so it follows from the inductive hypothesis that the exhaustive merge has to merge thecorresponding children. This in fact implies that nodes n1 and n2 will root the same subgraph when the exhaustivemerge ends, so they have to end up merged. Since the graph only becomes smaller by merging, based on the abovethe process of merging has to stop at a fix point.(2) Analogous to (1). (3) If the nodes can be merged, it follows that the subgraphs are identical, which implies thatthey define the same conditioned subproblems, and therefore the nodes can also be unified.R. Dechter, R. Mateescu / Artificial Intelligence 171 (2007) 73–106103Proof of Proposition 52. Parts 1 and 2 follow from definitions. Regarding claim 3, for the graph coloring problem inFig. 1(a), the minimal AND-OR search graph is identical to its explicit AND/OR search graph, GT (see Fig. 11).Proof of Proposition 53. In tree models, the functions are only over two variables. Therefore, after an assignment(cid:3)X, x(cid:4) is made and the appropriate weight is given to the arc from X to (cid:3)X, x(cid:4), the variable X and all its ancestors inthe pseudo tree do not contribute to any arc weight below in the AND/OR search tree. Therefore, the conditionedsubproblems rooted at any AND node labeled by (cid:3)X, x(cid:4) depend only on the assignment of X to x (and do notdepend on any other assignment on the current path), so it follows that all the AND nodes labeled by (cid:3)X, x(cid:4) can bemerged. Since the equivalence of AND/OR search spaces is preserved by merge, the explicit AND/OR search graphis equivalent to ST . At each AND level in the explicit graph there are at most k values, and therefore its size is O(nk).Proof of Theorem 54. The size of an explicit AND/OR graph of a tree model was shown to be O(nk) (Proposi-tion 52), yielding O(r · kw∗) size for the explicit AND/OR graph, because k is replaced by kw∗, the number of possibleassignments to a cluster of scope size w∗, and r replaces n.Proof of Proposition 56. (1) The induced width of G relative to a given pseudo tree is always greater than w∗, bydefinition of w∗. It remains to show that there exists a pseudo tree T such that wT (G) = w∗. Consider an orderingd that gives the induced width w∗. The ordering d defines a bucket tree BT (see Definition 36), which can also beviewed as a pseudo tree for the AND/OR search, therefore wBT (G) = w∗. (2) Analogous to (1).Proof of Proposition 60. Both claims follow directly from Definitions 58 and 59.Proof of Theorem 61 (context based merge). (1) The conditioned graphical models (Definition 10) at n1 and n2are defined by the functions whose scopes are not fully assigned by πn1 and πn2 . Since n1 and n2 have the samelabeling (cid:3)Xi, xi(cid:4), it follows that var(πn1 ) = var(πn2 ), and therefore the two conditioned subproblems are based onthe same set of functions, let’s call it F |var(πn1 ). The scopes of functions in F |var(πn1 ) determine connections in theprimal graph between ancestors of Xi and its descendants. Therefore, the only relevant variables that define therestricted subproblems are those in pasi , and Eq. (1) ensures that they have identical assignments. It follows that theconditioned subproblems are identical, and n1 and n2 can be merged.(2) Analogous to (1).Proof of Theorem 65. The number of different nodes in the context minimal AND/OR search graph, CT , does notexceed the number of contexts. From Eqs. (1) and (2) we see that, for any variable, the number of contexts is boundedby the number of possible instantiations of the largest context in GT ∗, which is bounded by O(kw). For all the nvariables, the bound O(n · kw) follows.Proof of Theorem 67. We can generate CT using depth-first or breadth-first search which caches all nodes via theircontexts and avoids generating duplicate searches for the same contexts. Therefore, the generation of the search graphis linear in its size, which is exponential in w and linear in n.Proof of Proposition 73. Let B1 = BFT (R1) and B2 = BFT (R2) be the corresponding backtrack-free AND/ORsearch trees of R1 and R2, respectively. Namely, BFT (R1) ⊆ ST (R1), BFT (R2) ⊆ ST (R2). Clearly they are sub-trees of the same full AND/OR tree. We claim that a path appears in B1 iff it appears in B2. If not, assume withoutloss of generality that there exists a path in B1, π , which does not exists in B2. Since this is a backtrack-free searchtree, every path appears in some solution and therefore there is a solution subtree in B1 that includes π which doesnot exist in B2, contradicting the assumption that R1 and R2 have the same set of solutions. The second part has anidentical proof based on flat functions (see introduction to Section 3).Proof of Theorem 74. From Proposition 73 we know that R1 and R2 have the same backtrack-free AND/ORtree. Since the backtrack-free AND/OR search tree for a backbone tree T uniquely determines the strongly mini-mal AND/OR graph, the theorem follows.104R. Dechter, R. Mateescu / Artificial Intelligence 171 (2007) 73–106Proof of Proposition 78 (recursive value computation). The proof is by induction over the number of levels in theAND/OR graph.Basis step: If the graph has only two levels, one OR and one AND, then the claim is straightforward because theAND leaves are labeled by “1” if consistent and the OR node accumulates “1” or the sum of consistent values below,or “0” if there is no consistent value.Inductive step: Assuming the proposition holds for k pairs of levels (one AND and one OR in each pair), provingit holds for k + 1 pairs of levels is similar to the basis step, only the labeling of the top AND nodes is the sum ofsolutions below in the case of counting.Proof of Proposition 80. The proof is again by induction, similar to the proof of Proposition 78. For simplicity ofwriting, the projection operator here takes as arguments the set of variables that are eliminated.Basis step: If the model has only one variable, then the claim is obvious.Inductive step: Let X be an OR node in the graph. Assume that the value of each OR node below it is the solutionto the reasoning problem corresponding to the conditioned subproblem rooted by it. We need to prove that the value ofX will be the solution to the reasoning problem of the conditioned subproblem rooted by X. Suppose X has childrenY1, . . . , Ym in the pseudo tree. We have v(Yi) = ⇓Yi ∪Desc(Yi )f , where Desc(Yi) are the descendants of Yi ,and the functions are restricted on the current path. Each AND node (cid:3)X, x(cid:4) will combine the values below. Becausethe sets Yi ∪ Desc(Yi) are pairwise disjoint, the marginalization operator commutes with the combination operatorand we get:f ∈F |πYi(cid:4)(cid:12)(cid:11)(cid:3)X, x(cid:4)v=m(cid:7)i=1⇓Yi ∪Desc(Yi )(cid:7)f ∈F |πYif = ⇓(cid:3)mi=1(Yi ∪Desc(Yi ))(cid:7)f.f ∈F |πxThe values v((cid:3)X, x(cid:4)) are then combined with the values of the bucket of X, which are the weights w(X,(cid:3)X,x(cid:4)). The func-tions that appear in the bucket of X do not contribute to any of the weights below Yi , and therefore the marginalizationovermi=1(Yi ∪ Desc(Yi)) can commute with the combination that we have just described:(cid:3)w(X,(cid:3)X,x(cid:4)) ⊗ v(cid:12)(cid:11)(cid:3)X, x(cid:4)= ⇓(cid:3)mi=1(Yi ∪Desc(Yi )) w(X,(cid:3)X,x(cid:4)) ⊗(cid:15) (cid:7)(cid:16)f.f ∈F |πxFinally, we get:v(X) = ⇓X w(X,(cid:3)X,x(cid:4)) ⊗ v(cid:12)(cid:11)(cid:3)X, x(cid:4)= ⇓X∪Desc(X)(cid:7)f.f ∈F |πXProof of Proposition 84. A bucket tree can be built by having a cluster for each variable Xi and its parents pai , andfollowing the structure of the pseudo tree T . Some of the clusters may not be maximal, and they have a one to onecorrespondence to the variables with dead caches. The parents pai that are not dead caches correspond to separatorsbetween maximal clusters in the bucket tree.References[1] N.J. Nilsson, Principles of Artificial Intelligence, Tioga, Palo Alto, CA, 1980.[2] E.C. Freuder, M.J. Quinn, Taking advantage of stable sets of variables in constraint satisfaction problems, in: Proceedings of the NinthInternational Joint Conference on Artificial Intelligence (IJCAI’85), 1985, pp. 1076–1078.[3] E.C. Freuder, M.J. Quinn, The use of lineal spanning trees to represent constraint satisfaction problems, Tech. Rep. 87-41, University of NewHampshire, Durham (1987).[4] Z. Collin, R. Dechter, S. Katz, On the feasibility of distributed constraint satisfaction, in: Proceedings of the Twelfth International Conferenceof Artificial Intelligence (IJCAI’91), 1991, pp. 318–324.[5] Z. Collin, R. Dechter, S. Katz, Self-stabilizing distributed constraint satisfaction, The Chicago Journal of Theoretical Computer Science 3 (4)(1999), special issue on self-stabilization.[6] P.J. Modi, W. Shena, M. Tambea, M. Yokoo, Adopt: asynchronous distributed constraint optimization with quality guarantees, ArtificialIntelligence 161 (2005) 149–180.[7] R. Dechter, Constraint networks, in: Encyclopedia of Artificial Intelligence, 1992, pp. 276–285.R. Dechter, R. Mateescu / Artificial Intelligence 171 (2007) 73–106105[8] R. Bayardo, D. Miranker, A complexity analysis of space-bound learning algorithms for the constraint satisfaction problem, in: Proceedingsof the Thirteenth National Conference on Artificial Intelligence (AAAI’96), 1996, pp. 298–304.[9] J. Larrosa, P. Meseguer, M. Sanchez, Pseudo-tree search with soft constraints, in: Proceedings of the European Conference on ArtificialIntelligence (ECAI’02), 2002, pp. 131–135.[10] C. Terrioux, P. Jégou, Hybrid backtracking bounded by tree-decomposition of constraint networks, Artificial Intelligence 146 (2003) 43–75.[11] C. Terrioux, P. Jégou, Bounded backtracking for the valued constraint satisfaction problems, in: Proceedings of the Ninth International Con-ference on Principles and Practice of Constraint Programming (CP’03), 2003, pp. 709–723.[12] A. Darwiche, Recursive conditioning, Artificial Intelligence 125 (1–2) (2001) 5–41.[13] F. Bacchus, S. Dalmao, T. Pitassi, Value elimination: Bayesian inference via backtracking search, in: Proceedings of the Nineteenth Conferenceon Uncertainty in Artificial Intelligence (UAI’03), 2003, pp. 20–28.[14] F. Bacchus, S. Dalmao, T. Pitassi, Algorithms and complexity results for #sat and bayesian inference, in: Proceedings of the 44th Annual IEEESymposium on Foundations of Computer Science (FOCS’03), 2003, pp. 340–351.[15] T. Sang, F. Bacchus, P. Beam, H. Kautz, T. Pitassi, Combining component caching and clause learning for effective model counting, in:Proceedings of the Seventh International Conference on Theory and Applications of Satisfiability Testing (SAT’04), 2004.[16] R. Dechter, Bucket elimination: A unifying framework for reasoning, Artificial Intelligence 113 (1999) 41–85.[17] R.E. Bryant, Graph-based algorithms for boolean function manipulation, IEEE Transaction on Computers 35 (1986) 677–691.[18] A. Darwiche, P. Marquis, A knowledge compilation map, Journal of Artificial Intelligence Research (JAIR) 17 (2002) 229–264.[19] A. Darwiche, A differential approach to inference in Bayesian networks, Journal of the ACM 50 (3) (2003) 280–305.[20] D. McAllester, M. Collins, F. Pereira, Case-factor diagrams for structured probabilistic modeling, in: Proceedings of the Twentieth Conferenceon Uncertainty in Artificial Intelligence (UAI’04), 2004, pp. 382–391.[21] H. Fargier, M. Vilarem, Compiling csps into tree-driven automata for interactive solving, Constraints 9 (4) (2004) 263–287.[22] V. Bertacco, M. Damiani, The disjunctive decomposition of logic functions, in: ICCAD, International Conference on Computer-Aided Design,1997, pp. 78–82.[23] N. Wilson, Decision diagrams for the computation of semiring valuations, in: Proceedings of the Nineteenth International Joint Conferenceon Artificial Intelligence (IJCAI’05), 2005, pp. 331–336.[24] R. Dechter, J. Pearl, Tree clustering for constraint networks, Artificial Intelligence 38 (1989) 353–366.[25] S.A. Arnborg, Efficient algorithms for combinatorial problems on graphs with bounded decomposability—a survey, BIT 25 (1985) 2–23.[26] H.L. Bodlaender, J.R. Gilbert, Approximating treewidth, pathwidth and minimum elimination tree-height, Tech. rep., Utrecht University(1991).[27] H.L. Bodlaender, Treewidth: Algorithmic techniques and results, in: The Twenty Second International Symposium on Mathematical Founda-tions of Computer Science (MFCS’97), 1997, pp. 19–36.[28] R. Dechter, A new perspective on algorithms for optimizing policies under uncertainty, in: International Conference on Artificial IntelligencePlanning Systems (AIPS-2000), 2000, pp. 72–81.[29] P. Shenoy, Valuation-based systems for bayesian decision analysis, Operations Research 40 (1992) 463–484.[30] J. Pearl, Probabilistic Reasoning in Intelligent Systems, Morgan Kaufmann, 1988.[31] R. Marinescu, R. Dechter, AND/OR branch-and-bound for graphical models, in: Proceedings of the Nineteenth International Joint Conferenceon Artificial Intelligence (IJCAI’05), 2005, pp. 224–229.[32] D. Allen, A. Darwiche, New advances in inference by recursive conditioning, in: Proceedings of the Nineteenth Conference on Uncertainty inArtificial Intelligence (UAI’03), 2003, pp. 2–10.[33] K. Kask, R. Dechter, J. Larrosa, A. Dechter, Unifying cluster-tree decompositions for reasoning in graphical models, Artificial Intelli-gence 166 (1–2) (2005) 165–193.[34] R. Dechter, Constraint Processing, Morgan Kaufmann, 2003.[35] R. Dechter, J. Pearl, Network-based heuristics for constraint satisfaction problems, Artificial Intelligence 34 (1987) 1–38.[36] I. Rish, R. Dechter, Resolution vs. search; two strategies for sat, Journal of Automated Reasoning 24 (1/2) (2000) 225–275.[37] R. Dechter, Enhancement schemes for constraint processing: Backjumping, learning and cutset decomposition, Artificial Intelligence 41(1990) 273–312.[38] R.J. Bayardo, R.C. Schrag, Using csp look-back techniques to solve real world sat instances, in: Proceedings of the Fourteenth NationalConference on Artificial Intelligence (AAAI’97), 1997, pp. 203–208.[39] J.P. Marques-Silva, K.A. Sakalla, Grasp: A search algorithm for propositional satisfiability, IEEE Transaction on Computers 48 (5) (1999)506–521.[40] N. Robertson, P. Seymour, Graph minors i. excluding a forest, J. Combin. Theory Ser. B 35 (1983) 39–61.[41] D. Bienstock, N. Robertson, P. Seymour, R. Thomas, Quickly excluding a forest, J. Combin. Theory Ser. B 52 (1991) 274–283.[42] R. Mateescu, R. Dechter, Compiling constraint networks into AND/OR multi-valued decision diagrams (AOMDDs), in: Proceedings of theTwelfth International Conference on Principles and Practice of Constraint Programming (CP’06), 2006, pp. 329–343.[43] D.H. Frost, Algorithms and heuristics for constraint satisfaction problems, Tech. rep., Ph.D. thesis, Information and Computer Science,University of California, Irvine (1997).[44] R. Mateescu, R. Dechter, The relationship between AND/OR search and variable elimination, in: Proceedings of the Twenty First Conferenceon Uncertainty in Artificial Intelligence (UAI’05), 2005, pp. 380–387.[45] R. Dechter, D. Frost, Backjump-based backtracking for constraint satisfaction problems, Artificial Intelligence 136 (2) (2002) 147–188.[46] J. Huang, A. Darwiche, Dpll with a trace: From sat to knowledge compilation, in: Proceedings of the Nineteenth International Joint Conferenceon Artificial Intelligence (IJCAI’05), 2005, pp. 156–162.[47] K.L. McMillan, Symbolic Model Checking, Kluwer Academic, 1993.106R. Dechter, R. Mateescu / Artificial Intelligence 171 (2007) 73–106[48] K.L. McMillan, Hierarchical representation of discrete functions with application to model checking, in: Computer Aided Verification, 1994,pp. 41–54.[49] J. Gergov, C. Meinel, Efficient boolean manipulation with obdds can be extended to fbdds, IEEE Trans. Computers 43 (1994) 1197–1209.[50] D. Sieling, I. Wegner, Graph driven BDDs—a new data structure for boolean functions, Theoretical Computer Science 141 (1994) 283–310.[51] R. Brayton, C. McMullen, The decomposition and factorization of boolean expressions, in: ISCAS, Proceedings of the International Sympo-sium on Circuits and Systems, 1982, pp. 49–54.