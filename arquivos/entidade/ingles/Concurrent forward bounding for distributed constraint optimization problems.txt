Artificial Intelligence 193 (2012) 186–216Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintConcurrent forward bounding for distributed constraint optimizationproblemsArnon Netzer, Alon Grubshtein∗, Amnon MeiselsDept. of Computer Science, Ben Gurion University of the Negev, P.O. Box 653, Be’er Sheva 84105, Israela r t i c l ei n f oa b s t r a c tArticle history:Received 6 November 2011Received in revised form 28 August 2012Accepted 4 September 2012Available online 7 September 2012Keywords:Distributed constraint optimizationproblemsAlgorithmsConcFBA distributed search algorithm for solving Distributed Constraints Optimization Problems(DCOPs) is presented. The new algorithm scans the search space by using multiple searchprocesses (SPs) that run on all agents concurrently. SPs search in non-intersecting parts ofthe global search space and perform Branch & Bound search. Each search process (SP) usesthe mechanism of forward bounding (FB) to prune efficiently its part of the global searchspace. The Concurrent Forward-Bounding (ConcFB) algorithm enables all SPs to share theirupper bound across all parts of the global search space. The number of concurrent SPs iscontrolled dynamically by the ConcFB algorithm, by performing dynamic splitting. Withineach SP a dynamic variable ordering is employed in order to help control the balanceof computational load among all agents and across different SPs. The ConcFB algorithmis evaluated experimentally and compared to all state of the art DCOP algorithms. Thenumber of Non-Concurrent Logical Operations, Non-Concurrent Steps, the total number ofmessages sent and CPU time are used as performance metrics. The evaluation procedureconsiders different DCOP problem types with a varying number of agents and differentconstraint graphs. As problems become larger and denser, ConcFB is shown to outperformall other evaluated algorithms by 2–3 orders of magnitude in all performance measures.Further evaluations comparing different variants of ConcFB provide important insights intothe working of the algorithm and reveals the contribution of its different components.© 2012 Elsevier B.V. All rights reserved.1. IntroductionThe field of Distributed Constraint Reasoning provides a widely accepted framework for representing and solving Multi-Agent Systems (MAS) problems. In a distributed constraint problem each agent holds a set of variables representing its state.These variables take values from a finite domain and are subject to constraints. A distributed constraint algorithm definesan interaction protocol for coordinating a joint assignment of variables. Optimally solving constraint problems is NP-Hard inthe general case [6].Distributed Constraint Reasoning provide an elegant model for many everyday combinatorial problems that are dis-tributed by nature. In these problems, independent computational entities, or agents, have partial knowledge of the problem.The distributed setting assumes that the agents are either incapable of disclosing private information or reluctant to do so[14,2]. Distributed Constraint Optimization Problems (DCOPs) were successfully applied to various MAS problems – coordi-nating mobile sensors [14,25], meeting and task scheduling [16], synchronization of traffic lights [13] and many others.Recent years have seen a large number of different and interesting algorithms for optimally solving DCOPs. These includeSynchronous Branch and Bound (SBB) [12], NCBB[4] , ADOPT [21], ODPOP[23] , BnB-ADOPT [26], OptAPO [10] and AFB [9].* Corresponding author. Tel.: +972 54 7706194; fax: +972 8 6477650.E-mail addresses: netzerar@cs.bgu.ac.il (A. Netzer), alongrub@cs.bgu.ac.il (A. Grubshtein), am@cs.bgu.ac.il (A. Meisels).0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.09.002A. Netzer et al. / Artificial Intelligence 193 (2012) 186–216187Some algorithms use pseudo trees [21,23,26] (introduced in Section 2.2) and some attempt to asynchronously prune thesearch space [9]. The OptAPO algorithm partially centralizes the problem [10] and DPOP uses Dynamic Programming [23].Despite these differences, all algorithms share two important properties: they all attempt to increase efficiency by increasingcomputational concurrency and they all attempt to promptly obtain good bounds to reduce the number of states visited inthe search space.The present paper presents a new approach towards finding an optimal solution to DCOPs. The proposed algorithmpartitions the search space into non-intersecting subproblems somewhat similar to those described for DCSPs in [31]. Eachsubproblem involves all agents and is solved by the Synchronous Forward Bounding (SFB) algorithm. This choice of SFBstems from its synchronous nature and its powerful pruning abilities.The agents take part in solving all independent subproblems concurrently by assigning unique identifiers and separatedata structures to each subproblem. In this form, information from different areas of the search space can be used to achievebounds faster. The Concurrent Forward Bounding (ConcFB) algorithm has the following important properties:• High degree of concurrency. Much of the computational effort is performed in parallel and the algorithm terminatesfaster. Moreover, as is shown in Section 3, ConcFB controls the number of running concurrent search processes bydynamically splitting the remaining parts of the problem.• Improves on former methods of Forward Bounding by sharing information between disjoint parts of the search space.• Controls work load balancing by employing dynamic ordering heuristics. This is useful when computational effort iseither costly or slow (weak mobile devices).The efficiency of ConcFB is extensively evaluated against the state of the art algorithms where the number of Non-Concurrent Logical Operations, Non-Concurrent Steps, total number of messages sent and CPU time are used as performancemetrics. An additional concurrent algorithm which combines multiple instances of SBB is introduced and its implementationis evaluated to provide further insights on the impact of concurrent algorithms.The evaluation procedure considers different DCOP problem types with a varying number of agents and different con-straint graphs. As problems become larger and denser, ConcFB is shown to outperform all other evaluated algorithms by2–3 orders of magnitude in all performance metrics. Further evaluations comparing different variants of ConcFB provide im-portant insights into the working of the algorithm and reveals the contribution of its different components.The remainder of this paper is structured as follows: Section 2 formally defines DCOPs and introduces some leadingDCOP algorithms. Section 3 presents ConcFB in detail and Section 4 presents correctness and completeness proof for ConcFB.Section 5 describes enhancements to the basic ConcFB algorithm. The experimental evaluation and a discussion of the resultsis in Section 6. The conclusions are summarized in Section 7.2. Distributed constraint optimization2.1. Distributed Constraint Optimization Problem (DCOP)Formally, a DCOP is a tuple (cid:3)A, X , D, C(cid:4) where:1. A is a finite set of agents A1, A2, . . . , An.2. X is a finite set of variables X1, X2, . . . , Xm. Each variable is held by a single agent but an agent may hold more thanone variable.3. D is a set of domains D1, D2, . . . , Dm. Each domain D i contains a finite set of values which can be assigned to thevariable Xi .4. C is a set of constraints. Each constraint c ∈ C defines a non-negative cost for every possible value combination of a setof variables, and is of the form:C : D i1× D i2× · · · × D ik→ R+A binary constraint is a constraint involving exactly two variables which takes the following formCi j : D i × D j → R+A binary DCOP is a DCOP in which all constraints are binary.We say that a constraint c is applicable to a joint (partial or full) assignment a, if all variables involved in c take valuein a.To facilitate understanding, we make the following assumptions on the structure of DCOPs:1. Each agent holds a single variable (the terms variable and agent will be used interchangeably).2. DCOPs are assumed to be binary.These are common assumptions in the DCOP literature (cf. [21,19,3,26]).188A. Netzer et al. / Artificial Intelligence 193 (2012) 186–216Fig. 1. A simple DCOP example with four agents.Fig. 2. The OR search tree of the DCOP depicted in Fig. 1.Relations between interacting agents of a DCOP are often represented by graphs. Each node corresponds to an agentwhile an edge represents a constraint between two agents. The nature of these constraints is specified by a set of valuescorresponding to the agents’ joint assignments. It is worth noting that unless explicitly stated otherwise, it is commonto assume that the constraint structure of a DCOP does not limit communication between agents [27]. Thus agents cancommunicate with other agents and add links [29,27], agree on an ordering between them [30] or broadcast importantinformation to other agents which are not directly connected to them via a constraint [9]. Fig. 1 presents a simple DCOPproblem with four agents. The cost of each value combination is specified on the right hand side of the figure.A DCOP algorithm proceeds by sending out messages and by adding or changing assignments to variables. An assignmentis a (cid:3)variable, value(cid:4) pair. A set of assignments, in which each variable appears at most once, is called a partial assignment.The cost of a partial assignment, PA, is the aggregated constraint cost of all variables constituting the assignment PA. Forexample, the cost of the partial assignment (cid:3)a1, 3(cid:4)(cid:3)a2, 2(cid:4) with respect to the DCOP of Fig. 1, is exactly 1. Afull assignmentis a partial assignment that includes all variables, and a solution is a full assignment of minimal cost. The solution to theabove DCOP is (cid:3)a1, 4(cid:4)(cid:3)a2, 2(cid:4)(cid:3)a3, 1(cid:4)(cid:3)a4, 2(cid:4) and its cost is 3.One can also explore Constraint Reasoning problems by means of their underlying search space. Fig. 2 presents a treerepresentation of the search space of the DCOP in Fig. 1 (also referred to as the “generate-and-test” tree). In this tree eachrow corresponds to exactly one agent, and edges correspond to assignments. For convenience, each leaf of the search treepresents the cost of a full assignment. The set of all leaf nodes present all possible costs for every assignment combination.Throughout this paper we refer to the tree representation of a DCOP search space as the search tree or as the DCOP searchtree and use these terms interchangeably.A path from the root to a leaf in the search tree corresponds to a complete assignment. For example, the highlightedpath in Fig. 2 corresponds to the assignment (cid:3)a1, 2(cid:4) (the second out of four possible edges) (cid:3)a2, 2(cid:4) (second out of two) and(cid:3)a3, 1(cid:4)(cid:3)a4, 2(cid:4). The cost of this assignment is 7, which is higher than the optimal cost.The search tree representation presented in Fig. 2 is also know as an OR search tree [17] of a constraint reasoningproblem. It can be very useful in understanding different properties of constraint algorithms and their progress. The samesearch space can also be represented by an AND/OR search tree [17] which captures the idea of independent subproblemswithin the problem’s search space. An AND/OR tree is guided by a pseudo tree [7].A pseudo tree [8] is a spanning tree involving all agents of the problem with the following important property: anytwo nodes located in separate branches of the tree do not share a constraint. That is, different branches of the pseudo treeA. Netzer et al. / Artificial Intelligence 193 (2012) 186–216189Fig. 3. A pseudo tree arrangement and the AND/OR tree corresponding to the simple DCOP example of Fig. 1.represent independent DCOP subproblems. The arrangement of agents in a pseudo tree can increase concurrency and isused by some DCOP algorithms. Fig. 3 presents a pseudo tree arrangement and an AND/OR tree for the DCOP of Fig. 1.General Cutset Conditioning [5,18] provides an alternative decomposition into independent subproblems. This approachis based on identifying a set of nodes that, once removed, would render the constraint graph cycle-free. That is, the methodenumerates all possible instantiations of the cutset and can independently solve the remaining singly connected network inlinear time. The performance gain from cutset conditioning is highly related to the constraint graph of a given instance andfinding the minimal one is NP-complete.2.2. DCOP algorithmsRecent years have seen a large number of algorithms for solving DCOPs. These vary in their approach towards findingminimal cost solutions. Successful DCOP algorithms are characterized by a high degree of concurrency and by methods forquick bounding of the search space.Synchronous Branch and Bound (SBB) [12,19] is the simplest DCOP algorithm. Often used as a baseline algorithm forevaluation, it conveys the general scheme and difficulties of most DCOP algorithms in a simple manner. SBB operates bypassing a unique CPA message (Current Partial Assignment) between agents. An agent holding the CPA attempts to extend itby adding an assignment which has a lower cost than the current upper bound. If a suitable assignment is found, it is addedto the CPA and the CPA is sent to the next in line agent. If there is no such assignment, the CPA is sent back to the lastagent in the CPA. At any given moment, only the agent holding the CPA may perform an action. This naive implementationproduces an algorithm in which agents are idle for most of the time. Recent algorithms significantly outperform SBB (cf.[19] for an in-depth introduction and discussion on DCOP algorithms):• Asynchronous Distributed Optimization (ADOPT) [21] – ADOPT is an inherently asynchronous algorithm. Agents runningADOPT are pre-arranged in a pseudo tree structure (or execute some pre-processing protocol which results in one) andcontinuously search the solutions space in a Best First manner. At any given moment agents maintain a lower and upperbound of the current search and when these meet, a solution is found.A powerful extension to ADOPT was recently introduced in [26]. Unlike its predecessor, BNB-ADOPT applies a Depth Firstsearch which is shown to greatly improve ADOPT’s performance.Both ADOPT and BNB-ADOPT exhibit a high degree of concurrency, and attain good bounds by employing strongheuristic functions. Although experimental evaluation indicates that these algorithms significantly improve (in termsof computational effort) the base line SBB algorithm, both suffer from a rapid growth in messages as the number ofneighbors an agent is constrained with increases (the problem’s density).• Distributed Pseudotree Optimization Protocol (DPOP) [22] – the DPOP algorithm is based on Dynamic Programminginstead of the standard Search approach (i.e. it is an inference algorithm and not a search algorithm). DPOP operates inthree phases: In the first phase, agents are re-arranged in a pseudo tree structure. In the second phase (UTIL), agentspropagate the optimal, aggregated utility of their subtrees from the leafs towards the root of the pseudo tree (bottom-upphase). Finally, in the third phase (VALUE) the optimal assignments are propagated from the root to the leafs (top-downphase) based on the aggregated calculation of the second phase.Unlike ADOPT, the three phase structure of DPOP ensures a low number of messages which is linear in the number ofagents. However, DPOP message sizes are exponential in the induced width of the underlying pseudo tree.ODPOP [23] is an extension to DPOP which overcomes this problem by sending UTIL tuples instead of complete optimalassignment combinations. These tuples are ordered by quality and are sent out one at a time. Thus, ODPOP is a completealgorithm with polynomial (in the width of the tree) sized messages.Although initially designed to handle open problems [23], ODPOP requires no changes when applied to standard DCOPs.The inherently different approach to solving DCOPs makes evaluating the computational effort of DPOP and ODPOP dif-ficult, and this performance measure was not specified by the authors [22,23]. Our experimental evaluation (Section 6)indicate that the number of logical operations taken by ODPOP is higher than those of SBB.190A. Netzer et al. / Artificial Intelligence 193 (2012) 186–216• Non-Commitment Branch and Bound (NCBB) [4] – NCBB is a pseudo tree extension of SBB which employs a non-committing scheme for improving its concurrency level. Taking advantage of the underlying tree structure, NCBB iscapable of searching through different branches of the tree simultaneously. This is combined with an interesting ex-ploration scheme in which an agent may inform its children of different assignment. This “non-commitment” to anassignment further increases the algorithm’s concurrency level as it allows one descendant to continue its search witha different context while its sibling is still pursuing the previous one.In [26] NCBB’s performance is evaluated against BnB-ADOPT and is shown to be slightly less efficient.• Asynchronous Forward Bounding (AFB) [9] – AFB applies a hybrid approach to asynchronicity: the CPA is passed be-tween agents and proceeds in synchronous steps but solution bounds are attained in an asynchronous manner.AFB agents refrain from sending large amounts of volatile data by synchronously extending the CPA. That is, the agentreceiving the CPA will attempt to extend it (add its assignment) and pass it on to the next agent. After the agentpasses the CPA to its successor the agent notifies all unassigned agents of its current assignment. Each unassignedagent infers a bound which is the lowest cost of the partial assignment. These values are computed concurrently andasynchronously, and responses are sent back to the originator of the request. This results in an asynchronous processof backwards costs propagation. Whenever the aggregated cost of the bound requests breaches the best known upperbound, the requesting agent generates a new CPA with a revised assignment (or backtracks).The AFB algorithm, which synchronously assigns values to variables but asynchronously compute lower bounds onsolution costs, was shown to produce better results in terms of network load and computational effort than those ofADOPT and DPOP, on most problem instances [9].3. Concurrent forward boundingConcurrent Forward Bounding (ConcFB) applies SFB (Synchronous Forward Bounding) as its means to attain good lowerbounds while utilizing multiple concurrent search processes to speed up the search. ConcFB partitions the original searchspace to disjoint parts and concurrently search through each part with SFB. This means that multiple instances of theSFB algorithms are executed by all agents, and each instance searches through a distinct part of the search space. Globalinformation such as the best upper bound is shared across all instances and further improves the algorithms pruningabilities.The following features of ConcFB should be noted:• It does not rely on a pseudo tree arrangement of agents. This simplifies the use of agent reordering heuristics whichusually provide a significant performance boost to DCSP algorithms [20,33,34] (Section 5.1).• ConcFB partitions the search space and do not rely on the structure of the constraints. The generated subproblemsinvolve all agents but differ in the domain of at least one agent’s variable (Section 3.2).• Although the search process within each subproblem proceeds in synchronous steps (Section 3.1) there is no synchro-nization between the ongoing processes of different subproblems. This means that the agents act asynchronously andconcurrently.The components of ConcFB are first described separately – Section 3.1 discusses the forward bounding search technique,and Section 3.2 discusses concurrent search of distributed constraint reasoning problems. Section 3.3 provides a detailedoverview of the ConcFB algorithm and Section 3.4 presents a ConcFB trace on the example DCOP problem of Fig. 1.3.1. Synchronous Forward Bounding (SFB)Synchronous Forward Bounding is highly related to the AFB algorithm presented in [9]. Similar to AFB, SFB agents pass aunique CPA message between them and only the agent that is holding the CPA may assign new values to it. SFB differs fromAFB in that the agents do not proceed with an assignment prior to receiving all lower bounds of unassigned agents. Thisresults in a synchronization of the algorithm which may help reduced propagation of irrelevant data at the cost of reducedconcurrency. Note that ConcFB combines SFB with a Concurrent framework (Section 3.2) to increase its concurrency level.Fig. 4 presents a simplistic Forward Bounding assignment scheme.1SFB agents wait for messages which trigger different responses. Whenever an agent ai receives a CPA, it first attemptsto extend it by assigning a value to its variable (lines 1–4). It then sends out (or broadcasts) a message with the updatedpartial assignment to all unassigned agents. This LB_Request message triggers a calculation of the minimal cost for eachagent which is sent back to ai (lines 5–6). Unlike AFB, progress is blocked until all LB_Report messages are received andaggregated from all unassigned agents (lines 7–8). This blocks further execution and may result in long periods of idlewaiting by agents. If the sum of this aggregated cost and the current cost of the CPA is lower than the current upper bound,then the CPA may be further extended by the next agent and the proper message is sent forward. If, however, this cost is1 Important details specifying the actions taken when the CPA is filled, the content of different message types and other relevant information is omittedfor the sake of clarity.A. Netzer et al. / Artificial Intelligence 193 (2012) 186–2161911 CPA ← m.CPA;2 if not Domain.isEmpty? then3CPA.add(Local_Assignment);CPA.cost ←− CPA.cost + assignment’s cost;for a j ∈ CPA.unassigned dosend(a j , LB_Request);Wait until all unassigned agents reply with an LB_Report message;LB ←− aggregated sum of all LB_Report;if CPA.cost + LB < Upper_Bound thensend(Next_Agent, CPA)elseCPA.remove(Local_Assignment);CPA.cost ←− CPA.cost − assignment’s cost;Remove Local_Assignment from domain;call assign_CPA(m);45678910111213141516 else17send(Last_Assigned_Agent, Backtrack_CPA);Fig. 4. assign_CPA(msg) – A simplistic pseudocode for the assign method of SFB. This code is executed upon the reception of a message containingthe CPA.Fig. 5. Six disjoint partitions of the search space.not lower than the current upper bound, a new assignment is attempted and the process repeats itself (lines 9–15). Whenthe domain of the agent is emptied a backtrack is triggered and the current CPA (without an assignment to ai ) is sent tothe last assigning agent (e.g. ai−1) (lines 16–17).3.2. Concurrent searchConcurrent search for solving DCSPs was presented by [31]. The basic idea in concurrent search algorithms is to logicallypartition the search space into non-intersecting parts. This allows the same set of agents to participate in distinct constraintsearch processes. Concurrent search is a powerful framework which may be applied to any DCSP algorithm [31].In the simplest partitioning scheme, each assignment of the initializing agent is used by a different Search Process.2 Thisresults in a number of search processes which is exactly the same as the domain size of the initializing agent.Concurrent search may also be adapted to DCOPs. However, unlike DCSPs which seek a single consistent solution, in aconcurrent DCOP framework the minimal cost solution over all subproblems is reported. Fig. 5 provides a graphical repre-sentation of a possible partition scheme to the problem of Fig. 1. The search space is partitioned into six disjoint segmentsSP1–SP6 induced by the different domain of agent a1 and a further split of SP4 based on the domain of agent a2. In each oneof these subproblems, a1 owns a single value in its variable domain. In SP1 the domain of a1 is 1, in SP2 it is 2, and so forth.Having partitioned the original problem any complete DCOP algorithm may be applied to solve subparts SP1, SP2, SP3, SP5and SP6 to extract the minimal cost solution. The minimal cost solutions of SP5 and SP6 should be combined by the agentinitiating the split of SP4 (agent a2).It is important to point out that all agents in concurrent search may participate in more than a single subproblem.Fig. 5 demonstrates this idea: each one of the four agents participate in multiple search processes. This is in contrast tothe subproblems resulting from a pseudo tree arrangement of agents, where each agent participate in one subproblem andresults are merged by a higher priority agents.2 Represented as an OR node at the top of the tree, cf. [17].192A. Netzer et al. / Artificial Intelligence 193 (2012) 186–216(a) Concurrent SBB.(b) Pruning multiple SPs in Concurrent SBB. Colored nodes are pruned when the CPA reaches agent 3 and 4.Fig. 6. Snapshots of a Concurrent SBB run.Information on the progress of each SP is maintained in a Search Process (SP) data structure maintained by each agent foreach SP. An SP is a single search process and in the remainder of this paper we use these terms interchangeably. Each SPincludes a unique identifier and maintains data on the global ordering of agents. All relevant messages and data structures ofthe underlying search algorithm are stamped by the relevant SP identifier and each agent holds a designated data structurerecording information on every SP. In particular each agent maintains information on its current domain with respect toevery SP (a value v j maybe pruned from the domain of agent ai in the context of SPx but still be valid with respect to SP y ).Before presenting ConcFB in detail, consider an example run of Concurrent SBB on the DCOP of Fig. 1. In this examplethe search space is partitioned into four SPs in which a1 holds a single value in its domain (as shown in Fig. 5). ConcSBBbegins by generating four different CPAs instead of the unique one used in standard SBB. In each SP, agent a1 assigns itsonly value to one of the CPAs and sends it to agent a2 (Fig. 6(a)). Upon receiving a CPA message, a2 examines its identifier(the SP ID code) and associates it with the corresponding local SP. If a2 is unfamiliar with the ID code, a new local SP isinstantiated. The agent then proceeds to extend each one of the CPAs and continue its SBB run. At some point in time, theCPA of SP1 holds a full assignment. A full assignment serves as a new upper bound which can be used to prune the searchspace. This new bound is relevant to the current SP, but it can also be used in other SPs to prune the search space. If agents3 and 4 are notified of the new bound before proceeding to assign values the bound found by SP1 can be used to pruneassignments of SP2, SP3 and SP4 (Fig. 6(b)).3.3. Concurrent Forward Bounding (ConcFB)The present work applies SFB to each individual search process resulting in Concurrent Forward Bounding (ConcFB).The SFB algorithm has two important features that make it suitable for concurrent search: powerful pruning abilities andsynchronous progress. In particular, the latter feature facilitate the introduction of dynamic reordering of agents and dynamicsplitting of the search space (discussed in Section 5).The first agent in ConcFB begins its operation by partitioning the search space into disjoint parts. For each assignment inits domain a Search Process (SP) is initiated. These SPs represent a partition upon which a search algorithm (SFB) is executed.When all search algorithms conclude, the first agent reports the minimal cost solution found in these subproblems.It is worth noting, that in order to improve pruning, upper bounds may be shared across search processes. That is,whenever a new upper bound is found, it is used to prune search on all SPs. Since an agent may participate in multiple SPsat any given time, means to identify and manage the execution of any search procedure carried out on any of its SPs areintroduced.A. Netzer et al. / Artificial Intelligence 193 (2012) 186–216193The following subsections provides a detailed account of ConcFB. We first introduce the main data structures. Next,the messages used in the algorithm are presented. Finally Section 3.3.3 describes the pseudocode of each one of ConcFB’sfunctions.3.3.1. Data structuresThe main data structures used in ConcFB are:CPALB_ListSplitsSPA CPA (Current Partial Assignment) maintains all values of currently assigned agents and the resulting cost of thejoint assignment. That is, it contains a set of pairs of the form (cid:3)Agent, Value(cid:4) and an integer value which is theaggregated sum of costs of all constraints applicable to the CPA. Every CPA is associated with a Search Process(discussed below) and shares with it the same unique identifier.The LB_List is a vector of Lower Bounds (LBs) reported by all unassigned agents with respect to a given CPA.A list of all SPs diverging from a Search Process (not an agent). In the basic implementation of ConcFB the splitsdata structure is used only by the root search process.The SP (Search Process) data structure lies at the heart of ConcFB. Each agent holds an SP for each logical searchprocess it takes part in (see Fig. 5). An SP is instantiated whenever a new CPA is received by the agent. Every SPcontains a unique ID, the current assignment the agent takes with respect to the specific SP along with its costand the agent’s current domain (again, with respect to the specific SP). Additionally, the SP holds the CPA thattriggered its creation, the list of LBs (LB_List) and the splits diverging from the SP.SP_List A list of all currently active SPs, held by each agent.3.3.2. MessagesConcFB uses five types of messages to transfer information and requests between agents:CPAA message containing a CPA and an LB_List, sent by an agent extending the CPA on a given search process to anunassigned agent.BT_CPA A backtrack message, notifying an agent that a CPA received needs to be backtracked.LB_Request A message containing a CPA, sent to an agent asking it to calculate and return a Lower Bound for the givenCPA.LB_Report A message sent as a reply to LB_Request, reporting a Lower Bound from a given agent for a given CPA.UBA broadcast message informing all agents on a newly reached Upper Bound.These messages are limited in size and will at most contain a message type, an SP identifier, a CPA, an LB_List vectorand possibly a few integer values (bounds).3.3.3. PseudocodeFig. 7, Main(): The pseudocode of ConcFB’s main procedure is described in Fig. 7. It starts with the initializing agentcreating a Root_SP (line 3), and in it a data structure to hold the search process that would be created by splitting thedomain of the initializing agent (line 4). The initializing agent calls the Init_SP() function to create the search processes andstarts the search (line 5). The main loop (line 6) continuously looks for incoming messages (line 7), and dispatches themaccording to the message type to the appropriate functions (lines 8–19).Fig. 8, Init_SP(): The Init_SP() function, described in Fig. 8, loops through all possible assignments in the domain (line 1).Each value in the domain is assigned to a different Search Process which is created with a unique SP_ID. The generatedSP contains a single relevant value (line 2). All SPs are added to a list in the Root_SP data structure (line 3), and theAssign_CPA() function is invoked multiple times – once for each SP.Fig. 9, Receive_CPA(): Upon receiving a CPA message, the function Receive_CPA() is called. In Receive_CPA() an agentcreates a new SP data structure with the SP_ID of the received CPA and the entire domain of the current agent (line 1).A copy of the received CPA and LB_List is saved in the SP (lines 2,3), and the current agent’s LB is removed from theLB_List (line 4). The removal of the agent’s LB from the LB_list is crucial as it will be replaced later by the agent’s actualcost according to its assignment. The newly created SP is added to a list of all SPs maintained by the agent (line 5), andAssign_CPA() is called.Fig. 10, Receive_BT_CPA(): In Receive_BT_CPA() the agents need to identify the Search Process for which the BT_CPAmessage was sent. This is done using the SP_List and according to the ID retrieved from the message (line 1). The currentassignment of the agent for the specific Search Process is removed from its domain (lines 2, 3). If the domain of the SP isexhausted then a Backtrack() is called. Alternatively an Assign_CPA() is called to try another assignment (lines 4–7).(cid:2)Fig. 11, Receive_LB_Request(): When an agent responds to one of the LB_Request messages, it calculates its lower boundwith respect to the CPA in the message (line 1). Formally the lower bound is defined as LB = mind∈Domain{xi ∈CPA.varsi , d)}. The lower bound is the minimum cost that can be achieved by summing all the constraints between anyCost(xaassignment in the agents domain and the given CPA. This lower bound is sent back to the LB_Request message originator asan LB_Report message (line 2).194A. Netzer et al. / Artificial Intelligence 193 (2012) 186–2161 done ←− false2 if Initializing_Agent then354Root_SP := new SP(SP_ID(root), domain)Root_SP.splits := new Split_Set()Init_SP()6 while not done do7msg ←− Get_Next_Msg()switch msg.type do89101112131415161718192021case CPA:Receive_CPA(msg)case BT_CPA:Receive_BT_CPA(msg)case LB_Request:Receive_LB_Request(msg)case LB_Report:Receive_LB_Report(msg)case Upper_Bound:if msg.UB < this.UB thenthis.UB ←− msg.UBcase Terminate:done ←− true22 return this.UB1 for i ←− 1 to domain.size do2SPid := new SP(SP_ID(i), domain[i])Root_SP.splits.add(SPid)Assign_CPA(SPid)34Fig. 7. Main().Fig. 8. Init_SP().1 SPid := new SP(msg.sp_id, domain)2 SPid.CPA ←− msg.CPA3 SPid.Org_LB_List ←− msg.LB_List4 SPid.Org_LB_List.remove(LB of current agent)5 SP_list.add(SPid)6 Assign_CPA(SPid)Fig. 9. Receive_CPA(msg).1 SPid ←− SP_list.get(msg.sp_id)2 ca ←− SPid.Current_Assignment3 SPid.domain.remove(ca)4 if SPid.domain.isEmpty? then56 else7Backtrack(SPid)Assign_CPA(SPid)Fig. 10. Receive_BT_CPA(msg).A. Netzer et al. / Artificial Intelligence 193 (2012) 186–216195(cid:2)1 LB = mind∈Domain{2 send(LB_Report, msg.origin, LB)xi ∈msg.CPA.vars Cost(xai , d)}Fig. 11. Receive_LB_Request(msg).1 SPid ←− SP_list.get(msg.sp_id)2 SPid.LB_List[msg.origin] ←− msg.LB3 if received LB_Report messages from all unassigned neighbors then4if SPid.CPA.cost + SPid.Current_Assignment_Cost +CPA ←− SPid.CPA ∪ SPid.Current_Assignmentsend(CPA, Next_Agent(), CPA and SPid.LB_List)(cid:2)SPid.LB_List[i] < this.UB thenelseReceive_BT_CPA(msg)Fig. 12. Receive_LB_Report(msg).5678Fig. 12, Receive_LB_Report(): The Receive_LB_Report() function is used to collect LB_Report messages and decide if thecurrent assignment of a given Search Process does not violate the UB. When LB_Report messages are received the agentneeds to find out to which Search Process it belongs (line 1). The received LB is then entered into the LB_List of theappropriate SP either as a new entry or as an update to a previous LB from that agent (line 2). If LB_Reports were receivedfor the specific SP from all unassigned neighbors (line 3) then all the Forward Bounding information has been received inorder to decide whether the current assignment should be used to extend the CPA.The cost of the CPA is added to the current assignment of the Search Process and to the sum of the Lower Bounds inthe LB_List. The CPA cost stands for the cost collected by all assigned agents, the current assignment cost is the cost addedby the current agent, and the sum of LB_List is a lower bound for the cost that would be added by all unassigned agents.If the sum of all the costs is smaller than the known Upper Bound (line 4) then a CPA is created by adding the currentassignment to the Search Process CPA (line 5) and a CPA message is sent to the next agent, with the newly created CPA andthe updated LB_List (line 6). If, on the other hand, the calculated sum of costs is bigger than the known Upper Bound, thenthe current assignment cannot extend the CPA to a solution and a Receive_BT_CPA() is called.Fig. 13, Assign_CPA(): The Assign_CPA function is called whenever an agent tries to assign a new value to a given SearchProcess. If the domain of the specific Search Process is empty (no more value to assign) then a Backtrack() is called (line 21).Otherwise, the next best assignment is picked from the domain (lines 2–3) and the cost of this assignment is calculatedand stored (line 4).3 The cost of an assignment is the sum of the costs of all constraints between the assignment and theassignments in the CPA. Formally Cost =(cid:2)xi ∈CPA.vars Cost(xai , assignment).The cost of the CPA is added to the current assignment cost and to the sum of the LB_List, and compared to the knownUpper Bound (line 5). Note that the sum of the LB_List represents the lower bounds of unassigned agents with respect to theCPA, without the current agent assignment. If the sum of costs is larger or equal to the Upper Bound then the assignmentcannot extend the CPA to a better solution. In this case the assignment is removed from the domain of the specific SearchProcess (line 6). If the removal of the assignment exhausts the domain, then a Backtrack() is called (line 8). Otherwise, theAssign_CPA() is called again to assign a new value (line 10).If the sum of costs is smaller then the Upper Bound, then if this is the last agent and the assignment is a full assignment(line 12) a new Upper Bound has been found. In this case the new Upper Bound value is broadcast to all agents (line 14)and a Backtrack() is called. If this is not the last agent, a copy of the Org_Lb_List is created (line 17) and a request is sent toall unassigned neighbors to report their Lower Bound on the CPA after the new assignment was added to it (lines 18, 19).Note that LB_Request only needs to be sent to unassigned neighbors and not all unassigned agents, since unassigned agentswhich are not neighbors of the current agent will not change their Lower Bound due to current agent assignment. Note alsothat the LB_List must be initialized to the Org_LB_List before any Lower Bounds are collected for a new assignment, sinceLower Bound updates for the previous assignment of the current agent are no longer valid and must be discarded.Fig. 14, Backtrack(): When an agent decides to backtrack, then if this is the Initializing Agent the specific Search Processis removed from the Root_SP.splits list (line 2). If all Search Processes ended (line 3) the search is complete. The currentUpper Bound is the solution and a terminate message is broadcast to all agents (lines 3–6). If this is not the Initializing Agentthen a BT_CPA message is sent to the previous agent (lines 8, 9).3 Dynamic ordering of assignments can be easily implemented by calculating, sorting and storing all assignments’ costs. This requires some (minor)additional computation and further improves performance.196A. Netzer et al. / Artificial Intelligence 193 (2012) 186–2161 if not SPid.domain.isEmpty? then2ca ←− next best assignment from SPid.domainSPid.Current_Assignment ←− caSPid.Current_Assignment_Cost ←−if SPid.CPA.cost + SPid.Current_Assignment_Cost +(cid:2)xi ∈msg.CPA.vars Cost(xa(cid:2)i , ca)SPid.Org_LB_List[i] (cid:2) this.UB then345678910111213141516171819SPid.domain.remove(ca)if SPid.domain.isEmpty? thenBacktrack(SPid)elseAssign_CPA(SPid)elseif current agent is the last agent in SPid thenthis.UB ←− SPid.CPA.cost + SPid.Current_Assignment_CostBroadcast(Upper_Bound, this.UB)Backtrack(SPid)elseSPid.SP_List ←− SPid.Org_SP_Listforeach ai ∈ SPid.CPA.Unassigned_Neighbor dosend(LB_Request, ai, SPid.CPA ∪ SPid.Current_Assignment)20 else21Backtrack(SPid)Fig. 13. Assign_CPA(SPid ).1 if Initializing_Agent then2Root_SP.splits.remove(SPid)if Root_SP.splits.isEmpty? thenSolution ←− this.UBdone ←− trueBroadcast(Terminate, null)345697 else8ai ←− SPid.CPA.Last_Assigned_Agent()send(BT_CPA, ai , SPid.sp_id)Fig. 14. Backtrack(SPid ).3.4. ConcFB run traceWe next present a detailed trace of ConcFB on the simple DCOP problem presented in Fig. 1.Agents begin by setting their upper bound value to ∞. All agents but the first (agent a1) remain idle and await incomingmessages.Agent a1 begins by generating four distinct search processes and assigns a different domain value to each one. TheseSearch Processes carry a unique identifier (SP1 to SP4 in our example in Fig. 15a) used by all agents. Agent a1 then assignsits value in each search process and broadcasts an LB_Request message to agents a2 to a4 (a total of 12 messages – onemessage per agent per search process). Note that the domain of a1 includes a single distinct value in each SP and thus agenta1 have four distinct assignments – one assignment per SP.Agents receiving these requests will compute the minimal cost assignment and reply with its value as their LB. Thus,agent a2 will respond with 2 for the message with the ID SP1, and respond with a 0 (in a different message) when receivinga1’s message with ID SP4. In contrast agent a4 will return 0 for all SPs since it has no constraint with a1.It is important to note that although ConcFB proceeds in synchronous steps there is no guarantee on the timing ofmessages and computation by other agents. In some SPs a1 may receive LB replies from all neighbors and proceed onwardbefore all other bounds are received from other SPs. Let us assume then, that a1 received the following five messages4:(cid:3)SP1, (cid:3)a2, L B = 2(cid:4)(cid:4), (cid:3)SP2, (cid:3)a2, LB = 3(cid:4)(cid:4), (cid:3)SP2, (cid:3)a3, LB = 2(cid:4)(cid:4), (cid:3)SP2, (cid:3)a4, LB = 0(cid:4)(cid:4) and the message (cid:3)SP4, (cid:3)a3, LB = 0(cid:4)(cid:4), as depictedin Fig. 15b.4 We use the following format for messages (cid:3)SPid, (cid:3)sender, value(cid:4)(cid:4).A. Netzer et al. / Artificial Intelligence 193 (2012) 186–216197(a) Four SPs which act on non-intersecting parts of the search space. Each SP executes an instance of SFB.(b) An LB request is made to each agent within each SP. At this point, agents a3 and a4 received the request in the context of SP2 only.(c) When a new upper bound is found its value is shared with all other agents which will apply it in all SPs.Fig. 15. Run trace of ConcFB.At this point agent a1’s SP2 computes the sum of lower bounds (which is 5) and since it is lower than the initial upperbound of ∞ it sends out the SP2 CPA to agent a2. Having received the CPA of SP2, agent a2 now attempts to extend it.Unlike the previous case agent a2 now has 2 domain value in this SP to choose from. It will assign the second one (bestone) which is 2 and broadcast LB requests from a3 and a4 (note that in the background other agents keep responding toagent a1’s LB request. Specifically, agent a2 may respond to such requests for other SPs as well but these are omitted forthe sake of clarity).Agents a3 and a4 respond to a2’s request by sending (cid:3)SP2, (cid:3)a3, LB = 3(cid:4)(cid:4) and (cid:3)SP2, (cid:3)a4, LB = 1(cid:4)(cid:4). As before, the resultingcost is lower than the initial upper bound and the CPA is passed onward. It is easy to see that at this point that SP2execution will proceed until a new upper bound of 7 is reached by agent a4. This information is broadcast to all otheragents (Fig. 15c) and the execution within SP2 continues.At this point let us focus on the progress of SP1 (while assuming that execution of other SPs on all agents continues).Assume that at this point a1 already received the following LB replies: (cid:3)SP1, (cid:3)a2, LB = 2(cid:4)(cid:4), (cid:3)SP1, (cid:3)a3, LB = 3(cid:4)(cid:4), (cid:3)SP1, (cid:3)a4, LB =0(cid:4)(cid:4). The resulting joint cost is 5 and as it is lower than the current upper bound of 7, a1 sends the SP1 CPA to agent a2. Theagent will choose its best assignment (2) and send an LB request to agents a3 and a4. Their responses are (cid:3)SP1, (cid:3)a3, LB = 3(cid:4)(cid:4)and (cid:3)SP1, (cid:3)a4, LB = 1(cid:4)(cid:4) which result in a cost equal to that of the bound (when combined with the constraint cost of a1and a2’s assignments). Agent a2 next attempts its other assignment a2 = 1 and resend LB requests to the unassigned agentsa3 and a4. Again the bound is breached and a backtrack message is generated by agent a2 to a1. Agent a1 receives thebacktrack message and being the initializing agent terminates SP1 by removing it from its split set.A similar interaction concurrently occurs for other SPs: most of SP3’s search space is pruned by agent a2 and the boundvalue of 7, SP2 fails to locate a bound lower than 7 and SP4 finds the optimal solution with a cost of 3.198A. Netzer et al. / Artificial Intelligence 193 (2012) 186–2164. Correctness of ConcFBTo prove the correctness of ConcFB we first prove that it terminates and then prove that upon termination the value ofthe upper bound UB is the same as the cost of the optimal solution.To prove that ConcFB terminates one needs to prove that it will never go into an endless loop. To do so, we will considerthe algorithm’s states s ∈ S, where S = (cid:3)S1 × S2 × · · · × Sk(cid:4) – the Cartesian product of all SP states. A state si ∈ S i includesall agents, their current assignment and domain. The following lemma proves that the same state is not generated morethan once.Lemma 1 (Unique states). A state S of ConcFB is never repeated.Proof. Begin by noting the following simple observation:Observation 1. Any two states of different SPs si ∈ S i , s j ∈ S j , i (cid:10)= j, will never be identical.Observation 1 stems from the fact that the partitioning scheme of ConcFB (discussed in Section 3.2) generates disjointsearch spaces assigned to the different SPs. In other words, the domain of the initializing agent is divides into differentnon-intersection parts (single values from its domain – line 2 of Init_SP()) which means that the assignment of agent a1 insi and s j can never be the same value.The above observation implies that one needs only consider the states of the individual SPs to prove the lemma. That is,it is enough to show that in any given SP, the SFB algorithm never repeats any of its states.Consider a specific search process, SPid. Assume by negation that aiis the highest priority agent (first agent in theorder of assignments) that by acting repeats a previously visited state. Specifically, repeating a state means that the partialassignment (the CPA) is duplicated. Any new assignment added to the CPA is selected in the Assign_CPA function. Thisfunction is invoked from either one of the following functions:• Init_SP() – This function is only invoked once – at the beginning of ConcFB’s run. This means that no other prior CPAexisted for SPid (or any of its sibling SPs for that matter). Hence one must conclude that the SPid’s CPA is identical tothe CPA generated for some other search process, SP j . However, since Init_SP() assigns a single unique value to eachone of the SPs domain (line 2 of Init_SP()) and since new CPA values are added based on the current domain (line 2of Assign_CPA()) we must conclude that the CPA generated for SPid is different than that of SP j in contradiction to ourfalse assumption.• Receive_CPA() – The Receive_CPA() function is invoked whenever a higher priority agent a j (where j < i) sends aCPA message to ai (line 10 of Main() and line 6 of Receive_LB_Report()). A duplicated CPA generated by ai includesthe same assignments to all of its variables and therefore the first j assignments must be the same. The fact thatReceive_LB_Report() is the only trigger for a forward sent CPA message and is in turn triggered by messages receivedfollowing line 18 of Assign_CPA() implies that agent a j was the one to generate a duplicate CPA. Since Receive_CPA()does not change any domain value or assignment value (the state sid) this contradicts the assumption that ai is thehighest priority agent which repeats a state.• Receive_BT_CPA() – If Assign_CPA() is invoked following line 7 of Receive_BT_CPA(), lines 1–4 are also executed. Specif-ically, line 3 which removes assignments from the current domain of SPid without adding new ones. As a result, line 2of Assign_CPA() can never generate a duplicate CPA unless a value is returned to the domain of SPid. This, however, onlyoccurs in line 1 of Receive_CPA() which contradicts our assumption. (cid:2)Theorem 1 (Termination). Every run of ConcFB terminates.Proof. A DCOP search algorithm will terminate if the following conditions hold:• The number of states it goes through is finite.• It does not examines the same state more than once (i.e. it does not fall into endless loops).• The algorithm maintains progress. That is, it moves from one state to another within a finite amount of time.The first condition is trivially met by the definition of a DCOP (Section 2.1), and the second one immediately follows fromLemma 1.Following Observation 1 it suffices to examine the progress of a single SP to see that the third condition holds.Consider the state sa ∈ S i . This state can proceed to some other state sb ∈ S i whenever the Assign_CPA() and Re-ceive_BT_CPA() functions are executed (assignment change or domain value removal) by some agent. Let ai be the lastagent in sa to add an assignment to the CPA.If ai is the first agent and it has just commenced its run, it will call Init_SP() from the main function, which will inturn invoke Assign_CPA(). Assign_CPA() will broadcast requests to all unassigned agents (line 19, Assign_CPA()) and whenA. Netzer et al. / Artificial Intelligence 193 (2012) 186–216199all request arrive it will either add its assignment to the CPA (line 5, Receive_LB_Report()) and move to state sb or executeReceive_BT_CPA() in line 8. Receive_BT_CPA() will remove the offending value from the domain (line 3, Receive_BT_CPA())and as a result the SP will move on to state sb.Otherwise, ai assigns a value to SPi ’s partial assignment in line 5 of Receive_LB_Report() only. It will then proceed tosend the CPA to agent a j . This message will eventually be received by agent a j which will call Receive_CPA (line 10 ofMain()). After updating relevant SP data structures Assign_CPA() will be executed. This can result in different outcomes:1. A new assignment will be examined by a j which will result in a breach of the upper bound (line 5 of Assign_CPA()).The agent will remove the offending value (line 6) which will change the current SP’s state.2. If the agent is the last agent, the Backtrack function will be invoked (line 15). A BT_CPA message will be sent to agentai (line 9, Backtrack()) which will invoke Receive_BT_CPA() (line 12 of Main()). As before, this function will remove thelast assigned value of ai from its domain (line 3 of Receive_BT_CPA()) and the SP’s state will change to sb.3. The CPA and the potential assignment are broadcast to all unassigned agents and a j resumes its Main() function. Unas-signed agent will receive the new LB_Request message, calculate their LB value and send it to a j (without removing anyvalue from the domain or changing their assignment. That is, without changing the SP’s state). Agent a j will receive itspeers replies and once the aggregated cost of all unassigned agents is calculated the agent will either update its currentassignment (Receive_LB_Report(), line 5) or else execute Receive_BT_CPA and remove the potential assignment from itsdomain. In either case, the result would be a new state. (cid:2)Next one needs to prove that the value returned by ConcFB upon completion is indeed the optimal cost of a full assign-ment.Theorem 2 (Optimality). Upon termination, the cost of the upper bound (the local variable UB) is equal to that of the minimal costassignment.Proof. ConcFB termination is initiated by the first agent (lines 5–6 of the Backtrack() function). The termination messagewill only be broadcast after all SPs are exhausted (line 3 of Backtrack()) so no other types of messages are generated (andhence UB will not be re-set after all SPs are exhausted). To prove optimality one must verify that whenever a new completeassignment with minimal cost is generated it is recorded, and that no valid assignments were pruned during search.An upper bound cost is valid only if its corresponding assignment includes all agents and if its cost is lower than thecurrent upper bound. This can only occur when the last unassigned agent successfully assigns a new value of lower cost.Lines 11–14 of the Assign_CPA() function manage this functionality. If the condition on lines 7 and 8 of this function hold,then a new upper bound is recorded by the last agent and all other agents are notified and consequently record this value(lines 17–19 in Main()).To prove that no other valid values are pruned one must examine all cases where an agent changes a CPA or skips avalue.A value may be skipped in line 5 of Assign_CPA() or as a result of line 4 of Receive_LB_Report(). In both cases the valueis skipped when the combined cost of the CPA, the current assignment and the minimal cost of future (unassigned) agentsis greater than the current cost of UB. Clearly the cost of the current assignment will not lead to a solution of lower costthan that of UB at termination and hence this value may be skipped over.Let us now consider all cases which lead to a change of value:• Assign_CPA() is invoked in line 4 of Init_SP(). Since this is the initial assignment of an SP and no prior value existedthere is no risk that this call prunes any part of the search space.• Receive_CPA()’s line 6 invokes Assign_CPA(). In this case an agent Ai receives a new CPA from a higher priority agentafter some change of value by its predecessors. Since Ai did not yet pick an assignment at this point, any assignment itwill make will not lose any potential solutions.• Assign_CPA() is called from line 7 of Receive_BT_CPA() as a result of a lower priority agent’s message. When a BT_CPA issent from a lower priority agent one can conclude that the entire subspace originating from the current CPA was fullyexplored and as a result any change of value will not result in lost solutions.• Assign_CPA() is called from line 7 of Receive_BT_CPA() as a result of a “message” from the agent to itself (line 15of Assign_ CPA() followed by line 9 of Backtrack()). This case will occur when an agent reaches a full CPA and mustexamine the cost of other assignments. Since the cost of each full CPA is examined and recorded (when a new UB valueis found) there is no risk of pruning solutions.Note that a similar situation can occur in line 8 of Receive_LB_Report(). However, this was considered as a value skippingcondition – discussed above.Finally, one must pay attention to situations in which a CPA is discarded. This can occur whenever an SP is fully explored(“exhausted”) – in line 2 of Backtrack(). However, since the CPA is discarded only after the SP it belonged to was exhausted,no part of the subspace is skipped or pruned.200A. Netzer et al. / Artificial Intelligence 193 (2012) 186–216(a) CPA assignments per SP, static lexicographic ordering.(b) CPA assignments per SP with random ordering.Fig. 16. Work load distribution with random ordering and with static lexicographic ordering.In conclusion, whenever a value is skipped, changed, or a CPA is discarded no better solutions are lost. Therefore, attermination ConcFB reports the lowest possible cost. (cid:2)5. EnhancementsThis section describes further enhancements to the basic ConcFB algorithm. Dynamic variable orderings and dynamicsplitting are introduced, and the pseudocode to incorporate these enhancements is presented.5.1. Variable orderingDynamic reordering was shown to significantly boost performance for DCSP algorithms. However, there are a limitednumber of works discussing dynamic reordering for DCOPs (a notable exception is [24] which focuses on reordering pseudotree based algorithms and may therefore be applied to DCOPs). The present paper presents two dynamic variable orderingheuristics which utilize the synchronous search carried out on each SP. One heuristic is aimed at improving the concurrencyof the algorithm, and the other is designed to improve the algorithm’s pruning ability by the use of a “fail first” heuristic.5.1.1. Random orderingTo illustrate the motivation for random variable ordering one can examine the work load distribution between the agentsduring a ConcFB run. Fig. 16(a) shows a histogram of the number of CPA assignments per agent during the run of ConcFBwith four Search Processes and twelve agents. It is clear that most of the assignments are done by agents 5–10. The firstfour agents are doing little work, being located at the higher levels of the search tree. Agents 10–12 are doing little workdue to effective pruning.To achieve a balanced work load distribution among the agent, one can use a random ordering scheme. The order ofvariables in each search process (after the Initiating Agent) is randomly selected. The only change needed in the pseudocodeis in the Receive_LB_Report() function, where the random selection of the next agent is inserted (line 6 in Fig. 17).A. Netzer et al. / Artificial Intelligence 193 (2012) 186–2162011 SPid ←− SP_list.get(msg.sp_id)2 SPid.LB_List[msg.origin] ←− msg.LB3 if received LB_Report messages from all unassigned neighbors then4(cid:2)if SPid.CPA.cost + SPid.Current_Assignment_Cost +CPA ←− SPid.CPA ∪ SPid.Current_AssignmentNext_Agent ←− random unassigned agentsend(CPA, Next_Agent, CPA and SPid.LB_List)SPid.LB_List[i] < this.UB thenelseReceive_BT_CPA(msg)Fig. 17. Receive_LB_Report(msg) – random ordering.56789Fig. 16(b) shows the same setup run with random variable ordering. One can clearly see the more balanced distributionamong all agents.5.1.2. Fail first orderingA different approach to dynamic ordering is to use reordering not for the purpose of improving concurrency, but inorder to improve pruning. One can use a “fail first” heuristic that is aimed at reaching the Upper Bound as soon as possible.A naive approach to “fail first” variable ordering would be to set the next agent in the ordering as the agent whose reportedLB value is maximal. However, ordering agents in this fashion is not expected to change performance. The reason for thatis that all unassigned agents are guaranteed to receive at least the same LB values as those received by the agent selectingthe next one in the order. Hence their expected impact can not be distinguished based on this information.To asses the possible impact of future agents on the total cost we consider unassigned agents’ average cost with otherunassigned agents. That is, we let each agent reporting its LB, calculate the additional average cost with others, assumingits LB assignment is used.Let Xi be a variable owned by agent Ai , which received an LB_Request message and let Xlbi be the assignment thatj its assignment. We write |Dom( X j)|produced the current LB for its LB_Report() message. X j represents a variable j and X ato specify the size of the complete domain of variable j. Agents precedence ordering is based on a calculated heuristicvalue:(cid:2)h XiCPA=(cid:3)X j /∈CPAa∈Dom( X j ) Cost(X a|Dom(X j)|j , Xlbi ).h XiCPA sums the average costs of unassigned variables with respect to Ai ’s LB assignment. This value is then sent back alongwith the Lower Bound. Note that the average cost of every agent with all other agents can be calculated in a preprocessstage in polynomial time.Whenever an agent receives an LB_Report message, it registers the h values along with the lower bound. When an agentselects its next agent, it selects the one with the highest h value. Figs. 18 and 19 show the code updates needed for the“fail first” heuristic dynamic ordering.5.1.3. Correctness of ConcFB with variable orderingTheorem 3. ConcFB with variable ordering terminates and is complete.Proof. As before, the initializing agent partitions the search space to disjoint parts. As a result one needs only consider thecorrectness of a single SP (see Observation 1).We use induction over the number of agents to prove that ConcFB with variable ordering maintains correctness and relyon the fact that the highest priority agent in all ordering remains the same – the initializing agent. The base case of ourinduction includes a single agent. In this case, ordering is static and the search is both complete and it terminates. Next,assume that our induction assumption is true for any DCOP with k < n agents and consider a DCOP with n agents.Since the initializing agent will never change its position within the ordering, it will assign its value and send it toone of the next (unassigned) agents. The remaining DCOP has n − 1 agents and its initial order is set by the initializingagent’s choice. By the induction assumption the remaining DCOP is complete and will terminate. That is, if a new upperbound is found it will be shared with all other agents (on all SPs) and its termination will result in a BT_CPA() messagesent to the initializing agent. The initializing agent will either attempt a different assignment (invoke Assign_CPA() in line 7of Receive_BT_CPA()) or backtrack and end the search in this SP (lines 1–6 of Backtrack()). Whenever a new successfulassignment is made the initializing agent again send it to one of the unassigned agents. As before the remaining DCOP hasn − 1 agents and applying the search on it is both complete and terminates. This number of times this process repeats itselfis exactly based on the number of values in the initializing agent’s domain, and thus the process must end within a finite202A. Netzer et al. / Artificial Intelligence 193 (2012) 186–216(cid:2)1 LB = mind∈Domain{xi ∈msg.CPA.vars Cost(xa2 dlb ←− assignment that produced the LBi , d)}(cid:2)(cid:2)3 h =X j /∈CPAa∈Dom( X j ) Cost( Xa|Dom( X j )|j , Xlbi )4 send(LB_Report, msg.origin, LB, h)Fig. 18. Receive_LB_Request(msg) – heuristic ordering.1 SPid ←− SP_list.get(msg.sp_id)2 SPid.LB_List[msg.origin] ←− msg.LB3 SPid.h_List[msg.origin] ←− msg.h4 if received LB_Report messages from all unassigned neighbors then5(cid:2)if SPid.CPA.cost + SPid.Current_Assignment_Cost +CPA ←− SPid.CPA ∪ SPid.Current_AssignmentNext_Agent ←− agent with highest hsend(CPA, Next_Agent, CPA and SPid.LB_List)678910elseReceive_BT_CPA(msg)Fig. 19. Receive_LB_Report(msg) – heuristic ordering.SPid.LB_List[i] < this.UB then(a) Total number of assignments per SP.(b) Total number of upper bounds reached per SP.Fig. 20. Work load per search process.amount of time. Its correctness stems from the fact that during each phase the minimal cost solution which includes allagents is found and broadcast to all agents. (cid:2)5.2. Dynamic splittingFig. 20(a) presents the assignments statistics of each of the 4 SPs that were created during the run time of ConcFB. Itincludes the total number of CPA assignments, per each of the SPs. There are 14 variables in the example with an averageof 4 neighbors per variable, and a domain size of 4.One can see that the distribution of CPA assignments is not uniform among the search processes. In this example SP2has about half the number of CPA assignments than that of SP1. This will result in SP2 exhausting its subspace much earlierthan other SPs, and lowering the degree of concurrency of the algorithm. Spawning more SPs to search the subspace ofSP1 will balance the work load among all search processes, and ensure that enough SPs are active at each time during thesearch.To increase the level of concurrency, a dynamic split request is passed to the agent which spawned the current SP whichin turn partitions the existing SP.5 Such a dynamic splitting heuristic for the DCSP case is described in [31]. In [31] theheuristic measures the number of assignments in a given SP, and when this value exceeds a given threshold a split isrequested. However, in the DCOP setting, dynamic splitting may also be used to focus the search efforts in promising sub-spaces which are more likely to produce Upper Bounds. Fig. 20(b) presents the distribution of the number of Upper Boundsfound per SP for the same runtime example. As can be seen, the number of Upper Bounds found can vary significantlybetween SPs. In this case, SP1 reaches most of the upper bounds and partitioning it into smaller subspaces is expected toimprove the overall pruning of the algorithm.5 This corresponds to an OR node which represents the split point to the original OR tree.A. Netzer et al. / Artificial Intelligence 193 (2012) 186–216203Split depthnn − 1n − 2n − 3n − 4n − 5n − 6n − 7n − 8n = 14, D = 5, k = 4Max SPs1840922306462049667915 12522 151NCCC474 936471 936453 880453 907459 084474 936483 030491 874495 933n = 10, D = 10, k = 4Max SPs2142882287851896–––NCCC201 010202 593199 194195 304202 718210 025–––Fig. 21. The maximal number of concurrent SPs and the number of NCCC as a function of split depth request, averaged over 50 executions with n agents, adomain size D and k neighbors per agent.While there are numerous partitioning heuristics, we propose a dynamic split mechanism in which agents residing inthe lower parts of the search tree send split requests for every search process that reaches them. The split request is sentto the agent that originated the search process, asking it to re-split. This heuristic is aimed at focusing search efforts onpromising parts of a SP, as implied by Fig. 16(a). Determining the threshold depth for sending a split request can have asignificant impact on the number of search process. In extreme cases over splitting may result in thrashing and increasedmemory load of agents.The impact of the split depth’s value on the maximal number of concurrent SPs and the total number of NCCCs ispresented in Fig. 21. We say that two or more SPs are concurrent if at a given moment both SPs are active. The tablemeasures split depth relative to the total number of agents, such that a split depth of n means that a split request isgenerated only by the last agent. The table shows an exponential increase in the maximal number of concurrent SPs as thesplit depth decreases and that the number of NCCCs is minimal for split depths of roughly n − 3. To understand these results,first consider split depth values which are greater than n − 3. An increase in the split depth decreases the maximal numberof concurrent SPs and concurrency in general. The number of NCCCs will therefore increase as less work is being donesimultaneously. In contrast, when lowering the split depth’s value the number of concurrent SPs dramatically increases andeach agent must process requests from multiple, relatively shallow, SPs. These requests interfere with the agents progresstowards new solutions which lie at the bottom of the search tree and as a result the number of NCCCs increase.5.2.1. Integrating dynamic splitting to ConcFBTo identify the originator of the Search Process, and keep track of search processes, a unique SP_ID is constructed froma list of pairs. That is, SP_ID = (cid:3)Agent, Counter(cid:4) where Agent is the ID of the creating agent, and Counter is incremented forevery search process spawned by that agent. The originator agent of a search process can always be retrieved by looking atthe Agent field of the SP_ID.To request dynamic splitting a new type of message is used:Split_Request A split request is sent to an agent asking it to split a specific Search Process.The main function is updated to respond to this type of message and upon receiving Split_Request it calls a new functionReceive_Split_Request() (lines 17, 18 in Fig. 22).In Receive_Split_Request() (Fig. 23) the agent retrieves the Search process that needs to be split (line 1). If the relevantSP domain has more than one value that was not assigned yet (line 2), then the current search process can be split. A newSP_ID is created in line 3, a new SP is created with the new SP_ID, and with half of the splitting Search Process domain(line 4). The new SP is added to the father SP Splits list (line 5), it is added to the agent SP_list (line 6) and Assign_CPA() iscalled for the new SP (line 7).If the current domain of the father SP is too small to split, and if the current agent is not too deep in the search tree(line 9), a Split_Request is sent to the next agent down, trying to split the SP deeper in the search tree (line 10).In addition to the new Receive_LB_Report() function, Receive_CPA() needs to be updated in order to support dynamicsplitting. The updated routine is presented in Fig. 24. In line 5 the newly created search process adds itself to its own splitslist. In lines 7, 8 the depth of the search tree is checked, and if a given depth is reached, a Split_Request is sent. A goodheuristic for the target depth was found experimentally to be the bottom quarter of the search tree.The last change required in the basic ConcFB pseudocode in order to support dynamic splitting, is crucial to maintainingcorrectness. The Backtrack() routine must be updated to make sure that all Search Processes spawned from a given Father_SPended their search, before Father_SP can backtrack (Fig. 25). The Father_SP of the backtracked SP is located in line 8. Thebacktracked SP is removed from its father splits list (line 9), and if this list is empty then the Father_SP backtracks.5.2.2. Correctness of ConcFB with dynamic splittingTheorem 4. ConcFB with dynamic splits terminates and is complete.204A. Netzer et al. / Artificial Intelligence 193 (2012) 186–2161 done ←− false2 if Initializing_Agent then345Root_SP := new SP(SP_ID(root), domain)Root_SP.splits := new Split_Set()Init_SP()6 while not done do7msg ←− Get_Next_Msg()switch msg.type docase CPA:Receive_CPA(msg)case BT_CPA:Receive_BT_CPA(msg)case LB_Request:Receive_LB_Request(msg)case LB_Report :Receive_LB_Report(msg)case Split_Request:Receive_Split_Request(msg)case Upper_Bound:if msg.UB < this.UB thenthis.UB ←− msg.UBcase Terminate:done ←− true891011121314151617181920212223456724 return this.UBFig. 22. Main() – dynamic splitting.1 spcurrent ←− SP_list.get(msg.sp_id)2 if spcurrent.Current_Domain.Size > 1 then3SP_ID := new SP_ID(serial, counter)spnew := new SP(SP_ID, spcurrent .Current_Domain.Split_Domain())spcurrent.splits.add(spnew)SP_list.add(spnew)Assign_CPA(spnew)8 else9if Not last agent then10send Split to next agent;Fig. 23. Receive_Split_Request(msg) – dynamic split.1 SPid := new SP(msg.sp_id, domain)2 SPid.CPA ←− msg.CPA3 SPid.Org_LB_List ←− msg.LB_List4 SPid.Org_LB_List.remove(LB of current agent)5 SPid.splits ←− msg.sp_id6 SP_list.add(SPid)7 if SPid.CPA.Number_Of _Assigned_Agents > Split_Depth then89 Assign_CPA(SPid)send Split to msg.sp_id.originator;Fig. 24. Receive_CPA(msg) – dynamic split.Proof. Proving that ConcFB with dynamic splits maintains correctness requires proving that the union of all subparts equalsthe entire SP’s space, that the search on all subparts of an SP are complete and terminate and that the algorithm do notconclude the search of the original SP before all subparts conclude.It is easy to see that a split request partitions the search space into disjoint parts which include all values of the splittingagent’s current domain (line 4 of Receive_Split_Request()).A. Netzer et al. / Artificial Intelligence 193 (2012) 186–2162051 if Initializing_Agent then2Root_SP.splits.remove(SPid)if Root_SP.splits.isEmpty? thensolution ←− this.UBdone ←− trueBroadcast(Terminate, null)Father_SP ←− father SP of SPidFather_SP.splits.remove(SPid)if Father_SP.splits.isEmpty() thenai ←− SPid.CPA.Last_Assigned_Agent()send(BT_CPA, ai , SPid.sp_id)345691011127 else8Fig. 25. Backtrack(SPid ) – dynamic split.To address the second point, it is enough to see that by generating sub-SPs from different values in the domain of theoriginal SP one creates disjoint search (sub)spaces (cf. Observation 1). Next, by following the correctness of SFB the searchon individual sub-SPs is complete and terminates.A complete search through each sub-SP is insufficient. To maintain correctness of ConcFB, the algorithm must not con-clude the search of an SP until all subsearches conclude.The dynamic split version of ConcFB achieves this by requiring that all sub-SPs are completed prior to sending a BT_CPAmessage to the last assigned agent (lines 10–12 of Fig. 25). Thus, whenever an agent executes the Backtrack() function ofFig. 25 it removes the current SP from its splits list (which may contain only the existing SP if the agent did not receive asplit request at an earlier stage), and hold messages to its predecessor until all sub-SPs are terminated. This guarantees thatonly after the search process is thoroughly examined a report acknowledging this fact is sent. (cid:2)6. Experimental evaluationThe experimental evaluation is divided into four subsections. The first subsection deals with a comparison betweenConcFB and other state of the art DCOP algorithms. The second, explores performance in a network environment where thecost of communication is significantly higher than the cost of computation. An evaluation of the concurrent search approachis detailed in the third subsection where we compare ConcFB with a concurrent search version of SBB. Finally, we analyzeConcFB and quantify the impact of each component in the algorithm.In all experiments the evaluated ConcFB variant included dynamic fail first reordering and dynamic splitting with thesplit depth heuristic set to n − 2.6.1. Algorithm performanceTwo performance measures are routinely used to evaluate DCOP algorithms: run-time in the form of Non-ConcurrentConstraints Checks (NCCCs) [32], and network load measured as the total number of messages sent [15,28].We focus the present evaluation on a comparison of ConcFB to leading DCOP algorithms – BnB-ADOPT [26], AFB-CBJ [9],ODPOP [23] and BnB-ADOPT+ [11] – a recent improvement of BnB-ADOPT which removes redundant messages (note thatBnB-ADOPT+’s computational effort in terms of NCCCs is exactly the same as BnB-ADOPT).Although DPOP is often used for solving DCOPs, we find it impractical for the problems we experimented on, mainly dueto its exponential sized messages. As discussed in Section 2.2, ODPOP [23] provides as a remedy for the exponential sizedmessage problem of DPOP on regular DCOPs.The main computational operation of ODPOP is the comparison of combinations of assignments, sent to each computingagent by its offspring in the pseudo tree [23]. This operation is performed by each agent in order to find an assignment foritself that is optimal with respect to the assignments of its ancestors.The introduction of ODPOP requires that all run time experimental evaluations are given in terms of non-concurrentlogical operations (NCLO). For ODPOP these are compatibility checks, and for BnB-ADOPT and ConcFB they are constraintschecks.In a recent paper, BnB-ADOPT was shown to be superior to both ADOPT and NCBB [26]. The present evaluation usesBnB-ADOPT with DP2 as a preprocessing phase for h values [1]. Synchronous branch & bound algorithm (SBB) with bestvalue assignment is used as a reference algorithm. The AFB variant used in our evaluation is the best known one – AFB-CBJ.In AFB-CBJ, back-jumps to the offending agent are used instead of simple backtrack steps. This provides a potential speedupof the original algorithm [9].Following [26] we applied a Distributed DFS protocol to all pseudo tree based algorithms. Communication overhead ofthis protocol was not added to the comparison.206A. Netzer et al. / Artificial Intelligence 193 (2012) 186–216Our evaluation setup included three problem types – Graph Coloring, Random DCOPs and sensor networks. In each setup50 instances were generated for each set of parameter configuration and the reported results were averaged over all runs.Fig. 26. A sensor network example.• Graph Coloring: This setup reconstructs the Graph Coloring tests presented in [26]. In this setup, each vertex cor-responds to an agent. An edge between two vertices corresponds to a constraint. Constraint costs are randomly anduniformly selected from the range of 0 to 10 000 and each vertex degree is set to 3 (randomly selected). The evaluationincluded several different setups where the number of agents used was varied across setups from 5 to 15. Each agent’sdomain include three possible values (colors). All problems instances are connected graphs.• Random problems: Random DCOPs include a set of agents randomly constrained with one another. This setup includesunstructured problems which are denser than the Graph Coloring problems and in which, if not specified otherwise,constraints costs were uniformly sampled in the range of 0 to 10 000. The number of agents, graph density, agents’domain sizes and cost ranges were varied to assess the algorithms robustness to different setups. As before, problemsinstances include connected graphs only.• Sensor networks: The sensor network setup models a target tracking system [26,16]. Sensors jointly attempt to tracktargets taking into account the availability of other sensors, the number of sensors required to track a target and thesensors spatial configuration. In this setup, agents are the targets, their domains are the time slots when they are beingtracked and the constraint are between adjacent targets. The cost of assigning a time slot to a target that is also assignedto an adjacent target is infinity (or a sufficiently large enough number) since the same sensor cannot track both targetsduring the same time slot. Similar to [26], the cost of tracking a target is in the range of 0 to 100, and the cost of atarget untracked during any time slot is 100.Fig. 26 depicts a sensor network example. In this example, there are 6 targets tracked by a grid of 3 × 4 sensors. Targetsare only constrained with other adjacent targets. In the evaluation of this setup the number of targets varied in therange of 5 to 14 over a grid of 3 × x sensors (where the number of sensors varied to accommodate the number oftargets).Fig. 27 presents performance measurements in the Graph Coloring setup. One can see that ConcFB outperforms all algo-rithms but ODPOP on both metrics. It is about twice as efficient in terms of NCLOs, and provides a significant improvementin terms of messages over BnB-ADOPT and BnB-ADOPT+. ConcFB also outperforms AFB-CBJ by at least an order of magni-tude in both metrics. ODPOP on the other hand, trades high computational effort with lower network load. Thus, althoughit uses less messages, its run time in terms of NCLOs is a hundred times slower.The results in Fig. 27(a) are in accordance with those reported by [26] for BnB-ADOPT. Since the BnB-ADOPT messagingscheme is similar to that used by ADOPT [21], the resulting high number of messages is not surprising – as was alreadyfound by [9].Our results also reaffirms the low number of messages used by ODPOP. It indicates the high computational effort associ-ated with the process of combining assignments and the trade off between computational effort and network load.The initial experiments conducted on Random DCOPs introduced a dramatic increase in the NCLO count of ODPOP.As problems became more constrained ODPOP’s performance rapidly degraded in comparison to other algorithms. Fig. 28presents a small random problem with 8 variables and a domain size of 4. As the number of constrained neighbors per agentincreased from 3 to 5 the number of NCLOs required by ODPOP rapidly increased. Applying ODPOP on larger problems didnot return within a reasonable time, and was therefore removed from the full sized Random DCOP setup.Fig. 29 presents the results of the random problems with 12 agents and a domain size of 5. The number of constrainedneighbors per agent was varied across setups from 3 to 7. In this setup the NCLO measure is actually equivalent to NCCC,for all algorithms. One can see that ConcFB outperforms BnB-ADOPT by 2 to 3 orders of magnitude and AFB-CBJ and BnB-ADOPT+ by 1 to 2 orders of magnitudes, on both metrics.These experiments show that BnB-ADOPT and BnB-ADOPT+ do not scale as well as ConcFB and AFB-CBJ to higher densityproblems. To understand this difference in performance one must examine two important aspects of BnB-ADOPT/+:A. Netzer et al. / Artificial Intelligence 193 (2012) 186–216207Fig. 27. Experimental results for the Graph Coloring setup (5 to 15 agents, domain size of 3 and density value 3).Fig. 28. Experimental results for small random problems (8 agents, domain size of 4 and varying number of neighbors).• Both rely on a pseudo tree arrangement of agents. As the density value increases, a “wide” pseudo tree becomes lesslikely and as a result concurrency level decreases.• BnB-ADOPT/+’s inability to reuse bounds. In these algorithms, when a CPA change does not violate the descendant’sassignment, all bounds are still valid. As constraint density increases, the probability that a CPA change will not violateany constraint decreases and bounds have to be recalculated.The relative robustness of ConcFB to various changes in the problem parameters is demonstrated in Figs. 30 and 31. Inthese experiments the averaged performance of ConcFB, BnB-ADOPT+, AFB and SBB was compared on problems with 12208A. Netzer et al. / Artificial Intelligence 193 (2012) 186–216Fig. 29. Experimental results for random problems (12 agents, domain size of 5 and varying number of neighbors).agents, each with 4 neighbors and varying domain sizes or costs structure. In the first setup, the domain size was varied inthe range of 3 to 8 (Fig. 30) and in the second one it was set to 5 and the costs were uniformly selected from the range 0 tox, where x = {1, 10, 100, 1000, 10 000} (Fig. 31). The results clearly validate ConcFB’s superiority over other state of the artalgorithms. ConcFB’s significant improvement over other algorithms in NCLOs and the number of messages is maintainedeven in the presence of these changes.Fig. 32 presents the performance of ConcFB, SBB, BnB-ADOPT+ and AFB as a function of the number of targets tracked inthe sensor network problem. These results are consistent with the evaluation of the other setups reaffirming the advantageConcFB holds over other algorithms.All run-time measurements of DCOP algorithms use a non-concurrent metric such as NCCCs or NCLOs, taking into accountthe concurrency of agents’ computations. However, these pure measures count steps of non-concurrent computation andare not influenced by details of implementation. In order to provide some insight on the cost of agents’ actions which gobeyond the most common logical operation – for example, operations on complex data structures – the CPU run-time hasbeen measured in one of the experiments.Fig. 33 presents the total CPU run time of ConcFB, SBB, BnB-ADOPT/+ and AFB. Although all experiments were conductedon the same platform (4 Cores Intel i5, 2.9 GHz, 4 GB RAM and 64 bits Windows 7) measuring the relative performancehelps to reduce some of the potential effects that the hardware may have on the evaluation. The results indicate that thetotal time required for BnB-ADOPT/+ is relatively higher than other algorithms. One possible explanation is that this may bedue to the computational overhead involved in processing messages and priority merges which are not measured by NCLOs.Pruning irrelevant messages by BnB-ADOPT+ seems to reduce this computational overhead. An alternative explanation forthese results can be the high concurrency level of the BnB-ADOPT versions which results in multiple computations carriedout at the same time and a large thread management overhead, which increase the CPU run time.A. Netzer et al. / Artificial Intelligence 193 (2012) 186–216209Fig. 30. Experimental results for random problems with 12 agents, 4 neighbors and domains of various sizes.6.2. Measuring performance in high latency networksIn many realistic settings communication time is dominant over computation time. In these settings a more appropriateevaluation metric is the number of non-concurrent steps (NC-Steps). This metric details the length of the longest chain ofmessages between agents [9,26].Fig. 34 presents the number of NC-Steps performed by SBB, AFB, BnB-ADOPT, BnB-ADOPT+ and ConcFB. In the graphcoloring setting (Fig. 34(a)), BnB-ADOPT+, ODPOP and ConcFB the number of NC-Steps is comparable, however, on the largerproblems with higher density values, ConcFB’s longest chain of messages is at least an order of magnitude shorter than thatof all other leading algorithms (Fig. 34(b)). It should also be noted that in these problems ODPOP failed to complete withina reasonable time and was therefore omitted (cf. Fig. 28).One can see that BnB-ADOPT+ improvement over BnB-ADOPT is consistent with its improvement in the total number ofmessage (Fig. 27(b) and Fig. 29(b)). In contrast, despite SBB’s significantly lower number of messages when compared toBnB-ADOPT and BnB-ADOPT+ (Fig. 29(v)) it is outperformed by BnB-ADOPT+ in terms of NC-Steps. This is due to the fact theSBB operates in a synchronous (sequential) manner whereas BnB-ADOPT and BnB-ADOPT+ are capable of sending messagesconcurrently.6.3. Evaluating concurrent searchWe next proceeded to evaluate the concurrent search approach by comparing ConcFB against SBB and its concurrentsearch implementation. We extended the Synchronous Branch and Bound algorithm so that multiple instances of this al-gorithm are executed on each search process. Each search process applied a different random (static) ordering and theresulting algorithm is referred to as ConcSBB. The performance evaluation of SBB, ConcFB and ConcSBB with the split depthheuristic set to n is presented in Fig. 35. Each data point represents the averaged results of 50 random problems with 12agents, domain size of 5 and varying number of neighbors.210A. Netzer et al. / Artificial Intelligence 193 (2012) 186–216Fig. 31. Experimental results for random problems with 12 agents, domain size of 5 and 4 neighbors. In these problems, integer cost ranges were varied inthe interval 0 to x, where x = {1, 10, 100, 1000, 10 000}.Not surprisingly, ConcFB outperforms ConcSBB in both measures by roughly two orders of magnitude. ConcSBB’s perfor-mance is significantly better than that of SBB in terms of NCLOs but not in terms of network load. This latter point, wherethe large number of messages generated by ConcSBB is inconsistent with its improvement over SBB, reveals the intricaterelation between concurrent search and the underlying algorithm applied to each SP.In this setup, the majority of messages are either due to an extension of the CPA or a backtracking messages for both SBBand ConcSBB. These message types are correlated with the covered parts of the search area. An equal amount of messagesimplies that on the average ConcSBB covers the same percentage of the search space as SBB. The improvement in ConcSBB’sNCLO over SBB demonstrates its ability to concurrently cover the same space.Note that despite the introduction of multiple upper bounds from different search processes a concurrent search algo-rithm does not necessarily cover smaller parts of the search space. This is due to unknown distribution of the costs andupper bounds within the search space.It is worth noting that unlike ConcFB, ConcSBB is much more susceptible to search process thrashing when applyingthe split depth heuristic presented in Section 5.2. The limited pruning ability of ConcSBB results in significantly moreassignments in lower parts of the search tree. As a result the number of split requests in ConcSBB is expected to substantiallygrow as the split depth is decreased, as presented in Fig. 36.6.4. Analysis of ConcFBOur analysis of ConcFB’s components and their contribution yielded four variants of the algorithm:• FB: A single synchronous forward bound search process. No concurrent search with static lexicographical ordering andNo dynamic splitting.A. Netzer et al. / Artificial Intelligence 193 (2012) 186–216211Fig. 32. Experimental results for the sensor network problem, with varying number of tracked targets.Fig. 33. CPU run time for random problems (12 agents, domain size of 5 and varying number of neighbors).• ConcFB-LO: A multiple search process, forward bounding search algorithm, with lexicographical ordering. No dynamicsplitting was used by this variant.• FB-DR: Similar to FB but with the heuristic fail first dynamic reordering of agents.• ConcFB-DR: A multiple search process, forward bounding search algorithm, with the heuristic fail first dynamic reorder-ing. No dynamic splitting was used by this variant.• ConcFB-Full: A fully featured ConcFB algorithm.212A. Netzer et al. / Artificial Intelligence 193 (2012) 186–216Fig. 34. The number of NC-Steps performed on graph coloring (a) and random (b) problems.These variants were tested on even larger random problems with 15 variables, a domain size 5 and 10 neighbors peragent. Constraint costs are uniformly sampled in the range of 0 to 10 000. 50 instances were generated for each set ofparameter configuration and the reported results were averaged over all runs. Fig. 37 presents the difference in performanceof the five ConcFB variants. One can see that dynamic ordering improves the NCCC count of FB by a factor of three. Addingadditional concurrent search processes improves NCCC performance by a factor of two (both with lexicographical orderingand with dynamic reordering), and another 10 percent is gained by the dynamic splitting.Similar trends are observed for network load, presented in Fig. 37(b). One can see that the total number of messagessent by FB decreases when dynamic ordering is introduced by roughly the same factor as NCCCs. This indicates that thefail first dynamic ordering heuristic improves the algorithm’s performance through increased pruning and not necessarilythrough increased concurrency. When comparing the total number of messages of the multiple search processes variantsand the single search process one, one can see that there is little improvement, despite the improved NCCC count (up toa factor of 2). This implies that concurrent search ConcFB improves NCCC count by increasing concurrency of computation,but does not reduce the total amount of computation performed.One can see that the dynamic reordering heuristic (Section 5.1.2) introduces a significant improvement to the naiveSynchronous Forward Bounding algorithm. Fig. 38 presents a comparison of SFB with dynamic reordering (FB-DR) and SBB,ConcFB, BnB-ADOPT+ and AFB. As before, the experimental setup included random problems with 12 agents, a domain sizeof 5 and varying number of agents.FB-DR provides a significant improvement over all state of the art algorithms. In comparison to ConcFB, FB-DR generatesroughly the same number of messages but does significantly more NCLOs.This can be understood by realizing that both ConcFB and FB-DR share the same powerful pruning abilities and thuscover a similar amount of the search space. The introduction of SP splitting by ConcFB results in greater concurrency andfewer NCLOs in comparison to FB-DR (this is in accordance to the difference in SBB and ConcSBB discussed in Section 6.3).A. Netzer et al. / Artificial Intelligence 193 (2012) 186–216213Fig. 35. Experimental results for random problems with 12 agents, domain size of 5 and varying number of neighbors.Split depthMax SPsn1161n − 122 529n − 2134 534n − 3243 467n − 4296 046n − 5308 274n − 6316 837Fig. 36. The maximal number of concurrent SPs in ConcSBB as a function of split depth request with 12 agents, a domain size 5 and 4 neighbors per agent.Fig. 37. ConcFb analysis.214A. Netzer et al. / Artificial Intelligence 193 (2012) 186–216Fig. 38. Performance of SFB with dynamic reordering (FB-DR) on problems with 12 agents, domain size of 5 and varying number of neighbors.Fig. 39. Performance of ConcFB with different ordering scheme on problems with 15 agents, domain size of 5 and 10 neighbors.We further analyzed the empirical impact of the chosen dynamic ordering heuristic with respect to the static lexi-cographical ordering and random dynamic ordering. The evaluation included ConcFB with static lexicographical ordering(ConcFB-LO), the dynamic fail first ordering heuristic described in Section 5.1.2 (ConcFB-DR) and dynamic random ordering(ConcFB-RR). 50 instances of random problems with 15 agents, a domain size of 5 and 10 neighbors to each agent wereexamined and the results of this evaluation are presented in Fig. 39.The results demonstrates the impact of dynamic ordering heuristics. As demonstrated in Fig. 16(b) the introductionof random ordering balances the load on agents which enables higher concurrency and reduces the number of NCCCs.A. Netzer et al. / Artificial Intelligence 193 (2012) 186–216215Nonetheless, the portion of the search space covered with random ordering remains roughly the same as that covered inthe lexicographical ordering version of ConcFB and hence the number of messages passed between agents is similar.The proposed dynamic ordering attempts to further improve on the random ordering scheme by guiding the search tomore promising parts of the search space. This enables ConcFB-DR to better prune the search and results in a lower numberof NCCCs and reduced network load.7. ConclusionThe present paper presents ConcFB – a Concurrent Forward Bounding algorithm for solving DCOPs. ConcFB combinestwo powerful techniques: Concurrent search and synchronized Forward Bounding. The combined approach results in analgorithm which is characterized by a high degree of concurrency and is capable of rapid pruning of the search space.Although any DCOP algorithm may be applied to the individual search processes, the present work focuses on SFB. SFBhas two important features that make it suitable for concurrent search: powerful pruning abilities and synchronous progress.In particular, the latter feature guarantees that any split request received by the agent is relevant to the system’s overallstate. This is not necessarily the case when dealing with asynchronous algorithms. For example, in Asynchronous ForwardBounding and in BnB-ADOPT a split request may be triggered by an agent holding an invalid view of the current assignment.In other words, the partial assignment held by the agent requesting a split can be outdated. This raises significant challengesin the application of Concurrent Search to asynchronous algorithms which is left open for future research.The present work also demonstrates the benefits of applying dynamic reordering to DCOP algorithms. Some work onreordering pseudo tree based algorithms was presented by [24]. However, there is no work specifying how to adapt theseto asynchronous algorithms which use a time stamping mechanism such as AFB and BnB-ADOPT. This stems from themechanism’s reliance on the agents total order to infer the relation between two different time stamps – a point we intendto pursue in future work.To conclude, the benefits of the proposed concurrent search approach are threefold:1. The agents applying forward bounding on disjoint parts of the problem share upper bound information across multiplesearch processes.2. Each search process is independent of all others and can apply different search heuristics.3. Additional search processes can easily be added to maintain a preferred level of concurrency.Three enhancements to the basic ConcFB algorithm are presented. The first enhancement introduces a random orderingheuristic for agents which significantly balances the work load. The second one introduces a fail first heuristic for DCOPswhich results in a significant improvement of the algorithm’s pruning abilities. Finally, dynamic splitting – the ability tospawn new search processes – is added and shown to further improve ConcFB’s performance.ConcFB is proved to terminate with an optimal solution and its performance is extensively evaluated. An extensive setof experiments on both structured and unstructured problems evaluates ConcFB’s performance against other state of the artDCOP algorithms. Additionally, a new concurrent algorithm – ConcSBB – was implemented to provide further insights on theworkings of a concurrent search algorithm with multiple Search Processes. Measuring performance in terms of NCLOs, NC-Steps, network load and CPU time, ConcFB is shown to outperform BnB-ADOPT, BnB-ADOPT+, AFB-CBJ, ODPOP and ConcSBB.A second set of experiments which quantifies the gain of different enhancements to the ConcFB algorithm is also pre-sented. It is shown that the combination of a Fail First heuristic with multiple search processes and a dynamic splittingscheme can improve the algorithm’s performance by up to an order of magnitude.References[1] Syed Muhammad Ali, Sven Koenig, Milind Tambe, Preprocessing techniques for accelerating the DCOP algorithm ADOPT, in: 4th International JointConference on Autonomous Agents and Multiagent Systems (AAMAS’05), Utrecht, The Netherlands, July 2005, pp. 1041–1048.[2] Ismel Brito, Amnon Meisels, Pedro Meseguer, Roie Zivan, Distributed constraint satisfaction with partially known constraints, Constraints 14 (2008)199–234.[3] David A. Burke, Kenneth N. Brown, Using relaxations to improve search in distributed constraint optimisation, Artificial Intelligence Review 28 (2007)35–50.[4] Anton Chechetka, Katia P. Sycara, No-commitment branch and bound search for distributed constraint optimization, in: 5th International Joint Confer-ence on Autonomous Agents and Multiagent Systems (AAMAS’06), Hakodate, Japan, May 2006, pp. 1427–1429.[5] Rina Dechter, Enhancement schemes for constraint processing: backjumping, learning, and cutset decomposition, Artificial Intelligence 41 (3) (1990)273–312.[6] Rina Dechter, Constraint Processing, Elsevier Morgan Kaufmann, ISBN 978-1-55860-890-0, 2003.[7] Rina Dechter, Robert Mateescu, AND/OR search spaces for graphical models, Artificial Intelligence 171 (2–3) (2007) 73–106.[8] Eugene C. Freuder, Michael J. Quinn, Taking advantage of stable sets of variables in constraint satisfaction problems, in: 9th International Joint Confer-ence on Artificial Intelligence (IJCAI’85), Los Angeles, USA, 1985, pp. 1076–1078.[9] Amir Gershman, Amnon Meisels, Roie Zivan, Asynchronous forward bounding, Journal of Artificial Intelligence Research 34 (2009) 25–46.[10] Tal Grinshpoun, Amnon Meisels, Completeness and performance of the APO algorithm, Journal of Artificial Intelligence Research 33 (2008) 223–258.[11] Patricia Gutierrez, Pedro Meseguer, Saving redundant messages in BnB-ADOPT, in: 24th AAAI Conference on Artificial Intelligence (AAAI’10), July 2010,pp. 1259–1260.[12] Katsutoshi Hirayama, Makoto Yokoo, Distributed partial constraint satisfaction problem, in: 3rd International Conference on Principles and Practice ofConstraint Programming (CP’97), Linz, Austria, 1997, pp. 222–236.216A. Netzer et al. / Artificial Intelligence 193 (2012) 186–216[13] Robert Junges, Ana L.C. Bazzan, Evaluating the performance of DCOP algorithms in a real world, dynamic problem, in: Proceedings of the 7th In-ternational Conference on Autonomous Agents and Multiagent Systems (AAMAS’08), Estoril, Portugal, May 2008, ISBN 978-0-9817381-1-6, 2008,pp. 599–606.[14] Viliam Lisý, Roie Zivan, Katia P. Sycara, Michal Pechoucek, Deception in networks of mobile sensing agents, in: 9th International Conference on Au-tonomous Agents and Multiagent Systems (AAMAS’10), Toronto, Canada, 2010, pp. 1031–1038.[15] Nancy A. Lynch, Distributed Algorithms, Morgan Kaufmann, ISBN 1-55860-348-4, 1996.[16] Rajiv T. Maheswaran, Milind Tambe, Emma Bowring, Jonathan P. Pearce, Pradeep Varakantham, Taking DCOP to the real world: Efficient completesolutions for distributed multi-event scheduling, in: 3rd International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS’04),New York, NY, USA, 2004, pp. 310–317.[17] Radu Marinescu, Rina Dechter, AND/OR branch-and-bound search for combinatorial optimization in graphical models, Artificial Intelligence 173 (16–17)(2009) 1457–1491.[18] Robert Mateescu, Rina Dechter, AND/OR cutset conditioning, in: 19th International Joint Conference on Artificial Intelligence (IJCAI’05), San Francisco,CA, USA, 2005, pp. 230–235.[19] Amnon Meisels, Distributed Search by Constrained Agents: Algorithms, Performance, Communication, Springer-Verlag, ISBN 1848000391, 2007.[20] Amnon Meisels, Igor Razgon, Distributed forward-checking with conflict-based backjumping and dynamic ordering, in: Workshop on CooperativeSolvers in Constraint Programming (CoSolv’02), Ithaca, NY, USA, 2002.[21] Pragnesh Jay Modi, Wei-Min Shen, Milind Tambe, Makoto Yokoo, ADOPT: asynchronous distributed constraints optimization with quality guarantees,Artificial Intelligence 161 (1–2) (2005) 149–180.[22] Adrian Petcu, Boi Faltings, A scalable method for multiagent constraint optimization, in: 19th International Joint Conference on Artificial Intelligence(IJCAI’05), Edinburgh, Scotland, UK, August 2005, pp. 266–271.[23] Adrian Petcu, Boi Faltings, ODPOP: An algorithm for open/distributed constraint optimization, in: 21st National Conference on Artificial Intelligenceand the 18th Innovative Applications of Artificial Intelligence Conference (AAAI’06), Boston, MA, USA, July 2006, pp. 703–708.[24] Marius-Calin Silaghi, Makoto Yokoo, Dynamic DFS tree in ADOPT-ing, in: 22nd AAAI Conference on Artificial Intelligence (AAAI’07), Vancouver, British,Columbia, Canada, July 2007, pp. 763–769.[25] Ruben Stranders, Alessandro Farinelli, Alex Rogers, Nick R. Jennings, Decentralised coordination of continuously valued control parameters using themax-sum algorithm, in: Proceedings of the 8th International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS’09), Budapest,Hungary, May 2009, pp. 601–608.[26] William Yeoh, Ariel Felner, Sven Koenig, BnB-ADOPT: An asynchronous branch-and-bound DCOP algorithm, Journal of Artificial Intelligence Research 38(2010) 85–133.[27] Makoto Yokoo, Distributed Constraint Satisfaction: Foundations of Cooperation in Multi-agent Systems, Springer-Verlag, ISBN 3-540-67596-5, 2000.[28] Makoto Yokoo, Algorithms for distributed constraint satisfaction problems: A review, Autonomous Agents and Multi-Agent Systems 3 (2000) 198–212.[29] Makoto Yokoo, Edmund H. Durfee, Toru Ishida, Kazuhiro Kuwabara, Distributed constraint satisfaction problem: Formalization and algorithms, IEEETransactions on Data and Knowledge Engineering 10 (1998) 673–685.[30] Roie Zivan, Amnon Meisels, Dynamic ordering for asynchronous backtracking on DisCSPs, in: 11th International Conference on Principles and Practiceof Constraint Programming (CP’05), Sitges (Barcelona), Spain, October 2005, pp. 32–46.[31] Roie Zivan, Amnon Meisels, Concurrent search for distributed CSPs, Artificial Intelligence 170 (4–5) (2006) 440–461.[32] Roie Zivan, Amnon Meisels, Message delay and DisCSP search algorithms, Annals of Mathematics and Artificial Intelligence 46 (2006) 415–439.[33] Roie Zivan, Amnon Meisels, Dynamic ordering for asynchronous backtracking on DisCSPs, Constraints 11 (2006) 179–197.[34] Roie Zivan, Moshe Zazone, Amnon Meisels, Min-domain ordering for asynchronous backtracking, in: 13th International Conference on Principles andPractice of Constraint Programming (CP’07), Rhode Island, USA, September 2007, pp. 758–772.