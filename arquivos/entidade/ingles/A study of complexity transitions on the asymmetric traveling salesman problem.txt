Artificial Intelligence 81 ( 1996) 223-239 Artificial Intelligence A study of complexity transitions on the traveling salesman problem * asymmkric Weixiong Zhanga>*, Richard E. Korfb-’ a Information Sciences institute and Computer Science Department, University of Southern California, 4676 Admiralty Way, Marina de1 Rey, CA 90292. USA ’ Computer Science Department, University of California, Los Angeles, Los Angeles, CA 90024, USA Received May 1994; revised April 1995 Abstract (BnB) The traveling salesman problem (TSP) is one of the best-known combinatorial optimization problems. Branch-and-bound is the best method for finding an optimal solution of the TSP. Previous research has shown that there exists a transition in the average computational complexity of BnB on random trees. We show experimentally that when the intercity distances of . . , r}, the complexity of BnB experiences the asymmetric TSP are drawn uniformly from {0,1,2,. transition as r increases. We also observe easy-hard-easy complexity transitions an easy-hard when asymmetric intercity distances are chosen from a log-normal distribution. This transition pattern is similar to one previously observed on the symmetric TSP. We then explain these different transition patterns by showing that the control parameter that determines the complexity is the number of distinct intercity distances. Keywords: Traveling salesman problem; Phase transitions; Problem solving: Combinatorial optimization: Complexity; Search; Branch and bound 1. Introduction A phase transition of a complex system is a dramatic change of some system property [29]. A simple example when an order or control parameter crosses a critical value *This research was supported by NSF Grant, IRI-9119825, a grant from Rockwell International, a GTE graduate fellowship (1992-93). and UCLA Chancellor’s Dissertation Year Fellowship (1993-94). * Corresponding author. B-mail: zhang@isi.edu. URL: http://isi.edu!isd/zhang. Some of this research was performed when this author was at the Computer Science Department, University of California, Los Angeles, CA 90024, USA. ’ E-mail: korf@cs.ucla.edu. 0004-3702/96/$15.00 @ 1996 Elsevier Science B.V. All rights reserved SSD/OOO4-3702(95)00054-2 224 u! Hang, R.E. Korf/Artificial Intelligence 81 (1996) 223-239 of a phase transition is water changing from a liquid to a solid when the temperature drops below the freezing point. In computer science, for example, the probability that a random graph is connected, or contains a Hamiltonian circuit, increases sharply when the average graph connectivity exceeds a certain value [3]. In artificial intelligence, dramatic transitions have also been observed [ 9,111. In this paper, computational complexity we refer to such transitions in the complexity of solving a problem as computational complexity transitions, or complexity tmnsitions for short. Complexity transitions of many combinatorial problems, in particular boolean sat- isfiability and the traveling salesman problem, have recently attracted much attention [ 6,7,13,21,26-28,30,3 1,333. These studies provide a deeper understanding of the problems, and help us to identify difficult problem regions. In addition, they also lead to the development of new methods to solve difficult problems [ 24,341. In this paper, we conduct a case study of complexity transitions on the traveling salesman problem. A number of real-world problems, including planning and schedul- ing problems, can be formulated and solved as the traveling salesman problem [ 141. Specifically, we study complexity transitions of branch-and-bound (BnB) for finding an optimal solution of the asymmetric traveling salesman problem. Given n cities and a distance matrix that defines a distance between each ordered pair of cities, the truvel- ing salesman problem (TSP) is to find a minimum-distance tour that visits each city exactly once, and returns to the starting city. When the distance matrix is symmetric, i.e. the distance from city i to city j is the same as that from j to i, the problem is the symmetric TSP. When the distance from city i to city j is not necessarily equal to that from j to i, it is the asymmetric TSP (ATSP). The optimal solutions of these problems can be found by branch-and-bound (BnB) [ 1,151. BnB is a general problem-solving technique, and is particularly effective for solving combinatorial problems optimally. It is the best known method for finding optimal solutions of the ATSP. BnB includes best-first search (BFS) and depth-first branch-and-bound (DFBnB) as special cases. [ 11,19,20,30,31,33]. Our research was motivated by a recent study of the average-case complexity of BnB on random trees The results show that there exists an exponential to polynomial complexity transition, in terms of tree depth, in the average- case complexity of BnB. The first goal of this research was to determine if such complexity transitions exist in real problems, such as the ATSP, and to what extent the analytical results on this random tree model apply to a real problem. We have reported our initial results previously in [ 30,331. These results show that there is a complexity transition of BnB on the ATSF? If discrete intercity distances are chosen uniformly from r}, then the ATSP is easy to solve when I is small, it is difficult when r {0,1,2,..., is large, and the complexity increases significantly when r exceeds a certain value. In short, the average-case complexity of BnB on the ATSP exhibits an easy-hard pattern as r increases. This research was also motivated by differences between the transition pattern of BnB observed in our previous study on the ATSP, and that reported by Cheeseman et al. on the symmetric TSP [ 5,6]. In their experiments, Cheeseman et al. randomly generated intercity distances from a log-normal distribution with a fixed mean value, and used Little’s algorithm [ 171 as the search method, which is also a branch-and-bound technique. They found that when the standard deviation o of the distribution, or the U! Hang, R.E. Korf/Amjkial Intelligence 81 (19%) 223-239 225 square root of the variance, is very small or very large, the symmetric TSP is easy to solve, i.e. only a small number of nodes of the search tree are expanded. However, when (+ is intermediate, the problem is difficult. In other words, the complexity transition appears as an easy-had-easy pattern as u increases. Because of the difference between symmetric and asymmetric intercity distances, dif- ferent heuristic cost functions are used to solve the symmetric and asymmetric TSP [ 11. For the symmetric TSP, the most effective cost function is based on the minimum span- ning tree [ 221, while for the ATSP, the most effective cost function is the solution to the assignment problem [ 221. In order to better understand the complexity transitions, and to further study the complexity of BnB. we use a log-normal distribution to generate intercity distances of the ATSP The paper is organized as follows. In Section 2 we discuss how to solve the ATSP using BnB, and the complexity transition of BnB on random trees. In Section 3, the main part of the paper, we present experimental complexity transitions of BnB on the ATSP with intercity distances drawn from uniform and log-normal distributions, and investigate the control parameter that determines the complexity. Finally, our summary appears in Section 4. Some of our preliminary results, such as those in Sections 3.1 and 3.2, were previously reported in [ 30,321. 2. Tree search and complexity transitions The search space of a combinatorial problem can usually be represented by a tree. This is because most combinatorial problems can be decomposed by the principle of inclusion and exclusion [ 1,181 in such a way that no duplicate subproblems are produced. The root node of the search tree corresponds to the original problem, and the interior nodes correspond to subproblems generated. In order to solve the problem more efficiently, lower-bound cost functions, or heuristic evaluation functions, are used to assign values to the nodes to estimate the minimal costs of solving the corresponding subproblems. Which subproblem is chosen for decomposition in each step gives rise to different search algorithms. In Section 2.1, we take the ATSP as an example to illustrate these concepts of tree search. We then discuss the average-case complexity and complexity transitions of searching a random tree in Section 2.2. 2.1. Solving the ATSP by tree search The most effective lower-bound cost function for the ATSP is the solution to the assignment problem, which is solvable in 0( n3) time for n cities [ 1,221. The assignment problem is to assign to each city i another city j, with the distance from i to j as the cost of this assignment, such that the total cost of all assignments is minimized The assignment problem is a relaxation of the ATSP since the assignments need not form a single tour, but allow collections of disjoint subtours, such as i to j and j to i. Thus, it provides a lower bound on the distance of the ATSP tour. If the assignment problem 226 W Zhang, R.E. KorflArtQicial Intelligence 81 (1996) 223-239 Fig. 1. An example of solving the ATSP. solution happens to be a single complete tour, it is the solution to the ATSP as well. An example of solving the ATSP using the assignment problem as the cost function is illustrated in Fig. 1. We first solve the assignment problem for the six given cities. Assume that the assignment problem solution contains two subtours shown in the root node of the tree. We then eliminate a subtour in the solution. If subtour 2-3-2 is chosen to be eliminated, we have two choices. We may either exclude edge (2,3) or edge (3,2), each of which leads to a subproblem with an additional constraint, the excluded edge. We then solve the assignment problems of the corresponding subproblems. Assume that the solutions to the derived assignment problems are not complete tours. We use inclusion and exclusion to decompose them further, until the solution to a derived assignment problem is a complete tour. We avoid generating duplicate subproblems by including in the current subproblem any edges that were excluded by its previously generated sibling subproblems. In our example, suppose that we generate the first subproblem A by excluding edge (2,3). The second subproblem B excludes edge (3,2), but includes the edge (2,3). Therefore, no subproblems generated under A can include edge (2,3), but all subproblems under B must include edge (2,3), guaranteeing that all their descendent subproblems will be mutually disjoint. In general, let E denote the set of excluded edges, and I the set of included edges of a subproblem whose assignment problem solution is not a single complete tour. We choose a subtour with a minimum number of edges to eliminate. Assume that there that are not in 1. We then decompose the are t edges in the subtour, {xi, x2,. . . , x,}, problem into r children, with the kth one having excluded arc set & and included XC set Ik, such that Ek=EU{Xk}, Ik=Iu{x I,..., x&i}, k=1,2 ,..., r. (1) Since Xk is an excluded edge of the kth subproblem, xk E Ek, and it is an in- cluded edge of the (k -I- 1) st subproblem, xk E zk+] , any subproblems generated from W Zhung, R.E. Korf/Art@cial Intelligence 81 (1996) 223-239 221 the kth subproblem cannot contain edge Xk, but all subproblems obtained from the (k + 1) st subproblem must include edge Xk. Therefore, no duplicate subproblems will be generated, and the search space is a tree of unique nodes. There are different schemes for decomposing a subproblem [ 11, but we adopted the method proposed by Carpaneto and Toth [4], as described in Eq. ( 1). In addition, a child subproblem is more con- strained than its parent problem, by virtue of having more included and excluded edges, so that the cost of the child is at least as large as that of the parent. In other words, subproblem costs are monotonically nondecreasing along a path from the root. In summary, the ATSP can be solved by BnB as a tree search. It maintains an upper bound (Y, which is the cost of the best complete tour found so far. The initial value of (Y is set to the cost of an approximate solution, such as the cost of the nearest neighbor tour [ 8,141. BnB takes the original problem as the current subproblem, and repeats the following steps. First, solve the assignment problem for the current subproblem. If the solution is not a single complete tour, then decompose the problem and generate all child subproblems according to Eq. ( 1). Next, select a subproblem that has been generated but not yet expanded as the next current subproblem. If the assignment cost of the current subproblem is greater than or equal to the current upper bound (Y, prune this branch of the tree, since it cannot lead to a complete tour with length less than (Y, and select another subproblem. If the optimal assignment of the current subproblem is a complete tour, and its length is less than LX, update (Y to the length of this new tour. If the optimal assignment of the current subproblem is not a single complete complete tour, and its cost is less than cy, decompose this subproblem. This subproblem selection and decomposition process continues until no unexpanded subproblems exists, or all unexpanded subproblems have costs greater than or equal to LY, the length of the best complete tour found so far. Which subproblem is selected for decomposition in each step gives rise to different implementations of BnB, particularly best-first search or depth-first BnB. Best-first search chooses a subproblem that has the minimum cost among all generated subproblems that have not yet been decomposed. Depth-first BnB selects a subproblem from the most recently decomposed subproblem. 2.2. Complex@ transitions of random tree search By relaxing the constraints on a problem, we can usually obtain a heuristic evaluation function which is a lower bound on the cost of solving a subproblem [ 231. A lower- bound cost function can be used to construct a monotonic cost function, which assigns a cost to a child node in a search tree that is no less than the cost of its parent. This is done by taking the cost of a node as the maximum of all node costs on the path from the root to the node. When node costs are monotonically nondecreasing, we can model the cost function by associating nonnegative costs with the edges of the search tree, such that the cost of an edge is the difference between the cost of the child node and the cost of its parent. A node cost is then the sum of the edge costs on the path from the root to the node. To analyze the average-case complexity of BnB, the following random tree was proposed and used in [19,20,31,33]. 228 W Zhang, R.E. Korf/Arrifcial InMligence 81 (1996) 223-239 optink goal Fig. 2. An example of random tree. Definition 2.1. An incremental random tree, or random tree T( b, d), is a tree with depth d, and independent and identically distributed (i.i.d) random branching factors with mean b. Nonnegative edge costs are bounded i.i.d. random values. The cost of a node is the sum of the edge costs along the path from the root to that node. An optimal goal node is a node of minimum cost at depth d. Fig. 2 shows an example of a random tree, where the numbers on the edges and the numbers in the nodes are the edge costs and the resulting node costs, respec- tively. The expected number of nodes expanded by BnB to find an optimal goal node of a random tree is governed by the expected number of children of a node that have the same cost as their parent, which are referred to as same-cost children. If po is the probability that an edge has zero cost, and b is the mean branching factor, then bpo is the expected number of same-cost children of a node. On a random tree T(b,d), Lemma 2.2 ([19,20,31,33]). as d + 00, both best-first search and depth-first branch-and-bound expand 13( pd) expected number of nodes when bpo < 1, where p is a constant between 1 and b. Best-first search expands 0(d2) expected number of nodes, and depth-jirst branch-and-bound expands 0(d3) number of nodes when bpo 2 1. expected Lemma 2.2 shows that there exists a complexity transition, from exponential to polyno- mial in the search depth, when the expected number of same-cost children bpo increases from below one to above one. This is summarized by Fig. 3. We need to emphasize that a random tree is an abstraction of a practical tree-search problem, making many assumptions to enable a tractable average-case analysis. For example, branching factors of different nodes in a random tree are independent and identically distributed, referred to as the i.i.d. assumption, which is rarely true in a real problem. Furthermore, edge costs of a random tree are independent from each other, which is also rarely true in practice. In general, to bridge the gap between an analytical model and a practical problem, empirical results are required. W zhang, R.E. Korf/Artijkial helligence 81 (1996) 223-239 229 m 1.0 SJ s s 0.8- 8 e z 0.6 - % 0.4 - .zT .z cd E 0.2- I I I bp,> 1 polynomial region transition boundary mean branching factor b Fig. 3. Complexity transition of random-tie search. 3. Complexity transitions on the ATSP transitions Do complexity such as the ATSP? How applicable are analytic results of complexity transitions on random trees to the ATSP? How do problem parameters affect complexity transitions? This section addresses these questions. in real search problems, exist 3. I. Transitions under uniform distributions ,..., The node costs in the search tree of the ATSP are the solution costs of the corre- sponding assignment problems. Assume that intercity distances are uniformly chosen r}, for some positive integer r. Consider the relationship between from R={O,1,2 the intercity distance range T, and the number of edges in the search tree that have zero cost. The probability that two sets of n values from R have the same total sum is smaller if r is larger. Thus, the probability that two sets of II edges in the assignment problem solutions to two subproblems have the same total cost decreases as r increases. When r is small compared to the number of cities, the probability that the assignment problem cost of a child subproblem in the search tree is equal to the assignment problem cost of its parent is large. In other words, the probability po of zero-cost edges in the search tree is larger when r is smaller, so that the average number of same-cost children bpo may be greater than one, if the branching factor b does not decrease significantly when r increases. Therefore, the problem may be easy to solve when r is small. Conversely, the probability that the assignment problem cost of a child is equal to that of its parent is smaller when r is relatively larger, as is the probability w of zero-cost edges in the search tree. Consequently, the problem may be difficult to solve when r is large. The above argument suggests that there may exist a complexity transition of BnB on the ATSP as r changes, following the complexity transition of random-tree search shown in Fig. 3. We experimentally tested this prediction by experiments on lOO-city ATSPs. In our experiments, we randomly generated 1000 problem instances for each different 230 W Zhang. R.E. Korf/Artifcial Intelligence 81 (1996) 223-239 (a) AP solutions are tours (percent) 7-7 7m-- (b) proportion of edges of cost zero b 15 14 13 t 12 11 10 9 range of intercity distances, r (c) average branching factor I 7-T d 1 range of intercity distances, r (d)averagesearchdepth --7i--- 2.6 2.2 1.8 -.-_-A_ 1 10 102 103 104 105 106 107 range of intercity distances, r I’ L _ (e) average # of same-cost children oP0 - 14 12 10 8 6 4 2 0 L _1_ I..-__ I 1 10 102 103 104 105 106 10’ range of intercity distances, r (f) number of APs solved - ,- - 7_--7 , -I -1 180 t c 160 140 120 100 80 60 40 20 -- mean b- median J 107 104 105 106 107 range of intercity distances, r 1 10 102 103 104 105 106 % range of intercity distances, r fig. 4. Complexity tmnsition on the loo-city ATSP, uniform distribution on (0.1.2,. . . , r}. value of r, solved them using depth-first BnB, and averaged the results for each value of r. Fig. 4(a) shows the percentage of problem instances whose assignment problem solutions are complete tours, where the horizontal axis is the intercity-distance range r, on a logarithmic scale. Overall, this percentage is small, especially for I 2 5. We further examined four important parameters of the search trees of the ATSP instances whose assignment problem solutions are not complete tours. These include the proportion of H? Zhang. R.E. Kotf/Art@cial Intelligence 81 (1996) 223-239 231 edges in the search tree that have cost zero, which corresponding to the probability po that a node has the same cost as its parent, &he average branching factor b, the average search depth d, and the average number of same-cost children of a node bpo. These four parameters are graphed in Figs. 4(b) through 4(e). Fig. 4(b) shows that when r < 10, PO is almost one, so that most nodes in the search tree have the same cost, and almost every leaf node is an optimal goal node. On the other hand, when 10 < r < 1000, increasing r causes po to decrease sharply, and approach zero. Figs. 4(c) and 4(d) illustrate the average branching factor b and average search depth d, respectively, which determine the size of the search tree. When r < 10, b increases but d decreases as r decreases, meaning that the search tree gets bushier and shallower as r decreases. b and d remain relatively constant when r > 100. Fig. 4(e) shows that bpo > 1 when r < 130, and bpo < 1 when r > 130, indicated by point A. Following the complexity transition of random-tree search in Fig. 3, this means that the problem should be easy to solve when r 6 130, but should be difficult when r > 130. Fig. 4(f) presents the mean and median numbers of assignment problems (AP) solved, or search tree nodes generated, under different values of intercity-distance range transition. When r < 20 the problem is easy, but is diffi- r, showing a complexity cult when r > 1000. Similar complexity transitions have also been observed on 200-, 300-, 400- and 500-city ATSPs. Fig. 5 shows the complexity transition on the 200-city ATSP The transition from easy problem instances to difficult ones, however, is not as dramatic as we expected. This may be due to the following factors. First, bpo decreases gradually as r increases for r < 1000, making the complexity increase slowly. Secondly, the size of the search tree increases slowly as b and d increase with r for 10 < r < 1000 (Figs. 4(c) and 4(d)). Thirdly, the search trees of the ATSPs have relatively small depths, while the complexity transitions of random tree search are asymptotic results as tree depth approaches infinity. Finally and more importantly, the edge costs and branching factors of different nodes in the search tree are not random variables, so that the i.i.d. assumptions made for random trees are violated. Nevertheless, point A in Fig. 4(f), which corresponds to point A of Fig. 4(e) for bpo = 1, is in the middle of the complexity transition. As suggested by Section 2, if we take the particular value of r such that bpo = 1 as the transition point, point A in Figs. 4(e) and (f), then this transition point increases with the problem size, or the number of cities, Point A’ in Figs. 5(a) and 5(b) is the transition point on the 200-city ATSP, corresponding to bpo = 1. Compared to point A in Fig. 4, point A’ in Fig. 5 has a larger value of intercity-distance range r = 450. 3.2. Transitions under log-normal distributions We now examine the complexity of BnB for solving ATSP with intercity distances drawn from a log-normal distribution [ lo]. It is a continuous distribution, whose density function * is * This is called a two-parameter density function [ IO]. 232 W Zhmg. R.E. Ko@/Artijcial Intelligence 81 (1996) 223-239 a average # of same-cost children bp ( ) 350 30 20 15 25 IO 5 0 1 10 102 103 104 105 106 107 range of intercity distances, r (b) number of APs solved :!z 350 300 250 200 400 150 100 50 I I G- mean -median 1 1’_,.~ -I 10 102 103 104 105 106 107 range of intercity distances, r Fig. 5. Complexity transition on the 200-city ATSP, uniform distribution on (0, 1,2,. . . , r}. f& 0.006 Fig. 6. Density functions of the log-normal distribution with mean 1CKKI. 1 fx(x> = &+ynexp 0, { logx-A y -z ’ 1 ( * )I , for x > 0, for x < 0. The mean ,U and the standard deviation u of the distribution are fJ = ,~+r% I CT= e2A+Y2(eY2 - 1). (2) (3) Fig. 6 illustrates the density function with a constant mean of different values of the standard deviation CT. p = 1000, and three When the standard deviation u of the distribution is very small, most values from the distribution are located near its mean value, so that most of them are the same after being discretized. Thus, when u is small, many intercity distances drawn from this distribution are equal, and the proportion po of zero-cost edges in the search tree is large, following our previous arguments. One observation on the log-normal distribution is that R Zhang, R.E. Korf/Artificial Intelligence 81 (19%) 223-239 233 it is biased toward small costs when (+ increases. When u is very large, most intercity distances are almost zero with a few very large intercity distances, which are unlikely to be chosen in the solution to an assignment problem. Consequently, the proportion pa of zero-cost edges in the search tree is large in this case as well. Thus, we should expect that the ATSP is easy to solve when u is small and large, but is difficult when (T is intermediate. We verified our arguments with experiments, in which we fixed the mean of the distribution to a constant, p = 1000, and used the standard deviation (T as a parameter to adjust the distribution. We generated 1000 problem instances of the loo-city ATSP for each different value of u. Fig. 7 shows our experimental results for depth-first BnB. Fig. 7(a) is the percentage of instances whose assignment problem solutions are complete tours, as a function of u, on a logarithmic scale. This percentage grows with u, indicating more easy problems were generated as u increases, supporting our arguments. Similar to the experiments with a uniform distribution, we also examined four parameters of the search trees of the problem instances whose assignment problem solutions are not complete tours. Figs. 7(b) to 7(e) show the proportion or probability pa that a node has the same cost as its parent, the average branching factor b, the average search depth d, and the average number of same-cost children of a node bpe, respectively. Fig. 7(b) shows that when the standard deviation u increases for u 2 0.4, the proportion of zero-cost edges in the search tree decreases, to near zero, then increases to one, and finally remains at one. Figs. 7(c) and 7(d) show the average branching factor b and average search depth d, which determine the search tree size. Fig. 7(e) shows that when u increases, the average number of same-cost children bpo first decreases, then remains at zero, and finally increases. bpo drops below one when u exceeds 8 (point B in Fig. 7(e)), and then grows above one when u exceeds 6000 (point C in Fig. 7(e)). Fig. 7(f) displays the mean and median numbers of assignment problems (AP) solved, or tree nodes generated, which follow a similar easy-difficult-easy transition pattern as that of the symmetric TSP [ 61. Fig. 7(f) shows that the problem is relatively easy when u is small or large, but is difficult when u is intermediate. However, the behavior of BnB in the region when u < 0.4 does not completely match our intuition. When u is very small, say u < 0.4, most intercity distances are equal to the mean of the distribution. In this case, most subproblems in the search tree should have the same assignment cost, giving a high proportion of edges of cost zero in the tree. In addition, the assignment problem algorithm intends to find solutions with small cycles, so that the branching factor of the search tree should be small and the search tree should be deep in this case. The average search depth in Fig. 7(d) when u < 0.4 confirms our intuition, but the average branching factor in Fig. 7(c) when u < 0.4 does not. Similar to the case when intercity distances are uniformly distributed, the transitions from easy problem instances to difficult ones, and from difficult instances to easy ones in Fig. 7(f), are not very sharp. This is mostly due to the fact that edge costs in the search tree are not independent. Nevertheless, points B and C of Fig. 7(e), which correspond to points B and C of Fig. 7(d) for bpo = 1, are both located at the middle of the respective complexity transitions. 234 W Hang, R.E. Korf/Ariifcial Intelligence 81 (1996) 223-239 (a) AP solutions are tours (percent) n (b) proportion of edges of cost zero 1:; 0.8 0.6 0.4 0.2 0.0 106 1 102 104 106 standard deviation0 1 102 lo4 standard deviation0 h (c) average branching factor d -7 (d) average search depth -~ 14 12 10 1 1 102 104 standard deviationo 3.6 3.2 2.8 2.4 2.0 1 1.6 r I 106 .~~_ I -_-L ~~ --- ~~ 1 102 104 106 standard deviation0 hp (e) average # of same-cost children n standard deviation0 180 160 140 120 100 80 60 40 20 1 I (f) number of APs solved .~ 7 ~---- ~.._ ~~~~ .__ __ ~~ --- mean + median 1 102 104 106 standard deviationo Fig. 7. Complexity transition on the lOO-city ATSP, log-normal distribution with a fixed mean of 1000. 3.3. Identifying the control parameter Our experiments in Sections 3.1 and 3.2 indicate that complexity transitions of the ATSP depend on the distributions of intercity distances. What factor causes different complexity transition patterns on the ATSP under different intercity-distance distribu- tions? In other words, what is the control parameter? I+! Zhang, R.E. KotflArtificial Intelligence 81 (1996) 223-239 235 (a) Average optimal tour length (b) # of distinct intercity distances 8x106 6~10~ 2x10+ 0t /,I 1 jlE f 10 102 lot 104 l@ 106 10’ range of intercity distances, r range of intercity distances, r (c) Complexity vs. distinct distances # of distinct intercity distances Fig. 8. Tour length, distinct intercity costs and complexity, uniform distribution on (0.1.2,. . . , r}. The complexity of the ATSP depends on the number of different intercity distances, their values, and the probability that a distance takes a particular value. When intercity distances are uniformly chosen from (0, 1,2, . . . , r}, both the optimal ATSP tour length and the total number of distinct intercity distances increase with the range r. For the lOO-city ATSP, the maximum number of distinct intercity-distance intercity distances is 10000, which is the total number of entities in the 100 by 100 distance matrix. We examined these two parameters using the same 1000 problem instances of the loo-city ATSP for each different r as we used for Fig. 4 of Section 3.1. Fig. 8(a) shows the average tour length, and Fig. 8(b) displays the average number of distinct intercity distances, as a function of the range r. The results in these figures confirm that the ATSP tour length and the number of distinct intercity distances grow with r. We then investigated the relationship between the number of distinct intercity dis- tances and the problem complexity, the total number of assignment problems solved. The numbers of distinct intercity distances of two particular problem instances that are generated using the same intercity-distance range r are not necessarily the same. Fur- thermore, the number of distinct intercity distances of two problem instances that are generated using two different r may be the same. Therefore, we rearranged the prob- lem instances generated from all values of r that we used, according to their numbers of distinct intercity distances. Since some numbers of distinct intercity distance may be represented by only a few problem instances, we chose those numbers of distinct 236 W Zhmg, R.E. Korf/Arttj?cial Intelligence 81 (1996) 223-239 (a) Average optimal tour length distinct intercity distances 10x104 5 2 8~10~ s “1 6~10~ 9 & 4x104 E 2 2x104 1 102 104 standard deviation0 106 ot- - ~_ 1-_-L- 1 102 -- 104 106 standard deviation0 (c) Complexity vs. distinct distances (d) Complexity vs. distinct distances 1 3 10 30 100 300 1000 # of distinct intercity distances 16 b4x103, 10’ } . . . . -% _--A 500 600 800 1000 1500 # of distinct intercity distances Fig. 9. Tour length, distinct intercity costs and complexity, log-normal distribution with a fixed mean of 1000. intercity distances that are represented by more than 30 problem instances, and plotted in Fig. 8(c) the average number of assignment problems solved as a function of the number of distinct intercity distances. Fig. 8(c) shows that the complexity of the ATSP increases with the number of distinct intercity distances. For example, when the number of distinct intercity distances is less than 40, the average total number of assignment problems solved is less than 25, and when the number of distinct intercity distances is greater than 100, the total number of assignment problems solved is greater than 120. In short, when intercity distances are chosen from a uniform distribution, the number of distinct intercity distances serves as the control parameter of the complexity transition. The problem is easy to solve when the number of distinct intercity distances is small, but is difficult when this number is large. We now consider the log-normal distribution. Fig. 9(a) and Fig. 9(b) show the average tour length and the number of distinct intercity distances, averaged over the same 1000 problem instances of the lOO-city ATSP for each standard deviation c as those used for Fig. 7 in Section 3.2, as a function of CT. Fig. 9(a) shows that when g < 10, the average tour length is close to 100 x 1000, indicating that the intercity distances included in the ATSP tour are close to the mean of the distribution, which is 1000. When (+ >, 3000 (after point D in Fig. 9(a)), the average tour length is less than 1000, and approaches zero quickly, indicating that small intercity distances are included in the ATSP tour, although large ones exist. This is mostly due to the fact that in this case most intercity distances are very small, and only a few large ones exist. U! Bang, R.E. Korf/ArtijEcial Intelligence 81 (1996) 223-239 23-l Fig. 9(b) shows that the average number of distinct intercity distances increases with u when 0.1 < (T < 2000. However, it decreases with u when 2000 < u < 10,000,OOO (after point D’ in Fig. 9(b)). This further indicates that more small intercity distances are generated for (T > 2000 in order to keep the mean constant. Most of these small distances are the same after being discretized. This is also the reason that the complexity drops quickly when cr > 2000 in Fig. 7 (f) . We further examined the relationship between the number of distinct intercity distances and the number of assignment problems solved. Similar to the case of the uniform distribution, we rearranged the problem instances according to their numbers of distinct intercity distances, and report the results for the numbers represented by more than 30 problem instances. Since many intercity distances generated with u > 3000 are equal to a few small values, and the large ones are rarely used in the optimal assignment, we separated the problem instances that were generated using (+ < 3000 from those using g > 3000. Fig. 9(c) and Fig. 9(d) show the average number of assignment problems solved as a function of the number of distinct intercity distances for the problem instances generated with the standard deviation u < 3000 and LT > 3000, respectively. Fig. 9(d) shows that when u is large, the average number of assignment problems (AP) solved is less than 35, meaning that the problem is easy to solve. Fig. 9(c) shows that the problem is easy when the number of distinct intercity distances is small, but is more difficult when this number is large. In summary, when intercity distances are chosen from the log-normal distribution, if the problem instances that are generated under an extremely large standard deviation are excluded, the number of distinct intercity distances can be used as the control parameter of the complexity transition. However, the change from easy problem instances to difficult instances, in both cases of uniform and log-normal distributions, is not as sharp as we expected. This is more likely due to the same reason as described in Section 3.1, namely that the branching factors and edge costs in the search tree are not independent of each other. We would like to emphasize that the meaning of the above results is that when the number of distinct intercity distances is relatively large, solving the ATSP requires computation that may be exponential in the search depth on average. This does not imply, however, that the average-case complexity of the ATSP is exponential in the number of cities when the number of distinct intercity distances is relatively large. In fact, it is still an open problem whether or not the ATSP can be solved in polynomial or exponential average time in the number of cities, and the opinion of experts on this question is divided [ 2,12,16,25]. 4. Conclusions the existence of complexity We have experimentally demonstrated transitions of branch-and-bound for finding an optimal solution of the ATSP We found that when discrete intercity distances were chosen uniformly from (0, 1,2,. . . , r}, the complexity exhibits an easy-hard transition as r increases. We also observed that when the inter- city distances were drawn from a discretized log-normal distribution, the complexity transitions as the standard deviation of the distribution grows. displays easy-hard-easy 238 W Zhang, R.E. Korf/Artificial Intelligence 81 (1996) 223-239 This transition pattern is similar to the complexity transition observed on the symmetric TSP [ $61. Furthermore, we explained why there exist two different transition patterns on the ATSP by hypothesizing that the control parameter that determines the transitions is the total number of distinct intercity distances of the ATSP The complexity transition follows an easy-hard transition as the number of distinct intercity distances increases. This research indicates that analytical results of tree-search complexity transitions can be applied to real search problems, such as the ATSP, helping us to predict the complexity transitions of the problem. However, the transition between easy and difficult regions is not as sharp as predicted by the analytical results. This is most probably due to the fact that the independence assumptions in the analysis are not valid in real problems. Acknowledgements Thanks to Peter Cheeseman, Tad Hogg and Colin Williams for stimulating discussions related to this work. We are also indebted to the two anonymous reviewers for their excellent comments that greatly improve the content and presentation of this paper. Thanks also to William Cheng for tgif, David Harrison for xgrqh, and the Free Software foundation for gee, gdb, and gnuemacs. References I I J E. Balas and t? Toth, Branch and bound methods, in: E.L. Lawler et al., eds., The Traveling Salesman Problem (Wiley, Chichester, England, 1985) 361-401. 12 1 M. Bellmore and J.C. Malone, Pathology of traveling-salesman subtour-elimination algorithms, Uper. Res. 19 (1971) 278-307. [ 31 B. BollobL, Random Graphs (Academic Press, New York, 1985). [4] G. Carpaaeto and F? Toth, Some new branching and bounding criteria for the asymmetric traveling salesman problem, Management Sci. 26 ( 1980) 736-743. 151 l? Cheeseman, Personal communication (1991-1992). ]6] l? Cheeseman, B. Kanefsky and W.M. Taylor, Where the really hard problems are, in: Proceedings IJCAI-91, Sydney, Australia (1991) 331-337. 17 1 J.M. Crawford and L.D. Auton, Experimental results on the crossover point in satisfiability problems, in: Proceedings of AAAI-93, Washington, DC (1993) 21-27. 181 A. Frieze, G. Galbiati and E Maffioli, On the worst-case performance of some algorithms for the asymmetric traveling salesman problem, Network 12 (1982) 23-39. 191 B.A. Huberman and T. Hogg, Phase transitions in artificial intelligence systems, Art$ InteN. 33 ( 1987) 155-171. [ IO] N.L. Johnson and S. Katz, Distributions in Statisrics: Continuous Univariate Distributions-l (Wiley, New York, 1970). [ 1 I ] R.M. Karp and J. Pearl, Searching for an optimal path in a tree with random costs, Artif: Intell. 21 ( 1983) 99-l 17. [ 12 ] R.M. Karp and J.M. Steele, Probabilistic analysis of heuristics, in: E.L. Bawler et al., eds., The Traveling Salesman Problem (Wiley, Chichester, England, 1985) 18 l-205. 1 13 1 T. Larrabee and Y. Tsuji, Evidence for a satisfiability threshold for random 3CNF formulas, in: Working Notes of AAAI 1993 Spring Symposium: AI and NP-Hard Problems, Stanford, CA ( 1993) 112-l 18. I 141 E.L. Lawler, J.K. Len&a, A.H.G. Rinnooy Kan and D.B. Shmoys, The Traveling Safesman Problem (Wiley, Chichester, England, 1985). [ 15 1 E.L. Lawler and D.E. Wood, Branch-and-bound methods: a survey, Oper. Res. 14 (1966) 699-719. W Zhang, R.E. Korf/Artijicial Intelligence 81 (I 996) 223-239 239 ( 16 1 J.K. Lenstra and A.H.G. Rinnooy Kan, On the expected performance of branch-and-bound algorithms, Oper. Res. 26 (1978) 347-349. [ 171 J.D.C. Little, K.G. Murty, D.W. Sweeney and C. Karel, An algorithm for the traveling salesman problem, Ol>er. Rex 11 (1963) 972-989. [ I8 1 C.L. Liu, Introduction to Combinatorial Mathematics (McGraw-Hill, New York, 1968). 1 19 1 C.J.H. McDiarmid, Probabilistic analysis of tree search, in: G.R. Gummett and D.J.A. Welsh, eds., 1201 121 I 1221 1231 1241 I251 [261 1271 [281 [291 1301 1311 I321 1331 1341 Disorder in Physical Systems (Oxford Science, 1990) 249-260. C.J.H. McDiarmid and G.M.A. Provan, An expected-cost analysis of backtracking and non-backtracking algorithms, in: Proceedings IJCAI-91, Sydney, Australia ( 1991) 172-177. D.G. Mitchell, B. Selman and H.J. Levesque, Hard and easy distributions of SAT problems, in: Proceedings AAAI-92, San Jose, CA (1992) 459-465. C.H. Papadimitriou and K. Steiglitz, Combinatorial Optimization: Algorithms and Complexity (Pmntice- Hall, Englewood Cliffs, NJ, 1982). 3. Pearl, Heuristics (Addison-Wesley, Reading, MA, 1984). J.C. Pembertou and W. Zhang, Epsilon-transformation: exploiting phase transitions to solve combinatorial optimization problems, Arti& Intell. 81 ( 1996) 297-325 (this volume). D.R. Smith, Random trees and the analysis of branch and bound procedures,J. ACM 31 (1984) 163-188. C.P Williams and T. Hogg, Using deep structure to locate hard problems, in: Proceedings AAAI-92, San Jose, CA ( 1992) 472-477. CX? Williams and T. Hogg, Extending deep structure, in: Proceedings of AAAI-93, Washington, DC (1993) 152-157. C.P. Williams and T. Hogg, Exploiting the deep structure of constraint problems, Art$ Intell. 70 (1994) 73-l 17. K.G. Wilson, Problems in physics with many scales of length, Scientific American 241 (1979) 158-179. W. Zhang and R.E. Korf, An average-case analysis of branch-and-bound with applications: summary of results, in: Proceedings AAAI-92, San Jose, CA ( 1992) 545-550. W. Zhang and R.E. Korf, Depth-first vs. best-first search: new results, in: Proceedings AAAI-93, Washington, DC ( 1993) 769-775. W. Zhang and R.E. Korf, A unified view of complexity transitions on the traveling salesman problem, in: Working Notes of AAAI 1994 Workshop on Experimental Evaluation of Reasoning and Search Methods, Seattle, WA (1994). W. Zhang and R.E. Korf, Performance of linear-space search algorithms, Art$ Intell. 79 ( 1995) 241- 292. W. Zhang and J.C. Pemberton, Epsilon-transformation: exploiting phase transitions to solve combinatorial optimization problems-initial results, in: Proceedings of AAAI-94, Seattle, WA (1994). 