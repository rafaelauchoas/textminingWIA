Neurocomputing 527 (2023) 184–195Contents lists available at ScienceDirectNeurocomputingj o u r n a l h o m e p a g e : w w w . e l s e v i e r . c o m / l o c a t e / n e u c o mHierarchical approach for fusion of electroencephalography andelectromyography for predicting finger movements and kinematicsusing deep learningTanaya Das a, Lakhyajit Gohain a, Nayan M Kakoty a, MB Malarvili b, Prihartini Widiyanti c,Gajendra Kumar d,⇑a Embedded Systems and Robotics Lab, School of Engineering, Tezpur University, Indiab Faculty of Bioscience and Medical Engineering, Universiti Teknologi Malaysia, Malaysiac Faculty of Science and Technology, Universitas Airlangga, Indonesiad Department of Neuroscience, City University of Hong Kong, Tat Chee Avenue, Hong Kong Special Administrative Regiona r t i c l ei n f oa b s t r a c tArticle history:Received 6 January 2022Revised 23 December 2022Accepted 9 January 2023Available online 13 January 2023Communicated by Zidong WangKeywords:ElectroencephalographyElectromyographyArtificial intelligenceBrain-computer interfaceHierarchicalFinger KinematicsFinger MovementsThe brain is a unique organ that performs multiple processes simultaneously, such as sensory, motor, andcognitive function. However, several neurological diseases (ataxia, dystonia, Huntington’s disease) ortrauma affect the limb movement and there is no cure. Although brain-computer interfaces (BCIs) havebeen recently used to improve the quality of life for people with severe motor disabilities, anthropomor-phic control of a prosthetic hand in upper limb rehabilitation still remains an unachieved goal. To thispurpose, a hierarchical integration of neural commands to fingers was applied for execution of humanhand grasping with better precision. For finger movement prediction and kinematics estimation, a neu-romuscular approach was employed to establish a hierarchical synergy between electroencephalography(EEG) and electromyography (EMG). EEG, EMG and metacarpophalangeal (MCP) joint kinematics wereacquired during five finger flexion movements of the human hand. EMG for five finger movements andkinematics were estimated from EEG using linear regression. A Long Short-Term Memory network(LSTM) and a random forest regressor were adjoined hierarchically for prediction of finger movementsand estimation of finger kinematics from the estimated EMG. The results showed an average accuracyof 84.25 ± 0.61 % in predicting finger movements and an average minimum error of 0.318 ± 0.011 in termsof root mean squared error (RMSE) in predicting finger kinematics from EEG across six subjects and fivefingers. These findings suggest the implementation of a hierarchical approach to develop anthropomor-phic control for upper limb prostheses.(cid:1) 2023 Elsevier B.V. All rights reserved.1. Introduction57.7 million traumatic non-fatal limb amputation occur world-wide [1] requiring partial or complete surgical removal of limb orextremity such as an arm, leg, foot, hand, toe, or finger. Absence ofanatomical structures due to amputations negatively affects psy-chology and body functions such as mobility. Prosthesis and reha-bilitation are being commonly used to improve the quality ofpeople’s life in such cases using electroencephalography (EEG)⇑ Corresponding author at: Department of Molecular Biology, Cell Biology &Biochemistry (MCB), Brown University, 70 Ship Street, Providence, RI, 02906.Phone: (+401) 499-6970.E-mail addresses:lakhya25@gmail.comtanaya12das@gmail.com (T. Das),(L. Gohain), nkakoty@tezu.ernet.in (N.M Kakoty), gajendra_kumar@brown.edu(G. Kumar).https://doi.org/10.1016/j.neucom.2023.01.0610925-2312/(cid:1) 2023 Elsevier B.V. All rights reserved.and electromyography (EMG) for their non-invasive signal acquisi-tion and an abundance of synchronized neuronal information [2].Prediction of upper limb movements using EEG and EMG has beenmostly applied to control limb prosthesis and rehabilitation [3].Several recent studies have reported interactions of EEG with theperformance of upper limb prosthetics devices [4], upper limbreaching tasks [5], and finger movements [6]. However, limitedstudies have been reported for estimation of EMG from EEG to pre-dict upper limb movements and kinematics. EMG estimation fromEEG to predict finger movements and finger kinematics will aid indeveloping control of robotic limb prostheses and rehabilitation foramputees as they generate minimal EMG [7]. Cho et al. [8] reporteda 63.89 % prediction accuracy for natural grasp movements basedon muscle activity patterns, estimated from EEG using a linear dis-criminant analysis (LDA) model. The studies confirm the benefit ofT. Das, L. Gohain, Nayan M Kakoty et al.Neurocomputing 527 (2023) 184–195EEG to control finger kinematics for grasping through brain-computer interfaces (BCIs). However, artificial intelligence (AI) isrequired to train large amounts of labelled data to enhance the pre-cision. Application of BCIs with AI has been recently investigated inclinics to achieve real-time modulation and feedback [9]. Algo-rithms modulates the decision based on the previous set of data.Therapeutic intervention in stroke patients showed partial regain-ing of function in the affected limb. A closed loop system betweencortical activity and movement, mimics the afferent feedback torestore functional corticospinal and corticomuscular connections[10]. Clinical application of BCI with AI are still very limited dueto disparity in prediction and interpretation of real-world activity,which can be improved by using deep learning techniques.Recently, BCI applications with AI assistance have advanced theanalysis and decoding of brain signals, as well as the ability to exe-cute real-time hand movements [10,11]. However, the perfor-mance of BCI with AI using EEG for prediction of fingermovements and estimation of finger kinematics remains elusive.Integration of AI with BCI has revolutionized the field of machinelearning through the advancement of deep learning, therebydecreasing the error rate, processing large amounts of data andmaximizing performance by performing self trials and errors[12,13]. The AI-BCI architecture holds promise to improve the clin-ical reliability of BCI performance in touch with EEG by enhancingthe AI key metric with the BCI architecture. Movement of a humanhand requires complex motor patterns by coordinating theresponses of multiple muscles. EEG and EMG have been used todecode the intention to move the hand [14–16] using BCIs, withEEG playing a vital role in the control of prosthetic limbs in ampu-tees [17]. BCIs integrate robotic systems with brain signals, allow-ing for intuitive control of neuro-prostheses such as robotic armsand actively generating a movement or imagining motor actions[18].This study proposes a novel strategy for finger movement pre-diction and kinematics estimation from EEG and EMG by utilizinga hybrid BCI system. To predict finger movement and kinematics, ahierarchical approach strategy comprising EEG and EMG fusionattained through estimation of EMG from EEG with AI techniqueswas used. Data from 18-channel EEG, 4-channel EMG and metacar-pophalangeal (MCP) joint angles during right hand flexion of fivefingers was acquired and used for the experiment. Fusion of infor-mation has been used in many studies to achieve better perfor-mance for a desired task. Tang et al. [19] proposed a Y-shapedynamic Transformer (YDTR) method based on fusion of infraredand visible image information to attain superior performance andbetter generalization ability. Tang et al. [20] further reported amultiscale adaptive transformer model fusing multimodal medicalimages to achieve better clinical diagnosis and surgical navigation.Leon-Garza et al. [21] used a type-2 based fuzzy logic systemapproach for fusion of 2D digital information into creating a 3DBIM model to attain an augmentable and interpretable model.The studies demonstrate the benefit of combining different infor-mation for a task. As such, the proposed study also aims to achievebetter accuracy for predicting finger movement and kinematicsusing hierarchical fusion of EMG and EEG. Application of hierarchi-cal approach represents sub-networks of EEG-based signal recogni-tion, EMG decoding from EEG, and BCI system integration with AIimpartment. Proposed work thus skillfully combines several con-cepts, approaches, techniques and components such as EEG,EMG, BCI, AI, finger movements and finger kinematics. The estima-tion of EMG from EEG is advantageous for developing control ofhand prostheses and robotic exoskeletons in individuals with handimpairment as they generate little to no EMG due to insufficientmuscle strength. Further, since the motor cortex region is the mainsource of movement and grasping, decoding muscle signals (EMG)from cortical signals (EEG) would also be beneficial.Simultaneous prediction of finger movements and kinematicsfrom the estimated EMG with AI techniques contributes to a moreintuitive and natural movement as well as grasp control in a pros-thetic or exoskeleton hand for rehabilitation. Additionally, the useof deep learning architectures and regression models allows forhigh precision and accuracy in the neurorehabilitation process.The methods dissect the mechanism of motor deficits caused bypathological brain changes. Furthermore, it helps to customizethe therapies by supporting the clinicians with relevant data onmotor organization. The reported work has been further tested tocontrol individual finger movements of an indigenously developedsensorized prosthetic hand. The study being implemented intendsto develop anthropomorphic control for upper limb prostheses,that can be utilized in clinical settings.The remainder of this paper is organized as follows: Section 2describes materials and methods for subject preparation, hardwareimplementation, software implementation, experimental setupwith data collection and experimental protocol. Section 3 presentsexperimentalresults and discussion including signal pre-processing as well as movement and kinematics prediction frame-work. Section 4 summarizes conclusion of the study.2. Materials and methods2.1. SubjectsSix healthy volunteers (4 males and 2 females) with a mean ageof 26.5 ± 4 years took part in the experiment. The study wasapproved by the institutional ethics committee of Tezpur Univer-sity, India. Written consent according to the Helsinki declaration[22] was obtained from each subject. All participants were right-handed and had no known neurological or muscular disorders.Experimental protocol was demonstrated to the participantsbefore the start of the experiment.2.2. Hardware implementation2.2.1. NS-EEG-D1 systemNS-EEG-D1 system from Neurostyle (Neurostyle PTE ltd, HillView, Singapore) was used for the acquisition of EEG. The systemprovided up to 64 channels of EEG recordings, built-in impedancetesting, and synchronous acquisition with other physiological sig-nals. It comprised of an EEG cap with electrodes affixed accordingto the 10–20 international standard as well as cables for connect-ing the system to power supply and laptop. Important technicalspecifications of the system are listed in Table S9 (SupplementaryMaterial).2.2.2. Shield-EKG-EMGFour SHIELD-EKG-EMG boards from Olimex were stacked ontop of one another and interfaced with an Arduino UNO for acqui-sition of 4-channel EMG. Inputs attached to shield, picks the analogdifferential signal generated by the muscles while the shield con-verts it into a single stream of output data. To discretize the signal,ADC embedded in the microcontroller of Arduino UNO further con-verts the analog signal to a digital signal. The shield has an inbuiltinstrumentation amplifier and a Besselworth filter with a cut-off40 Hz. The total gain of the shield is 2848. A SHIELD-EKG-EMGboard is shown in Figure S5 (Supplementary Material).2.2.3. Arduino UnoArduino Uno was used with the SHIELD-EKG-EMG boards forthe acquisition of 4-channel EMG and acquisition of kinematic datafrom a data glove. The SHIELD-EKG-EMG boards were mounted onone another with Arduino Uno as the base board. Connectors on185T. Das, L. Gohain, Nayan M Kakoty et al.Neurocomputing 527 (2023) 184–195the SHIELD-EKG-EMG, adhered to the Arduino Uno interfacingspecifications.remove noise. EMG acquired were visualized in real-time to ensurequality of the signals during acquisition.2.2.4. Ag-AgCl electrodesPre-gelled disposable Ag-AgCl electrodes of 1 cm in diameterfrom 3 M were used for EMG acquisition by placing them overthe area of target muscles. An important feature of these electrodeswas that they were single use and hygienic. Connection betweenelectrodes to shield boards was made through four lead cables.2.2.5. Data gloveA right-hand standard gardener’s glove customized with fiveflex sensors, one per finger was utilised for the acquisition of kine-matic data. It was interfaced with an Arduino Uno for data acqui-sition. The data glove equipped with flex sensors is shown inFigure S6.2.2.6. Flex sensorsFive flex sensors of 2.2 in. from Spectra Symbol were attached tothe data glove to collect kinematic data of five fingers. The sensorswere calibrated to collect data for flexion of MCP joint angles ofeach finger.2.3. Software implementation2.3.1. Arduino IDEArduino IDE is an integrated development environment (IDE),required for writing and uploading code to Arduino board. Thecode for acquisition of EMG and kinematic data was written inArduino IDE Windows version 1.6.11 and uploaded to an ArduinoUno board.2.3.2. NS-EEG softwareNS-EEG software version 19 was used to record, store, and visu-alise EEG data. The software assisted in selecting EEG montagesrequired for the experiment, automatic impedance checking, stor-ing subjects’ databases, visualizing and analysing the data.Kinematics of finger movements was acquired simultaneouslywith EMG, from right hand of the subjects using the data gloveequipped with five flex sensors. The data glove was calibrated tocollect data on the MCP joint angles for each finger of the righthand. These data was recorded at a sampling rate of 100 Hz. Laterin the data pre-processing step, cubic interpolation was performedto fix the sampling rate at 512 Hz, so as to keep it synchronizedwith that of the EMG and EEG data.EEG data was recorded simultaneously with EMG and fingerkinematics using Neurostyle’s NS-EEG-D1 system from 22monopolar channels fixed to an EEG electrode cap according tothe international 10–20 standards [23]. The selected channelsincluded Fp1, Fp2, F3, F4, C3, C4, P3, P4, O1, O2, F7, F8, T3, T4,T5, T6, Fz, Cz, Pz, Oz, A1,A2, referenced to a common ground(GND). The data was sampled at 512 Hz. Figure S1 shows theEEG montage that was used during acquisition of the EEG data.Prior to EEG recordings being taken, certain basic preparationswere carried out: cleaning the hair, adjustments of the EEG capposition, and impedance checking (was kept below 10 K ohm)were carried out in order to ensure good electrical contact withthe scalp of the participants.2.5. Experimental protocolParticipants were asked to sit on a comfortable chair, wearingthe data glove on their right hand and their elbow resting on a flatsurface table placed in front of them as shown in Fig. 1A. The acqui-sition session for each subject was of 16 min duration, consisting ofa total of eight trials for each finger. The trials started with a’RELAX’ followed by ’WAIT’,’STOP’ and’END’ visual cue, displayed on a laptop screen, indicating the sub-ject to relax, wait, then perform finger movements, stop and endthe session. Subjects were asked to focus on the screen while per-forming the displayed tasks. Fig. 1C depicts the timeline of theexperimental protocol categorized into 5 stages as follows:’FINGER MOVEMENT’,(0) S0 (Relax Stage): Screen displayed ’RELAX’ cue and subject2.3.3. Spyder (Anaconda)performed no movement for 25 s.Spyder (Scientific Python Development Environment), a freeand open-source python-based scientific development environ-ment (IDE), was used for coding and implementing the machinelearning and deep learning models presented in this work. Spyder’sbuilt-in integrated libraries, such as NumPy, Pandas, SciPy, andMatplotlib, were used in preparing and pre-processing the datasetusing Python 3.7. Also, Scikit Learn and Tensorflow 2.0 with Keras2.4.1 libraries were used to develop the proposed models for thehierarchical approach.2.4. Experimental setup and data collectionExperimental setup was comprised of an EMG acquisition sys-tem, an EEG acquisition system, and a data glove as shown inFig. 1A. SHIELD-EKG-EMG boards were used for the acquisition of4-channel EMG from each subject. Disposable pre-gelled Ag-AgClsurface electrodes were placed in a bipolar setting, keeping aninter-electrode distance of 20 mm over the area of target musclesof the subjects. Skin covering the area of target muscles wascleaned with isopropyl alcohol before placing the electrodes. Leadcables were connected to the electrodes and SHIELD-EKG-EMGboard for EMG acquisition. The target muscles with their corre-sponding finger movements and flexed joints are listed inTable S1. All channels had a common reference at the right elbow.The EMG data was acquired at a sampling rate of 512 Hz from theshield using Arduino Uno with a 10-bit analog-to-digital (A/D) con-verter. The shield has an inbuilt amplifier and bandpass filter to(1) S1 (Wait Stage): Screen displayed ’WAIT’ cue and subjectwaited for 2 s to get ready before performing the movement.(2) S2 (Movement Stage): Screen displayed ’FINGER MOVE-MENT’ along with a visual cue of a finger movement, and subjectperformed the movement for 12 s. The ’FINGER MOVEMENT’ visualcue consisted of one of the following five movements: thumb flex-ion, index flexion, middle flexion, ring flexion and little flexion. Allmovements were performed in the above sequence during a trial inaccordance with the visual cue being displayed.(3) S3 (Stop Stage): Screen displayed ’STOP’ cue indicating com-pletion of the movement and subject stopped for 7 s. The subjectperformed S1 to S3 5 times during a trial, where at each time thesubject performed a different finger movement according to thementioned sequence.(4) S4 (Rest stage): Screen displayed ’REST’ cue indicating sub-ject to rest for 10 s. This was done to reduce muscle fatigue inthe subject before beginning the next trial. After S4, the subjectperformed S1 to S3 for the next trial. Overall, the subject performedS1 to S4 for a total of 8 times.(5) S5 (End Stage): Screen displayed ’END’ cue indicating theend of session, and subject performed no movement for 25 s.2.6. DatasetThe dataset included 240 (6 subjects (cid:1) 5 movements (cid:1) 8 trials)4-channel EMG, 240 (6 subjects (cid:1) 5 movements (cid:1) 8 trials) 22 -channel EEG movement trials, and 240 (6 subjects (cid:1) 5 move-186T. Das, L. Gohain, Nayan M Kakoty et al.Neurocomputing 527 (2023) 184–195Fig. 1. (A) Experimental setup for EEG, EMG and finger kinematics data acquisition (B) Target muscle (flexor pollicis longus, flexor digitorum profundus, flexor digitorumsuperficialis) for placement of EMG electrodes (C) Timeline of experimental protocol (D) Pre-processing of EMG. (a) raw 4-channel EMG (b) enlarged view of a flexion trial andbaseline correction (c) Filtering (d) Rectification (e) Onset detection (f) Segmentation of a flexion trial (E) Pre-processing of EEG. (a) raw 18-channel EEG (b) enlarged view of aflexion trial (c) baseline correction (d) filtering and Onset detection (e) and segmented EEG of a flexion trial (F) Pre-processing of finger kinematics (a) Raw MCP joint fingerkinematics (b) Enlarged view of four trials (c) Filtering.ments (cid:1) 8 trials) finger kinematic data. Based on the data for sub-jects, the dataset was partitioned into 70 % for training and 30 % fortesting, i.e., out of six subjects, data from four subjects were usedfor training and data from two subjects were used for testing.3. Experimental results and discussion3.1. EEG and EMG pre-processing2.7. Statistical analysisA paired student’s t-test was performed to compare the predic-tion and estimation performance of the implemented models. Thet-tests were applied to results of the models used in estimatingEMG from EEG and predicting finger movements and kinematicsusing estimated EMG. The level of significance was set at 5 %(alpha = 0.05).In this study, finger movements and kinematics were decoded inan online BCI scenario from EEG using AI algorithms. The dataset,comprised of EEG, EMG, and finger kinematics recordings was pre-processed in steps that included baseline correction, filtering, recti-fication, onset detection, and segmentation. A baseline correctionalgorithm was applied to raw EMG (Fig. 1D-a) to remove off-set fromzero amplitude during no movement. The algorithm subtractedmean of the Rest stage samples corresponding to each channel fromthe Movement stage samples. To remove movement artefacts and187T. Das, L. Gohain, Nayan M Kakoty et al.Neurocomputing 527 (2023) 184–195power line interference, the baseline corrected EMG (Fig. 1D-b) wasfiltered using a 6th order band pass Butterworth filter in the fre-quency range of 10–250 Hz, followed by a 50 Hz notch filter (Fig. 1-D-c) [24]. Following that, the filtered EMG was rectified, and asmooth envelope of the EMG was achieved using a low pass filterwith a 4 Hz cut-off (Fig. 1D-d). The resulting EMG was then pro-cessed using a threshold detection algorithm for onset detection(Fig. 1D-e). Once the EMG amplitude exceeded a defined thresholdlevel for more than fifty consecutive samples, the first sample wasautomatically marked as the movement onset point. After detectionof the onset, the resulting EMG was segmented for further analysisusing a non-overlapping window size of 250 ms (Fig. 1D-f). Similarlyto EMG, EEG was pre-processed in steps that included baseline cor-rection, filtering, onset detection, and segmentation. Raw EEG wasbaseline corrected (Fig. 1E-b, c) by subtracting mean of the Relaxstage samples across 22 EEG channels from the Movement stageraw EEG samples. For final analysis, 18 channels of EEG for wasselected for the proposed study (Fig. 1E-a). To remove movementartefacts and power line interference, the corrected EEG was filteredusing a 2nd order band pass Butterworth filter within a frequencyrange of 0.1–40 Hz and a 50 Hz notch [25]. This was followed bydetection of onset of movement in EEG (Fig. 1E-d). Using a non-overlapping window of 250 ms, the resulting EEG was finally seg-mented for further analysis (Fig. 1E-e). Next, the finger kinematicsdata was pre-processed with a low pass filter (cut-off frequency =10 Hz) (Fig. 1F-a,e) and segmented to a window size of 250 ms foreach movement (Figure S3).3.2. Finger movement and finger kinematics prediction frameworkPredicting each finger movement in coordination using EEG sig-nal necessitates complex processing algorithms that must beapplied in stages [6,26]. Since, each stage employs a different algo-rithm for sequential training, it makes the overall adaptive systemcomplex. To this end, deep learning methods aid in the simultane-ous processing of multiple signals to achieve high performancewith satisfactory accuracy in real-time. It offers a single learningalgorithm for training several signals in parallel to increase decod-ing performance [27]. The proposed study, uses a deep neural net-work comprising of a LSTM network for predicting fingermovements and an ensemble learning method comprising of a ran-dom forest regressor was used for estimating the finger kinematics.Fig. 2A depicts the framework used to predict finger movementsand kinematics through EMG estimation EMG from EEG. Thisframework was accomplished in three stages. The first stageinvolved predicting the type of finger movement using acquiredEMG after it had been pre-processed. As described in section 2.6,the dataset was used accordingly for training and testing. Usingthe acquired EMG, a LSTM network model was trained for predic-tion of five finger movements of the right hand: thumb flexion,index flexion, middle flexion, ring flexion and little flexion. Themodel’s performance was validated using 5-fold cross validation.For a comparative analysis of the prediction model, a ConvolutionalNeural Network-Long Short-Term Memory (CNN-LSTM) network, aConvolutional LSTM (Conv-LSTM) network, and a random forestmodel were also evaluated. The second stage involved predictingthe type of finger movement using estimated EMG. Followingpre-processing, the EEG was used to train a linear regression modelto estimate the 4-channel EMG from the corresponding 18-channelEEG. A 5-fold cross validation was also used to validate the linearregression model. This was followed by the prediction of fingermovements with estimated EMG using the trained predictionmodel obtained in the first stage. The third stage involved predict-ing the finger kinematics from acquired EMG and estimated EMG.Following pre-processing, the finger kinematics were used to traina random forest regression model to predict the joint angle kine-matics of five fingers: thumb MCP, index MCP, middle MCP, ringMCP and little MCP from the corresponding acquired EMG. 5-foldcross validation was used to validate the model. A linear regres-sion, k-nearest neighbours (KNN), ridge, and LSTM models werealso evaluated for a comparative analysis. The prediction of fingerkinematics with estimated EMG was then followed using thetrained prediction model obtained earlier in this stage.3.3. Prediction models3.3.1. Prediction model for finger movements predictionDeep learning (DL) neural networks manages to deliver highaccuracy without the need to input hand-extracted features intothe network for training. A LSTM network is one such DL networkthat performs automatic feature extraction from time-series dataand captures the temporal information, delivering a high accuracy[28,29]. In presented study, a LSTM network was implemented forthe prediction of finger movements from EMG. The LSTM networklearned better by remembering the sequential information of theinput EMG samples in short time steps. The LSTM unit is comprisedof a forget gate layer, input gate layer, output gate layer and stategate layer. The forward pass equations of a LSTM unit with a forgetgate layer are described from Equation (1) to Equation (6).it ¼ r W i (cid:3) ht(cid:4)1; xt(cid:5) þ bið1ÞðÞ½(cid:1)¼ r W f (cid:3) ht(cid:4)1; xt½f tot ¼ r W o (cid:3) ht(cid:4)1; xtð½(cid:3)(cid:5) þ bf(cid:5) þ boÞ(cid:6)c¼ tanh W c (cid:3) ht(cid:4)1; xtð½(cid:5) þ btÞct ¼ f t(cid:6)(cid:3) ct(cid:4)1 þ it (cid:3) ctht ¼ ot (cid:3) tanhðctÞð2Þð3Þð4Þð5Þð6Þwhere t, i, o, f and c denote the time steps, input gate, output gate,forget gate, and cell state respectively. W i, W f ; W o,W c denotes theinput gate, forget gate, output gate, and cell state weights respec-tively and b denotes the unit’s bias. These equations suggested thatthe activation value of a LSTM unit required knowledge of the pre-vious value in time. The input gate it and forget gate f t, controlledhow much of the previous hidden state ht(cid:4)1 and current input xtwas contributed to the cell state ct. The sigmoid function r scaledthe activation of the forget, input, and output gates, and to finallyget the prediction result from the model the hidden state was fil-tered with the hyperbolic tangent function tanh.The LSTM model developed for this study was a four-layeredarchitecture (Fig. 2B). The input layer had 150 nodes, followed bytwo hidden layers: a recurrent layer with 200 LSTM cells and afully - connected dense layer of 250 units. At the last, was a denseoutput layer with 5 units for five movements. The activation func-tion used in the hidden and output layer was a rectifier (reLU) andsoftmax function respectively. Softmax function in the output layergave a probability distribution for the prediction output. To avoidmodel over-fitting, a dropout regularization of 20 percent wasapplied to the input and hidden layers and was trained with theearly stopping method. A manual search was used to determinethe network’s parameters based on the input parameter value thatprovided highest accuracy. The network had 425,556 parametersthat were optimized using the ADAM version of stochastic gradientdescent (SGD), with a learning rate of 0.001, a sparse categoricalloss function, and a batch size equal to sequence length of the inputEMG samples (800-time steps). The sparse categorical loss waschosen in the LSTM model to address the multi-class predictionproblem with integer target values so that the model labels the188T. Das, L. Gohain, Nayan M Kakoty et al.Neurocomputing 527 (2023) 184–195Fig. 2. (A) Framework for prediction of finger movements and finger kinematics through estimation of EMG from EEG (B) Configuration of implemented LSTM model (C)Configuration of implemented random forest regression model (D) LSTM model’s accuracy plot on training and testing set across 150 epochs depicting the predictionaccuracy during training and testing (E) LSTM model’s loss curve on training and testing set across 150 epochs (F) Confusion matrix obtained during (a) fold 1 (b) fold 2 (c)fold 3 (d) fold 4 (e) fold 5 using acquired EMG.predicted type of finger movement as integer values rather thanone-hot encoded labels. Also, it had the benefit of requiring lessmemory and computation time. For n number of prediction classes,Equation (7) described the sparse categorical loss function (SCF).SCF ¼ (cid:4)ti log piðÞð7ÞXni¼1where ti is the target label and pi is the softmax probability for theith class.3.3.2. Prediction model for finger kinematics predictionRandom forest is an ensemble learning algorithm that usesdecision trees to solve classification and regression problems. Arandom forest regression model predicts the target data moreaccurately by averaging the output of multiple decision trees inthe ensemble. In comparison to other regression models for pre-dicting hand kinematics, a random forest regression model is sim-pler to train and resistant to outliers and noise. Its processing timeduring training is faster than that of a neural network because itcan be parallelized. It can also process time series data with auto-matic feature extraction [30]. In this study, a random forest regres-sion model was used to predict finger kinematics from EMG data(Fig. 2C). The model’s input was pre-processed EMG, and outputwas the predicted MCP joint angles. The parameters of random for-est model consisted of 15 number of trees in the forest and value 5as the maximum depth of the trees. These parameters were deter-mined by a manual search based on the value of the input param-eter that gave the lowest error.3.4. Estimation modelThe proposed study employs a novel method for fusing EEG andEMG. A regression technique based on linear regression is used to189T. Das, L. Gohain, Nayan M Kakoty et al.Neurocomputing 527 (2023) 184–195estimate 4-channel EMG from 18-channel EEG, corresponding tofive types of finger movements. The regression model was appliedto establish a linear pathway between EEG and EMG in order toestimate EMG from EEG since the regression algorithm is basedon the assumption that the independent variable is related to thedependent variable [31]. In this estimation model, the independentvariable was EEG, which was input, and dependent variable wasEMG to be estimated. The linear regression model implementedis described by Equation (8).Yi ¼ bi0þ bi1(cid:3) Xi1 þ (cid:2)ð8Þwhere i = 1,2,3,4,. . ..n (n = number of samples), Xi1 is ith 18-channelinput EEG sample and Yi was ith 4-channel EMG to be estimated bythe model. Estimation coefficients of the model were given by val-ues of bi0 i.e., regression EEG intercept, bi1 i.e., regression coefficientand (cid:2) was the error in the model.3.5. Prediction of finger movements and kinematics from EEG throughestimation of EMGResults obtained for prediction of finger movements and kine-matics from EEG via estimation of EMG involving various stages,as well as the performance of the models in terms of their evalua-tion metrics and comparison analysis with other models, are pre-sented in this section. The hardware used for performing all theexperiments in the study was on a Intel i7-5500U CPU 64-bit2.40 GHz processor with 8.00 GB RAM memory.3.5.1. Prediction of finger movements using acquired EMGThe finger movement prediction model was trained for 150epochs applying early stopping method using acquired EMG. Fig. 2-D-E shows the learning curves for average prediction accuracy andloss of the LSTM model during training and testing across 150epochs indicating that as the loss decreased with number ofepochs, the accuracy increased, resulting in an optimal result atthe end of 150 epochs. 5-fold cross validation evaluated the mod-el’s performance and gave the best prediction model. The model’saccuracy was reported in average accuracy over 5-fold cross vali-dation results and across six subjects. The prediction accuracyobtained for each fold across five movements was evaluated usingEquation (9).Ai ¼X51TPi þ TNiTPi þ TNi þ FPi þ FNiið9Þwhere i is the number of movements across which average accuracywas evaluated. TP, TN, FP and FN are true positive, true negative,false positive and false negative predictions respectively [32].Confusion matrices were obtained representing the number ofcorrectly predicted movements i.e., the true positives and numberof incorrectly predicted movements i.e., the true negatives duringtesting for each fold. The diagonal of the confusion matrices high-lighted the correctly predicted movements (Figure S4; Supplemen-tary Material). Average prediction accuracy of the LSTM model foreach movement across all test subjects showed a maximum of (97.50 ± 5.00) % for thumb and middle finger while for index and ringfinger it was above 93.75 %. Lowest average prediction accuracy of88.75 % was obtained by little finger (Fig. 3A). This was indicativeof the model being able to predict thumb and middle flexion pre-dominantly followed by prediction of index and ring finger flex-ions, while finding most difficulty in predicting little fingerflexion. A reason for this could be due to the accurately performedthumb and middle finger movements by the subjects during theexperiment. The average prediction accuracy achieved across fivemovements and all test subjects was (94.75 ± 0.93)% with each foldobtaining a prediction accuracy above 93.75 % (Fig. 3B), indicatinga good performance of the prediction model in predicting themovements using the acquired EMG.In a comparative analysis, when the LSTM model was comparedwith other models such as CNN-LSTM, ConvLSTM, and random for-est, the LSTM model’s average prediction accuracy demonstratedan average 0.21 % higher accuracy than CNN-LSTM and ConvLSTMmodels and a 12.45 % higher accuracy than random forest model(Fig. 3C). However, the processing time (i. e., time taken by themodel during training) was higher in LSTM model as comparedto CNN-LSTM and ConvLSTM (Fig. 3D). This was because CNN-LSTM and ConvLSTM models attained a faster state of convergenceduring their model training in fewer epochs than LSTM model. Inthe presented experiment, CNN-LSTM and ConvLSTM took 65 and70 epochs respectively. Whereas it consumed more epochs forthe LSTM network to attain that convergence state, which was150 in our experiment. Although the training time per epoch forCNN-LSTM (i.e., 13.00 s) and ConvLSTM (i.e.,12.00 s) werelonger compared to LSTM (i.e., 11.60 s) due to the complexity oftheir convolution layers, the aggregated training time over a num-ber of epochs for CNN-LSTM and ConvLSTM were less i.e., 900 s and906 s compared to 2500 s for LSTM. This is also substantiated bythe fact that the special structure of CNN and Convolution canreduce the complexity as well as the overall training time of themodel [33] and can remember much longer sequences comparedto LSTM [34]. The LSTM model was chosen for prediction of fingermovements due to its higher accuracy, although it had a longercomputation time.3.5.2. Prediction of finger kinematics using acquired EMGPerformance of the prediction model implemented for predic-tion of finger kinematics using acquired EMG, was evaluated bytwo metrics: root mean squared error (RMSE), and coefficient ofdetermination (R2). RMSE measured the square root of the differ-ence between predicted and target values using Equation (10).RMSE ¼vuutffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiXN(cid:4) xiÞ2ðyiNi¼1ð10Þwhere yi is the target value of sample i, xi is the ith predicted valueand N is the total number of samples taken for evaluation. R2 gavethe difference between predicted and target values in terms of theiramplitude and correlation. It was calculated using Equation (11).PR2 ¼ 1 (cid:4)PNi¼1Ni¼1ðyiðyi(cid:4) xiÞ2(cid:4)iÞ2(cid:4) xð11Þwhere yi is the target value of sample i, xi is the predicted value of(cid:4)i is the mean of yi. R2 of a good prediction is betweensample i, and x0 and 1 and for a perfect prediction it is close to 1.A random forest regression model was trained for the predictionof finger kinematics. An average RMSE (Fig. 3E) of (0.258 ± 0.017)degree and an average R2 (Fig. 3F) of 0.842 ± 0.015 was achieved over5-fold cross validation across five fingers’ MCP joint angles and allsubjects. This result indicated a low error in predicting the fingerkinematics using acquired EMG, and a good model prediction usingacquired EMG across five fingers’ joint angles and all subjects. Thethumb and ring finger MCP joint angle showed an average RMSEerror of (0.24 ± 0.015) and (0.27 ± 0.016) respectively followed bythe middle finger joint angle which showed an average RMSE errorof 0.28 ± 0.014 (Fig. 3G). The index and little finger MCP joint angleshowed a comparatively higher error than the rest of the finger jointangles. It may be understood that while the model predicted thethumb, middle and ring MCP joint angles very well, it poorly pre-dicted the little finger MCP joint angle. The reason for this could bethat while performing flexion of little finger, other fingers got flexedalong, thereby making the model difficult to correctly distinguish it190T. Das, L. Gohain, Nayan M Kakoty et al.Neurocomputing 527 (2023) 184–195Fig. 3. (A) Average prediction accuracy of LSTM model for each finger movement across six subjects and five folds using acquired EMG (B) Prediction accuracy of LSTM modelacross five movements and at each fold using acquired EMG (C) Comparison of LSTM, CNN-LSTM and ConvLSTM models in terms of average prediction accuracy usingacquired EMG (D) Comparison of LSTM, CNN-LSTM and ConvLSTM models in terms of average processing time across five movements and six subjects using acquired EMG (E)Prediction performance of random forest regression model in terms of RMSE across finger kinematics of five fingers and six subjects at each fold using acquired EMG (F)Prediction performance of random forest regression model in terms of R2 across finger kinematics of five fingers at each fold using acquired EMG (G) Prediction performanceof random forest regression model in terms of average RMSE for each finger MCP joint angle across six subjects and 5-folds (H) Prediction performance of random forestregression model in terms of average R2 for each finger MCP joint angle across six subjects and 5-folds (I) Comparison results of random forest regression with linearregression, and K-NN regression model on the basis of their average RMSE.from the joint angles of other fingers. Comparison between the per-formance of random forest regression model with KNN regression,linear regression and a LSTM regression models depicted in Fig. 3I,showed random forest outperforming the aforementioned modelsbased on RMSE and R2 metrics (Table S2; Supplementary Materials).Random forest model gave an average of around 0.22 degree lessererror than the other models and showed a high correlation of 0.84demonstrating a strong linear relationship between the acquiredEMG and finger kinematics.3.5.3. Estimation of EMG from EEG4-channel EMG for finger movements: thumb, index, middle,ring and little finger flexion were estimated from corresponding18-channel EEG using linear regression. The average 5-fold crossvalidation result evaluated in terms of RMSE and R2 using the linearregression model across five movements and all subjects (Table S3)was 0.55 ± 0.014 and 0.74 ± 0.007 respectively. This showed goodestimation of the EMG from EEG with a low error. 18 channels ofEEG from a total 22 EEG channels was selected for EMG estimationbased on the linear regression model’s performance during estima-tion and prediction of the movements by LSTM model with the esti-mated EMG. The process provided optimal number of channels to beused for obtaining estimation and prediction performance result(Table S4). In a comparative analysis, the linear regression modelproduced an average of around 0.0086 degree lesser error and highercorrelation (0.742) than that of random forest, KNN and ridge esti-mation models in terms of average RMSE, average R2, and averageprocessing time. This indicated a good estimation of EMG fromEEG and depicted that EEG has a somewhat linear relationship withthe estimated EMG (Table S5).3.5.4. Prediction of finger movements using estimated EMGEstimated EMG obtained using linear regression model wastested with the trained LSTM model for prediction of desired fingermovement. The average prediction accuracy of LSTM model foreach finger movement across all subjects and five folds using esti-mated EMG showed highest prediction accuracy in ring finger (92.50 ± 2.5)%, followed by middle, thumb, and index finger (Fig. 4A).The index finger displayed the lowest prediction accuracy (65 %)using estimated EMG. Like in prediction using acquired EMG, theseresults showed the model’s ability to easily predict thumb, ringmiddle and index finger flexions but difficulty in predicting littlefinger flexion. The confusion matrices results during 5-fold crossvalidation (Fig. 2F) showed more than a 83 % accuracy at each foldand the average accuracy was (84.25 ± 0.61)% across five move-ments and all subjects (Fig. 4B). These are further indicative of agood model performance using estimated EMG at power with theperformance achieved using acquired EMG. Thus, suggesting thatthe proposed hierarchical approach can satisfactorily predict fingermovements using estimated EMG. Moreover, comparison withCNN-LSTM, ConvLSTM, and random forest classifier models usingestimated EMG, the LSTM model showed around 0.5 % higher aver-age prediction accuracy than those models (Fig. 4C). Statisticalanalysis evaluated with a paired t-test revealed LSTM model per-191T. Das, L. Gohain, Nayan M Kakoty et al.Neurocomputing 527 (2023) 184–195Fig. 4. (A) Average prediction accuracy of LSTM model for each finger movement across six subjects and five folds using estimated EMG (B) Prediction accuracy of LSTMmodel across five movements and six subjects at each fold using estimated EMG (C) Comparison of average prediction accuracy between LSTM, CNN-LSTM and ConvLSTMmodel across five movements and six subjects using estimated EMG (D) Prediction performance of random forest regression model in terms of average RMSE across fingerkinematics of five fingers and six subjects at each fold using acquired EMG (E) Prediction performance of random forest regression model in terms of R2 across fingerkinematics of five fingers at each fold using estimated EMG (F) Prediction performance of random forest regression model in terms of average RMSE for each finger MCP jointangle across six subjects and 5-folds using estimated EMG (G) Prediction performance of random forest regression model in terms of average R2 for each finger MCP jointangle across six subjects and 5-folds using estimated EMG (H) Comparison between random forest regression, linear regression, KNN regression and LSTM model in terms ofaverage RMSE (I) Comparison between random forest regression, linear regression, KNN regression and LSTM model in terms of average R2.forming better than the aforementioned prediction models havinga p-value < 0.05 (Table S8). These observations together with thecomparison shown between the models in terms of accuracy andprocessing time in Fig. 3C and Fig. 3D led to selection of the LSTMmodel for the proposed study in prediction of finger movements.3.5.5. Prediction of finger kinematics using estimated EMGUsing the trained random forest regression model, the fingerkinematics were predicted from estimated EMG. An average RMSEof (0.318 ± 0.011) (Fig. 4D) and average R2 of (0.772 ± 0.011)(Fig. 4E) over 5-fold cross-validation across five fingers and all sub-jects was achieved for the random forest regression model usingestimated EMG. This demonstrated a good performance of theregression model having a low error and satisfactory estimationof finger joint angles using the estimated EMG. The thumb andmiddle MCP joint angle’s average error in terms of RMSE was (0.30 ± 0.016) and (0.38 ± 0.014) (Fig. 4F) while the average R2 was0.75 and 0.72 respectively (Fig. 4G). The highest error was reportedin little finger joint angle (RMSE = 0.50 ± 0.015) and index fingerjoint angle (RMSE = 0.46 ± 0.014) prediction. An average of around0.1 degree higher error and around 0.13 lower average R2 value inpredicting thumb, middle, and ring finger joint angles using esti-mated EMG was revealed than in their prediction using acquiredEMG. This suggested that the model performed well for thumb,middle, ring and to a some extent for index finger but performedpoorly for the little finger joint angle. The prediction of fingerkinematics using acquired EMG gave a better result than predic-tion using estimated EMG since in the former case the predictionwas achieved using pre-processed EMG which was obtained fromthe direct source of its generation thereby yielding a much lessererror than using estimated EMG. On comparing the random forestregression model with linear regression, KNN regression, and aLSTM model in terms of RMSE and R2 (Fig. 4H-I), the random for-est regression model showed an average of around 0.26 degreelesser error and a 2.77 higher R2 value than the other models.The paired student t-test results (Table S8) too showed that therandom forest (p <.05) had a statistically significant differencein performance than those models. Between LSTM and randomforest model, the random forest model performed better asdepicted in Fig. 4H-I (Table S2, Table S8) and thus selected forour proposed study. The paired t-test statistical analysis betweenLSTM and random forest further justified use of the specific mod-els in predicting finger movements and estimating finger kine-matics respectively.3.6. Emulation of estimated finger movements and kinematics in aprosthetic handResults of estimated finger movements and kinematics wereemulated into a prosthetic hand finger movement control. A fivefingered prosthetic hand prototype was customized with anglesensors at MCP joints. Estimation of finger kinematics was192T. Das, L. Gohain, Nayan M Kakoty et al.Neurocomputing 527 (2023) 184–195Fig. 5. 16-Grasp types following Cutkosky’s grasp taxonomy and five finger movements by the prosthetic hand using the reported EEG-EMG based finger movement andkinematics estimation.employed as superior control for commanding a proportionalderivative controller to emulate the estimated results into thehand. Following the hierarchical approach for fusion of EEG andEMG for predicting finger movements and kinematics, the modelhas been tested for detection of simultaneous finger movementsand kinematics. Thereby, the prosthetic hand could perform 16-grasp types of Cutkosky’s grasp taxonomy and individual fingermovements as presented in Fig. 5.193T. Das, L. Gohain, Nayan M Kakoty et al.Neurocomputing 527 (2023) 184–1954. ConclusionAcknowledgementsPresented work successfully demonstrated prediction of fingermovements, finger kinematics through EMG estimation from EEGusing machine learning techniques integrated with BCI-AI net-working. The final result presented prediction of finger kinematicsfrom the EEG with estimation of EMG from EEG as an intermediatestep as presented in section 3.5.3 to 3.5.5. In addition, the fingermovements were also predicted from EEG with intermediate stepsof estimating EMG. These results have been used for emulating theidentified finger movement and kinematics into a prosthetic handprototype as presented in section 3.6. The research has emphasizedthe significance of EEG and EMG fusion, utilizing the process ofestimating EMG from EEG in development of hybrid BCI-AI sys-tems, which has not been reported in literature to the best of theauthors’ knowledge. AI integration with BCI systems has empow-ered the designed hierarchical approach in attaining the high accu-racy prediction of finger movements and finger kinematics.Synchronisation of EEG and EMG provide an efficient predictionof finger movements due to high coherence index co-linearity.Although BCI systems have earned their recognition, the state-of-art BCI integration with AI networking has a broad spectrum toexplore for ideal interpretation of brain’s normal output pathwaysof peripheral nerves and muscles. The work presented is highlyrecommended for implementation in the development of roboticlimb prosthesis and rehabilitation for amputees to ease the recog-nition and prediction of limb movements at clinical settings. Fur-thermore, it has been established that the proposed hierarchicalmethod can estimate finger kinematics and finger movementsbased on the fusion of EEG and EMG for control of real-time proto-type and can be extended to 3D applications. Another prospect ofthe presented work is to extend for multi-objective optimizationusing 3D point clouds and 3D mesh to provide for cost-effective,flexible and scalable solutions.5. Data and materials availabilityAll the data are available in the main text or supplementarymaterials. Code of this study is openly available at http://www.tezu.ernet.in/erl/sm.html.CRediT authorship contribution statementTanaya Das: Conceptualization, Data Curation, Formal analysis,Methodology, Investigation, Software, Visualization, Writing-origi-nal draft, Writing-review & editing. Lakhyajit Gohain: HardwareDesign, Writing-review & editing. Nayan M Kakoty: Conceptuali-zation, Funding Acquisition, Project Administration, Resources,Supervision, Methodology, Writing-review & editing, Hardwaredesign. MB Malarvili: Conceptualization, Funding acquisition,Writing-review & editing. Prihartini Widiyanti: Conceptualiza-tion, Funding acquisition, Writing-review & editing. GajendraKumar: Conceptualization, Funding acquisition, Writing-originaldraft, Writing-review & editing.Data availabilityDatasets generated during this study are available from the cor-responding author on resonable request.The support received in the project number CRD/2018/000049under the department of Science and Technology (DST), Govern-ment of India; project number NECBH/2019-20/144 under thedepartment of Biotechnology, Government of India; project num-ber GP/2021/RR/018 under the I-Hub Foundation for Cobotics-Indian Institute of Technology Delhi, DST, Government of Indiaand The Health and Medical Research Fund (HMRF) under Foodand Health Bureau, Hong Kong Special Administrative RegionGovernment (08193956) are gratefully acknowledged.Appendix A. Supplementary dataSupplementary data to this article can be found online athttps://doi.org/10.1016/j.neucom.2023.01.061.References[1] C.L. McDonald, S. Westcott-McCoy, M.R. Weaver, J. Haagsma, D. Kartin, Globalprevalence of traumatic non-fatal limb amputation, Prosthet. Orthot. Int. 45 (2)(2021) 105–114, https://doi.org/10.1177/0309364620972258.[2] J. Lobo-Prat, P.N. Kooren, A.H. Stienen, J.L. Herder, B.F. Koopman, P.H. Veltink,Non-invasive control interfaces for intention detection in active movement-assistive devices, J. Neuroeng. Rehabil. 11 (2014) 168, https://doi.org/10.1186/1743-0003-11-168.[3] A.I. Sburlea, L. Montesano, R. Cano de la Cuerda, I.M. Alguacil Diego, J.C.Miangolarra-Page, J. Minguez, Detecting intention to walk in stroke patientsfrom pre-movement EEG correlates, J. Neuroeng. Rehabil. 12 (2015) 113,https://doi.org/10.1186/s12984-015-0087-4.[4] A. Toda, H. Imamizu, M. Kawato, M.A. Sato, Reconstruction of two-dimensionalmovementfrom selected magnetoencephalography corticalcurrents by combined sparse Bayesian methods, Neuroimage 54 (2) (2011)892–905, https://doi.org/10.1016/j.neuroimage.2010.09.057.trajectories[5] F. Artoni, E. Pirondini, A. Panarese, S. Micera, Exploring neuro-muscularsynergies of reaching movements with unified independent componentanalysis, Annu. Int. Conf. IEEE Eng. Med. Biol. Soc. 2016 (2016) 3183–3186,https://doi.org/10.1109/EMBC.2016.7591405.[6] N. Yoshimura, H. Tsuda, T. Kawase, H. Kambara, Y. Koike, Decoding fingermovement in humans using synergy of EEG cortical current signals, Sci. Rep. 7(1) (2017) 11382, https://doi.org/10.1038/s41598-017-09770-5.[7] M. Barsotti, S. Dupan, I. Vujaklija, S. Dosen, A. Frisoli, D. Farina, ‘‘Online FingerControl Using High-Density EMG and Minimal Training Data for RoboticApplications,” (in English), IEEE Robot Autom Let 4 (2) (2019) 217–223,https://doi.org/10.1109/Lra.2018.2885753.[8] J. H. Cho, J. H. Jeong, D. J. Kim, and S. W. Lee, ‘‘A Novel Approach to ClassifyNatural Grasp Actions by Estimating Muscle Activity Patterns from EEGSignals,” (in English),I Wint C Brain-Comp, pp. 24-27, 2020. [Online].Available: <Go to ISI>://WOS:000612527100008.[9] D. Camargo-Vargas, M. Callejas-Cuervo, S. Mazzoleni, Brain-ComputerInterfaces Systems for Upper and Lower Limb Rehabilitation: A SystematicReview, Sensors (Basel) 21 (13) (2021), https://doi.org/10.3390/s21134312.[10] X. Zhang et al., The combination of brain-computer interfaces and artificialintelligence: applications and challenges, Ann. Transl. Med. 8 (11) (2020) 712,https://doi.org/10.21037/atm.2019.11.109.[11] S. Olsen, J. Zhang, K.F. Liang, M. Lam, U. Riaz, J.C. Kao, An artificial intelligencethat increases simulated brain-computer interface performance, J. Neural Eng.18 (4) (2021), https://doi.org/10.1088/1741-2552/abfaaa.[12] I. Tobore et al., Deep Learning Intervention for Health Care Challenges: SomeBiomedical Domain Considerations, JMIR Mhealth Uhealth 7 (8) (2019) e11966.[13] A.R. Asif et al., Performance Evaluation of Convolutional Neural Network forHand Gesture Recognition Using EMG, Sensors (Basel) 20 (6) (2020), https://doi.org/10.3390/s20061642.[14] A. Muralidharan, J. Chae, D.M. Taylor, Early detection of hand movements fromelectroencephalograms for stroke therapy applications, J. Neural Eng. 8 (4)(2011), https://doi.org/10.1088/1741-2560/8/4/046003.[15] N.A. Bhagat et al., Neural activity modulations and motor recovery followingbrain-exoskeleton interface mediated stroke rehabilitation, Neuroimage Clin.28 (2020), https://doi.org/10.1016/j.nicl.2020.102502.[16] P.D.E. Baniqued et al., Brain-computerfor handrehabilitation after stroke: a systematic review, J. Neuroeng. Rehabil. 18 (1)(2021) 15, https://doi.org/10.1186/s12984-021-00820-8.interface roboticsDeclaration of Competing InterestThe authors declare that they have no known competing finan-cial interests or personal relationships that could have appearedto influence the work reported in this paper.[17] A. Schwarz, M.K. Holler, J. Pereira, P. Ofner, G.R. Muller-Putz, Decoding handmovements from human EEG to control a robotic arm in a simulationenvironment, J. Neural Eng. 17 (3) (2020), https://doi.org/10.1088/1741-2552/ab882e.[18] M.A. Bockbrader, G. Francisco, R. Lee, J. Olson, R. Solinsky, M.L. Boninger, BrainComputer Interfaces in Rehabilitation Medicine, PM R 10 (9 Suppl 2) (2018)S233–S243, https://doi.org/10.1016/j.pmrj.2018.05.028.194T. Das, L. Gohain, Nayan M Kakoty et al.Neurocomputing 527 (2023) 184–195Lakhyajit Gohain graduated from Tezpur University in2018 with Bachelor’s degree in Electronics and Com-munication Engineering. He pursued Masters degree inBioelectronics with specialisation in rehabilitationrobotics in 2021. Currently he is working on cloudtechnologies as an Infrastructure engineer at DeloitteConsulting, Bengaluru. He has worked on multipleprojects associated with robotics and IoT. He has keeninterest in multidisciplinary technologies and lookingforward to work on the same.MB Malarvili received the bachelor’s and master’sdegrees in biomedical signal processing from UniversitiTeknologi Malaysia (UTM), Malaysia and the Ph.D.degree in medical sciences engineering from theUniversity of Queensland, Brisbane, Australia, in 2008.She is currently with the School of Biomedical Engi-neering and Health Science and the Head oftheBiosignal Processing Research Group, UTM. She hasauthored and co-authored over 100 research papers inpeer-reviewed journals, book chapters, and conferenceproceedings. Her research interest includes the areas ofphysiological signal processing, pattern recognition inbiomedical applications, time-frequency signal analysis, multi-modal signal pro-cessing, computer aided medical diagnosis system, and biomedical data.Gajendra Kumar received bachelor’s degree in HumanBiology, Master and PhD in Pharmacology. He worked atCity University of Hong Kong and University of Illinoisat Chicago, USA as a Post-Doctoral Fellow. He is cur-rently working as Research Assistant Professor atDepartment of Molecular Biology, Cell Biology & Bio-chemistry (MCB), Brown University, USA. He investi-gates the novel therapeutics for neurodegenerativediseases using electrophysiology in rodents model ofdisease, brain computer interphase and artificial intel-ligence.Prihartini Widiyanti graduated from Dentistry Facultyof Universitas Airlangga, Master of Basic Medical Sci-ences from Postgraduate Faculty of Universitas Air-langga and Doctoral Degree of Medical Sciences fromPostgraduate Faculty Universitas Airlangga. She per-formed her doctoral research in Institute of Biochem-istry University of Humboldt - Charite University ofClinics Berlin Germany by DAAD funding. She has per-formed researches in constructing diagnostic kit andanti- infectious disease in Institute of Tropical DiseaseUniversitas Airlangga and created several artificialorgans and scaffolds for Regenerative medicine. She hasauthored an Co-authored more than 75 reputed internationaljournals, bookchapters and international conference proceedings. Her research interest is inBiomedical sciences, Biomaterial, Tissue Engineering, Artificial Organs, MolecularBiology and Regenerative Medicine.[19] W. Tang, F. He, Y. Liu, YDTR: Infrared and Visible Image Fusion via Y-shapeDynamic Transformer, IEEE Trans. Multimedia (2022), https://doi.org/10.1109/TMM.2022.3192661.[20] W. Tang, F. He, Y. Liu, Y. Duan, MATR: Multimodal Medical Image Fusion viaMultiscale Adaptive Transformer, Trans. Img. Proc. 31 (2022) 5134–5149,https://doi.org/10.1109/TIP.2022.3193288.[21] H. Leon-Garza, H. Hagras, A. Peña-Rios, A. Conway, G. Owusu, A type-2 fuzzysystem-based approach for image data fusion to create building informationhttps://doi.org/10.1016/j.models,inffus.2022.07.007.115–125,(2022)FusionInf.88[22] World Medical Association.‘‘World Medical Association Declaration ofHelsinki: Ethical Principles for Medical Research Involving Human Subjects,”JAMA, 310(20), pp. 2191–2194,2013, doi:10.1001/jama.2013.281053.[23] G. Pfurtscheller, C. Neuper, and G. Krausz, ‘‘Functional dissociation of lowerand upper frequency mu rhythms in relation to voluntary limb movement”,Clinical Neurophysiology 111, 1873–1879.[24] H.G. Kortier, V.I. Sluiter, D. Roetenberg, P.H. Veltink, Assessment of handkinematics using inertial and magnetic sensors, J. Neuroeng. Rehabil. 11(2014) 70, https://doi.org/10.1186/1743-0003-11-70.[25] J.R. Potvin, S.H. Brown, Less is more: high pass filtering, to remove up to 99% ofthe surface EMG signal power, improves EMG-based biceps brachii muscleforce estimates, J. Electromyogr. Kinesiol. 14 (3) (2004) 389–399, https://doi.org/10.1016/j.jelekin.2003.10.005.[26] R.U. Alam, H. Zhao, A. Goodwin, O. Kavehei, A. McEwan, Differences in PowerSpectral Densities and Phase Quantities Due to Processing of EEG Signals,Sensors (Basel) 20 (21) (2020), https://doi.org/10.3390/s20216285.[27] K. Kritsis, M. Kaliakatsos-Papakostas, V. Katsouros, and A. Pikrakis,‘‘DeepConvolutional and LSTM Neural Network Architectures on Leap Motion HandTracking Data Sequences,” (in English), Eur Signal Pr Conf, 2019. [Online].Available: <Go to ISI>://WOS:000604567700296.[28] Z. Xie, O. Schwartz, A. Prasad, Decoding of finger trajectory from ECoG usingdeep learning, J. Neural Eng. 15 (3) (2018), https://doi.org/10.1088/1741-2552/aa9dbe.[29] F. Ma, F. Song, Y. Liu, J. Niu, sEMG-Based Neural Network Prediction ModelIntell.Selection of Gesture Fatigue and Dataset Optimization, Comput.Neurosci. 2020 (2020) 8853314, https://doi.org/10.1155/2020/8853314.[30] F. Xiao, Y. Wang, Y. Gao, Y. Zhu, J. Zhao, Continuous estimation of joint anglefrom electromyography using multiple time-delayed features and randomforests, Biomed. Signal Process 39 (2018) 303–311.[31] K.J. You, K.W. Rhee, H.C. Shin, Finger Motion Decoding Using EMG SignalsCorresponding Various Arm Postures, Exp. Neurobiol. 19 (1) (2010) 54–61,https://doi.org/10.5607/en.2010.19.1.54.[32] K. Englehart, B. Hudgins, P.A. Parker, ‘‘A wavelet-based continuous classificationscheme for multifunction myoelectric control,” (in English), IEEE T Bio-Med.Eng. 48 (3) (2001) 302–311, https://doi.org/10.1109/10.914793.[33] H. Qiao, T. Wang, P. Wang, S. Qiao, L. Zhang, A Time-DistributedSpatiotemporal Feature Learning Method for Machine Health Monitoringwith Multi-Sensor Time Series, Sensors 18 (2018) 1–20.[34] F.J. Ordóñez, D. Roggen, Deep Convolutional and LSTM Recurrent Neural Networksfor Multimodal Wearable Activity Recognition, Sensors 16 (2016) 1–25.Nayan M. Kakoty, IEEE Senior Member, received Bach-elor’s degree in Electrical Engineering, Master of Tech-nology in Bioelectronics and PhD in the area ofRehabilitation Robotics. He worked in City University ofHong Kong as Post-Doctoral Fellow and currentlyworking as a Professor in the department of ECE, TezpurUniversity, India. He is leading the Embedded Systemsand Robotics Lab (www.tezu.ernet.in/erl) and hisresearch interest is anthropomorphic prosthetic handand co-adaptation of user with prosthesis.Tanaya Das received her Master of Technology degreein Bioelectronics in 2021 and her Bachelor of Technol-ogy degree in Electronics and Communication Engi-neering in 2019 from Tezpur University, India. Hercurrent research interests lie in the fields of deeplearning, machine learning, biomedical signal process-ing and rehabilitation robotics.195