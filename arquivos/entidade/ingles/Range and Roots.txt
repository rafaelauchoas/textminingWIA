Artificial Intelligence 173 (2009) 1054–1078Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintRange and Roots: Two common patterns for specifying and propagatingcounting and occurrence constraints ✩Christian Bessiere a, Emmanuel Hebrard b, Brahim Hnich c, Zeynep Kiziltan d, Toby Walsh e,∗a LIRMM, CNRS and U. Montpellier, Montpellier, Franceb 4C and UCC, Cork, Irelandc Izmir University of Economics, Izmir, Turkeyd Department of Computer Science, Univ. di Bologna, Italye NICTA and UNSW, Sydney, Australiaa r t i c l ei n f oa b s t r a c tArticle history:Received 18 September 2007Received in revised form 26 February 2009Accepted 3 March 2009Available online 17 March 2009Keywords:Constraint programmingConstraint satisfactionGlobal constraintsOpen global constraintsDecompositions1. IntroductionWe propose Range and Roots which are two common patterns useful for specifying awide range of counting and occurrence constraints. We design specialised propagationalgorithms for these two patterns. Counting and occurrence constraints specified usingthese patterns thus directly inherit a propagation algorithm. To illustrate the capabilities ofthe Range and Roots constraints, we specify a number of global constraints taken from theliterature. Preliminary experiments demonstrate that propagating counting and occurrenceconstraints using these two patterns leads to a small loss in performance when comparedto specialised global constraints and is competitive with alternative decompositions usingelementary constraints.© 2009 Elsevier B.V. All rights reserved.Global constraints are central to the success of constraint programming [25]. Global constraints allow users to specifypatterns that occur in many problems, and to exploit efficient and effective propagation algorithms for pruning the searchspace. Two common types of global constraints are counting and occurrence constraints. Occurrence constraints place re-strictions on the occurrences of particular values. For instance, we may wish to ensure that no value used by one set ofvariables occurs in a second set. Counting constraints, on the other hand, restrict the number of values or variables meetingsome condition. For example, we may want to limit the number of distinct values assigned to a set of variables. Many dif-ferent counting and occurrences constraints have been proposed to help model a wide range of problems, especially thoseinvolving resources (see, for example, [22,4,23,3,5]).In this paper, we will show that many such constraints can be specified by means of two new global constraints, Rangeand Roots together with some standard elementary constraints like subset and set cardinality. These two new global con-straints capture the familiar notions of image and domain of a function. Understanding such notions does not require a strong✩This paper is a compilation and an extension of [C. Bessiere, E. Hebrard, B. Hnich, Z. Kiziltan, T. Walsh, The RANGE and ROOTS constraints: Specifyingcounting and occurrence problems, in: L.P. Kaelbling, A. Saffiotti (Eds.), IJCAI, Professional Book Center, 2005, pp. 60–65; C. Bessiere, E. Hebrard, B. Hnich, Z.Kiziltan, T. Walsh, The RANGE constraint: Algorithms and implementation, in: J.C. Beck, B.M. Smith (Eds.), CPAIOR, in: Lecture Notes in Computer Science,vol. 3990, Springer, 2006, pp. 59–73; C. Bessiere, E. Hebrard, B. Hnich, Z. Kiziltan, T. Walsh, The ROOTS constraint, in: F. Benhamou (Ed.), CP, in: LectureNotes in Computer Science, vol. 4204, Springer, 2006, pp. 75–90]. The first author was supported by the ANR project ANR-06-BLAN-0383-02.* Corresponding author.E-mail addresses: bessiere@lirmm.fr (C. Bessiere), e.hebrard@4c.ucc.ie (E. Hebrard), brahim.hnich@ieu.edu.tr (B. Hnich), zeynep@cs.unibo.it (Z. Kiziltan),tw@cse.unsw.edu.au (T. Walsh).0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2009.03.001C. Bessiere et al. / Artificial Intelligence 173 (2009) 1054–10781055background in constraint programming. A basic mathematical background is sufficient to understand these constraints anduse them to specify other global constraints. We will show, for example, that Range and Roots are versatile enough toallow specification of open global constraints, a recent kind of global constraints for which the set of variables involved isnot known in advance.Specifications made with Range and Roots constraints are executable. We show that efficient propagators can be de-signed for the Range and Roots constraints. We give an efficient algorithm for propagating the Range constraint based ona flow algorithm. We also prove that it is intractable to propagate the Roots constraint completely. We therefore proposea decomposition of the Roots constraint that can propagate it partially in linear time. This decomposition does not destroythe global nature of the Roots constraint as in many situations met in practice, it prunes all possible values. The proposedpropagators can easily be incorporated into a constraint toolkit.We show that specifying a global constraint using Range and Roots provides us with an reasonable method to propagatecounting and occurrence constraints. There are three possible situations. In the first, the global nature of the Range andRoots constraints is enough to capture the global nature of the given counting or occurrence constraint, and propagation isnot hindered. In the second situation, completely propagating the counting or occurrence constraint is NP-hard. We mustaccept some loss of propagation if propagation is to be tractable. Using Range and Roots is then one means to propagatethe counting or occurrence constraint partially. In the third situation, the global constraint can be propagated completely inpolynomial time but using Roots and Range hinders propagation. In this case, if we want to achieve full propagation, weneed to develop a specialised propagation algorithm.We also show that decomposing occurrence constraints and counting constraints using the Range and Roots constraintsperforms well in practice. Our experiments on random CSPs and a on real world problem from CSPLib demonstrate thatpropagating counting and occurrence constraints using the Range and Roots constraints leads to a small loss in performancewhen compared to specialised global constraints and is competitive with alternative decompositions into more elementaryconstraints.The rest of the paper is organised as follows. Section 2 gives the formal background. Section 3 defines the Range andRoots constraints and gives a couple of examples to illustrate how global constraints can be decomposed using these twoconstraints. In Section 4, we propose a polynomial algorithm for the Range constraint. In Section 5, we give a completetheoretical analysis of the Roots constraint and our decomposition of it, and we discuss implementation details. Section 6gives many examples of counting and occurrence constraints that can be specified using the Range and Roots constraints.Experimental results are presented in Section 7. Finally, we end with conclusions in Section 8.2. Formal backgroundA constraint satisfaction problem consists of a set of variables, each with a finite domain of values, and a set of con-straints specifying allowed combinations of values for subsets of variables. We use capitals for variables (e.g. X , Y and S),and lower case for values (e.g. v and w). We write D( X) for the domain of a variable X . A solution is an assignment ofvalues to the variables satisfying the constraints. A variable is ground when it is assigned a value. We consider both integerand set variables. A set variable S is often represented by its lower bound lb(S) which contains the definite elements (thatmust belong to the set) and an upper bound ub(S) which also contains the potential elements (that may or may not belongto the set).Constraint solvers typically explore partial assignments enforcing a local consistency property using either specialised orgeneral purpose propagation algorithms. Given a constraint C , a bound support on C is a tuple that assigns to each integervariable a value between its minimum and maximum, and to each set variable a set between its lower and upper boundswhich satisfies C . A bound support in which each integer variable is assigned a value in its domain is called a hybrid support.If C involves only integer variables, a hybrid support is a support. A value (resp. set of values) for an integer variable (resp.set variable) is bound or hybrid consistent with C iff there exists a bound or hybrid support assigning this value (resp. set ofvalues) to this variable. A constraint C is bound consistent (BC) iff for each integer variable Xi , its minimum and maximumvalues belong to a bound support, and for each set variable S j , the values in ub(S j) belong to S j in at least one boundsupport and the values in lb(S j) are those from ub(S j) that belong to S j in all bound supports. A constraint C is hybridconsistent (HC) iff for each integer variable Xi , every value in D( Xi) belongs to a hybrid support, and for each set variable S j ,the values in ub(S j) belong to S j in at least one hybrid support, and the values in lb(S j) are those from ub(S j) that belongto S j in all hybrid supports. A constraint C involving only integer variables is generalised arc consistent (GAC) iff for eachvariable Xi , every value in D( Xi) belongs to a support. If all variables in C are integer variables, hybrid consistency reducesto generalised arc consistency, and if all variables in C are set variables, hybrid consistency reduces to bound consistency.To illustrate these different concepts, consider the constraint C( X1, X2, T ) that holds iff the set variable T is assignedexactly the values used by the integer variables X1 and X2. Let D( X1) = {1, 3}, D( X2) = {2, 4}, lb(T ) = {2} and ub(T ) ={1, 2, 3, 4}. BC does not remove any value since all domains are already bound consistent (value 2 was considered as possiblefor X1 because BC deals with bounds). On the other hand, HC removes 4 from D( X2) and from ub(T ) as there does notexist any tuple satisfying C in which X2 does not take value 2.We will compare local consistency properties applied to (sets of) logically equivalent constraints, c1 and c2. As in [15], alocal consistency property Φ on c1 is as strong as Ψ on c2 iff, given any domains, if Φ holds on c1 then Ψ holds on c2; Φon c1 is stronger than Ψ on c2 iff Φ on c1 is as strong as Ψ on c2 but not vice versa; Φ on c1 is equivalent to Ψ on c2 iff1056C. Bessiere et al. / Artificial Intelligence 173 (2009) 1054–1078Φ on c1 is as strong as Ψ on c2 and vice versa; Φ on c1 is incomparable to Ψ on c2 iff Φ on c1 is not as strong as Ψ onc2 and vice versa.A total function F from a source set S into a target set T is denoted by F : S −→ T . The set of all elements in S thatF (i), whilst theF −1( j). Throughout, we will view a set of integer variables, X1 to Xn ashave the same image j ∈ T is F −1( j) = {i: F (i) = j}. The image of a set S ⊆ S under F is F (S) =domain of a set T ⊆ T under F is F −1(T ) =j∈TD( Xi). That is, X (i) is the value of Xi .a function X : {1, .., n} →i∈S(cid:2)(cid:2)(cid:2)i=ni=13. Two useful patterns: Range and RootsMany counting and occurrence constraints can be specified using simple non-global constraints over integer variables(like X (cid:2) m), simple non-global constraints over set variables (like S 1 ⊆ S2 or |S| = k) available in most constraint solvers,and two special global constraints acting on sequences of variables: Range and Roots. Range captures the notion of imageof a function and Roots captures the notion of domain. Specification with Range and Roots is executable. It permits us todecompose other global constraints into more primitive constraints.Given a function X representing a set of integer variables, X1 to Xn, the Range constraint holds iff a set variable T isthe image of another set variable S under X .(cid:3)[ X1, .., Xn], S, TRange(cid:4)iffT = X (S)(cid:3)that is, T = { Xi | i ∈ S}(cid:4)The Roots constraint holds iff a set variable S is the domain of the another set variable T under X .(cid:3)[ X1, . . . , Xn], S, TRoots(cid:4)iffS = X −1(T )(cid:3)that is, S = {i | Xi ∈ T }(cid:4)Range and Roots are not exact inverses. A Range constraint can hold, but the corresponding Roots constraint maynot, and vice versa. For instance, Range([1, 1], {1}, {1}) holds but not Roots([1, 1], {1}, {1}) since X −1(1) = {1, 2}, andRoots([1, 1, 1], {1, 2, 3}, {1, 2}) holds but not Range([1, 1, 1], {1, 2, 3}, {1, 2}) as no Xi is assigned to 2.Before showing how to propagate Range and Roots efficiently, we give two examples that illustrate how some countingand occurrence global constraints from [2] can be specified using Range and Roots.The NValue constraint counts the number of distinct values used by a sequence of variables [19,8,7]. NValue([ X1, .., Xn],N) holds iff N = |{ Xi | 1 (cid:2) i (cid:2) n}|. A way to implement this constraint is with a Range constraint:(cid:3)[ X1, .., Xn], NNValue(cid:3)[ X1, .., Xn], {1, .., n}, TRangeiff(cid:4)(cid:4)∧ |T | = NThe AtMost constraint is one of the oldest global constraints [29]. The AtMost constraint puts an upper bound on thenumber of variables using a particular value. AtMost([ X1, .., Xn], d, N) holds iff |{i | Xi = d}| (cid:2) N. It can be decomposedusing a Roots constraint.(cid:3)[ X1, .., Xn], d, NAtMost(cid:3)(cid:4)[ X1, .., Xn], S, {d}Roots(cid:4)iff∧ |S| (cid:2) NThese two examples show that it can be quite simple to decompose global constraints using Range and Roots. As wewill show later, some other global constraints will require the use of both Range and Roots in the same decomposition. Thenext sections show how Range and Roots can be propagated efficiently.4. Propagating the Range constraintEnforcing hybrid consistency on the Range constraint is polynomial. This can be done using a maximum network flowproblem. In fact, the Range constraint can be decomposed using a global cardinality constraint (Gcc) for which propagatorsbased on flow problems already exist [23,21]. But the Range constraint does not need the whole power of maximumnetwork flow problems, and thus HC can be enforced on it at a lower cost than that of calling a Gcc propagator. In thissection, we propose an efficient way to enforce HC on Range. To simplify the presentation, the use of the flow is limitedto a constraint that performs only part of the work needed for enforcing HC on Range. This constraint, that we nameOccurs([ X1, . . . , Xn], T ), ensures that all the values in the set variable T are used by the integer variables X1 to Xn:(cid:3)[ X1, . . . , Xn], TOccurs(cid:4)iffT ⊆ X(cid:4)(cid:3){1..n}(cid:3)that is, T ⊆ { Xi | i ∈ 1..n}(cid:4)We first present an algorithm for achieving HC on Occurs (Section 4.1), and then use this to propagate the Rangeconstraint (Section 4.2).4.1. Hybrid consistency on OccursWe achieve HC on Occurs([ X1, . . . , Xn], T ) using a network flow.C. Bessiere et al. / Artificial Intelligence 173 (2009) 1054–10781057Fig. 1. Unit capacity network of the constraint C = Occurs([ X1, X2, X3], T ) with D( X1) = {1, 2}, D( X2) = {2, 3, 4}, D( X3) = {3, 4}, lb(T ) = {3, 4} and ub(T ) ={1, 2, 3, 4}. Arcs are directed from left to right.Fig. 2. A maximum flow for the network of Fig. 1. Bold arcs are those that belong to the flow. Arcs are directed from left to right.4.1.1. Building the network flowWe use a unit capacity network [1] in which capacities between two nodes can only be 0 or 1. This is represented by adirected graph where an arc from node x to node y means that a maximum flow of 1 is allowed between x and y whilethe absence of an arc means that the maximum flow allowed is 0. The unit capacity network G C = (N, E) of the constraintC = Occurs([ X1, . . . , Xn], T ) is built in the following way. N = {s} ∪ N1 ∪ N2 ∪ {t}, where s is a source node, t is a sink node,N1 = {v | v ∈(cid:3){s} × N1D( Xi)} ∪ {xi | i ∈ [1..n]}. The set of arcs E is as follows:(cid:6)(v, zv ), ∀v /∈ lb(T )D( Xi)} and N2 = {zv | v ∈(cid:7)(cid:6)(cid:7) v ∈ D( Xi)N2 × {t}(v, xi)E =(cid:2)(cid:2)∪∪∪(cid:5)(cid:5)(cid:3)(cid:4)(cid:4)G C is quadripartite, i.e., E ⊆ ({s} × N1) ∪ (N1 × N2) ∪ (N2 × {t}). In Fig. 1, we depict the network G C of the constraintC = Occurs([ X1, X2, X3], T ) with D( X1) = {1, 2}, D( X2) = {2, 3, 4}, D( X3) = {3, 4}, lb(T ) = {3, 4} and ub(T ) = {1, 2, 3, 4}.The intuition behind this graph is that when a flow uses an arc from a node v to a node xi this means that Xi is assignedv, and when a flow uses the arc (v, zv ) this means that v is not necessarily used by the Xi ’s.1 In Fig. 1 nodes 3 and 4 arelinked only to nodes x2 and x3, that is, values 3 and 4 must necessarily be taken by one of the variables Xi (3 and 4 belongto lb(T )). On the contrary, nodes 1 and 2 are also linked to nodes z1 and z2 because values 1 and 2 do not have to be takenby a Xi (they are not in lb(T )).(cid:9)In the particular case of unit capacity networks, a flow is any set Eis assigned 1 and the arcs inare assigned 0. A feasible flow from s to t in G C is a subset E f of E such that ∀n ∈ N \ {s, t} the number of arcs ofE \ E(cid:9)(cid:9)) ∈ E f }|. The value of theE f entering n is equal to the number of arcs of E f going out of n, that is, |{(nflow E f from s to t, denoted val(E f , s, t), is val(E f , s, t) = |{n | (s, n) ∈ E f }|. A maximum flow from s to t in G C is a feasibleflow E M such that there does not exist a feasible flow E f , with val(E f , s, t) > val(E M , s, t). A maximum flow for the networkof Fig. 1 is given in Fig. 2. By construction a feasible flow cannot have a value greater than |N1| and cannot contain twoarcs entering a node xi from N2. Hence, we can define a function ϕ linking feasible flows and partial instantiations on theXi ’s. Given any feasible flow E f from s to t in G C , ϕ(E f ) = {( Xi, v) | (v, xi) ∈ E f }. The maximum flow in Fig. 2 correspondsto the instantiation X2 = 4, X3 = 3. The way G C is built induces the following theorem.(cid:9), n) ∈ E f }| = |{(n, n(cid:9) ⊆ E: any arc in E(cid:9)1 Note that in our presentation of the graph, the edges go from the nodes representing the values to the nodes representing the variables. This is theopposite to the direction used in the presentation of network flows for propagators of the AllDifferent or Gcc constraints [22,23].1058C. Bessiere et al. / Artificial Intelligence 173 (2009) 1054–1078Fig. 3. Residual graph obtained from the network in Fig. 1 and the maximum flow in Fig. 2.Theorem 1. Let G C = (N, E) be the capacity network of a constraint C = Occurs([ X1, . . . , Xn], T ).1. A value v in the domain D( Xi) for some i ∈ [1..n] is HC iff there exists a flow E f from s to t in G C with val(E f , s, t) = |N1| and(v, xi) ∈ E f .2. If the Xi ’s are HC, T is HC iff ub(T ) ⊆(cid:2)i D( Xi).Proof. (1. ⇒) Let I be a solution for C with ( Xi, v) ∈ I . Build the following flow H : Put (v, xi) in H ; ∀w ∈ I[T ], w (cid:11)= v, take a(cid:9) (cid:11)= v,variable X j such that ( X j, w) ∈ I (we know there is at least one since I is solution), and put (w, x j) in H ; ∀w(cid:9), zw(cid:9) ) to H . Add to H the edges from s to N1 and from N2 to t so that we obtain a feasible flow. By construction,add (wall w ∈ N1 belong to an edge of H . So, val(H, s, t) = |N1| and H is a maximum flow with (v, xi) ∈ H .(1. ⇐) Let E M be a flow from s to t in G C with (v, xi) ∈ E M and val(E M , s, t) = |N1|. By construction of G C , we areguaranteed that all nodes in N1 belong to an arc in E M ∩ (N1 × N2), and that for every value w ∈ lb(T ), { y | (w, y) ∈ E} ⊆{xi | i ∈ [1..n]}. Thus, for each w ∈ lb(T ), ∃ X j | ( X j, w) ∈ ϕ(E M ). Hence, any extension of ϕ(E M ) where each unassigned X jtakes any value in D( X j) and T = lb(T ) is a solution of C with Xi = v.(cid:9) /∈ I[T ], w(2. ⇒) If T is HC, all values in ub(T ) appear in at least one solution tuple. Since C ensures that T ⊆(cid:2){ Xi}, ub(T )icannot contain a value appearing in none of the D( Xi).(cid:2)(cid:2)(2. ⇐) Let ub(T ) ⊆i D( Xi) is taken by some Xi in at(cid:9)(cid:9)[T ] = I[T ] ∪ {v}. Ileast one solution tuple I . Build the tuple Iis still solutionof C . So, ub(T ) is as tight as it can be wrt HC. In addition, since all Xi ’s are HC, this means that in every solution tuple I ,for each v ∈ lb(T ) there exists i such that I[ Xi] = v. So, lb(T ) is HC. (cid:2)i D( Xi). Since all Xi ’s are HC, we know that each value v in(cid:9)[ Xi] = I[ Xi] for each i ∈ [1..n] and Iso that I(cid:9)Following Theorem 1, we need a way to check which edges belong to a maximum flow. Residual graphs are useful for thistask. Given a unit capacity network G C and a maximal flow E M from s to t in G C , the residual graph R G C (E M ) = (N, E R )is the directed graph obtained from G C by reversing all arcs belonging to the maximum flow E M ; that is, E R = {(x, y) ∈E \ E M } ∪ {( y, x) | (x, y) ∈ E ∩ E M }. Given the network G C of Fig. 1 and the maximum flow E M of Fig. 2, R G C (E M ) is depictedin Fig. 3. Given a maximum flow E M from s to t in G C , given (x, y) ∈ N1 × N2 ∩ E \ E M , there exists a maximum flowcontaining (x, y) iff (x, y) belongs to a cycle in R G C (E M ) [26]. Furthermore, finding all the arcs (x, y) that do not belongto a cycle in a graph can be performed by building the strongly connected components of the graph. We see in Fig. 3 thatthe arcs (1, x1) and (2, x1) belong to a cycle. So, they belong to some maximum flow and ( X1, 1) and ( X1, 2) are hybridconsistent. (2, x2) does not belong to any cycle. So, ( X2, 2) is not HC.4.1.2. Using the network flow for achieving HC on OccursWe now have all the tools for achieving HC on any Occurs constraint. We first build G C . We compute a maximumflow E M from s to t in G C ; if val(E M , s, t) < |N1|, we fail. Otherwise we compute R G C (E M ), build the strongly connectedcomponents in R G C (E M ), and remove from D( Xi) any value v such that (v, xi) belongs to neither E M nor to a stronglyconnected component in R G C (E M ). Finally, we set ub(T ) to ub(T )∩i D( Xi). Following Theorem 1 and properties of residualgraphs, this algorithm enforces HC on Occurs([ X1, .., Xn], T ).(cid:2)Complexity. Building G C is in O (nd) where d is the maximum domain size. We need then to find a maximum flow E Min G C . This can be done in two sub-steps. First, we use the arc (v, zv ) for each v /∈ lb(T ) (in O (|i D( Xi)|)). Afterwards,we compute a maximum flow on the subgraph composed of all paths traversing nodes w with w ∈ lb(T ) (because there isk · e)no arc (w, zw ) in G C for such w). The complexity of finding a maximum flow in a unit capacity network is in O (|lb(T )| · |lb(T )| · n) for this secondif k is the number of nodes and e the number of edges. This gives a complexity in O (sub-step. Building the residual graph and computing the strongly connected components is in O (nd). Extracting the HCdomains for the Xi ’s is direct. There remains to compute BC on T , which takes O (nd). Therefore, the total complexity is inO (nd + n · |lb(T )|3/2).(cid:2)√(cid:8)C. Bessiere et al. / Artificial Intelligence 173 (2009) 1054–10781059procedure Propag-Range([ X1, . . . , Xn], S, T );1 Introduce the set of integer variables Y = {Y i | i ∈ ub(S)},with D(Y i ) = D( Xi ) ∪ {dummy};2 Achieve hybrid consistency on the constraint Occurs(Y , T );3 Achieve hybrid consistency on the constraints i ∈ S ↔ Y i ∈ T , for all Y i ∈ Y ;4 Achieve GAC on the constraints (Y i = dummy) ∨ (Y i = Xi ), for all Y i ∈ Y ;Algorithm 1. Hybrid consistency on Range.Incrementality.In constraint solvers, constraints are usually maintained in a locally consistent state after each modification(restriction) of the domains of the variables. It is thus interesting to consider the total complexity of maintaining HC onOccurs after an arbitrary number of restrictions on the domains (values removed from D( Xi) and ub(T ), or added to lb(T ))as we descend a branch of a backtracking search tree. Whereas some constraints are completely incremental (i.e., the totalcomplexity after any number of restrictions is the same as the complexity of one propagation), this is not the case forconstraints based on flow techniques like AllDifferent or Gcc [22,23]. They potentially require the computation of a newmaximum flow after each modification. Restoring a maximum flow from one that lost p edges is in O (p · e). If values areremoved one by one (nd possible times), and if each removal affects the current maximum flow, the overall complexity overa sequence of restrictions on Xi ’s, S, T , is in O (n2d2).4.2. Hybrid consistency on RangeEnforcing HC on Range([ X1, . . . , Xn], S, T ) can be done by decomposing it as an Occurs constraint on new variables Y iand some channelling constraints [14] linking T and the Y i ’s to S and the Xi ’s. Interestingly, we do not need to maintainHC on the decomposition but just need to propagate the constraints in one pass.The algorithm Propag-Range, enforcing HC on the Range constraint, is presented in Algorithm 1. In line 1, a specialencoding is built, where a Y i is introduced for each Xi with index in ub(S). The domain of a Y i is the same as that of Xiplus a dummy value. The dummy value works as a flag. If Occurs prunes it from D(Y i) this means that Y i is necessary inOccurs to cover lb(T ). Then, Xi is also necessary to cover lb(T ) in Range. In line 2, HC on Occurs removes a value froma Y i each time it contains other values that are necessary to cover lb(T ) in every solution tuple. HC also removes valuesfrom ub(T ) that cannot be covered by any Y i in a solution. Line 3 updates the bounds of S and the domain of Y i ’s. Finally,in line 4, the channelling constraints between Y i and Xi propagate removals on Xi for each i which belongs to S in allsolutions.Theorem 2. The algorithm Propag-Range is a correct algorithm for enforcing HC on Range, that runs in O (nd + n · |lb(T )|3/2) time,where d is the maximal size of Xi domains.Proof. Soundness. A value v is removed from D( Xi) in line 4 if it is removed from Y i together with dummy in lines 2 or 3.If a value v is removed from Y i in line 2, this means that any tuple on variables in Y covering lb(T ) requires that Y i takesa value from D(Y i) other than v. So, we cannot find a solution of Range in which Xi = v since lb(T ) must be covered aswell. A value v is removed from D(Y i) in line 3 if i ∈ lb(S) and v /∈ ub(T ). In this case, Range cannot be satisfied by a tuplewhere Xi = v. If a value v is removed from ub(T ) in line 2, none of the tuples of values for variables in Y covering lb(T )can cover v as well. Since variables in Y duplicate variables Xi with index in ub(S), there is no hope to satisfy Range if vis in T . Note that ub(T ) cannot be modified in line 3 since Y contains only variables Y i for which i was in ub(S). If a valuev is added to lb(T ) in line 3, this is because there exists i in lb(S) such that D(Y i) ∩ ub(T ) = {v}. Hence, v is necessarilyin T in all solutions of Range. An index i can be removed from ub(S) only in line 3. This happens when the domain of Y idoes not intersect ub(T ). In such a case, this is evident that a tuple where i ∈ S could not satisfy Range since Xi could nottake a value in T . Finally, if an index i is added to lb(S) in line 3, this is because D(Y i) is included in lb(T ), which meansthat the dummy value has been removed from D(Y i) in line 2. This means that Y i takes a value from lb(T ) in all solutionsof Occurs. Xi also has to take a value from lb(T ) in all solutions of Range.Completeness. Suppose that a value v is not pruned from D( Xi) after line 4 of Propag-Range. If Y i ∈ Y , we know thatafter line 2 there was an instantiation I on Y and T , solution of Occurs with I[Y i] = v or with Y i = dummy (thanks toon X1, .., Xn, S, T where Xi takes value v, every X j withthe channelling constraints in line 4). We can build the tuple Ij ∈ ub(S) and I[Y j] ∈ I[T ] takes I[Y j], and the remaining X j ’s take any value in their domain. T is set to I[T ] plus thevalues taken by X j ’s with j ∈ lb(S). These values are in ub(T ) thanks to line 3. Finally, S is set to lb(S) plus the indicesof the Y j ’s with I[Y j] ∈ I[T ]. These indices are in ub(S) since the only j’s removed from ub(S) in line 3 are such that(cid:9)[ Xi] = v. We haveD(Y j) ∩ ub(T ) = ∅, which prevents I[Y j] from taking a value in I[T ]. Thus Iproved that the Xi ’s are hybrid consistent after Propag-Range.is a solution of Range with ISuppose a value i ∈ ub(S) after line 4. Thanks to constraint in line 3 we know there exists v in D(Y i) ∩ ub(T ), and so,v ∈ D( Xi) ∩ ub(T ). Now, Xi is hybrid consistent after line 4. Thus Xi = v belongs to a solution of Range. If we modify thissolution by putting i in S and v in T (if not already there), we keep a solution.(cid:9)(cid:9)Completeness on lb(S), lb(T ) and ub(T ) is proved in a similar way.1060C. Bessiere et al. / Artificial Intelligence 173 (2009) 1054–1078Complexity. The important thing to notice in Propag-Range is that constraints in lines 2–4 are propagated in sequence.Thus, Occurs is propagated only once, for a complexity in O (nd + n · |lb(T )|3/2). Lines 1, 3, and 4 are in O (nd). Thus, thecomplexity of Propag-Range is in O (nd + n · |lb(T )|3/2). This reduces to linear time complexity when lb(T ) is empty.Incrementality. The overall complexity over a sequence of restrictions on Xi ’s, S and T is in O (n2d2). (See incrementalityof Occurs in Section 4.1.) (cid:2)Note that the Range constraint can be decomposed using the Gcc constraint. However, propagation on such a decompo-sition is in O (n2d + n2.66) time complexity (see [21]). Propag-Range is thus significantly cheaper.5. Propagating the Roots constraintWe now give a thorough theoretical analysis of the Roots constraint. In Section 5.1, we provide a proof that enforcing HCon Roots is NP-hard in general. Section 5.2 presents a decomposition of the Roots constraint that permits us to propagatethe Roots constraint partially in linear time. Section 5.3 shows that in many cases this decomposition does not destroythe global nature of the Roots constraint as enforcing HC on the decomposition achieves HC on the Roots constraint.Section 5.4 shows that we can obtain BC on the Roots constraint by enforcing BC on its decomposition. Finally, we providesome implementation details in Section 5.5.5.1. Complete propagationUnfortunately, propagating the Roots constraint completely is intractable in general. Whilst we made this claim in [10],a proof has not yet been published. For this reason, we give one here.Theorem 3. Enforcing HC on the Roots constraint is NP-hard.Proof. We transform 3Sat into the problem of the existence of a solution for Roots. Finding a hybrid support is thus NP-hard. Hence enforcing HC on Roots is NP-hard. Let ϕ = {c1, . . . , cm} be a 3CNF on the Boolean variables x1, . . . , xn. Webuild the constraint Roots([ X1, . . . , Xn+m], S, T ) as follows. Each Boolean variable xi is represented by the variable Xi withdomain D( Xi) = {i, −i}. Each clause c p = xi ∨ ¬x j ∨ xk is represented by the variable Xn+p with domain D( Xn+p) = {i, − j, k}.We build S and T in such a way that it is impossible for both the index i of a Boolean variable xi and its complement −i to{i, −i}, and lb(S) = ub(S) = {n + 1, . . . , n + m}. An interpretation M on thebelong to T . We set lb(T ) = ∅ and ub(T ) =Boolean variables x1, . . . , xn is a model of ϕ iff the tuple τ in which τ [ Xi] = i iff M[xi] = 0 can be extended to a solution ofRoots. (This extension puts in T value i iff M[xi] = 1 and assigns Xn+p with the value corresponding to the literal satisfyingc p in M.) (cid:2)(cid:2)ni=1We thus have to look for a lesser level of consistency for Roots or for particular cases on which HC is polynomial. Wewill show that bound consistency is tractable and that, under conditions often met in practice (e.g. one of the last twoarguments of Roots is ground), enforcing HC is also.5.2. A decomposition of RootsTo show that Roots can be propagated tractably, we will give a straightforward decomposition into ternary constraintsthat can be propagated in linear time. This decomposition does not destroy the global nature of the Roots constraintsince enforcing HC on the decomposition will, in many cases, achieve HC on the original Roots constraint, and since in allcases, enforcing BC on the decomposition achieves BC on the original Roots constraint. Given Roots([ X1, .., Xn], S, T ), wedecompose it into the implications:i ∈ S → Xi ∈ TXi ∈ T → i ∈ Swhere i ∈ [1..n]. We have to be careful how we implement such a decomposition in a constraint solver. First, some solverswill not achieve HC on such constraints (see Section 5.5 for more details). Second, we need an efficient algorithm to be ableto propagate the decomposition in linear time. As we explain in more detail in Section 5.5, a constraint solver could easilytake quadratic time if it is not incremental.We first show that this decomposition prevents us from propagating the Roots constraint completely. However, this is tobe expected as propagating Roots completely is NP-hard and this decomposition is linear to propagate. In addition, as welater show, in many circumstances met in practice, the decomposition does not in fact hinder propagation.Theorem 4. HC on Roots([ X1, .., Xn], S, T ) is strictly stronger than HC on i ∈ S → Xi ∈ T , and Xi ∈ T → i ∈ S for all i ∈ [1..n].C. Bessiere et al. / Artificial Intelligence 173 (2009) 1054–10781061Proof. Consider X1 ∈ {1, 2}, X2 ∈ {3, 4}, X3 ∈ {1, 3}, X4 ∈ {2, 3}, lb(S) = ub(S) = {3, 4}, lb(T ) = ∅, and ub(T ) = {1, 2, 3, 4}. Thedecomposition is HC. However, enforcing HC on Roots will prune 3 from D( X2). (cid:2)In fact, enforcing HC on the decomposition achieves a level of consistency between BC and HC on the original Rootsconstraint. Consider X1 ∈ {1, 2, 3}, X2 ∈ {1, 2, 3}, lb(S) = ub(S) = {1, 2}, lb(T ) = {}, and ub(T ) = {1, 3}. The Roots constraintis BC. However, enforcing HC on the decomposition will remove 2 from the domains of X1 and X2. In the next section, weidentify exactly when the decomposition achieves HC on Roots.5.3. Some special casesMany of the counting and occurrence constraints do not use the Roots constraint in its more general form, but havesome restrictions on the variables S, T or Xi ’s. For example, it is often the case that T or S are ground. We select fourimportant cases that cover many of these uses of Roots and show that enforcing HC on Roots is then tractable.C1. ∀i ∈ lb(S), D( Xi) ⊆ lb(T )C2. ∀i /∈ ub(S), D( Xi) ∩ ub(T ) = ∅C3. X1, .., Xn are groundC4. T is groundWe will show that in any of these cases, we can achieve HC on Roots simply by propagating the decomposition.Theorem 5. If one of the conditions C 1 to C 4 holds, then enforcing HC on i ∈ S → Xi ∈ T , and Xi ∈ T → i ∈ S for all i ∈ [1..n]achieves HC on Roots([ X1, .., Xn], S, T ).Proof. Our proof will exploit the following properties that are guaranteed to hold when we have enforced HC on thedecomposition.P1 if D( Xi) ⊆ lb(T ) then i ∈ lb(S)P2 if D( Xi) ∩ ub(T ) = ∅ then i /∈ ub(S)P3 if i ∈ lb(S) then D( Xi) ⊆ ub(T )P4 if i /∈ ub(S) then D( Xi) ∩ lb(T ) = ∅P5 if D( Xi) = {v} and i ∈ lb(S) then v ∈ lb(T )P6 if D( Xi) = {v} and i /∈ ub(S) then v /∈ ub(T )P7 if i is added to lb(S) by the constraint Xi ∈ T → i ∈ S then D( Xi) ⊆ lb(T )P8 if i is deleted from ub(S) by the constraint i ∈ S → Xi ∈ T then D( Xi) ∩ ub(T ) = ∅Soundness. Immediate.Completeness. We assume that one of the conditions C1–C4 holds and the decomposition is HC. We will first prove thatthe Roots constraint is satisfiable. Then, we will prove that, for any Xi , all the values in D( Xi) belong to a solution of Roots,and that the bounds on S and T are as tight as possible.We prove that the Roots constraint is satisfiable. Suppose that one of the conditions C1–C4 holds and that the decom-position is HC. Build the following tuple τ of values for the Xi , S, and T . Initialise τ [S] and τ [T ] with lb(S) and lb(T )respectively. Now, let us consider the four conditions separately.(C1) For each i ∈ τ [S], choose any value v in D( Xi) for τ [ Xi]. From the assumption and from property P7 we deducethat v is in lb(T ), and so in τ [T ]. For each other i, assign Xi with any value in D( Xi) \ lb(T ). (This set is not empty thanksto property P1.) τ obviously satisfies Roots.(C2) For each i ∈ τ [S], choose any value in D( Xi) for τ [ Xi]. By construction such a value is in ub(T ) thanks to propertyP3. If necessary, add τ [ Xi] to τ [T ]. For each other i ∈ ub(S), assign Xi with any value in D( Xi) \ τ [T ] if possible. Otherwiseassign Xi with any value in D( Xi) and add i to τ [S]. For each i /∈ ub(S), assign Xi any value from its domain. By assumptionand by property P8 we know that D( Xi) ∩ ub(T ) = ∅. Thus, τ satisfies Roots.(C3) τ [ Xi] is already assigned for all Xi . For each i ∈ τ [S], property P5 tells us that τ [ Xi] is in τ [T ], and for eachi /∈ lb(S), property P1 tells us that τ [ Xi] is outside lb(T ). τ satisfies Roots.(C4) For each i ∈ τ [S] choose any value v in D( Xi) for τ [ Xi]. Property P3 tells us v ∈ ub(T ). By assumption, v is thus inτ [T ]. For each i outside ub(S), assign Xi with any value v in D( Xi). (v is outside τ [T ] by assumption and property P4). Foreach other i, assign Xi with any value in D( Xi) and update τ [S] if necessary. τ satisfies Roots.We have proved that the Roots constraint has a solution. We now prove that for any value in ub(S) or in ub(T ) or inD( Xi) for any Xi , we can transform the arbitrary solution of Roots into a solution that contains that value. Similarly, forany value not in lb(S) or not in lb(T ), we can transform the arbitrary solution of Roots into a solution that does not containthat value.Let us prove that lb(T ) is tight. Suppose the tuple τ is a solution of the Roots constraint. Let v /∈ lb(T ) and v ∈ τ [T ].We show that there exists a solution with v /∈ τ [T ]. (Remark that this case is irrelevant to condition C4.) We remove v1062C. Bessiere et al. / Artificial Intelligence 173 (2009) 1054–1078(cid:9)(cid:9)(cid:9)in τ , we add vfrom τ [T ]. For each i /∈ lb(S) such that τ [ Xi] = v we remove i from τ [S]. With C1 we are sure that none of the i in lb(S)have τ [ Xi] = v, thanks to property P7 and the fact that v /∈ lb(T ). With C3 we are sure that none of the i in lb(S) haveτ [ Xi] = v, thanks to property P5 and the fact that v /∈ lb(T ). There remains to check C2. For each i ∈ lb(S), we know that(cid:9) ∈ D( Xi) ∩ ub(T ), thanks to properties P3 and P5. We set Xi to v(cid:9) (cid:11)= v, vto τ [T ] and add all k with∃v(cid:9)to τ [S]. We are sure that k ∈ ub(S) because vτ [ Xk] = v(cid:9)(cid:9) ∈ ub(T ) plus condition C2 and property P8.Completeness on ub(T ), lb(S), ub(S) and Xi ’s are shown with similar proofs. Let v ∈ ub(T ) \ τ [T ]. (Again C4 is irrelevant.)We show that there exists a solution with v ∈ τ [T ]. Add v to τ [T ] and for each i ∈ ub(S), if τ [ Xi] = v, put i in τ [S]. C2 issolved thanks to property P8 and the fact that v ∈ ub(T ). C3 is solved thanks to property P6 and the fact that v ∈ ub(T ).(cid:9) ∈ D( Xi) \ lb(T ) (thanks to propertiesThere remains to check C1. For each i /∈ ub(S) and τ [ Xi] = v, we know that ∃v(cid:9)is removed from τ [S], and this isin τ and remove vP4 and P6). We set Xi to vpossible because we are in condition C1, v(cid:9) (cid:11)= v, vfrom τ [T ]. Each k with τ [ Xk] = v(cid:9) /∈ lb(T ), and thanks to property P7.Let v ∈ D( Xi) and τ [ Xi] = v(cid:9) (cid:11)= v. (C3 is irrelevant.) Assign v to Xi in τ . If both v and v(cid:9)or none of them are in τ [T ],(cid:9) /∈ τ [T ], the two alternatives to satisfy Roots are to add i inwe are done. There remain two cases. First, if v ∈ τ [T ] and vτ [S] or to remove v from τ [T ]. If i ∈ ub(S), we add i to τ [S] and we are done. If i /∈ ub(S), we know that v /∈ lb(T ) thanksto property P4. So, v is removed from τ [T ] and we are sure that the X j ’s can be updated consistently for the same reason(cid:9) ∈ τ [T ], the two alternatives to satisfy Roots are to remove i from τ [S]as in the proof of lb(T ). Second, if v /∈ τ [T ] and vor to add v to τ [T ]. If i /∈ lb(S), we remove i from τ [S] and we are done. If i ∈ lb(S), we know that v ∈ ub(T ) thanks toproperty P3. So, v is added to τ [T ] and we are sure that the X j ’s can be updated consistently for the same reason as in theproof of ub(T ) \ τ [T ].Let i /∈ lb(S) and i ∈ τ [S]. We show that there exists a solution with i /∈ τ [S]. We remove i from τ [S]. Thanks to property(cid:9) ∈ D( Xi) \ lb(T ). With C4 we are done because we are sure(cid:9) ∈ τ [T ], we remove it from τ [T ] and we are sure that the X j ’s can beP1, we know that D( Xi) (cid:2) lb(T ). So, we set Xi to a value v(cid:9) /∈ τ [T ]. With conditions C1, C2, and C3, if vvupdated consistently for the same reason as in the proof of lb(T ).(cid:9), vLet i ∈ ub(S) \ τ [S]. We show that there exists a solution with i ∈ τ [S]. We add i to τ [S]. Thanks to property P2, we(cid:9) ∈ D( Xi) ∩ ub(T ). With condition C4 we are done because we are(cid:9) /∈ τ [T ], we add it to τ [T ] and we are sure that the X j ’s can be updatedknow that D( Xi) ∩ ub(T ) (cid:11)= ∅. So, we set Xi to a value v(cid:9) ∈ τ [T ]. With conditions C1, C2, and C3, if vsure vconsistently for the same reason as in the proof of ub(T ) \ τ [T ]. (cid:2)5.4. Bound consistencyIn addition to being able to enforce HC on Roots in some special cases, enforcing HC on the decomposition always en-forces a level of consistency at least as strong as BC. In fact, in any situation (even those where enforcing HC is intractable),enforcing BC on the decomposition enforces BC on the Roots constraint.Theorem 6. Enforcing BC on i ∈ S → Xi ∈ T , and Xi ∈ T → i ∈ S for all i ∈ [1..n] achieves BC on Roots([ X1, .., Xn], S, T ).Proof. Soundness. Immediate.Completeness. The proof follows the same structure as that in Theorem 5. We relax the properties P1–P4 into properties(cid:9)–P4.(cid:9)P1(cid:9)(cid:9)(cid:9)(cid:9)P1P2P3P4if [min( Xi), max( Xi)] ⊆ lb(T ) then i ∈ lb(S)if [min( Xi), max( Xi)] ∩ ub(T ) = ∅ then i /∈ ub(S)if i ∈ lb(S) then the bounds of Xi are included in ub(T )if i /∈ ub(S) then the bounds of Xi are outside lb(T )(cid:2)Let us prove that lb(T ) and ub(T ) are tight. Let o be the total ordering on D =i D( Xi) ∪ ub(T ). Build the tuples σand τ as follows: For each v ∈ lb(T ): put v in σ [T ] and τ [T ]. For each v ∈ ub(T ) \ lb(T ), following o, do: put v in σ [T ](cid:9)or τ [T ] alternately. For each i ∈ lb(S), P3guarantees that both min( Xi) and max( Xi) are in ub(T ). By construction of σ [T ](and τ [T ]) with alternation of values, if min( Xi) (cid:11)= max( Xi), we are sure that there exists a value in σ [T ] (in τ [T ]) betweenmin( Xi) and max( Xi). In the case |D( Xi)| = 1, P5 guarantees that the only value is in σ [T ] (in τ [T ]). Thus, we assign Xi inσ (in τ ) with such a value in σ [T ] (in τ [T ]). For each i /∈ ub(S), we assign Xi in σ with a value in [min( Xi), max( Xi)] \ σ [T ](the same for τ ). We know that such a value exists with the same reasoning as for i ∈ lb(S) on alternation of values, and(cid:9)and P6. We complete σ and τ by building σ [S] and τ [S] consistently with the assignments of Xi and T . Thethanks to P4resulting tuples satisfy Roots. From this we deduce that lb(T ) and ub(T ) are BC as all values in ub(T ) \ lb(T ) are either inσ or in τ , but not both.We show that the Xi are BC. Take any Xi and its lower bound min( Xi). If i ∈ lb(S) we know that min( Xi) is in T either(cid:9)and by construction of σ and τ . We assign min( Xi) to Xi in the relevant tuple. This remains ain σ or in τ thanks to P3(cid:9)solution of Roots. If i /∈ ub(S), we know that min( Xi) is outside T either in σ or in τ thanks to P4and by construction ofσ and τ . We assign min( Xi) to Xi in the relevant tuple. This remains a solution of Roots. If i ∈ ub(S) \ lb(S), assign Xi tomin( Xi) in σ . If min( Xi) /∈ σ [T ], remove i from σ [S] else add i to σ [S]. The tuple obtained is a solution of Roots using thelower bound of Xi . By the same reasoning, we show that the upper bound of Xi is BC also, and therefore, all Xi ’s are BC.C. Bessiere et al. / Artificial Intelligence 173 (2009) 1054–10781063We prove that lb(S) and ub(S) are BC with similar proofs. Let us show that ub(S) is BC. Take any Xi with i ∈ ub(S)and i /∈ σ [S]. Since Xi was assigned any value from [min( Xi), max( Xi)] when σ was built, and since we know that(cid:9)[min( Xi), max( Xi)] ∩ ub(T ) (cid:11)= ∅ thanks to P2, we can modify σ by assigning Xi a value in ub(T ), putting the value inT if not already there, and adding i into S. The tuple obtained satisfies Roots. So ub(S) is BC.(cid:9)There remains to show that lb(S) is BC. Thanks to P1, we know that values i ∈ ub(S) \ lb(S) are such that[min( Xi), max( Xi)] \ lb(T ) (cid:11)= ∅. Take v ∈ [min( Xi), max( Xi)] \ lb(T ). Thus, either σ or τ is such that v /∈ T . Take the cor-responding tuple, assign Xi to v and remove i from S. The modified tuple is still a solution of Roots and lb(S) is BC. (cid:2)5.5. Implementation detailsThis decomposition of the Roots constraint can be implemented in many solvers using disjunctions of membership andnegated membership constraints: or(member(i, S), notmember( Xi, T )) and or(notmember(i, S), member( Xi, T )). How-ever, this requires a little care. Unfortunately, some existing solvers (like Ilog Solver [16]) may not achieve HC on suchdisjunctions of primitives. For instance, the negated membership constraint notmember( Xi, T ) may be activated only if Xiis instantiated with a value of T (whereas it should be as soon as D( Xi) ⊆ lb(T )). We have to ensure that the solver wakesup when it should to ensure we achieve HC. As we explain in the complexity proof, we also have to be careful that thesolver does not wake up too often or we will lose the optimal O (nd) time complexity which can be achieved.Theorem 7. It is possible to enforce HC (or BC) on the decomposition of Roots([ X1, .., Xn], S, T ) in O (nd) time, where d =max(∀i.|D( Xi)|, |ub(T )|).Proof. The decomposition of Roots is composed of 2n constraints. To obtain an overall complexity in O (nd), the totalamount of work spent propagating each of these constraints must be in O (d) time.First, it is necessary that each of the 2n constraints of the decomposition is not called for propagation more than dtimes. Since S can be modified up to n times (n can be larger than d) it is important that not all constraints are called forpropagation at each change in lb(S) or ub(S). By implementing ‘propagating events’ as described in [17,27], we can ensurethat when a value i is added to lb(S) or removed from ub(S), constraints j ∈ S → X j ∈ T and X j ∈ T → j ∈ S, j (cid:11)= i, are notcalled for propagation.Second, we show that enforcing HC on constraint i ∈ S → Xi ∈ T is in O (d) time. Testing the precondition (does i belongto lb(S)?) is constant time. If true, removing from D( Xi) all values not in ub(T ) is in O (d) time and updating lb(T ) (if|D( Xi)| = 1) is constant time. Testing that the postcondition is false (is D( Xi) disjoint from ub(T )?) is in O (d) time. If false,updating ub(S) is constant time. Thus HC on i ∈ S → Xi ∈ T is in O (d) time. Enforcing HC on Xi ∈ T → i ∈ S is in O (d)time as well because testing the precondition (D( Xi) ⊆ lb(T )?) is in O (d) time, updating lb(S) is constant time, testing thatthe postcondition is false (i /∈ ub(S)?) is constant time, and removing from D( Xi) all values in lb(T ) is in O (d) time andupdating ub(T ) (if |D( Xi)| = 1) is constant time.When T is modified, all constraints are potentially concerned. Since T can be modified up to d times, we can haved calls of the propagation in O (d) time for each of the 2n constraints. It is thus important that the propagation of the2n constraints is incremental to avoid an O (nd2) overall complexity. An algorithm for i ∈ S → Xi ∈ T is incremental if thecomplexity of calling the propagation of the constraint i ∈ S → Xi ∈ T up to d times (once for each change in T or D( Xi))is the same as propagating the constraint once. This can be achieved by an AC2001-like algorithm that stores the lastvalue found in D( Xi) ∩ ub(T ), which is a witness that the postcondition can be true. (Similarly, the last value found inD( Xi) \ lb(T ) is a witness that the precondition of the constraint Xi ∈ T → i ∈ S can be false.) Finally, each time lb(T ) (resp.ub(T )) is modified, D( Xi) must be updated for each i outside ub(S) (resp. inside lb(S)). If the propagation mechanism ofthe solver provides the values that have been added to lb(T ) or removed from ub(T ) to the propagator of the 2n constraints(as described in [30]), updating a given D( Xi) has a total complexity in O (d) time for the d possible changes in T . Theproof that BC can also be enforced in linear time follows a similar argument. (cid:2)6. A catalog of decompositions using Range and RootsWe have shown how to propagate the Range and Roots constraints. Specification of counting and occurrence constraintsusing Range and Roots will thus be executable. Range and Roots permit us to decompose counting and occurrence globalconstraints into more primitive constraints, each of which having an associated polynomial propagation algorithm. In somecases, such decomposition does not hinder propagation. In other cases, enforcing local consistency on the global constraintis intractable, and decomposition is one method to obtain a polynomial propagation algorithm [11,13,12].In a technical report [9], we present a catalog containing over 70 global constraints from [2] specified with the helpof the Range and Roots constraints. Here we present a few of the more important constraints. In the subsequent fivesubsections, we list some counting and occurrence constraints which can be specified using Range constraints, using Rootsconstraints, and using both Range and Roots constraints. We also show that Range and Roots can be used to specify openglobal constraints, a new kind of global constraints introduced recently. We finally include problem domains other thancounting and occurrence to illustrate the wide range of global constraints expressible in terms of Range and Roots.1064C. Bessiere et al. / Artificial Intelligence 173 (2009) 1054–10786.1. Applications of Range constraintRange constraints are often useful to specify constraints on the values used by a sequence of variables.6.1.1. All differentThe AllDifferent constraint forces a sequence of variables to take different values from each other. Such a constraintis useful in a wide range of problems (e.g. allocation of activities to different slots in a time-tabling problem). It can bepropagated efficiently [22]. It can also be decomposed with a single Range constraint:(cid:3)[ X1, .., Xn]AllDifferentiff(cid:4)(cid:3)[ X1, .., Xn], {1, .., n}, TRange(cid:4)∧ |T | = nA special but nevertheless important case of this constraint is the Permutation constraint. This is an AllDifferentconstraint where we additionally know R, the set of values to be taken. That is, the sequence of variables is a permutationof the values in R where |R| = n. This also can be decomposed using a single Range constraint:(cid:3)[ X1, .., Xn], RPermutation(cid:3)[ X1, .., Xn], {1, .., n}, RRange(cid:4)iff(cid:4)Such a decomposition of the Permutation constraint obviously does not hinder propagation. However, decomposition ofAllDifferent into a Range constraint does. This example illustrates that, whilst many global constraints can be expressed interms of Range and Roots, there are some global constraints like AllDifferent for which it is worth developing specialisedpropagation algorithms. Nevertheless, Range and Roots provide a means of propagation for such constraints in the absenceof specialised algorithms. They can also enhance the existing propagators. For instance, HC on the Range decomposition isincomparable to AC on the decomposition of AllDifferent which uses a clique of binary inequality constraints. Thus, wemay be able to obtain more pruning by using both decompositions.Theorem 8. (1) GAC on Permutation is equivalent to HC on the decomposition with Range. (2) GAC on AllDifferent is strongerthan HC on the decomposition with Range. (3) AC on the decomposition of AllDifferent into binary inequalities is incomparable toHC on the decomposition with Range.Proof. (1) Permutation can be encoded as a single Range. Moreover, since R is fixed, HC is equivalent to AC. (2) ConsiderX1, X2 ∈ {1, 2}, X3 ∈ {1, 2, 3, 4}, and {1, 2} ⊆ T ⊆ {1, 2, 3, 4}. Then Range([ X1, X2, X3], {1, 2, 3}, T ) and |T | = 3 are both HC,but AllDifferent([ X1, X2, X3]) is not GAC. (3) Consider X1, X2 ∈ {1, 2}, X3 ∈ {1, 2, 3}, and T = {1, 2, 3}. Then X1 (cid:11)= X2,X1 (cid:11)= X3 and X2 (cid:11)= X3 are AC but Range([ X1, X2, X3], {1, 2, 3}, T ) is not HC. Consider X1, X2 ∈ {1, 2, 3, 4}, X3 ∈ {2}, and{2} ⊆ T ⊆ {1, 2, 3, 4}. Then Range([ X1, X2, X3], {1, 2, 3}, T ) and |T | = 3 are HC. But X1 (cid:11)= X3 and X2 (cid:11)= X3 are not AC. (cid:2)6.1.2. DisjointWe may require that two sequences of variables be disjoint (i.e. have no value in common). For instance, two sequencesof tasks sharing the same resource might be required to be disjoint in time. The Disjoint([ X1, .., Xn], [Y 1, .., Ym]) constraintintroduced in [2] ensures Xi (cid:11)= Y j for any i and j. We prove here that we cannot expect to enforce GAC on such a constraintas it is NP-hard to do so in general.Theorem 9. Enforcing GAC on Disjoint is NP-hard.Proof. We reduce 3-SAT to the problem of deciding if a Disjoint constraint has any satisfying assignment. Finding supportis therefore NP-hard. Consider a formula ϕ with n variables and m clauses. For each Boolean variable x, we let Xx ∈ {x, ¬x}and Y j ∈ {x, ¬ y, z} where the jth clause in ϕ is x ∨ ¬ y ∨ z. If ϕ has a model then the Disjoint constraint has a satisfyingassignment in which the Xx take the literals false in this model. (cid:2)One way to propagate a Disjoint constraint is to decompose it into two Range constraints:(cid:4)(cid:3)[ X1, .., Xn], [Y 1, .., Ym]Disjoint(cid:4)(cid:3)[ X1, .., Xn], {1, .., n}, S∧Range(cid:4)(cid:3)[Y 1, .., Ym], {1, .., m}, TRangeiff∧ S ∩ T = {}Enforcing HC on this decomposition is polynomial. Decomposition thus offers a simple and promising method to propagatea Disjoint constraint. Not surprisingly, the decomposition hinders propagation (otherwise we would have a polynomialalgorithm for a NP-hard problem).C. Bessiere et al. / Artificial Intelligence 173 (2009) 1054–10781065Theorem 10. GAC on Disjoint is stronger than HC on the decomposition.Proof. Consider X1, Y 1 ∈ {1, 2}, X2, Y 2 ∈ {1, 3}, Y 3 ∈ {2, 3} and {} ⊆ S, T ⊆ {1, 2, 3}. Then Range([ X1, X2], {1, 2}, S) andRange([Y 1, Y 2, Y 3], {1, 2, 3}, T ) are HC, and S ∩ T = {} is BC. However, enforcing GAC on Disjoint([ X1, X2], [Y 1, Y 2, Y 3])prunes 3 from X2 and 1 from both Y 1 and Y 2. (cid:2)6.1.3. Number of valuesThe NValue constraint is useful in a wide range of problems involving resources since it counts the number of distinctvalues used by a sequence of variables [19,8,7]. As we saw in Section 3, NValue([ X1, .., Xn], N) holds iff N = |{ Xi | 1 (cid:2) i (cid:2) n}|.The AllDifferent constraint is a special case of the NValue constraint in which N = n. Unfortunately, it is NP-hard in generalto enforce GAC on a NValue constraint [11]. However, there is an O (n log(n)) algorithm to enforce a level of consistencysimilar to BC [3]. An alternative and even simpler way to implement this constraint is with a Range constraint:(cid:3)[ X1, .., Xn], NNValue(cid:3)[ X1, .., Xn], {1, .., n}, TRangeiff(cid:4)(cid:4)∧ |T | = NHC on this decomposition is incomparable to BC on the NValue constraint.Theorem 11. BC on NValue is incomparable to HC on the decomposition.Proof. Consider X1, X2 ∈ {1, 2}, X3 ∈ {1, 2, 3, 4}, N ∈ {3} and {} ⊆ T ⊆ {1, 2, 3, 4}. Then Range([ X1, X2, X3], {1, 2, 3}, T ) and|T | = N are both HC. However, enforcing BC on NValue([ X1, X2, X3], N) prunes 1 and 2 from X3.Consider X1, X2, X3 ∈ {1, 3} and N ∈ {3}. Then NValue([ X1, X2, X3], N) is BC. However, enforcing HC on Range([ X1, X2,X3], {1, 2, 3}, T ) makes {} ⊆ T ⊆ {1, 3} which will cause |T | = 3 to fail. (cid:2)6.1.4. UsesIn [5], propagation algorithms achieving GAC and BC are proposed for the UsedBy constraint. UsedBy([ X1, .., Xn], [Y 1, ..,Ym]) holds iff the multiset of values assigned to Y 1, .., Ym is a subset of the multiset of values assigned to X1, .., Xn. Wenow introduce a variant of the UsedBy constraint called the Uses constraint. Uses([ X1, .., Xn], [Y 1, .., Ym]) holds iff the setof values assigned to Y 1, .., Ym is a subset of the set of values assigned to X1, .., Xn. That is, UsedBy takes into account thenumber of times a value is used while Uses does not. Unlike the UsedBy constraint, enforcing GAC on Uses is NP-hard.Theorem 12. Enforcing GAC on Uses is NP-hard.Proof. We reduce 3-SAT to the problem of deciding if a Uses constraint has a solution. Finding support is therefore NP-hard. Consider a formula ϕ with n Boolean variables and m clauses. For each Boolean variable x, we introduce a variableXx ∈ {x, −x}. For each clause c j = x ∨ ¬ y ∨ z, we introduce Y j ∈ {x, − y, z}. Then ϕ has a model iff the Uses constraint has asatisfying assignment, and x is true iff Xx = x. (cid:2)One way to propagate a Uses constraint is to decompose it using Range constraints:(cid:4)Uses(cid:3)[ X1, .., Xn], [Y 1, .., Ym](cid:3)[ X1, .., Xn], {1, .., n}, TRange(cid:3)[Y 1, .., Ym], {1, .., m}, TRange(cid:4)(cid:9)iff∧(cid:4)∧ T(cid:9) ⊆ TEnforcing HC on this decomposition is polynomial. Not surprisingly, this hinders propagation (otherwise we would havea polynomial algorithm for a NP-hard problem).Theorem 13. GAC on Uses is stronger than HC on the decomposition.Proof. Consider X1 ∈ {1, 2, 3, 4}, X2 ∈ {1, 2, 3, 5}, X3, X4 ∈ {4, 5, 6}, Y 1 ∈ {1, 2}, Y 2 ∈ {1, 3}, and Y 3 ∈ {2, 3}. The decomposi-tion is HC while GAC on Uses prunes 4 from the domain of X1 and 5 from the domain of X2. (cid:2)Thus, decomposition is a simple method to obtain a polynomial propagation algorithm.6.2. Applications of Roots constraintRange constraints are often useful to specify constraints on the values used by a sequence of variables. Roots constraint,on the other hand, are useful to specify constraints on the variables taking particular values.1066C. Bessiere et al. / Artificial Intelligence 173 (2009) 1054–10786.2.1. Global cardinalityThe global cardinality constraint introduced in [23] constrains the number of times values are used. We considera generalisation in which the number of occurrences of a value may itself be an integer variable. More precisely,Gcc([ X1, .., Xn], [d1, .., dm], [O 1, .., O m]) holds iff |{i | Xi = d j}| = O j for allj. Such a Gcc constraint can be decomposedinto a set of Roots constraints:(cid:3)[ X1, .., Xn], [d1, .., dm], [O 1, .., O m]Gcc(cid:3)[ X1, .., Xn], S i, {di}∀i . Rootsiff∧ |S i| = O i(cid:4)(cid:4)Enforcing HC on these Roots constraints is polynomial since the sets {di} are ground (see Theorem 5). Enforcing GAC ona generalised Gcc constraint is NP-hard, but we can enforce GAC on the Xi and BC on the O j in polynomial time using aspecialised algorithm [21]. This is more than is achieved by the decomposition.Theorem 14. GAC on the Xi and BC on the O j of a Gcc constraint is stronger than HC on the decomposition using Roots constraints.Proof. As sets are represented by their bounds, HC on the decomposition cannot prune more on the O j than BC does onthe Gcc. To show strictness, consider X1, X2 ∈ {1, 2}, X3 ∈ {1, 2, 3}, di = i and O 1, O 2, O 3 ∈ {0, 1}. The decomposition is HC(with {} ⊆ S1, S2 ⊆ {1, 2, 3} and {} ⊆ S3 ⊆ {3}). However, enforcing GAC on the Xi and BC on the O j of the Gcc constraintwill prune 1 and 2 from X3 and 0 from O 1, O 2 and O 3. (cid:2)This illustrates another global constraint for which it is worth developing a specialised propagation algorithm.6.2.2. AmongThe Among constraint was introduced in CHIP to help model resource allocation problems like car sequencing [4]. Itcounts the number of variables using values from a given set. Among([ X1, .., Xn], [d1, .., dm], N) holds iff N = |{i | Xi ∈{d1, .., dm}}|.An alternative way to propagate the Among constraint is to decompose it using a Roots constraint:(cid:3)[ X1, .., Xn], [d1, .., dm], NAmong(cid:4)(cid:3)[ X1, .., Xn], S, {d1, .., dm}Roots(cid:4)iff∧ |S| = NIt is polynomial to enforce HC on this case of the Roots constraint since the target set is ground. This decompositionalso does not hinder propagation. It is therefore a potentially attractive method to implement the Among constraint.Theorem 15. GAC on Among is equivalent to HC on the decomposition using Roots.Proof. Suppose the decomposition into Roots([ X1, .., Xn], S, {d1, .., dm}) and |S| = N is HC. The variables Xi divide intothree categories: those whose domain only contains elements from {d1, .., dm} (at most min(N) such variables); those whosedomain do not contain any such elements (at most n − max(N) such vars); those whose domain contains both elementsfrom this set and from outside. Consider any value for a variable Xi in the first such category. To construct support for thisvalue, we assign the remaining variables in the first category with values from {d1, .., dm}. If the total number of assignedvalues is less than min(N), we assign a sufficient number of variables from the second category with values from {d1, .., dm}to bring up the count to min(N). We then assign all the remaining unassigned X j with values outside {d1, .., dm}. Finally,we assign min(N) to N. Support can be constructed for variables in the other two categories in a similar way, as well as forany value of N between min(N) and max(N). (cid:2)6.2.3. At most and at leastThe AtMost and AtLeast constraints are closely related. The AtMost constraint puts an upper bound on the number ofvariables using a particular value, whilst the AtLeast puts a lower bound. For instance, AtMost([ X1, .., Xn], d, N) holds iff|{i | Xi = d}| (cid:2) N. Both AtMost and AtLeast can be decomposed into Roots constraints. For example:(cid:3)[ X1, .., Xn], d, NAtMost(cid:4)(cid:3)[ X1, .., Xn], S, {d}Roots(cid:4)iff∧ |S| (cid:2) NAgain it is polynomial to enforce HC on these cases of the Roots constraint, and the decomposition does not hinder prop-agation. Decomposition is therefore also a potential method to implement the AtMost and AtLeast constraints in case wedo not have such constraints available in our constraint toolkit.Theorem 16. GAC on AtMost is equivalent to HC on the decomposition. Roots([ X1, .., Xn], S, {d}) and on |S| (cid:2) N.GAC on AtLeast is equivalent to HC on the decomposition. Roots([ X1, .., Xn], S, {d}) and on |S| (cid:3) N.Proof. The proof of the last theorem can be easily adapted to these two constraints. (cid:2)C. Bessiere et al. / Artificial Intelligence 173 (2009) 1054–107810676.3. Applications of Range and Roots constraintsSome global constraints need both Range and Roots constraints in their specifications.6.3.1. Assign and number of valuesIn bin packing and knapsack problems, we may wish to assign both a value and a bin to each item, andplace constraints on the values appearing in each bin. For instance,in the steel mill slab design problem (prob038in CSPLib), we assign colours and slabs to orders so that there are a limited number of colours on each slab.Assign&NValues([ X1, .., Xn], [Y 1, .., Yn], N) holds iff |{Y i | Xi = j}| (cid:2) N for each j [2]. We cannot expect to enforce GACon such a constraint as it is NP-hard to do so in general.Theorem 17. Enforcing GAC on Assign&NValues is NP-hard.Proof. Deciding if the constraint AtMostNValue has a solution is NP-complete, where AtMostNValue([Y 1, .., Yn], N) holdsiff |{Y i | 1 (cid:2) i (cid:2) n}| (cid:2) N [8,7]. The problem of the existence of a solution in this constraint is equivalent to the problemof the existence of a solution in Assign&NValues([ X1, .., Xn], [Y 1, .., Yn], N) where D( Xi) = {0}, ∀i ∈ 1..n. Deciding whetherAssign&NValues is thus NP-complete and enforcing GAC is NP-hard. (cid:2)Assign&NValues can be decomposed into a set of Range and Roots constraints:(cid:3)[ X1, .., Xn], [Y 1, .., Yn], NAssign&NValues(cid:4)(cid:3)[ X1, .., Xn], S j, { j}∀ j . Roots(cid:4)iff(cid:3)[Y 1, .., Yn], S j, T j∧ Range(cid:4)∧ |T j| (cid:2) NHowever, this decomposition hinders propagation.Theorem 18. GAC on Assign&NValues is stronger than HC on the decomposition.Proof. Consider N = 1, X1, X2 ∈ {0}, Y 1 ∈ {1, 2}, Y 2 ∈ {2, 3}. HC on the decomposition enforces S0 = {1, 2} and {} ⊆ T 0 ⊆{1, 2, 3} but no pruning on the Xi and Y j . However, enforcing GAC on Assign&NValues([ X1, X2], [Y 1, Y 2], N) prunes 1 fromY 1 and 3 from Y 2. (cid:2)6.3.2. CommonA generalisation of the Among and AllDifferent constraints introduced in [2] is the Common constraint. Common(N, M,[ X1, .., Xn], [Y 1, .., Ym]) ensures N = |{i | ∃ j, Xi = Y j}| and M = |{ j | ∃i, Xi = Y j}|. That is, N variables in Xi take values incommon with Y j and M variables in Y j takes values in common with Xi . We prove that we cannot expect to enforce GACon such a constraint as it is NP-hard to do so in general.Theorem 19. Enforcing GAC on Common is NP-hard.Proof. We again use a transformation from 3-SAT. Consider a formula ϕ with n Boolean variables and m clauses. For eachBoolean variable i, we introduce a variable Xi ∈ {i, −i}. For each clause c j = x ∨ ¬ y ∨ z, we introduce Y j ∈ {x, − y, z}. We letN ∈ {0, .., n} and M = m. ϕ has a model iff the Common constraint has a solution in which the Xi take the literals true inthis model. (cid:2)One way to propagate a Common constraint is to decompose it into Range and Roots constraints:(cid:4)iff(cid:3)CommonN, M, [ X1, .., Xn], [Y 1, .., Ym](cid:4)∧(cid:3)[Y 1, .., Ym], {1, .., m}, TRange(cid:3)[ X1, .., Xn], S, TRoots(cid:3)[ X1, .., Xn], {1, .., n}, VRange(cid:3)[Y 1, .., Ym], U , VRoots(cid:4)(cid:4)∧ |S| = N ∧(cid:4)∧∧ |U | = MEnforcing HC on this decomposition is polynomial. Decomposition thus offers a simple method to propagate a Commonconstraint. Not surprisingly, the decomposition hinders propagation.Theorem 20. GAC on Common is stronger than HC on the decomposition.Proof. Consider N = M = 0, X1, Y 1 ∈ {1, 2}, X2, Y 2 ∈ {1, 3}, Y 3 ∈ {2, 3}. Hybrid consistency on the decomposition enforces{} ⊆ T , V ⊆ {1, 2, 3}, and S = U = {} but no pruning on the Xi and Y j . However, enforcing GAC on Common(N, M, [ X1, X2],[Y 1, Y 2, Y 3]) prunes 2 from X1, 3 from X2 and 1 from both Y 1 and Y 2. (cid:2)1068C. Bessiere et al. / Artificial Intelligence 173 (2009) 1054–10786.3.3. Symmetric all differentIn certain domains, we may need to find symmetric solutions. For example, in sports scheduling problems, if one teamis assigned to play another then the second team should also be assigned to play the first. SymAllDiff([ X1, .., Xn]) ensuresXi = j iff X j = i [24]. It can be decomposed into a set of Range and Roots constraints:(cid:3)[ X1, .., Xn](cid:4)SymAllDiff(cid:3)[ X1, .., Xn], {1, .., n}, {1, .., n}Range(cid:3)∀i . Roots[ X1, .., Xn], S i, {i}iff(cid:4)(cid:4)∧∧ Xi ∈ S i ∧ |S i| = 1It is polynomial to enforce HC on these cases of the Roots constraint. However, as with the AllDifferent constraint, itis more effective to use a specialised propagation algorithm like that in [24].Theorem 21. GAC on SymAllDiff is stronger than HC on the decomposition.Proof. Consider X1 ∈ {2, 3}, X2 ∈ {1, 3}, X3 ∈ {1, 2}, {} ⊆ S1 ⊆ {2, 3}, {} ⊆ S2 ⊆ {1, 3}, and {} ⊆ S3 ⊆ {1, 2}. Then the decom-position is HC. However, enforcing GAC on SymAllDiff([ X1, X2, X3]) will detect unsatisfiability. (cid:2)To our knowledge, this constraint has not been integrated into any constraint solver. Thus, this decomposition providesa means of propagation for the SymAllDiff constraint.6.3.4. UsesIn Section 6.1.4, we decomposed the constraint Uses with Range constraints. Another way to propagate a Uses constraintis to decompose it using both Range and Roots constraints:(cid:4)Uses(cid:3)[ X1, .., Xn], [Y 1, .., Ym](cid:3)[ X1, .., Xn], {1, .., n}, TRange(cid:3)[Y 1, .., Ym], {1, .., m}, TRoots(cid:4)(cid:4)iff∧Enforcing HC on this decomposition is polynomial. Again, such a decomposition hinders propagation as achieving GACon a Uses constraint is NP-Hard. Interestingly, the decomposition of Uses using Range constraints presented in Section 6.1.4and the decomposition presented here are equivalent.Theorem 22. HC on the decomposition of Uses using only Range constraints is equivalent to HC on the decomposition using Rangeand Roots constraints.Proof. We just need to show that HC on Roots([Y 1, .., Ym], {1, .., m}, T ) is equivalent to HC on Range([Y 1, .., Ym], {1, .., m},(cid:9) ⊆ T . Since, the Range and the Roots constraints are over the same set of variables ([Y 1, .., Ym]) and the same set(cid:9)) ∧ TTof indices ({1, .., m}) is fixed for both, then it follows that set variable Tmaintained by Range is a subset of T maintainedby Roots. (cid:2)(cid:9)6.4. Open constraintsOpen global constraints have recently been introduced. They are a new kind of global constraints for which the setof variables involved is not fixed. Range and Roots constraints are particularly useful to specify many such open globalconstraints.The Gcc constraint has been extended to OpenGcc, a Gcc constraint for which the set of variables involved is not knownin advance [31]. Given variables X1, .., Xn and a set variable S, ∅ ⊆ S ⊆ {1..n}, OpenGcc([ X1, .., Xn], S, [d1, .., dm], [O 1, .., O m])holds iff |{i ∈ S | Xi = d j}| = O j for allj. OpenGcc can be decomposed into a set of Roots constraints in almost the sameway as Gcc was decomposed in Section 6.2.1:S =(cid:3)[ X1, .., Xn], S, [d1, .., dm], [O 1, .., O m]OpenGcc(cid:9)S i ∧i∈1..m(cid:3)[ X1, .., Xn], S i, {di}∀i . Roots∧ |S i| = O i(cid:4)(cid:4)iffPropagators for such an open constraint have not yet been included in constraint solvers. In [31], a propagator is proposedfor the case where O i ’s are ground intervals. In the decomposition above, the O i ’s can either be variables or groundintervals. However, even when O i ’s are ground intervals, both the decomposition and the propagator presented in [31]hinder propagation and are incomparable to each other.C. Bessiere et al. / Artificial Intelligence 173 (2009) 1054–10781069Theorem 23. Even if O i ’s are ground intervals, (1) HC on the OpenGcc constraint is stronger than HC on the decomposition usingRoots constraints, (2) the propagator in [31] and HC on the decomposition using Roots constraints are incomparable.Proof. (1) Consider X1, X2 ∈ {1, 2}, X3 ∈ {1, 2, 3}, di = i, S = {1, 2, 3} and O 1, O 2, O 3 = [0, 1]. The decomposition is HC (with{} ⊆ S1, S2 ⊆ {1, 2, 3} and {} ⊆ S3 ⊆ {3}). However, enforcing HC on the OpenGcc constraint will prune 1 and 2 from X3.(2) Consider the example in case (1). The propagator in [31] will prune 1 and 2 from X3 whereas the decompositionis HC. Consider X1 ∈ {1, 2}, X2 ∈ {2, 3}, X3 ∈ {3, 4}, di = i, {} ⊆ S ⊆ {1, 2, 3} and O 1 = [1, 1], O 2 = [0, 1], O 3 = [0, 0], O 4 =[0, 0]. The propagator in [31] will prune the only value in the Xi variables which is not HC, that is, value 2 for X1. It will notprune the bounds on S. However, enforcing HC on the decomposition using Roots constraints will set S 1 = {1}, then willprune value 2 for X1, will shrink S2 to {} ⊆ S2 ⊆ {2}, will set S3 = S4 = {} and will finally shrink S to {1} ⊆ S ⊆ {1, 2}. (cid:2)As observed in [31], the definition of OpenGcc subsumes the definition for the open version of the AllDifferentconstraint. Given variables X1, .., Xn and a set variable S, ∅ ⊆ S ⊆ {1..n}, OpenAllDifferent([ X1, .., Xn], S) holds iff Xi (cid:11)=X j, ∀i, j ∈ S. Interestingly, this constraint can be decomposed using Range in almost the same way as AllDifferent wasdecomposed in Section 6.1.1.(cid:3)[ X1, .., Xn], SOpenAllDifferent(cid:4)iff(cid:3)[ X1, .., Xn], S, TRange(cid:4)∧ |S| = |T |Not surprisingly, this decomposition hinders propagation (see the example used in Theorem 8 to show that the decom-position of AllDifferent using Range hinders propagation). Nevertheless, as in the case of OpenGcc, we do not know ofany polynomial algorithm for achieving HC on OpenAllDifferent.6.5. Applications beyond counting and occurrence constraintsThe Range and Roots constraints are useful for specifying a wide range of counting and occurrence constraints. Never-theless, their expressive power permits their use to specify many other constraints.6.5.1. ElementThe Element constraint introduced in [28] indexes into an array with a variable. More precisely, Element(I, [ X1, .., Xn], J )holds iff X I = J . For example, we can use such a constraint to look up the price of a component included in a configurationproblem. The Element constraint can be decomposed into a Range constraint without hindering propagation:(cid:3)ElementI, [ X1, .., Xn], Jiff(cid:3)[ X1, .., Xn], S, TI ∈ S ∧ J ∈ T ∧ Range|S| = |T | = 1 ∧(cid:4)(cid:4)Theorem 24. GAC on Element is equivalent to HC on the decomposition.Proof. S has all the values in the domain of I in its upper bound. Similarly T has all the values in the domain of J in itsupper bound. In addition, S and T are forced to take a single value. Thus enforcing HC on Range([ X1, .., Xn], S, T ) has thesame effect as enforcing GAC on Element(I, [ X1, .., Xn], J ). (cid:2)6.5.2. Global contiguityThe Contiguity constraint ensures that, in a sequence of 0/1 variables, those taking the value 1 appear contiguously. Thisis a discrete form of convexity. The constraint was introduced in [18] to model a hardware configuration problem. It can bedecomposed into a Roots constraint:(cid:3)[ X1, .., Xn]Contiguity(cid:3)[ X1, .., Xn], S, {1}Rootsiff∧(cid:4)(cid:4)X = max(S) ∧ Y = min(S) ∧ |S| = X − Y + 1Again it is polynomial to enforce HC on this case of the Roots constraint. Unfortunately, decomposition hinders propagation.Whilst Range and Roots can specify concepts quite distant from counting and occurrences like convexity, it seems that wemay need other algorithmic ideas to propagate them effectively.Theorem 25. GAC on Contiguity is stronger than HC on the decomposition.Proof. Consider X1, X3 ∈ {0, 1}, X2, X4 ∈ {1}. Hybrid consistency on the decomposition will enforce {2, 4} ⊆ S ⊆ {1, 2, 3, 4},X ∈ {4}, Y ∈ {1, 2} and |S| to be in {3, 4} but no pruning will happen. However, enforcing GAC on Contiguity([ X1, .., Xn])will prune 0 from X3. (cid:2)1070C. Bessiere et al. / Artificial Intelligence 173 (2009) 1054–10787. Experimental resultsWe now experimentally assess the value of using the Range and Roots constraints in specifying global counting andoccurrence constraints. For these experiments, performed with the Ilog Solver toolkit [16], we implemented an algo-rithm achieving HC on Range and an algorithm achieving HC on the decomposition of Roots presented in Section 5.2.Note that our algorithm for the decomposition of Roots does not use the Ilog Solver primitives member(value, set) andnotmember(value, set) because Ilog Solver does not appear to give complete propagation on combinations of such primi-tives (see the discussion in Section 5.5). We therefore implemented our own algorithms from scratch.7.1. Pruning power of RootsIn Section 5.2 we proposed a decomposition of the Roots constraint into simple implications. The purpose of this sub-section is to measure the pruning power of HC on the decomposition of Roots with respect to HC on the original Rootsconstraint when we do not meet any of the conditions that make HC on the decomposition equivalent to HC on the originalconstraint (see Section 5.3). We should bear in mind that enforcing HC on the Roots constraint is NP-hard in general. Inorder to enforce HC on the Roots constraint we used a simple table constraint (i.e., a constraint in extension) that has anexponential time and space complexity. Consequently, the size of the instances on which we were able to run this filteringmethod was severely constrained.An instance is a set of integer variables { X1, .., Xn} and two set variables S and T . It can be described by a tuple(cid:19)n, m, k, r(cid:20). The parameter n stands for the number of integer variables. These n variables are initialised with the domain{1, . . . , m}. The upper bound of S is initialised with {1, . . . , n} and the upper bound of T is initialised with {1, . . . , m}.The parameter k corresponds to the number of elements of the set variable S (resp. set variable T ) that are, with equalprobability, either put in the lower bound or excluded from the upper bound of S (resp. of T ). Finally, the parameter r isthe total number of values removed, with uniform probabilities from the domains of the integer variables, keeping at leastone value per domain. We generated 1000 random instances for each combination of n, m ∈ [4, ..6], k ∈ [1.. min(n, m)] andr ∈ [1..n(m − 1)].For each one of the instances we generated, we propagated Roots([ X1, .., Xn], S, T ) using either the table constraint(enforcing HC), or our decomposition (enforcing HC in special cases). We observed that on 29 out of the 32 combinationsof the parameters n, m and k, the decomposition achieves HC for all 1000 instances of every value of r. On the remainingthree classes ((cid:19)4, 6, 3, ∗(cid:20), (cid:19)5, 6, 3, ∗(cid:20) and (cid:19)6, 6, 3, ∗(cid:20)), the decomposition fails to detect 0.003% of the inconsistent values.As a second experiment, we used the same instances expect that we did not fix or remove k values randomly from T ,that is, in all instances, lb(T ) = ∅ and ub(T ) = {1, . . . , m}. All other settings remained equal. By doing so, we allowed therandom domains to reach situations equivalent to that of the counter example given in the proof of Theorem 4. With thissetting, we observed that the decomposition still achieves HC on 18 out of the 32 combinations of the parameters n, m andk, for all 1000 instances of every value of r. On the remaining classes, the percentage of inconsistent values not pruned bythe decomposition increases to 0.039%.Clearly, this experiment is limited in its scope, first by the relatively small size of the instances, and second by the choicesmade for generating random domains. However, we conclude that examples of inconsistent values not being detected bythe decomposition appear to be rare.7.2. Pruning power and efficiency of RangeContrary to the Roots constraint, we have a complete HC propagator for the Range constraint. Thus, we do not needto assess the pruning power of our propagator. Nevertheless, it can be interesting to compare the pruning power and theefficiency of decomposing a global constraint using Range or using another decomposition with simpler constraints.The purpose of this subsection is to compare the decomposition of Uses using Range constraints against a simple de-composition using more elementary constraints. We chose the Uses constraint because it is NP-hard to achieve GAC on theUses constraint (see Section 6.1.4) and there is no propagator available for this constraint in the literature. Furthermore, oneof the time-tabling problems at the University of Montpellier can easily be modelled as a CSP with Uses constraints. Wefirst compare the two decompositions of Uses (with or without Range) in terms of run-time as well as pruning power onrandom CSPs. Then, we solve the problem of building the set of courses in the Master of Computer Science at the Universityof Montpellier with the two decompositions.7.2.1. Random CSPsIn order to isolate the effect of the Range constraint from other modelling issues, we used the following protocol: werandomly generated instances of binary CSPs and we added Uses([ X1, .., Xn], [Y 1, .., Yn]) constraints. In all our experiments,we encode Uses in two different ways:[range]: by decomposing Uses using Range as described in Section 6.1.4,[decomp]: by decomposing the Uses constraint using primitive constraints as described next.Uses(cid:3)[ X1, .., Xn], [Y 1, .., Yn](cid:4)iffC. Bessiere et al. / Artificial Intelligence 173 (2009) 1054–10781071i ∈ S → Xi ∈ T ∧ j ∈ T → ∃i ∈ S. Xi = j ∧(cid:9) ∧ j ∈ Ti ∈ S(cid:9) → ∃i ∈ S(cid:9).Y i = j ∧(cid:9) → Y i ∈ T(cid:9)T ⊆ TThe problem instances are generated according to model B in [20], and can be described with the following parameters:the number of X and Y variables nx and ny in Uses constraints, the total number of variables nz, the domain size d, thenumber of binary constraint m1, the number of forbidden tuples t per binary constraint, and the number of Uses constraintsm2. Note that the Uses constraints can have overlapping or disjoint scopes of variables. We distinguish the two cases. Allreported results are averages on 1000 instances.Our first experiment studies the effectiveness of decomposing Uses with Range for propagation alone (not solving). Wecompared the number of values removed by propagation on the models obtained by representing Uses constraints in twodifferent ways, either using Range (range) or using the simple decomposition (decomp). To simulate what happens insidea backtrack search, we repeatedly and randomly choose a variable, assign it to one of its values and propagate the setof random binary constraints. After doing so for a given number of variables, if the CSP is still consistent, we enforce HCon each one of the two decompositions above. Hence, in the experiments, the constraints are exposed to a wide range ofdifferent variable domains. We report the ratio of values removed by propagation on the following classes of problems:class A:class B:(cid:19)nx = 5, ny = 10, nz = 35, d = 20, m1 = 70, t = 150, m2 = 3 (overlap)(cid:20)(cid:19)nx = 5, ny = 10, nz = 45, d = 20, m1 = 90, t = 150, m2 = 3 (disjoint)(cid:20)in which the number of assigned variables varies between 1 and 14. A failure detected by the propagation algorithm yieldsa ratio of 1 (all values are removed).We observe in Figs. 4 and 5 that propagating the Uses constraint using the Range constraint (range model) is muchmore effective than propagating it using the decomposition using elementary constraints (decomp model). In certain cases,the range model more than doubles the amount of values pruned. For instance after 7 random assignments the decompmodel prunes only 28.8% of the values for the first problem class (Fig. 4) and 4.4% for the second (Fig. 5) whilst the Rangealgorithm respectively prunes 56% and 10.2% of the values. As we see in the next experiments, such a difference in pruningcan map to considerable savings when solving a problem.Our second experiment studies the efficiency of decomposing Uses with Range when solving the problems. Our solverused the smallest-domain-first variable ordering heuristic with the lexicographical value ordering and a cut-off at 600 sec-onds. We compared the cost of solving the two types of models: range and decomp. We report the number of fails andthe cpu-time needed to find the first solution on the following classes of problems:class C:class D:(cid:19)nx = 5, ny = 10, nz = 25, d = 10, m1 = 40, t, m2 = 2(cid:20)(cid:19)nx = 5, ny = 10, nz = 30, d = 10, m1 = 60, t, m2 = 2(cid:20)in which t varies between 30 and 80.We observe in Figs. 6 and 7 that using the decomposition using the elementary constraints (decomp model) is notefficient (note the log scale). The instances solved here (classes C and D) are much smaller than those used for propaga-tion (classes A and B). Solving larger instances was impractical. This second experiment shows that Range can reasonablyFig. 4. Propagating random binary constraint satisfaction problems with three overlapping Uses constraints (class A).1072C. Bessiere et al. / Artificial Intelligence 173 (2009) 1054–1078Fig. 5. Propagating random binary constraint satisfaction problems with three disjoint Uses constraints (class B).solve problems containing Uses constraints. It also shows the clear benefit of using our algorithm in preference to thedecomposition using elementary constraints over the under-constrained region. As the problems get over-constrained, thebinary constraints dominate the pruning, and the algorithm has a slight overhead in run-time, pruning the same as thedecomposition using elementary constraints.7.2.2. Problem of the courses in the master of computer scienceTo confirm the results obtained on several types of random instances, we tackle the problem of deciding which courses torun in the Master of Computer Science at the University of Montpellier. This problem, which is usually solved by hand withthe help of an Excel program, can be specified as follows. The second year of the Master of Computer Science advertises aset C of possible courses. There is a set L of n lecturers who have skills to teach some subset of the courses (between 1 and9 per lecturer). There is a set S of m students who bid for which courses they would like to attend (between 6 and 10 bidsper student). A course runs only if at least 5 students bid for it. Every lecturer participates in just one course, but severallecturers can be assigned to the same course. There is also a set P ⊆ L of professors who are in charge of the course inwhich they participate. The goal is to run enough courses so that all lecturers are assigned to one course and all studentscan attend at least one of the courses for which they bid.The models we used have variables Li representing which course is taught by lecturer i and variables S j representingone of the courses student j wants to attend. D(Li) contains all courses lecturer i can teach except those that receivedless than 5 bids. D(S j) contains all courses student j has bid for, except those that received less than 5 bids. We put aconstraint Uses([L1, . . . , Ln], [S1, . . . , Sm]) and a constraint AllDifferent(Li1 , . . . , Li p ) where {Li1 , . . . , Li p} = P . Model rangedecomposes Uses with Range, and model decomp decomposes Uses with primitive constraints as described in Section 7.2.1.In the only instance we could obtain from the university, year-2008, there are 50 lecturers, 26 professors, 53 courses, and177 students. We solved year-2008, both with model decomp and with model range. Both models could find a solutionin a few milliseconds.We modified the two models so that the satisfaction of the students is improved. Instead of trying to satisfy onlyone of their choices, we try now to satisfy k choices. The models are modified in the following way. We create kcopies of each variable S j , that is, S 1j) containing the same values as D(S j) (see above). Wej , . . . , Skpost constraints S 1j all take different values.Then, instead of having a single Uses constraint, we have k Uses constraints, one on each set S i2, . . . , S im of vari-ables: Uses([L1, . . . , Ln], [S 1]). Model range-k decomposes Uses with Range,]), . . . , Uses([L1, . . . , Ln], [Skand model decomp-k decomposes Uses with primitive constraints as described in Section 7.2.1.j that break symmetries and guarantee that S 1j < · · · < Skj , with D(S i1, . . . , S 11, . . . , Skj , . . . , Skj < S 2j , S 2j , S 21, S iWe solved instance year-2008 with k = 2, 3, 4, 5. When k = 2 or k = 3, both models find a solution in a few milliseconds,decomp-k being slightly faster than range-k. range-4 finds a solution in 4 fails and 5.83 sec. whereas decomp-4 wasstopped after 24 hours without finding any solution. range-5 and decomp-5 were stopped after 24 hours without findingany solution or proving that none exists. This experiment shows that it can be effective to solve a real-world problemcontaining a global constraint like Uses by specifying it with Range instead of using a decomposition with elementaryconstraints.mm7.3. Solving problems using Range and RootsIn Section 7.2.2, we showed how decomposing a global constraint with Range can be useful to solve a real-world prob-lem. In this subsection we study another real-world problem that involves a greater variety of global constraints, someC. Bessiere et al. / Artificial Intelligence 173 (2009) 1054–10781073Fig. 6. Solving random binary constraint satisfaction problems with two overlapping Uses constraints (class C).allowing decompositions with Range, some others with Roots. More importantly, we will compare monolithic propagatorsof existing well-known global constraints with their decompositions using Range and Roots. The purpose of this subsectionis to see if solving real-world constraint problems using Range and Roots leads to acceptable performance compared tospecialised global constraints and their propagators.We used a model for the Mystery Shopper problem [14] due to Helmut Simonis that appears in CSPLib (prob004).We used the same problem instances as in [10] but perform a more thorough and extensive analysis. We partition theconstraints of this problem into three groups:Temporal and geographical: All visits for any week are made by different shoppers. Similarly, a particular area cannot bevisited more than once by the same shopper.Shopper: Each shopper makes exactly the required number of visits.Saleslady: A saleslady must be visited by some shoppers from at least 2 different groups (the shoppers are partitioned intogroups).The first group of constraints can be modelled by using AllDifferent constraints [22], the second can be modelled byGcc [23] and the third by Among constraints [4]. We experimented with several models using Ilog Solver where theseconstraints are either implemented as their Ilog Solver primitives (respectively, IloAllDiff, IloDistribute, and adecomposition using IloSum on Boolean variables) or as their decompositions with Range and Roots. The decompositionof Among([ X1, .., Xn], [d1, .., dm], N) we use is the one presented in [6], that is, (B i = 1 ↔ Xi ∈ [d1, .., dm]), ∀i ∈ 1..n ∧(cid:10)i B i = N. Note that this decomposition of the Among constraint maintains GAC in theory [6]. This decomposition canbe implemented in many solvers using disjunctions of membership constraints: or(notmember( Xi, [d1, .., dm]), B i = 1)and or(member( Xi, [d1, .., dm]), B i = 0). Unfortunately, Ilog Solver does not appear to achieve GAC on such disjunctions ofprimitives because the negated membership constraint notmember( Xi, [d1, .., dm]) is activated only if Xi is instantiatedwith a value in [d1, .., dm] whereas it should be as soon as D( Xi) ⊆ [d1, .., dm].1074C. Bessiere et al. / Artificial Intelligence 173 (2009) 1054–1078Fig. 7. Solving random binary constraint satisfaction problems with two disjoint Uses constraints (class D).We report results for the following representative models:• Alld-Gcc-Sum uses only Ilog Solver primitives;• Alld-Gcc-Roots where Among is encoded using Roots;• Alld-Roots-Sum where Gcc is encoded using Roots;• Range-Gcc-Sum where AllDifferent is encoded using Range;• Alld-Roots-Roots where Among and Gcc are encoded using Roots.Note that Among encoded as Roots uses the decomposition presented in Section 6.2.2, the Gcc uses the decompositionpresented in Section 6.2.1, and AllDifferent uses the decomposition presented in Section 6.1.1.We study the following important questions:• How does the Roots decomposition of the Among constraint compare to the Sum decomposition in terms of pruningand run-times?• Does the decomposition of Gcc using Roots lead to a reasonable and acceptable loss in performance?• Does the decomposition of AllDifferent using Range lead to a reasonable and acceptable loss in performance?• Do we gain in performance by branching on the set variables introduced by the Roots decomposition?To answer the first question, we will compare the model Alld-Gcc-Sum against the model Alld-Gcc-Roots. To answerthe second question, we will compare the model Alld-Gcc-Sum against the model Alld-Roots-Sum. To answer the thirdquestion, we will compare the model Alld-Gcc-Sum against the model Range-Gcc-Sum. To answer the fourth question,we will compare Alld-Gcc-Sum against the model Alld-Roots-Roots that branches on the set variables.The instances we use in the experiments are generated as follows. For each number of salesladies s ∈ {10, 15, 20, 25,30, 35}, we generate (cid:21)(s + 2/4) ∗ 4(cid:22) shoppers, 4 visits. Furthermore, to determine the partitioning of the outlets, we boundthe number of salesladies per outlet between a lower bound and an upper bound and generate all possible partitions withinC. Bessiere et al. / Artificial Intelligence 173 (2009) 1054–10781075Table 1The sum decomposition of Among in the Mystery Shopper problem versus the Roots decomposition using lex as a branching strategy.Sizealld-gcc-sum-lex#solvedtime (sec.)1015202530359292516631by selfby all0.010.070.020.030.050.230.010.070.020.030.050.23#failsby self0.89431.5510.607.0650.00414.68by all0.89431.5510.607.0650.00414.68alld-gcc-roots-lex#solvedtime (sec.)by selfby all92925166310.010.070.020.040.070.240.010.070.020.040.070.24Table 2The Gcc constraints in the Mystery Shopper problem versus the Roots decomposition using lex as a branching strategy.Sizealld-gcc-sum-lex#solvedtime (sec.)1015202530359292516631by selfby all0.010.070.020.030.050.230.010.070.020.030.050.27#failsby self0.89431.5510.607.0650.00414.68by all0.89431.5510.607.0650.00505.48alld-gcc-roots-lex#solvedtime (sec.)by selfby all92925166230.010.430.100.230.433.890.010.430.100.230.433.89#failsby self0.89281.909.487.0049.67269.32#failsby self1.78434.3810.6038.3172.33521.74by all0.89281.909.487.0049.67269.32by all1.78434.3810.6038.3172.33521.74these bounds. The number of instances for each class is as follows; for 10 salesladies we have 10 instances, for 15 salesladieswe have 52 instances, for 20 salesladies we have 35 instances, for 25 salesladies we have 20 instances, for 30 salesladies wehave 10 instances, and for 35 salesladies we have 56 instances.We also tested two variable and value ordering heuristics:• We branch on the variables with the minimum domain first and assign values lexicographically. We refer to this asdom;• We assign a shopper to each saleslady for the first, then for the second week and so on. This a static variables andvalue ordering heuristic. We refer to this as lex.However, since lex was consistently better than dom we only report the results using lex.All instances solved in the experiments use a time limit of 5 minutes. For each class of instances we report the numberof instances solved (#solved), the average cpu-time in seconds over all instances solved by the method (by self), the averagecpu-time in seconds over all instances solved by both methods (by all), the average number of failures over all instancessolved by the method (by self), the average number of failures over all instances solved by both methods (by all).7.3.1. AmongWhen branching on the integer variables using lex (Table 1) strategy, the Alld-Gcc-Roots model tends to perform betterthan the Alld-Gcc-Sum model in terms of pruning (smaller number of fails). Note that the Sum decomposition missessome pruning because of the Ilog Solver propagators used in this decomposition, as explained at the beginning of Section 7.3.This explains the discrepancy. Both models solve the same number of instances. The results show that in this case of theAmong constraint, our Roots decomposition is as efficient as the decomposition using elementary Sum constraints. Minorrun-time differences are probably due to the cheaper propagator of Ilog Solver which achieves less pruning.7.3.2. GccThe Gcc constraint is one of the most efficient and effective global constraints available in most constraint toolkits.The results comparing the Alld-Gcc-Sum model versus its equivalent (the Alld-Roots-Sum model) where instead of Gccconstraints we use our decomposition using Roots are shown in Table 2. We observe that when branching on the integervariables using lex, the loss in terms of pruning due to our decomposition is very low: the difference in number of failsis less than 5% on the hardest instances. This means that our decomposition should scale well when size and difficulty ofproblems increases. The difference in run-times is larger (up to more than one order of magnitude). This can be explainedin part by the propagation algorithms for Range and Roots that we have implemented in Ilog Solver. They are far frombeing optimised, as opposed to the highly specialised native Gcc propagator. Overall, the loss appears to be acceptable.Our results show that, for the Gcc constraint, the decomposition into Roots leads to adequate performance for prototyping.Nevertheless, providing more efficient propagators for Roots is an interesting and open issue.1076C. Bessiere et al. / Artificial Intelligence 173 (2009) 1054–1078Table 3The AllDifferent constraints in the Mystery Shopper problem versus the Range decomposition using lex as a branching strategy.Sizealld-gcc-sum-lex#solvedtime (sec.)1015202530359292516631by selfby all0.010.070.020.030.050.230.010.070.020.030.050.23#failsby self0.89431.5510.607.0650.00414.68by all0.89431.5510.607.0650.00414.68alld-gcc-roots-lex#solvedtime (sec.)by selfby all92925166310.020.180.170.320.571.390.020.180.170.320.571.39Table 4Branching on set variables in the Mystery Shoppers problem.Sizealld-gcc-sum-lex#solvedtime (sec.)by selfby all0.010.070.020.030.050.230.010.070.020.030.050.2310152025303592925166317.3.3. Alldifferent#failsby self0.89431.5510.607.0650.00414.68alld-gcc-roots-lex#solvedtime (sec.)by all0.89431.5510.607.0650.00412.24105235201051by self0.050.121.305.0815.0533.88by all0.050.051.255.123.6535.86#failsby self0.89431.5510.607.0650.00414.68#failsby self98.20102.83852.142218.004476.406111.67by all0.89431.5510.607.0650.00414.68by all91.3323.34794.202170.121675.336410.14The AllDifferent constraint is again one of the most efficient and effective global constraints available in most constrainttoolkits. The results comparing the Alld-Gcc-Sum model versus its equivalent (the Range-Gcc-Sum model) where insteadof AllDifferent constraints we use our decomposition using Range are shown in Table 3. We observe that when branchingon the integer variables using lex both methods achieve the same amount of pruning even if we are not in a case whereAllDifferent constraints are Permutation constraints (see Section 6.1.1). This means that even when our decompositionusing Range theoretically hinders propagation, it can in practice achieve GAC. Concerning run-time efficiency, we observethat both methods solve the same number of instances. This is probably a consequence of the good level of pruning achievedby the decomposition of AllDifferent using Range. But the Alld-Gcc-Sum model is usually faster, up to one order ofmagnitude in the extreme case. Again, this can be explained in part by our basic implementation of the Range and Rootspropagators in Ilog Solver, as opposed to the highly specialised native AllDifferent propagator.7.3.4. Exploiting the set variablesIn the previous subsections, we have seen that decomposing global constraints with Range and Roots constraints is aviable approach. Such decompositions generally give very small (if any) loss in terms of pruning and they give acceptablerun-time performance. However, we have seen that our basic decomposition using Roots can be slow compared to highlyspecialised propagators such as those used by Ilog Solver for the Gcc constraint. In this subsection, we show that, evenwithout optimising our code, we can improve the run-time performance of our decomposition just by exploiting its internalstructure through the extra variables it introduces.The decomposition of global constraints using Range and Roots introduces extra set variables. We here explore thepossibility of branching on the set variables as follows. We branch on the set variables first, then on the integer variableswith min domain once all set variables are instantiated. We refer to this as set. We compare the best model that uses theavailable constraints in Ilog Solver (model Alld-Gcc-Sum) versus the best model that branches on the set variables (modelAlld-Roots-Roots, in which the Among and the Gcc constraints are expressed using the Roots constraint). Surprisingly,we solve significantly more instances when branching on the set variables than the model Alld-Gcc-Sum. But, again,Alld-Gcc-Sum is a more efficient model when it manages to solve the instance.These results are primarily due to the better branching strategy. However, such a strategy would not be easily imple-mentable without Roots since the extra set variables are part of it. We observe here that the extra set variables introducedby the Roots decomposition may provide new possibilities for branching strategies that might be beneficial in practice.These results show that by simply changing the branching strategy so that it exploits the internal structure of thedecompositions, we obtain a significant increase in performance. This gain compensates the loss in cpu-time caused by thepreliminary nature of our implementation.8. ConclusionWe have proposed two global constraints useful in specifying many counting and occurrence constraints: the Rangeconstraint which computes the range of values used by a set of variables, and the Roots constraint which computes theC. Bessiere et al. / Artificial Intelligence 173 (2009) 1054–10781077variables in a set mapping onto particular values. These two constraints capture the notion of image and domain of afunction, making them easy to understand to the non-expert in constraint programming. We have shown that these twoconstraints can easily specify counting and occurrence constraints. For example, the open versions of some well-knownglobal constraints can be specified with Range and Roots. Beyond counting and occurrence constraints, we have shown thatthe expressive power of Range and Roots allows them to specify many other constraints.We have proposed propagation algorithms for these two constraints. Hence, any global constraint specified using Rangeand Roots can be propagated. In some cases, this gives a propagation algorithm which achieves GAC on the original globalconstraint (e.g. the Permutation and Among constraints). In other cases, this propagation algorithm may not make theoriginal constraint GAC, but achieving GAC is NP-hard (e.g. the NValue and Common constraints). Decomposition is then onemethod to obtain a polynomial algorithm. In the remaining cases, the propagation algorithm may not make the constraintGAC, although specialised propagation algorithms can do so in polynomial time (e.g. the SymAllDiff constraint). Our methodcan still be attractive in this last case as it provides a generic means of propagation for counting and occurrence constraintswhen specialised algorithms have not yet been proposed or are not available in the constraint toolkit.We have presented a comprehensive study of the Range constraint. We proposed an algorithm for enforcing hybrid con-sistency on Range. We also have presented a comprehensive study of the Roots constraint. We proved that propagatingcompletely the Roots constraint is intractable in general. We therefore proposed a decomposition to propagate it partially.This decomposition achieves hybrid consistency on the Roots constraint under some simple conditions often met in prac-tice. In addition, enforcing bound consistency on the decomposition achieves bound consistency on the Roots constraintwhatever conditions hold.Our experiments show the benefit we can obtain by incorporating the Range and the Roots constraints in a constrainttoolkit. First, despite being intractable, the Roots constraint can be propagated using the decomposition we presented. Evenif this decomposition hinders propagation in theory, our experiments show that it is seldom the case in practice. Second,in the absence of specialised propagation algorithms, Range and Roots appear to be a simple and a reasonable methodfor propagating (possibly intractable) global constraints that is competitive to other decompositions into more elementaryconstraints. Our experiments show that sometimes we do better than these other decompositions either in terms of pruningor in solution time or both (like the case of the decomposition of the Uses constraint). In addition, compared to highlyspecialised propagation algorithms like those for the AllDifferent and Gcc constraints in Ilog Solver, the loss in performancewhen using Range and Roots was not great. Thus, if the constraint toolkit lacks a specialised propagation algorithm, Rangeand Roots offer a quick, easy, and acceptable way of propagation. Finally, we observed that the extra set variables introducedin Range and Roots decompositions can be exploited in the design of new branching strategies. These extra set variablesmay provide both a modelling and solving advantage to the user. We hope that by presenting these results, developers ofthe many different constraint toolkits will be encouraged to include the Range and Roots constraints into their solvers.AcknowledgementsWe thank Eric Bourreau for having provided the data for the problem of the master of computer science of the universityof Montpellier. We also thank our reviewers for their helpful comments which improved this paper.References[1] R.K. Ahuja, T.L. Magnanti, J.B. Orlin, Network Flows, Prentice Hall, Upper Saddle River, NJ, 1993.[2] N. Beldiceanu, Global constraints as graph properties on a structured network of elementary constraints of the same type, Technical report, SwedishInstitute of Computer Science, 2000. SICS Technical Report T2000/01.[3] N. Beldiceanu, Pruning for the minimum constraint family and for the number of distinct values constraint family, in: T. Walsh (Ed.), CP, in: LectureNotes in Computer Science, vol. 2239, Springer, 2001, pp. 211–224.[4] N. Beldiceanu, E. Contejean, Introducing global constraints in CHIP, Math. Comput. Modelling 20 (12) (1994) 97–123.[5] N. Beldiceanu, I. Katriel, S. Thiel, Filtering algorithms for the same and usedby constraints, in: MPI Technical Report MPI-I-2004-1-001, 2004.[6] C. Bessiere, E. Hebrard, B. Hnich, Z. Kiziltan, T. Walsh, Among, common and disjoint constraints, in: B. Hnich, M. Carlsson, F. Fages, F. Rossi (Eds.),CSCLP, in: Lecture Notes in Computer Science, vol. 3978, Springer, 2005, pp. 29–43.[7] C. Bessiere, E. Hebrard, B. Hnich, Z. Kiziltan, T. Walsh, Filtering algorithms for the NVALUE constraint, Constraints 11 (4) (2006) 271–293.[8] C. Bessiere, E. Hebrard, B. Hnich, Z. Kiziltan, T. Walsh, Filtering algorithms for the NVALUE constraint, in: R. Bartak, M. Milano (Eds.), CPAIOR, in: LectureNotes in Computer Science, vol. 3524, Springer, 2005, pp. 79–93.[9] C. Bessiere, E. Hebrard, B. Hnich, Z. Kiziltan, T. Walsh, The RANGE and ROOTS constraints: some applications, Technical report COMIC-2006-003, 2006.[10] C. Bessiere, E. Hebrard, B. Hnich, Z. Kiziltan, T. Walsh, The RANGE and ROOTS constraints: Specifying counting and occurrence problems, in: L.P.Kaelbling, A. Saffiotti (Eds.), IJCAI, Professional Book Center, 2005, pp. 60–65.[11] C. Bessiere, E. Hebrard, B. Hnich, T. Walsh, The complexity of global constraints, in: D.L. McGuinness, G. Ferguson (Eds.), AAAI, AAAI Press/The MITPress, 2004, pp. 112–117.[12] C. Bessiere, E. Hebrard, B. Hnich, T. Walsh, The complexity of reasoning with global constraints, Constraints 12 (2) (2007) 239–259.[13] C. Bessiere, E. Hebrard, B. Hnich, T. Walsh, The tractability of global constraints, in: M. Wallace (Ed.), CP, in: Lecture Notes in Computer Science,vol. 3258, Springer, 2004, pp. 716–720.[14] B.M.W. Cheng, K.M.F. Choi, J.H.M. Lee, J.C.K. Wu, Increasing constraint propagation by redundant modeling: An experience report, Constraints 4 (2)(1999) 167–192.[15] R. Debruyne, C. Bessiere, Some practicable filtering techniques for the constraint satisfaction problem, in: IJCAI, 1997, pp. 412–417.[16] ILOG, Reference and User Manual, ILOG Solver 5.3, ILOG S.A., 2002.[17] F. Laburthe, Choco: implementing a CP kernel, in: Proceedings of TRICS: Techniques foR Implementing Constraint programming Systems, a post-conference workshop of CP, Singapore, 2000.1078C. Bessiere et al. / Artificial Intelligence 173 (2009) 1054–1078[18] M. Maher, Analysis of a global contiguity constraint, in: Proceedings of the Workshop on Rule Based Constraint Reasoning and Programming, heldalongside CP, Ithaca, NY, 2002.[19] F. Pachet, P. Roy, Automatic generation of music programs, in: J. Jaffar (Ed.), CP, in: Lecture Notes in Computer Science, vol. 1713, Springer, 1999,pp. 331–345.[20] P. Prosser, An empirical study of phase transitions in binary constraint satisfaction problems, Artif. Intell. 81 (1–2) (1996) 81–109.[21] C.G. Quimper, A. López-Ortiz, P. van Beek, A. Golynski, Improved algorithms for the global cardinality constraint, in: M. Wallace (Ed.), CP, in: LectureNotes in Computer Science, vol. 3258, Springer, 2004, pp. 542–556.[22] J.C. Régin, A filtering algorithm for constraints of difference in csps, in: AAAI, 1994, pp. 362–367.[23] J.C. Régin, Generalized arc consistency for global cardinality constraint, in: AAAI/IAAI, vol. 1, 1996, pp. 209–215.[24] J.C. Régin, The symmetric alldiff constraint, in: T. Dean (Ed.), IJCAI, Morgan Kaufmann, 1999, pp. 420–425.[25] F. Rossi, P. van Beek, T. Walsh, Handbook of Constraint Programming, Elsevier, 2006.[26] A. Schrijver, Combinatorial Optimization – Polyhedra and Efficiency, Springer-Verlag, Berlin, 2003.[27] C. Schulte, P.J. Stuckey, Speeding up constraint propagation, in: M. Wallace (Ed.), CP, in: Lecture Notes in Computer Science, vol. 3258, Springer, 2004,pp. 619–633.[28] P. Van Hentenryck, J.P. Carillon, Generality versus specificity: An experience with ai and or techniques, in: AAAI, 1988, pp. 660–664.[29] P. Van Hentenryck, Y. Deville, The cardinality operator: A new logical connective for constraint logic programming, in: ICLP, 1991, pp. 745–759.[30] P. Van Hentenryck, Y. Deville, C.M. Teng, A generic arc-consistency algorithm and its specializations, Artif. Intell. 57 (2–3) (1992) 291–321.[31] W.J. van Hoeve, J.C. Régin, Open constraints in a closed world, in: J.C. Beck, B.M. Smith (Eds.), CPAIOR, in: Lecture Notes in Computer Science, vol. 3990,Springer, 2006, pp. 244–257.