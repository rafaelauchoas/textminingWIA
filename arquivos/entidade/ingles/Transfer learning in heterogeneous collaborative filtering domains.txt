Artificial Intelligence 197 (2013) 39–55Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintTransfer learning in heterogeneous collaborative filteringdomainsWeike Pan, Qiang Yang∗Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Clearwater Bay, Kowloon, Hong Konga r t i c l ei n f oa b s t r a c tArticle history:Received 6 December 2010Received in revised form 6 December 2012Accepted 12 January 2013Available online 11 February 2013Keywords:Transfer learningCollaborative filteringMissing ratingsA major challenge for collaborative filtering (CF) techniques in recommender systems isthe data sparsity that is caused by missing and noisy ratings. This problem is even moreserious for CF domains where the ratings are expressed numerically, e.g. as 5-star grades.We assume the 5-star ratings are unordered bins instead of ordinal relative preferences. Weobserve that, while we may lack the information in numerical ratings, we sometimes haveadditional auxiliary data in the form of binary ratings. This is especially true given thatusers can easily express themselves with their preferences expressed as likes or dislikesfor items. In this paper, we explore how to use these binary auxiliary preference data tohelp reduce the impact of data sparsity for CF domains expressed in numerical ratings. Wesolve this problem by transferring the rating knowledge from some auxiliary data sourcein binary form (that is, likes or dislikes), to a target numerical rating matrix.In particular, our solution is to model both the numerical ratings and ratings expressed aslike or dislike in a principled way. We present a novel framework of Transfer by CollectiveFactorization (TCF), in which we construct a shared latent space collectively and learn thedata-dependent effect separately. A major advantage of the TCF approach over the previousbilinear method of collective matrix factorization is that we are able to capture the data-dependent effect when sharing the data-independent knowledge. This allows us to increasethe overall quality of knowledge transfer. We present extensive experimental results todemonstrate the effectiveness of TCF at various sparsity levels, and show improvements ofour approach as compared to several state-of-the-art methods.© 2013 Elsevier B.V. All rights reserved.1. IntroductionData sparsity is a major challenge in collaborative filtering [23,9,43]. Sparsity refers to the fact that some observedratings, e.g. 5-star grades, in a user-item rating matrix are too few, such that overfitting can easily happen when we use aprediction model for missing values in the test data. However, we observe that, some auxiliary data of the form “like” or“dislike” may be more easily obtained, such as the favored/disfavored data in Moviepilot1 and Qiyi,2 the dig/bury data inTudou,3 the love/ban data in Last.fm,4 and the “Want to see”/“Not interested” data in Flixster.5 It is often more convenientfor users to express such preferences instead of numerical ratings. The question we ask in this paper is: how do we take* Corresponding author.E-mail addresses: weikep@cse.ust.hk (W. Pan), qyang@cse.ust.hk (Q. Yang).1 http://www.moviepilot.de.2 http://www.qiyi.com.3 http://www.tudou.com.4 http://www.last.fm.5 http://www.flixster.com.0004-3702/$ – see front matter © 2013 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2013.01.00340W. Pan, Q. Yang / Artificial Intelligence 197 (2013) 39–55Table 1Matrix illustration of some related work on transfer learning in collaborative filtering. Note that SoRec, CMF, CBT and RMGM can beapplied in more general problem settings, e.g. more than two matrices, more than one types of alignments, etc.MethodsTraining dataAuxiliary dataSoRec (user side) [39]CMF (item side) [52]CBT (not aligned) [31]RMGM (not aligned) [32]R ∼ UVTKnowledge sharing: U = U1Value domain: (U, V), (U1, V1) ∈ DRDR = {(U, V) | U ∈ Rn×d, V ∈ Rm×d}R ∼ UVTKnowledge sharing: V = V2Value domain: (U, V), (U2, V2) ∈ DRDR = {(U, V) | U ∈ Rn×d, V ∈ Rm×d}R1 ∼ U1VT1R2 ∼ U2VT2R ∼ UBVTKnowledge sharing: B = B3Value domain: (U, V), (U3, V3) ∈ D{0,1}D{0,1} = {(U, V) | U ∈ {0, 1}n×d, U1 = 1, V ∈ {0, 1}m×d, V1 = 1}R3 ∼ U3B3VT3R ∼ UBVTKnowledge sharing: B = B3Value domain: (U, V), (U3, V3) ∈ D[0,1]D[0,1] = {(U, V) | U ∈ [0, 1]n×d, U1 = 1, V ∈ [0, 1]m×d, V1 = 1}R3 ∼ U3B3VT3advantage of auxiliary knowledge in the form of binary ratings to alleviate the sparsity problem in numerical ratings whenwe build a rating-prediction model?To the best of our knowledge, no previous work answered the question of how to jointly model a target data of numericalratings and an auxiliary data of binary ratings. There are some prior works on using both the numerical ratings and implicitdata of “whether rated” [28,35] or “whether purchased” [57] to help boost the prediction performance. Among the previousworks, Koren [28] uses implicit data of “rated” as offsets in a factorization model, and Liu et al. [35] adapt the collectivematrix factorization (CMF) approach [52] to integrate the implicit data of “rated.” Zhang and Nie [57] convert the implicitdata of simulated purchases to a user-brand matrix as a user-side meta data representing brand loyalty and a user-itemmatrix of “purchased.” However, none of these previous works consider how to use auxiliary data in the form of like anddislike type of binary ratings in collaborative filtering in a transfer learning framework.Most existing transfer learning methods in collaborative filtering consider auxiliary data from several perspectives, includ-ing user-side transfer [39,11,58,38,55], item-side transfer [52], or knowledge-transfer using related but not aligned data [31,32]. We illustrate the ideas of knowledge sharing from a matrix factorization view as shown in Table 1. We show fourrepresentative methods [39,52,31,32] in Table 1 and describe the details starting from a non-transfer learning method ofprobabilistic matrix factorization (PMF) [47].Probabilistic matrix factorization The PMF [47] or latent factorization model (LFM) [4] seeks an appropriate low-ranki· , where U ∈ Rn×d, V ∈ Rm×d areapproximation, R = UVT , for which any missing value can be predicted by ˆrui = U u· V Tuser-specific and item-specific latent feature matrices, respectively. The optimization problem of PMF is as follows [47,4],EI(U, V) + αR(U, V)minU,V(1)W. Pan, Q. Yang / Artificial Intelligence 197 (2013) 39–55where EI(U, V) = 1(cid:2)2(cid:2)(cid:2)nu=1mi=1 yui(rui − U u· V Ti· )2 = 12(cid:5)Y (cid:6) (R − UVT )(cid:5)2F is the loss function, and R(U, V) = 12 ((cid:2)nu=1mi=1(cid:5)V i·(cid:5)2) = 12 ((cid:5)U(cid:5)2F+ (cid:5)V(cid:5)2F ) is a regularization term used to avoid overfitting.41(cid:5)U u·(cid:5)2 +Social recommendation SoRec [39] is proposed to alternatively factorize the target rating matrix R and a user-side socialnetwork matrix R1 with the constraint of sharing the same user-specific latent feature matrix (see U = U1 in Table 1). Theobjective function is formalized as follows [39],EI(U, V) + EI(U, V1) + αR(U, V, V1)minU,V1,U(2)where (U, V) ∈ DR, and R(U, V, V1) = 12 ((cid:5)U(cid:5)2F+ (cid:5)V(cid:5)2F+ (cid:5)V1(cid:5)2F ) is a regularization term on the latent variables.Collective matrix factorization CMF [52] is proposed to alternatively factorize the target rating matrix R and an item-sidecontent matrix R2 with the constraint of sharing the same item-specific latent feature matrix (see V = V2 in Table 1). Thisapproach is similar to that in SoRec [39], but with different auxiliary data. The optimization problem of CMF is stated asfollows [52],EI(U, V) + EI(U2, V) + αR(U, V, U2)minU,V,U2(3)where (U, V) ∈ DR, and R(U, V, U2) = 12 ((cid:5)U(cid:5)2F+ (cid:5)V(cid:5)2F+ (cid:5)U2(cid:5)2F ) is again a regularization term used to avoid overfitting.Codebook transfer The CBT [31] method consists of codebook construction and expansion steps. It achieves knowledgetransfer with the assumption that both auxiliary and target data share a common cluster-level rating pattern (see B = B3 inTable 1).1. Codebook construction. Assume that (U3, V3) ∈ D{0,1} are user-specific and item-specific membership indicator matricesof the auxiliary rating matrix R3, which are obtained using co-clustering algorithms such as NMF [19]. The constructed3 R3V3]k(cid:3) denotes the summation of ratingscodebook is represented as B3 = [UTby users in a user cluster k on items in an item cluster (cid:3). [UT3 (R3 > 0)V3]k(cid:3) denotes the number of ratings from users ina user cluster k on items in an item cluster (cid:3), hence, the element-wise division (cid:7) resembles the idea of normalization,and [B3]k(cid:3) is the average rating of users in a user cluster k on items in an item cluster (cid:3).3 (R3 > 0)V3] [31], where [UT3 R3V3] (cid:7) [UT2. Codebook expansion. The codebook expansion problem is formalized as follows [31],EB(U, V)s.t.(U, V) ∈ D{0,1}minU,V(4)(cid:5)Y (cid:6) (R − UBVT )(cid:5)2where EB(U, V) = 1F is a B-regularized square loss function, and B = B3 is the codebook constructed2from the auxiliary data R3. In [31], an alternating greedy-search algorithm is proposed to solve the combinatorialoptimization problem in Eq. (4), and the choices of U uk = 1, V i(cid:3) = 1 are used to select the entry located at (k, (cid:3)) ofi· . Thus, the predicted rating ˆrui = [UBVT ]ui = [B]k(cid:3) is the average rating of users in the userB via [UBVT ]ui = U u·BV Tcluster k on items in an item cluster (cid:3) of the auxiliary data.Rating-matrix generative model RMGM [32] is derived and extended from the FMM generative model [50], and we re-write it in a matrix factorization manner,minU,V,B,U3,V3EB(U, V) + EB(U3, V3)s.t.(U, V), (U3, V3) ∈ D[0,1](5)where EB(U, V) is again a B-regularized loss function, the same as given in Eq. (4). We can see that RMGM is differentfrom CBT since it learns (U, V) and (U3, V3) alternatively and relaxes the hard membership requirement as imposed by theindicator matrix, e.g. U ∈ {0, 1}n×d. A soft indicator matrix is used in RMGM [32], e.g., U ∈ [0, 1]n×d.In this paper, we consider the situation where the auxiliary data is such that the following information are aligned: usersand items of the target rating matrix and the auxiliary binary rating matrix. This assumption gives us precise information onthe mapping between auxiliary and target data, which can lead to higher performance than not having this knowledge. Weillustrate the idea of these assumptions using matrices in Table 2, where we can see that our problem setting and proposedsolution are both novel and different from the previous ones as shown in Table 1. We will discuss these novelty in thesequel.Our idea extends the ideas in our previous conference papers on this topic [43,42], on which we have extensively ex-tended. Compared to these preliminary works, we have extended in the following aspects. First, we have included a newanalysis of transfer learning methods in collaborative filtering from the perspective of matrix factorization in Section 1. Sec-ond, we have provided more detailed derivations of our equations in Section 3. Third, we have included more experimentalresults that are reported in Section 4. Finally, we have added more related works and associated discussions as given inSection 5.42W. Pan, Q. Yang / Artificial Intelligence 197 (2013) 39–55Table 2Matrix illustration of Transfer by Collective Factorization.Variants of TCFTraining dataAuxiliary dataCMTF (frontal side)R ∼ UBVTKnowledge sharing: U = ˜U, V = ˜VValue domain: (U, V), ( ˜U, ˜V) ∈ DRDR = {(U, V) | U ∈ Rn×d, V ∈ Rm×d}CSVD (frontal side)R ∼ UBVTKnowledge sharing: U = ˜U, V = ˜VValue domain: (U, V), ( ˜U, ˜V) ∈ D⊥D⊥ = {(U, V) | U ∈ Rn×d, UT U = I, V ∈ Rm×d, VT V = I}˜R ∼ ˜U ˜B ˜VT˜R ∼ ˜U ˜B ˜VTThe organization of the paper is as follows. We give a formal definition of the problem in Section 2 and then describeour solution in detail in Section 3. We present experimental results on real-world data sets in Section 4, and discuss aboutsome related work in Section 5. Finally, we give some concluding remarks and future works in Section 6.2. Heterogeneous collaborative filtering problems2.1. Problem definitionIn the target data, we have a user-item numerical rating matrix R = [rui]n×m ∈ {1, 2, 3, 4, 5, ?}n×m with q observedratings, where the question mark “?” denotes a missing value, which can be an unobserved value. Note that the ob-served rating values in R are considered as unordered bins and are not limited to 5-star grades; instead, they can beany real numbers. We use an indicator matrix Y = [ yui]n×m ∈ {0, 1}n×m to denote whether the entry (u, i) is observed( yui = 1) or not ( yui = 0), andu,i yui = q. Similarly, in the auxiliary data, we have a user-item binary rating matrix˜R = [˜rui]n×m ∈ {0, 1, ?}n×m with ˜q observations, where a value of one denotes the observed ‘like’ value, and zero denotes theobserved ‘dislike’ value. The question mark denotes the missing value. Similar to the target data, we have a correspondingindicator matrix ˜Y = [ ˜yui]n×m ∈ {0, 1}n×m, and˜yui = ˜q. Note that there is a one–one mapping between the users anditems of R and ˜R. Our goal is to predict the missing values in R by transferring the rating knowledge from ˜R. Note thatthe binary ratings here are different from the implicit data used in [28,35,57], which can be represented as {1, ?}n×m, sinceimplicit data corresponds to positive observations only.(cid:2)(cid:2)u,i2.2. ChallengesOur problem setting is novel and challenging. In particular, we enumerate the following challenges for the problemsetting (see Fig. 1).1. How to make use of the existing correspondences among users and items from two domains, given that such relationshipsare important and can serve as a bridge across two domains. Some previous solutions were proposed without suchcorrespondences [31,32], and are thus imprecise. Other works have used correspondence information as additionalconstraints on the user-specific or item-specific latent feature matrices [39,52].2. What to transfer and how to transfer, as raised in [41]. Previous works that address this question include approachesthat transfer the knowledge of latent features in an adaptive way [43] or in a collective way [39,52]. Some works inthis direction include those that transfer cluster-level rating patterns [31] in an adaptive manner or in a collectivemanner [32].3. How to model the data-dependent effect of numerical ratings and binary ratings when sharing the data-independent knowl-edge? This question is important since clearly the auxiliary and target data may have different distributions and quitedifferent semantic meanings.From Table 1, we can see that the solutions of [39,52,31,32] were proposed for different problem settings as comparedto ours, as shown in Table 2 and Fig. 1. More specifically, for the aforementioned three challenges from our problem setting,W. Pan, Q. Yang / Artificial Intelligence 197 (2013) 39–5543Fig. 1. Graphical model of Transfer by Collective Factorization for transfer learning in collaborative filtering. Note that we use the same set of user-specificlatent feature vectors and the same set of item-specific latent feature vectors for both target data and auxiliary data.the approaches of [39,52] cannot capture the data-dependent information, and the methods of [31,32] cannot make use ofthe existing correspondence information.2.3. Overview of our solutionWe propose a principled matrix-based transfer-learning framework referred to as Transfer by Collective Factorization, whichjointly factorizes the data matrices in three parts: a user-specific latent feature matrix, an item-specific latent feature matrix,and two data-dependent inner matrices. Specifically, the main idea of our solution has two major steps. First, we factorizeboth the target numerical rating matrix, R ∼ UBVT , and the auxiliary binary rating matrix, ˜R ∼ ˜U ˜B ˜VT , with constraintsof sharing user-specific latent feature matrix U = ˜U and item-specific latent feature matrix V = ˜V (see Table 2 for matrixillustration). Second, we learn the inner matrices B and ˜B separately in each domain to capture the domain-dependentinformation, since the semantic meaning and distributions of numerical ratings and binary ratings may be different. Asan alternative interpretation, the inner matrices B and ˜B can be considered as data-dependent correlations between therows of U and columns of VT for target data and auxiliary data, respectively. Those two major steps are iterated to havericher interactions for knowledge sharing [13,54] until we reach convergence to a locally optimal state. The intuition of ourapproach is that same users and items in two domains are likely to have the same latent feature matrices, e.g. U = ˜U andV = ˜V, while the domain differences, the data-dependent information, are left for the inner matrices, B and ˜B.In summary, our major contributions are:1. We make full use of the correspondences among users and items, from a source and a target domains. We allow thealigned users and items to share the same user-specific latent feature matrix and item-specific latent feature matrix,respectively.2. We construct a shared latent space to address the what to transfer question, via a matrix tri-factorization, or trilinear,method in a collective way to address the how to transfer question.3. We model the data-dependent effect of binary ratings and numerical ratings by learning the inner matrices of trilinearmethod separately.3. Transfer by collective factorization3.1. Model formulationWe assume that a user u’s rating on an item i in the target data, rui , is generated from the user-specific latent featurevector U u· ∈ R1×du , item-specific latent feature vector V i· ∈ R1×dv , and some data-dependent effect denoted as B ∈ Rdu ×dv .Note that this formulation is different from the PMF formulation [47], which only contains U u· and V i·. Similarly, ourgraphical model as shown in Fig. 1 is a significant extension of the graphical model of PMF [47], where U u·, u = 1, . . . , n,and V i·, i = 1, . . . , m, are shared to bridge two data, while B, ˜B are designed to capture the data-dependent effect. We fixd = du = dv for notation simplicity in the sequel. We define a conditional distribution as44W. Pan, Q. Yang / Artificial Intelligence 197 (2013) 39–55p(rui|U u·, B, V i·, αr) = N(cid:3)rui|U u·BV Ti· , α−1r(cid:4),(cid:5)−α(x−μ)22where N (x|μ, α−1) =is the Gaussian distribution with mean μ and precision α. We further definethe prior distributions over U u·, V i· and B as p(U u·|αu) = N (U u·|0, α−1v I), and p(B|β) =N (B|0, (β/q)−1I). We then have the log-posterior function over the latent variables U ∈ Rn×d, B ∈ Rd×d and V ∈ Rm×dvia Bayesian inference,u I), p(V i·|αv ) = N (V i·|0, α−1α2π explog p(U, B, V|R, αr, αu, αv , β)m(cid:6)(cid:7)n(cid:6)= log(cid:8)p(rui|U u·, B, V i·, αr)p(U u·|αu)p(V i·|αv )p(B|β)yuiu=1n(cid:6)i=1m(cid:6)(cid:7)N= log(cid:3)rui|U u·BV Ti· , α−1r(cid:4)N(cid:3)(cid:4)U u·|0, α−1u IN(cid:3)(cid:4)V i·|0, α−1v IN(cid:3)B|0, (β/q)−1I(cid:4)(cid:8)yuiu=1n(cid:9)i=1m(cid:9)yui= −i=1u=1(cid:5)(cid:10)αr2(cid:3)rui − U u·BV Ti·(cid:4)2 + αu2(cid:5)U u·(cid:5)2F+ αv2(cid:5)V i·(cid:5)2F+ β2q(cid:5)B(cid:5)2F+ C(cid:11)where C = lnαr2π+ lnαu2π+ lnαv2π+ ln(cid:5)(cid:5)(cid:5)n(cid:9)m(cid:9)−u=1i=1(cid:10)12yui(cid:3)rui − U u·BV Ti·(cid:4)β2qπ is a constant. Setting αr = 1, we have(cid:11)2 + αu2(cid:5)U u·(cid:5)2F+ αv2(cid:5)V i·(cid:5)2F− β2(cid:5)B(cid:5)2F .Similarly, in the auxiliary data, we have a log-posterior function for the matrix tri-factorization, or trilinear, model,log p(U, ˜B, V| ˜R, αr, αu, αv , β). To jointly maximize these two log-posterior functions, we havelog p(U, B, V|R, αr, αu, αv , β) + λ log p(U, ˜B, V| ˜R, αr, αu, αv , β)maxU,V,B, ˜Bs.t. U, V ∈ Dwhere λ > 0 is a tradeoff parameter to balance the target and auxiliary data and D is the value domain of the latentvariables. D can be DR = {U ∈ Rn×d, V ∈ Rm×d} or D⊥ = DR ∩ {UT U = I, VT V = I} to get the effect of finding latent top-ics [18,43] and noise reduction [6,27] in SVD. Thus we have two variants of TCF, CMTF (collective matrix tri-factorization)for DR and CSVD (collective SVD) for D⊥. Although 2DSVD or Tucker2 [20] can factorize a sequence of full matrices, it doesnot achieve the goal of missing-value prediction in sparse observation matrices, which is accomplished in our proposedapproach.Finally, we obtain the following equivalent minimization problem for TCF,n(cid:9)m(cid:9)(cid:10)minU,V,B, ˜Bu=1+ λyuii=1n(cid:9)m(cid:9)u=1i=1(cid:3)rui − U u·BV Ti·(cid:4)122 + αu2(cid:5)U u·(cid:5)2 + αv2(cid:5)V i·(cid:5)2(cid:11)(cid:10)12˜yui(cid:3)˜rui − U u· ˜BV Ti·(cid:4)2 + αu2(cid:5)U u·(cid:5)2 + αv2(cid:5)V i·(cid:5)2(cid:11)+ β2(cid:5)B(cid:5)2FU, V ∈ D.+ λβ2(cid:5) ˜B(cid:5)2Fs.t.(6)To solve the optimization problem in Eq. (6), we first collectively factorize two data matrices of R and ˜R to learn Uand V. We then estimate B and ˜B separately. We transfer the knowledge of latent feature matrices, U and V via collectivefactorization of the rating matrices R and ˜R. For this reason, we call our approach Transfer by Collective Factorization.3.2. Learning the TCFLearning U and V in CMTF Given B and V, we show that the user-specific latent feature matrix U in Eq. (6) can be obtainedanalytically.Theorem 1. Given B and V, we can obtain the user-specific latent feature matrix U in a closed form.W. Pan, Q. Yang / Artificial Intelligence 197 (2013) 39–55i· )2 + αu2(cid:5)U u·(cid:5)2 + αv2(cid:5)V i·(cid:5)2] + β2(cid:5)B(cid:5)2F+ λ{(cid:2)mi=1˜yui[ 12 (˜rui − U u· ˜BV Ti· )2 + αu245(cid:5)U u·(cid:5)2 +Proof. Let f u =αv(cid:5)V i·(cid:5)2] + β22m2 (rui − U u·BV Ti=1 yui[ 1}, and we have(cid:2)(cid:5) ˜B(cid:5)2Fm(cid:9)∂ f u∂ U u·=(cid:7)(cid:3)−rui + U u·BV Ti·(cid:4)V i·BT + αu U u·(cid:8)yuii=1+ λm(cid:9)(cid:7)(cid:3)˜yui−˜rui + U u· ˜BV Ti·(cid:4)V i· ˜BT + αu U u·(cid:8)i=1m(cid:9)(cid:3)yuirui V i·BT + λ ˜yui= −(cid:4)˜rui V i· ˜BTi=1+ αu U u·m(cid:9)( yui + λ ˜yui) + U u·i=1m(cid:9)(cid:3)i=1yuiBV Ti· V i·BT + λ ˜yui˜BV Ti· V i· ˜BT(cid:4).= 0, we have the update rule for each U u·,Setting ∂ f u∂ U u·U u· = bu C(cid:2)−1u ,where C u =mi=1( yuiBV Ti· V i·BT + λ ˜yui˜BV Ti· V i· ˜BT ) + αuuser-specific latent feature matrix U analytically. (cid:2)We can see that U u· in Eq. (7) is independent of all other users’ latent features given B and V, thus we can obtain the(cid:2)mi=1( yui + λ ˜yui)I and bu =(cid:2)mi=1( yuirui V i·BT + λ ˜yui(7)˜rui V i· ˜BT ).Similarly, given B and U, the latent feature vector V i· of each item i can be estimated in a closed form, and thus thewhole item-specific latent feature matrix V can be obtained analytically,,−1V i· = bi Ci(cid:2)nu=1( yuiBT U Twhere C i =u·U u·B + λ ˜yui˜BT U Tu·U u· ˜B) + αv(cid:2)nu=1( yui + λ ˜yui)I and bi =(cid:2)nu=1( yuirui U u·B + λ ˜yui˜rui U u· ˜B).(8)The closed-form update rule in Eq. (7) or Eq. (8) can be considered as a generalization of the alternating least square(ALS) approach in [4]. Note that Bell and Koren [4] consider bilinear model in a single matrix, which is different from ourtrilinear models of two matrices.Learning U and V in CSVD Since the constraints D⊥ have similar effect of regularization, we remove the regularizationterms in Eq. (6) and reach a simplified optimization problem,(cid:4)(cid:12)(cid:12)2F˜R − U ˜BVTR − UBVT(cid:12)(cid:12) ˜Y (cid:6)(cid:12)(cid:12)Y (cid:6)(cid:4)(cid:12)(cid:12)2F1(cid:3)(cid:3)2minU,Vs.t. UT U = I,+ λ2VT V = I.Let f = 12∂ f∂U=(cid:5)Y (cid:6) (R − UBVT )(cid:5)2F(cid:4)(cid:4)(cid:3)Y (cid:6)UBVT − R(cid:3)+ λ2(cid:5) ˜Y (cid:6) ( ˜R − U ˜BVT )(cid:5)2(cid:3)(cid:3)˜Y (cid:6)U ˜BVT − ˜RVBT + λ(cid:4)(cid:4)V ˜BT .F . We have the gradients on U as follows,Then, the variable U can be learned via a gradient descent algorithm on the Grassmann manifold [21,10,27],U ← U − γ(cid:3)I − UUT(cid:4) ∂ f∂U= U − γ ∇U.We now show that γ can be obtained analytically in the following theorem.Theorem 2. The step size γ in Eq. (10) can be obtained analytically.Proof. Plugging in the update rule in Eq. (10) into the objective function in Eq. (9), we have(cid:12)(cid:12)Y (cid:6)(cid:12)(cid:12) ˜Y (cid:6)(cid:3)g(γ ) = 12+ λ2(cid:12)(cid:12)Y (cid:6)(cid:12)(cid:12) ˜Y (cid:6)= 12+ λ2(cid:7)R − (U − γ ∇U)BVT(cid:7)˜R − (U − γ ∇U) ˜BVT(cid:3)(cid:4)R − UBVT+ γ Y (cid:6)(cid:8)(cid:12)(cid:12)2F(cid:8)(cid:12)(cid:12)2F(cid:3)˜R − U ˜BVT(cid:4)+ γ ˜Y (cid:6)∇U ˜BVT∇UBVT(cid:3)(cid:4)(cid:12)(cid:12)2F(cid:4)(cid:12)(cid:12)2F .(9)(10)46W. Pan, Q. Yang / Artificial Intelligence 197 (2013) 39–55Denoting t1 = Y (cid:6) (R − UBVT ), ˜t1 = ˜Y (cid:6) ( ˜R − U ˜BVT ), t2 = Y (cid:6) (∇UBVT ), ˜t2 = ˜Y (cid:6) (∇U ˜BVT ), we have g(γ ) = 1(cid:5)˜t1 + γ ˜t2(cid:5)2λ22(cid:5)t1 + γ t2(cid:5)2F+F , and the gradient(cid:3)+ γ trt T2 t2(cid:3)t T1 t2= tr(cid:4)∂ g(γ )∂γ(cid:4)(cid:4)(cid:3)(cid:7)˜t Ttr1˜t2+ λ+ γ tr(cid:3)˜t T2(cid:4)(cid:8),˜t2from which we obtain γ = − tr(t Ttr(t T1 t2)−λ tr(˜t T2 t2)+λ tr(˜t T˜t2)˜t2)12via setting∂ g(γ )∂γ= 0. (cid:2)Similarly, we have the update rule for the item-specific latent feature matrix V,V ← V − γ ∇V(11)where ∇V = (I − VVT ) ∂ f∂V , and ∂ f∂V= (Y (cid:6) (UBVT − R))UB + λ( ˜Y (cid:6) (U ˜BVT − ˜R))U ˜B.Note that the previous works of [10,27] use the gradient descent approach also on a Grassmann manifold. But, they studya single-matrix factorization problem and adopt a different learning algorithm on the Grassmann manifold for searching thestep size γ .Learning B and ˜B Given U, V, we can estimate B and ˜B separately in each data, e.g. for the target data. Let F (R ∼ UBVT ) =(cid:2)nu=1(cid:5)U u·(cid:5)2 + αvi=1 yui[ 1F , we have(cid:5)B(cid:5)2(cid:2)m2 (rui − U u·BV Tm(cid:9)n(cid:9)(cid:4)2i· )2 + αu(cid:10)(cid:3)rui − U u·BV Ti·yui12(cid:4)2(cid:5)V i·(cid:5)2] + β(cid:11)2+ β2(cid:5)B(cid:5)2F2(cid:3)R ∼ UBVTF∝u=1i=1(cid:12)(cid:12)Y (cid:6)= 12(cid:3)R − UBVT(cid:4)(cid:12)(cid:12)2F+ β2(cid:5)B(cid:5)2F .Thus, we obtain the following equivalent minimization problem,+ β2R − UBVT(cid:12)(cid:12)Y (cid:6)(cid:4)(cid:12)(cid:12)2F(cid:5)B(cid:5)2FminB21(cid:3)(12)where the data-dependent parameter B can be estimated exactly the same as that of estimating w in a corresponding]T ∈ Rd2×1 is a large vector that is concatenated from columns ofleast square SVM problem, where w = vec(B) = [B Tu· V i·) ∈ Rd2×1. Hence, we obtain thematrix B. The instances can be constructed as {xui, rui} with yui = 1, where xui = vec(U Tfollowing least-square SVM problem,·1 . . . B T·dminw12(cid:5)r − Xw(cid:5)2F+ β2(cid:5)w(cid:5)2F(13)where X = [. . . xui . . .]T ∈ Rp×d2ratings from R. Setting ∇ w = −XT (r − Xw) + β w = 0, we have(with yui = 1) is the data matrix, and r ∈ {1, 2, 3, 4, 5}p×1 is the corresponding observed(cid:3)XT X + βI(cid:4)−1XT r.w =(14)Note that B or w can be considered as a linear compact operator [1] and solved efficiently using various existing off-the-shelf tools.Finally, we can solve the optimization problem in Eq. (6) by alternatively estimating B, ˜B, U and V. The complete algo-rithm is given in Fig. 2. Note that we can scale the target matrix R with rui = rui−14 , yui = 1, u = 1, . . . , n, i = 1, . . . , m, inorder to remove the value range difference of two data sources. We adopt random initialization for U, V in CMTF and SVDresults [17] of ˜R for that in CSVD.3.3. AnalysisEach sub-step of updating B, ˜B, U and V in Fig. 2 will monotonically decrease the objective function in Eq. (6), andhence ensure the convergence to a local minimum. We use a validation data set to determine the convergence conditionand tune the parameters (see Section 4.3). The time complexity of TCF and other baseline methods (see Section 4) areobtained as follows: (i) AF: O (q), (ii) PMF [47]: O (K qd2 + K max(n, m)d3), (iii) cPMF [47]: O (K q˜cd2 + K max(n, m)d3), (iv)SVD [48]: O (nm) since it fills the missing ratings with average values, (v) PCC [45]: O (n2), (vi) OptSpace [27]: O (K qd3 +K d6), (vii) CMF [52]: O (K max(q, ˜q)d2 + K max(n, m)d3), and (viii) TCF: O (K max(q, ˜q)d3 + K d6), where K is the number ofiterations to convergence, q, ˜q (q, ˜q > n, m) is the number of non-missing entries in the matrix R and ˜R, respectively, ˜c isthe average number of raters of an item in ˜R, and d is the number of latent features.Note that the TCF algorithm can be sped up via a stochastic sampling (or stochastic gradient descent) algorithm ordistributed computing. More specifically, the step for estimating B or ˜B in both CMTF and CSVD is equivalent to thatW. Pan, Q. Yang / Artificial Intelligence 197 (2013) 39–5547Input: The target user-item numerical rating matrix R, the auxiliary user-item binary rating matrix ˜R, the targetuser-itemindicator matrix Y, the auxiliary user-item indicator matrix ˜Y.Output: The shared user-specific latent feature matrix U, the shared item-specific latent feature matrix V, the inner matrixto model the target data-dependent information B, the inner matrix to model the auxiliary data-dependent information ˜B.Step 1. Scale ratings in R (rui = rui−14Step 2. Initialize U, V: randomly initialize U and V for CMTF; initialize U and V in CSVD using the SVD [17] results of ˜R.Step 3. Estimate B and ˜B as shown in Eq. (14).Step 4. Update U, V, B, ˜B.repeat, yui = 1, u = 1, . . . , n, i = 1, . . . , m).repeatStep 4.1.1. Fix B and V, update U in CMTF as shown in Eq. (7) or CSVD as shown in Eq. (10).Step 4.1.2. Fix B and U, update V in CMTF as shown in Eq. (8) or CSVD as shown in Eq. (11).until ConvergenceStep 4.2. Fix U and V, update B and ˜B as shown in Eq. (14).until ConvergenceFig. 2. The algorithm of Transfer by Collective Factorization.of least square SVM, thus various existing off-the-shelf tools can be used, e.g. we can use the stochastic sampling (orstochastic gradient descent) method [8] and distributed algorithms [14]. Second, the step for estimating U, V in CMTF canbe distributed the same as that of PMF and CMF. For example, once B and V are given, each user u’s latent feature vectorU u· is independent of that of other users, which fits the MPI (message passing interface) framework well.4. Experimental resultsOur experiments are designed to verify the following hypotheses. We believe that transfer learning is effective in address-ing the data sparsity problem in collaborative filtering, although the smoothing methods are very competitive baselines forthe task of missing-value prediction in a sparse rating matrix. In particular,(a) we believe that the proposed transfer learning methods, CMTF and CSVD, perform better than baseline algorithms;(b) we believe that the transfer learning method CMTF-link is better than the non-transfer learning methods of PMF [47],SVD [48] and OptSpace [27];(c) we believe that the transfer learning method CMTF is better than CMF-link, since the inner matrices B and ˜B in CMTFare used to capture data-dependent information;(d) we believe that the transfer learning method CSVD is better than CMTF, since the orthonormal constraints in CSVD canselectively transfer the most useful knowledge via noise reduction.We verify each of the above four hypotheses in Section 4.3.4.1. Data sets and evaluation metricsWe evaluate the proposed method using two movie rating data sets, Moviepilot and Netflix,6 and compare to somestate-of-the-art baseline algorithms.Subset of Moviepilot data The Moviepilot rating data contains more than 4.5 × 106 ratings with values in [0, 100], whichare given by more than 1.0 × 105 users on around 2.5 × 104 movies [46]. The data set used in the experiments is constructedas follows,1. we first randomly extract a 2000 × 2000 dense rating matrix R from the Moviepilot data. We then normalize the ratingsby rui25+ 1, and the new rating range is [1, 5];2. we randomly split R into training and test sets, T R , T E , with 50% ratings, respectively. T R , T E ⊂ {(u, i, rui) ∈ N × N ×[1, 5] | 1 (cid:2) u (cid:2) n, 1 (cid:2) i (cid:2) m}. T E is kept unchanged, while different (average) number of observed ratings for each user,u,i yui/n/m) levels of 0.2%, 0.4%, 0.6%4, 8, 12, 16, are randomly sampled from T R for training, with different sparsity (and 0.8% correspondingly;3. we randomly pick 40 observed ratings on average from T R for each user to construct the auxiliary data matrix ˜R. Tosimulate heterogeneous auxiliary and target data, we adopt a pre-processing approach [51] on ˜R, by relabeling ratingswith value rui (cid:2) 3 in ˜R as 0 (dislike), and then ratings with value rui > 3 as 1 (like). The overlap between ˜R and R(cid:2)(˜yui/n/m) is 0.026%, 0.062%, 0.096% and 0.13% correspondingly.(cid:2)u,i yui6 http://www.netflix.com.48W. Pan, Q. Yang / Artificial Intelligence 197 (2013) 39–55Table 3Description of subset of Moviepilot data (n = m = 2000) and subset of Netflix data (n = m = 5000).Data setMoviepilot (subset)Netflix (subset)target (training)target (test)auxiliarytarget (training)target (test)auxiliaryForm[1, 5] ∪ {?}[1, 5] ∪ {?}{0, 1, ?}{1, 2, 3, 4, 5, ?}{1, 2, 3, 4, 5, ?}{0, 1, ?}Sparsity< 1%11.4%2%< 1%11.3%2%Subset of Netflix data The Netflix rating data contains more than 108 ratings with values in {1, 2, 3, 4, 5}, which are givenby more than 4.8 × 105 users on around 1.8 × 104 movies. The data set used in the experiments is constructed as follows,1. we use the target data in our previous work [43], which is a dense 5000 × 5000 rating matrix R from the Netflix data;more specifically, in [43], we first identify 5000 movies appearing both in MovieLens7 and Netflix via the movie title,and then select 10 000 most frequent users and another 5000 most popular items from Netflix, and the 5000 itemsused in this paper are the movies appearing both in MovieLens and Netflix and the 5000 users used in this paper arethe most frequent 5000 users;2. we randomly split R into training and test sets, T R , T E , with 50% ratings, respectively. T E is kept unchanged, whiledifferent (average) number of observed ratings for each user, 10, 20, 30, 40, are randomly sampled from T R for training,with different sparsity levels of 0.2%, 0.4%, 0.6% and 0.8% correspondingly;3. we randomly pick 100 observed ratings on average from T R for each user to construct the auxiliary data matrix ˜R. Tosimulate heterogeneous auxiliary and target data, we adopt the pre-processing approach [51] on ˜R, by relabeling 1, 2, 3ratings in ˜R as 0 (dislike), and then 4, 5 ratings as 1 (like). The overlap between ˜R and R (˜yui/n/m) is 0.035%,0.071%, 0.11% and 0.14% correspondingly.u,i yui(cid:2)The final data sets8 are summarized in Table 3.Evaluation metrics We adopt the evaluation metrics of Mean Absolute Error (MAE) and Root Mean Square Error (RMSE),(cid:9)MAE =|rui − ˆrui|/|T E |,(u,i,rui)∈T E(cid:13) (cid:9)RMSE =(u,i,rui)∈T E(rui − ˆrui)2/|T E |where rui and ˆrui are the true and predicted ratings, respectively, and |T E | is the number of test ratings. In all experi-ments, we run 3 random trials when generating the required number of observed ratings from T R , and averaged results arereported.4.2. Baselines and parameter settingsWe compare our TCF method with five non-transfer learning methods: the average filling method (AF), Pearson cor-relation coefficient (PCC) [45], PMF [47], SVD [48], OptSpace [27], as well as two learning methods using auxiliary data:CMF [52] with logistic link function (CMF-link) and constrained PMF (cPMF) [47].We study the following six average filling (AF) methods,ˆrui = ¯ru·,ˆrui = ¯r·i,ˆrui = (¯ru· + ¯r·i)/2,ˆrui = bu· + ¯r·i,ˆrui = ¯ru· + b·i,ˆrui = ¯r + bu· + b·i7 http://www.grouplens.org/node/73.8 The data and code can be downloaded at http://www.cse.ust.hk/~weikep/TCF-data-code.zip.W. Pan, Q. Yang / Artificial Intelligence 197 (2013) 39–5549Fig. 3. Logistic link function σ (x) =11+exp{−γ (x−0.5)} .(cid:2)(cid:2)i yuirui/(cid:2)where ¯ru· =(cid:2)i yui(rui − ¯r·i)/u yui is the average rating of item i, bu· =u,i yuiis the global average rating. We use ˆrui = ¯r + bu· + b·i as it performs best in our experiments. In order to compare with thecommonly used average filling methods, we also report the results of ˆrui = ¯ru· and ˆrui = ¯r·i .i yui is the average rating of user u, ¯r·i =u yui(rui − ¯ru·)/u yuirui/u yui is the bias of item i, and ¯r =i yui is the bias of user u, b·i =u,i yuirui/(cid:2)(cid:2)(cid:2)For SVD [48], we adopt the approach of 5-star numerical rating predictions, which are reported as the best one in [48].Specifically, we convert the original rating matrix R to ˘R as follows [48],(cid:2)(cid:2)(cid:2)(cid:14)rui → ˘rui =rui − ¯ru·,¯r·i − ¯ru·,if yui = 1 (rated),if yui = 0 (not rated)where ¯ru· is the user u’s average rating and ¯r·i is the item i’s average rating, the same as that used in the aforementionedaverage filling methods; and then we apply SVD [5,48] on the matrix ˘R, ˘R = UΣVT ; and finally, the rating of user u on itemi can be predicted as follows [48],ˆrui = ¯ru· + U u·Σ V Ti·where the average rating ¯ru· is added to the prediction rule.For PCC, since the data matrices are sparse, we use the whole set of neighboring users in the prediction rule. For PMF,cPMF, SVD, OptSpace, CMF-link and TCF, we fix the latent feature number d = 10. For PMF, different tradeoff parametersof αu = αv ∈ {0.01, 0.1, 1} are tried; for cPMF, different tradeoff parameters of αu = αv = αw ∈ {0.01, 0.1, 1} are tried; forCMF-link, different tradeoff parameters αu = αv ∈ {0.01, 0.1, 1}, λ ∈ {0.01, 0.1, 1} are tried; for CMTF, β is fixed as 1, anddifferent tradeoff parameters αu = αv ∈ {0.01, 0.1, 1}, λ ∈ {0.01, 0.1, 1} are tried; for CSVD, different tradeoff parametersλ ∈ {0.01, 0.1, 1} are tried.{1,2,3,4,5}−14or[1,2,3,4,5]−14, a logistic link function σ (U u· V Ti· ) is embed-To alleviate the data heterogeneity of {0, 1} andded in the auxiliary data matrix factorization of CMF,(cid:10)yuiN(cid:9)M(cid:9)u=1i=1minU,VN(cid:9)M(cid:9)+ λ˜yui12(cid:10)(cid:3)rui − U u· V Ti·(cid:4)2 + αu2(cid:5)U u·(cid:5)2 + αv2(cid:5)V i·(cid:5)2(cid:11)(cid:3)˜rui − σ(cid:3)U u· V Ti·(cid:4)(cid:4)122 + αu2(cid:5)U u·(cid:5)2 + αv2(cid:11)(cid:5)V i·(cid:5)2where σ (x) =i=1u=11+exp{−γ (x−0.5)} (see Fig. 3) and different parameters γ ∈ {1, 10, 20} are tried.1For cPMF [47], we integrate the auxiliary data as follows,minU,V,Wn(cid:9)m(cid:9)u=1i=1yui12(cid:15)(cid:16)(cid:16)rui −U u· +m(cid:9)˜yu j W j·(cid:17) m(cid:9)(cid:18)(cid:18)2˜yu jV Ti·+ αu2(cid:5)U u·(cid:5)2 + αv2(cid:5)V i·(cid:5)2 + αw2j=1(cid:19)j=1m(cid:9)(cid:5)W j·(cid:5)2j=1where U ∈ Rn×d is a user-specific latent feature matrix, V ∈ Rm×d is an item-specific latent feature matrix, and W ∈ Rm×d iscalled the latent similarity constraint matrix [47]. Once we have learned the model parameters, we can predict the rating50W. Pan, Q. Yang / Artificial Intelligence 197 (2013) 39–55Table 4Prediction performance on the subset of Moviepilot data (see Table 3) of AF for ˆrui = ¯r + bu· + b·i , AF (user) for ˆrui = ¯ru·, AF (item) for ˆrui = ¯r·i , PCC[45],SVD [48], PMF [47], cPMF for constrained PMF [47], OptSpace [27], CMF-link for CMF [52] with logistic link function, and two variants of Transfer byCollective Factorization, TCF (CMTF) and TCF (CSVD). Numbers in boldface (e.g. 0.7087) and in Italic (e.g. 0.7415) are the best and second best results amongall methods, respectively.MetricsMethodsMAERMSEAFAF (user)AF (item)PCCPMFcPMFSVDOptSpaceCMF-linkTCF (CMTF)TCF (CSVD)AFAF (user)AF (item)PCCPMFcPMFSVDOptSpaceCMF-linkTCF (CMTF)TCF (CSVD)Sparsity0.2%(tr. 3, val. 1)0.7942±0.00470.8269±0.00810.8126±0.00350.7956±0.02370.8118±0.00140.8368±0.00120.8262±0.00811.3465±0.03520.9956±0.01490.7415±0.00180.7087±0.00351.0391±0.00711.0867±0.01201.0615±0.00531.0395±0.03581.0330±0.00121.0906±0.00161.0869±0.01211.7189±0.03141.3024±0.01700.9449±0.00180.9298±0.00380.4%(tr. 7, val. 1)0.7259±0.00220.7819±0.00410.7721±0.00140.7785±0.01020.7794±0.00090.7681±0.00110.7796±0.00390.7971±0.00310.7632±0.00050.7021±0.00200.6860±0.00230.9558±0.0021.0206±0.00541.0073±0.00121.0217±0.00911.0123±0.00130.9900±0.00041.0210±0.00531.0611±0.00621.0066±0.00360.9109±0.00130.9039±0.00180.6%(tr. 11, val. 1)0.6956±0.00170.7643±0.00180.7541±0.00110.7215±0.02110.7602±0.00090.7526±0.00130.7603±0.00170.7541±0.00390.7121±0.00070.6871±0.00130.6743±0.00480.9177±0.00170.9929±0.00250.9836±0.00090.9582±0.02610.9832±0.00090.9679±0.00130.9936±0.00240.9952±0.00240.9366±0.00070.8967±0.00110.8898±0.00520.8%(tr. 15, val. 1)0.6798±0.00100.7559±0.00110.7449±0.00020.6766±0.00950.7513±0.00050.7462±0.00070.7505±0.00130.7260±0.00240.6905±0.00070.6776±0.00060.6612±0.00280.8977±0.00020.9802±0.00150.9722±0.00030.9005±0.01250.9706±0.00030.9599±0.00040.9813±0.00140.9543±0.00420.9072±0.00090.8875±0.00030.8744±0.0033of user u on item i as ˆrui = (U u· +since it produces better results than using both “like” and “dislike.”˜yu j W j·/˜yu j)V Tmj=1mj=1(cid:2)(cid:2)i· . In our experiments of cPMF, we use auxiliary data of “like”4.3. Summary of the experimental resultsWe randomly sample n ratings (one rating per user on average) from the training data R and use them as the validationset to determine the tradeoff parameters (αu , αv , αw , β, λ) and the number of iterations to convergence for PMF, cPMF,OptSpace, CMF-link and TCF. For AF, PCC and SVD, both the training set and validation set are combined as one set oftraining data. The results on test data (unavailable during training) are reported in Tables 4 and 5. We can make thefollowing observations:1. For the smoothing method of average filling (AF), we can see that the best variant, ˆrui = ¯ru· +bu· +b·i , is very competitivefor sparse rating data, while the commonly used average filling methods of ˆrui = ¯ru· and ˆrui = ¯r·i are much worse. Thereare two reasons for the advantages of AF. First, average filling is a very strong baseline, especially on small and densesubsets of the Netflix and Moviepilot data. Second, PMF and cPMF show their advantages when the user-item ratingmatrix is large, e.g. the whole data set used in the Netflix competition, and can be improved if we tune the parametersin finer granularity.2. For matrix factorization methods with orthonormal constraint including SVD and OptSpace, we can see that SVD isbetter than OptSpace when the sparsity is lower (e.g. (cid:2) 0.6% for Moviepilot and (cid:2) 0.4% for Netflix), while OptSpacebeats SVD when the rating matrix becomes denser, which can be explained by the different strategies adopted by SVDand OptSpace for missing ratings. SVD fills the missing ratings with average values, which may help for an extremelysparse rating matrix, but will hurt the performance when the rating matrix becomes denser.3. For the sparsity problem in collaborative filtering, transfer learning is a very attractive technique:(a) The proposed transfer learning methods of CMTF and CSVD perform significantly better than all other baselines atall sparsity levels.(b) For the transfer learning method of CMF-link, we can see that it is significantly better than the non-transfer learningmethods of PMF, SVD and OptSpace at almost all sparsity levels (except the extremely sparse case of 0.2% onMoviepilot), but is still worse than AF, which can be explained by the heterogeneity of the auxiliary binary ratingdata and target numerical rating data, and the usefulness of smoothing (AF) for sparse data. For PMF and cPMF, wecan see that cPMF with auxiliary data is better than PMF in most cases.(c) For the transfer learning methods of CMTF and CMF-link, we can see that CMTF performs better than CMF-link inall cases, which shows the advantages of modeling the data-dependent effect using inner matrices B and ˜B in CMTF.W. Pan, Q. Yang / Artificial Intelligence 197 (2013) 39–5551Table 5Prediction performance on the subset of Netflix data (see Table 3) of AF for ˆrui = ¯r + bu· + b·i , AF (user) for ˆrui = ¯ru·, AF (item) for ˆrui = ¯r·i , PCC [45],SVD [48], PMF [47], cPMF for constrained PMF [47], OptSpace [27], CMF-link for CMF [52] with logistic link function, and two variants of Transfer byCollective Factorization, TCF (CMTF) and TCF (CSVD). Numbers in boldface (e.g. 0.7405) and in Italic (e.g. 0.7589) are the best and second best results amongall methods, respectively.MetricsMethodsMAERMSEAFAF (user)AF (item)PCCPMFcPMFSVDOptSpaceCMF-linkTCF (CMTF)TCF (CSVD)AFAF (user)AF (item)PCCPMFcPMFSVDOptSpaceCMF-linkTCF (CMTF)TCF (CSVD)Sparsity0.2%(tr. 9, val. 1)0.7765±0.00060.8060±0.00210.8535±0.00070.8233±0.02280.8879±0.00080.8491±0.01810.8055±0.00210.8276±0.00040.7994±0.00170.7589±0.01750.7405±0.00070.9855±0.00041.0208±0.00151.0708±0.00111.0462±0.03261.0779±0.00011.0606±0.01991.0202±0.00141.0676±0.00201.0204±0.00130.9653±0.01980.9502±0.00050.4%(tr. 19, val. 1)0.7429±0.00060.7865±0.00100.8372±0.00050.7888±0.04180.8467±0.00060.8147±0.00060.7846±0.00100.7812±0.00400.7508±0.00080.7195±0.00550.7080±0.00020.9427±0.00070.9921±0.00121.0477±0.00051.0041±0.05181.0473±0.00041.0125±0.00070.9906±0.00121.0089±0.00240.9552±0.00090.9171±0.00630.9074±0.00040.6%(tr. 29, val. 1)0.7308±0.00050.7798±0.00090.8304±0.00020.7714±0.06640.8087±0.01880.8122±0.00050.7757±0.00090.7572±0.00270.7365±0.00040.7031±0.00050.6948±0.00070.9277±0.00060.9834±0.00041.0386±0.00040.9841±0.08481.0205±0.01121.0066±0.00060.9798±0.00050.9750±0.00100.9369±0.00040.8971±0.00050.8903±0.00060.8%(tr. 39, val. 1)0.7246±0.00030.7767±0.00030.8270±0.00010.7788±0.05160.7642±0.00030.7864±0.00570.7711±0.00020.7418±0.00380.7295±0.00030.6962±0.00090.6877±0.00070.9200±0.00020.9791±0.00021.0339±0.00010.9934±0.06620.9691±0.00070.9930±0.00440.9741±0.00040.9543±0.00370.9277±0.00040.8884±0.00070.8809±0.0005(d) For the two variants of TCF, we can see that the transfer learning method CSVD further improves the performanceover CMTF in all cases, which shows the effect of noise reduction from the orthonormal constraints, UT U = I andVT V = I.To further study the effectiveness of selective transfer via noise reduction in TCF, we compare the performance of CMTFand CSVD at different sparsity levels with different auxiliary data of sparsity 1%, 2% and 3% on the subset Netflix data. Theresults are shown in Fig. 4. We can see that CSVD performs better than CMTF in all cases, which again shows the advantageof CSVD in transferring the most useful knowledge.There is a very fundamental question in transfer learning [41], namely when to transfer, which is related to negativetransfer [40]. For our problem setting (see Fig. 1), negative transfer [40] may happen when the density of auxiliary binaryratings is lower than that of target numerical ratings, or the semantic meaning of auxiliary binary ratings are completelydifferent from that of target numerical ratings. However, in our work, we assume that the auxiliary binary ratings aredenser than the target numerical ratings, and both ratings are related though there are some differences. Thus, under ourassumption, negative transfer is not likely to happen. In fact, negative transfer is not observed in our empirical studies.5. Related worksSVD Low-rank singular value decomposition (SVD) or principal component analysis (PCA) [5,25] is widely used in informa-tion retrieval and data mining to find latent topics [18] and to reduce noise [6]. These solutions have also been applied incollaborative filtering [24,22,7,44,48,53,29,10,27]. Among them, some works apply non-iterative SVD or PCA on a full matrixafter some preprocessing to remove the missing values [24,22,7,44,48], while other works [53,29] use iterative SVD on a fullmatrix in an expectation-maximization (EM) procedure. Still other works [10,27] take the missing ratings as unknown anddirectly optimize the objective function over the observed ratings only. Our strategy is similar to that of [10,27], since wealso take missing ratings as unknown. We use two representative methods of SVD [48] and OptSpace [27] as our baselinesin the experiments.The differences of our approach and those previously published SVD-based methods can be identified from two aspects.First, we take missing ratings as unknown, while most previous works pre-process the rating matrix to obtain a full matrixon which PCA or SVD is applied. Second, we make use of some auxiliary data besides the target rating data via transferlearning techniques, while the aforementioned works only have a target rating matrix.PMF PMF [47] is a recently proposed method for missing-value prediction in a single matrix, which can be reduced fromTCF in Eq. (6) when D = DR, λ = 0, β = 0 and B = I. The RSTE model [38] generalizes PMF and factorizes a single rating52W. Pan, Q. Yang / Artificial Intelligence 197 (2013) 39–55Fig. 4. Prediction performance of TCF (CMTF, CSVD) on Netflix at different sparsity levels with different auxiliary data.matrix with a regularization term from the user-side social data, which is different from our two-matrix factorization model.The PLRM model [57] generalizes the PMF model to incorporate numerical ratings, implicit purchasing data, meta dataand social network information, but does not consider the explicit auxiliary data of both like and dislike. Mathematically,the PLRM model only considering numerical ratings and implicit feedback can be considered as a special case of our TCFframework, CMTF for D = DR, but the learning algorithm is still different since CMTF has closed-form solutions for allsteps.CMF CMF [52] is proposed for jointly factorizing two matrices with the constraints of sharing item-specific latent features,and SoRec [39] is proposed for sharing user-specific latent features. CMF and SoRec can be reduced from TCF in Eq. (6)when D = DR, β = 0, B = ˜B = I, and only requiring one-side latent feature matrix to be the same, e.g. user side of R ∼ UVT ,˜R ∼ U ˜VT , or item side of R ∼ UVT , ˜R ∼ ˜UVT . However, in our problem setting as shown in Fig. 1, both users and items arealigned. To alleviate the data heterogeneity in CMF or SoRec, we embed a logistic link function in the auxiliary data matrixfactorization in our experiments.There are at least three differences between TCF and CMF. First, TCF is a trilinear method, R = UBVT , ˜R = U ˜BVT , wherethe inner matrices B and ˜B are designed to capture the domain-dependent information, while CMF is a bilinear method andcannot be applied to our studied problem (see Fig. 1). Second, we introduce orthonormal constraints in one variant of TCF,CSVD, which is empirically proved to be more effective on noise reduction, while CMF does not have such constraints andeffect. Finally, the learning algorithms of TCF (CSVD), TCF (CMTF) and CMF are different.DPMF Dependent probabilistic matrix factorization (DPMF) [2] is a multi-task version of PMF based on Gaussian processes,which is proposed for incorporating homogeneous, but not heterogeneous, side information via sharing the inner covariancematrices of user-specific and item-specific latent features. The slice sampling algorithm used in DPMF may be too timeconsuming for some medium sized problems, e.g. the problems studied in the experiments.CST Coordinate system transfer (CST) [43] is a recently proposed transfer learning method in collaborative filtering totransfer the coordinate system from two auxiliary CF matrices to a target one in an adaptive way. CST performs quitewell when the coordinate system is constructed when the auxiliary data is dense, and when the target data is not verysparse [43]. However, when the auxiliary and target data are not so dense, constructing the shared latent feature matricesin a collective way as used in TCF may perform better, since the collective behavior brings in richer interactions whenbridging two data sources [13,54].W. Pan, Q. Yang / Artificial Intelligence 197 (2013) 39–5553Table 6Summary of related work of transfer learning in collaborative filtering.Knowledge (what to transfer)Algorithm style (how to transfer)PMF [47] familyNMF [30] familyCovarianceLatent featuresCodebookLatent featuresAdaptiveCollectiveCST [43]CBT [31]DPMF [2]SoRec [39], CMF [52], TCFRMGM [32]WNMCTF [56]Parallel to the PMF family of CMF and DPMF, there is a corresponding NMF [30] family with non-negative constraints:1. Trilinear method of WNMCTF [56] is proposed to factorize three matrices of user-item,item-content and user-demographics, and2. codebook sharing methods of CBT [31] and RMGM [32] can be considered as adaptive and collective extensions of[50,19]. RMGM-OT [33] is a follow-up work of RMGM [32], which studies the effect of user preferences over time bysharing the cluster-level rating patterns across temporal domains. This work focused on homogeneous user feedbacksof 5-star grades instead of heterogeneous user feedbacks.Models in the NMF family usually have better interpretability, e.g. the learned latent feature matrices U and V in CBT [31]and RMGM [32] can be considered as memberships of the corresponding users and items, while the top ranking models [28]in collaborative filtering are from the PMF family. We summarize the above related work in Table 6, in the perspective ofwhether having non-negative constraints on the latent variables, and what & how to transfer in transfer learning [41].Clustering on relational data Long et al. [36,37] study a clustering problem on a full matrix without missing values, whichis different from our problem setting for missing rating prediction, while the idea of sharing common subspace or latentfeature matrices is similar to ours. Cohn et al. [15] study document clustering using content information and auxiliaryinformation of document–document link information, while the two matrices of term–document and document–document areboth full without missing values. Banerjee et al. [3] study clustering of relational data without missing values or the missingentries are imputed with zeros, while our approach takes missing values as unknown and aims for missing rating prediction.Logistic loss function in matrix factorization There are some matrix factorization methods using logistic loss functionsfor binary rating data [16,26,49]. There are two reasons why we do not use such loss functions. First, using different lossfunctions, e.g. the logistic loss function in binary PCA [16,26,49], is a vertical research direction to our focus of developingtransfer learning solutions, and we will study this issue in our future work. Second, it is difficult to justify using logistic lossfunction [16,26,49] in the factorization of the auxiliary binary rating matrix and square loss function in the target numericalrating matrix, since the objective functions are then totally different, and thus the meanings and scales of the user-specificlatent feature matrix U in two domains are not comparable (similar for V), which may cause the difficulty of knowledgesharing.We illustrate the two loss functions bellow,(cid:8)(cid:7)rui log ˆrui + (1 − rui) log(1 − ˆrui)−vs.(cid:3)rui − U u· V Ti·(cid:4)2where rui ∈ {0, 1} is the true binary rating, ˆrui = σ (U u· V Tsigmoid function (or logistic link function).i· ) ∈ [0, 1] is the predicted rating, and σ (θ) =11+exp(−θ)is theFurthermore, to address the heterogeneities of numerical ratings and binary ratings, we have scaled the 5-star numericalratings to the range of [0, 1] and then introduced a sigmoid link function (or logistic link function) instead of logistic lossfunction as follows (see Section 4),(rui − ˆrui)2 vs.where ˆrui = σ (U u· V T(cid:4)(cid:3)rui − U u· V Ti·i· ) ∈ [0, 1] is the predicted rating.2To sum up, the differences between our proposed transfer learning solution and other works include the following. First,we focus on missing rating prediction instead of clustering [36]. Second, we study auxiliary data of user feedbacks insteadof content information [52]. Third, we leverage auxiliary data from frontal side instead of user side [11] or item side [52].Fourth, we take missing ratings as unknown instead of negative feedbacks of zeros [3] in order to optimize the objec-tive function specifically on the observed ratings only. Fifth, we introduce orthonormal constraints instead of non-negativeconstraints [56] to resemble the effect of noise reduction. Sixth, we design a collective algorithm instead of an adaptivealgorithm for richer interactions between the auxiliary domain and the target domain [13,54]. Seventh, we transfer knowl-edge of latent features among all aligned users and items instead of sharing only compressed knowledge of cluster-level54W. Pan, Q. Yang / Artificial Intelligence 197 (2013) 39–55rating patterns [31,32] or covariance matrix [2]. Finally, we extend a trilinear base model instead of a bilinear model [52]to capture both domain-independent knowledge and domain-dependent effect. In summary, the first three points illustratethe novelty of our proposed problem setting, and the next six points show the novelty of our designed algorithm.6. Conclusions and future workIn this paper, we investigate how to address the sparsity problem in collaborative filtering via a transfer learning solu-tion. Specifically, we present a novel transfer learning framework of Transfer by Collective Factorization, to transfer knowledgefrom auxiliary data of explicit binary ratings (like and dislike), which alleviates the data sparsity problem in the targetnumerical ratings. Note that we assume the 5-star ratings are unordered bins instead of ordinal relative preferences. Ourmethod constructs the shared latent space U, V in a collective manner, captures the data-dependent effect via learning innermatrices B, ˜B separately, and selectively transfers the most useful knowledge via noise reduction by introducing orthonor-mal constraints. The novelty of our algorithm includes generalizing transfer learning methods in collaborative filtering ina principled way. Experimental results show that TCF performs significantly better than several state-of-the-art baselinealgorithms at various sparsity levels.The problem setting of TCF (Fig. 1) forheterogeneous explicit user feedbacksis novel and widely applicable in many ap-plications beyond the user-item representation in recommender systems. Examples include query-document in informationretrieval, author-word in academic publications, user-community in social network services [59], location-activity in ubiquitouscomputing [60], and even drug-protein in biomedicine, etc.For our future work, we will study and extend the transfer learning framework in additional areas and to include moretheoretical analysis and larger-scale experiments. In particular, we will address the “pure” cold-start recommendation prob-lem for users without any rating, sparse learning and matrix completion [27], partial correspondence between users anditems [34], distributed implementation on the MPI framework, adaptive transfer learning [12] in collaborative filtering, morecomplex user feedbacks of different rating distributions, and different loss functions [16,26], etc.AcknowledgementsWe thank the support of RGC-NSFC Joint Research Grant N_HKUST624/09 and Hong Kong RGC Grant 621211. We alsothank the anonymous reviewers for their detailed and helpful comments.References[1] Jacob Abernethy, Francis Bach, Theodoros Evgeniou, Jean-Philippe Vert, A new approach to collaborative filtering: Operator estimation with spectralregularization, J. Mach. Learn. Res. 10 (June 2009) 803–826.[2] Ryan P. Adams, George E. Dahl, Iain Murray, Incorporating side information into probabilistic matrix factorization using Gaussian processes, in: Uncer-tainty in Artificial Intelligence (UAI), 2010, pp. 1–9.[3] Arindam Banerjee, Sugato Basu, Srujana Merugu, Multi-way clustering on relation graphs, in: SIAM International Conference on Data Mining (SDM),2007.[4] Robert M. Bell, Yehuda Koren, Scalable collaborative filtering with jointly derived neighborhood interpolation weights, in: Proceedings of the 2007Seventh IEEE International Conference on Data Mining, IEEE Computer Society, Washington, DC, USA, 2007, pp. 43–52.[5] Michael W. Berry, Svdpack: A fortran-77 software library for the sparse singular value decomposition, Technical report, Knoxville, TN, USA, 1992.[6] Michael W. Berry, Susan T. Dumais, Gavin W. O’Brien, Using linear algebra for intelligent information retrieval, SIAM Rev. 37 (December 1995) 573–595.[7] Daniel Billsus, Michael J. Pazzani, Learning collaborative information filters, in: Proceedings of the Fifteenth International Conference on MachineLearning, ICML’98, Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 1998, pp. 46–54.[8] Léon Bottou, Large-scale machine learning with stochastic gradient descent, in: Yves Lechevallier, Gilbert Saporta (Eds.), Proceedings of the 19thInternational Conference on Computational Statistics (COMPSTAT’2010), Springer, Paris, France, August 2010, pp. 177–187.[9] John S. Breese, David Heckerman, Carl Myers Kadie, Empirical analysis of predictive algorithms for collaborative filtering, Technical report, MSR-TR-98-12, 1998.[10] Nicoletta Del Buono, Tiziano Politi, A continuous technique for the weighted low-rank approximation problem, in: International Conference on Com-putational Science and Applications (ICCSA), 2004, pp. 988–997.[11] Bin Cao, Nathan Nan Liu, Qiang Yang, Transfer learning for collective link prediction in multiple heterogenous domains, in: International Conferenceon Machine Learning (ICML), 2010, pp. 159–166.[12] Bin Cao, Sinno Jialin Pan, Yu Zhang, Dit-Yan Yeung, Qiang Yang, Adaptive transfer learning, in: Twenty-Fourth Conference on Artificial Intelligence(AAAI), 2010.[13] Rich Caruana, Multitask learning, Mach. Learn. 28 (July 1997) 41–75.[14] Edward Y. Chang, Hongjie Bai, Kaihua Zhu, Hao Wang, Jian Li, Zhihuan Qiu, PSVM: Parallel support vector machines with incomplete Cholesky factor-ization, in: Scaling up Machine Learning: Parallel and Distributed Approaches, Cambridge Univ. Press, 2011.[15] David Cohn, Deepak Verma, Karl Pfleger, Recursive attribute factoring, in: Neural Information Processing Systems (NIPS), 2006, pp. 297–304.[16] Michael Collins, S. Dasgupta, Robert E. Schapire, A generalization of principal components analysis to the exponential family, in: Neural InformationProcessing Systems (NIPS), 2001, pp. 617–624.[17] Paolo Cremonesi, Yehuda Koren, Roberto Turrin, Performance of recommender algorithms on top-n recommendation tasks, in: Proceedings of theFourth ACM Conference on Recommender Systems, RecSys’10, ACM, New York, NY, USA, 2010, pp. 39–46.[18] Scott C. Deerwester, Susan T. Dumais, Thomas K. Landauer, George W. Furnas, Richard A. Harshman, Indexing by latent semantic analysis, J. Am. Soc.Inf. Sci. 41 (6) (1990) 391–407.[19] Chris Ding, Tao Li, Wei Peng, Haesun Park, Orthogonal nonnegative matrix tri-factorizations for clustering, in: Proceedings of the 12th ACM SIGKDDInternational Conference on Knowledge Discovery and Data Mining, KDD’06, ACM, New York, NY, USA, 2006, pp. 126–135.[20] Chris H.Q. Ding, Jieping Ye, 2-dimensional singular value decomposition for 2d maps and images, in: SIAM International Conference on Data Mining(SDM), 2005, pp. 32–43.W. Pan, Q. Yang / Artificial Intelligence 197 (2013) 39–5555[21] Alan Edelman, Tomás A. Arias, Steven T. Smith, The geometry of algorithms with orthogonality constraints, SIAM J. Matrix Anal. Appl. 20 (2) (1999)303–353.[22] Danyel Fisher, Kris Hildrum, Jason Hong, Mark Newman, Megan Thomas, Rich Vuduc, Swami (poster session): A framework for collaborative filteringalgorithm development and evaluation, in: Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development inInformation Retrieval, SIGIR’00, ACM, New York, NY, USA, 2000, pp. 366–368.[23] David Goldberg, David Nichols, Brian M. Oki, Douglas Terry, Using collaborative filtering to weave an information tapestry, Commun. ACM 35 (December1992) 61–70.[24] Ken Goldberg, Theresa Roeder, Dhruv Gupta, Chris Perkins, Eigentaste: A constant time collaborative filtering algorithm, Inf. Retr. 4 (July 2001) 133–151.[25] Gene H. Golub, Charles F. Van Loan, Matrix Computations, 3rd ed., Johns Hopkins University Press, Baltimore, MD, USA, 1996.[26] Geoffrey J. Gordon, Generalized2 linear2 models, in: Neural Information Processing Systems (NIPS), 2002, pp. 577–584.[27] Raghunandan H. Keshavan, Andrea Montanari, Sewoong Oh, Matrix completion from noisy entries, J. Mach. Learn. Res. 11 (August 2010) 2057–2078.[28] Yehuda Koren, Factor in the neighbors: Scalable and accurate collaborative filtering, ACM Trans. Knowl. Discov. Data 4 (1) (January 2010) 1–24.[29] Miklós Kurucz, András A. Benczúr, Balázs Torma, Methods for large scale svd with missing values, in: KDDCup 2007, 2007.[30] Daniel D. Lee, H. Sebastian Seung, Algorithms for non-negative matrix factorization, in: Neural Information Processing Systems (NIPS), 2001, pp. 556–562.[31] Bin Li, Qiang Yang, Xiangyang Xue, Can movies and books collaborate? Cross-domain collaborative filtering for sparsity reduction, in: InternationalJoint Conferences on Artificial Intelligence (IJCAI), 2009, pp. 2052–2057.[32] Bin Li, Qiang Yang, Xiangyang Xue, Transfer learning for collaborative filtering via a rating-matrix generative model, in: International Conference onMachine Learning (ICML), 2009, pp. 617–624.[33] Bin Li, Xingquan Zhu, Ruijiang Li, Chengqi Zhang, Xiangyang Xue, Xindong Wu, Cross-domain collaborative filtering over time, in: IJCAI, 2011, pp. 2293–2298.[34] Tao Li, Vikas Sindhwani, Chris H.Q. Ding, Yi Zhang, Bridging domains with words: Opinion analysis with matrix tri-factorizations, in: SIAM InternationalConference on Data Mining (SDM), 2010, pp. 293–302.[35] Nathan N. Liu, Evan W. Xiang, Min Zhao, Qiang Yang, Unifying explicit and implicit feedback for collaborative filtering, in: Proceedings of the 19th ACMInternational Conference on Information and Knowledge Management, CIKM’10, ACM, New York, NY, USA, 2010, pp. 1445–1448.[36] Bo Long, Zhongfei (Mark) Zhang, Xiaoyun Wú, Philip S. Yu, Spectral clustering for multi-type relational data, in: Proceedings of the 23rd InternationalConference on Machine Learning, ICML’06, ACM, New York, NY, USA, 2006, pp. 585–592.[37] Bo Long, Zhongfei Mark Zhang, Philip S. Yu, A probabilistic framework for relational clustering, in: Proceedings of the 13th ACM SIGKDD InternationalConference on Knowledge Discovery and Data Mining, KDD’07, ACM, New York, NY, USA, 2007, pp. 470–479.[38] Hao Ma, Irwin King, Michael R. Lyu, Learning to recommend with explicit and implicit social relations, ACM Trans. Intell. Syst. Technol. 2 (3) (May2011) 1–19.[39] Hao Ma, Haixuan Yang, Michael R. Lyu, Irwin King, Sorec: Social recommendation using probabilistic matrix factorization, in: ACM Conference onInformation and Knowledge Management (CIKM), 2008, pp. 931–940.[40] Leslie Pack Kaelbling, Michael T. Rosenstein, Zvika Marx, To transfer or not to transfer, in: Neural Information Processing Systems (NIPS), 2005.[41] Sinno Jialin Pan, Qiang Yang, A survey on transfer learning, IEEE Trans. Knowl. Data Eng. 22 (10) (2010) 1345–1359.[42] Weike Pan, Nathan N. Liu, Evan W. Xiang, Qiang Yang, Transfer learning to predict missing ratings via heterogeneous user feedbacks, in: InternationalJoint Conferences on Artificial Intelligence (IJCAI), 2011, pp. 2318–2323.[43] Weike Pan, Evan W. Xiang, Nathan N. Liu, Qiang Yang, Transfer learning in collaborative filtering for sparsity reduction, in: Twenty-Fourth Conferenceon Artificial Intelligence (AAAI), 2010, pp. 230–235.[44] Michael H. Pryor, The effects of singular value decomposition on collaborative filtering, Technical report, Hanover, NH, USA, 1998.[45] Paul Resnick, Neophytos Iacovou, Mitesh Suchak, Peter Bergstrom, John Riedl, Grouplens: An open architecture for collaborative filtering of netnews,in: Computer Supported Cooperative Work (CSCW), 1994, pp. 175–186.[46] Alan Said, Shlomo Berkovsky, Ernesto W. De Luca, Putting things in context: Challenge on context-aware movie recommendation, in: Proceedings ofthe Workshop on Context-Aware Movie Recommendation, CAMRa’10, ACM, New York, NY, USA, 2010, pp. 2–6.[47] Ruslan Salakhutdinov, Andriy Mnih, Probabilistic matrix factorization, in: Neural Information Processing Systems (NIPS), 2008, pp. 1257–1264.[48] Badrul M. Sarwar, George Karypis, Joseph A. Konstan, John T. Riedl, Application of dimensionality reduction in recommender system – A case study,in: ACM WEBKDD WORKSHOP, 2000.[49] Andrew I. Schein, Lawrence K. Saul, Lyle H. Ungar, A generalized linear model for principal component analysis of binary data, in: Proceedings of the9th International Workshop on Artificial Intelligence and Statistics, 2003.[50] Luo Si, Rong Jin, Flexible mixture model for collaborative filtering, in: International Conference on Machine Learning (ICML), 2003, pp. 704–711.[51] Vikas Sindhwani, S.S. Bucak, J. Hu, A. Mojsilovic, A family of non-negative matrix factorizations for one-class collaborative filtering, in: RIA Workshopof ACM Conference on Recommender Systems, 2009.[52] Ajit P. Singh, Geoffrey J. Gordon, Relational learning via collective matrix factorization, in: Proceedings of the 14th ACM SIGKDD International Confer-ence on Knowledge Discovery and Data Mining, KDD’08, ACM, New York, NY, USA, 2008, pp. 650–658.[53] Nathan Srebro, Tommi Jaakkola, Weighted low-rank approximations, in: International Conference on Machine Learning (ICML), 2003, pp. 720–727.[54] Charles Sutton, Andrew McCallum, Composition of conditional random fields for transfer learning, in: Proceedings of the Conference on Human Lan-guage Technology and Empirical Methods in Natural Language Processing, HLT’05, Association for Computational Linguistics, Stroudsburg, PA, USA,2005, pp. 748–754.[55] Vishvas Vasuki, Nagarajan Natarajan, Zhengdong Lu, Berkant Savas, Inderjit Dhillon, Scalable affiliation recommendation using auxiliary networks, ACMTrans. Intell. Syst. Technol. 3 (1) (October 2011) 1–20.[56] Jiho Yoo, Seungjin Choi, Weighted nonnegative matrix co-tri-factorization for collaborative prediction, in: Proceedings of the 1st Asian Conference onMachine Learning: Advances in Machine Learning, ACML’09, Springer-Verlag, Berlin, Heidelberg, 2009, pp. 396–411.[57] Yi Zhang, Jiazhong Nie, Probabilistic latent relational model for integrating heterogeneous information for recommendation, Technical report, School ofEngineering, UCSC, 2010.[58] Yu Zhang, Bin Cao, Dit-Yan Yeung, Multi-domain collaborative filtering, in: Uncertainty in Artificial Intelligence (UAI), 2010, pp. 725–732.[59] Shiwan Zhao, Michelle X. Zhou, Xiatian Zhang, Quan Yuan, Wentao Zheng, Rongyao Fu, Who is doing what and when: Social map-based recommenda-tion for content-centric social web sites, ACM Trans. Intell. Syst. Technol. 3 (1) (October 2011) 1–23.[60] Yu Zheng, Xing Xie, Learning travel recommendations from user-generated gps traces, ACM Trans. Intell. Syst. Technol. 2 (1) (January 2011) 1–29.