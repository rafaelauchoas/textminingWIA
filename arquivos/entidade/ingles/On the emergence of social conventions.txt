Artificial Intelligence 94 (1997) 139-166 Artificial Intelligence On the emergence of social conventions: modeling, analysis, and simulations * Yoav Shoham a*l, Moshe Tennenholtz bl* a Robotic? Laboratory, Department of Computer Science, Stanford University, Stanford, CA 94305, USA b Faculty of Industrial Engineering and Management, Technion-Israel Institute of Technology, Haifa 32000, Israel Abstract information in a stochastic in a standard game-theoretic in economic circles, namely framework currently popular the emergence of such conventions We define the notion of social conventions framework, and identify rationality. We setting; we do so within a that of stochastic games. This in several forms; in our setting agents interact with each other through a random reevaluate information. We introduce a simple reward (HCR) . We show a class of various criteria of consistency of such conventions with the principle of individual then investigate stylized framework comes process, and accumulate their current choice of strategy and natural strategy-selection to a rationally acceptable social convention. games in which HCR guarantees eventual convergence are achieved. the efficiency with which such social conventions Most importantly, we investigate lower bound on this rate, and then present results about how HCR works out We give an analytic in practice. Specifically, we pick one of the most basic games, namely a basic coordination game (as defined by Lewis), and through extensive computer simulations determine not only the effect of applying HCR, but also the subtle effects of various system parameters, such as the amount of memory and the frequency of update performed by all agents. @ 1997 Elsevier Science B.V. in light of the accumulated rule, called highest cumulative about the system. As they do so, they continually Keywords: Conventions; Emergent behavior; Coordination; Convergence rate *This work has been partially * Corresponding 1 Email: shoham@robotics.stanford.edu. author. Email: moshet@ie.technion.ac.il. supported by AFOSR grant AF F49620-94-l-0090. 0004-3702/97/$17.00 @ 1997 Elsevier Science B.V. All rights reserved. PIZSOOO4-3702(97)00028-3 140 Z Shoham, M. Tennenholtz/Artijicial Intelligence 94 (1997) 139-166 1. Introduction such rules even agents sufficient and services, or indirectly by sharing system resources. systems, be they human (people societies or distributed in the one case, programs or processes it is crucial them and promote cooperative behavior. Without In multi-agent different agents achieve different goals, and yet these agents must information systems among goals might become unattainable (just imagine driving allowing they do not interfere We have been computing systems, in the other) aim to interact either directly by sharing In such distributed that the agents agree on certain rules, in order to decrease conflicts the simplest by any of the agents, or at least not efficiently attainable in the absence of traflic rules). These rules strike a balance between them so that tool. Some of these rules are social rules as a design designed and agreed upon ahead of time (traffic laws are an example) ; in previous work laws. However, [21,25] we investigated not all rules can be agreed upon in advance. This is either because of the design of all the society are unknown, or because that rules in advance might be computationally the society converge on a convention this is common; this is how (e.g., software) in official regulations. some aspects of this off-line design of social in a dynamic standards emerge hard. In such cases, it is often important they change over time. In addition, too much with one another. their goals, and restricting In human societies they are enshrined the characteristics long before investigating to achieve freedom fashion. individual agents occasionally How do such conventions emerge? Roughly speaking, the process we aim to study is interact with one another, and as a result one in which gain some new information. Based on its personal accumulated each agent updates its behavior over time. The complexity of this process derives from its concurrent these nature: As one agent adapts fashion. This tends to result in complex system agents update in particle physics, population genetics, and dynamics, other areas. Each of these areas has developed to carry out the investigations; we ourselves will adopt the framework of stochastic games from the economics to the behavior of the agents of those encountered it has encountered, stylized settings their behavior information, in a similar reminiscent in which literature. terms, we will be asking In general ( 1) Under what conditions (2) How efficiently As it turns out, our results on eventual convergence will be primarily analytic, whereas results of do conventions are these conventions lower bounds and empirical eventually achieved? two types of question: include both analytic emerge? and the results on efficiency extensive computer simulations. Here is the structure of our article, explained followed by a more detailed description at two levels of granularity: that appeals a brief, to game- jargon-free theoretic description, terminology. The brief description of the article is as follows: l We give a formal definition of social laws and conventions, which are essentially to agents. the restriction of choices available l We identify individual those standpoint. laws and conventions that might be deemed rational from an I: Shoham, M. Tennenholh/Art$icial Intelligence 94 (1997) 139-166 141 l We dlefine a stochastic setting as a result. We define a particular update in which agents interact with one another and update that in social rule, and show to accept a rational to lead all agents it is guaranteed their behavior certain circumstances convention. l We then investigate how fast such rational conventions might emerge. We first give in a lower bound, and then investigate the actual rate of convergence an analytic particular case through extensive computer simulations. is a more detailed overview of the article, which makes to game- terms. The reader unfamiliar with game theory should just skim the following, sec- to it once all the terms have been defined in subsequent refer back reference Here theoretic and perhaps tions. l We adopt without change l Next we consider the possibility as utility maximization. We also make reference Nash equilibria, and Pareto optimal@. We make no novel contribution the notions of games, payofs matrices, and rationality to the notions of maximin values, in this part. to a subset of the original a sub-game of the original one. We call to of limiting the agents if the restriction a social constraint; leaves only one strategy strategies of a given game, thus inducing such a restriction each agent, it is called a (social) convention. Some social constraints are consistent with the principle of individual for agents In fact, we identify several senses to accept those (assuming in any reasonable are not rational of “rational sense. Both rational from types of constraints may be of interest a design to the former. As social standpoint, fall within the general area of cooperative games in economics, whatever constraints contribution we make in this part takes the form of added concreteness, a somewhat new Iperspective, and the attendant new terminology. and but we will pay special attention social behavior”. Some constraints irrational rationality, all others do as well). in the sense that it is rational l Classical that results [ 9,12]), important is known the game the assumption realistic models. One strand of recent work in which agents engage pairwise) (specifically, inspired by models of population to relax not only even in game theory make strong assumptions; they rely is devoted in genetics that the game is common at all. Specifically, in particular, on the game being common knowledge. Much recent work in economics to investigating more economics, which has been strongly tends (e.g., knowledge, but sometimes number of models have been proposed of (typically the system perhaps about the strategies used by other agents, and, if the game is not known advance, about the game). The agents may then use that information choice of strategy, and the process that the system will converge had complete information vary widely on how agents accumulate choice of strategy. One important model of evolutionary conditions novel contribution a in some process about interactions about how well each of their strategies has fared so far, in to update their to show in fact and were acting rationally. The models within economics information, their is that of stochastic games and the notion that under certain to a Nash equilibrium. We make no to a particular global state as if the players the iterated process will converge It is then sometimes possible and how they update to this work as such. stable strategies through which (ess’s), where it is shown information they gain repeats. 142 I! Shoham. M. Tennenholtz/Artificial Intelligence 94 (1997) 139-I66 The items below constitute l We ask, in an analogous the core of our article, and are all novel. fashion, how desirable through a stochastic process. These social conventions Equilibria.2 We adopt the framework of stochastic games mentioned ever, that framework unique features tantly, we define a simple and natural strategy-selection lative reward (HCR). (Again, this rule replaces social conventions might emerge are not necessarily Nash- above. How- setting has later). Most impor- rule called highest cumu- that allows quite a few variants, and our particular for the reader familiar with ess’s, we remark (we will explain and motivate the best response rule.) these features l We show a class of stochastic games to a rational social convention. converge in which the HCR rule is guaranteed to to this last topic. We first give an analytic l We then ask how fast such social conventions might be achieved; most of our lower bound rule how fast such the simple coordination game, determine not systems such as the amount of memory and frequency of update performed by is in fact devoted article on how fast it can be expected (we use a coupon-collector-style conventions as defined by Lewis,3 only parameters, all agents. and through extensive computer the effect of applying HCR, but also the subtle effects of various to be reached given any strategy-selection argument). We then evolve in practice. We do so by picking simulations investigate 2. Games, social laws, and conventions In this section we lay out the static framework, starting with those with the notions of social laws and conventions. the standard game- theoretic notions, and overlaying 2.1. Games All definitions the article self-contained to make to be clear about in this section are standard and, in fact, very basic, in game theory. for those not familiar with this section We include theory, and also from game game (although we will take a bit more when we get to stochastic games). We start theory a by defining the standard notion of a (one-shot) number of players, each of which has available to it a number of possible strategies. 4 Depending on the strategies selected by each agent, they each receive a certain payoff. 5 The payoffs of the different agents are in general of one another, and are captured just how much we are taking in a payoff matrix. Formally: game. Intuitively, independent involves a game 2 Although in some cases they may be. Our study will differ from the related studies in economics on various other dimensions as well. the perhaps most simple coordination in AI uses the term ‘action’ rather than game. the term “strategy”; we will use both terms s In fact we choose 4 Some ‘work interchangeably. 5 Some work in AI uses the term “reward” instead; again, we will use both terms. I! Shoham, M. TennenholtdArtificial Intelligence 94 (1997) 139-166 143 Definiti~rl 1 (k-person game). A k-person game is defined by a k-dimensional matrix M, the entries of which are each a k-long vector of real numbers. Intuitively, each dimension of the matrix represents the possible players o-f the game. The jth element of the vector M(tl, feedback respectively. to the jth player if the actions taken by all the players i2,. . . , ik) represents actions of the k the are il, s’p, . . . , ik, In this article we will be concerned exclusively with symmetric games. Intuitively, symmetric get does not depend on their roles or identities. More precisely: games all players have the same strategies available, and the feedback in they Definition 2 (Symmetric game). A payoff matrix M defines a symmetric game iff the following hold: ( 1) All dimensions of M are of equal length, 1. (Intuitively: The agents all have the same strategies availably.) (2) For all il,. ..,ik(i<iij<&wherel<j<k)andl<m,n<k,if&=i,then the mth and nth elements of the vector M( il,. . . , ik) are identical. Two players who play identically is a permutation of (jt , jz, . . . , jk) then the vectors get the same payoff.) . . , ik) (3) If (it,iz,. (Intuitively: ,ik) and M(.h,jz,. .- , jk) are the co~~ponding pe~utations f%f( 6, i2, of one another. in the to the players does not depend on their roles &uitively: game.) The payoff to sy~etric IR addition to the res~iction throughout most of the paper we games (i.e., M wiil be a 2 x 2 matrix with k = 2). will concentrate on 2-person-2-choice In the remainder of the article, and unless specified otherwise, a game will be understood to be a symmetric 2-person-2-choice game, and thus will have a matrix of the following form: games, Here are two examples of games. These the phenomena of coordination the: first game describes a situation capture literature, itively, the society; his study of conventions [ 181. it is an instance of the class of coordination and cooperation, two games, which are well known respectively. in the Intu- in games as defined by Lewis in in which the goal is to reach homogeneity The second game we will consider is an instance of the well known prisoners dilem~ setting, of the sort studied, the study of cooperation. for example, by Axelrod [Z] . This game is a basic game in 144 1! Shoham, M. Tennenholtz/Artificial Intelligence 94 (1997) 139-166 Example 4 (A co~perutio~ game, also snows as prisoners’ di~ern~ 6 ) . 131 3, -3 ( -3,3 -2,-2 > (In the cooperation game we call the first strategy available to each player “cooperate” (or “c” for short), and the second ‘defect” (or “d”) .) The general question asked is, given a game, what strategies might the various players their joint of game theory, which underlies many in the sense of being utility them the highest payoff. A select. The combination strategy of its famous maximizers; number of important notions arise as a result; here are three. is that individuals that is, they will pick strategies (or joint action)+ A basic assumption are rational that guarantee selected by all the agents of strategies theorems, is called (1) (2) (3) he might consider that they are rational), that the other taking that guarantee him the highest minimal payoff, no matter what the is called maximin value. An action the maximin value is called a maximin strategy. If an agent knows what game is being played, but cannot assume players do (or ~t~rnatively those actions other agents do. The amount of this payoff that guarantees If the game the agents play is common-knowledge not be the best choice; scenario a non-optimal arise. A more appropriate notion is any joint strategy switching is among Another optimal one agent without decreasing to another strategy the most ~~fluenti~ notions notion influential if there does not exist another joint action the payoff to another. then the maximin strategy may for a given agent might be also and therefore can be assumed not to this from that is stable in the sense that no single agent benefits if all others remain unchanged. Nash equilibrium is that of Pareto optima&y. A joint action in such setting is that of a Nash equilibrium; case for the other agent(s), is Pareto to in game theory. the worst-case that increases the payoff Example 3 (continged). both strategies are maximin joint strategies on the main diagonal, Nash equilibria happen In the coordination game the maximin value obtained strategies. There are two Nash equilibria, namely and in both the payoff to each player is -1; the two is 1. These to also be the two Pareto-optimal joint strategies in the game. Example 4 (continued). “defect”, with a maximin value of -2; in the (unique) Nash equilibrium. Nevertheless, strategy that is not Pareto optimal. In the cooperation game the (unique) maximin strategy is this is also the strategy this Nash equilibrium that will be performed is the only joint 2.2, Social laws and conventions Notions such as Nash equilibria make sense in a competitive any central control. In such a setting one can reasonably setting argue, for example, that is devoid of that in the hThe reason we prefer the term “cooperation game” to “prisoners’ dilemma” is that in cooperative, or bargaining, situations, which are the sort that we will consider, there is no dilemma associated with the game. I: Shoham, M. Tennenholtz/Artficial Intelligence 94 (1997) 139-166 cooperation paradox, since the agents are better off if they both cooperate). game it is irrational for an agent to do anything but defect (and hence 145 the the authority may step in and dictate constraints. society or a system administrator in which there does exist some central authority, be it a society. In it may dictate of the individual payoffs. This is an that there may be design goals lies in in an electronic In general, since Indeed, our own primary motivation effective distributed systems. Nevertheless, that serve the goals of the individual However, consider a setting possibility in a human in the individual from a design standpoint, at all, in a way that is independent payoffs. laws as a tool for designing government this case, any constraint interesting are not reflected using social in this article we will concentrate agents. Splecifically, we consider opportuni-ty similar constraints. The constraints will be imposed and in that case compliance with the constraints The question these conditions. on constraints the following scenario. Each agent is presented with the to accept constraints on his actions, conditional on all other agents accepting if and only if all agents accept them, is guaranteed by the central authority. for the agent to accept under is what sort of social constraints are rational Definition 5 (Social law). A social to the agents. A game g and a social restriction of g to actions that are not prohibited by sl. law is a restriction on the set of actions available law sl induce a sub-game gsl of g that is the We may now define criteria according to which a social such as the three already mentioned-the r,ational. The tool we have at our disposal deemed defined on games, of values of the various Nash equilibria, strategies. For any such variable V, let V(g) denote game g. 7 At this point variables; we will be less vague about conventions. it when we discuss in the article we remain agnostic about law may or may not be consists of the various variables the set maximin value, the value of that variable in the the choice of game of social the evolution and the set of values of the Pareto-optimal and < an Definition 6 (Rational social law). ordering on the possible values of this variable. A social law sl is rational with respect to g and V if V(g) < V(g,l>. * Let g be a game, V a game variable, The reader should notice that rationality here does not imply optimality. We view the if it improves upon what acceptance of a suggestion made by the designer as rational could be obtained without such suggestion. 9 7 Recall that in this article we arc restricting the discussion to symmetric games, and so we need not worry about different players attaching different values to a game variable. R In a case that the game variable refers to a set of elements (such as the set of Nash Equilibria) we take < to be an ordering over sets. In the case of maximin, the meaning of < is straightforward. gThis does not imply of course that we view an agent who accepts a suggestion which does not improve in symmetric games) (given our interest interested upon its situation as irrational. However, we are especially in social laws which enable the agents to improve upon their situation. 146 Z Shoham, M. Tennenholtz/Arlificial Intelligence 94 (1997) 139-166 Of special interest are social laws that restrict the agents’ behavior to a particular action: Definition 7 (&dual convention). A social one particular is called a (soduE) convention. strategy law that restricts the agents’ behavior to In most of has to decide conventions. this paper we will be concerned with simple games where each agent in social from among two actions; hence, we will be mostly interested Example 3 (continued). In the coordination ventions with respect restriction game, to the maximin value, namely to the second. there are two rational restriction social con- to the first strategy and Example 4 (continued). rational with respect In the cooperation game there is one social convention lo to the maximin value, namely to “cooperate”. restriction that is 3. Stodmstic games and emergent convention results classical genetics, in particular, As was mentioned in the Introduction, in game theory make strong they rely on the game being common knowledge. Much re- is devoted to investigating more realistic models. One impo~ant in economics, which has been strongly to relax not only even that the game is known at all. Specifically, assumptions; cent work in ~ono~~s strand of recent work tends population knowledge, but sometimes models have been proposed wise) about the system about how well each of their strategies has fared so far, perhaps about used by other agents, and, The agents may process repeats. It is then sometimes possible particular global state as if the players rationally. if the game then use that information is not known to update in which agents engage in fact had comptete they gain info~ation (s~i~c~ly, the strategies the game). about their choice of strategy, and the to a and were acting to show that the system will converge information inspired by models of is common a number of in some process of (typically pair- through which the assumption that the game in advance, inter~tions The models within economics vary widely on how agents accumulate and how they update their choice of strategy. One important model is that of stochastic games that under and the notion of ~~~~~~u~~~ ~~~~~e ~t~~t~g~e~ (es’s), where it is shown certain conditions to a Nash equilibrium. Kandori et al. [ 121 show that by gathering detailed statistics about the relative success of different and adopting a rule which strategies to says the society moves in a symmetric game that is played stochastically, in the direction of the more successful the iterated process will converge information, strategies, subject I” By showing that cooperation is a rational convention we do not mean to imply that there are not other settings that sanction cooperation; see [2]. Z Shohmn, M. TennenhoWArtifwial Intelligence 94 (1997) 139-166 147 is also adopted to Nash equilibrium. the system converges to be learned by stochastic rule related work in the work of Gilboa and Matsui the strategy (which are assumed In [ 131, Kandori and Rob certain mutations, rule, where a extend some of the results of [ 121; they use the best response update that is the best strategy assuming other agents keep using player selects The best their strategies [ 91, as well response update work is as in additional by the fact it uses a model of global interactions where any agent interacts character&d stochastically with all other agents, until gathering almost full information either on the strategies #adopted by other agents or on the success of various strategies. This is quite different to interact from models of local in a more frequent manner. A only with certain neighbors and to update on global and local models of interactions detailed discussion in [ 151. We will later in the end of Section 3.1, when we discuss a novel aspect of to this point return the model we use. [ 151. The main feature of the above-mentioned the agents are assumed interactions where their behavior interactions). appear In the above discussion we mentioned some results on the emergence of Nash equi- results similar for social in obtaining to voluntarily the opportunity libria. We are interested After all, the process we described were presented with same strong assumptions the game ‘being known ing rational. We now ask whether social conventions, might emerge also without they might emerge games mentioned particular laws and conventions. for adopting a social law (the one in which agents the it relied on and on agents be- and perhaps even rational ones, Specifically, we ask whether to the framework of stochastic that framework allows quite a few variants, and our give up some options) made theory; in particular, commonly known), these strong presuppositions. through a stochastic process similar :setting has somewhat unique as classical work in game (though not necessarily above. However, features. 3.1. From static to stochastic games Definition 8 (n-k-g stochastic social game). An n-k-g stochastic social game consists of a set of’ n agents, a k-person game g, and an unbounded tuples of k agents selected from a uniform distribution over the n given agents. l1 sequence of ordered social game describes a process the particular game. In each iteration in the game in a synchronous in the game g in one of the rounds of n-k-g, Intuitively, a stochastic k agents meet and play by the agents who participate selected from among freedom we have in defining update rule). We adopt two principles the actions available to play the action-selection function in this regard: in which, repeatedly, fashion. When agent random the actions are selected i is i must select an action is what (which we will also call the for it in the game g. An important question l Obliviousness. The selection function cannot be based on the identities of agents or the names of actions. l1 The uniform-distribution in the paper can be generalized suitably. assumption is made to simplify the discussion, but it can be relaxed and the results 148 E Shoham, M. Tennenholtz/Artijkial Intelligence 94 (1997) 139-166 l Locality. The selection function is purely a function of the agent’s personal history; in particular, it is not a function of global system properties. in the following definition: these principles We capture function Definition 9. A selection taken by the agent and the corresponding local if it is a function of the history of actions by the other agents encountered cases it is required corresponding is local if it is a function of the history of actions is semi- taken In both lead to a by the agent, and the corresponding of the names of actions payoffs received. A selection taken, the corresponding of the actions selected. that a permutation in the history permutation payoffs. function actions Notice that a local selection function obeys both the locality and the obliviousness rule; function selection important but allows is oblivious, in the update the above principles that its mathematical in particular, we can admit definition. We are interested to refer to the ac- is rule which has all agents drive on the right in cases in which we cannot anticipate if we know that the coordination principles. A semi-local tions performed by the agents encountered. The intuition behind perhaps more in emergent rational social conventions in advance the games that will be played. For example, problem will be that of deciding whether to drive on the left of the road or on the right, we can very well use the names “left” and “right” the trivial update the type of coordination problem we are concerned with is better typified by the following example. a collection Consider at a plant for five years, at which time a new collection of parts arrive that must be assembled. The assembly requires using one of two available attachment widgets, which were introduced three years ago (and hence were unknown to the designer of the robots five years ago). the Either of the widgets will do, but if two robots use different ones then they incur high cost of conversion when it is time for them to mate their respective parts. Our goal is that the robots about this example is that five years ago the designer could have stated rules of the general form “if in the future you have several choices, each of which has been tried this many times and has yielded the designer could not, however, have referred to the specific choices of widget, since those were only to use the same kind of widget. The point then next time make the following choice”; that have been operating this much payoff, of manufacturing two years later. to emphasize immediately. invented Instead, robots learn type identities the update in the rules This explains why we do not want on using agent to rely on action names. The rules (e.g., “if you see Robot 17 use a then do the same, but if you see Robot 5 do it then never is similarly motivated by the dynamic nature of the society; agents drop in and in advance. (such as in prohibition widget of a certain mind”) out of the society, denying acknowledge We definitely Head Robot), and have them be treated in a special manner. We are very interested the role of agents with special structure will not be distinguishable of successful role of personal in the role of organization [ 291)) but even with those it is still the case in a rich setting most of the agents the emergence ignore to anticipate membership to single out certain agents the ability the designer that it is often useful in such “faceless masses”, and completely In this article we investigate joint actions only in this fashion. in particular identities. identities (and the E Shoham, M. TennenhoWArtifzcial Intelligence 94 (1997) 139-166 149 The above discussion so as to have reliable global statistics about framework which inspired concentrated mainly on the obliviousness of locality. Interestingly, systems put forward above, assumes in similar settings. that agents participate this requirement In particular, requirement. Finally is not the work in sufficiently many the system. This bias has its in [ 11. This global character [ 301, and the economic model, and in particular in population genetics in the area of mathematical [ IO]. It is not our claim that global information sociology in a society; counter-examples it is made in the absence of this global and our aim is to home in on this element. We will return to this topic when in other fields, and, in particular, abound. However, decision making system models to dynamic discussed to motivate the requirement we need met by most dynamic in economics interactions roots in the biological the global fitness function encountered of the update rule is even more blatant ecologies in the work on computational is never available is clear that much of individual information, we compare our setting economics. to an individual 3.2. The Highest Cumulative Reward rule on one particular to start investigating [24] we useful action-selection We are now ready results of experiments with a number of such rules. Here we reported on preliminary will concentrate local update rule, called Highest Cumulative Reward. There are a few reasons we concentrate on this rule. First, it is a very natural one. Second, in stochastic settings. Finally, past experiments we will see that, despite (In the following definition, games.) have shown it to be particularly its simplicity, recall that in this article games are by default 2-person-2-choice this rule gives rise to nontrivial phenomena. effective rules. In According Definition 10 (HCR). HCR), an agent switches in the latest m iterations action in the same time period. to a new action is greater to the Highest Cumulative Reward update rule (or from that action iff the total payoff obtained than the payoff obtained from the currently-chosen The parameter m in the above definition denotes a finite bound, but the bound may vary. As we mentioned, HCR is a simple and natural update rule. It is, however, clearly to consider update rules that use not the only such rule. In particular, a weighted accumulation Indeed, we have the results obtained, both analytic and experimented with such rules as well. However, experimental, were not qualitatively for HCR, and hence rule. A more detailed discussion of other update rules can be we stick with the simpler found rather than simple accumulation. from those obtained it would be natural of feedback in [ 241. different Clearly, HCR is a local update rule. (For the reader familiar with the relevant that HCR stands in contrast its best response in economics, we remark which the agent applies all other agents.) We now would like to understand how HCR affects the emergence of rational social conventions, and cooperation. its effects on the evolution of coordination to a somewhat broader In fact, we are able to show a result that applies to the set of strategies adopted by, essentially, and, in particular, literature to the best response update rule, in 150 K Shoham, M. Tennenholtz/Artijicial Intelligence 94 (1997) 139-166 class of games, which games social agreement games. include the coordination and cooperation games. We call these Definition 11. A social agreement game is a symmetric game g with matrix in which x, y, u, u # 0, either x > 0 or y > 0 and either u < 0 or v < 0; if both x > 0 and y > 0 then x = y. ‘* It is easy to see that the cooperation game and the coordination game are both social agreement games. The theorems below larger m is much that m > n > 4, and that the payoffs assumptions, we have: than the entries that refer to HCR assume that the parameter (memory bound) in the payoff matrix of the game. We also assume representation. With these in g have finite decimal Theorem 12. I3 Given an n-2-g stochastic social agreement game, placing no con- straints on the initial choices of action by all agents, and assuming that all agents employ the HCR rule, the following holds: l For every E > 0 there exists a bounded number M such that if the system runs iterations then the probability that a social convention will be reached is for M greater than 1 - E. l Once the convention is reached, it will never be left. a If a social convention is reached then it guarantees to the agent a payoff which is no less than the maximin value that was initially guaranteed. l Furthermore, if a social convention exists for g that is rational with respect to the maximin value, then the social convention reached will be rational with respect to maximin. The above theorem shows that stable conventions local it discusses also the evolution of stable conventions which are local update rule In particular, our results show that using a purely can emerge using the a purely (with respect to maximin) would emerge in the coordination update rule. In addition, not Nash-Equilibria. a rational stable convention and cooperation games: Corollary 13. The HCR update rule guarantees eventual emergence of coordination and of cooperation, that is, rational conventions in the respective games. rewards, and thus one that does not allow a constant offset of all numbers. the notions of “positive” and “negative” l2 It will be perhaps a bit jarring and “negative” whether are not trivially dismissed. Furthermore, one could perhaps (related t3 Proofs appear for example, in Appendix A. ideas appear, synthesize one dynamically to some readers to see a formulation that depends on notions of “positive” It is debatable rewards are defensible; we believe that at the very least they to do away with an objective notion of zero, on average payoffs encountered so far is beyond (for example) this discussion the scope of our paper. even if one wished based in [ 231). However, 3.3. The eficiency of evolution: a lower bound The above results shed light on the eventual emergence of social behavior, but they about is devoted is attained; this behavior the efficiency with which say nothing of this article evolution will refer to the number of iterations This measure of efficiency of stochastic global number of interaction periods which is required interaction period consists of a huge number of iterations the agents gather bound on the efficiency of convention definition the remainder to this question. Our study of the efficiency of convention a desired behavior. in models the Each such (in our terminology) where lower evolution. This will be obtained by the following about each other. We start by presenting interactions. The measure of efficiency from the one which has been studied to reach a Nash-equilibrium. in that work has been and theorem. for obtaining is different information a general required 14. Let g be a social agreement social game, and the n . (n - 1) games Definition stochastic might be played at that iteration. Define X,(t) the number of games for a player that T(n) be a function update rule R, and some distribution that R guarantees E[ X,, (T( n) ) ] converges game. Consider (possible t of an n-2-g that that contains in a payoff Let social convention. (of iterations). Given a local on the initial actions of the agents, we will say if the emergence of a rational social convention that associates with each n a number the one obtained by a rational to be a random variable that might be played iteration agent t and that result interactions) in iteration after T(n) iterations, is less to 0. than Roughly speaking, we measure how far the system like this distance to be as close is from reaching a rational social in a minimal to 0 as possible convention. We would number of iterations. there Theorem Assume action by any particular convention 15. Let g be a social agreement game, and let R be a local update rule. ” for starting with any particular the emergence of a rational social is some non-zero agent. in the related n-2-g games iterations, then T(n) = a( n log(n) ). constant probabilig [f R guarantees in T(n) 4. The evolution of coordination: Experimental results At this point we seem to be converging on an understanding of the dynamics brought about by HCR; at least for social agreement games, we have a guarantee of eventual emergence lower bound on how fast we can expect to arrive at such a happy occasion. It would be natural finer and finer lower and upper to expect bounds, (if one exists), as well as a cautionary to a rational social convention investigations would provide increasing our understanding that subsequent of HCR. IJ Similar results hold for semi-local rules. 152 Z Shoham, M. TennenholtdArtifcial Intelligence 94 (1997) 139-166 Unfortunately, this has not been our experience. What we found that it appears extremely difficult rather specific properties of the particular games being played strongly update function. We arrived at this conclusion which yielded been (fully) that not only had not been anticipated, explained mathematically to arrive at general even after the fact. the point with the two games highlighted Let us illustrate results instead was that so results at the level of the flavor the dynamics through extensive computer simulations, but in fact have not yet and games. Both are instances of social agreement games, and hence subject section, and yet the practical in the previous In the case of the coordination above, the coordination radically different. the two has been cooperation to the upper and lower bounds presented experience with game, rate that approaches the HCR applications. the theoretical to be very the HCR rule not only rule proved led to the emergence of convention, lower bound. inefficient, rendering it useless In contrast, in the cooperation but it did so at a game for most practical social convention In the remainder to the coordination of this article we restrict our attention game, evolves. l5 Unless and explore various aspects of the efficiency with which coordination evolution, we will refer to the emergence stated otherwise, when we refer to convention of rational in an n-2-g stochastic social game, where g is the coordi- nation game. More specifically, when we say that a set of agents reached a convention, and we mean game, by any results other constant x > 0. In this section we take the default value of m (in the definition of HCR) ; to be greater than the number of iterations we will be explicit when we depart from this default. in that set adopt the same strategy. All of our discussion (i.e., agents refer to their full history) the constant 1 in the coordination remain valid when we replace that the agents Unless stated otherwise, the experimental results appearing in this section refer to experiments with 100 agents starting with random consists of many given number of iterations. trials, each of which consists of a run of the stochastic game for a initial strategies. Each experiment 4.1. The effect of update frequency The first parameter section we assumed and modification we consider concern update In the that each agent updates l6 its behavior at each iteration. less frequently? This condition might of the system, or alternatively might be selected their behavior frequency. limitations if agents update internal previous What happens be imposed by voluntarily to impose greater stability on the system. A plausible a priori intuition about the effect of delaying the application of the update function might be as follows. If one does not delay at all, agents may react on the basis in the system. If one delays too of insufficient much, agents may be preventing there is some optimal, middle-of-the-road from updating even when appropriate. So perhaps to a lot of thrashing course of action. information, leading I5 The efficiency of cooperation I6 By “update” we mean the application of the update function; is discussed evolution further in 1261. the result need not be a change in action. E Shoham, M. Tennenholtz/Art@ial Intelligence 94 (1997) 139-166 153 Success . . . 50 100 150 - 200 Update delay . Fig. 1. The effects of update frequency. Particularly, in this setting this intuition is not born out. We found then of update decreases, frequency Our results are illustrated by Fig. 1. In this figure, the x coordinate describes between in which update number of trials from among 4000 95% of the agents reached a convention. is performed, while trials of 1600 iterations the efficiency of convention iterations the y coordinate describes each in which more that when the evolution decreases. the distance the than 4.2. The ejTect of memory restarts interesting is restarted, the memory We investigated from time to time. When in Section 4.4. One type of limited memory the effects of memory size on the efficiency of convention evolution. two forms of limited memory; one is treated in this section, and the other We consider that is is a memory one will be treated restarted the agents’ current strategies (the ones they will now start with) are not forgotten, but previous history is. This might for a short while from time in systems which stop operating be in particular to time. For example, a society might be interested only in to forget what they have exactly some periods of the year, where agents are assumed seen in the previous periods although strategy. evolution as a function of the frequency of We investigated iterations where the memory memory is restarted decreases, is evolution to the distance between illustrated the number of trials iterations where the memory from among 4000 trials of 800 iterations each, in which more than 85% of the agents reached a convention. in Fig. 2. The x coordinate of this graph corresponds restarts. We found that when the distance between is restarted. The y coordinate describes the efficiency of convention the efficiency of convention in a particular coordination they still remember decreases. This their current (latest) then The reader may be tempted result; however, full memory to treat this as an “obvious” is not always an advantage. Sections 4.3 and 4.4 will provide some examples; here is another example. We ran an experiment their memory always their strategy. In that case the evolution of convention was even and only after changing in 3298 from among 4000 trials of 800 more efficient than in the case of full memory; in which agents restarted 154 E Shoham, M. Tennenholtz/Artijicial Intelligence 94 (1997) 139-166 * . * - ..*t** ’ l . . . . - . Success 3000 I 2500 . l . . Fig. 2. The effects of memory restarts, iterations each, more than 85% of the agents reached a convention (while with complete information this was true of only 3010 of the trials.) We will explain why full memory is not always an advantage in the following sections. We have so far varied update frequency and memory independently; we now show that these two parameters interact. Consider the results from Section 4.1, where we showed that the rate of convention evolution is a monotonic increasing function of update frequency. We now show that decreasing memory blocks the degradation of convergence with the decrease in update frequency. Specifically, in this experiment we adopted the memory-restart model, and varied together the memory-restart frequency and the update frequency; that is, at the end of each window each agent updated its choice according to HCR for that window. The general result we obtained is that when then it update becomes infrequent (there is a long delay between strategy updates), is better to restart the memory from time to time than to rely on the whole memory. Our results are illustrated in Fig. 3. The x coordinate of this figure corresponds to the update frequency, which is equal to the number of iterations between consecutive memory restarts. That is, in this case, we had a single interval which served both as the update frequency and the memory restart frequency. The y coordinate corresponds to the number of trials from among 4000 trials of 1600 iterations each in which 95% of the agents reached a convention. It is illuminating to compare Fig. 3 to Fig. 1 (where ; when the update frequency drops below about 100 iterations, full memos it becomes better to use the statistics of only the last window than to rely on the entire history. is ~surn~) The rationale of the above result may be explained as follows. When agents have update delays they start relying on unreliable old info~ation. By restarting its memory the agent succeeds in getting rid of some of this unreliable info~ation. One of the implications of the above result, from a design perspective, is that in systems where there are update delays the designer may wish to tell the agents to restart I! Shoham, M. TennenhoWArtiJcial Intelligence 94 (1997) 139-166 155 Success 3500. 3000 2500. - .: . . - * . - . . :. .- . 2000. 1500. 1000. 500. I 2 50 100 150 Update delay 200 Fig. 3. The case in which update frequency = memory restart frequency. from their memory In the next section we will see that when there are no update delays even a more concrete kind of advice/result the evolution of conventions. to time in order to speedup can be supplied/obtained. time 4.4. Limited memory windows A more continuous keeps a limited window window, We have considered the last m iterations agent remembers in those. form of limited memory into its past experience, is one in which each agent at each time that and bases the HCR rule on only two forms of windows, one in which an agent remembers in which it participated in a meeting, regardless of whether and another it participated in which the in a meeting the last m iterations, Our results of these two experiments are illustrated the x coordinate describes in Figs. 4 and 5, respectively. In the size of the memory window, and trials of 800 each, in which more than 85% of the agents reached a convention. Note that, is surprisingly, and therefore in both cases it pays to forget, though some minimal memory to the number of trials from among 4000 (in the first case this minimum is in fact equal to 2 iterations, in the second case). is that the old history of the agents information, than to rely on old refers to. On the other had, too short memory the agents enough sampling of what is going on in the system, and may it may be better not and as a result is less adequate as part of the data a decision corresponds both of these figures the y coordinate iterations somewhat essential this can be seen more easily The rationale of this result new the relatively information may not enable lead to inefficient behavior. A good choice of the memory window while applying HCR will give us in fact an size update rule whose behavior is between 2n to 3n (where close More specifically, given that there are n agents who adopt HCR with a memory window as in Fig. 5), we 3n (where is close it is the number of agents) gives us the above-mentioned of 0( n . log(n)). to the overall number of iterations, is in fact a speed of convergence to optimal. The case in which to optimal behavior, which the memory this number refers 156 E Shoham, M. Tennenholtz/Art@cial Intelligence 94 (1997) 139-166 3000 I 2800 2600 3500 t 3000. 2500. . * . . Fig. 4. Limited memory (latest observations). *... .* . . . . * . . . . . * * * . . . . 2000. . 200 400 600 800 Memory Fig. 5. Limited memory (latest iterations). that all of the agents reach a convention observed (when we vary the number of agents.) The optimality from Theorem 15. The important point is that HCR with an appropriate window can be supplied convention iterations stems from the above fact and limited memory rule that will enable an efficient in a system where there are no update delays. to the agents as an update after less than 3n . log(n) evolution One implication of this result is that it enables the designer a concrete useful update rule which will enable conventions are no update delays. This may be of course most useful in situations where conventions are essential but can not be determined in advance. to supply the agents with to evolve rapidly when there 4.5. Further discussion of HCR The previous sections have discussed several results about the efficiency of convention evolution. Our measure of efficiency has been convention after a given number of iterations. the number of agents which adopt a In particular, our graphs show the number I: Shoham, M. Tennenholtz/Art@cial Intelligence 94 (1997) 139-166 157 C!onforming agents 60. . .* . . . 500 1000 1500 Fig. 6. The shape of convention evolution. Z~OOIterations of trials adopt a similar qualitative used. in which, after a particular number of iterations, (most popular) strategy is greater results do not change when different the number of agents who threshold. Our thresholds and numbers of iterations are than a particular In addition is obtained; this number are quite simple time. The explanation of the process; in which then, this number increases, the numbers of agents adopting different of the parameters. As it turns out, the dynamics in the beginning the speed of these phenomena to the above, one may be interested also in the dynamics of HCR for fixed assignments for any selection of the parameters. The number of agents who adopt the more popular strategy increases may have little fluctuations decreases until a convention along appears strategies are equally divided, mostly when selection of agents. The fact that the increase and it is simply a result of the random the end of the process in the number of conforming is explained b:y the fact that it takes time to a non-conforming agent to be selected by the this by Fig. 6, in which HCR is used by an agent with memory of process. We illustrate and with no update delays. 3000 (i.e., We consider in the to the number of iterations, and beginning of the process. The x coordinate corresponds to the most popular the y coordinate strategy the case where the strategies are equally divided among igreater than the maximal number of iterations), to the number of agents conforming is as follows. The fluctuation is more modest in that point. corresponds the agents towards agents 4.6. More complicated decisions from among The coordination social conventions option option should be chosen. What happens among more two available options, a bit? How does the number of options convention game captures a situation where a selection among a pair of rational as a selection of an has to be made. This can also be considered about which from than affect the efficiency of if the agents have to agree on an option that is, on something more complicated two possible options, without an a-priori agreement conventions) evolution? (potential than 158 I! Shoham, M. Tennenholk/Art~ciaI intelligence 94 (1997) 139-166 In order to answer the above question we use the following observation: whenever an game, it can interpret agent performs a particular coordination it encountered. I, we can say that the agent observed Having quasi-local For example, inte~r~tation the above update rules only, we can define: strategy and gets a particular feedback in a 2-person-2-choice if the agent performs it as an observation of the strategy used by the agent strategy a and gets a feedback of that another agent used the strategy a as well. to for the feedback, and assuming we restrict ourselves Definition 16. The External Majority Adopt strategy strategy and remain with your current observed i if so far it was observed in other agents more often than it. (EM) update rule is an update rule which says: than any other in a case no other strategy has been in other agents more often strategy We can show: Lemma 17. EM coincides with HCR in an n-2-g stochastic the coordination game. social game, where g is the above Given coordination 2-choice than there are more our study would be to discuss EM games. lemma, HCR and EM are isomorphic in the context of 2-person- games. Hence, although EM and HCR do not coincide when of two choices game, a natural the coordination in in the context of 2-person-s-choice extension coordination Notice that the coordination the payoff matrix of the game, as well as are able to observe game makes perfect sense, and it is of major the behavior of agents interest, they encounter. Moreover, even when agents are able to observe the if the agents know they encounter, but do not have agreement on the names of strategies behavior of agents they should adopt) we still get (i.e., the designer can not just tell them which strategy problem. This is due to the full symme~y we have a most interesting in Section 3 will still be valid in this case, here. For example, [ 181. In the sequel we as well as many other examples will therefore assume a restriction only to quasi-local update rules, where the agents can observe and fund~ent~ the example we presented in the study of coordination the behavior of agents We would like to mention is lost. We will still be interested power of our setting in the sense that they may update their behavior at each iteration each of which response update now refer to the strategies executed by the other agents in the past. update rules, some of the in local adaptation of the agents, in the strategies of the other agents, as in case of the best but the update rules may in the economics the agent learns rule discussed (and not in periods, literature), they encounter. that by allowing quasi-local As mentioned, we would like to discuss the case in which the number of potential conventions is greater than 2: Definition 18. An extended cuordi~atia~ game is a symmetric 2-person-s-choice where and it is --x otherwise. game, if they perform similar actions, the payoff for both agents is x > 0 if and only Z Shoham. M. Tennenholrz/Art@cial Intelligence 94 (1997) 139-166 159 . . . . . . . * *..* 2.5 3 3.5 4’.‘4,+,. (log of) potential conventions Fig. 7. The effects of the number of potential conventions. evolution Our general tions decreases In addition we find that the absolute amount of success in convention in less than logarithmic to decrease by factor of 2, we need to increase a factor of more number of potential conventions results point not affected results are as follows. What we find is that adding more potential conven- fashion. the efficiency of convention evolution decreases evolution by the speaking, our is evolution the number of potential conventions than 4; for them to decrease by a factor of 3 we need to increase fashion: For the number of successes of convention by a factor of more than 8. l7 Intuitively fact: the efficiency of convention in a less than logarithmic rithmic scale the number of potential conventions, while the y coordinate describes number of successful trials trials of 800 iterations each. than 85% reached a convention) (more in the number of potential conventions. in Fig. 7. The n coordinate describes on a loga- the from among 4000 to the following encouraging too badly by an increase results are illustrated Some specific The message of this result from a designer’s perspective appropriate, systems where emergence some structured rule, the emergence of useful conventions conventions the number of potential of more complex kind of conventions strategy) may be an interesting subject for future research. is that, by supplying an is not hopeless also for complex the is more is (e.g., where two. Naturally, the convention itself than 5. Discussion and related work Several lines of research are related to our work. These computational ecologies, quantitative include work in population sociology, machine genetics, learning, statistical mechanics, and mathematical Recent work in mathematical economics. like to re-emphasize was discussed some of the major differences between our study and the related work in mathematical in some detail economics in the previous is the one most related sections. We would to our work, and I7 We have verified these basic results also in the case of limited memory. 160 E Shoham, M. Tennenholtz/Arti$cial Intelligence 94 (1997) 139-166 settings interaction it is able its behavior related economic the other agents. This is of course quite different at each point of the matching in this paper. We also concentrate In addition, our study concentrates literature, but our adaptation process its behavior after some period of interactions the agent need not be aware of the strategies evolution. We also note that the efficiency of convergence the agents, where each period consists of a gathering of statistical in which the other agents, but to obey a local adaptation [ 151 which has been is local; I8 the agent it is rule process. One taken by on issues such as the efficiency in the above- [7] refers to the number of periods of interaction information the type of efficiency on the effects of various basic parameters the effects and other parameters. Although memory plays a (as the related to update to gather statistics about to update is that in our study economics. The model we use is a model of global borrowed from is not assumed assumed where other point the other agents. of convention mentioned among about studied of the adaptive of update delays, memory role in part of the related work in economics well as of the other parameters discussed evolution solutions we are interested of social conventions Although work to our work, in this paper would not be complete without at least a brief description the of discussion the work carried out in other related fields. Each of these works involve a setting with multiple elements cells, or agents), which local changes. The questions usually asked center repeatedly undergo around local changes, in. In particular, that are not Nash equilibria. scheme on the emergent behavior of the system. We study relatively global system properties has not been discussed. The final comparative in this paper) on the efficiency of convention some of our results refer to the emergence [ 3 11, the effects of this parameter point concerns the type of they are called particles, and phase transitions. time out of these that emerge over in mathematical is the most restrictions, individuals, economics interesting (whether related simple from such as equilibria tempting It is often to try to carry over lessons from one setting to another. Indeed, for example, work in quantitative genetics. However, the actual dynamic systems some of these areas were inspired by one another; sociology was inspired by work in statistical mechanics, inspired by work in population in spirit rather than in detail; most part quite different, in them result with our own framework; our framework to make such borrowing interested work, anticipating work in these other areas. then turned out to be sufficiently different impossible, technical and also very sensitive in quite different cross influences, in understanding and work in economics was to be in the various areas are for the in the sense that even small changes system dynamics. This has also been our experience these inspirations have tended initially we had hoped to borrow results from other areas, but from any of the others so as or at least very difficult. We are still very much connections with these other areas and our own but at this point all we will do is briefly describe Statistical mechanics models are a powerful tool for explaining a variety of phenomena in physics. An important the Ising model can be in -l/l [ 141, In a typical state, and which are organized in that area goes under the general name of Ising model we have a set of spins, each of which into some fixed spatial arrangement family of models ‘* The reader should be careful not to confuse at this point global interaction with global adaptation. k: Shoham, M. Tennenholtz/Artificial Intelligence 94 (1997) 139-166 161 (that among limited interactions is in some configuration local representing the spins, and a component sequence or a two-dimensional the effect of some global magnetic grid). At each point in time (such as a one-dimensional the system is, the spins each have a particular value), and this system has a certain measure energy, or entropy. The energy has a component is sometimes representing among omitted) spins for the energy of the is usually x . y, where x and y are the values of system willl include neighboring is defined over the the likelihood of the system actually being space of all configurations, which determines in any particular properties: to the values of the neighboring spatially spin having a particular value is sensitive only of the values of spins that are the sum of all multiples spins. In terms of this energy a probability spins, and is independent field. The interaction reimoved from it. This probability spins; a typical to neighboring of a particular the probability configuration. independence has strong distribution distribution formula (that The Ising model has proved useful for the investigations (that such as spontaneous magnetization same value), but it is also abstract enough example, as “opinions”, differing opinions”, government”. in some work within quantitative the energy between the orientation individual and is, a majority of spins ending up with to have motivated other applications. sociology of various physical properties the For [ 301 the spins were interpreted individuals with field as “the opinion of the spins as “tension among of the magnetic As described, the Ising model does not provide a dynamical in other fields. One is quantitative shifts over time within .augmented the inspiration (e.g. differential) to include a dynamical to predict opinion also provided the that idea creates a “computational that it does not provide system over time; what it does instead system. This is also true for the more elaborate have been found applications been used mechanics based on framework its spirit to quantitative mechanics. The notions used having conflicts predictions on the behavior of those “computational in some situations). These multi-agent (“cooperation”) A precise continuous (“competition”). the existence frameworks borrow a powerful sociology, strategies identical equations is define stable (i.e., that describe in the sense system, the evolution of the states of the low energy) framework of spin-glass. However, both system. These dynamic models have also sociology, where the models have [ 301. Statistical large populations to computational ecology [ lo] ; this work is of many agents in an advanced computerized similar ecology”. A computational in is developed and analyzed using the tools of statistical framework, there are “strategies” of individual as well as its disadvantage, agents, the utility of due to resource is built, which allows several (such as chaotic behavior framework ecologies” tool from statistical mechanics, but flavor; agents), or “non-mechanical” they have a heavily “non-local” the dynamics as a result speak abou.t how certain global statistics change over time (such as the average number of cooperating its local state on the basis of its current is quite unlike our the dynamics of the atomic changes are the basis for change, own framework, where and any statistical properties are derived from these. genetics local state and/or history. This of course rather than about how an individual and work in urt$ciul Work in population life inspired by agent changes [ 1,3,19]) it (e.g., [ :16,20] ) is closer in this sense. Here we have a set of individuals, (e.g., to ours 162 X Shoham, M. Tennenholtz/Art@cial Intelligence 94 (1997) 139-166 includes is computed, the individual each belonging generation (which each agent individual will survive usually between generations pairs of individuals individual from, the types of the parents. to one of several types. The system evolves in “generations”; in each evolves in a way that is defined by its type and the environment the other agents), and at the end of the generation applying some given fitness function. The probability the “fitness” of that an into the next generation is proportional to its fitness. Additionally, in the population (“the offspring”), whose a process of “recombination” (the “parents”) may combine takes place, in which some to produce a new in general be defined by, but different type will This setting is thus more the frameworks discussed the fitness forces, function. The fitness is computed on the basis of global system properties, than and the reproductive flavor. An important global component selection to all agents equally. For example, local, or mechanical, lier; the activity of each agent within a generation transition-oriented, automata-like ever, namely external applied a typical definition of the fitness of an individual with an opinion be the proportion of individuals element perhaps of course may other differences limited memory, and our particular turns out to have a strong the deepest difference between exist, the earlier ‘~opinion” example, in a population would the same opinion. This global is the population genetics setting and our own; but history, the notion of an accumulated incIuding ear- process have a remains, how- unspecified influence on the dynamics of the system. stochastic process of encounters.) in the population having function, which if we consider represents and is (This The model used in population genetics has strongly true of work published influenced work in mathematical in recent years. This recent work in in spirit to our work, and therefore we discussed is the closest economics; mathematics it in detail previously_ this is especially economics The way the agents update rules used in the reinforcement learning that we have a multi-agent some similarity with work on learning automat our work borrows a framework of agent mathematical much different the study of emergent from existing studies economics literature their behavior in our setting, has some similarity with [ 11 I), and the fact system where agents behave based on local feedback has [ 221. Neverthel~s, as we mentions, literature learning (e.g., interactions which in the recent inspired by theoretical biology. This makes our study learning. Moreover, our objective, in reinforcement is common [ 271. The research rational social conventions, Our work is clearly relevant systems where social behavior before, as well as to theories of social commitments we have mentioned social reasoning dynamic emergence of social reasoning of our current work, and may be a subject may be relevant has been widely discussed can consider they may use when encountering is different as well. to previous work on Artificial Social Systems which [ 5,171 and is concerned however with is an emergent property of the system. The the scope topic which is concerned with the concept of negotiations, which [ 4,6], One ability which each other in the stochastic setting; t9 based on these the situation where agents may have a limited negotiation and complex social commitments and decentralized AI literature for future research research. Another in the distributed in this paper are beyond for further reported I9 Some of the results in [24] are concerned with a limited form of such extension. K Shoham. M. TennenholtdArtQicial Intelligence 94 (1997) 139-166 163 the agents may learn for example about available interactions considered conventions, where cooperative work is concerned with the emergence of such cooperative related they have not im the past. Finally, since our work in concerned with the emergence of social [ 8,321 are devised. However, since our it becomes more to work on cooperative games and mechanism design work on complex dynamic to the above-mentioned to multi-agent it is related interactions strategies solutions, solutions systems. 6. Summary We used the framework of stochastic social games gence of rational we concentrated of coordination efficiency Besides social conventions on the emergence of rational problem, and supplied and the efficiency of that process. social conventions in a most basic results on the emergence of conventions the emer- In particular type and its in order to investigate literature the model from the economics and work in machine for a class of games. the novelty of our work, which we have previously discussed, we believe learning, that it also creates a bridge between work in economics We borrow among agents, which is a most popular and dominant model for agent interactions. On the other hand we borrow in order their strategies. As a to capture result, we get a combined local update rules are used to update an agent behavior and the model of global importance framework may lead to additional [ 151 for a survey) are taken to be of major of our learning the fact that agents use local update communities, we believe and fruitful cross-fertilization. in a model of global interaction. Since both the local updates from the AI literature to update ideas of reinforcement to the corresponding that the introduction framework where for stochastic [28] rules interactions interactions [ 11,22,28] (see Appendix A. Proofs of theorems Proof of Tlheorem 13. Recall the structure that the payoff matrix of a social agreement game has in which either x > 0 or y > 0, either u < 0 or u < 0, and if both x > 0 and y > 0 then x = y. We prove the theorem by case analysis. We can assume without that game is a special case of the case in which y < 0, game is a special case of the case in which y > 0, the proof for these two cases; proofs for the other cases loss of generality x > 0. Noti.ce that the cooperation u < 0, u > 0, and the coordination u < 0, u < 0. We will provide can be obtained in a similar fashion. Consider will restrict always exists a pair of agents with identical the case where y > 0, u < 0, u < 0. In this case a rational social convention the behavior of all agents strategy. First, observe that there that the following strategies. Then, notice to a similar 164 Z Shoham, M. Tennenholtz/Art$icial Intelligence 94 (1997) 139-166 in g(n) and leads to a rational their past. Afterwards, (all agents will adopt is defined as follows: a pair of agents p = l/f(n) the same strategy) are bounded by an exponent of the form nS where s is polynomial size) and n. The process process can be generated with a probability convention f(n) and g(n) m (the memory with the same strategy forget step continues members convention for M = k. g(n) will not be reached Taking k > - log(e) yields social iterations, where both in (i, j) is selected and meet each other until all of the rest of the agents last j. The it meets all the to a rational social runs if the system that a rational social convention in the society. It is easy to see that this process will bring the same strategy). As a result, then the probability i meets a member x # time j, and i meets a new x until (all agents will adopt iterations (not all of the agents will adopt the same strategy) in a loop where at each the desired result. then meets is at most eWk. . f(n) the case where y < 0, u < 0, u > 0. In the sequel we will refer to an agent and to an agent who adopts social convention will restrict is as the structure of the case where y > 0, u < 0, u < 0, but the basic process will two that there will be at least to be cooperative. The structure of the proof In this case a rational this, the process will include in its beginning Consider agents agent. selects agents. regarding of creating two non-cooperative In order to guarantee a pair of cooperative the strategy c as a “cooperative” agent who adopts d as a “non-cooperative” all of the agents the proof now change. This process will now at first guarantee cooperative a procedure procedure latter pair meet until the former pair of cooperative until will meet sequentially. cooperative. In order following procedure: will become non-cooperative selected and meet each other until process will end by an encounter other. to make the non-cooperative the other agents will forget this agent cooperative (non-cooperative) as well, and in which agents. agents agents and two additional the former pair will forget its past. Afterwards to participate In a second stage this pair of cooperative their past, and then pairs of non-cooperative This will create a society where at most one agent (if no such pair exists). This let the agents, and the process selects in a meeting. This will create a agents will meet agents is non- the agent until it agents will be their past. The agents meet each the process will end with agent will meet a cooperative then a pair of cooperative the rest of the agents will forget the two non-cooperative The above process will take place with probability and will guarantee all of the agents will become cooperative, where appropriate p = l/f(n) iterations bounds can be given as for the coordination for f(n) game, and the desired result can be obtained. and g(n). Hence, the number M can be that after g(n) exponential calculated The results for the other cases are determined adopt a similar strategy S, where the payoff for the joint strategy implies than 0. This (given of the game g will restrict will eventually is greater will never be dropped convention where y > 0 we have that x = y, and given above, we get that if a rational process. q for both agents the payoffs similarly. In all of these cases all agents (s, s) that social conventions will be reached, and that they the structure of HCR). Notice also that any rational social strategy that if both x > 0 and discussed in the related the behavior of agents is positive. Hence, given the structure of emerged conventions it will also emerge to a particular convention exists I! Shoham, M. Tennenholtz/Artijicial Intelligence 94 (1997) 139-166 165 that did not participate in any iteration of n-2-g until Proof of Theorem 15. Let Yn (i) be a random variable which contains agents iteration see that E[:X,(i)] particular, E[ X, (T( n) )] 2 k . E[ Y,(T( n)) ] for every n. Hence, that if E[ I’, (T( n)) ] converges order of n . log(n). The probability T(n) = (rz - 1) . f(n) the number of i. It is easy to for some constant k > 0 and for every n and i. In to show is at least of the agent will not be chosen along to 0 as a function of n, then T(n) that a particular is bounded by 2 k-E[Y,(i)] it suffices iterations (1 (n A J+-‘).f(“) which converges and hence have f(n) log). This gives us the desired there is no convergence > 0.5 . log(n) to ep2f(“), If eW2fcn) > l/n then we will get that E[ Y,(T( n)) ] > 1 to 0. But, in order to have em2fcn) < l/n we must the natural loss of generality (where we consider without lower bound. Cl for strategy let us denote i of a given agent j. Notice to the number of times j met an agent which used 1 - i if ci is larger payoff that j met an agent which used i minus its (j’s) the strategies by 0 and 1, that ci the number of i, when to than cl-i, but cc - cl = (number of times you Proof of ILemma 17. For ease of exposition and let ci be the accumulated equals times HCR, an agent chooses met 0 when you had 0 minus number of times you met 1 when you had 0) -(number of times you met 1 when you had 1 minus number of times you met 0 when you had the number of times you met l), which equals 1. Hence, we get that the comparison payoffs coincide with the comparison in other agents. This gives us the desired result. the accumulated the number of times the different strategies were encountered the number of times you met 0 minus strategy was i. According between between 0 References [I] L. Altenberg genes, 1. The reduction principle, Genetics (November transmission, 1987) 559-572. and M.W. Feldman, Selection, generalized and the evolution of modifier [2] R. Axelrod, The Evolution of Cooperation (Basic Books, New York, 1984). [ 31 A. Bergman and M.W. Feldman, More on selection for and against recombination, Theoret. Population Biology 38 (1990.) 68-92 [ 41 A.H. Eland and L. Gasser, Readings in Distributed Artificial Intelligence ( Ablex, Norwood, NJ, 1988). [ 51 C. Castelfranchi, Commitments: in: Proceedings to groups and organizations, from individual intentions 1st International Conference on Multi-Agent Systems ( 1995) 41-48. and J.-P Mtlller, Decentralized AI (North-Holland, Amsterdam, [ 61 Y. Demazeau [7] G. Ellison, Learning, [ 81 D. Fudenberg 191 1. Gilboa and A. Matsui, Social stability and equilibrium, Econometrica 59 ( 1991) 859-867. [ 101 B.A. Huberman in: B.A. Huberman, and J. Tirole, Game Theory (MIT Press, Cambridge, MA, 1991). and coordination, Econometrica 61 (1993) 1047-1071. and T. Hogg, The behavior of computational local interaction, ecologies, 1990). ed., The Ecology of Computation (Elsevier, Amsterdam, 1988). [ 111 L.P. Kaelbling, Learning in Embedded Systems (MIT Press, Cambridge, MA, 1993). [ 121 M. Kandori, G. Mailath and R. Rob, Learning, mutation and long equilibria in games, Mimeo, University of Pennsylvania, Philadelphia, PA ( 199 1). 166 E Shoham, M. Tennenholtz/Art@cial Intelligence 94 (1997) 139-166 ] 131 M. Kandori and R. Rob, Evolution of equilibria in the long run: A general theory and applications, Mimeo, University Pennsylvania, Philadelphia, PA ( 1991) [ 141 R. Kinderman and S.L. Snell, Murkov Random Fields and their Applications (American Mathematical Society, Providence, RI, 1980). [ 151 AI? Kirman, Economies with interacting [ 161 J. Koza, Genetic evolution and co-evolution agents, SFl Working Paper 94-05-030 ( 1994). of computer programs, in: C.G. Langton, C. Taylor, J.D. Farmer and S. Rasmussen, eds., Artificial Life II (Addison-Wesley, Reading, MA, 1992). [ 171 H.J. Levesque, P.R. Cohen and J.H. Nunes, On acting together, in: Proceedings AAAI-90, Boston, MA (1990). [ 181 D. Lewis, Convention, A Philosophical Study (Harvard University Press, Cambridge, MA, 1969). [ 191 U. Liberman and M.W. Feldman, A general for genetic modifiers of recombination, reduction principle Theoret. Population Biology 30 (1986) 341-370. [20] K. Lindgren, Evolutionary and S. Rasmussen, phenomena in simple dynamics, eds., Artijcial Life II (Addison-Wesley, Reading, MA, 1992). in: C.G. Langton, C. Taylor, J.D. Farmer [21] Y. Moses and M. Tennenholtz, On computational aspects of artificial social systems, in: Proceedings DAI-92 ( 1992). [22] K. Narendra and M.A.L. Thathachar, Learning Automata: An Introduction (Prentice Hall, Englewood Cliffs, NJ, 1989). [ 231 A. Schwartz, A reinforcement undiscounted 10th International Conference on Machine Learning, Amherst, MA ( 1993). learning method for maximizing rewards, in: Proceedings [24] Y. Shoham and M. Tennenholtz, Emergent in multi-agent in: Proceedings 3rd International Conference on Principles of Knowledge initial experimental conventions systems: results and observations, Representation and Reasoning, Cambridge, MA ( 1992) 225-231. [25] Y. Shoham and M. Tennenholtz, On the synthesis of useful social laws for artificial agent societies, in: Proceedings AAAI-92, San Jose, CA ( 1992) 276-281. [26] Y. Shoham and M. Tennenholtz, Co-learning and the evolution of social activity, Technical Report STAN-CS-TR-94-1511, Department of Computer Science, Stanford University, Stanford, CA ( 1994). [ 271 J.M. Sichman and Y. Demazeau, Exploiting social reasoning to deal with agency level inconsistency, in: Proceedings Ist International Conference on Multi-Agent Systems (1995) 352-359. [ 281 R.S. Sutton, Special [29] M. Tennenholtz, On computational Issue on Reinforcement Learning, Machine Learning 8 (3-4) social laws for dynamic non-homogeneous ( 1992). social structures, J. Experimental and Theoret. Artificial Intelligence 7 (1995) 379-390. [ 301 W. Weidlich and G. Haag, Concepts and Models of a Quantitative Sociology: The Dynamics of Interacting Populations (Springer, Berlin, 1983). [31] HP Young, The evolution of conventions, Econometrica 61 (1993) 57-84. [ 321 G. Zlotkin and J.S. Rosenschein, A domain theory for task oriented negotiation, in: Proceedings IJCAI- 93, Chambery, France (1993) 416-422. 