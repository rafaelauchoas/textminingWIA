Artificial Intelligence 175 (2011) 1122–1152Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintThe local geometry of multiattribute tradeoff preferencesMichael McGeachie a,∗, Jon Doyle ba Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA 02139, USAb Department of Computer Science, North Carolina State University, Raleigh, NC 27695-8206, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 2 March 2009Received in revised form 10 August 2010Accepted 10 August 2010Available online 2 December 2010Keywords:Decision theoryPreference representationMultiattribute tradeoffsCeteris paribus reasoningExisting representations for multiattribute ceteris paribus preference statements haveprovided useful treatments and clear semantics for qualitative comparisons, but havenot provided similarly clear representations or semantics for comparisons involvingquantitative tradeoffs. We use directional derivatives and other concepts from elementarydifferential geometry to interpret conditional multiattribute ceteris paribus preferencecomparisons that state bounds on quantitative tradeoff ratios. This semantics extends thefamiliar economic notion of marginal rate of substitution to multiple continuous or discreteattributes. The same geometric concepts also provide means for interpreting statementsabout the relative importance of different attributes.© 2010 Elsevier B.V. All rights reserved.1. Building value functions from preferences and tradeoffsKnowledge of someone’s preferences can be used to make decisions on their behalf. Following the work of von Neumannand Morgenstern [35], direct and complete elicitation of preferences and their representation in the form of utility functionshas enabled decision analysts to advise decision makers on how to decide specific questions. To go beyond manual construc-tion of specific decision models, and to automate decision analysis in a way that applies in a broad range of mundane andfleeting human activities, one must find richer representations that permit making decisions with imprecise, incomplete,and accumulating information about preferences.We pursue this end by presenting semantics for several different types of preference statements that build on earliersemantics for ceteris paribus preferences (preference other things being equal) [38,14]. We focus on quantitative tradeoffstatements, such as “having a CPU speed of 3 GHz is at least twice as important as having 4 GB memory and a 250 GB diskin my new computer purchase.” Such statements say that some outcomes that satisfy one condition (CPU speed of 3 GHz)are preferred to some outcomes that satisfy another condition (4 GB memory and 250 GB disk), and also bound belowhow much better the former are than the latter. We provide semantics for numerous types of statements of this charac-ter, including multiattribute tradeoffs that relate more than one attribute at a time; tradeoffs over discrete or continuousdomains; conditional or unconditional tradeoffs; and quantitative or purely qualitative comparisons. We also treat relatedtypes of statements about attribute importance, such as “increasing CPU speed is at least twice as important as increasingmemory and disk size in my new computer purchase.” Such statements say that the weight given to some attribute orattributes in a decision should be greater than that given to other attributes.Computing expected utility of actions requires a numerical utility or value function that represents preferences in thesense that the numerical representation assigns a greater value to one outcome than to a second outcome if the preferencestatements entail that the first outcome is preferred to the second. Building on earlier constructions [32], we accompany* Corresponding author.E-mail addresses: mmcgeach@csail.mit.edu (M. McGeachie), Jon_Doyle@ncsu.edu (J. Doyle).0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.11.014M. McGeachie, J. Doyle / Artificial Intelligence 175 (2011) 1122–11521123the semantics for ceteris paribus preferences statements with companion algorithms for compiling utility or value functionsfrom collections of multiattribute tradeoff statements.1.1. Decision-analytic methodologyOur methodology seeks to extend traditional decision analysis by relaxing assumptions and restrictions on the form andcharacter of the preference information captured in the preference acquisition process. In particular, we aim for represen-tations of preference information that permit automation of the process of constructing decision models starting at earlierpoints in the process than has been possible with traditional modeling methods.In traditional decision analysis methodology [33,25], a human decision analyst does considerable work in understandingand analyzing a decision informally before the point at which the tools of traditional decision theory [35,34,19] are broughtto bear. The decision analyst first interviews the decision maker about what dimensions or attributes of the decision are ofconsequence. The decision analyst then assesses utility functions on each of these dimensions by standard gambles or othermeans. This assessment requires the decision maker to think carefully about the upper and lower bounds of each dimension,to consider his or her attitude toward risky hypothetical choices, and to determine which attributes are utility independentof other attributes. The relative importance of each dimension must then be assessed, at which point the decision analystcan combine the results into a multiattribute utility function that models the preferences of the decision maker.This traditional methodology has the virtue of producing considered and complete decision models appropriate to thedecision at hand. It also, however, demands much effort on the part of the decision maker by requiring careful attentionto complexities of the decision that might not have been considered previously, and that perhaps should not be answeredimmediately with only the information currently on hand. All this makes the interviewing and analysis steps lengthy andtime-consuming in many cases, so that one mainly applies decision analysis in detail to repetitive decisions in which the costof analysis can be amortized over many individual decisions, and to one-off decisions of great import, such as governmentalpolicy or complicated life-or-death medical decisions.We seek to begin the process of formalization earlier than with traditional decision analytic techniques. The traditionalformal techniques apply once the analyst has done much of the work needed to identify the dimensions along which pref-erences vary. Our preference semantics allows one to formalize partial information about preferences. Such information maybe stated and captured naturally without any requirement that the stated preferences involve independent or fundamentalattributes, and without explicit indications of utility independence or preferential independence. In our view, such inde-pendence relations properly reflect conclusions reached during the analysis of some decision, as inferences from the wholebody of stated conditions on preferences, rather than presuppositions underlying the entire analysis. We thus address theidentification of dependencies and independencies among attributes in our numerical-compilation methods, which performanalyses that yield model-structuring conclusions akin to those reached by a human analyst at the point at which thehuman analyst begins quantitative assessment procedures. Our approach thus supports protracted incremental deliberationprior to the introduction of traditional formal decision analysis, and helps automate the initial steps previously relegated toinformal reasoning that produce the formal framing of a problem.1.2. IllustrationTo illustrate these ideas, we describe a fictitious scenario in which Mike, a human, informs an automated personalshopping agent of his preferences so that it can watch for online deals on computer hardware he may find attractive. Mikewill buy a new laptop if there is a good deal on one he likes. Mike does not try to tell the agent all about his preferences atthe start, as without detailed knowledge of what is currently available he might not yet have developed definite preferencesregarding the options. Mike instead gives his agent information about his preferences bit by bit as he learns more aboutwhat preferences are germane.His agent retrieves a list of laptops for sale at various vendors’ websites. Seeing the list, Mike decides that, with respectto price and speed, a $1500, 3 GHz machine is preferable to a $2000, 3.4 GHz machine, other things being equal. Thispreference sets up a tradeoff between price and speed, so the agent then filters out the results that are very expensive eventhough they are somewhat faster than average. Thinking about it a little more, Mike decides that the first machine is muchbetter than the other one, in fact that it is at least five times better.Looking at some of the expensive options with many attractive features, Mike then realizes that adding features andadding ounces of weight at the same time is not what he wants. Mike tells the agent that Weight is more important thanPrice. The agent readjusts its evaluation of options, and shows more laptops ordered by weight, with several attractivelight-weight options at the top of the list.Mike sees that there are some good machines available that are light, moderately powerful, and within his price range,but realizes that he must decide how big a screen and what resolution he needs to do his work on the road, since thisscreen on a 4.5 pound machine for $1700 is better than aadversely impacts the price and the weight. Mike decides a 12(cid:3)(cid:3)screen on a 6 pound machine for $1800. This suffices to order the remaining options in a way that satisfies Mike, and14ends up earmarking a machine for later consideration and probable purchase.(cid:3)(cid:3)Our intent in this paper is to provide meanings for the sorts of statements Mike makes and rationales for the conclusionsMike draws. We do not treat the hard problems of preference elicitation, of coaxing Mike to reveal his preferences through1124M. McGeachie, J. Doyle / Artificial Intelligence 175 (2011) 1122–1152introspection, interview, or observation. We instead focus on how to make use of the information that Mike does express,which differs from that required by traditional decision analysis.For example, Mike never explicitly considers whether some attribute or other is fundamental or independent of otherattributes. Indeed, at some point he might discover that computer manufacturers offer differing amounts of memory de-pending on which operating system is installed. Mike also does not think too carefully about the relative weights that mightbe assigned to different dimensions in a hypothetical value function. He knows that one product is much more attractivethan the other, and makes guesses as to how much more attractive, guesses that he might later revise to produce a differentset of options and final decision, as in [13].1.3. Semantical approachTo accompany the methodology of incremental interpretation and revision of preference information, we interpret trade-off preference statements as constraints on the shape of a utility or value function, and in particular, as constraints on thepartial derivatives in different regions of the space of outcomes.For example, a decision maker could state that “Increased longevity is five times as important as decreased price,”a sentiment which one might express in the context of repainting one’s home, and this is interpreted as indicating thatvalue increases in the increasing lifetime direction five times faster than value increases in the decreasing price direction.The tradeoff interpretation presented in this very simple example is one treated in standard economics as the notion ofmarginal rate of substitution between the two commodities longevity and price. The partial derivative of the utility function uover commodity bundles with respect to an attribute α, is known as the marginal utility of α, and represents the marginalimpact of this commodity on utility. To compare the impact on utility due to changes in commodity α relative to commod-ity β, one divides the marginal utility of α by the marginal utility of β. This ratio is invariant under monotone increasingtransforms of u, and is variously called the rate of commodity substitution of β for α and the marginal rate of substitution of βfor α, and expresses the amounts of α and β that can be exchanged without changing desirability [24]. Thus in the formalmarginal rate conception, one would restate “Increased longevity is five times as important as decreased price” as “Increas-ing longevity by one unit of longevity would be as good to me as decreasing price by five units of price.” To stipulate thatv makes the marginal rate of substitution of β for α at least r everywhere, we can choose v so as to satisfy the constraintthat(1)(cid:2)((cid:4)a)∂ v∂ v∂α∂βat each outcome (cid:4)a.((cid:4)a) (cid:2) rIn practice, however, one cannot always rely on tradeoffs to concern only two decision attributes. For example, a personbuilding a computer might state a preference for AMD and Overclocked over Intel and Cheaper, other things being equal. Tohandle such preferences, our semantics extends the approach taken in inequality (1) to complex multivariate, discrete, andqualitative comparisons by using the more general notion of directional derivative.A directional derivative D(cid:4)x(v) of a function v : Rn → R evaluated at a point (cid:4)a ∈ Rn is the derivative along a vector withbase (cid:4)a and direction (cid:4)x. Furthermore, the directional derivative of a function v in the direction of vector (cid:4)x is equal in valueto the inner product ∇ v · (cid:4)x of the gradient of the function with (cid:4)x. This quantity measures the increase of v in the directionof (cid:4)x. Thus if we want to talk about constraints on the directional derivatives of the value function, or rates of increase inthe directions of (cid:4)x and (cid:4)y, we can state constraints of the form∇u((cid:4)a) · (cid:4)x (cid:2) r∇u((cid:4)a) · (cid:4)y.(2)In the following, we show how such constraints can, in turn, be represented as inequalities among directional derivatives ofvalue functions over continuous or discrete attributes.1.4. Plan of the paperSection 2 summarizes past approaches to representation of preference information, along with traditional independenceconcepts used in analyzing the structure of preferences, including the notion of generalized additive independence usedin our construction algorithms. Section 3 presents background concepts and definitions that will be useful throughout,namely the familiar concepts of preference orders, value functions, and what it means for a value function to representa preference order. This section also introduces a language for partial descriptions of outcomes called “bundles” (of goods)together with useful operations on bundles and descriptions of bundles in vector terms. Section 4 introduces an extension offirst-order logic for expressing specifications of preferences and tradeoffs in a way that fits the methodology of incrementalspecification and interpretation. The subsequent sections present the semantics of the preference and tradeoff extensions.Sections 5 through 7 constitute the semantical core of the paper. Section 5 provides meanings for a range of types ofpreference and tradeoff statements including tradeoffs between concrete alternatives described partially, over many or fewattributes (Section 5.2), and tradeoffs over continuous and discrete attributes (Section 5.4). Section 6 presents a semanticsfor qualitative ceteris paribus preferences that adapts the semantics of [14] to the new setting. Section 7 applies the sametechniques to interpret specifications of relative importance judgments of attributes, over many or few attributes.M. McGeachie, J. Doyle / Artificial Intelligence 175 (2011) 1122–11521125Section 8 presents one method for constructing value functions from the preference statements analyzed in earliersections. This method updates one developed in earlier work [32] both to support the enhanced representation of qual-itative preferences and to reflect the addition of tradeoff preferences. Section 9 shows how our tradeoff preferences can becombined with the popular CP-net representation for conditional qualitative ceteris paribus preferences. We provide straight-forward methods for enhancing a CP-net with quantitative tradeoffs. Section 10 concludes with a review of our contributionsand a discussion of some promising avenues for future work.2. Related workOur objective is to lessen the difficulty of decision analysis by allowing the human decision maker to express preferencesin forms he or she finds natural. Our work builds on a large and varied literature attempting to make the elicitation, specifi-cation, use, and applicability of utility functions faster, simpler, easier, and broader. Some that literature concerns operationalmethods for elicitation of preferences, particularly in the case in which fundamental attributes for characterizing the deci-sion have already been identified and one must formulate questions about the relative desirability of different combinationsof attribute values. Other parts of the literature concern languages for expressing preferences. Our main purpose in thepresent work is to define a specification language for qualitative and quantitative ceteris paribus preferences and quantitativetradeoffs that allows direct expression of preferences and their dependence on other portions of knowledge, along with amethod of compiling a utility function consistent with the set of those statements. This section briefly illustrates how ourwork combines ideas and harnesses benefits of prior work on preference representations.In pursuing an approach that seeks to understand the structure of attributes that underlie preferences from expressionsof preferences about these, we follow on substantial work in the fields of multiattribute decision theory and conjointmeasurement theory. Multiattribute decision theory [25] takes utility function representations of the preferences of adecision-maker and studies mathematical methods for decomposing these functions into weighted combinations of subfunc-tions corresponding to different attributes or sets of attributes. Theorems of multiattribute decision theory allow inferencesabout several forms of independence of attributes from the subfunctions that make up an overall utility theorem (see, forexample, [22,36,39]). We draw directly on the underlying framework of multiattribute decision theory in the following de-velopment, and focus on using differential properties to specify the utility functions being modeled. Conjoint measurementtheory [27] takes orders over combinations of attributes as fundamental, and studies when one can use these to identifyseparable orders over attributes. Conjoint measurement theory formulates families of axioms relating orders over individualattributes to orders over combinations of attributes, with various conceptions of “cancellation” corresponding to differentforms of lifting of orders, along with statistical methods for determining when observed data fits these axioms. We drawsome connections to the theory of conjoint measurement in the following, but more work would be useful here, as ourunderlying methodology exhibits something of the same spirit in seeking to take facts about preferences among differentsets of attributes, in our case assorted subsets of attributes rather than all combinations of all attributes as in conjointmeasurement theory, and then relate these to preferences over individual attributes and to possible complete orders overall attribute combinations.2.1. Logics of preferenceResearchers have long considered logics of preference, whereby an entity can specify statements in some logical languageencoding preference information. Logical statements of the form p (cid:8) q, meaning formula p is preferred to formula q, can begiven varying interpretations. One of those interpretations, termed preference ceteris paribus, allows preferences that apply“keeping other things equal.” Such a preference might be “Other things being equal, I prefer white wine to red wine.”These preferences capture the intuitive idea that other unmentioned qualities might affect the decision making process. Forexample, in a situation where white wine turns out to be much more expensive than red wine, and hence all else is notequal, this preference would not apply.Ceteris paribus preferences were introduced formally by von Wright [37], and later studied in semantic and inferentialterms by Hansson [23] and Doyle, Shoham, and Wellman [14]. This work describes a set of qualitative preferences that canbe used to partially order outcomes described by logical variables. Other researchers have added complexities to basic ceterisparibus statements, including the possibility of expressing preferential independence between attributes using a specializedsyntax [2].A simple list of ceteris paribus preferences allows reasoning with partial preference information, complex qualitativepreferences, and include information about preferential independence of various attributes or dimensions in the domain.2.2. Conditional preference networks (CP-nets)Also using a form of ceteris paribus preferences, come a series of graphical preference networks using different typesof preference or utility independence conditions to define the network structure. These start with the CP-net [6,5] (herethe abbreviation “CP-net” stands for “conditional preference” networks, not “ceteris paribus” networks). Nodes in the graphcorrespond to single attributes and the directed edges in the graph represent preferential dependence between attributes.In this system, one lists the preference for a particular attribute given the values of the attribute’s parents in the graph, and1126M. McGeachie, J. Doyle / Artificial Intelligence 175 (2011) 1122–1152may then determine the resulting preferences over elements from the entire domain. The CP-net representation combinesthese explicit preferences with explicit preferential independence and dependence, achieving efficient reasoning in manycases. Subsequent work builds upon this base in different ways, adding representations of more complex preferences.Brafman, Domshlak and Shimony [9] considered CP-nets with tradeoffs, or TCP-nets, an extension of CP-nets that allowsexpression of trade-offs between attributes. TCP-nets allow one to stipulate that one preference is more important than an-other preference, conditioned on the value of some other attributes. This allows a TCP-net to represent preferences betweenoutcomes that vary on two attributes, while including attribute prioritization in the representation.Wilson [40] uses a circumscription-like semantics for augmenting conditional ceteris paribus preference statements inCP-nets. This representation addresses approximate reasoning, stating preferences where all else is held almost equal, by(cid:3)[W ] means that given value v for attribute V , andallowing the specification of some irrelevancies. The expression v : x (cid:8) x(cid:3)a list of attributes W , we prefer value x to xfor attribute X , as long as all unmentioned attributes are held equal, whileattributes W are allowed to be equal or unequal.To take the CP-net idea and develop it in a different direction, Boutilier, Bacchus, and Brafman [4] introduce a quantitativeextension to CP-nets called UCP-nets. A UCP-net allows a combination of utility independence information with ceterisparibus semantics and explicit numeric utility values assigned to each preference. As [4] observe, such an approach iswarranted in cases where uncertainty is an issue, probabilities are known, and reasoning in terms of expected utility isrequired.Conditional preference networks are conceptually similar to Bayesian networks in many ways. In a more direct de-velopment from Bayes nets, La Mura and Shoham have proposed combining Bayesian networks with a type of utilityindependence networks into what they call Expected Utility Networks (EUNs) [28]. This representation differs from CP-nets by using a type of multiplicative preference independence, rather than additive independence, which allows preferencereasoning analogous to probability reasoning and results in a representation of expected utility. In [28] preference judg-ments are stated in multiples of the value of an arbitrary reference outcome, i.e. “being healthy and wealthy is three timesas desirable as being merely wealthy.”In another development with roots in both Bayesian networks and preference networks, Gonzales and Perny [20,21]discuss generalized additive independence (GAI) networks. Generalized additive independence [19,1] is a model that decom-poses a utility function into functions of independent, but overlapping, sets of attributes. Given some domain, these arestructurally similar to the clique-trees used in inference algorithms of Bayesian networks, and similar message-passing al-gorithms are used in utility computations in GAI nets. The GAI framework, in general, allows somewhat more complicatedutility models than simple additive independence allows.Networks with other utility independence assumptions and conditions have been considered. Engel and Wellman [17]define CUI-nets for conditional utility independence networks, which have a different decomposition than CP-nets, leadingto smaller representations when additive independence does not apply. This is a treatment of quantitative utility functionswhere each node potentially has a utility function based on the parents of that node, elicited using standard methods frommultiattribute utility theory. This system handles both complementary attributes and substitution between attributes.2.3. Other preference machineryOther avenues of preference research have resulted from adding something like utility weights to propositional logicformulae and then reasoning about the relative utility of outcomes that obtain. For example, systems based on possibilisticlogic [15] attach a “priority” to formulae in propositional logic, where priorities form a totally-ordered set. In this type ofapproach one infers a preference for a condition p over a condition q from the priorities assigned to p and q, with the for-mula given the higher priority preferred to the formula with the lesser priority. These systems are less related to the currentproject than systems employing explicit preference representation and tacit preferential independence assumptions. They dohowever share our intention to reason with partial preference information by encoding an arbitrary set of user statementsand then inferring preference orders from that set. More related is the work of Lang et al. [29] in which propositions aregraded with numerical “utility” values, and in which utilities assigned to situations reflects the sum of positive and nega-tive rewards of each satisfied goal proposition. This allows comparison of situations in which multiple goals are satisfied.Adding weights together creates preferences over outcomes or choices of actions, allowing an implicit utility function to beincrementally and partially specified. In very simple cases, one might regard the ratio of utilities assigned to goals as corre-sponding to marginal rates of substitution. Although an exact interpretation along these lines would be complicated by theprovision of the model to specify cardinal gaps in utility values for goals and the nonmonotonic provisions of the semantics,the overall result of constructing preference orders from this additive basis exhibits a similar spirit to the constructions wemake from different semantical bases.These approaches both base preference specification on comparisons to an assumed standard of comparison or“numéraire” in the language of economics. While there is nothing problematic about the notion of numéraire in stan-dard market economics, that is the case because one can choose any market good as the standard of comparison, whether itis an ounce of gold, a dollar, or a bushel of wheat. In contrast, starting out with a given standard of comparison, especiallyintangible ones like units of currency, presupposes many unstated comparisons of that standard with things familiar to themodeler. Our approach attempts to avoid this problem by making it possible to state direct comparisons between sets ofattributes, from which one might construct a numéraire as in market theory, from which one might identify preferentialM. McGeachie, J. Doyle / Artificial Intelligence 175 (2011) 1122–11521127or utility dependencies between attributes, and with which one can express overriding and context-dependent preferences.One can always still use some agreed numéraire as an attribute in phrasing comparisons, one need not coerce all compar-isons into that restricted form. Eliciting preferences with respect to currency values is a common technique, but in lightof the problems people have putting dollar (or mark, or franc, or yen) values on some things, empirical work would seemneeded to determine whether people would always find it easier than stating direct comparisons.Part of our goal in the current work is to compile a set of preference judgments, naturally stated, into a utility functionfor efficient reasoning, and one example of such a system is the proposal of Domshlak and Joachims [12]. Therein, theycompute a value function from a few preference statements (of the form x (cid:8) y, where x, y are formula over a space ofn binary attributes) using a support vector machine (SVM). The SVM kernel implicitly translates the n attributes into aspace of size 4n, where there is one new attribute for each attribute in the input space and for each interaction betweenattributes in the input space. This translation both trivializes preferential independence concerns and provides tolerance tosome slight errors or inconsistencies in the input preferences, while enabling reasoning with partial preference information.2.4. Going forwardOur work builds on a base of qualitative ceteris paribus preferences [38,14], and augments this with reasoning aboutquantitative and qualitative preference and tradeoff information. As such, our preference machinery in this paper moves ina slightly different direction than CP-nets. Like the collections of logical statements augmented with preference information,we are able to reason with any number of statements; unlike CP-nets we do not require complete elicitation of preferencesfor each variable or according to each independence condition. Like TCP-nets, we add tradeoff and importance statementsto ceteris paribus preferences, but we choose to add quantitative statements of importance and tradeoffs. Like UCP-nets, weendeavor to allow efficient reasoning about quantified preferences. The UCP-net has been combined with TCP-nets in recentwork [7], which provide a qualitative tradeoff semantics to UCP-nets. We will show that our quantitative tradeoffs can alsobe combined with UCP-nets, in Section 9.Our work also builds upon elements of the other preference systems mentioned in the preceding. Expected Utility Net-works base their semantics on multiplicative judgments of value; we combine a semantics of multiplicative tradeoffs withqualitative logical preferences. Like the SVM and possibilistic logic preference compilation techniques, we take as input alist of statements of preference, in some natural logical form, and seek to compile them into an explicit utility functionthat enables more efficient preference reasoning. In addition to providing support for tradeoffs and importance judgments,our system may be applicable in some domains where the cardinality of some attributes makes the SVM’s dimensionaltranslation impractical, or where explicit tradeoffs provide handy shortcuts for weighted possibilistic logic statements.In sum, our work combines elements of many existing lines of preference reasoning and representational research. Theresult, as presented in this article, is a formalism of qualitative preference ceteris paribus that combines quantified tradeoffsand importance judgments while allowing partial reasoning and assuming no particular independence forms with a compi-lation procedure that translates the forgoing into an explicit utility function for efficient reasoning. Such a system should bea valuable contribution to the preference research community.3. Formal backgroundIn this section we present the formal concepts and notation that we use throughout for outcomes, attributes, orders,representations, and independence properties of orders.3.1. Outcomes, attributes, and partial outcomesFor the present treatment we follow common practice and identify decision outcomes with tuples of values of a setof attributes. Formally, let A = { Ai | 1 (cid:3) i (cid:3) n} be a finite, enumerated set of attributes, and each attribute’s domain bea set denoted D i . Attribute domains can be finite or infinite, discrete or continuous. A set of outcomes is described by(cid:4)A = D1 × · · · × Dn, a cartesian attribute space.To simplify the presentation and discussion in the remainder, we will assume throughout that the domain of each at-tribute is numeric. In particular, we assume the use of a one-to-one function ρ : (cid:4)A → Rn that gives a numeric representationof the entire attribute space, including numeric representations of nonnumeric attribute domains. We make no assumptionsregarding whether the domains of each attribute are continuous intervals or not, as this will not be of central importancein the following.In choosing the numeric representations of attributes, we assume that the representations conform to the character ofthe underlying attribute. Numeric representations of nominal attributes can be chosen arbitrarily. For ordinal attributes,the underlying attribute domain has a natural order, and we assume that the numeric representations are chosen to havea numeric order consistent with that of the natural order on the represented nonnumeric values. Similarly, for intervalattributes, we assume that the numeric representation preserves distances between underlying attribute values, and forratio attributes, we assume that the representation preserves ratios as well.To interpret preference statements that refer to some attributes but not to others requires means for talking about partialoutcomes defined over the specific attributes mentioned by the preference statements. In fact, we employ three different1128M. McGeachie, J. Doyle / Artificial Intelligence 175 (2011) 1122–1152ways of talking about partial outcomes: as partial assignments of values to attributes, as vectors over attribute valuesextended with a “0” (meaning “unassigned”) value, and as vectors over subsets of attributes.(cid:3)We use bundles as descriptions of outcomes in terms of partial assignments of values to attributes. A bundle (of goods) isa partial function from (cid:4)A toi D i , the disjoint union of domains of each attribute. For a bundle b, b(i) is the value assignedby b to attribute i. b(i) is either undefined, in which case we write b(i) = ⊥, or b(i) is a value w ∈ D i . If a bundle definesone value for every attribute Ai ∈ A then we say it is complete. We can also write a bundle as a list of the pairs it defines:b = {( Ai = w i), ( A j = w j), . . .} where w i ∈ D i, w j ∈ D j . We call the set of attributes to which a bundle b assigns values thesupport of b, and denote it by σ (b).(cid:3)We define operations on bundles by defining component-wise operations using standard algebra, but with additionalsupport for ⊥. We have ⊥ + ⊥ = ⊥, ⊥ ∗ ⊥ = ⊥, ⊥ ∗ 0 = 0, and for any real r (cid:10)= 0, ⊥ + r = ⊥ and ⊥ ∗ r = ⊥. Otherwise,bundle addition is much like vector addition, as is multiplication of a scalar and a bundle. One multiplies two bundles(cid:3)(i). Replacement of a bundle by values from(cid:3)(cid:3)component-wise: for bundles b, b(cid:3)(cid:3)(i) = b(i). We also write(cid:3)(cid:3)(i) = banother is written b[bb[(i = w)] for the replacement of b with an implicit bundle b(cid:3) = b, we have b ∗ band defined as follows: b(cid:3)(i) = ⊥, in which case b(cid:3)(i) unless b(cid:3) = {(i = w)}.(cid:3)(cid:3)(i) = b(i) ∗ bwhere b(cid:3)] = b(cid:3)(cid:3)For each bundle b, we define a corresponding vector φ(b) ∈ Rn, which we call the value vector for b. Writing φi(b) forthe ith component of φ(b), we define φ(b) by φi(b) = b(i) whenever b(i) (cid:10)= ⊥ and φi(b) = 0 otherwise. Because valuevectorization maps both 0 and ⊥ to 0 elements in the vector, one cannot recover the original bundle from a vector unless 0is not in D i , but this degeneracy will not matter in the following, where we vectorize bundles before computing their innerproduct with other vectors, and the additional 0s make the development much simpler. Value vectorization allows us to use(cid:3)) of value vectorsoperations on vectors in place of operations on bundles. For example, we use the inner product φ(b) · φ(b. We call a vector (cid:4)x ∈ Rn the characteristic vector for a set of attributesto compute the inner product of bundles b and bG ⊆ A iff xi = 1 iff Ai ∈ G and xi = 0 otherwise.For each subset G ⊆ A of attributes, we define the outcomes (cid:4)G over G to be the cartesian product Π G, taking the productin the enumeration order inherited from A. If (cid:4)x ∈ (cid:4)A, we define the projection function πG : (cid:4)A → (cid:4)G so that [πG ((cid:4)x)]a = xa foreach a ∈ G. If (cid:4)g ∈ (cid:4)G, we define the bundle b((cid:4)g) corresponding to (cid:4)g so that the bundle is undefined on every attribute notin G, and takes the same value as (cid:4)g on every attribute in G.We write vectors next to each other when we refer to their combination; if (cid:4)X and (cid:4)Y are disjoint sets of attributes and(cid:4)x ∈ (cid:4)X and (cid:4)y ∈ (cid:4)Y , then (cid:4)x(cid:4)y refers to the vector over (cid:4)X ∪ (cid:4)Y that orders the combined values of (cid:4)x and (cid:4)y according to theattribute enumeration order.(cid:3)We call C = {C1, . . . , Ck} a cover of the attributes A iff each Ci ⊆ A andi Ci = A. Distinct attribute subsets in a cover(cid:4)need not be disjoint.3.2. Preference orders and value functionsWe model the preferences of a decision maker as an ordering over the outcomes described by (cid:4)A. A weak preference. We do notjust inordering is a reflexive and transitive relation (cid:4) on (cid:4)A where (cid:4)a (cid:4) (cid:4)aassume or require that (cid:4) forms a total order. Strict preference (cid:8) consists of the irreflexive part of (cid:4), that is (cid:4)a (cid:8) (cid:4)acase (cid:4)a (cid:4) (cid:4)aindicates that (cid:4)a is at least as preferable as (cid:4)aare indifferent and write (cid:4)a ∼ (cid:4)a(cid:3) (cid:4) (cid:4)a we say (cid:4)a and (cid:4)a. When (cid:4)a (cid:4) (cid:4)aand (cid:4)abut (cid:4)a(cid:3) (cid:10)(cid:4) (cid:4)a.(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)Economics and decision theory use the terms “utility function” and “value function” to name numerical representationsof preference orders. We will use the terms interchangeably in this paper, but favor the term “value function.” Althoughnone of the following treats decision-making under uncertainty, for which the usual term is “utility,” our intent here isdefinitely to provide a language and semantics for characterizing the structure of utility functions.A value function, v : (cid:4)A → R, allows the use of (cid:2) as the standard order (and therefore preorder) over the reals, and thusover the image of (cid:4)A under v. We write (cid:2)v for the preorder on (cid:4)A induced by v. Complete preorders (cid:4) over countable (cid:4)Acan be expressed exactly by value functions, so that v((cid:4)a) (cid:2) v((cid:4)a. We say a value function v representsa complete preference order (cid:4) when v((cid:4)a) (cid:2) v((cid:4)a. An incomplete preorder (cid:4) is necessarily a subset ofsome preorder (cid:2)v . When (cid:4) is a subset of the preorder (cid:2)v , we say that v is consistent with (cid:4).We call functions ˆv G : (cid:4)G → R partial value functions; these assign a number to partial descriptions of an outcome. Wedefine subvalue functions over G to be value functions v G : (cid:4)A → R such that v G ((cid:4)a) = ˆv G (πG ((cid:4)a)). Subvalue functions over Gignore all but some set of attributes, G. As a matter of notational convenience, we frequently use bundles as argumentsto value functions, and would write v(φ(b)) for the operation of v on the characteristic vector of a bundle b. When thecontext is clear, we suppress the φ function and just write v(b).(cid:3)) if and only if (cid:4)a (cid:4) (cid:4)a(cid:3)) if and only if (cid:4)a (cid:4) (cid:4)a(cid:3)(cid:3)3.3. Preferential independencePreferential independence is a property that obtains when the contribution to value of some attributes can be determinedwithout knowledge of other attributes. More precisely, a set of attributes X is preferentially independent of a disjoint set ofattributes Y when the comparisons over attributes in X do not depend on the assignment of values to attributes in Y . Westate this formally in the following definition.M. McGeachie, J. Doyle / Artificial Intelligence 175 (2011) 1122–11521129Definition 3.1 (Preferential independence). A set of attributes (cid:4)X is preferentially independent of a disjoint set of attributes (cid:4)Ywith A = (cid:4)X ∪ (cid:4)Y , if and only if, for all (cid:4)x1, (cid:4)x2 ∈ (cid:4)X , and (cid:4)y1, (cid:4)y2 ∈ (cid:4)Y ,(cid:4)x1 (cid:4)y1 (cid:8) (cid:4)x2 (cid:4)y1 → (cid:4)x1 (cid:4)y2 (cid:8) (cid:4)x2 (cid:4)y2.(3)Note that preferential dependence is not symmetric. It is possible for a set of attributes (cid:4)X to be preferentially dependentupon a disjoint set of attributes (cid:4)Y , while (cid:4)Y is independent of (cid:4)X . However, the case of symmetric preferential independenceis the same as satisfying the “single cancellation axiom” of conjoint measurement theory [27].Preferential independence generally simplifies the structure of the corresponding value functions. The simplest preferencestructures occur when every subset of attributes is preferentially independent of every disjoint subset, which produces afully additive value function and a condition called additive independence. An additive value function over two attributes (orsets of attributes) is obtained when the marginal rates of substitution do not depend on the particular value [25, p. 91]. ForD = {G, H}, with G, H disjoint, an additive value function has the formv((cid:4)a) = gi v G ((cid:4)a) + hi v H ((cid:4)a).(4)A more general case is that seen in a generalized additive value function for a cover C = {C1, . . . , Ck} of A is a valuefunction v : (cid:4)A → R formed as a weighted sum of k subvalue functions v i = v Ci: (cid:4)A → R [19,1,10,7], that is,v((cid:4)a) =k(cid:5)i=1ti v i((cid:4)a).(5)The function-construction methods presented in Section 8 assume that attributes are preferentially independent when-ever there is no evidence to the contrary, and then construct value functions with generalized additive forms over subvaluefunctions representing subsets of attributes determined to be mutually dependent on the basis of preference statementsrelating them.4. A language for preference specificationAs Section 2 indicated, there are statements of preference that cannot be formally stated in existing preference reasoningsystems. Preferences regarding numerical tradeoffs cannot be combined with qualitative statements of direct preference,ceteris paribus preference, incompletely-specified preferences, and ambivalence toward preferential independence. The tra-ditional means for combining the import of disparate types of statements is to embed the statements in a single logicallanguage and provide interpretations that merge the sense of the various statements. Accordingly, in this section we intro-duce a language and logic for preference specification called Lopat, for Logic of Preferences and Tradeoffs that provides sucha combined representation. Lopat uses a first-order logical language to express attributes and conditions, and adds to thisfirst-order base one or more sets of preference and tradeoff relations, with each such set representing a preference orderand associated utility function over outcomes.4.1. Base language and logicThe base of Lopat consists of a first-order Logic of Attributes and Comparisons (Lac) obtained by choosing finite sets ofrelation symbols R1, . . . , Rl, function symbols F 1, . . . , Fm, and a finite or infinite set of individual constant symbols C1, . . . ,in which the constants and function symbols are used to name decision attributes. For example, a language describingcomputer-purchasing preferences might include function symbols like speed, CPU, and GHz, allowing reference to the nu-merical measurement in gigaHertz of the CPU speed of a computer X with the term GHz(speed(CPU( X))). Naturally, constantsamount to zero-ary functions, but we distinguish them from nonzero arity functions. We require that the relation symbolsof Lac include the symbols =, <, (cid:3), >, (cid:2) representing familiar equality and inequality binary relations. We assume that theconstants of Lac include names for any numbers in R needed to state conditions and values.As usual, an interpretation I = (D, RII1 , . . .) of Lac consists of an underlying domain D togetherm , Cwith interpretations of each n-ary relation as a subset of Dn, of each n-ary function as a function from Dn to D, and of eachconstant as an element of D.I1 , . . . , RI1 , . . . , FIl , FWe define satisfaction and entailment in Lac in the usual way, so that I |(cid:14) q just in case the meanings assigned by Imake q true. We write p |(cid:14) q just in case every interpretation making p true also makes q true, and for a theory (set ofsentences) S write S |(cid:14) q just in case p |(cid:14) q for each p ∈ S. We write (cid:2)p(cid:3) and (cid:2)S(cid:3) to denote the set of all models of pand S, that is, (cid:2)p(cid:3) = {I | I |(cid:14) p}.4.1.1. Logical and decision-making attributesWe regard each ground term of Lac as representing a potential decision-making attribute. For example, a theory de-scribing computer-purchasing preferences might involve terms such as speed(CPU( X)) and GHz(speed(CPU( X))), the formerrepresenting the CPU speed of a computer X, and the latter representing the numerical measurement of that speed ingigaHertz.1130M. McGeachie, J. Doyle / Artificial Intelligence 175 (2011) 1122–1152In most practical situations, one restricts attention to a finite number of these attributes, denoted here by A1, . . . , An tomatch the finite set of attributes presented in Section 3 to characterize our underlying treatment of decision making. Wemake no assumptions that the restricted set of attributes must be given at the beginning of decision analysis, or that itremains unchanged throughout the course of developing a decision model. We assume only that at any point in the analyticprocess the set of attributes of interest is finite. More general treatments of outcomes described in terms of infinitely manyattributes might be useful, we do not develop such here.With attention focused on a set of attributes A1, . . . , An, one can regard each interpretation I of Lopat as inducing thetuple of values ( A. If, as in Section 3, we associate a particular domainof values with each of these attributes, we can call an interpretation I conforming (to the assumed domains) if it interpretsall attribute terms as taking values in the corresponding attribute value domains. We will assume all interpretations areconforming throughout the remainder of this paper.n ), which we also denote as ( A1, . . . , An)III1 , . . . , AIn the case of conforming interpretations, we can define the attribute meaning (cid:2)p(cid:3)a of a statement p to be the set of valuetuples possible in interpretations consistent with p, that is, (cid:2)p(cid:3)a = {( A1, . . . , An)I | I ∈ (cid:2)p(cid:3)} = {(cid:4)x ∈ (cid:4)A | (cid:4)x = ( A1, . . . , An)I ∧I |(cid:14) p}.We do not assume that using a ground term as a decision attribute says anything about the logical or preferentialdependence or independence of that attribute on other attributes or on other terms not chosen as decision attributes.Part of the work of decision analysis is to identify such dependencies and independencies. We also leave open questionsabout how best to treat such restrictions of attention. In some settings one might translate a theory into a Datalog-likesublanguage of Lac, that is, a sublanguage that omits all functions except for a finite set of individual constants, each ofwhich represents one outcome attribute.We assume that the set of constants of Lac also includes names for any elements of the attribute domains D i needed toexpress preferences and tradeoffs.4.1.2. Attribute types and comparisonsWe can use the intended orderings of attribute domains to divide the set of decision attributes into nominal and ordinalattributes. Nominal attributes, such as colors and names, bear no nontrivial inequality relations among their values, so thatα < β is always false, and α (cid:2) β is true only if α = β is true. Ordinal attributes can carry nontrivial strict total or partialorderings over their values, orderings distinct from any preferential orderings of these values.We have assumed a numerical encoding of all attributes for simplicity of presentation, but numerical encodings al-ways admit order comparisons, no matter what type of attributes they represent. Our language does not forbid use oforder relations in value propositions about nominal attributes, but sensible uses of the language will avoid such as makingmeaningless comparisons. We therefore extend the notion of conformance from interpretations to interpreted theories byrequiring that a conforming preference theory states no order comparisons between purely nominal attributes. We assumeall theories discussed in the following are conforming.The focus of our use of Lac expressions in Lopat is in stating preferences and tradeoffs. We thus focus our attention ona sublanguage of Lac in which each statement describes bundles of attribute values.First, we define atomic value propositions to be inequalities or negations of inequalities relating attribute terms to eachother or to named domain values, and define compound value propositions to be statements formed as Boolean combinationsof atomic value propositions. We use the term value proposition to refer to both atomic and compound value propositions.Second, we define a positive value proposition to consist of a simple equality statement (α = β) relating an attribute αwith a value β. Such statements are of course also atomic value propositions. A bundle proposition consists of a conjunc-tion of positive value propositions in which no two conjuncts involve the same attribute. One can regard these as logicalstatements of bundles as defined earlier. In particular, assuming that all the attribute values have names in Lac, a bundleb = {(i = w i), ( j = w j), . . .} corresponds to the proposition pb expressed as Ai = w i ∧ A j = w j ∧ . . . . Finally, a propositionin disjunctive normal form (DNF) consists of a disjunction of conjunctions of atomic value propositions, that is, a disjunctionof bundle propositions.In addition to ordinary logical interpretations of value propositions, we also regard bundles as partial interpretations, anddefine the bundle meaning of value propositions accordingly.For each bundle b, we say that b satisfies a positive value proposition α = w, and write b |(cid:14) α = w, just in case pbassigns the value w to attribute α. We write b (cid:10)|(cid:14) α = w if b |(cid:14) α = w does not hold. It follows that b (cid:10)|(cid:14) α = w just in caseeither b assigns some other value to α or b does not assign a value to α. We define bundle satisfaction of the other formsof atomic value propositions similarly.For complex value propositions p and q, we define b |(cid:14) (p ∧ q) to hold just in case b |(cid:14) p and b |(cid:14) q, and define b |(cid:14) ¬pto hold just in case b (cid:10)|(cid:14) p. We define the meanings of the other Boolean connectives similarly.4.2. Order and utility expressionsWe obtain the full language Lopat by extending Lac with a set of preference and tradeoff relations {(cid:4)cp, (cid:8)cp, (cid:4)mt, (cid:8)mt,(cid:4)ai, (cid:8)ai}, together with a restriction connective ⇒, and a ratio connective :. We use these new linguistic elements andstatements c, p, and q of Lac to form three classes of Lopat statements as follows.M. McGeachie, J. Doyle / Artificial Intelligence 175 (2011) 1122–11521131First, Lopat includes expressions for traditional ceteris paribus preference statements, which we refer to here as qualitativeceteris paribus preference statements, similar to those presented in [14]. We restrict such statements to comparing conditionsdescribable as value propositions p and q, for which we form the expression p (cid:4)cp q, meaning that condition q is weaklypreferred to condition p ceteris paribus, and p (cid:8)cp q, meaning that condition q is strictly preferred to condition p ceterisparibus. For example, one might write ((α1 = 3) ∧ (α2 = 1)) (cid:8)cp ((α1 = 1) ∧ (α2 = 2)).We form restricted or conditional qualitative preference statements by conditioning a qualitative preference statement ona value proposition that restricts the domain of quantification implicit in the ceteris paribus comparison. If c is a valueproposition, we form such statements as c ⇒ p (cid:8)cp q and c ⇒ p (cid:4)cp q, each of which means that the indicated preferenceholds ceteris paribus among outcomes satisfying the condition c. For example, we can make statements ((α1 > 3) ∧ (α1 <5)) ⇒ ((α2 = 3) (cid:4)cp (α2 = 1) ∧ (α3 = 0)).Note that the preference conditional ⇒ has no relation to propositional implication →. It instead restricts the set ofoutcomes over which a preference comparison applies. Moreover, the explicit preference conditionalization indicated inc ⇒ p (cid:8)cp q is also different from the implicit conditionalization indicated in pc (cid:8)cp qc, because the attributes mentionedin c play a role in the interpretation of the latter expression, but play no role in the interpretation of the former. (SeeTheorem 27 of [14]; c ⇒ p (cid:8)cp q when pc (cid:8)cp qc and c has no attributes in common with p or q, but that c ⇒ p (cid:8)cp q canhold even though pc (cid:8)cp qc is false.)Second, Lopat includes expressions that allow one to say by how much one prefers some improvement in one conditionto some improvement in another condition. Marginal tradeoff statements take the form r : p (cid:8)mt s : q or r : p (cid:4)mt s : q forvalue propositions p and q and numbers r, s ∈ R such that r, s (cid:2) 1. We interpret these statements such that the pair oftradeoff factors r, s produce a meaning equivalent to the pair of tradeoff factors 1, sr . We allow omission of either or both ofthe numerical factors when they take the value 1. For example one could write 2 : (α2 = 3) (cid:8)mt 5 : ((α1 = 1) ∧ (α3 = 0)), orequivalently, write 1 : (α2 = 3) (cid:8)mt 2.5 : ((α1 = 1) ∧ (α3 = 0)). The semantics given later interprets p (cid:4)mt r : q as meaning,roughly, that increases in p are at least r times as desirable as increases in q, ceteris paribus. Conditional marginal tradeoffstatements, naturally, condition a marginal tradeoff statement with a value proposition, as in c ⇒ r : p (cid:8)mt s : q. For example,we can make the statement ((α1 > 3) ∧ (α1 < 5)) ⇒ (α2 = 3) (cid:4)mt 3 : ((α2 = 1) ∧ (α3 = 0)).Third, Lopat includes statements that allow one to say that one set of attributes is more important than another. To}. More general languagesdo this, we extend the language to include concrete sets of attribute names, as in {αi1 , . . . , αikmight include set terms and quantification over them, but we do not do so here. There is no substitution of equals forequals in such expressions; it is the attribute names that matter, not their values. With concrete sets G and H and numerictradeoff parameters r, s (cid:2) 1, we form attribute tradeoff statements r : G (cid:8)ai s : H and r : G (cid:4)ai s : H . As with marginal tradeoffstatements, we can simplify such statements to ones using a single tradeoff factor, for instance, G (cid:8)ai: H , meaning,roughly, that the attributes in G are at least sr times as important as the attributes in H . We also form conditional attributetradeoff statements by conditioning an attribute tradeoff statement to hold only for outcomes satisfying a value proposition,as in c ⇒ r : G (cid:8)ai s : H .sr4.3. Obtaining utility functions as meaningsAn interpretation I = (D, Ra utility function.I1 , . . . , RIl , FI1 , . . . , FIm , CI1 , . . . , v) of Lopat, accordingly, extends an interpretation of Lac withEach preference or tradeoff sentence in Lopat expresses a condition or constraint on a value function, either directly byconstraining the value function or its partial derivatives, or indirectly by constraining a preference order represented by thevalue function. We present the semantics for the weak preference, tradeoff, and importance statements in Sections 6–7. Weinterpret the strict versions in the usual way, so that• r : p (cid:8)cp s : q holds iff r : p (cid:4)cp s : q and r : p (cid:10)(cid:4)cp s : q;• r : p (cid:8)mt s : q holds iff r : p (cid:4)mt s : q and r : p (cid:10)(cid:4)mt s : q; and• r : p (cid:8)ai s : q holds iff r : p (cid:4)ai s : q and r : p (cid:10)(cid:4)ai s : q.In particular, because we assume conforming interpretations, we can define the value meaning (cid:2)S(cid:3)v of a statement or setof statements S to be the set of value functions appearing in some interpretation of S, that is, (cid:2)S(cid:3)v = {v | I ∈ (cid:2)S(cid:3) ∧ I =(. . . , v)}. When v is a value function over (cid:4)A, we write v |(cid:14) S to mean that v ∈ (cid:2)S(cid:3)v.In general, then, combining a theory S phrased in Lopat with a set of attribute terms appearing within S determinestwo things; a set of possible outcomes (cid:2)S(cid:3)a, and a set of possible value functions (cid:2)S(cid:3)v. We mostly ignore the restrictionson possible outcomes in this paper, and focus instead on the interpretation of the theory in terms of value functions. Thevalue function construction method of Section 8 constitutes one way of computing a particular value function v ∈ (cid:2)S(cid:3)vwhen given a consistent set of sentences S.Although Lopat offers forms of preference specifications intended to extend the range of compactly expressible utilityfunctions, we do not yet have a characterization of just what functions are expressible or inexpressible in Lopat. For pref-erence orders over finite domains, one can of course construct a finite set of axioms that specify each pairwise comparisondirectly, and for preference orders over countable domains, one can do the same with a countable set of specification ax-ioms. Such axiom sets can be interpreted as specifying any utility function consistent with the preference order. The real1132M. McGeachie, J. Doyle / Artificial Intelligence 175 (2011) 1122–1152question, however, is what utility functions over infinite domains can be specified usefully with finite sets of Lopat axiomsor axiom schemata, and the answer to this question is unknown at present.Note that Lopat theories do not explicitly include symbols to represent outcomes or utility functions over outcomes. Theinterpretations of the logic make sense no matter how one identifies decision-making attributes among the terms of thelanguage. The ability to refer implicitly to utility functions comes directly from the inability to express utility values directlyin the language. The only statements Lopat allows about utility functions are ceteris paribus orderings over partial derivatives.These can be made without reference to the utility function itself or to its domain. In effect, the language presupposes thatthe utility function formally depends on all terms of the language, leaving it up to the analyst to determine on which termsit actually depends.5. Marginal tradeoff preferencesAs indicated in Section 1, we interpret marginal tradeoff statements p (cid:4)mt r : q as constraints on the directional deriva-tives of the value function. This section shows how to do this for a range of complex statements of conditions by associatingone or more directions with each of p and q. We first dispose of what one might consider as a plausible alternative inter-pretation.5.1. Avoiding a value-based tradeoff semanticsThe simplest possible interpretation of a marginal tradeoff comparison between bundles x and y, x (cid:4)mt r : y, is thatutilities of outcomes in one class are at least r times greater than utilities of outcomes in another class, that φ(x) ispreferred to φ( y) by a factor of more than r, or formally, for bundles x, y, and (cid:4)a, (cid:4)a(cid:3) ∈ (cid:4)A(cid:6)(cid:7)(cid:4)a[x]v(cid:6)(cid:4)a(cid:7)(cid:3)[ y].(cid:2) r v(6)We choose not to pursue this interpretation because it does not allow additive independence (Eq. (4)) between attributes.Theorem 5.1. If x and y are bundles with attributes G = σ (x) ∪ σ ( y) additively independent of the attributes G, and v((cid:4)a[x]) (cid:2)r v((cid:4)a(cid:3) ∈ (cid:4)A, then r = 1.(cid:3)[ y]) for all (cid:4)a, (cid:4)aProof. Since G is additively independent of G, there exists a value function involving the subvalue function v G ((cid:4)a[x]) forattributes in G. Then (6) must hold when k is a constant representing the value contributed by the attributes outside of G,which is the case when the assignment to attributes in G is fixed, and results in(cid:6)(cid:7)(cid:4)a[x]v G+ k (cid:2) r(cid:6)v G(cid:6)(cid:4)a(cid:7)(cid:3)[ y](cid:7).+ kHowever (7) simplifies to(cid:6)(cid:7)(cid:4)a[x]v G(cid:2) r v G(cid:6)(cid:4)a(cid:7)(cid:3)[ y]+ (r − 1)k.This inequality can only hold independent of k when r = 1. (cid:2)(7)Theorem 5.1 shows that a too-simplistic value-based tradeoff semantics would not be compatible with the simplest ofindependence conditions. While we will give much attention to generalized additive independence, which Theorem 5.1 doesnot rule out, in later sections we will be concerned to infer or assume independence conditions within a domain, and sodo not wish to preclude ourselves from using a simple additive value function. We therefore conclude that to speak aboutquantified tradeoffs with nontrivial tradeoff ratios, we cannot use the simple value-based tradeoff semantics representedby (6).5.2. Geometric tradeoff semanticsOur semantics for marginal tradeoff statements begins by interpreting the special case in which the tradeoff conditionsrepresent individual bundles, and defines meanings for more complex conditions by reducing statements over complexconditions to sets of statements over bundle conditions.To interpret nontrivial marginal tradeoff ratios, we follow the approach of preference ceteris paribus and interpret trade-offs as comparisons holding other attributes constant. Specifically, we regard such tradeoff statements as constraining thepartial derivatives of the utility function, as these partial derivatives explicitly hold constant attributes other than the onesbeing differentiated. Constraints on derivatives stating that value increases in one direction r times faster than in anotherdirection constrain the shape of the utility function rather than its values, and this includes reference to the units of theattributes.We interpret marginal bundle tradeoffs through the following definition.M. McGeachie, J. Doyle / Artificial Intelligence 175 (2011) 1122–1152Definition 5.1 (Conditional bundle tradeoff). If x and y are bundle propositions, we have v ∈ (cid:2)c ⇒ x (cid:4)mt r : y(cid:3)v iff(cid:6)(cid:7)∇ v((cid:4)a) · φ(x)(cid:6)(cid:7)∇ v((cid:4)a) · φ( y)(cid:2) rfor each (cid:4)a ∈ (cid:2)c(cid:3)a.1133(8)Inequality (8) means that the partial derivatives of each utility function v ∈ (cid:2)x (cid:4)mt r : y(cid:3)v must satisfy the constraint(cid:5)x(i)(cid:10)=⊥∂ v∂ Ai((cid:4)a)φi(x) (cid:2) r(cid:5)y( j)(cid:10)=⊥∂ v∂ A j((cid:4)a)φ j( y)at all points (cid:4)a satisfying the conditioning proposition.(9)For example, suppose we are comparing different computers and wish to state that a 3.6 GHz processor with a 1-MBL2-cache and an 800 MHz front side bus is twice as good as 4 GB of ram with a 400 MHz front side bus. We can expressthis in Lopat as(cid:6)GHzspeed(cid:6)processor(X)(cid:7)(cid:7)(cid:6)(cid:6)= 3.6 ∧ MBsize= 0.8 (cid:4)mt 2 : GB(cid:7)(cid:7)cache(X)(cid:6)(cid:6)= 1 ∧ GHz(cid:7)(cid:7)(cid:6)(cid:6)speed(cid:6)(cid:7)(cid:7)bus(X)(cid:6)(cid:7)(cid:7)sizeRAM(X)= 4 ∧ GHzspeedbus(X)= 0.4.This formulation follows the representation used in Section 4.1 in making explicit both the dimensions of measurement(speed, size) and the units of measurement (GHz, MB, GB), and distinguishing both of these from the object of measurement(processor, cache, bus, RAM). In this case, we are talking about values for four different variables, GHz(speed(processor( X))),MB(size(cache( X))), GHz(speed(bus( X))), and GB(size(RAM( X))), which measure processor speed in GHz, cache size in MB,bus speed in GHz, and RAM size in GB. For typesetting convenience, we abbreviate these variables as processor, cache, bus,and RAM in the following discussion.The preference stated above concerns two bundles, {(processor = 3.6), (cache = 1)(bus = 0.8)} and {(RAM = 4), (bus =0.4)}, and by Definition 5.1 constrains the utility function to obey∂ v∂processor((cid:4)a)3.6√14.6+ ∂ v∂cache((cid:4)a)1√14.6+ ∂ v∂bus((cid:4)a)0.8√14.6(cid:2) 2(cid:8)∂ v∂RAM((cid:4)a)4√16.16+ ∂ v∂bus((cid:4)a)0.4√16.16(cid:9).We interpret comparisons between general value propositions by reducing them to comparisons between propositionsin disjunctive normal form, and interpret marginal tradeoffs between DNF conditions p and q by regarding each conjunctin p and q as a bundle and interpreting the comparison between these disjunctions of bundles as pairwise comparisons ofall combinations of the disjoined bundles.Definition 5.2. The meaning of a conditional marginal tradeoff statement c ⇒ r : p (cid:4)mt s : q is the same as the meaning ofthe statement rewritten so that the compared propositions are in disjunctive normal form, and the meaning of a conditionalmarginal tradeoff statement c ⇒ r : p (cid:4)mt s : q in which p and q are in disjunctive normal form is the same as the meaningsandof all such comparisons between conjuncts in p and conjuncts in q. That is, if the disjunctive normal form of p is pY , thenthe disjunctive normal form of q is q(cid:2)c ⇒ r : p (cid:4)mt s : q(cid:3)v = (cid:2){c ⇒ r : x (cid:4)mt s : y | x ∈ X, y ∈ Y }(cid:3)v., then (cid:2)c ⇒ r : p (cid:4)mt s : q(cid:3)v = (cid:2)c ⇒ r : p(cid:3)(cid:3)v, and if p =(cid:3) (cid:4)mt s : qX and q =(cid:10)(cid:10)(cid:3)(cid:3)To continue the example from computer configuration, suppose we see other configurations of computers and amend ourpreference from before. We now think that a 3.2 GHz or 3.6 GHz processor with a 1-MB or 2-MB L2-cache and an 800 MHzfront side bus is twice as good as 4 GB of ram with a 400 MHz front side bus. We have compound value propositionsp = (processor = 3.6 ∨ processor = 3.2) ∧ (cache = 1 ∨ cache = 2) ∧ bus = 0.8, and q = RAM = 4 ∧ bus = 0.4. We then convertp into disjunctive normal form, obtaining p = (w ∨ x ∨ y ∨ z) where(cid:11)(cid:12)(processor = 3.6), (cache = 1)(cid:12)(processor = 3.2), (cache = 1),(cid:12)(cid:11)(processor = 3.6), (cache = 2)(cid:12)(processor = 3.2), (cache = 2),(cid:11),w =(cid:11)x =y =z =and letting q(cid:3) = {(RAM = 4), (bus = 0.4)}, we then have(cid:2)p (cid:4)mt 2 : q(cid:3)v =(cid:4)(cid:11)w (cid:4)mt 2 : q(cid:3), x (cid:4)mt 2 : q(cid:3), y (cid:4)mt 2 : q(cid:3), z (cid:4)mt 2 : q(cid:3)(cid:12)(cid:5)v.1134M. McGeachie, J. Doyle / Artificial Intelligence 175 (2011) 1122–11525.3. Properties of the semanticsConditional bundle tradeoffs exhibit a natural form of transitivity.Theorem 5.2 (Transitivity). The two conditional bundle tradeoffsc1 ⇒ x (cid:4)mt r1 : y,c2 ⇒ y (cid:4)mt r2 : ztaken together entail the tradeoff statementc1 ∧ c2 ⇒ x (cid:4)mt r1r2 : z.Proof. The statements (10) and (11) are interpreted, respectively, as the constraints∇u((cid:4)a) · φ(x) (cid:2) r1∇u((cid:4)a) · φ( y),∇u((cid:4)a) · φ( y) (cid:2) r2∇u((cid:4)a) · φ(z).(10)(11)(12)(13)(14)Both (10) and (11) apply to outcomes falling within c1 ∧ c2, the intersection of their regions of applicability. Within thisregion, we can multiply (14) by r1 and then substitute back into (13), to obtain the preference part of (12). (cid:2)We now verify that the definition of quantitative tradeoffs between groups of attributes is a generalization of the stan-dard economic notion of the marginal rate of substitution between two attributes. More precisely, the marginal rate ofsubstitution is usually defined as the negative of the slope of the indifference curve of the value function for two commodi-ties [24]. Specifically, in the case of unit-vector tradeoffs between two attributes, our directional derivative representation fortradeoffs between sets of attributes reduces to a condition on the marginal rate of substitution. We show this by simplifyingthe condition in Definition 5.1.Theorem 5.3 (Marginal rate of substitution). If x is the bundle proposition Ai = 1, and y is the bundle proposition A j = 1, with i (cid:10)= j,then the tradeoff ratio r in x (cid:4)mt r : y forms a lower bound on the marginal rate of substitution between attributes Ai and A j , that is,if v ∈ (cid:2)x (cid:4)mt r : y(cid:3)v, then(cid:2)∂ v∂ Ai∂ v∂ A j(cid:2) r.Proof. Definition 5.1 implies ∇ v((cid:4)a) · φ(x)/∇ v((cid:4)a) · φ( y) (cid:2) r. Expanding the inner product gives(cid:2)∂ v∂ A j∂ v∂ Ai(cid:2) r,which states the claimed bound on the marginal rate of substitution. (cid:2)The description of tradeoff preferences we have given so far is very general. In research on preference elicitation, linearutility functions or piece-wise linear functions are considered exceedingly frequently [26,16]. It is thus worth noting thatsimple linear utility functions can satisfy a bundle tradeoff, stated formally in the following lemma.Lemma 5.1 (Linear utility functions). If C = {C1, C2, . . . , C Q } is a cover of A and v((cid:4)a) =function with v i = v Ci such that v i is linear in each attribute Ai1, . . . , AiN ∈ Ci , then v ∈ (cid:2)x (cid:4)mt r : y(cid:3)v iffQi=1 ti v i((cid:4)a) is a generalized additive value(cid:13)n(cid:5)j=1k jφ j(x) (cid:2) rn(cid:5)j=1kiφ j( y),with ki, k j constants.Proof. The claim follows from Definition 5.1. (cid:2)(15)We will make use of this result in Section 8 when we construct linear value functions from preference statements inLopat.Another property of the semantics we examine is the special case of colinear bundle propositions, that is, the meaningof x (cid:4)mt r : y when x and y are bundle propositions and there is some number t such that φ(x) = tφ( y), that is, theM. McGeachie, J. Doyle / Artificial Intelligence 175 (2011) 1122–11521135comparison involves attribute values in one bundle that are the same multiple of the values in the other bundle. In thiscase, the semantical condition (8) reduces to (∇ v((cid:4)a) · tφ( y)) (cid:2) r(∇ v((cid:4)a) · φ( y)), which is satisfiable just in case either t (cid:2) ror ∇ v((cid:4)a) · φ( y) = 0.A final property of our semantics is that it exhibits sensitivity to the units with which one expresses bundles, in thatan attribute with a range of values between 0 and 1 will typically influence comparisons less than an attribute takingvalues in the range between 1000 and 1,000,000. This is a common problem arising in many situations in which one mustmeasure or compare disparate attributes. One could approach the problem by normalizing attribute values and ranges insome automatic fashion, but as has been remarked in the literature on preference elicitation, normalizing ranges can leadto bias and misunderstanding instead of to a solution to the problem [25,3,18]. We therefore do not regard the problem asone solvable in the abstract for all problems, and leave the burden on the decision analyst to formulate tradeoffs sensiblyin light of the differences among attributes and units of measurement. The literature on conjoint measurement theory [27]provides some useful results addressing these problems.It is worth mentioning, however, that at least one sort of normalization is compatible with the semantics presented here.An earlier version of this paper used definitions that compared the bundles normalized to have unit Euclidean length, soas to compare directional derivatives without reference to the magnitudes of the vectors used to identify the directions.Formally, let 1(x) to be the normalized vector x/|x|, and for a bundle x let 1(x) = 1(φ(x)). The normalized semantics thendefined the meaning of c ⇒ x (cid:4)mt r : y so that v ∈ (cid:2)c ⇒ x (cid:4)mt r : y(cid:3)v iff (∇ v((cid:4)a) · 1(x)) (cid:2) r(∇ v((cid:4)a) · 1( y)) for each (cid:4)a ∈ (cid:2)c(cid:3)a.Essentially all of the theorems we state and prove in this paper hold true with the normalized semantics as well: only theexamples of utility construction differ by much. Nevertheless, this simple sort of normalization does not really alter theunderlying problem significantly. Instead, it introduces an additional complication, for making tradeoff comparisons by onlyconsidering the direction of different bundles but not their magnitudes means that one cannot treat comparison of colinearbundles with the normalized definition, and must reintroduce the unnormalized semantics given here for that special case,producing an unpleasant discontinuity of interpretation.5.4. Marginal tradeoffs among discrete attributesThere is a natural extension of our directional derivatives formulation of tradeoffs to discontinuous value functions overdiscrete attributes. When we have two bundles x, y over discrete attributes and want to say that value is increasing inthe φ(x)-direction r times faster than in the φ( y)-direction, we can still give meaning to this type of preference by usingdiscrete difference analogues of the partial derivatives.For bundles of either discrete or continuous attributes, we define a discrete difference vector (cid:10)v(x, y) of complete bun-dles x, y, to be a vector with ith component(cid:14)(cid:10)i v(x, y) =v(φ(x))−v(φ(x[(i=φi( y))]))φi (x)−φi ( y)0if φi(x) − φi( y) (cid:10)= 0,if φi(x) − φi( y) = 0.A discrete difference vector is a vector of slope-approximations, where the ith component of the vector is an approximationof the slope of v in the ith dimension.We assign meanings to tradeoffs among discrete attributes using discrete difference vectors as follows.Definition 5.3 (Discrete bundle tradeoffs). If x and y are bundles over discrete attributes, then v ∈ (cid:2)c ⇒ x (cid:4)mt r : y(cid:3)v iff(cid:7)(cid:6)a, a(cid:3)(cid:10)v· φ(x) (cid:2) r(cid:10)vfor all complete bundles a (cid:10)= a(cid:7)(cid:6)a, a(cid:3)(cid:3)such that φ(a), φ(a(cid:3)) ∈ (cid:2)c(cid:3)a.· φ( y).(16)Consider a simple example of how one might use Definition 5.3 to analyze a preference stated by a certain computerscientist who in the morning thinks that a small cup of caffeinated coffee is twice a preferable as a large cup of decaffeinatedcoffee. The aim of this example is to illustrate our inferences about the scientist’s preferences, not to attribute inferences tothe scientist.We begin by considering attributes coffee with domain {decaf , regular}, and size with domain {S, M, L}. For simplicity,suppose ρ(decaf) = 1, ρ(regular) = 2, and for size we let ρ(S) = 1, ρ(M) = 2, ρ(L) = 3. We then have bundles x = (coffee =regular), (size = S), y = (coffee = decaf ), (size = L), and a discrete bundle tradeoff x (cid:4)mt> 2 : y. This tradeoff holds when(cid:10)v(a, a(cid:3)) · φ( y) for all (a, a(cid:3) = (2, 3). We have(cid:6)(cid:3)) · φ(x) (cid:2) 2(cid:10)v(a, a(cid:7)(1, 1), (2, 3)(cid:7)(1, 1), (2, 3)(cid:6)(cid:10)1 v(cid:10)2 v==(cid:3)). For example, first consider a = (1, 1), a(cid:7)v(1, 1) − v(2, 1)(cid:7)v(1, 1) − v(1, 3)/(1 − 2),/(1 − 3).(cid:6)(cid:6)(cid:6)This lets us compute the dot-products as follows:(cid:7)(1, 1), (2, 3)(cid:7)(1, 1), (2, 3)(cid:7)v(1, 1) − v(2, 1)(cid:7)(cid:6)v(1, 1) − v(2, 1)· φ(x) = −2· φ( y) = −1(cid:10)v(cid:10)v(cid:6)(cid:6)− 1/2 ∗− 3/2 ∗(cid:6)(cid:7)v(1, 1) − v(1, 3),(cid:7)(cid:6)v(1, 1) − v(1, 3)1136M. McGeachie, J. Doyle / Artificial Intelligence 175 (2011) 1122–1152and these leave us with the constraint on the utility function:−2.5v(1, 1) + 2v(2, 1) + 0.5v(1, 3) (cid:2) 2 ∗(cid:6)(cid:7)−2.5v(1, 1) + v(2, 1) + 1.5v(1, 3)which simplifies to v(1, 1) (cid:2) v(1, 3).By considering other values of (a, a(cid:3), a). After simpli-(cid:3) = (1, 3), then we achieve the constraint v(2, 1) (cid:2) v(2, 3). Consideringfication we obtain v(2, 1) (cid:2) v(2, 3). Let b = (2, 1), b(cid:3)) = 0, but after simplifying(cid:10)v(bwe again get the constraint v(1, 1) (cid:2) v(1, 3), and in this case reversing the arguments to (cid:10) gives the identical constraint.We list these and other constraints in the following table:(cid:3)) we obtain other constraints on the utility function. Consider (cid:10)v(a(cid:3), b) gives v(1, 1) (cid:2) v(1, 3). Suppose we define c = (1, 1), c(cid:3) = (1, 3), in this case (cid:10)1 v(c, ca(1, 1)(2, 3)(2, 1)(1, 3)(1, 1)(1, 3)(1, 1)(2, 1)(2, 3)(2, 1)(2, 3)(1, 3)(cid:3)a(2, 3)(1, 1)(1, 3)(2, 1)(1, 3)(1, 1)(2, 1)(1, 1)(2, 1)(2, 3)(1, 3)(2, 3)Constraintv(1, 1) (cid:2) v(1, 3)v(2, 1) (cid:2) v(2, 3)v(2, 1) (cid:2) v(2, 3)v(1, 1) (cid:2) v(1, 3)v(1, 1) (cid:2) v(1, 3)v(1, 1) (cid:2) v(1, 3)0 (cid:2) 00 (cid:2) 0v(2, 1) (cid:2) v(2, 3)v(2, 1) (cid:2) v(2, 3)0 (cid:2) 00 (cid:2) 0The results here suffice to order several values of the domain, such that (2, 1) which corresponds to (regular, S) is theelement most preferred and (decaf , L) is the least. In contrast to the continuous development in the previous section, valuessuch that ai = xi orof (cid:10)v(a, aai = yi will provide new, unentailed, constraints. A proof of this conjecture is left to future work.(cid:3)) can be used to provide additional constraints, but we conjecture that only values of a, aThe following theorem shows the meanings assigned to c ⇒ x (cid:4)mt r : y by Definition 5.3 for discrete tradeoffs is compat-ible with the meaning assigned to the same statement by Definition 5.1 for continuous tradeoffs in the case in which wetake continuous attributes and a differentiable value function and regard the attributes instead as discrete.(cid:3)Theorem 5.4 (Continuous tradeoffs). If x and y are bundles of continuous attributes and v is a differentiable function over (cid:4)A that(cid:3)) ∈ (cid:2)c(cid:3)a, then v also satisfies the continuous(cid:3)satisfies the discrete inequality (16) for all complete bundles a (cid:10)= ainequality (8).such that φ(a), φ(aProof. By assumption we have(cid:7)(cid:6)a, a(cid:3)(cid:10)v· φ(x) (cid:2) r(cid:10)v(cid:7)(cid:6)a, a(cid:3)· φ( y)(17)for all complete bundles a (cid:10)= aapproximations to the slopes in each dimension of the value function. Consider the term(cid:3) ∈ (cid:2)c(cid:3)a. Since v is differentiable, the terms in the expansion of the discrete difference are(cid:6)(cid:7)φ(a)v(cid:15)(cid:6)(cid:6)(cid:6)aφ− v(cid:6)a(cid:3)i = φi(cid:7)(cid:7)(cid:16)(cid:7)(cid:7)(cid:17)(cid:6)(cid:7)(cid:7)(cid:6)a(cid:3)such(cid:3)) = φi(a) − h for some h. We are then assured that for differentiable v relations involving (18) hold when (18) isφi(a) − φi(cid:3)), and approximates the slope of v in the ith dimension. We can choose a,(cid:3)(18)(cid:3), for φi(a) (cid:10)= φi(awhich holds at all a, athat φi(areplaced with(cid:6)(cid:7)φ(a)(cid:15)(cid:6)(cid:6)(cid:6)aφ− vi = φi(a) − h(cid:7)(cid:16)(cid:7)(cid:7)/h.vlimh→0Since (19) is equal to ∂ v∂i , we can rewrite (17) asn(cid:5)i∂ v∂i((cid:4)a)φi(x) (cid:2) rn(cid:5)j∂ v∂ j((cid:4)a)φ j( y),which is the definitional condition for the continuous inequality (8). (cid:2)(19)M. McGeachie, J. Doyle / Artificial Intelligence 175 (2011) 1122–115211376. Qualitative ceteris paribus preferencesQualitative ceteris paribus preference statements state that one condition is preferable to another, other things be-ing equal. The conditions are typically expressed as logical combinations of values of various attributes, so “other thingsbeing equal” means comparing only outcomes that do not differ on attributes not involved in either of the conditions beingcompared. The comparison, moreover, is made without implying anything about possible tradeoff ratios. Qualitative ceterisparibus preferences have served as the basis for numerous representations of preference information, including [14,32,5].6.1. Reinterpreting qualitative ceteris paribus preferencesThe semantics given here to the qualitative ceteris paribus preference statements included in Lopat differs somewhat fromthat given to comparable statements treated in [14]. We explain the difference in the following. To keep the two conceptionsseparate, we use the comparison operators (cid:8)DSW and (cid:4)DSW in this section to refer to statements and semantics of the formconsidered in [14]. Statements involving (cid:8)DSW or (cid:4)DSW are not included in Lopat.(cid:3)are equivalent modulo p if they take the same values outside the support of p. Formally, b ≡ bThe support of a value proposition p, denoted σ (p), is the minimal set of attributes determining the truth of p. Bundles bmod p iff b[a] =(cid:3)[a] for some bundle overand b(cid:3)[a] for some bundle a over σ (p). More generally, we say that b ≡ bbσ (p1) ∪ σ (p2) ∪ . . . . With these notions in hand, we can restate the meaning definition from [14] as follows.mod p1, p2, . . . if b[a] = b(cid:3)(cid:3)Definition 6.1 (Qualitative ceteris paribus preferences, Definition 3 in [14]). If p and q are value propositions and v is a value(cid:3) |(cid:14) (q ∧ ¬p), and(cid:3)) for all bundles b, bfunction, then v ∈ (cid:2)c ⇒ p (cid:4)DSW q(cid:3)v iff v(b) (cid:2) v(b(cid:3) ∈ (cid:2)c(cid:3)a such thatb ≡ bb |(cid:14) (p ∧ ¬q), bmod p, q. Similarly, v ∈ (cid:2)c ⇒ p (cid:8)DSW q(cid:3)v iff v ∈ (cid:2)c ⇒ p (cid:4)DSW q(cid:3)v and v(b) > v(b(cid:3) ∈ (cid:2)c(cid:3)a such that b |(cid:14) (p ∧ ¬q), b(cid:3)) for some b, b(cid:3) |(cid:14) (q ∧ ¬p), and b ≡ bmod p, q.(cid:3)(cid:3)For the comparisons expressed in Lopat, tradeoffs between discrete attributes generalize ceteris paribus preferences be-tween binary attributes. This formulation is stated most simply in terms of binary attributes. A ceteris paribus tradeoffbetween two binary attributes can be thought of as stating that “a change in P from ¬p to p is preferable to a changein Q from ¬q to q.” For discrete attributes with larger domains, the statement becomes “a change in P from p j to pi ispreferable to a change in Q from q j to qi .” The definition that follows implements this intuition.Definition 6.2 (Qualitative ceteris paribus tradeoffs). If p and q are value propositions with σ (p) = σ (q) and v is a valuefunction, then v ∈ (cid:2)c ⇒ p (cid:4)cp q(cid:3)v if and only if(cid:6)(cid:7)a[q], a[p](cid:6)(cid:7)a[p], a[q]· φ(p) (cid:2) (cid:10)v· φ(q)(20)(cid:10)vfor all complete bundles a such that φ(a) ∈ (cid:2)c(cid:3)a.For example, we can state preference concerning wine and food in the context of classical dining; suppose we haveattributes A = {meal, wine} and let meal have two values: b1 = meat, b2 = fish and wine have two values: w 1 = red,w 2 = white. We can then define clauses p1 = fish ∧ white and q1 = fish ∧ red, and state qualitative ceteris paribus trade-off p1 (cid:8)cp q1. We state another preference using clauses p2 = meat ∧ red and q2 = meat ∧ white, where p2 (cid:8)cp q2. We makethe assumptions that ρ(meat) = 1, ρ(fish) = 2, ρ(red) = 1, and ρ(white) = 2. Using these simplifications, we proceed as wedid in Section 5.4 and consider the values of (cid:10)v(a[p], a[q]). Since we have only two attributes, a is an empty bundle, andso (cid:10)v(a[p1], a[q1]) = (cid:10)v((2, 2), (2, 1))(cid:6)(cid:7)(2, 2), (2, 1)= 0,(cid:10)1 v(cid:6)(cid:7)(2, 2), (2, 1)(cid:10)2 v= v(2, 2) − v(2, 1).This lets us compute the dot-products as follows:(cid:7)(2, 2), (2, 1)(cid:7)v(2, 2) − v(2, 1)· φ(p1) = 2(cid:10)v(cid:6)(cid:6)(cid:6)(cid:7)(2, 2), (2, 1)(cid:10)v,· φ(q1) = v(2, 2) − v(2, 1)and these leave us with the constraint on the utility function v(2, 2) > v(2, 1). Similarly, we consider the condition fromp2 (cid:8) q2, or (cid:10)v((1, 1), (1, 2)) · φ(p2) > (cid:10)v((1, 1), (1, 2)) · φ(q2), and through similar calculations, obtain v(1, 1) > v(1, 2).Restating this in terms of the qualitative domains of each attribute leaves us with v(fish, white) > v(fish, red), andv(meat, red) > v(meat, white); note that these mirror the stated ceteris paribus preferences: fish ∧ white (cid:8)cp fish ∧ red andmeat ∧ red (cid:8)cp meat ∧ white.The semantics given here for ceteris paribus preferences differs from that given in [14], in that [14] interprets p (cid:4)DSW q interms of bundles satisfying p ∧ ¬q and q ∧ ¬p. The support of these propositions can differ in some cases, and our presentsemantics avoids this complication.The following theorem shows that, for linear value functions, the definition given for qualitative ceteris paribus com-parisons obeys a useful property of the value function: that the outcomes satisfying the left-hand side of the preferencerelation have greater value than those on the right-hand side.1138M. McGeachie, J. Doyle / Artificial Intelligence 175 (2011) 1122–1152Theorem 6.1. If x, y are bundles and v is a linear function in (cid:2)c ⇒ x (cid:4)cp y(cid:3)v, then(cid:6)(cid:7)a[x]v(cid:6)(cid:7)a[ y](cid:2) vfor each complete bundle a such that φ(a) ∈ (cid:2)c(cid:3)a.(21)Proof. For v ∈ (cid:2)c ⇒ x (cid:4)cp y(cid:3)v, the definition of qualitative tradeoffs expands to(cid:5)(cid:5)v(a[xi]) − v(a[ yi])xi − yixi (cid:2)v(a[ y j]) − v(a[x j])y j − x jy j.i∈σ (x)j∈σ ( y)−Multiply those terms that have negative denominators bylet zbe the indices where x j < y j . We then can write(cid:5)(cid:5)v(a[xi]) − v(a[ yi])xi − yi(xi − yi) (cid:2)v(a[ y j]) − v(a[x j])y j − x j( y j − x j).j∈z−i∈z+−1−1 , let z+be the indices of φ(x) and φ( y) such that xi > yi , andThe differences in the numerators of the above summations are simply the increase of the value function in a particulardimension. When v is linear, this slope is constant, and without loss of generality let ti be the slope in the i-dimension,and t j be the slope in the j-dimension. The preceding inequality simplifies to(cid:5)i∈z+ti(xi − yi) (cid:2)(cid:5)j∈z−t j( y j − x j),which we rearrange to get(cid:5)ti xi −(cid:5)i∈σ (x)j∈σ ( y)t j y j (cid:2) 0.This inequality is just(cid:6)(cid:7)z[x]v(cid:6)(cid:7)z[ y]− v(cid:2) 0,as required. (cid:2)The preceding theorem can be used to draw a correspondence between the definitions of ceteris paribus preference givenof two literals in the language of [14] can be representedin Definitions 6.1 and 6.2, showing that a comparison xby the same value function as represents the Lopat bundle comparison b[x(cid:3)] for an empty bundle b.(cid:3) (cid:4)DSW y(cid:3), ¬ y(cid:3)] (cid:4)cp b[¬x(cid:3), y(cid:3)(cid:3)(cid:3)and yTheorem 6.2. Let x(cid:3)] and y = b[¬x(cid:3), ¬ yx = b[xbe two binary attributes with x(cid:3), y(cid:3)(cid:3)]. Then every linear value function in (cid:2)c ⇒ x (cid:4)cp y(cid:3)v is also in (cid:2)c ⇒ x(cid:3) (cid:10)= y(cid:3) (cid:4)DSW y(cid:3)(cid:3)v., let b be an empty bundle, and let x and y be bundles such thatProof. Suppose v ∈ (cid:2)c ⇒ x (cid:4)cp y(cid:3)v is linear. By Theorem 6.1, we have v(a[x]) (cid:2) v(a[ y]) for every complete bundle a ∈ (cid:2)c(cid:3)a., so by Definition 6.1, v is in (cid:2)c ⇒ xNow we clearly have a[x] ≡ a[ y] mod x(cid:3), y(cid:3) (cid:4)DSW y(cid:3)(cid:3)v. (cid:2)(cid:3)This result shows that some statements of weak preference between binary attributes expressed using (cid:4)DSW can betransformed into statements of weak preference expressed using (cid:4)cp such that they are satisfied by the same linear valuefunctions, if any exist.7. Marginal attribute importanceWe have so far considered tradeoffs between particular instances of attributes: an assignment to some attributes G ispreferred to an assignment to some attributes H , ceteris paribus, or by some factor r. In this section we describe tradeoffsof the form G (cid:8)ai r : H between groups of attributes, which can also be considered a statement about the importance of thegroups of attributes, namely that “attributes G are more important than attributes H by a factor of r.”By saying that one set of attributes is more important than another, we mean to say that the first set has a largerinfluence on the value function than does the second. The influence of an attribute on value does not depend on anydirection in the space of outcomes, on the influence being a positive or negative contribution to value, or on the particularinstantiations of attributes being considered. It is, instead, purely a measure of the weight assigned to an attribute itself. Weexpect such comparisons mainly arise during elicitation of preferences, in which one might want to talk about the relativevalue of attributes and sets of attributes.M. McGeachie, J. Doyle / Artificial Intelligence 175 (2011) 1122–11521139The “importance” of attributes is a quantity that is frequently used in traditional decision analysis, and McGeachie [30]reviews various techniques for obtaining, assuming, or computing the relative importance of attributes in a value function.Our presentation here extends the usual decision analysis methodology in three ways. The first is that, as was stated inthe introduction to this paper, the decision maker is not required to make any importance statements at all, for we merelytake as many importance statements as occur and consider them alongside the other preference information we have. Thesecond is that we do not expect decision makers to talk about importance in just one attribute. The importance statementswe describe herein are between sets of attributes. Someone may decide that the combination of restaurant attributes meal-quality, drink-quality, and atmosphere-quality are at least twice as important as time-to-arrive and time-spent-waiting at arestaurant. The third difference is that instead of simply assigning a numeric weight to each attribute as a way of expressingattribute importance, as is often done, we instead interpret importance comparisons in the same geometric framework usedfor marginal tradeoff statements, in particular as a comparison between the norms of the gradients associated with differentsets of attributes.We formalize the geometric interpretation of conditional attribute importance statements as follows. Given an arbitrarysubset G ⊆ A and a function v G over (cid:4)G, the gradient ∇ v G ((cid:4)x) at a point (cid:4)x ∈ (cid:4)G is a vector based at x pointing in the directionof maximum increase of v G in (cid:4)G. The length |∇ v G ((cid:4)x)| of that vector is the magnitude of that increase. Thus if we interpret atradeoff between a set of attributes G and another set of attributes H as a comparison between the maximum possible ratesof increase in the subspaces defined by G and H , we can write that comparison in terms of the magnitudes of gradients inthose spaces. Specifically,(cid:18)(cid:18)(cid:18)∇ v G ((cid:4)a)(cid:18) (cid:2) r(cid:18)(cid:18)(cid:18)∇ v H ((cid:4)a)(cid:18)(22)compares the increase in the G-space to the increase in the H -space. Further, if we choose the L1 norm to measure thelength of the above vectors, inequality (22) is equivalent to(cid:18)(cid:18)(cid:18)(cid:18)(cid:5)f ∈G∂ v∂ f(cid:18)(cid:18)(cid:18)((cid:4)a)(cid:18) (cid:2) r(cid:18)(cid:18)(cid:18)(cid:18)(cid:5)f ∈H∂ v∂ f(cid:18)(cid:18)(cid:18)((cid:4)a)(cid:18).(23)(24)(25)Let (cid:4)x and (cid:4)y be the characteristic vectors for G and H , respectively, then (23) is equivalent to(cid:18)| A|(cid:5)(cid:18)(cid:18)(cid:18)i=1∂ v∂ Ai((cid:4)a)xi(cid:18)(cid:18)(cid:18)(cid:18) (cid:2) r(cid:18)(cid:18)(cid:18)(cid:18)∂ v∂ Ai| A|(cid:5)i=1(cid:18)(cid:18)(cid:18)(cid:18).((cid:4)a) yiWith this in mind, we define the meaning of attribute importance tradeoffs as follows. We write abs() to denote the absolutevalue of the gradient, that is, the absolute value of each element in a vector, so that abs((cid:4)x) = (cid:20)|x1|, |x2|, . . . , |xn|(cid:21). We use thisnotation to distinguish the absolute value from the length of the vector, |(cid:4)x|. For the following statement, recall that a vector(cid:4)x ∈ (cid:4)A is the characteristic vector for G if (cid:4)x is such that xi = 1 iff Ai ∈ G and xi = 0 otherwise.Definition 7.1 (Attribute importance tradeoffs). If (cid:4)x and (cid:4)y are characteristic vectors for attribute sets G and H respectively,then v ∈ (cid:2)c ⇒ G (cid:4)ai r : H(cid:3)v iff(cid:7)(cid:7)(cid:6)(cid:6)abs· (cid:4)x (cid:2) r∇ v((cid:4)a)holds on all points (cid:4)a ∈ (cid:2)c(cid:3)a.(cid:6)(cid:6)abs(cid:7)∇ v((cid:4)a)· (cid:4)y(cid:7)The condition (25) is clearly equivalent to (24) and so also to (23).Consider a simple example. Suppose we are going out to eat and need to pick a restaurant. In this context, amongthe things we might consider are the time required: the time to get to a given restaurant, and the time spent waitingonce at the restaurant. For instance, we can let travel time (tt) and wait time (wt) be continuous attributes measured inminutes, where less is better. We state a tradeoffs about these attributes: minutes(waittime) (cid:8)ai 1.5 : minutes(traveltime),which indicates that, in this estimation, it is roughly 50% more annoying to wait at the restaurant than to travel to it. Forbrevity, we define A = {wt, tt}, as shorthand for the longer propositional attributes. The characteristic vectors for wt and ttare, respectively, (1, 0) and (0, 1). From these, we can compute the condition provided on the utility function by Eq. (25),and obtain: | ∂ v∂ wt ((cid:4)x)| > 1.5| ∂ v∂tt ((cid:4)x)|.Definition 7.1 thus relates the “maximum increase” measure of importance between attribute sets to the “directional-derivative” representation of importance comparisons. This correspondence allows us to use the intuitive characterization ofimportance tradeoffs as comparisons of the maximum increase in two different subspaces while extending the frameworkof partial derivatives presented in Section 5 for the formal semantics.One may object that comparing the maximum increase of value in different subspaces seems an arbitrary choice, forwe could compare other statistics of the spaces instead, such as the average increase, the median increase, or the increaseat the origin. However, comparing the maximum increase of value in a space is appropriate in many cases, especially inwhat has been called “configuration problems,” in which the goal is to find the configuration of some elements (a schedule,a composite product, a results set, etc.) in a domain that maximizes the utility of the configuration. These situations are1140M. McGeachie, J. Doyle / Artificial Intelligence 175 (2011) 1122–1152characterized by the presence of a rational actor that chooses the configuration or outcome, and a lack of uncertainty:however the choice among outcomes is made, that is the outcome that results. In these cases, a rational actor will alwayschoose the outcome with greatest value, so the comparison of interest is between maximum increases in various constrainedspaces of the configuration problem.7.1. Properties of the semanticsWe first present two simple corollaries to Definition 7.1.Corollary 7.1. If G\H (cid:10)= ∅, then c ⇒ G (cid:4)ai r : H is satisfiable.Proof. If v is a linear function of the form v((cid:4)a) =that(cid:5)(cid:5)|ti| (cid:2) r|t j|.Ai ∈GA j∈H(cid:13)i ti v i((cid:4)a), then according to (23), v satisfies c ⇒ G (cid:4)ai r : H just in caseNow choose the weights for attributes in G\H so that the weight t of each attribute f ∈ G\H satisfies(cid:5)t > rA j ∈H|t j|,and choose weights for attributes not in G\H arbitrarily. The function v so defined then satisfies v ∈ (cid:2)c ⇒ G (cid:4)ai r : H(cid:3)v. (cid:2)Corollary 7.2. The conditional attribute tradeoff statement c ⇒ G (cid:4)ai r : G is satisfiable only if r (cid:3) 1 or if ∇ v is zero over attributes G.Proof. We have v ∈ (cid:2)c ⇒ G (cid:4)ai r : H(cid:3)v only if(cid:7)(cid:7)(cid:6)(cid:6)(cid:6)abs(cid:7)∇ v((cid:4)a)· (cid:4)x(cid:2) r(cid:6)abs(cid:7)∇ v((cid:4)a)· (cid:4)xfor each (cid:4)a ∈ (cid:2)c(cid:3)a. This is satisfied by any r (cid:3) 1, and when the inner product of the absolute value of the gradient of v at (cid:4)awith (cid:4)x is zero. Since (cid:4)x is a characteristic vector for G, it contains only zeros and ones. Since we take the absolute value of∇ v((cid:4)a), the elements of that vector are all greater or equal to zero. The inner product of two nonnegative vectors is zeroonly when each of the terms in the summation are zero. This is the case only when the gradient is zero in each attributein G. (cid:2)Our definition of an attribute tradeoff ratio leaves open the possibility that the two sets of attributes involved are notdisjoint, in which case the following result applies.Theorem 7.1 (Intersecting attributes). If G, H are sets of attributes with J = G ∩ H and v ∈ (cid:2)c ⇒ G (cid:4)ai r : H(cid:3)v, then(cid:18)(cid:5)(cid:18)(cid:18)(cid:18)(cid:18)(cid:18)(cid:18)((cid:4)a)(cid:18) + (r − 1)(cid:18)(cid:18)(cid:18)((cid:4)a)(cid:18) (cid:2) r(cid:18)(cid:18)(cid:18)((cid:4)a)(cid:18)(cid:5)(cid:18)(cid:18)(cid:18)(cid:18)(cid:5)(cid:18)(cid:18)(cid:18)(cid:18)f ∈(H\ J )∂ v∂ f∂ v∂ ff ∈ J∂ v∂ ff ∈(G\ J )for all (cid:4)a ∈ (cid:2)c(cid:3)a.We omit the proof, but it follows directly from Definition 7.1 by rearranging terms. An important corollary of Theorem 7.1is the case in which one set of attributes contains the other.Corollary 7.3. If G and H are sets of attributes such that H ⊂ G and r > 1, then(cid:2)c ⇒ G (cid:4)ai r : H(cid:3)a =(cid:4)c ⇒ G\H (cid:4)ai (r − 1) : H(cid:5)a.Proof. The proof is straightforward. By definition G (cid:4)ai r : H is(cid:18)(cid:18)(cid:18)(cid:18)(cid:5)f ∈G∂ v∂ f(cid:18)(cid:18)(cid:18)((cid:4)a)(cid:18) (cid:2) r(cid:18)(cid:18)(cid:18)(cid:18)(cid:5)f ∈H∂ v∂ f(cid:18)(cid:18)(cid:18)((cid:4)a)(cid:18).Since H ⊂ G, we can split the first summation, giving(cid:18)(cid:5)(cid:18)(cid:18)((cid:4)a)(cid:18).(cid:18)(cid:18)(cid:18)((cid:4)a)(cid:18) (cid:2) r(cid:18)(cid:18)(cid:18)((cid:4)a)(cid:18) +(cid:5)(cid:5)(cid:18)(cid:18)(cid:18)(cid:18)(cid:18)(cid:18)(cid:18)(cid:18)(cid:18)(cid:18)(cid:18)(cid:18)f ∈(G\H)∂ v∂ ff ∈Hf ∈H∂ v∂ f∂ v∂ fM. McGeachie, J. Doyle / Artificial Intelligence 175 (2011) 1122–11521141From this it is obvious that we have(cid:18)(cid:5)(cid:18)(cid:18)(cid:18)(cid:18)(cid:18)(cid:18)((cid:4)a)(cid:18) (cid:2) (r − 1)(cid:5)(cid:18)(cid:18)(cid:18)(cid:18)f ∈(G\H)∂ v∂ ff ∈Y(cid:18)(cid:18)(cid:18)((cid:4)a)(cid:18),∂ v∂ fwhich establishes our equivalence. (cid:2)Theorem 7.1 shows that intersecting attributes imply simplified constraints on the utility function, while Corollary 7.3shows that only in the case of one attribute set being contained within the other does this reduce to an attribute tradeoffbetween disjoint sets of attributes.For an example of a different character, someone preparing for armed conflict might wish to state that “Guns and bulletstogether are r-times more important than guns or bullets individually.” This is an example of complementary attributes thatare worth more together than they are separately, and it captures the desire of the quartermaster to balance, somehow,the amount of guns acquired and the amount of ammunition for those guns. Let us assume for simplicity that in thiscase A = {#guns, #bullets}, which are continuous attributes representing the number of guns and of bullets. Then supposethat the decision maker encodes his intuition as two importance statements: firstly, {#guns, #bullets} (cid:8)ai r : {#guns}, andsecondly, {#guns, #bullets} (cid:8)ai r : {#bullets}. By applying Corollary 7.3 these are equivalent to the pair{#bullets} (cid:8)ai r − 1 : {#guns},{#guns} (cid:8)ai r − 1 : {#bullets}.It is clear that these cannot hold simultaneously.We remark, however, that it is possible to express a related sentiment using conditional attribute importance statements.We could state that:(cid:6)(cid:7)#guns > k(#bullets)(cid:8)⇒ {#bullets} (cid:8)ai r : {#guns},(cid:9)#bullets >(#guns)⇒ {#guns} (cid:8)ai r : {#bullets}.1kTogether, these mean that while the number of one attribute, guns, is k times more than the number of bullets, it is moreimportant to gain additional bullets; while if this is not the case, then the attribute importance is reversed.Just as with bundle tradeoffs, attribute tradeoff statements reduce to linear conditions on the parameters of linear valuefunctions. We state here a lemma for attribute tradeoffs similar to Lemma 5.1. Recall that for a bundle b, σ (b) is the supportof b, the set of attributes assigned values other than ⊥ in b.Lemma 7.1. Suppose that x and y are bundles and v((cid:4)a) ={C1, C2, . . . , C Q } of A, with v i = v Ci . If v is linear in each A j ∈ A, then v ∈ (cid:2)σ (x) (cid:4)ai r : σ ( y)(cid:3)v iffi=1 ti v i((cid:4)a) is a generalized additive value function for a cover C =Q(cid:13)(cid:5)|k j| (cid:2) r(cid:5)|k j|.i∈σ (x)i∈σ ( y)(26)Just as tradeoff statements are transitive over common conditions, so are statements of conditional importance.Theorem 7.2 (Attribute transitivity). The conditional attribute tradeoff statementsc1 ⇒ G (cid:4)ai r1 : G(cid:3) (cid:4)ai r2 : Gc2 ⇒ G(cid:3),(cid:3)(cid:3)taken together entail the tradeoff statementc1 ∧ c2 ⇒ G (cid:4)ai r1r2 : G(cid:3)(cid:3).We omit the proof, which parallels that of Theorem 5.2 exactly.7.2. Importance of discrete attributesWe extend attribute importance comparisons over continuous value functions to comparisons over discrete attributes, aswe have done with bundle tradeoffs. Again, we use discrete difference equations as analogues to partial derivatives.1142M. McGeachie, J. Doyle / Artificial Intelligence 175 (2011) 1122–1152Definition 7.2 (Discrete importance statements). If G, H ⊆ A, then v ∈ (cid:2)c ⇒ G (cid:4)ai r : H(cid:3)v iff G is mutually preferentially inde-pendent of G, H is mutually preferentially independent of H , and, letting (cid:4)x and (cid:4)y, denote the characteristic vectors for Gand H , respectively, we have(cid:6)(cid:6)a, a(cid:6)a, a(cid:6)abs(cid:6)abs· (cid:4)x (cid:2) r(27)(cid:10)v(cid:10)v· (cid:4)y(cid:7)(cid:7)(cid:7)(cid:7)(cid:7)(cid:3)(cid:3)for all complete bundles a, a(cid:3)such that φi(a) (cid:10)= φi(a(cid:3)) with φ(a), φ(a(cid:3)) ∈ (cid:2)c(cid:3)a.It should be clear that this definition allows a correspondence between the discrete case and the continuous case,much as using a discrete approximation of partial derivatives sufficed in the case of attribute tradeoffs. The argumentsinvolved parallel those of Definition 5.3. Because much of what is said of discrete attribute tradeoffs can be said of discrete(cid:3)) in the definitionimportance tradeoffs, we do not repeat those statements here. We note that the limitations on (a, aparallel the differentiability constraints of the continuous case.We will, however, revisit the case of the coffee-drinking scientist. In our previous incarnation of this example, we sawthat a small cup of caffeinated coffee is twice a preferable as a large cup of decaffeinated coffee. Suppose we make thetradeoff more explicit with an attribute importance statement: coffee is equally or more important than size. Recall attributecoffee has domain {decaf , regular}, and size has domain {S, M, L}. We thus have a preference coffee (cid:8)ai size. Using thetranslation defined before, ρ(decaf ) = 1, ρ(regular) = 2, and for size we let ρ(S) = 1, ρ(M) = 2, ρ(L) = 3. The characteristicvector for coffee is then x = (1, 0), and for size y = (0, 1). Eq. (27) then becomes:(cid:6)a, a(cid:6)a, a(cid:6)abs(cid:10)v(cid:7)(cid:7)(cid:7)(cid:7)(cid:6)(cid:3)(cid:3)Consider a = (1, 3), a(cid:18)(cid:18)(cid:10)1 v(cid:18)(cid:18)(cid:10)2 v(cid:6)(cid:6)(1, 3), (2, 1)(1, 3), (2, 1)· (1, 0) (cid:2) abs· (0, 1).(cid:10)v(cid:3) = (2, 1), and the above becomes(cid:7)(cid:18)(cid:18) =(cid:7)(cid:18)(cid:18) =(cid:18)(cid:6)(cid:18)(cid:18)(cid:6)(cid:18)(cid:7)v(1, 3) − v(2, 3)(cid:7)v(1, 3) − v(1, 1)(cid:18)(cid:18),/(1 − 2)(cid:18)(cid:18)./(3 − 1)This lets us compute the dot-products as follows:(cid:6)abs(cid:6)abs(cid:10)v(cid:6)(cid:6)(cid:7)(cid:7)(1, 3), (2, 1)(cid:7)(cid:7)(cid:10)v(1, 3), (2, 1)(cid:18)(cid:18)−1· (1, 0) =· (0, 1) = 0 +(cid:6)v(1, 3) − v(2, 3)(cid:18)(cid:18)0.5v(1, 3) − v(1, 1)(cid:6)(cid:7)(cid:18)(cid:18) − 0,(cid:7)(cid:18)(cid:18)and these leave us with the constraint on the utility function: |v(2, 3) − v(1, 3)| (cid:2) 0.5|v(1, 3) − v(1, 1)|. Similarly, a = (2, 1),(cid:3))(cid:3) = (1, 3) gives us the constraint on the utility function: |v(2, 1) − v(1, 1)| (cid:2) 0.5|v(2, 3) − v(2, 1)|. Other values of (a, aaare shown in the table below, together with the constraint they imply on the utility function.a(1, 3)(2, 1)(1, 1)(2, 3)(cid:3)a(2, 1)(1, 3)(2, 3)(1, 1)Constraint|v(2, 3) − v(1, 3)| (cid:2) 0.5|v(1, 3) − v(1, 1)||v(2, 1) − v(1, 1)| (cid:2) 0.5|v(2, 3) − v(2, 1)||v(2, 1) − v(1, 1)| (cid:2) 0.5|v(1, 3) − v(1, 1)||v(2, 3) − v(1, 3)| (cid:2) 0.5|v(2, 3) − v(2, 1)|Note that including values of (a, ain unsatisfiable constraints (0 (cid:2) |v(1, 3) − v(1, 1)|).(cid:3)) such that φi(a) = φi(a(cid:3)) result in either trivial constraints (e.g., |v(2, 1) − v(1, 1)| (cid:2) 0) or8. Value function constructionWe have given many representations of different types of preferences. It remains now to join them together by providingvalue functions consistent with partial orderings over the attribute space representing a given set of preferences.In this section, we consider questions concerning construction of value functions that represent a satisfiable set of state-ments, including conditional qualitative ceteris paribus preferences, conditional marginal tradeoffs, and conditional attributetradeoff statements. The questions we address are the following. Can one find a value function consistent with a consistentset of preference statements? Under what circumstances can we find one efficiently? Does this provide a unified and flexibleframework for the expression of various types of preferences?In light of these aims, we clarify that we do not provide a consistency checking procedure for a set of statementsin Lopat. We are merely constructing a satisfying value function, the existence of which implies that the statements inquestion are consistent; but the absence of which does not imply the statements are necessarily inconsistent. Furthermore,we aim to find only one function consistent with a set of statements, and not all such functions. We regard the problemsof deducing what a set of preference specifications entail as a harder problem than merely constructing an example of theirsatisfiability. However, this example, corresponding to test cases, can sometimes help identify missing conditions on thedesired preferences, and so provide some information of the preferences’ scope and refinement.M. McGeachie, J. Doyle / Artificial Intelligence 175 (2011) 1122–11521143Much of the following augments techniques presented in [32] for constructing an ordinal value function for ceteris paribuspreferences over binary attributes. The presentation given here is updated to accommodate all of the types of preferencesdiscussed so far. There are still some sections and results that require little modification from the original, and as such areskipped here. For the modified theorems we present here as analogues to the theorems of [32], a more complete treatmentis found in [30].8.1. Value functions from qualitative ceteris paribus preferencesIn previous work [32], we considered how to create value functions from qualitative ceteris paribus statements. For con-sistent sets of ceteris paribus preferences over small domains, it is practical to use a method based on the ordering impliedby the statements over the entire domain. The idea is to look at the preference graph for a set of such statements, then usesome variant of a topological sort of that graph to rank-order the nodes of the graph in approximate desirability. Such anordering is isomorphic to a value function consistent with the input preferences. This technique is generally too inefficientto be used on an entire domain, but works well for the constituent subvalue functions of an additive value function.We describe in [32] a method for computing possible additive value decompositions of the domain attributes based ona set of qualitative ceteris paribus preferences. The method produces a collection of subsets of the attributes such that anadditive value function using each subset as the domain of a subvalue function can be defined. Such a function is of theformv((cid:4)a) =(cid:5)Ci∈Cti v Ci ((cid:4)a),for a cover C of the attributes A.This method is based on a technique using the structure of qualitative ceteris paribus preference statements to determinewhich attributes are necessarily preferentially dependent. This allows us to make intelligent assumptions about the structureof the value functions that are consistent with the input preferences. To extend this method to our current situation weneed to determine which attributes are preferentially independent given a set of marginal and attribute tradeoff preferences.We will show here that no such methods are possible, but we also show that no such methods are necessary.To examine this question we examine two concerns in this section. Firstly, does a tradeoff statement between attributes Gand attributes H imply that G and H are preferentially independent? The answer is no. Secondly, is it possible that G and Hare preferentially independent? The answer is yes whenever the tradeoffs made between G and H are satisfiable.It is not true that every tradeoff statement means there must be preferential independence between the related at-tributes. We present this result by demonstrating a counterexample.Theorem 8.1 (Preferential dependence). There exists v ∈ (cid:2)b (cid:4)mt r : bpreferentially dependent on σ (b(cid:3)).(cid:3)(cid:3)v with b, b(cid:3)nonempty bundles over A such that v has σ (b)Proof. We exhibit a simple example. Let A = { X, Y }. Let bundles b = ( X = 1), b(rx + y − 1)2 that exhibits preferential dependence of X on Y . (cid:2)(cid:3) = (Y = 1), and a value function v(x, y) =The opposite concern is also interesting. Is it always possible to create a linear additive value function (and therefore onethat exhibits preferential independence) given any set of tradeoff preferences? In fact, one can construct a piecewise linearvalue function for any set of satisfiable preferences.Theorem 8.2 (Preferential independence). For any satisfiable set of unconditional marginal tradeoff statements T , there exists v ∈ (cid:2)T (cid:3)vsuch that v is linear in each attribute in A.Proof. We are given some set T of unconditional marginal tradeoff preferences of the form b (cid:4)mt r : bover some set ofattributes A. These tradeoff statements, in turn, require that the partial derivatives of the value function satisfy conditions Cof the form(cid:3)∇ v((cid:4)a) · φ(b) (cid:2) r∇u((cid:4)a) · φ(cid:7)(cid:6)b(cid:3)(cid:3) ∈ (cid:4)A and for some particular bundles b, bfor all (cid:4)a, (cid:4)a. These constraints C hold at all points (cid:4)a in the preference space.A solution to C is a value for ∇ v((cid:4)a). If C is satisfiable, the solution to constraints C is a vector of numbers, let it be (cid:4)w, andthis vector is the vector of partial derivatives ∇ v((cid:4)a). In this case there exists v with ∇ v((cid:4)a) = (cid:4)w for all (cid:4)a ∈ (cid:4)A. This function vsatisfies the condition, and proves the theorem. (cid:2)(cid:3)One can extend this result to conditional tradeoff statements by considering piecewise linear value functions, but we donot do so formally here. Each condition divides the space into two parts, so by considering the regions defined by consistent1144M. McGeachie, J. Doyle / Artificial Intelligence 175 (2011) 1122–1152combinations of conditions, we choose a different linear value function for each such region. This is discussed in more detailin the following section.These two results combine to show that we can use our previous algorithm for computing a generalized additive de-composition from a set of preferences without modification. Although we have more and different types of preferencesin the current case, these two results show that only the ceteris paribus preferences are relevant to defining the additivedecomposition of the attributes.8.2. Value function construction(cid:3)Q(cid:3)(cid:3)The algorithm of [32] for computing a generalized additive decomposition results in a partition of A : C1, C2, . . . ,(cid:3)(cid:3)}, such that each set of attributes C} and corresponding set of sets of attributes B1, BCi is preferentially(cid:3)i . We define a cover C = {C1, C2, . . . , C Q } such thatdependent on the attributes B(cid:3)Ci = (Ci). Given the cover C , we construct an additive value function that is a linear combination of subvalue func-tions v i , each subvalue a separate function of a particular Ci . We associate a scaling parameter ti with each v i such that thevalue of a model is(cid:3)i and preferentially independent of A\B(cid:3)2, . . . , B(cid:3) = {B(cid:3) = {C∪ B(cid:3)Q(cid:3)iv(m) =Q(cid:5)i=1ti v i(m).(28)We will argue that this is consistent with a set of preferences M where M is a set of qualitative ceteris paribus preferencesstatements, conditional marginal tradeoff statements, and conditional attribute tradeoffs in Lopat. Given the cover C , wehave two remaining tasks: to craft the subvalue functions v i , and to choose the scaling constants ti . We will accomplishthese two tasks in roughly the following way. We partition input preferences into two sets, ceteris paribus and tradeoffpreferences. We use ceteris paribus preferences to make subvalue functions and the tradeoff preferences provide linear con-straints in a linear programming problem that sets the weights ti . There is a method in [32] that further partitions ceterisparibus preferences into those used to make subvalue functions and those that provide additional linear constraints on thescaling parameters. We say no more about subvalue functions here, techniques from [32] apply without modification. Toassign values to scaling parameters ti , we will define a set of linear inequalities which constrain the variables ti . The lin-ear inequalities can then be solved using standard methods for solving linear programming problems. The solutions to theinequalities are the values for the scaling parameters ti .8.2.1. Adding tradeoffs to qualitative ceteris paribus preferencesWe are going to construct three lists of linear inequalities,, that must be satisfied by choosing appropriatesubvalue function parameters ti . The constraints in list I will come from the given ceteris paribus tradeoff statements in M.These are computed by the methodology of [32], along with the subutility functions. Iwill represent the constraints in thebundle tradeoffs, and I, from the attribute tradeoffs.I ,(cid:3)(cid:3)II,(cid:3)and Mbe sets of marginal tradeoff and importance statements, respectively. For each marginal tradeoff statement(cid:3)(cid:3)(cid:3)(cid:3)Let M(cid:3)(cid:3)(cid:3)S ∈ M, where S = x (cid:4)mt r : y, by Definition 5.1, we have constraints of the formQ(cid:5)(cid:5)i=1A j ∈σ (x)∩Ci∂ v∂ Ai((cid:4)a)φ j(x) (cid:2) rQ(cid:5)(cid:5)k=1Al∈σ ( y)∩Ck∂ v∂ A j((cid:4)a)φl( y)and the partials can be computed from the subutility functions. Let the set of these constraints for all S ∈ Mlinear inequalities I.(cid:3)Then if we consider all the attribute statements S(cid:3) ∈ M(cid:3)(cid:3), we will obtain additional linear inequalities bounding thewhere(cid:3) = G (cid:4)ai r : H , S(cid:3) ∈ Mwith S(cid:3)(cid:3)(cid:3)tradeoff parameters ti of the value function. For each attribute tradeoff statement Sx, y are the characteristic vectors for G, H :(cid:7)(cid:7).(cid:3) ∈ MLet the set of these constraints for all Sbe the set of linear inequalities I(cid:7)∇ v((cid:4)a)(cid:7)∇ v((cid:4)a)(cid:6)abs(cid:6)abs(cid:2) r· (cid:4)y· (cid:4)x(cid:6)(cid:6)(cid:3)(cid:3)(cid:3)(cid:3).We will discuss conditional statements for conditions other than True ⇒ S in the following subsection.Any value function v ∈ (cid:2)I(cid:3)(cid:3)(cid:3)v is consistent with the tradeoff and attribute preferences the inequalities represent. We(cid:3), Istate the theorem here, which is true by definition of the preferences.Theorem 8.3 (General inequalities). Let Msystem of linear inequalities, I(cid:3) ∪ I(cid:3)(cid:3)be sets of marginal tradeoff and attribute preferences in Lopat, respectively. If the, has a solution, this solution corresponds to a value function v such that v ∈ (cid:2)M(cid:3) ∪ M(cid:3)(cid:3)(cid:3)v.(cid:3)(cid:3)(cid:3), MProof. Follows from the definitions of marginal and attribute tradeoff preferences. (cid:2)(29)(cid:3)be the set of(30)M. McGeachie, J. Doyle / Artificial Intelligence 175 (2011) 1122–11521145We can solve the system of linear inequalities I ∪ Iusing any linear inequality solver. We note that it is possible tophrase this as a linear programming problem, and use any of a number of popular linear programming techniques to findscaling parameters ti .(cid:3) ∪ I(cid:3)(cid:3)The number of inequalities in Iis determined by the number of the statements in the tradeoff preferences. Simplemarginal tradeoff preferences True ⇒ x (cid:4)mt r : y and attribute tradeoff statements True ⇒ G (cid:4)ai r : H contribute one linearinequality each. (Note that if statements are given in disjunctive normal form, like True ⇒ d (cid:4)mt r : dthen this statementresults in a number of inequalities: |d| ∗ |dadd a polynomial number of inequalities toinequality set I .(cid:3)|.) Consequently, preferences M(cid:3), M(cid:3)(cid:3)(cid:3)(cid:3)8.2.2. Piecewise linear value functionsWhen preferences are conditional, and hold at different regions in the outcome space (cid:4)A, these various preferences implydifferent constraints on the value function in separate regions of (cid:4)A. In general these constraints are not simultaneouslysatisfiable, and this necessitates different value functions for different regions of the space. In this way, the value functionfor one region can satisfy the constraints required of the value function in that region, and a value function for anotherregion can satisfy the constraints for that region. The value function for the whole attribute space (cid:4)A is then a collectionof different value functions for different subsets of the attribute space. Since each of these value functions are linear, thewhole becomes a piecewise linear value function.Definition 8.1 (Piecewise value function). U is a piecewise value function if U is a set of pairs (V , v V ) where V is a compoundvalue proposition and v V : (cid:4)A → R is a value function.U assigns the value v V ((cid:4)x) to (cid:4)x when (cid:4)x ∈ (cid:2)V (cid:3)a. We write U ((cid:4)x) for the value U assigns to (cid:4)x. In this way, a piecewisevalue function is like a switch or case statement in a programming language; it selects which of several value functions touse based on the input.When the value functions are linear in each of the attributes, different constraints on the value function are the result ofconditional preferences. This is straightforward; different preferences can be conditioned on different regions of the space,using the conditional preferences provided in the language Lopat.The conditional tradeoffs expressed in Lopat are binary conditions. In some region of the attribute space, the preferenceholds, and in the remainder of the attribute space, the preference does not apply. Thus, given k conditional statements, eachwith independent conditions, we have as many as 2k separate divisions of the attribute space with different preferencesholding in each division.Given k conditional tradeoffs, we can define the 2k subsets of the attribute space by the intersection of a unique subset of, then each w ∈ W is a separate compoundthe k conditions. Let W be the set of condition statements corresponding to Mvalue statement. Any subset V ⊆ W holds on a region of the attribute space defined by{w | w ∈ V }.(cid:19)(cid:3)For each subset V of W , the set of tradeoff preferences that hold over the corresponding space is just that whichcorrespond to the conditions. We state this in the following theorem.Theorem 8.4 (Space conditions). Given a set of conditional preferences M, with corresponding conditions W , each subset V ⊆ Wdefines a region of the attribute space{w | w ∈ V } where preferences corresponding to V in M hold.(cid:19)Proof. This theorem follows directly from the definition of conditional preference. (cid:2)Note that if conditionno further consideration.(cid:19){w | w ∈ V } is unsatisfiable, then V describes no portion of the attribute space, and so requiresThis theorem defines the regions of the space where different constraints hold. However, just because these regionshave different constraints, it does not mean that the constraints are mutually exclusive or unsatisfiable. Given a set ofconditions W and two subsets, V ⊂ W , Vare satisfiable by(cid:3)some value function v(cid:3) ⊂ W , if the value function constraints holding over V ∪ V, then this value function can be used for V ∪ V.(cid:3)(cid:3)In the presence of conditional tradeoff preferences, we proceed as follows. For a set of conditional and unconditional(cid:3)(cid:3)}, consider the set W of conditions on those preferences. For each subset Vtradeoff and attribute preferences {M(cid:3)(cid:3)} conditioned by V . Then for preferences J ∪ M, we can construct setsof W , let J be the set of preferences from {Mof linear inequalities as discussed in the preceding section; the solution to this set of linear inequalities gives us a value{w | w ∈ V }.function. This value function, in turn, is the value function for the subset of the attribute space indicated byIn this way, we construct separate value functions for different sections of the attribute space.(cid:3) ∪ M(cid:3) ∪ M(cid:19)The methods of dealing with different conditions on tradeoffs here can be computationally difficult. It is possible thatborrowing techniques from constraint satisfaction literature would be efficacious here.8.3. A detailed exampleLet us consider an example and how it can fit into the frameworks mentioned above. Suppose we are going out to eat inBoston, and need to pick a restaurant. We consider the food, the wine, the atmosphere, the time to get there, and the time1146M. McGeachie, J. Doyle / Artificial Intelligence 175 (2011) 1122–1152spent waiting once at the restaurant. Usually, in Boston, restaurants are crowded, and since we do not have reservationsexpedience can be a serious concern. Let (cid:4)A = (cid:20)m, w, a, tt, wt(cid:21) for meal, wine, atmosphere, travel time, and wait time. Then letmeal have two values: b1 = meat, b2 = fish; wine have two values: w 1 = red, w 2 = white; and atmosphere have three values:a1 = bland, a2 = gaudy, a3 = quiet. Travel time and wait time will be measured in minutes. We now state some simple ceterisparibus preferences:p1p2p3p4p5VariablemwwaaPreferencesfish (cid:8) meatfish ∧ white (cid:8) fish ∧ redmeat ∧ red (cid:8) meat ∧ whitequiet (cid:8) gaudygaudy (cid:8) blandThese preferences mean that we prefer fish to meat. Preferences p2 and p3 mean that our preference for wine dependson the main course. The remaining two preferences establish an order over the possible restaurant atmospheres.Travel time and wait time are numeric attributes where less is better. We state tradeoffs about these attributes: wt (cid:8)ai1.5 : tt, which indicates that is roughly 50% more annoying to wait at the restaurant than to travel to it. These preferenceshave laid the groundwork for a tradeoff between groups of attributes: {m, w, a} (cid:8)ai 10 : {tt, wt}. Suppose someone in thedinner party asserts that {(wt = 15), (tt = 10)} (cid:8)mt {(m = meat), (w = white)}, meaning that a moderate delay is preferableto having white wine with dark meat. This last preference (p8, below) is somewhat fanciful but illustrates the tradeoffbetween delay and meal quality. We then have these three tradeoff preferences:p6p7p8Preferenceswt (cid:8)ai 1.5 : tt{m, w, a} (cid:8)ai 10 : {tt, wt}{(wt = 15), (tt = 10)} (cid:8)mt {(m = meat), (w = white)}Preferences p6–p8 imply the following conditions on the partial derivatives of the value function:s1s2s3Conditions∂ wt ((cid:4)x)| > 1.5| ∂ v| ∂ v∂m ((cid:4)x)| + | ∂ v| ∂ v∂ wt ((cid:4)x) + 10 ∂ v15 ∂ v∂tt ((cid:4)x)|∂ w ((cid:4)x)| + | ∂ v∂tt ((cid:4)x) > ∂ v∂a ((cid:4)x)| (cid:2) 10(| ∂ v∂ w ((cid:4)x)∂m ((cid:4)x) + ∂ v∂tt ((cid:4)x)| + | ∂ v∂ wt ((cid:4)x)|)We return to the ordinal attributes, and can now construct subvalue functions for each of the attributes, or, in thiscase, for each preferentially independent set of attributes. Here attribute w is preferentially dependent on attribute m, sofollowing the system of [32], we generate one subvalue function for {m, w}, one subvalue function for a, one for tt, andone for wt. For the qualitative attributes, we can specify their subvalue functions simply by assigning numbers to each ofthe qualitative alternatives of each attribute, and using these assignments as the output of the subvalue function for theseattributes, respectively. To continue this example, let us assign subvalue functions as follows:Subvaluev{m,w}(fish, white)v{m,w}(fish, red)v{m,w}(meat, red)v{m,w}(meat, white)Value3221Subvalueva(quiet)va(gaudy)va(bland)Value321For numeric attributes wt and tt, we can choose a simple linear subvalue function. We take v wt = −wt and vtt = −tt.The subvalue functions are now known, and the form of the value function (additive) is known, that is, the valuefunction is of the form: v((cid:4)a) =i ti v i((cid:4)a). But before we can use the inequalities involving the partial derivatives of thevalue function, we must assign value functions, ρ, that take the discrete domains to numbers. We proceed in the moststraightforward way, and assign values as follows:(cid:13)Value functionValueValue functionValueρm(fish)ρm(meat)ρw (white)ρw (red)2121ρa(quiet)ρa(gaudy)ρa(bland)321M. McGeachie, J. Doyle / Artificial Intelligence 175 (2011) 1122–11521147In Section 5.4 we argued that the slope of a linear subvalue function can be used as the partial derivative of thatsubvalue function with respect to the value of our ordinal attributes, and therefore we can compute the partial derivativesof the value function and simplify conditions s1, s2, and s3. We must consider that we have different partial derivatives atdifferent vectors in (cid:4)A. In particular, when we evaluate the partials of v with respect to m and to w, we let x be in thedomain of m, and y be in the domain of w. In these cases we have∂ v∂ w∂ v∂m(x, y) = t{m,w}(cid:6)(x, y) = t{m,w}(cid:6)(cid:7)v{m,w}(x, white) − v{m,w}(x, red)/(cid:7)v{m,w}(fish, y) − v{m,w}(meat, y)/(cid:6)(cid:7)ρ(white) − ρ(red)(cid:7)(cid:6)ρ(fish) − ρ(meat),.Note that the other partial derivatives are straightforward (following from Lemmas 5.1 and 7.1). Thus, using the above, whenwe fix m = fish when computing ∂ v∂ w (w) and w = white when computing ∂ v(cid:7)(cid:6)∂m (m) we have|2t{m,w}| + |t{m,w}| + |ta| (cid:2) 10|−ttt| + |−t wt|.Similarly if we fix m = meat and w = white then|2t{m,w}| + |−t{m,w}| + |ta| (cid:2) 10(cid:6)|−ttt| + |−t wt|(cid:7),and m = fish with w = red gives(cid:6)|−ttt| + |−t wt|0 + |t{m,w}| + |ta| (cid:2) 10(cid:7).Finally fixing m = meat and w = red gives this constraint0 + |−t{m,w}| + |ta| (cid:2) 10(cid:6)|−ttt| + |−t wt|(cid:7).Some of these constraints are identical because of the absolute value functions, so we can collect cases into two, and have3t{m,w} + ta (cid:2) 10(ttt + t wt) w = white,t{m,w} + ta (cid:2) 10(ttt + t wt) w = red.When computing the constraints implied by condition s3, we get slightly different results for m = meat and for m = fish.These appear with the other constraints on the parameters of the value function in the table below:c1c2c3c4c5Constraint3t{m,w} + ta (cid:2) 10(ttt + t wt )t{m,w} + ta (cid:2) 10(ttt + t wt )t wt (cid:2) 1.5ttt15t wt + 10ttt > tmw15t wt + 10ttt > −tmww = whitew = redm = fishm = meatThese systems of linear inequalities can be solved for the different cases, in principle resulting in piece-wise linear valuefunctions. In this case, since constraint c1 follows from constraint c2, and c5 from c4 for positive t’s, there is no need tohave different functional forms of the value function based on different values of the w attribute. Therefore, a solution forthis construction is tm,w = 1, ta = 50, t wt = 3, and ttt = 2.Thus a value function for this example isv((cid:4)x) = vm,w ((cid:4)x) + 50va((cid:4)x) + 3v wt((cid:4)x) + 2vtt((cid:4)x).Such a value function can then be used to make decisions between different alternatives. Consider the three hypotheticalrestaurants in the following table:wtttam, wv()A−15−15loudfish, white−22B−45−5simplefish, white−42C−25−60elegantmeat, red−43In such a situation restaurant A is preferable.1148M. McGeachie, J. Doyle / Artificial Intelligence 175 (2011) 1122–11528.4. A sound algorithm for value function constructionIn the preceding, we have described several parts of an algorithm for computing with qualitative ceteris paribus preferencestatements, marginal tradeoff preferences, and conditional attribute tradeoffs. This has given us enough tools to accomplishour goal: generating a value function consistent with various types of input preferences. We will outline the algorithm forsuch here.The algorithm takes as input a set M of qualitative ceteris paribus preference statements, of marginal tradeoff statements,and of attribute statements, in the language Lopat, and parameters for building subvalue functions (from [32]). Simplyspeaking, a generalized additively independent cover of the attributes is computed. Then the preferences are interpreted asconstraints on the partial derivatives of the value function. Next, the conditions on the preferences are considered, and apartition of the attribute space is created. Then the constraints are solved using linear programming; giving values for theparameters of the additive value function. The algorithm finally outputs a piecewise linear value function U , a set of pairs(V , v V ) such that each value functions v V is consistent with the input preferences at a different region V of the attributespace (cid:4)A.Some remarks must be said about the failure conditions of this algorithm, by which we mean, the algorithm encoun-tering error conditions that cause it to stop. First of all, the algorithm may fail because the steps concerning merely thequalitative ceteris paribus preferences can fail; these are heuristic methods. As we discuss in [32], consistent ceteris paribuspreferences can always be represented by a trivial value function; one that orders each outcome according to the pre-order implied by the preferences, but this gains none of the advantages of a generalized additive decomposition valuefunction.Secondly, a set of tradeoff preferences cannot be considered to be consistent or inconsistent without knowledge ofthe partial derivatives of the value function. The partial derivatives of the value function, in this case, are determined bythe generalized additive decomposition of the attribute space. Thus we cannot know with certainty before the algorithmdetermines the additive decomposition of the attribute space if the tradeoff preferences are consistent or not.With these shortcomings in mind, we must consider this algorithm heuristic. There is always the possibility of con-flicting preferences leading to no solution. However, when the algorithm finds a solution, it is guaranteed to represent theinput preferences faithfully. This algorithm, therefore, fulfills its main purpose: it illustrates that tradeoff preferences canin principle be combined with qualitative ceteris paribus preferences of the type presented in Section 6. Indeed, we showin the next section that tradeoff preferences can be combined with the CP-net representation of qualitative ceteris paribuspreferences.The soundness of this algorithm can be proven by reference to the preceding theorems of this article, and to thoseappearing in [30].Theorem 8.5 (Soundness). Given a set of ceteris paribus, marginal tradeoff, and attribute preferences M, if the above-outlined algo-rithm produces a piecewise linear value function U , then U ∈ (cid:2)M(cid:3)v.A proof appears in [30].9. Quantitative tradeoffs and CP-netsIn general, the tradeoffs and importance preference statements described in this article generate linear constraints on theparameters of additive value functions. These constraints can be easily integrated with any preference or utility estimationsystem that uses linear inequalities to constrain the parameters of possible value functions. And since linear models ofutilities are so common in practice, the system we have proposed should be widely applicable. In the previous section weshowed how to combine tradeoff preferences with the method of [32]. In the present section we show how to combine thelinear inequalities generated from our preference tradeoff statements with the CP-nets system. We stress that integrationwith these two systems are merely representative of other possible integrations.Methods proposed by Brafman, Domshlak, and Kogan [8] take CP-nets [5] and TCP-nets [9] and generate a value func-tion consistent with the order implied by the CP-net or TCP-net. These methods use qualitative ceteris paribus preferenceas their input, and output a generalized additive-independent ordinal value function. When we consider the system wehave presented in this article alongside the systems based on CP-nets, we find there are differences of expressiveness andtractability. CP-nets place restrictions on the form of the preference statements, and make independence relationships ex-plicit; the methodology we have presented allows arbitrary qualitative ceteris paribus preferences and infers independencefrom the statements. The restrictions on CP-nets allow strong tractability results. Acyclic TCP-nets, for example, always allowefficient value function construction [7]. Such differences mean that both CP-nets and the preference statements presentedherein may be appropriate in different situations.We now demonstrate that the various quantitative tradeoffs we have developed fit easily together with CP-nets. And,following that exposition we will briefly outline a correspondence between our tradeoffs and the tradeoffs of TCP-nets [9].M. McGeachie, J. Doyle / Artificial Intelligence 175 (2011) 1122–115211499.1. Adding quantitative tradeoffs to CP-netsFig. 1. CP-net for preferences p1–p5.To add quantitative tradeoffs to CP-nets we require two things of the value function; one, that it should be a generalizedadditive value function and two, that it should have linear subvalue functions.Using the methods of [8,7] to compile a CP-net into a value function, commits us to using a generalized additive valuefunction. We can force the subvalue functions (termed “factors” in that source) of this value function to be linear in theirinput by adding additional inequalities to the system of linear equations that generates the value function. These conditionsassure that our tradeoff statements in Lopat can be easily added to the CP-net.The system of linear inequalities constructed by [7, Section 3] has one variable per input per subvalue function, sowe can add additional linearizing inequalities assuring that the output of the subvalue function for X is linear in X . Theproper ordering among values of X can be found by considering the CP-Family of X [7, Section 3], and computing a dif-ferent linear program for each possible ordering consistent with the CP-Family. This is a locally-exponential addition tothe complexity of value function construction, so the problem remains in P when the exponents are bounded by a con-stant.After assuring the subvalue functions are linear in their input, it is simple to solve an additional system of linear inequal-ities which constrain the tradeoff ratios between subvalue functions. This new problem has one variable for each subvaluefunction, representing the weight given to it in the generalized additive value function, and one or more inequalities foreach tradeoff statement S ∈ Lopat. Each tradeoff statement results in linear constraints on the tradeoff parameters of thevalue function, but may result in different constraints over different areas of the domain of the value function. This isthe case when the preferences over one attribute, and thus partial derivatives with respect to that attribute, switch withthe values assumed by a different attribute. Such is the normal case of utility dependence between attributes. In thesecases, the value function will be a piecewise linear one, having different functional forms for different parts of its do-main.9.2. A CP-net exampleWe previously considered an example involving choosing a restaurant in Boston. We will work through the same examplehere, again, but this time in a CP-net framework. This illustrates the differences between the CP-net formalism and themethods presented earlier in this article.We again choose (cid:4)A = (cid:20)m, w, a, tt, wt(cid:21) for meal, wine, atmosphere, travel time, and wait time, just as in the previousexample.The simple ceteris paribus preferences we used before, p1–p5 can be used to construct a CP-net.In a CP-net for these preferences, we have to consider which attributes are preferentially dependent. In this case only wdepends on m so we draw the CP-net as shown in Fig. 1.We likewise use the same tradeoff preferences (p6–p8) from our previous example. These tradeoffs imply the sameconstraints as before, but here they are an addendum to the CP-net framework: we will keep them aside for now.To compute a value function for the CP-net we must solve a system of linear inequalities, of the form of inequality 1in [8]. In this case, it results in the following linear inequalities:e1e2e3e4e5e6Preferencesva(quiet) > va(gaudy)va(gaudy) > va(bland)v w (fish, white) > v w (fish, red)v w (meat, red) > v w (meat, white)vm(fish) + v w (fish, white) > vm(meat) + v w (meat, white)vm(fish) + v w (fish, red) > vm(meat) + v w (meat, red)We can then add linearizing inequalities to the system, forcing 3ka va(quiet) (cid:2) 2ka va(gaudy) (cid:2) ka va(bland) and 3ka va(quiet) (cid:3)2ka va(gaudy) (cid:3) ka va(bland), using a new variable ka. We make similar inequalities for v w and vm. We require these1150M. McGeachie, J. Doyle / Artificial Intelligence 175 (2011) 1122–1152additional inequalities to force the subvalue functions for each attribute in the CP-net to be linear; this simplifies ourmethodology. A solution is as follows:Subvaluevm(fish)vm(meat)va(quiet)va(gaudy)va(bland)kmValueSubvalueValue213211v w (fish, white)v w (fish, red)v w (meat, red)v w (meat, white)kakw432111For attributes wt and tt, we use these linear subvalue functions : v wt = −wt and vtt = −tt.The partial derivatives of the value function are different in the CP-nets example than those in our previous example. Wecompute the partial derivatives of v with respect to each attribute, paying special attention to the formulae for the partialsof m and of w. For x ∈ {fish, meat} and y ∈ {white, red}, we have(x, y) = t w(cid:6)(cid:7)v w (x, white) − v w (x, red)/(x, y) = t w(cid:6)(cid:7)v w (fish, y) − v w (meat, y)/(cid:7)(cid:6)ρ(white) − ρ(red)(cid:7)(cid:6)ρ(fish) − ρ(meat),(cid:6)(cid:7)vm(fish) − vm(meat)(cid:6)(cid:7)ρ(fish) − ρ(meat)./+ tm∂ v∂ w∂ v∂mThus, when we fix m = fish when computing ∂ v∂ w (w) and w = white when computing ∂ v∂m (m) we have|t w | + |3t w | + |tm| + |ta| (cid:2) 10(cid:6)|−ttt| + |−t wt|(cid:7).Similarly if we fix m = meat and w = white then|−t w | + |3t w | + |tm| + |ta| (cid:2) 10(cid:6)|−ttt| + |−t wt|(cid:7),and m = fish with w = red gives|t w | + |−t w | + |tm| + |ta| (cid:2) 10(cid:6)|−ttt| + |−t wt|(cid:7).Finally fixing m = meat and w = red gives this constraint|−t w | + |−3t w | + |tm| + |ta| (cid:2) 10(cid:6)|−ttt| + |−t wt|(cid:7).As we did with the constraints in the last example, we can again collect cases into two, and have4t w + tm + ta (cid:2) 10(ttt + t wt) w = white,2t w + tm + ta (cid:2) 10(ttt + t wt) w = red.These constraints can then be collected with all other constraints on the parameters of the value function. We then havethe following constraints on the parameters of the value function:c1c2c3c4c5Constraint4t w + tm + ta (cid:2) 10(ttt + t wt )2t w + tm + ta (cid:2) 10(ttt + t wt )t wt (cid:2) 1.5ttt15t wt + 10ttt > t w15t wt + 10ttt > −t ww = whitew = redm = fishm = meatThe only remaining step is to solve this system of linear inequalities for the tradeoff parameters t. As in the previousexample, constraint c1 follows from constraint c2, so there is no need to have different functional forms of the valuefunction based on different values of the w attribute. A solution to the CP-net system of inequalities is tm = 1, t w = 1,ta = 50, t wt = 3, and ttt = 2.Thus a value function for the CP-net isv((cid:4)a) = vm((cid:4)a) + 50va((cid:4)a) + v w ((cid:4)a) + 3v wt((cid:4)a) + 2vtt((cid:4)a).M. McGeachie, J. Doyle / Artificial Intelligence 175 (2011) 1122–115211519.3. Other types of CP-netsIt should be clear from the preceding discussion that the qualitative ceteris paribus preferences in a CP-net can be trans-posed with little difficulty to ceteris paribus preferences in Lopat.The conditional preferences of a CP-net are of the form: c ⇒ x1 (cid:8) x2 for an attribute X and values x1, x2 ∈ D( X) andsome conditions in c such that X /∈ σ (c). In the formalism of the CP-network, the conditions c involve the parents ofattribute X according to the network topology of the network; in a ceteris paribus preference in Lopat c is merely a setof arbitrary conditions. We state that a conditional preference from a CP-net c ⇒ xi (cid:8) x j is equivalent to a ceteris paribuspreference c ⇒ xi (cid:8)cp x j , although we leave a proof of this to future work.The tradeoffs in TCP-net are conditional qualitative tradeoffs, wherein a selector set of attributes Z determine the partic-ular tradeoff between two other attributes X, Y . In [9], this is written RI( X, Y |Z), meaning that the Relative Importance ofX and Y is conditional on values taken by attributes in Z . When the relative importance of X is greater than that of Y ,then written X (cid:5)z Y any (small) increase in X is preferable to any (possibly large) increase in Y . In these cases, there isa preference order over the domain of X expressed in the CP-net portion of the TCP-net, and similarly with Y . In Lopat,we can express a structurally similar tradeoff by z1 ⇒ X (cid:8)ai r : Y together with z2 ⇒ Y (cid:8)ai r : X , where z1 indicates valuesof Z for which X (cid:5) Y and z2 indicates values of Z where Y (cid:5) X . We have only to choose a very small value of r such thatit approximates the dominance of X (cid:5) Y ; we must choose r such that r times max i, j(v Y ( yi) − v Y ( y j)) is smaller thanmini, j(v X (xi) − v X (x j)). Again, we leave a proof of such equivalence, as well as selection methods for r, to future work.While the forgoing may lead to possible advantages of mixing representations, it may be advantageous to convert aCP-net or TCP-net to preferences in Lopat if the CP-net or TCP-net cannot be fully elicited or specified.10. ConclusionsWe have presented novel methods for enriching systems of qualitative ceteris paribus preferences with quantitativetradeoffs of various types over multiple attributes. These preference systems can then be compiled into quantitative valuefunctions using modifications of existing techniques. Our work here has provided an important extension to both the sys-tems of [31] and [5].The main contribution of this article has been the representation of tradeoffs as constraints on the partial derivatives ofthe value function. We have demonstrated that this general approach to tradeoff semantics is broad enough to cover (1)tradeoffs between particular values of attributes, (2) importance constraints between sets of attributes, (3) multiattributetradeoffs of each preference type considered, and (4) tradeoffs over discrete and continuous attributes.We also obtained numerous results relating these types of constraints to each other and to earlier notions. Our seman-tics for multiattribute marginal tradeoffs, applied to pairs of individual attributes, reduces to the notion of marginal rateof substitution familiar in economics, and our semantics for discrete marginal tradeoffs allows for rerepresentation of thequalitative ceteris paribus preferences of Doyle, Wellman and Shoham [14]. Among our new concepts, we show that discretemarginal tradeoffs reduce to continuous bundle tradeoffs, that discrete attribute tradeoffs reduce to continuous attributetradeoffs, and that discrete marginal tradeoffs reduce to discrete attribute tradeoffs when the bundles involved are equiva-lent to the characteristic vectors of the sets of attributes related in the attribute tradeoff.These results show that one can combine all of these tradeoff preferences into a single methodology, together withqualitative ceteris paribus preferences, for computing a value function representing preference statements of all forms. Fur-thermore, these combination methods can function with however many or few preferences happen to be available, thesepreferences can be over any attributes, and there need be no explicit preferential independence or preferential dependencegiven with the preferences. These are all significant departures from the assumptions underlying traditional decision analy-sis.Our representation of tradeoff statements as constraints on the partial derivatives of the value function is novel, andit raises many new questions for further research, both in its own right, and in interaction with ceteris paribus preferencestatements.The basis of our interpretation of attribute importance tradeoffs is the ratio of gradients of the value function. Our useof the magnitude of the gradient of the value function to calibrate the relative utilities of two subspaces is a heuristicchoice, and one could employ other measures instead, such as some kind of average-case improvement measure that triesto capture the average case outcome.Some problems for further investigation concern the interaction of complex constraints on derivatives over nonlinearsubvalue functions, especially when constructing piecewise linear value functions and when considering preferentially de-pendent attributes and preference reversals. When do preference reversals result in mutually incompatible constraints? Dopreference reversals require negative values of the subvalue function scaling parameters? Can one characterize the types ofsubvalue functions that require piecewise linear solutions and those that do not?One might investigate the integration of our partial-derivative based tradeoff preferences with other preference reasoningsystems. There could be a stronger integration of our results with TCP-nets. One might seek a combination with answer-setsolvers that incorporate preference representations [11]. A combination with a machine-learning system based on an SVMarchitecture [12] might be straightforward, but the value of this combination of techniques would require assessment.1152M. McGeachie, J. Doyle / Artificial Intelligence 175 (2011) 1122–1152AcknowledgementsWe thank Peter Szolovits, Patrick Winston, and Howard Shrobe for comments, encouragement, and support. We alsothank the anonymous reviewers of earlier versions of this manuscript for their helpful and encouraging comments, andthank one reviewer in particular for suggestions regarding the guns and bullets example. Michael McGeachie is grateful forsupport from DARPA, a training grant from the National Library of Medicine, and the Pfizer Corporation. Jon Doyle thanksSAS Institute for its endowment that supports his work.References[1] F. Bacchus, A. Grove, Graphical models for preference and utility, in: Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence,Morgan Kaufmann, 1995, pp. 3–19.[2] F. Bacchus, A. Grove, Utility independence in a qualitative decision theory, in: Proceedings of the Fifth International Conference on Knowledge Repre-sentation and Reasoning, Morgan Kaufmann, 1996, pp. 542–552.[3] J. Beattie, J. Baron, Investigating the effect of stimulus range on attribute weight, Journal of Experimental Psychology: Human Perception and Perfor-mance 17 (2) (1991) 571–585.[4] C. Boutilier, F. Bacchus, R.L. Brafman, UCP-networks: A directed graphical representation of conditional utilities, in: Proceedings of Seventeenth Confer-ence on Uncertainty in Artificial Intelligence, Seattle, 2001.[5] C. Boutilier, R.I. Brafman, C. Domshlak, H.H. Hoos, D. Poole, Cp-nets: A tool for representing and reasoning about conditional ceteris paribus preferencestatements, Journal of Artificial Intelligence Research 21 (2004) 135–191.[6] C. Boutilier, R.I. Brafman, H.H. Hoos, D. Poole, Reasoning with conditional ceteris paribus preference statements, in: Proceedings of Uncertainty inArtificial Intelligence (UAI-99), 1999.[7] R.I. Brafman, C. Domshlak, Graphically structured value-function compilation, Artificial Intelligence Journal 172 (2–3) (2008) 325–349.[8] R.I. Brafman, C. Domshlak, T. Kogan, Compact value-function representations for qualitative preferences, in: Proceedings of Uncertainty in ArtificialIntelligence (UAI’04), AUAI Press, Arlington, VA, 2004, pp. 51–59.[9] R.I. Brafman, C. Domshlak, S.E. Shimony, On graphical modeling of preference and importance, Journal of Artificial Intelligence Research 25 (2006)389–424.[10] D. Braziunas, C. Boutilier, Local utility elicitation in GAI models, in: Proceedings of the Twenty-first Conference on Uncertainty in Artificial Intelligence,Edinburgh, 2005, pp. 42–49.[11] G. Brewka, Answer sets and qualitative decision making, Synthese 146 (2004) 171–187.[12] C. Domshlak, T. Joachims, Unstructuring user preferences: Efficient non-parametric utility revelation, in: Proceedings of the Twenty-first Annual Con-ference on Uncertainty in Artificial Intelligence (UAI-05), AUAI Press, 2005, p. 169.[13] J. Doyle, M. McGeachie, Exercising qualitative control in autonomous adaptive survivable systems, in: Revised papers from the Second InternationalWorkshop on Self-Adaptive Software (IWSAS 2), May 2001, Springer Verlag, Berlin, 2003, pp. 158–170.[14] J. Doyle, Y. Shoham, M.P. Wellman, A logic of relative desire (preliminary report), in: Z. Ras (Ed.), Proceedings of the Sixth International Symposium onMethodologies for Intelligent Systems, in: Lecture Notes in Computer Science, Springer Verlag, Berlin, 1991, pp. 158–170.[15] D. Dubois, H. Prade, Possibilistic logic: A retrospective and prospective view, Fuzzy Sets and Systems 144 (2004) 3–23.[16] W. Edwards, F.H. Barron, Smarts and smarter: Improved simple methods for multiattribute utility measurement, Organizational Behavior and HumanDecision Making 60 (1994) 306–325.[17] Y. Engel, M.P. Wellman, CUI networks: A graphical representation for conditional utility independence, Journal of Artificial Intelligence Research 31(2008) 83–112.[18] G.W. Fischer, Range sensitivity of attribute weights in multiattribute value models, Organizational Behavior and Human Decision Processes 62 (3)(1995) 252–266.[19] P.C. Fishburn, Decision and Value Theory, John Wiley & Sons, New York, 1964.[20] C. Gonzales, P. Perny, GAI networks for utility elicitation, in: Proceedings of the Ninth International Conference on Knowledge Representation andReasoning (KR’04), 2004.[21] C. Gonzales, P. Perny, GAI networks for decision making under certainty, in: IJCAI’05 – Workshop on Advances in Preference Handling, 2005.[22] W.M. Gorman, The structure of utility functions, Review of Economic Studies 35 (1968) 367–390.[23] S.O. Hansson, A new semantical approach to the logic of preference, Erkenntnis 31 (1989) 1–42.[24] J.M. Henderson, R.E. Quandt, Microeconomic Theory: A Mathematical Approach, third ed., McGraw–Hill, New York, 1980.[25] R. Keeney, H. Raiffa, Decisions with Multiple Objectives: Preferences and Value Tradeoffs, Wiley and Sons, New York, 1976.[26] R.L. Keeney, Value-Focused Thinking: A Path to Creative Decision Making, Harvard University Press, Cambridge, MA, 1992.[27] D.H. Krantz, R.D. Luce, P. Suppes, A. Tversky, Foundations of Measurement, Academic Press, New York, 1971.[28] P. La Mura, Y. Shoham, Expected utility networks, in: Proceedings of 15th Conference on Uncertainty in Artificial Intelligence, 1999, pp. 366–373.[29] J. Lang, L. Van Der Torre, E. Weydert, Utilitarian desires, Autonomous Agents and Multi-Agent Systems 5 (3) (2002) 329–363.[30] M. McGeachie, Local geometry of multiattribute preference tradeoffs, Ph.D. thesis, Tech. rep. MIT-CSAIL-TR-2007-029, Massachusetts Institute of Tech-nology, Cambridge, MA, 2007.[31] M. McGeachie, J. Doyle, Efficient utility functions for ceteris paribus preferences, in: AAAI Eighteenth National Conference on Artificial Intelligence,Edmonton, Alberta, 2002.[32] M. McGeachie, J. Doyle, Utility functions for ceteris paribus preferences, Computational Intelligence 20 (2) (2004) 158–217.[33] H. Raiffa, Decision Analysis: Introductory Lectures on Choices Under Uncertainty, Addison–Wesley, Reading, MA, 1968.[34] L.J. Savage, The Foundations of Statistics, John Wiley & Sons, New York, 1954.[35] J. von Neumann, O. Morgenstern, Theory of Games and Economic Behavior, Princeton University Press, 1944.[36] B. von Stengel, Decomposition of multiattribute expected-utility functions, Annals of Operations Research (1988).[37] G.H. von Wright, The Logic of Preference: An Essay, Edinburgh University Press, Edinburgh, 1963.[38] M. Wellman, J. Doyle, Preferential semantics for goals, in: T. Dean, K. McKeown (Eds.), Proceedings of the Ninth National Conference on ArtificialIntelligence, AAAI Press, Menlo Park, CA, 1991, pp. 698–703.[39] M.P. Wellman, J. Doyle, Modular utility representation for decision-theoretic planning, in: Proceedings of the First International Conference on AIPlanning Systems, 1992, pp. 236–242.[40] N. Wilson, Extending CP-nets with stronger conditional preference statements, in: Proceedings of Nineteenth National Conference on AI (AAAI’04),2004, pp. 735–741.