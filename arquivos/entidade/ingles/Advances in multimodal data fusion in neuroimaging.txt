Since January 2020 Elsevier has created a COVID-19 resource centre with free information in English and Mandarin on the novel coronavirus COVID-19. The COVID-19 resource centre is hosted on Elsevier Connect, the company's public news and information website. Elsevier hereby grants permission to make all its COVID-19-related research that is available on the COVID-19 resource centre - including this research content - immediately available in PubMed Central and other publicly funded repositories, such as the WHO COVID database with rights for unrestricted research re-use and analyses in any form or by any means with acknowledgement of the original source. These permissions are granted for free by Elsevier for as long as the COVID-19 resource centre remains active.   Information Fusion 64 (2020) 149–187 Contents lists available at ScienceDirect Information Fusion journal homepage: www.elsevier.com/locate/inffus Advances in multimodal data fusion in neuroimaging: Overview, challenges, and novel orientation Yu-Dong Zhang a , b , ∗ , Zhengchao Dong c , d , Shui-Hua Wang b , f , g , Xiang Yu a , Xujing Yao a , Qinghua Zhou a , Hua Hu c , e , Min Li c , h , Carmen Jiménez-Mesa i , Javier Ramirez i , Francisco J. Martinez i , Juan Manuel Gorriz i , j a School of Informatics, University of Leicester, Leicester, LE1 7RH, Leicestershire, UK b Department of Information Systems, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah 21589, Saudi Arabia c Department of Psychiatry, Columbia University, USA d New York State Psychiatric Institute, New York, NY 10032, USA e Department of Neurology, The Second Affiliated Hospital of Soochow University, China f School of Architecture Building and Civil engineering, Loughborough University, Loughborough, LE11 3TU, UK g School of Mathematics and Actuarial Science, University of Leicester, LE1 7RH, UK h School of Internet of Things, Hohai University, Changzhou, China i Department of Signal Theory, Networking and Communications, University of Granada, Granada, Spain j Department of Psychiatry, University of Cambridge, Cambridge CB21TN, UK a r t i c l e i n f o a b s t r a c t Keywords: Multimodal data fusion Neuroimaging Magnetic resonance imaging PET SPECT Fusion rules Assessment Applications Partial volume effect 1. Introduction Multimodal fusion in neuroimaging combines data from multiple imaging modalities to overcome the fundamen- tal limitations of individual modalities. Neuroimaging fusion can achieve higher temporal and spatial resolution, enhance contrast, correct imaging distortions, and bridge physiological and cognitive information. In this study, we analyzed over 450 references from PubMed, Google Scholar, IEEE, ScienceDirect, Web of Science, and var- ious sources published from 1978 to 2020. We provide a review that encompasses (1) an overview of current challenges in multimodal fusion (2) the current medical applications of fusion for specific neurological diseases, (3) strengths and limitations of available imaging modalities, (4) fundamental fusion rules, (5) fusion quality assessment methods, and (6) the applications of fusion for atlas-based segmentation and quantification. Overall, multimodal fusion shows significant benefits in clinical diagnosis and neuroscience research. Widespread edu- cation and further research amongst engineers, researchers and clinicians will benefit the field of multimodal neuroimaging. Neuroimaging has been playing pivotal roles in clinical diagnosis and basic biomedical research in the past decades. As described in the follow- ing section, the most widely used imaging modalities are magnetic res- onance imaging (MRI), computerized tomography (CT), positron emis- sion tomography (PET), and single-photon emission computed tomog- raphy (SPECT). Among them, MRI itself is a non-radioactive, non- invasive, and versatile technique that has derived many unique imaging modalities, such as diffusion-weighted imaging, diffusion tensor imag- ing, susceptibility-weighted imaging, and spectroscopic imaging. PET is also versatile, as it may use different radiotracers to target different molecules or to trace different biologic pathways of the receptors in the body. Therefore, these individual imaging modalities (the use of one imag- ing modality), with their characteristics in signal sources, energy lev- els, spatial resolutions, and temporal resolutions, provide complemen- tary information on anatomical structure, pathophysiology, metabolism, structural connectivity, functional connectivity, etc. Over the past decades, everlasting efforts have been made in developing individual modalities and improving their technical performance. Directions of im- provements include data acquisition and data processing aspects to in- crease spatial and/or temporal resolutions, improve signal-to-noise ratio and contrast to noise ratio, and reduce scan time. On application aspects, ∗ Corresponding author. E-mail addresses: yudongzhang@ieee.org (Y.-D. Zhang), zhengchao.dong@nyspi.columbia.edu (Z. Dong), shuihuawang@ieee.org (S.-H. Wang), xy144@le.ac.uk (X. Yu), xy147@le.ac.uk (X. Yao), qz105@le.ac.uk (Q. Zhou), huhua8775@suda.edu.cn (H. Hu), limin@hhu.edu.cn (M. Li), carmenj@ugr.es (C. Jiménez-Mesa), javierrp@ugr.es (J. Ramirez), fjesusmartinez@ugr.es (F.J. Martinez), gorriz@ugr.es (J.M. Gorriz). https://doi.org/10.1016/j.inffus.2020.07.006 Received 30 April 2020; Received in revised form 6 July 2020; Accepted 14 July 2020 Available online 17 July 2020 1566-2535/© 2020 Elsevier B.V. All rights reserved. Y.-D. Zhang, Z. Dong and S.-H. Wang et al. Information Fusion 64 (2020) 149–187 the strength and limitations of the neuroimaging modalities and the cor- responding analysis methods, and in particular, the needs for improved image fusion methods and (2) we will review recent methodological development in data preprocessing and data fusion in multimodal neu- roimaging. We note that although we tried to cover all neuroimaging modalities, we inevitably paid more attention to MRI modalities. This is not only due to the most practical application and versatility of the MRI but also due to the limitations of our expertise. Fig. 2 shows the taxonomy of this review. The main contents of the paper are organized as follows. Chapter 2 will give a brief introduction to neuroimaging, and challenges of multi- modal imaging; Chapter 3 introduces the commonly used neuroimaging modalities, which include computerized tomography, positron emission tomography, single-proton emission computed tomography, and mag- netic resonance imaging, which has many modalities in its own right. For each modality, we will concisely describe its signal source, energy level, spatial resolution, temporal resolution, and major applications; Chapter 4 describe applications of neuroimaging in three major areas: the developing brains, the degenerative brains, and mental disorders. In each part, we will first briefly describe what the clinical and/or biomed- ical problems are, we then review recent papers on how neuroimaging has been used to address these problems, and we point out what the unmet needs and challenges; Chapters 5 to 9 are devoted to the multimodal neuroimaging fusion, covering some important procedures in data fusion. The topics are not necessarily complete and their order of presentation is not necessarily coherent with the pipeline of fusion processing. Chapter 5 reviews the fundamental methods, which covers types, rules, atlas-based segmenta- tion, decomposition, reconstruction, and quantification; Chapter 6 re- views subjective and objective assessment of data fusion in multimodal neuroimaging; Chapter 7 reviews the advantages of data fusion in im- proving the spatial/temporal resolution, distortion correction, and con- trast; it also reviews the benefits of these advantages in fusing structural and functional images; Chapter 8 reviews atlas-based segmentations in multimodal imaging fusion; Chapter 9 reviews the quantification in mul- timodal neuroimaging fusion. While the focus of this part is given to PET and SPECT, some of the approaches and principles discussed here, such as partial volume correction and attenuation (relaxation), can be applied to quantitative MRI modalities, such as DTI, ASL, quantitative susceptibility mapping (QSM), etc. Chapter 10 concludes the paper. 2. Multimodal imaging data fusion: challenges in neuroimaging In this part, we will review the current challenges of neuroimag- ing, including limited spatial/temporal resolution, lack of quantifica- tion, and imaging distortions. These challenges often create fundamental limitations on individual modalities of neuroimaging, while some chal- lenges also exist in current multi-modal neuroimaging. This part will mainly cover the challenges of individual neuroimaging modalities that led to the development and ongoing research of multimodal neuroimag- ing methods. 2.1. Individual modality imaging Neuroimaging can be divided into structural imaging and functional imaging according to the imaging mode. Structural imaging is used to show the structure of the brain to aid the diagnosis of some brain dis- eases, such as brain tumors or brain trauma. Functional imaging is used to show how the brain metabolizes while carrying out certain tasks, in- cluding sensory, motor, and cognitive functions. Functional imaging is mainly used in neuroscience and psychological research, but it is grad- ually becoming a new way of clinical-neurological diagnosis [10] . The amount of information obtainable through single-mode imag- ing is limited and often cannot reflect the complex specificity of organ- isms. For instance, although CT imaging is effective in identifying nor- mal structures and abnormal diseased tissues according to their density Fig. 1. Numbers of peer-reviewed papers with the keywords of “neuroimaging ”or “brain imaging ” in titles (the numbers and the bar graph were generated by PubMed in Feb 2020). individual modalities have been widely used to meet clinical and scien- tific challenges. At the same time, technical developments and biomedi- cal applications of the concert, integrated use of multiple neuroimaging modalities are trending up in both research and clinical institutions. The driving force of this trend is twofold. First, all individual modalities have their limitations. For example, some lesions in MS can appear normal in T1-weighted or T2-weighted MR images but show pathological changes in DWI or SWI images [1] . Second, a disease, disorder, or lesion may manifest itself in different forms, symptoms, or etiology; or on the other hand, different diseases may share some common symptoms or appear- ances [2, 3] . Therefore, an individual image modality may not be able to reveal a complete picture of the disease; and multimodal imaging modality (the use of multiple imaging modalities) may lead to a more comprehensive understanding, identify factors, and develop biomarkers of the disease. In the narrow sense, a multimodal imaging study would mean the use of multiple imaging devices such as PET and MRI scanners, differ- ent imaging modes such as structural MRI, diffusion-weighted imaging, and magnetic resonance spectroscopy, or even different contract mech- anism such as with or without contract agents in a single examination or experiment of a subject. This practice has been widely used in clinical diagnosis and medical research. For example, a routine protocol of MRI examination of a stroke patient may include T1-weighted, T1-weighted high-resolution structural MRI scans, diffusion-weighted imaging, SWI, etc [4, 5] . A protocol of an MRI study of a psychiatric disorder may con- tain a combination of structural MRI, functional MRI, MR spectroscopic imaging, etc [6, 7] . In the broad sense, a multimodal imaging study may mean the use of multimodal imaging data obtained separately, from different sub- jects, and/or from different clinical or research sites. This practice offers the advantages of large and diverse datasets. However, it also comes with challenges of sophisticated models, complicated data normaliza- tion (that includes correction of errors and variations imbedded in data from different institutions), data fusion, and data integration [8, 9] . In recent years, the quantity of peer-reviewed journal articles on neu- roimaging has been increasing steadily. A database (PubMed) query us- ing the keywords in titles of “neuroimaging ” OR “brain imaging ” re- turned more than 39,000 articles from 2010 to the present time when this paper was drafted in Feb 2020 ( Fig. 1 ). These publications include not only applications of multimodal neuroimaging in clinical examina- tions and biomedical research but also methodological studies in imag- ing processing and fusion of multimodal neuroimaging. Therefore, this present paper will focus on the following two main aspects: (1) we will review some of the recent, typical papers that exhibit 150 Y.-D. Zhang, Z. Dong and S.-H. Wang et al. Information Fusion 64 (2020) 149–187 Fig. 2. Taxonomy of this review. Fig. 3. Advantages and disadvantages of various individual modality imaging. and thus can provide clear anatomical structure information, it cannot image soft tissue well. Generally speaking, MRI imaging has good soft- tissue contrast resolution for most sequences, but its display of bone structure is relatively poor. PET imaging and SPECT imaging are not limited by the detection depth, with high imaging sensitivity, and are easy to quantify, but their spatial resolutions are low [11] . Optical imag- ing refers to the detection of fluorescence or bioluminescent dyes using the principle of light emission. This technique has high sensitivity, no radioactivity, good specificity, and low cost. Optical imaging allows dy- namical monitoring of the replication process of virus bacteria in organ- isms. However, it has low spatial resolution and limited imaging depth [12, 13] . Therefore, it can be observed that various imaging technolo- gies all have both benefits and drawbacks, as shown in Fig. 3 , and it is difficult to provide comprehensive and accurate information through utilizing individual modality imaging. 2.2. Low spatial/temporal resolution The nowadays most commonly used noninvasive functional imaging methods and their spatial and temporal range are illustrated in Fig. 4 . It can be distinctly observed that among these most advanced meth- ods, functional MRI (fMRI) reaches the highest range of spatial resolu- tion. fMRI can assess the whole brain and image the hemodynamic pro- cesses at the layered and columnar levels of the human cortex, under the condition of a high-intensity magnetic field (i.e., submillimeter level) [14] . However, it has a relatively lower temporal resolution in terms 151 Y.-D. Zhang, Z. Dong and S.-H. Wang et al. Information Fusion 64 (2020) 149–187 Fig. 4. Functional neuroimaging modalities. of imaging the neuronal population dynamics. Electroencephalogram (EEG) and Magnetoencephalography (MEG) can both measure electro- magnetic changes in the scale of milliseconds. However, their spatial resolution/uncertainty is more than several millimeters [15, 16] . The mi- croscopic level of neuroscience is often beyond the reach of noninvasive imaging techniques due to the requirement of high spatial or temporal resolution. 2.3. Non-quantitative The majority of imaging modalities are non-quantitative and have to gain complement information from other data. This additional in- formation allows the normalization of signals, acquirement of absolute units, and inter-subject comparison. As an example, the fMRI signal is a measure of neuronal activity incited hemodynamic changes caused by a combination of complex physical and physiological processes. In differ- ent subjects or brain areas, the same level of neuronal activity can evoke different corresponding fMRI signals. As a consequence, fMRI signals can only be considered as roughly proportional to the activity of neu- rons. Four years later, in 2008, the studies from Ances have found that the cerebral blood flow (CBF) is relevant to fMRI signal variations in individual’s brain regions, patients’ age groups, and health conditions. This broad relevance brings fMRI signal high sensitivity [17] . Various approaches have been proposed to explain the ensuing sensitivity dif- ferences. Amongst these approaches, the so-called calibrated BOLD ap- proach proposed and improved by Blockley, Chiarelli and Hoge over the years has been the most widely used [18-20] . However, the more reliable absolute quantitative results of CBF with improved spatial and temporal resolutions are provided by the Arterial spin labeling (ASL) technique by the UMICH fMRI lab [21] . 2.4. Distortion Some neuroimaging modalities are prone to geometric distortions. Echo ‐planar imaging (EPI) is a fast imaging approach that could obtain the complete k ‐space data set just in a single acquisition. Due to its un- matched acquisition speed, it has revolutionized the field of neuroimag- ing and has served as the standard readout module for most fMRI and dMRI acquisition. Nevertheless, EPI suffers from distortion and inten- sity loss mainly caused by field inhomogeneities, leading to relatively poor image quality [22] . In general, the imperfection of equipment may result in information loss, noise amplification and artifacts, resulting in the distortion of images. 152 Fig. 5. An example of a CT brain scan. To conclude, in practical application, utilizing individual modality imaging often has limitations, such as low sensitivity and specificity, low spatial/temporal/contrast resolution, distortion and so on. Because of these deficiencies, we need to introduce the usage of multimodal neu- roimaging to eliminate those shortcomings in some degree. 3. Multimodal imaging data fusion: imaging technologies Neuroimaging, more commonly known as brain imaging, is referred to as different types of technologies to display the function, pathology, and structure of the nervous system. There are mainly two types of neu- roimaging: the functional imaging that directly or indirectly visualizes the processing of information by the central neural system of the brain and the structural imaging that shows the structure information of the brain. Neuroimaging is used for a patient who is found a neurological disorder by a physician to have a more in-depth investigation. There are different types of imaging modalities, such as Magnetic resonance imag- ing (MRI), Single-Photon Emission Computed Tomography, Computer- ized Tomography, Positron Emission Tomography, Pneumoencephalog- raphy, Functional Magnetic Resonance Imaging (fMRI). According to the types of possible diseases, patients will be investigated by different methods. 3.1. Computerized tomography Computerized Tomography (CT), also known as computerized x-ray imaging, combines a series of X-ray signals obtained from multiple an- gles around the body and creates cross-sectional images by computer processing. Different from the conventional X-ray [23] that uses a fixed X-ray tube, the CT scanner uses a motorized x-ray source, which rotates around a gantry, a circular frame in a donut-shaped structure. CT scan images, therefore, can provide more information than conventional X- rays. CT can be recommended for disease or injury of various parts of the body, such as lesions or tumors of the abdomen, different types of heart disease, injuries, tumors or clots of the head [24-26] . Fig. 5 [27] shows an example of a CT scan of a brain. 3.2. Positron emission tomography Positron Emission Tomography, shortened as PET, is a combination of nuclear medicine and biochemical analysis that is mostly used for the diagnosis of brain or heart conditions and cancer. Instead of detecting the amount of a radioactive substance existing in body tissues of a spe- cific location to check the tissue’s function, PET detects the biochemical changes within body tissues. The biochemical changes can reveal the onset of a disease process before other imaging processes can visualize Y.-D. Zhang, Z. Dong and S.-H. Wang et al. Information Fusion 64 (2020) 149–187 Fig. 6. Common scan modalities. the anatomical changes related to the disease. During PET studies, only a tiny amount of radioactive substance is needed for the examination of targeted tissues. PET scans not only can be used to detect the pres- ence of disease or other conditions of organs or tissues but can also be used to evaluate the function of organs, like the heart or the brain. The most common application of PET scan is cancer detection and treatment. Fig. 6 (a) shows a PET image of the brain, and Fig. 6 (b) shows a PET scan of the kidney [27] . 3.3. Single-photon emission computed tomography Single-photon emission computed tomography, commonly known as SPECT, uses gamma rays as the tracer to detect blood flow in organs or tissue. Therefore, a gamma-emitting radioisotope, such as isotope gal- lium, should be injected into the bloodstream of the patient for SPECT. The computer collects the gamma rays from the tracer and shows it on the CT cross-section. It bears similarity with the traditional nuclear medicine planar imaging but provides 3D information as multiple im- ages of cross-sectional slices through the patient. The information can be manipulated or reformatted freely according to diagnostic or research requirements. Besides detecting blood flow, SPECT scanning is also ap- plied for the presurgical evaluation of medically controlled seizures. Fig. 6 (c) [27] shows a SPECT scan of the brain 3.4. Magnetic resonance imaging Magnetic resonance imaging (MRI) utilizes strong magnetic field, magnetic field gradients, and radio waves to generate pictures of the anatomy and the physiological processes of the body [28] . Different from PET or CT, MRI does not need the injection of ionizing radioiso- topes or involve X-rays. As all radiation instances can cause ionization that leads to cancer, MRI, without exposing the body to radiation, be- comes a better choice than CT and one of the safest medical procedures. MRI is widely used in hospitals and clinics for the medical diagnosis of different body regions, including the brain, spinal cord, bones and joints, breasts, heart and blood vessels, and other internal organs, such as the liver, womb or prostate gland [29-31] . Besides, MRI can also be used for non-living objects [32] . Fig. 6 (d) shows an MRI brain image [33] . 3.4.1. T1, T2, and proton density T1, T2 and Proton density (PD) are three basic types of MRI imaging. T1, T2 and PD, which all vary with sequence parameters, can simultane- ously determine the contrast of the MR images [34] . Via selecting differ- 153 Fig. 7. The relationship between M z and M xy . ent pulse sequences with different timings, we can decide the contrast in the region being imaged. There are also other types of sequences, such as fluid attenuates inversion recovery (FLAIR) and short tau inversion recovery (STIR). In this section, we will only mention the three main types. Fig. 7 shows the relationship between M xy , of which xy refers to plane [35] . z and M Higher M z at the time of applying the 90° RF pulse brings the larger transverse signal ( M xy ). The time to repetition (TR) is defined as the determent of the length of time between 90° RF pulses. The Echo time [26] is defined as the time between the excitation pulse and the peak of the signal. T1, the longitudinal relaxation time, is defined as a time constant that stands for the magnetization to recover from 0 to 63% of their maximum z in a static magnetic field. T1 values of hydrogen nuclei are differ- M ent for different molecules and different tissues. T1 relaxation is defined as the recovery of the longitudinal magnetization. T1 is commonly ap- plied for detecting fatty tissue, general morphological information, and characterizing focal liver lesions. xy to decay to 37% of its initial M T2, the transverse relaxation time, is defined as the time for trans- verse magnetization M xy . Similar to T1 values, we also have different T2 values of Hydrogen nuclei in differ- ent molecules and different tissues. T2 weighted imaging is suitable for revealing cerebral white matter lesions and assessing edema, inflamma- tion and zonal anatomy in the prostate and uterus. Y.-D. Zhang, Z. Dong and S.-H. Wang et al. Information Fusion 64 (2020) 149–187 Fig. 8. Two types of weighted images of the same brain. Different from T1 and T2, which mainly focuses on the magnetic characteristics of the hydrogen nuclei, PD is more related to the number of nuclei in the region being imaged. PD weighted images are obtained by a short echo time and a long repetition time, which can provide a more apparent distinction between the gray matter and white matter. PD weighted imaging is specifically useful for detecting joint disease and injury. Fig. 8 (a) and (b) show a T1 weighted brain image and T2 weighted brain image, respectively [27] . 3.4.2. Functional magnetic resonance imaging Functional magnetic resonance imaging or functional MRI (fMRI) measures brain activity by detecting changes associated with blood flow. As it has been proved that when an area of the brain is in use, the blood flow to that area increases, which means that the neuronal activation and cerebral blood flow are matched. fMRI is a particular type of imag- ing technology used to map the neuron activities in the spinal cord and brain of humans or animals by visualizing the change in blood flow, which is related to the energy use by brain cells. fMRI also includes resting-state fMRI [36] or task-less fMRI, which can provide subjects’ baseline BOLD service [37] . 3.4.3. Diffusion weighted/tensor imaging Diffusion Weighted/Tensor Imaging (DWI) generates image contrast from the differences in the magnitude of diffusion of water molecules within the brain. Diffusion in biology is defined as the passive movement of molecules from a higher concentration region to a lower concentra- tion region, which is also known as Brownian motion [38] . Diffusion within the brain is affected by many factors, such as temperature, type of molecule under investigation, and the microenvironmental architec- ture in which the diffusion takes place. Based on the MRI sequences of which diffusion is sensitive to, the image contrast can be generated ac- cording to the difference in diffusion rates. DWI is highly effective for the early diagnosis of ischemic tissue injury, even before the pathology can be shown by the traditional MR sequence. Therefore, DWI provides the time window for tissue salvaging interventions. 3.4.4. Perfusion and susceptibility weighted imaging Perfusion weight imaging (PWI) is defined as a variety of MRI tech- niques that are able to provide insights into the perfusion of tissues by blood [39] . PWI can be used for the evaluation of ischaemic conditions, neoplasms, and neurodegenerative diseases. Perfusion MRI mainly has three main techniques: Dynamic susceptibility contrast (DSC), Dynamic contrast-enhanced (DCE), and Arterial spin labeling (ASL). Susceptibility weighted imaging (SWI), previously known as BOLD venographic imaging, is a type of MRI sequence that is extremely sen- sitive to venous blood, hemorrhage, and iron storage. As an fMRI tech- nique, SWI can explore the susceptibility differences between tissues and detect differences based on the phase image. An enhanced contrast magnitude image can be obtained by combing the magnitude and phase data. SWI is commonly used in traumatic brain injuries (TBI) and high- resolution brain venographies as it is sensitive to venous blood. 3.4.5. Magnetic resonance fingerprinting Magnetic resonance fingerprinting (MRF) [40] is new MRI tech- nique that integrates MR physics theory and computer pattern recog- nition technology and realizes fast and multi-parameter parallel quanti- zation imaging. The technique consists of three modules. First, the fin- gerprinting signals are excited and acquired from the subject in the MR scanner by the pseudorandom temporal varied pulse sequence to re- flect the physiological property of tissue. Second, the evolution of fin- gerprinting signals with different physiological parameter combinations are predicted by the computer simulation using the Bloch equation; and a fingerprint dictionary indexed by the quantized parameters is con- structed. Finally, the pattern recognition technology is applied to find the matched fingerprinting entries for the measured fingerprinting sig- nals, so as to obtain the corresponding quantization parameters and realize quantization MR imaging. Different from most of the conven- tional MRI modalities, which provide qualitative contrast-based images that are determined not only by the tissue properties but also by exper- imental conditions, MRF provides quantitative images of tissue prop- erties that reflects pathological conditions of the subject. Fig. 9 shows digital phantom experiments of conventional MRI and MRF. The upper row shows a digital brain with T1 values (left), T1-weighted MRIs with different experimental parameters (middle), and MRF reconstructed T1 map (right), respectively; The lower row shows a digital brain with T2 values (left), T2-weighted MRIs with different experimental parameters (middle), and MRF reconstructed T2 map, respectively. The experiments demonstrated that the contrasts of the conventionally “weighted ” MRI images depend on both the tissue properties and experimental param- eters, but MRF can reconstruct the parameter images independent of experimental parameters. Currently, the applications of MRF have been limited to biomedical research and the fusion of MRF with other neuroimaging modalities has not been reported. Given its parametric and quantitative features, the MRF technique will play an important role not only in neuroimaging but also in fusion of multimodal neuroimaging. 3.5. Comparison of imaging methods Table 1 lists the main advantages, disadvantages and applications of each neuroimaging technology. 154 Y.-D. Zhang, Z. Dong and S.-H. Wang et al. Information Fusion 64 (2020) 149–187 Fig. 9. Digital phantom experiments of con- ventional T1 weighted and T2 weighted MRIs, and MRF. Table 1 Comparison of various imaging methods. Imaging methods Advantages Computerized Tomography (CT) • Painless, noninvasive and accurate • Image bone, soft tissue and blood vessels all at the same time • Fast and simple Positron Emission Tomography (PET) • Double the diagnostic clarity compared to CT • Easy , Nondisruptive • More available and widely used • Less expensive than PET Single-photon Emission Computed Tomography (SPET) Magnetic Resonance Imaging (MRI) Disadvantages • Radiation Applications • Brain tumors. • Blood clots and blood vessel defects. enlarged ventricles • Not recommended for pregnant women • Abnormalities in the nerves or muscles of the eye • Not recommended for pregnant women • Diabetics require certain precautions. • Long scan times • Low-resolution and prone to artifacts and attenuation • Cancer • Heart disease • Brain disorders • Functional brain imaging • Functional cardiac imaging • No radiation • Expensive • Apparent, detailed images of soft-tissue structures compared to other imaging techniques • Cannot find all cancers • Cannot always distinguish between malignant or benign tumors • Anomalies of the brain and spinal cord • Tumors, cysts, and other anomalies in various parts of the body • Breast cancer screening for women who face a high risk of breast cancer • Injuries or abnormalities of the joints, such as the back and knee • Certain types of heart conditions • Diseases of the liver and other abdominal organs • The evaluation of pelvic pain in women, with causes including fibroids and endometriosis • Suspected uterine anomalies in women undergoing infertility evaluation Table 2 Public datasets. Database Name Web Address TCIA ATLAS CTisus OASIS ADNI FITBIR http://www.cancerimagingarchive.net/ http://www.med.harvard.edu/aanlib/home.html http://www.ctisus.com/ https://www.oasis-brains.org/ http://adni.loni.usc.edu/ https://fitbir.nih.gov/ 3.6. Databases In this section, we listed some public databases, as shown in Table 2 . The International Cat Association (TICA) database is an extensive 155 database that contains different types of medical images of cancers, in- cluding lung cancer, breast cancer, and kidney cancer. ATLAS is a pub- lic database of Harvard University, which mainly contains image data of Cerebrovascular Disease, Neoplastic Disease, Degenerative Disease, Inflammatory or Infectious Disease. CTisus has numerous MRI, CT, X- rays of different organs and tissues. The Open Access Series of Imaging Studies (OASIS) dataset contains 2000 MR sessions, which includes: T1 weighted image, T2 weighted image, FLAIR, ASL, SWI, time of flight, resting-state BOLD and DTI sequences, PET images from three types of traces, PIB, AV45 and FDG. The Alzheimer’s Disease Neuroimaging Ini- tiative (ADNI) database contains several types of data like MR, PET from a group of volunteers and dementia patients. The Federal Interagency Traumatic Brain Injury Research (FITBIR) shares the data for Traumatic Brain Injury (TBI) research. Y.-D. Zhang, Z. Dong and S.-H. Wang et al. Information Fusion 64 (2020) 149–187 4. Multimodal imaging data fusion: diseases In this part, we will review recent advancements in the application of multimodal neuroimaging in some clinical and research areas such as early brain development, neurodegenerative diseases, psychiatric dis- orders, and neurological diseases. It is not our intention to cover all aspects or provide a complete review of these areas. Instead, we fo- cus on the aspects related to the development and applications of the multimodal neuroimaging techniques that meet the expectations and challenges of biomedicine. As such, each of the areas will begin with a brief description of background information such as clinical features, pathology, diagnosis, treatment of the diseases; then a general introduc- tion of the roles, applications, and current status of the medical imaging techniques to the disease; the major part will be a review of recent pa- pers that used one or more imaging modalities and used image fusion in multiple imaging modalities. 4.1. Developing brains Recent studies show that the human brain experiences a rapid de- velopment in the first eight years and continues to develop and change into adulthood. During this long period, the brain develops in size, neu- roanatomy, and functions. This period is significant for a person’s phys- ical and mental health, intellectual and emotional development, and learning, working, and life success [41-43] . Many factors have influences on the brain development of young children, which will have an impact on cognitive abilities and mental health in later life. These influencing factors include genes, maternal stress, and drug abuse, exposure to toxic environments, infectious dis- eases, socioeconomic status of the family, etc. Approximately one-third of genes in the human genome are expressed primarily in the brain and will affect brain development. Many psychiatric and mental disorders, such as autism, ADHD, bipolar, and schizophrenia, are highly heritable or have genetic risk factors. Maternal stress and drug abuse are asso- ciated with preterm birth and low birth weight and increased risk of neurodevelopmental disorders and mental disorders in children [44] . The nutritional status of a child, which is affected by the socioeconomic status of the family, has a significant impact on neurocognitive devel- opment [45] . Neuroimaging techniques have been used to study normal and/or abnormal development of the brain, enhancing our understanding of neuroanatomy, connectivity, and functionality of the brain. These tech- niques also reveal the etiological associations of abnormal brain devel- opment with risk factors and contribute to the development of inter- vention procedures for diseased children [42] . Young children are more sensitive to radiation than adults are, so the use of PET and CT is limited. Thanks to the in vivo nature and versatility of MRI, not only young chil- dren but also newborn babies can be imaged, offering the opportunity to study white matter development and cognition in babies [46-48] . MRI has become the most important pediatric neuroimaging modality and has been widely used to study normal and abnormal brain development, allowing repeated longitudinal observation of the changes of brains of the same individuals before and after birth [49] . In the following, our re- view will focus on the major MRI modalities in pediatric imaging, which include structural, functional, and diffusion tensor imaging. Early pediatric brain MRI studies focused on the anatomical as- pects using T1-weighted and T2-weighted images. Qualitative stud- ies provided information about changing patterns of gray matter and white matter differentiation and myelination in the first months of birth [50] and early childhood [51] . Quantitative studies also revealed the changes in water contents, T1, and T2 relaxation times in both gray mat- ter and white matter; age-related changes in gray matter, white matter, and CSF volumes. All these reflect ongoing maturation and remodeling of the central nervous system [52, 53] . Compared with adult cohorts, brain MR imaging of young children is challenging because of several factors. Young children are less coopera- tive than adults with scanning procedures, which can be long, noisy, and uncomfortable when lying still for long; the images are often plagued with motion artifacts. The brain changes rapidly with age in early life after birth; the brain is not well myelinated; the contrast between gray matter and white matter is low. These pose difficulties to the optimized parameters for data acquisition protocol and also the standard param- eters or criteria for the postprocessing procedures, such as the segmen- tation of the brain to determine cortical thickness [54] . As a result, the physical properties, such as relaxation times, water content, diffusion coefficients, of the developing brain are not very well characterized. Other technical challenges exist to scan young children [55] . Knowledge of the variations of biophysical properties, such as T1 and T2 relaxation times, water contents in GM and WM during the early life of children, is of critical importance to the understanding of neurode- velopment of young children and also to the development of diagnostic protocols of abnormal brain development. The measurement of these biophysical properties is challenging due to the prolonged scan time. Re- cent technical development of magnetic resonance fingerprinting (MRF) allows rapid and quantitative analysis of multiple tissue properties [40] . For example, MRF can provide T1, T2, and proton density maps of the brain in contrast to the conventional T1-weighted, T2-weighted, or pro- ton density-weighted images. A recent paper reported an application of the MRF to study the T1, T2, and MWF of children aged from 0 to 5 years old [56] . This study was able to record different patterns of variations of tissue biophysical parameters over different age stages. MRF techniques were also used to parametrically characterize brain tumors in children and young adults [57] . In a broad sense, the parametric information in MRF opened doors to studies of the correlations between brain tissue properties and brain development, impairment, and physiopathology. Techniques of image fusion can play an essential role in the processing, interpretation, and application of MRF data. 4.2. Degenerative brains Degenerative brain diseases are caused by the decline of neuronal function and the reduction of numbers of neurons in the central ner- vous system (CNS). Known degenerative brain diseases include mild cog- nition impairment, Alzheimer’s disease (AD), Parkinson’s disease, etc. The patients of these diseases suffer from losses of functions in mem- ory, speech, movement, etc. Most of these diseases (except for some mild cognitive impairment subtypes) are progressive, i.e. the symptoms deteriorate as the brains age. As the population is rapidly aging, degen- erative brain diseases post enormous impacts on individuals, families, and society. The etiology of these diseases is still unknown, and there is currently no cure. In the following sessions, we will review advances of neuroimaging on MCI, ADs, and PDs. 4.2.1. Mild cognitive impairment Mild cognitive impairment (MCI) is a clinical transition between nor- mal aging and dementia or Alzheimer’s disease (AD), in which individ- uals have memory or other cognitive impairments beyond their age, but not to the extent of dementia. Patients with MCI often only have minor difficulties in functional ability. In studies based on people older than 65 years of age, the incidence of MCI is estimated to be at 10–20% [58] , and the Mayo clinical study on aging shows an 11.1% incidence of amnestic MCI (aMCI) and 4.9% incidence of non-amnestic MCI (naMCI) in undiagnosed patients aged 70-89 years [59] . Several longitudinal studies have shown that most MCI patients have a significantly higher risk of developing to dementia compared to the general U.S. population (1-2%/ year) [60] , the com- munity population (5-15%/ year), and the clinical patients (10-15%/ year) [61-63] . The latter data suggest that cognitive impairment tends to develop more rapidly for the patients that display serious symptoms. Although some studies have shown that the incidence of MCI reversals to normal cognitive function is as high as 25-30%, recent studies sug- gest that the incidence may be lower. In addition, cognitive reversals 156 Y.-D. Zhang, Z. Dong and S.-H. Wang et al. Information Fusion 64 (2020) 149–187 over a short period of follow-up study showed that they did not prevent subsequent disease progression. Magnetic resonance imaging Magnetic resonance imaging (MRI) techniques have been used in the clinical identification of MCI and various types of dementia to predict the progression of MCI to dementia. For MRI measurements of brain structure, linear, area, or volume measurements can be used. The re- sults showed that the area of MCI brain atrophy was consistent with AD, but to a lesser extent, between the normal elderly (control group) and AD patients [64-67] . Similar results were found using voxel-based mea- surement and analysis, with abnormal changes in not only gray matter but also white matter [68, 69] . The previous diagnosis of AD by struc- tural MRI was mainly based on the degree of brain atrophy, especially in the medial temporal lobe. The structural MRI studies showed the atro- phy along the hippocampal pathway (entorhinal cortex, hippocampus and posterior cingulate cortex), which was consistent with the loss of early memory. As the disease progresses, the temporal, frontal, and api- cal lobes shrink with neuronal loss, causing abnormalities in language, practice, vision, and behavior [70, 71] . However, no definitive biomark- ers have been identified by structural MRI alone to distinguish MCI and AD, to stage MCI, and to predict MCI conversion to AD or not [72, 73] . MRI-based functional imaging has been applied to the understand- ing of and to the discrimination between AD and MCI. These techniques include perfusion-weighted imaging (PWI), diffusion-weighted imaging (DWI), diffusion tensor imaging (DTI), and blood oxygen-dependent fMRI (including task execution and resting state) [72] . Functional MRI allows the delineation of microstructural brain changes, which is com- plementary to structural MRI that can depict the global changes of the brain in MCI. An MRI-based functional imaging study that employed PWI, DTI and proton MRS showed significant abnormalities in parame- ters derived from the three imaging modalities for AD patients. PWI and DTI parameters showed a significant, but a lower degree of abnormali- ties in some areas for MCI patients. fMRI has also been used to distin- guish AD and MCI and to predict the transition from cognitive normal to MCI and from MCI to AD. Recent studies show that BOLD-fMRI can detect changes in brain function before MCI progresses to AD, making it an important technique to study the neural mechanism of MCI [74, 75] . Proton magnetic resonance spectroscopy ( 1 HMRS) is a noninvasive imaging method that can detect biochemical and metabolic changes in brain tissue in vivo and conduct quantitative analysis. Early MRS stud- ies show abnormal concentrations of N-acetylaspartate (NAA), creatine, and choline are associated with the status of memory and cognition impairment and have a promise for assessing cognitive status, evaluat- ing response to medicine, and monitoring progression during treatment [76-78] . In recent years, with advances in the technical development of MR hardware and pulse sequences, the roles of glutamate, the exci- tatory neurotransmitter, and GABA, the inhibitory neurotransmitter, in MCI patients became the main focus [79-81] . For example, with ultra- high field 7 Tesla MR scanner, abnormal concentrations of GABA, gluta- mate, NAA, glutathione, and myo-inositol (mI) in different brain regions were detected [82] . The manifestations of 1 HMRS in MCI patients were mainly shown in decreased NAA/Cr ratio and increased mI/Cr ratio. The pathological results showed neuronal deletion and glial prolifera- tion, and the changes in metabolite concentration were consistent with the pathological results [82, 83] . Multimodal imaging PET and SPECT provide insight into blood perfusion and metabolism in tissues and organs, as well as explore changes in function. The nu- clear medical images of aMCI patients showed decreased perfusion and metabolism in the hippocampus, temporoparietal lobe, and posterior cingulate gyrus. Studies using PET, SPECT, and MRI have shown that glucose metabolism in the hippocampus, glucose metabolism rate in the bilateral temporal-parietal lobe, and blood perfusion in patients with aMCI are lower than those in normal elderly. These studies have also shown that low glucose metabolism in the temporal-parietal lobe is a reliable indicator of conversion to AD [84-86] . Excessive deposition of 𝛽-amyloid peptide in the brain and the cascade reaction caused by it are the early onset of AD. Therefore, early detection of 𝛽-amyloid pep- tide in the brain can help identify patients with aMCI, and monitor the progression of the disease and treatment effect. It was found that the 11 C-PiB-PET could attach to A 𝛽 in the brain. PET imaging showed the amount and location of A 𝛽 deposition in the brain, which was expected to be an early diagnostic method for AD [87-89] . Multimodal imaging techniques involving MRI-based imaging and PET-based imaging have been frequently used for prediction, charac- terization, and classification of MCI [90, 91] . In facilitating these com- plex tasks, imaging fusion methods based on artificial intelligence, neu- ral network, deep learning and graph theory have been used [92-94] . Brain network studies based on multimodal MRI and graph theory anal- ysis have found that the topological properties of AD and aMCI affected brain networks have undergone abnormal changes, which mainly man- ifested as the imbalance between functional differentiation and integra- tion. This approach provided a new way to reveal topological mecha- nisms and pathophysiological mechanisms of brain networks [93, 95] . In addition, the combination of graph theory analysis and classification analysis suggests that the brain network topology attribute can be used as an imaging marker of AD and has a good clinical application prospect. 4.2.2. Alzheimer’s disease Alzheimer’s disease (AD) is a neurodegenerative disorder and the most common cause of dementia. AD is characterized by progressive memory loss, aphasia, loss of use, loss of recognition, impairment of visual-spatial skills, executive dysfunction, and personality and behavior changes [96, 97] . It has become one of the major diseases that seriously threaten the health and quality of life of the elderly [98] . The onset of AD is slow or insidious, with patients and their families often unable to tell when it starts. It is more common in the elderly over the age of 70 (the average male is 73, and the average female is 75 years old), with more females than males (female to male ratio of 3:1) [99] . There is currently no cure for AD, but large numbers of novel com- pounds are currently under development that have the potential to mod- ify the course of the disease and to assess the efficacy of these proposed treatments. There is a pressing need for imaging biomarkers to improve understanding of the disease and to assess the efficacy of these proposed treatments. Magnetic resonance imaging Structural MRI (sMRI) is the most widely used imaging modality for the study of AD. The techniques for analyzing sMRI are classified into volume-based and surface-based methods [100] . Previous studies have shown that hippocampal volume atrophy and whole-brain atrophy inde- pendently predicted the progression of AD [101] . Hippocampal damage or atrophy occurs in the early stage of AD, which is an important struc- tural basis for the clinical manifestations of AD. Although global hip- pocampal atrophy in AD was well accepted, the differences were often detected large sample-size studies [102] . De Winter et al. studied 48 elderly AD patients with depression and 52 healthy control elderly people and examined all the subjects with sMRI and neuropsychology [103] . They found that there was no signif- icant difference in the positive rate of A 𝛽 between the depression group and the healthy control group. However, the hippocampal volume in the depression group was significantly smaller than that in the healthy control group. There is significant hippocampal atrophy in elderly de- pression patients, and hippocampal atrophy has nothing to do with A 𝛽, which challenges the reliability of hippocampal atrophy in the clinical diagnosis of AD. It is suggested that hippocampal atrophy not only oc- curs in AD but also in senile depression. The study of sMRI indicates that the brain atrophy shown by brain morphology and structure has refer- ence value for the diagnosis of AD. However, the diagnosis of AD still needs to be confirmed by combining clinical manifestations, neuropsy- chological assessments, and other examination methods. It also indicates that follow-up is needed for suspected depression in patients with AD. 157 Y.-D. Zhang, Z. Dong and S.-H. Wang et al. Information Fusion 64 (2020) 149–187 The above studies showed the limitations of structural MRI and the ne- cessity of the multimodal approach in the study of AD [104] . puting algorithms, and especially, novel data fusion methods [113-116] , which will be reviewed in detail in the following sections. Other MRI modalities, including functional MRI, DWI, PWI, have also been widely used in the study of neurodegenerative diseases. We will review recent advances of the resting-state functional magnetic res- onance imaging (rs-fMRI) as an example. As opposed to the conventional task-based fMRI, rs-fMRI does not require the subject to perform any task or be subjected to any external excitation. The rs-fMRI captures the low-frequency oscillations signals that are related to the spontaneous neural activity of the brain by analyzing the brain blood oxygen level dependent (BOLD) signal. Sophisticated methods of analysis of the rs- fMRI data depict the functional connectivity of the brain. The rs-fMRI has been used to reveal how the networks of the functional connectiv- ity are correlated to the brain functions of individuals with cognitive impairment. Zamboni et al. found that the recognition task of AD pa- tients was related to the increased activation of the lateral prefrontal area, which also overlapped with the functional connection enhance- ment area indicated by the rs-fMRI [105] . Zhou et al. predicted the pathological changes of AD by using the calculation model of resting brain function network and studied five different brain regions vulner- able to neurodegenerative diseases through the use of task state fMRI [106] . They found that the brain network of AD patients may have the phenomenon of weak functional connectivity and their ability to trans- mit information of functional brain network decline. Wang et al. found that the functional brain network of MCI patients had different degrees of functional connectivity disorder. The evaluation of overall functional brain connectivity of patients plays an important role in the early diag- nosis and treatment of AD [107] . Abnormal brain connectivity can be a biomarker of the disease. Many neuropsychiatric diseases and dementia can change the default mode network (DMN) of the brain. Identification of the change in the connectivity of DMN is constructive for the early recognition of AD. Jin et al. collected 8 patients with aMCI and 8 healthy people to analyze rs- fMRI data by independent component analysis (ICA) [108] . They found that the functional activities of the lateral prefrontal cortex, left medial temporal lobe, left middle temporal gyrus and right angular gyrus in aMCI patients decreased, while the activity of the middle and medial prefrontal cortex and the left parietal cortex increased. Further studies found that the functional activities of the left lateral prefrontal cortex, left middle temporal gyrus and right angular gyrus were positively cor- related with memory, especially delayed memory [109] . Although there was no significant difference between the two groups in the degree of medial temporal lobe atrophy, the functional activities of the left me- dial temporal lobe decreased. This decrease suggests that the functional changes of DMN may occur in the early stage of AD, i.e. aMCI, and the functional changes may occur before the obvious change of brain struc- ture. Multimodal imaging Due to severe overlap in symptoms and findings of individual imag- ing modalities of the neurodegenerative diseases, it is difficult to identify the biomarkers that could be used to differentiate the types of these dis- eases and/or to stage the progress of a disease. Therefore, multimodal neuroimaging techniques are used to overcome the challenges [110] . As pointed out in [111] , individual modalities of MRI and EEG lack preci- sion in AD diagnosis and staging. By employing both imaging modalities, with the MRI measuring the cortical thickness and the EEG measuring the rhythmic activities, the authors found joint markers that identified the subjects of Alzheimer’s disease with an accuracy of 84.7%, a signifi- cant increase from those of individual modalities. While some studies of multimodal imaging confirmed correlations of findings among individ- ual modalities as in a study of sMRI and fMRI [112] , multimodal imaging studies can also be used to dissociate the tau deposition and brain atro- phy in early ADs using PET and MRI. The study found that the tau load had little effect on the gray matter atrophy, and this might imply that tau protein deposit precedes and predicts brain atrophy. The multimodal imaging studies require statistical and analytical models, advanced com- 4.2.3. Parkinson’s disease Parkinson’s disease (PD) is a chronic progressive degenerative dis- ease of the central nervous system, which is commonly seen in elderly patients. Typical clinical manifestations of PD include static tremor, my- otonia, bradykinesia, and abnormal posture and pace [117] . With the continuous increase of the aging population, the incidence and disabil- ity rates of the population are also increasing year by year. The results of epidemiological surveys indicate that the prevalence of PD in people over 65 is about 1.7%, and the prevalence of PD in people over 80 is as high as 4% [118-120] . PD is more and more harmful to the health of the middle-aged and elderly, especially involving the central nervous system. Due to the lack of objective basis and diagnostic criteria for the diag- nosis of PD, the previous clinical diagnosis of PD was mainly based on the clinical symptoms, resulting in a low coincidence rate between the clinical diagnosis and pathology of PD and in a significant lag behind the pathological changes of brain microstructure. With the increasingly standardized diagnosis and treatment of PD, neuroimaging examination has become an indispensable part of the diagnosis. This differential di- agnosis of PD can help identify different movement disorders, locate anatomical dysfunction sites, and determine the causes of the lesion, which will improve clinical evaluation and prognosis [121, 122] . Magnetic resonance imaging Structural cranial MRI can distinguish white matter from gray mat- ter by setting different imaging parameters while avoiding radiation. It is better than cranial CT in revealing white matter lesions, small in- farcts, subacute intracerebral hemorrhage, and lesions in the brain stem, subcortical regions, and posterior fossa. On structural MRI such as T1, T2-weighted, and fluid-attenuated inversion recovery (FLAIR) images, PD patients usually exhibit broadening of the ventricles (caused by ex- trapyramidal atrophy) and widened sulci (diffuse brain cortical atrophy) [123] . The quantitative measurements of cortical atrophy can be mea- sured based on voxel morphometric assessment. When the compact belt of the substantia nigra shrinks and the short T2 signal of the substan- tia nigra disappears, the width of the dense belt of the substantia nigra, the ratio of the width of the dense belt of the substantia nigra to the diameter of the midbrain, the caudex nucleus, the putamen nucleus, the thalamus and other areas of interest are measured. In evaluating the ex- tent of atrophy, physiological changes such as age increase and relevant clinical supporting evidence should be taken into account [124] . Neuromelanin-sensitive MRI is used to detect neuromelanin, a sur- rogate biomarker for the PD. Neuromelanin is a dark pigment found in neurons in the substantia nigra pars compacta. The concentration of neuromelanin increases with age but is found to be around 50% higher in PD patients compared with age-matched non-PD subjects, due to the death of cells in the substantia nigra. Neuromelanin-sensitive MRI al- lows the visualization of the neuromelanin-containing neurons in the substantia nigra, pars compacta. With the use of morphological analy- sis and signal intensity (contrast to noise ratio), the width and CNR of the lateral and central substantia nigra were found to be significantly lower in the PD subjects than in the control group and untreated es- sential tremor (ET) group [125, 126] . Therefore, this imaging technique can be potentially used as a biomarker to differentiate ET from the de novo tremor-dominant PD subtype. The neuromelanin levels were quan- titatively assessed using neuromelanin-sensitive MRI and quantitative susceptibility mapping (QSM) [127] , an MRI modality for measuring the absolute concentrations of iron, calcium, and other substances in tissues based on changes of local susceptibility [128] . While the neuromelanin imaging found significantly lower neuromelanin levels in the PD group than the health controls (HC), which is in agreement with the neurome- lanin MRI only study, the QSM values were significantly higher in the PS group than in the HC group. This result suggested the usefulness of QSM in detecting PD [127] . 158 Y.-D. Zhang, Z. Dong and S.-H. Wang et al. Information Fusion 64 (2020) 149–187 Resting functional magnetic resonance imaging (fMRI) is a technique that collects the blood oxygen level dependent signal changes of pa- tients in the awake and resting states to obtain the functional activ- ity level of the brain in the baseline state. In recent years, fMRI has been widely used in clinical studies of all motor disorders or neurode- generative diseases, including PD [129-131] . Resting-state functional MRI (rs-fMRI) can calculate a variety of brain activity attributes, such as local consistency, range of low-frequency fluctuation, and ampli- tude of low-frequency fluctuation etc. By observing the correlation be- tween time-dependent signals of blood oxygen levels in different vox- els or areas of interest, we can further evaluate the synchronization of functional activity in different brain areas, i.e. functional connectivity [129, 132, 133] . In recent years, calculation methods based on indepen- dent component analysis, Granger causality analysis and Graph Theory can help to find complex pattern changes in the brain network of PD patients. Other imaging modalities and multimodal imaging Other imaging modalities, including PET, SPECT, EEG, CT, have been applied to study the functional and structural abnormalities and changes of PD patients, and they provide much complementary information to MR-based imaging modalities mentioned earlier. PET studies investi- gated cerebral glucose metabolism with or without medications, with or without brain stimulations [134-136] . Metabolic and brain chemical changes related to dopamine neurons in PD patients were also studied using SPECT, which cannot be assessed by other MRI modalities includ- ing proton magnetic resonance spectroscopy (MRS) [137] . By jointly applying SPECT and DTI, this study identified regions and connections of the brain that differentiate PD patients and healthy controls. Differ- ent from the imaging modalities in that study, a recent study employed PET scans with two different tracers and rs-fMRI to investigate vari- ations of metabolism and functional connectivity of the PD patients [138] . It identified correlations between motor impairments with hy- pometabolism and hypoconnectivity in multiple brain regions. With the use of different modalities under similar aims, results from these studies can provide complementary information for the impaired regions. The data from them can be integrated and analyzed using data fusion like the work in [139] , in which data of anatomical MRI, rs-fMRI, and DTI were analyzed for more accurate and reliable biomarkers of PD. 4.3. Mental disorders Mental disorders are conditions that affect a person’s thinking, mode, behavior, relationship with others, and functions of daily life and work. Major psychiatric disorders include depressive disorders, bipolar disor- ders, obsessive-compulsive disorders, schizophrenic disorders, autistic spectrum disorders, attention deficit, and hyperactivity disorder. It is estimated that nearly one-fifth of adults aged 18 or older in the United States live with a psychiatric disorder [140] . The World Health Orga- nization estimates that mental disorders affect one-fourth of the world- wide population [141] . The high prevalence of mental disorders have a significant impact on the wellbeing of societies and the development of the world economy [142-144] Unlike the diagnosis of other diseases, such as cancer and diabetes, there are currently no medical tests that can determine mental illness. The diagnosis of mental illness is determined by a psychiatrist using official criteria such as The Diagnostic and Statistical Manual of Men- tal Disorders, fifth edition (DSM-5) according to the feeling, symptoms, and behaviors of the patient. However, neuroimaging techniques have been used to detect, identify, differentiate, and understand the abnor- malities, differences, etiologies, and biomarkers of psychiatric disorders [145-149] . 4.3.1. Depression Depression is a common mood disorder, which can be caused by a variety of reasons. The main clinical feature is marked with persis- tent depression of mood, which is incompatible with the situation. In severe cases, suicidal thoughts and behaviors may occur. Most cases tend to show recurrence; and most can be relieved each time, while some may have residual symptoms or progress to chronic depression. At least 10% of clinical depression patients also show manic episodes and should be diagnosed as bipolar disorder [150, 151] . What we com- monly call depression is clinical or major depression, which affects 16% of the population at some point in their lives [152] . In addition to the severe emotional and social costs of depression, the economic costs are also enormous. According to the World Health Organization, depression has become the fourth most serious disease in the world and is expected to become the second most serious disease after coronary heart disease by 2020 [153] . So far, the etiology and pathogenesis of depression are not clear, and there are no obvious signs or laboratory indicators of abnormality. Although there have been many basic and clinical studies on depres- sion, no critical breakthrough has been made in the three most impor- tant clinical problems: pathogenesis, objective diagnosis, and efficient treatment. A key breakthrough in these issues is to find and establish a stable biological marker from gene to clinical phenotype and then fur- ther study its pathogenesis, establish objective diagnostic methods and develop efficient clinical therapy. Magnetic resonance imaging Up to now, in the clinical research field of mental illness, especially depression, the most sought after biological markers may potentially be provided by the study of neuroimaging, especially brain MRI. Brain MRI examination have characteristics of good clinical applicability, non- invasive, simple operation, universal, relatively stable results and easy to repeat, but its sensitivity and specificity need to be improved. Brain MRI research has become an intermediate mechanism from molecular research to clinical phenotype. Through this mechanism research, we can not only explore how genes, molecules, and proteins affect the brain structure and function of patients with depression but also use MRI as an objective diagnostic tool for the most urgent clinical needs. Over the past 20 years, the application of multi-mode MRI technology to study the brain structural and functional characteristics of depression, especially to establish clear biological marker targets around the characteristics of emotional circuits, has become one of the major scientific frontiers in the basic and clinical research of neuroscience. Many studies have found that patients with depression have abnor- malities in brain structure and function of emotional circuits, as well as in neurotransmitters associated with these circuits [149, 154] . MRI stud- ies in recent years found that the depressive mood is associated with three brain regions, namely in the amygdala and the ventral striatum as the primary mood areas, the orbital gyrus, medial prefrontal cortex and cingulate gyrus as the emotional auto-regulation areas, and the dor- solateral and ventrolateral prefrontal cortex as the center of the active emotional regulation area [154-156] . Multimodal MRI Multimodal MRI techniques used in mental disorders seek to find cor- related, complementary, and/or converging image features from multi- ple image modalities and applied sophisticated analytical methods to identify robust biomarkers for the types of depression. A study employed DTI, magnetic resonance spectroscopy (MRS), rs- fMRI, and magnetoencephalography (MEG) and revealed patterns of abnormalities of patients with major depressive disorders. These pat- terns included factors in the neurotransmitters (glutamate concentra- tion), white matter fibers (fractional anisotropy), and functional excita- tions (fMRI) [157] . A multimodal MRI study involves structural MRI and ASL to assess grey matter volume and regional cerebral blood flow in MDD patients. This multimodal study revealed negative correlations be- tween the extent of depressive symptoms and CBF in the bilateral para- hippocampus and between depressive symptoms and CBF in the right middle frontal cortex [158] . In addition to confirming the correlations among findings of individual modalities, some multimodal MRI stud- ies, however, found disrelations among individual findings in the MDD group [159] . Further multimodal data analysis involving MRI imaging 159 Y.-D. Zhang, Z. Dong and S.-H. Wang et al. Information Fusion 64 (2020) 149–187 data and clinical, neurobiological metrics of the patients may resolve the disparities. Among the methods of the multimodal MRI image fusion in depres- sive disorders, support vector machine (SVM) [160] and linked indepen- dent component analysis [161] was recently used, respectively, to iden- tify biomarkers for the classification and prediction of symptom loads of heterogeneous MDD cohorts. Imaging data and neurobiological data were included in the data fusion. In both studies, the results did not show strong support for the hypothesis and did not provide sufficient evidence for the sought biomarkers [160, 161] . 4.3.2. Obsessive-compulsive disorder Obsessive-compulsive disorder (OCD) is a group of neuropsychiatric disorders with obsessive thinking and compulsive behavior as the main clinical manifestations. It is characterized by the co-existence of con- scious compulsion and anti-compulsion, and the repeated intrusion of thoughts or impulses into the daily life of patients that are often mean- ingless and involuntary. Although patient perceives that these thoughts or impulses are their own and resist them to the utmost degree, he or she is still unable to control them. The intense conflict between the two causes the patient great anxiety and pain, which affects his other study, work, interpersonal communication, and even daily life. Magnetic resonance imaging Voxel-based morphometry was widely used in the sMRI studies of OCD. These studies measure the structures and volumes of regions of interest in various OCD groups and healthy control groups. OCD pa- tients were found to have lower grey matter volumes in specific regions of the brain. For children with OCD, these regions include the bilateral frontal lobe, cingulate cortex, and temporal-parietal junction [162] . For adults with OCD, these regions are the left and right orbitofrontal cor- tex [67] . Lower volumes were also seen in white matter in the cingulate and occipital cortex, right frontal and parietal and left temporal regions [162] and in a small area of the parietal cortex for patients with OCD [163] . fMRI studies can provide information about the pathophysiology of OCD [164, 165] . However, whether this information from single fMRI modality alone could be of clinical value in the diagnosis of individ- ual patients is not clear [166] . The pathophysiological feature of OCD, as revealed by fMRI studies, suggest that abnormal brain metabolites may be implied in OCDs. Abnormalities in brain metabolite concentra- tions in patients with OCD were investigated using proton MRS [167- 170] . Among about ten detectable metabolites, glutamate, glutamine, and GABA are of particular interest, as they are involved in neurotrans- mission. Recent studies show that OCD patients had an elevated GABA level and a higher GABA/glutamate ratio in the anterior cingulate cor- tex [171] , and they had lower GABA concentration in the prefrontal lobe, as compared to healthy control groups [172] . The roles of gluta- mate and glutamine in OCD are in the focus of research interest, but the findings lacked reasonable consistency [173-175] . The heterogeneity of structural neuroimaging findings of OCD may reflect the heterogeneity of the disease itself. Multimodal MRI Multimodal MRI studies in OCD provide complementary, correlated and/or integrated information of findings from individual modalities [176, 177] . Early structural MRI study suggested that the volume re- duction of superior temporal gyrus (STG) is associated with the patho- physiology of OCD [178] . A functional MRI study found increased low- frequency fluctuations in neural activities in STG [179] . A correlation between these findings was found in a combined structural MRI and fMRI study, which shows that the volume of the superior temporal sul- cus is strongly correlated with functional connectivity between several brain regions that may form a neuro-network [177, 180] . The simultane- ous 1H-MRS and DTI study, to investigate metabolic and white matter integrity alterations in OCD, found that the level of Glx to Cr ratio in the anterior cingulate cortex was higher in the OCD group than the healthy control group [181] . The study also found from DTI analysis that the FA values in the left cingulate bundle of the OCD group were significantly higher than the healthy controls. A limitation of this study is that the Glx level, which is a combination of glutamate and glutamine, was mea- sured instead of measuring glutamate and glutamine individually. It has been recognized that it is difficult to distinguish these two structurally similar metabolites using 3 Tesla scanners and ultra-high magnetic field (e.g. 7T) scanners are required. 4.3.3. Schizophrenia Schizophrenia is a group of serious psychosis with unknown etiology, which usually starts slowly or sub-acute in the young and middle-aged individuals [182] . Clinically, it often manifests as a syndrome with dif- ferent symptoms, including abnormalities in sensory perception, think- ing, emotion, and behavior, as well as uncoordinated mental activities [183] . Schizophrenia is a multifactor disease [184] . Although the un- derstanding of etiology is not clear at present, effects of the susceptible quality of individual psychology and the adverse factors of external so- cial environment on the occurrence and development of the disease have been widely recognized. Both susceptible quality and external adverse factors may lead to the occurrence of disease through the joint action of internal biological factors. The course of schizophrenia is generally pro- tracted, showing repeated attack, aggravation, or deterioration. Some patients eventually show recession and mental disability, but some pa- tients can maintain recovery or basic recovery after treatment [185] . Magnetic resonance imaging Structural MRI was widely used to study the morphology and vol- umetry of the brains of schizophrenia patients. Studies found that the average brain volume of schizophrenia patients was smaller than that of healthy people [186, 187] . The abnormal volume and structure of white matter usually appear before the onset of the disease, and these abnor- malities tend to be stable during the development of the disease [188] ; the change of gray matter volume is more evident after the onset of the disease and decreases progressively over time [189] . According to a lon- gitudinal study, gray matter deficiency in schizophrenia mainly occurs in the first five years [190] . Quiet complement to the structural MRI, DTI reveals the abnormal- ities of white matter microstructure of schizophrenia patients [191] . Decreased fractional anisotropy in white matter tracts, different cor- tical regions, and subcortical regions was found in schizophrenia pa- tients in some studies. However, controversial findings were also re- ported [192, 193] . These inconsistencies might be attributed, in part, to small sample sizes. A large-scale DTI study involving more 4,000 subjects found widespread white matter microstructural differences be- tween schizophrenia patients and healthy controls [194] . Significantly reduced fractional anisotropy values were found in 20 of the 25 investi- gated regions within the white matter. Furthermore, significantly higher mean diffusivity and radial diffusivity were also observed in schizophre- nia patients than in healthy controls. Functional MRI techniques are used to detect the deficits in neu- ral networks of patients with schizophrenia [195] . Brain network stud- ies show that the functional connectivity of the default mode network (DMN) in schizophrenic patients has changed. Although the research structures are inconsistent, most studies show that DMN functional con- nectivity is enhanced in schizophrenia, and functional connectivity in the prefrontal cortex is weakened (especially in the prefrontal cortex) [196] . In addition, the functional connections of auditory/linguistic net- works and basal nuclei are related to auditory hallucinations and delu- sional symptoms. The study of brain structure networks found that the number of frontal and temporal core nodes decreased and the average shortest path increased, indicating decrease in global efficiency. Wang et al constructed a network of DTI images of 79 schizophrenia patients and 96 age-matched normal subjects [197] . They found that: compared with the normal subjects, the global efficiency of the schizophrenic group decreased; the local efficiency of the core nodes distributed in the frontal cortex, the paralimbic system, the limbic system and the left putamen decreased; and the global efficiency of the network was nega- tively correlated with the PANSS score. Research shows that the change 160 Y.-D. Zhang, Z. Dong and S.-H. Wang et al. Information Fusion 64 (2020) 149–187 in brain structure network started at the beginning of the disease. More severe symptoms indicate lower the global or local efficiency of the net- work, and the slower the speed of information integration. Magnetic resonance spectroscopy studies found that the brain metabolism of schizophrenia patients was abnormal [198-200] . The lev- els of N-acetyl-aspartic acid (NAA) in the hippocampus, frontal lobe, temporal lobe, and thalamus of schizophrenic patients decreased; the levels of NAA in the thalamus of high-risk groups also decreased, while the level of NAA in temporal lobe decreased. It was also found that the increase of glutamate level in the hippocampus and medial temporal lobe was related to the decrease of executive function. Multimodal imaging The heterogeneities of findings of individual imaging modalities have been driving the multimodal neuroimaging approach to the search of the more consistent and precise biomarkers for the deficits, abnormal- ities in functions of schizophrenia patients. A concerted use of three MRI modalities, namely, resting-state of fMRI, structural MRI, and diffusion MRI, was able to simultaneously reveal abnormalities from these three kinds of MRI images and, thereby, identify the cortico-striato-thalamic circuits that might be related the cognitive impairments in schizophre- nia [201] . In addition to the multimodal imaging investigation of struc- tural and functional brain abnormalities in schizophrenia, proton MRS has also been used in combination with fMRI to investigate cognitive im- pairment in schizophrenia at both neurometabolic and functional levels [202] . The combined proton MRS and fMRI study are particularly useful for short-term longitudinal studies on the effects of medication, which is invariant to brain structural change. In this study [202] , the relation- ship between Glx/Cr levels and BOLD response significantly changed after six weeks of medication for schizophrenia patients, although fac- tors that confound interpretations of the results remain. More examples of multimodal imaging studies on schizophrenia are given in recent re- view articles [203, 204] . 5. Multimodal imaging data fusion: methodology Multimodal fusion has gradually entered the center of research in- terest as an approach to tackle the challenges of neuroimaging. The first main reason is that there exists a great complementarity between differ- ent imaging modes. For instance, the images obtained by positron emis- sion tomography imaging (PET) or single-photon emission tomogra- phy imaging (SPECT) do not contain high resolution, three-dimensional anatomical information. On the other hand, high-resolution structural images can be obtained via the use of CT and/or MRI. These images complement each other to provide a complete picture of the targeted organs’ anatomy, physiology, and pathology. The fusion of these images is of great significance for the relevant clinical and pre-clinical studies. Another outstanding merit of utilizing multimodal fusion is that it efficiently enhances the spatial and temporal resolution in the charac- terization of brain processes. In other words, multimodal imaging may allow the combination of the hyper-temporal resolution of one imaging mode with the hyper-spatial resolution of another, taking advantage of the spatial-temporal complementarity. Take a study in 2014 as an ex- ample, Ke Zhang et al have successfully measured the cerebral blood flow with a combination of Arterial Spin Labeling (ASL), MRI and PET [205] . Apart from this, utilizing EEG together with fMRI to improve spa- tial and temporal resolution has also been studied by many scientists in neuroscience [206-209] It is worth mentioning that, in both narrow and wide senses, mul- timodal data fusion has a high capacity of generalization. A typical in- stance is the alignment of functional MRI, EEG, and fNIRS images to an anatomical coordinate system. The coordinate system can act as a tem- plate to standardize reported results. The alignment of the images to a single coordinate system not only allows comparison with other studies but also allows the combination of functional and structural information [210] . PET/CT combination is a multimodal absolute quantification ap- proach where CT provides structural data information on bones, which also serves as the main absorber for the 𝛾-rays in PET. This combination allows decay correction, in which the accumulation of radioactive iso- topes in human tissues becomes apparent, and the amount of radioactive decay can be absolutely quantified [211, 212] . Multimodal imaging also has the benefit of utilizing data from one modality to improve the data quality of another modality, such as cor- recting the geometric distortions of EPI images by acquiring a B0 field map or obtaining EPI with different parameters [213, 214] . Another clas- sic case is in a combined MR-PET study, where the motion information provided by high-temporal resolution MRI data was used to help the reconstruction of the PET data [10] . 5.1. Forms of multimodality fusion The long history of neuroimaging has led to the development of an assortment of imaging technologies and modalities, as seen in Section 3. The existing research and apparatus provided a solid foundation for mul- timodal fusion, leading to the rapid development of many fusion tech- niques. In this part, we classify reviewed methodologies into four pri- mary forms: multimodal, multi-focus, multi-temporal, and multi-view. 5.1.1. Multimodal fusion Modern medical imaging methods aim at revealing possible dysfunc- tions in patients. For example, neuroimaging methods are often used to image the structure of nervous system on a macroscopic level, which in turn helps explore the neuroglial basis of behavior and cognition of patients. However, how to combine different medical imaging methods to provide images with better quality or clearer structures remains to be the heated research interest in the field. Therefore, multimodal image fusion is proposed to minimize the gap. In a narrow sense, multimodal image fusion, a technique to improve the interpretation of the structure and functions of target organ or re- gion, generally combines two or even more images collected from dif- ferent imaging instruments. In order to achieve the goal of simultaneous acquisition, researchers have developed particular instrumentations to allow data of one modality to be acquired with low or neglectable infer- ence from another modality. For instance, the EEG-fMRI combination fuses data acquired from EEG instruments like amplifiers and MRI scan- ners. Also, the novel instrumentations range from simple arrangements to relatively complex technological innovations. However, in some com- binations, simultaneous acquisition of data was impossible due to the physical interactions of the imaging devices. Multimodal image fusion, in a broader sense, also combines data but collected with the same instrument. In this case, MRI is widely used due to its versatility in the generation of different tissue contrasts with the well-studied phenomenon of magnetic resonance. There is also research that combines two and more contrasts in the same acquisition, which has been routinely used for many years. Multiple contrasts can also be acquired by PET (Positron emission tomography) when radioactive com- pounds injected are different. 5.1.2. Multi-focus fusion Multi-focus fusion, which keeps interested objects staying in focus, is a technique to fuse images acquired with different focal length. Gen- erally, regions containing objects of interest were segmented from indi- vidual images, and then fusion is applied to form fused images. Many multi-focus image fusion methods have been developed during the past decades. These methods, however, can be classified into two categories: spatial domain and frequency domain. Spatial domain methods work on image pixels. Methods like Inten- sity Hue Saturation [215] and Principle Component Analysis (PCA) be- long to the category of the spatial domain [216] . A method based on Dis- crete Cosine Transform proposed by Phamila and Amutha [217] turns out to be more efficient compared to other existing DCT methods [218] . 161 Y.-D. Zhang, Z. Dong and S.-H. Wang et al. Information Fusion 64 (2020) 149–187 In the proposed method, original images are divided into 8 ∗ 8 blocks, while DCT coefficients of each block are calculated. AC coefficients, to- gether with DC coefficients, are two components that form DCT coef- ficients. The blocks with higher AC coefficient values are selected for fusion since higher AC coefficient value indicates higher variance and more fine-grained images. The analysis of performance is based on met- rics of mean square error (MSE), Petrovic’s metric, and Peak Signal to Noise Ratio (PSNR). The reason why this method is so efficient is likely because it does not require complex floating-point operations. A region-based method, which incorporated segmentation into the fusion process, was proposed by S. Li in [219] . The algorithm is com- posed of three steps: segmentation, clarity measurement, and fusion of images. Prior to these steps, images are first fused by averaging. Objects of interest are then extracted by normalization-based cuts segmentation. The normalized criterion measures similarity and dissimilarity between different images. After measuring the spatial frequency, the fusion of corresponding regions of source images can be performed. In order to evaluate the performance, mutual information and the Petrovic metric are considered. The Petrovic metric examines the quality of edge-based information transferred from source images to fused images. Compared to pixel-based fusion methods, which suffer from problems including blurring effect, sensitivity to noise and pixel misregistration, the pro- posed method has lower complexity while being more robust and reli- able. Based on the scale-invariant feature transform (SIFT), Yu et al. pro- posed that local image features such as SIFT can be used for image fusion [220] . The characteristic of SIFT is the robustness to spatial variations, including scale, rotation and translation. Generally, there are two phases in SIFT: feature points detection and feature point description. The pro- posed algorithm acquired the initial decision map by dense SIFT descrip- tor, which was used to measure the activity level of the source image patches. The decision map is further improved with feature matching and local focus measure comparison. It was pointed out that local fea- tures such as dense SIFT can also be used to match pixels that were misregistered between multiple source images. In methods based on frequency, images are transformed into the frequency-domain for fusion. Wavelet-based methods, including Discrete Wavelet Transform (DWT) [221] , Haar wavelet [222] and pyramid-based methods such as the Laplacian pyramid [223] , fall under the category of frequency-domain methods. A DWT based method was proposed in [224] . Principal component analysis (PCA) was used for approximating coefficients of input images. The principal components were evaluated to obtain multiscale coefficients. The weights for the fusion rule were then acquired by averaging those components. Besides the promising performance, the proposed method was widely applied in medical image fusion for CT and MRI images. In [225] , the authors pro- posed the Daubechies complex wavelet transform (DCxWT) to fuse mul- timodal medical image. By using the maximum selection rule, the com- plex wavelet coefficients of source images are fused. Source images at different levels are decomposed by DCxWT, followed by Inverse DCxWT to form the fused image. Compared to the other five methods, includ- ing Dual tree complex wavelet transform (DTCWT) based fusion and PCA based fusion, the proposed method achieved the best performance in terms of five measurements, including standard deviation, entropy, edge strength, fusion symmetry, and fusion factor. It was proved that the proposed method was robust to noises, including speckle, salt and pepper, while maintaining the property of shift-invariance. 5.1.3. Multi-temporal fusion and data acquisition Multi-temporal fusion is to fuse images taken at different times but of the same modality. Multi-temporal fusion enables easy detection of changes in images by subtracting one or multiple images from another. Data acquisition consists of separate recording and simultaneous record- ing. The choice between separate or simultaneous acquisition should be cautiously considered. Compared to separate recordings, where an im- age from each modality is acquired individually, simultaneous acquisi- 162 tions have relatively lower data quality and more artifacts. For exam- ple, EEG-fMRI simultaneously acquires cardio-ballistic artifacts and MRI gradients. Data acquisition consists of separate recording and simulta- neous recording [226] . In the MR-PET scenario, components of the MRI scanner would trigger degradation in PET scanning results. Therefore, the costs of simultaneous acquisition are higher than separate acquisi- tion due to subject discomfort and long set-up time. However, there are also many cases in which costs are of less concern, given the benefits of simultaneous acquisitions. 5.1.4. Multi-view fusion In multi-view fusion, images of the same modality are taken under different conditions at the same time. This fusion technique is applied to increase the amount of information for the fused images, while source images are taken under different conditions. The choice between asymmetric and symmetric data fusion makes a significant difference in the integration and joint analysis of multimodal data. For integration methods falling under the asymmetric category, in- formation from different modalities is assigned with different weights so that information from one modality could be treated as a constraint on the other modality. For instance, fMRI contrast maps limit the source localization of EEG/MEG. Modalities in symmetric data fusion, how- ever, are treated equally in terms of spatial and temporal resolution as well as the uncertainty in the possible indirect relation to neural activ- ity. Hypothesis-driven approaches and data-driven approaches are the two main categories of symmetric fusion approaches. Hypothesis-driven approaches, also called model-driven approaches, are usually in model- based setting, while data-driven approaches belong to blind source sep- aration methods [227] . Examples of different fusion methods are shown in Table 3 . 5.2. Fusion rules Image fusion rules are applied to highlight the features of inter- est in images while suppressing the unimportant features. Generally, fusion rules are mainly comprised of four components: activity-level measurement, coefficient grouping, coefficient combination, and con- sistency verification [230] . 5.2.1. Components of fusion rules The activity-level measurement rule, as can be subdivided into window-based activity (WBA), coefficient-based activity (CBA) and region-based activity (RBA), characterizes coefficients at different scales. In the coefficient grouping component, there are mainly three typical groupings, including single-scale grouping (SG), multi-scale grouping (MG), and no-grouping (NG). SG indicates that the same strat- egy is applied to fuse different coefficients between sub-images on the same scale. The coefficient combination component mainly comprises of max- imum rules (MR), weighted rules (WAR), and average rules (AR). MR can be given as: { 𝐶 𝐹 = 𝑗 > 𝐶 2 j 𝑗 > 𝐶 1 j 𝐶 1 𝑗 when 𝐶 1 𝑗 when 𝐶 2 𝐶 2 F indicates the combined coefficient, 𝐶 1 where C ficients of two input images at the level of j . For WAR, 𝐶 1 combined by multiplying different weights 𝑊 1 𝑗 and 𝐶 2 𝑗 and 𝑊 2 𝑗 , that is 𝑗 are the coef- 𝑗 and 𝐶 2 𝑗 are (1) (𝐶 𝐹 = 1 2 𝑊 1 𝑗 × 𝐶 1 𝑗 + 𝑊 2 )𝑗 × 𝐶 2 𝑗 (2) AR, which has the coefficient of input images averaged, is a special case of WAR. (𝐶 𝐹 = 1 2 )𝑗 + 𝐶 2 𝐶 1 𝑗 (3) The consistency verification component ensures that the same rules are applied to fuse the coefficients in the neighborhood. Y.-D. Zhang, Z. Dong and S.-H. Wang et al. Information Fusion 64 (2020) 149–187 Table 3 Examples of different fusion methods. Methods Source Image 1 Source Image 2 Fused Image Multi-focus [228] Multi-temporal Multi-view Multi-modal [229] Table 4 Three fusion levels. Decision level Feature level Pixel level • Image segmentation • Fusion based on initial object detection and classification • Image segmentation • Fusion based on the properties • Information acquisition of each pixel • Fusion of each pixel based on the information 5.2.2. Fusion levels There are three different levels of image fusion: pixel level, feature level, and decision level. This categorization can be seen in Table 4 and Fig. 10 . Pixel level rules directly deal with the information ac- quired from each pixel of source images and then generates pixel values for the fused image correspondingly. Feature level rules focus on re- gional information and features such as texture and salient features. The fused image in the decision level is acquired through rules of fuzzy logic and statistics. Before rules in feature level and decision level apply to the source images, segmentation of the source images is needed. Compared to the pixel level fusion, feature and decision level fusion shows more advantages are less affected by noises and misreg- istration. Feature and decision level fusion also shows better contrast and lower complexity [231] . In the following sections, we will intro- 163 Y.-D. Zhang, Z. Dong and S.-H. Wang et al. Information Fusion 64 (2020) 149–187 𝑗 and 𝑋 2 where 𝑋 1 𝑗 (1 ≤ j ≤ M ) are column vectors of two coefficients C 1 and C 2 . The importance of components is related to the eigenvalues in the covariance matrix between C 1 and C 2 . The covariance matrix can be computed through: 𝐶 1 , 𝐶 2 )(𝐶 𝑜𝑉 [( 𝐶 1 = 𝑬 (𝐶 2 1 ) − 𝑋 − 𝑋 2 )](8) where E is the expectation of vectors, 𝑋 average of C 1 and C 2 respectively, that is 1 and 𝑋 2 corresponds to the 1 = 1 𝑋 𝑀 2 = 1 𝑋 𝑀 𝑀 ∑𝑗=1 𝑀 ∑𝑗=1 𝑋 1 𝑗 𝑋 2 𝑗 (9) (10) Fig. 10. pixel-based and window-based fusion. duce fusion rules for multi-model image fusion, followed by validation metrics. 5.2.3. Fuzzy logic Fuzzy logic-based rules belong to decision level fusion. These rules are usually used to solve challenges in blurry fused images. Mamdani and T-S models are two fuzzy logic models. The difference between them lies in the consequence parts. T-S models linearly mapped input variables into functions to form the consequence parts, while Mamdani models used fuzzy sets. The T-S model is more advantageous than the Mamdani model in regard to number of rules and accuracy. In general, feature extraction through fuzzy logic algorithms is per- formed prior to fusion, which generates pixel-wise features C 1 and C 2 from two input images. The fusion procedure can be divided into three steps. In the first step, the fuzzy logic, which is usually comprised of four conditional rules, is used to label the individual pixels as following. Given the eigenvalues obtained from the covariance matrix as Y , the normalized weights w 1 and w 2 for C 1 and C 2 can be denoted as: 𝑤 1 = 𝑤 2 = 𝒀 ( 1 , 1 ) 𝒀 ( 1 , 1 ) + 𝒀 ( 2 , 1 ) 𝒀 ( 2 , 1 ) 𝒀 ( 1 , 1 ) + 𝒀 ( 2 , 1 ) (11) (12) Therefore, the fused coefficient C F can be the combination of two input images: 𝐶 𝐹 = 𝑤 1 × 𝐶 1 + 𝑤 2 × 𝐶 2 (13) The two-state HMT method, unlike PCA methods, can be deployed to model the coefficients. Two mixed Gaussian random distributions, as well as the hidden states, depict Intra-coefficients. The hidden states here refer to the one parent and four children coefficients. Given each coefficient denoted as C , the coefficient is obtained by probability den- sity function: 1 ∑𝐶 𝑖 = 𝑝 𝑖 ( 𝑛 ) × 𝑓 ( 𝐶 𝑖 |𝑆 𝑖 = 𝑛 ) (14) 𝑛 =0 𝐶 𝑤 = ⎧ ⎪ ⎪ ⎨ ⎪ ⎪ ⎩ ℎ𝑖𝑔ℎ, 𝑚𝑒𝑑𝑖𝑢𝑚, 𝑙𝑜𝑤, 𝑖𝑓 both of 𝐶 1 and 𝐶 2 are high ( Rule 1 ) 𝑖𝑓 𝐶 1 is low but 𝐶 2 is high ( Rule 2 ) OR 𝐶 1 is high but 𝐶 2 is low ( Rule 3 ) 𝑖𝑓 both of 𝐶 1 and 𝐶 2 are low ( Rule 4 ) (4) Then the new pixel-wise feature values can be calculated through: when the coefficient C i in the state n ( n = 0, 1), 𝑓 ( 𝐶 𝑖 |𝑆 𝑖 = 𝑛 ) is the prob- ability density function correspondingly. The fused coefficient is then given by: { 𝐶 𝐹 = 𝐶 1 |≥ |𝐶 2 ||𝐶 1 , if ||||𝐶 2 ||𝐶 1 ||𝐶 2 , if < ||||||||(15) 𝐶 𝑤,𝑗 ((( 𝑥 ) = 𝑒 − ))∕ 𝛽𝑗 𝑥 − 𝛼𝑗 2 , 𝑗 = 1 , 2 , 3 (5) 5.2.5. Human vision system where 1, 2, 3 corresponds to low, medium and high components, re- spectively. 𝛼 and 𝛽 are the mean and variance of each component. By incorporating the center average defuzzifier to process fuzzy outputs, the weight of fuzzy logic can be obtained. 5.2.4. Statistics model The essence in statistics-based methods lies in the data-driven tech- nique and high order statistics that can reveal the underlying pattern across multiple modes of data. Principal component analysis (PCA) [232-235] together with Hidden Markow Tree (HMT) [236-238] are two typical examples of statistic methods in the field of multi-modal medical image fusion. PCA is an orthogonal linear transformation that reveals the most valuable components of the input images. Let C 1 and C 2 be the two coefficients of the input images that can be denoted as: 𝐶 1 [1 , 𝑋 1 𝑋 1 = 2 , ⋯ , 𝑋 1 𝑀 ]𝑇 𝐶 2 [1 , 𝑋 2 𝑋 2 = 2 , ⋯ , 𝑋 2 𝑀 ]𝑇 (6) (7) 164 Methods based on the Human visual system (HVS) aim at solving the fusion problem in the way of image recognition and comprehension. The system includes components such as visibility, smallest univalve segment assimilating nucleus (SUSAN) [239] , and retina-inspired model (RIM) [240, 241] . The sharpness of an image can be quantified by visibility. Therefore, the images with higher visibility show lower blurriness. Given an image I of size h × w , then the visibility of the I can be mathematically expressed as: 𝑉 ( 𝑰 ) = 1 ℎ × 𝑤 ℎ ∑𝑤 ∑𝑥 =1 𝑦 =1 1 μ𝛼|𝑰 ( 𝑥, 𝑦 ) − μ|μ(16) where 𝜇 is acquired by calculating the mean grey value of the image I and 𝛼, the visual constant varying from 0.6 to 0.7. SUSAN, proposed in [242] , is a feature extraction algorithm inspired by HVS. SUSAN computes the feature of a pixel by considering a circular mask around the pixel. In the mask, the area consisting of pixels that have similar brightness to the nucleus, or the central pixel, is selected and is called Univalue Segment Assimilating Nucleus (USAN). Let the Y.-D. Zhang, Z. Dong and S.-H. Wang et al. Information Fusion 64 (2020) 149–187 input image to be I and the circular mask with the radius ̇𝑟 , then simplest USAN can be given as: { (|𝐼 ( 𝑟 ) − 𝐼 ||(|𝐼 ( 𝑟 ) − 𝐼 ||)|𝑟 |0 |)|𝑟 |0 |)𝑟, 𝑟 0 1 , 0 , ≤ 𝐿, (17) > 𝐿 (𝑔 = where r 0 is the central pixel, r is a nominal depicting surrounding pixels. I ( r )is the pixel value at r and L is the brightness difference threshold. The value of L , which specifies the range of pixel values to be considered, must be carefully chosen because extracted features are sensitive to it. In order to lower the sensitiveness, the distance between pixels is also taken into consideration, and the extended USAN function is: (𝑔 )𝑟, 𝑟 0 = exp ( )(2 𝑟 − 𝑟 − 0 2 𝜌2 ) ( ⎛ ⎜ − exp ⎜ ⎝ )(𝑰 ( 𝒓 ) − 𝑰 𝒓 0 𝐿 ) 6 ⎞ ⎟ ⎟ ⎠ (18) where 𝜌 is the distance scaling factor. For components in intensity-hue saturation (IHS) decomposition methods, the RIM model can be used as the fusion rules. There are five layers in RIM. The first cone layer outputs an array of high-resolution cone photoreceptors with high resolution. The second layer is the ex- tractor for spatial feature, while the third layers are horizontal cells. The fourth and fifth layers, which combine features, are bipolar and ganglion cells The RIM based image fusion rule can be demonstrated as: 𝐶 𝐹 = ℎ 1 × 𝐶 1 + ℎ 2 × 𝐶 2 (19) where C 1 and C 2 stand for intensity components of two source images. h 1 and h 2 are the filters of feature extractors. The filter h 1 , a high-scale spatial feature extractor, calculates the spatial difference between high- resolution and low-resolution. Filter h 2 combines the output of horizon- tal cells. 5.2.6. Validation metrics Objective evaluation metrics are used to evaluate the efficacy of im- age fusion rules on improving the quality of the fused image. Widely used metrics includes spatial frequency (SF) [243] , the ratio of spatial frequency error (rSFe) [244] , wavelet entropy (WE) [245] , Signal noise ratio (SNR) [246] , mutual information (MI) [247] and directive contrast (DC) [248] . SF metric, which measures images’ activity, is generally used for PCA integrated HIS methods in multimodal image fusion. SF can be defined as )𝐶 𝐹 2 (+ )𝑅 𝐹 2 (20) F and R F stand for column frequency and row frequency, respec- ′Based on SF, rSFe compares the SF 2 of the input images where SF’ can be extended as: F of the fused image with 𝑆𝐹 ′𝑆𝐹 ′1 and )2 𝐶 𝐹 )(2 𝑅 𝐹 + )(𝑀 𝐷 𝐹 + 2 ()𝑆 𝐷 𝐹 2 (21) where MD nal SF. rSFe can then be formulated as: F and SD F are the main diagonal SF and the secondary diago- √ (SF = where C tively. √ (SF ′ = [ ′SF 𝑟𝑆𝐹 𝑒 = 1 2 ′F − SF 1 SF ′1 + ′SF ′F − SF 2 SF ′2 ] In [246] , the authors proposed SNR-based image fusion rules. The proposed fusion method can be formulated in the following form. 𝐴 ( 𝑡 ) = 1 𝑀 𝑡 1 ≤ 𝑙≤ 𝑀 𝑡 ∑𝑝 𝑙 (25) for a specific region k. A ( t ) is the activity level of that, while M total number of pixels. The probability of pixel activity p lated through: t is the l can be calcu- ∑𝑝 𝑙 = 𝑤 𝑁 1 ≤ 𝑖 ≤ 𝑁 1 3 . 2 2 ( 𝑁− 𝑖 ) ∑∑𝑗 1 𝑗 2 )|(𝑑 𝑖 1 , 𝑗 𝑗 |2 ||||(26) where w is the weight of SNR from the image, N is the number of de- composition levels and d 2 ) is the detailed wavelet coefficient. 1 , j i ( j MI is deployed as the fusion rule for WT-based multi-modal medical 2 and the fused image image fusion. MI between the input images I 1 , I F , is maximized to give C F , which is acquired by: I )](𝑰 2 , 𝑰 𝐹 + 𝑀 𝐼 )(𝑰 𝑀 𝐼 1 , 𝑰 𝐹 𝐶 𝐹 [= 1 2 (27) DC measures the difference between the pixel and its neighbors. The H and the low-frequency ratio between the high-frequency intensity I intensity I L is the intensity contrast DC . 𝐷𝐶 = 𝑰 𝐻 ( 𝑥, 𝑦 ) 𝑰 𝐿 ( 𝑥, 𝑦 ) 5.3. Decomposition and reconstruction (28) For the multi-modal image fusion of neuroimaging, the selection of various decomposition and reconstruction methods influence the fusion procedure and outcomes. In this survey, we shall discuss seven popular methods: (i) RGB-IHS; (ii) Pyramid representation; (iii) wavelet-based approach and its variants; (iv) multi-resolution analysis; (v) sparse rep- resentation; and (vi) salient features. 5.3.1. RGB-IHS The intensity-hue-saturation (IHS) model [249] helps transform the original image in RGB color space to hue, saturation, and intensity chan- nels. This RGB to IHS procedure is calculated by simple equations. Be- sides, the reconstruction is carried out by inversed transformation (IHS to RGB). For the RGB- > IHS procedure, the intensity of each input image was estimated by the following equations: 𝐼 = 𝑅 + 𝐺 + 𝐵 3 (29) Then, we consider three conditions: C 1 : B < R,G; C 2 : R < B,G; C 3 : G < R,B . The hue value is obtained by ⎧ ⎪ ⎪ ⎨ ⎪ ⎪ ⎩ 𝐻 = 𝐻 = 𝐻 = 𝐺 − 𝐵 3 𝐼 − 3 𝐵 𝐵 − 𝑅 3 𝐼 − 3 𝑅 𝑅 − 𝐺 3 𝐼 − 3 𝐺 𝐶 1 𝐶 2 𝐶 3 (30) (31) Calculated by multi-scale entropy, WE can be given by: ∑𝑊 𝐸 = − ( 𝑝 𝑖 ⋅ 𝑙𝑛 𝑝 𝑖 ) 𝑖< 0 where i is the resolution level, p the energy of the detail signal E i is the density distribution derived from i and the total energy E T 𝑝 𝑖 = 𝐸 𝑖 𝐸 𝑇 (24) 165 (22) (23) The saturation value was yielded from the equation ⎧ ⎪ ⎪ ⎨ ⎪ ⎪ ⎩ 𝑆 = 𝑆 = 𝑆 = 𝐼 − 𝐵 𝐼 𝐼 − 𝑅 𝐼 𝐼 − 𝐺 𝐼 𝐶 1 𝐶 2 𝐶 3 On the other hand, after the revision was performed on the I, H , and S components, we can convert from IHS color space to original RGB space based on three various conditions: Y.-D. Zhang, Z. Dong and S.-H. Wang et al. Information Fusion 64 (2020) 149–187 Fig. 12. Diagram of two-level pyramid representation based fusion. where K is the maximum iteration number. After modification on the PR of input images, the fused image I F is obtained by inverse pyramid transformation (IPT) as 𝐾 ∑𝐼 𝐹 = 𝑝 𝑘 + 𝑟 𝑘 𝑘 =1 (39) Fig. 11. A toy example showing pyramid representation. The process of PR based fusion is shown in Fig. 12 . For C 1 , we have 𝑅 = 𝐼 × ( 1 + 2 𝑆 − 3 𝑆 × 𝐻 ) 𝐺 = 𝐼 × ( 1 − 𝑆 + 3 𝑆 × 𝐻 ) 𝐵 = 𝐼 × ( 1 − 𝑆 ) For C 2 , we have 𝑅 = 𝐼 × ( 1 − 𝑆 ) 𝐺 = 𝐼 × ( 1 + 5 𝑆 − 3 𝑆 × 𝐻 ) 𝐵 = 𝐼 × ( 1 − 4 𝑆 + 3 𝑆 × 𝐻 ) For C 3 , we have 𝑅 = 𝐼 × ( 1 − 7 𝑆 + 3 𝑆 × 𝐻 ) 𝐺 = 𝐼 × ( 1 − S ) 𝐵 = 𝐼 × ( 1 + 8 𝑆 − 3 𝑆 × 𝐻 ) ⎧ ⎪ ⎨ ⎪ ⎩ ⎧ ⎪ ⎨ ⎪ ⎩ ⎧ ⎪ ⎨ ⎪ ⎩ (32) (33) (34) 5.3.2. Pyramid representation Pyramid representation (PR) is commonly employed in image fu- sion. PR is a typical multi-scale signal representation approach that can be used for 1D signals, 2D images, etc. Fig. 11 shows a toy example us- ing the cameraman picture. There are two pyramids commonly seen in practice: lowpass pyramid and bandpass pyramid. The former smooths the image and then under-samples the smoothed image. The latter gen- erates the difference between images at adjacent levels and carry out image interpolation between neighboring levels of resolution. Let us assume we have input image I . We have a series of pyramid representations of this input image I as )2 , … , 𝑝 𝑘 , (𝑃 𝑅 = 1 , 𝑝 𝑝 1 = 𝐼 𝑝 Suppose F k is the filter and down-sampling, PR can be obtained by 𝑟 𝑘 = 𝐹 𝑘 × 𝑝 𝑘 𝑝 𝑘 +1 = 𝑝 𝑘 − 𝑟 𝑘 (36) (37) where r k is the residual image of I at i -th level, and k is in the range of 5.3.3. Wavelet-based method Wavelet transform (WT) based fusion is one of the multi-scale analy- sis methods. The idea is simple, as shown in Fig. 13 . WT will decompose the input images into low-frequency (LF) and high-frequency (HF) sub- bands. The corresponding image fusion rules will be applied to fuse LF and HF subbands. Finally, the fused image is yielded by the WT recon- struction technique [250] . Continuous wavelet transform (CWT) decomposes a square- integrable function S ( t ) as follows 𝑊 Φ( 𝑐, 𝑏 ) = ∫−∞∞𝑆 ( 𝑡 ) Φ𝑐,𝑏 ( 𝑡 ) d 𝑡 where Φ𝑐,𝑏 ( 𝑡 ) = 1 √( 𝑐 ) × Φ()𝑡 − 𝑐 𝑏 (40) (41) Here, the wavelet Φc, b ( t ) is calculated from the mother wavelet Φ( t ) by translation and dilation. The dilation factor c and translation factor b are all positive numbers. On the other hand, the discrete wavelet transform (DWT) captures both spatial information along x and y axes, by discretizing above two equations 𝑐 = 2 − 𝑝 𝑏 = 𝑞 × 2 − 𝑝 (42) (43) Then, suppose a low-pass filter (LPF) 𝕘 and a high-pass filter (HPF) 𝕙 are created, we have ( ) (35) 𝑒 𝑎 ( 𝑝, 𝑞 ) = ∑( 𝑛 ∑𝑒 𝑑 ( 𝑝, 𝑞 ) = 𝑛 𝐼 ( 𝑛 ) × 𝕘 ∗ 𝑝 ( 𝑛 − 2 𝑝 × 𝑞 ) ↓ 2 ) 𝐼 ( 𝑛 ) × 𝕙 ∗ 𝑝 ( 𝑛 − 2 𝑝 × 𝑞 ) ↓ 2 (44) (45) where n is the discrete version of time t, e represents the coefficients, a and d correspond to approximation and detail, respectively. The symbol ↓ represents the downsampling operation. 𝑘 ∈ [ 1 , … , 𝐾 ] (38) ( 𝐼 ↓ 𝑗 ) ( 𝑛 ) = 𝐼 ( 𝑗 × 𝑛 ) (46) 166 Y.-D. Zhang, Z. Dong and S.-H. Wang et al. Information Fusion 64 (2020) 149–187 Fig. 13. Diagram of wavelet-based fusion methods. Fig. 14. Diagram of 2D-DWT. Modulus Maxima. Pawar and Kadam [253] used SWT and convolutional sparse representation for multi-modal image fusion. The DWT calculates each decomposition level by passing only the previous approximation coefficients to quadrature mirror filters (QMF). Nevertheless, the discrete wavelet packet transform (DWPT) [254, 255] passes all coefficients (both approximation and detail) through QMF to create a full binary tree. Sreekala and Kuncheria [256] used WPT to implement misaligned image fusion. Shah, Merchant [257] combined curvelet wavelet and the WPT method to carry out image fusion. To increase directional selectivity, the dual-tree complex wavelet transform (DTCWT) used two separate two-channel filter banks. The scaling and wavelet filters in the dual-tree cannot be selected arbitrarily. In one tree, the wavelet and scaling filters produce a wavelet and scaling function, which are approximate Hilbert transforms of those generated by another tree. At each level of 2D DTCWT, it produces a total of six directionally selective subbands ( ± 15 °, ± 45 °, ± 75 °). Fig. 16 presented a comparison of DWT, SWT, DWPT, and DTCWT. Lift scheme (LS) is a solution to reduce computation time and ac- celerate the design and application of DWT [258] . The idea of LS is to factorize DWT with finite filters, into a sequence of ordinary convolu- tion operators, which are called “lifting steps ” [259] . This procedure can reduce the arithmetic operations by almost two. Mathematically, the analysis filters ( 𝕘 , 𝕙 ) can be formulated in the form of polyphase matrix P ( z ) = [ ( ) ] even ( 𝑧 ) 𝕘 𝑒𝑣𝑒𝑛 ( 𝑧 ) 𝕙 𝕘 𝑜𝑑𝑑 ( 𝑧 ) 𝕙 𝑜𝑑𝑑 ( 𝑧 ) (51) This polyphase matrix P(z) is a 2 × 2 matrix, which contains the anal- ysis LPF and HPF, each split up into their even and odd polynomial co- efficients and normalized. [ (1 𝕒 P ( z ) = )] 1 + 𝑧 −1 ×0 1 1 ⎡ ⎢ ⎢ 𝕓 × ( 1 + 𝑧 ) ⎣ ⎤ 0 ⎥ ⎥ ⎦ 1 (52) The above decomposition process can be iterated with successive approximations being decomposed in turn, so that one signal is broken down into various levels of resolution. When I ( n ) is extended to be a 2D brain image I ( m, n ), the 1D-DWT is applied to row and column directions separately. The approximation ( a ) and detail ( d ) subbands now expand to four subbands: approximation subband ( a ), horizontal subband ( h ), vertical subband ( v ), and diagonal subband ( d ), as shown in Fig. 14 . ∑𝑒 𝑎 ( 𝑚, 𝑛 ) = 𝐼 ( 𝑥, 𝑦 ) × 𝕘 ( 2 𝑚 − 𝑥 ) × 𝕘 ( 2 𝑛 − 𝑦 ) 𝑥,𝑦 ∑𝑒 ℎ ( 𝑚, 𝑛 ) = 𝐼 ( 𝑥, 𝑦 ) × 𝕙 ( 2 𝑚 − 𝑥 ) × 𝕘 ( 2 𝑛 − 𝑦 ) 𝑥,𝑦 ∑𝑒 𝑣 ( 𝑚, 𝑛 ) = 𝐼 ( 𝑥, 𝑦 ) × 𝕘 ( 2 𝑚 − 𝑥 ) × 𝕙 ( 2 𝑛 − 𝑦 ) 𝑥,𝑦 ∑𝑒 𝑑 ( 𝑚, 𝑛 ) = 𝐼 ( 𝑥, 𝑦 ) × 𝕙 ( 2 𝑚 − 𝑥 ) × 𝕙 ( 2 𝑛 − 𝑦 ) (47) (48) (49) (50) 𝑥,𝑦 2D-DWT can even be generalized to 3D-DWT. A straightforward im- plementation is to apply 1D-DWT to row, column, and slice directions, respectively. Fig. 15 shows an example of carrying out 3D-DWT to a cu- bic image. Instead of using a, h, v , and d , we now use LLL, LLH, LHL, LHH, HLL, HLH, HHL, and HHH to represent the eight subbands in 3D- DWT [251] . Here L and H represent the result after LPF and HPF, re- spectively. 5.3.4. Variants of wavelet-based analysis The DWT can provide better performances than traditional signal processing techniques, but it lacks translation-invariance and directional selectivity. Hence, new variants of wavelet-based techniques have been applied to multi-modality image fusion. The stationary wavelet transform (SWT) can solve the shift-variance problem by getting rid of the downsampling operation from ordinary DWT. SWT can provide more details and texture information than DWT. Prakash and Khare [252] fused CT and MR images based on SWT by 167 Y.-D. Zhang, Z. Dong and S.-H. Wang et al. Information Fusion 64 (2020) 149–187 Fig. 15. Illustration of performing 3D-DWT on a cu- bic image. P(z) is then factored into a series of 2 × 2 upper triangular matri- ces (UTM) and lower triangular matrices (LTM), each with diagonal en- tries equal to 1. UTM contains the coefficients 𝕒 for prediction, while LTM contains the coefficients 𝕓 for updates. Prakash, Park [260] used LS based biorthogonal wavelet transform to realize the multi-scale fu- sion of multimodal medical images. Haouam, Beladgham [261] used the level-set method and LS-based CDF wavelet to compress magnetic resonance images. 5.3.5. Other multi-resolution analysis Apart from the wavelet analysis, scholars have also proposed other multi-resolution analysis (MRA) methods for multimodal image fusion. The wavelet does not work well in detecting smoothness along the edges, and it lacks directional resolution because it only has three high- frequency subbands. The contourlet transform (CT) utilizes the con- tour segments to capture the geometrical structures of the input im- ages. The procedure is two-stage: First, the Laplacian pyramid (LP) per- forms multi-scale decomposition, capturing point discontinuities. Sec- ond, directional filter bank (DFB) yields directional information and forms those point discontinuities into a linear structure. The flowchart of CT is shown in Fig. 17 . Similar to stationary wavelet transform developed from dis- crete wavelet transform, nonsubsampled contourlet transform (NSCT) [262] was also developed due to the shift-variance of CT. Ramlal, Sachdeva [263] proposed an improved multimodal medical image fu- sion scheme, via a hybrid combination technique of NSCT and SWT. Li, Wang [264] presented a new practical medical image enhancement based on NSCT. Wang, Zhao [265] used NSCT and simplified-spatial frequency-pulse coupled neural network to develop a multi-modal func- tional/anatomical medical image fusion framework. Wavelets also fail to capture the geometric regularity along the sin- gularities of surfaces, because of their isotropic support. Shearlet trans- form (ST) is one of the best sparse directional image representation methods. Fig. 18 showed the ST coefficients, where the input image is 168 Fig. 16 (a). Li, Wang [266] proposed a novel medical image fusion ap- proach based on nonsubsampled ST (NSST). Vishwakarma and Bhuyan [267] offered a new image fusion framework via adjustable NSST. Ak- barpour, Shamsi [268] suggested a novel combination of NSST and prin- cipal component averaging. 5.3.6. Sparse representation Different from standard multi-scale analytic methods, the sparse rep- resentation (SR) assumes that both high-frequency and low-frequency components share the same set of sparse coefficients [269] . SR based fu- sion method root from compressed sensing. Nowadays, there are some famous variants of SR, such as group sparse representation and joint sparse representation (JSP) [270] , the diagram of which is shown in Fig. 19 . From Fig. 19 we can observe the detailed steps of JSP [271] . First, 2 are transformed into vectors  via sliding 1 and I both input images I window  = SW ( 𝐼) (53) where SW represents the sliding window method. An over-complete dic- tionary sparsely represents the vectors of both images  =  C +  𝑈 (54) where  C represents the intersection of vectors of images I 2 , and  U represents their differences. The two variances  C and  U can be obtained by 1 and I  C = 𝐸 × 𝑇 𝐶  U = 𝐸 × 𝑇 𝑈 (55) (56) where E stands for the over-complete dictionary, and T C and T U denote the sparse coefficients (SC) of  C and  U . Y.-D. Zhang, Z. Dong and S.-H. Wang et al. Information Fusion 64 (2020) 149–187 Fig. 16. Comparison of different wavelet-based decomposition techniques. Fig. 17. Diagram of contour transform. Afterward, SCs from both input images are combined using fusion rules  as (F =  T T C , T U )(57) Fig. 18. Example of coefficients of shearlet transform. where T erate the fused vectors F stands for the fused SC. The over-complete dictionary can gen-  F = 𝐸 × 𝑇 𝐹 (58) scheme [272] , multi-scale edge-preserving decomposition [273] , edge- preserving smoothing pyramid [274] . where  F stands for the fused vector. Finally, we can transform  F to image space and get the fused image F . I 5.3.7. Salient feature Salient feature based fusion approaches are a type of novel meth- ods, with the benefits of shift-invariance, low-cost computation, and saliency-feature preservation. The edge-preserving filter (EPF) is an im- portant research method among all salient feature fusion approaches. Scholars have proposed many EPF approaches, such as local extrema 169 Fig. 20 shows the diagram of the EPF-based image fusion approach, where BL and DL represent the base layer and detailed layer, respec- tively. The procedures of EPF-based image fusion approach are listed below: First, both input images are decomposed into base layer (BL) and de- tailed layer (DL) by edge-preserving filters. The BL of each input image at different scales is obtained by 𝐵 𝑘 𝑗 = 𝐼 𝑘 × 𝐹 𝑗 (59) where k ∈ [1, 2] means the index of two input images, and j is the level j represents the EPF at j -th level. Similarly, the of decomposition, and F Y.-D. Zhang, Z. Dong and S.-H. Wang et al. Information Fusion 64 (2020) 149–187 Fig. 19. Diagram of JSP based fusion method. descriptors (e.g. none, minimal, some, substantial) associated with con- tinuous scores. Subjects are required to answer questions with respect to a set of images. It is ideal for image sets between subjects to over- lap in order to ensure multiple surveys for the same image. With a set of high-quality fused images as references, the survey scores are then converted to difference scores with respect to scores of reference im- ages. The difference scores are then converted to Z-scores and rescaled to the required range for analysis [276] . The double stimulus method is commonly applied to account for the potential misalignment in quality scales between different image sets or different assessment sessions. In the double stimulus method, both surveys and references are randomly included in the test set [277] . Conventional quality metrics obtained using these methods are the mean opinion score (MOS) and difference mean opinion score (DMOS). Data noise elimination and outlier removal for images & subjects are then performed after obtaining the scores. Subjective quality assessments are vulnerable to both intra-expert and inter-expert variability, while the requirement for expertise significantly increases the cost of assessments. For extensive studies, considerable ef- forts are required to standardize and maintain assessment protocols for optimal consistency [278] . (60) 6.2. Objective quality assessment In contrast to subjective Quality Assessment (QA), which involves a complex organization of observers and strict tests, objective QA only re- quires the computation of a single numerical score. Objective QA should be consistent with subjective QA, and often relies on statistical proper- ties of the images, or even stochastic modeling of the Human Visual System (HVS) [279] . Objective QA can be classified according to the reference (distortion- I used in the score computation. The best-case scenario is free) image I I , with the same resolution as the full-reference QA [280] , in which I F , is known. This approach is, by far, the most widely the fused image I extended. However, this full-reference is rarely available in practical applications. For example, in multi-spectral satellite imaging or medi- cal imaging, some image modalities are acquired at a lower resolution and then fused with higher-resolution gray-level images. This is known I is sometimes available at a as the reduced-reference case, where I coarser resolution and sometimes just a set of extracted features, and the QA is performed in this feature space. Finally, a third case is when no reference is available at all [281] . In this case, I F is considered by itself, and measures like entropy and contrast are computed using only the information contained within. Depending on the type of quantification used, the metrics can be classified into “signal distortion ” and “salient feature ” categories. The former uses strict mathematical theory to assess quality, e.g. with en- tropy, standard deviation, etc. The later is grounded on a modeling of the HVS to assess salient feature transferred from I I to I F . 6.2.1. Signal distortion based metrics The first signal distortion metric is a commonly used statistic, the F . Let us con- F ( x, y ) defined in the range standard deviation (STD) between the input image I sider the images as a function I I ( x, y ) and I I and I Fig. 20. Diagram of EPF based fusion approach. DLs are obtained by 𝐷 𝑘 𝑗 = 𝐼 𝑘 − 𝐵 𝑘 𝑗 Afterward, the BL and DL fusion rules 𝔾 B and 𝔾 D are applied to corresponding BLs and DLs, respectively; 𝐵 𝑓 = 𝔾 𝐵 ( 𝐵 1 𝑗 , 𝐵 2 𝑗 |𝑗 = 1 , 2 , … 𝐽 ) 𝐷 𝑓 = 𝔾 𝐷 ( 𝐷 1 𝑗 , 𝐷 2 𝑗 |𝑗 = 1 , 2 , … 𝐽 ) (61) (62) f and D where B position level. Finally, the fused image I below or other weighted equations. f are the fused BL and DL, and J is the maximum decom- F is recovered by the summation 𝐼 𝐹 = 𝐵 𝑓 + 𝐷 𝑓 (63) 6. Multimodal imaging data fusion: assessment Assessment is an essential component of multimodal data fusion that provides perspective into the quality of fusion results. There are two main forms of qualitative assessment: subjective quality assessment and objective quality assessment. In this part, we will review the conven- tional techniques and metrics applied in both forms. 6.1. Subjective quality assessment Subjective assessments are established as a reliable form of quality evaluation in image fusion [275] . Professional subjective assessments based on medical and radiology expertise are widely applied in neu- roimaging studies. Conventional subjective quality assessments are in the form of surveys with a set predesignated of questions and solutions, which represents a non-linear mapping to quantitative quality metrics [276] . Typical questions in neuroimaging fusion are the number of ar- tifacts or distortion, while typical solutions can be in the form of basic 170 Y.-D. Zhang, Z. Dong and S.-H. Wang et al. Information Fusion 64 (2020) 149–187 𝑥 ∈ [ 0 , … 𝑀 ] and 𝑦 ∈ [ 0 , … 𝑁 ] , with M the number of rows and N the number of columns in the image. The STD is computed as: )(𝐼 𝐼 , 𝐼 𝐹 𝑆𝑇 𝐷 = 𝑀−1 ∑[𝑁−1 ∑]2 𝐼 𝐼 ( 𝑥, 𝑦 ) − 𝜇𝐼 𝐹 (64) √ √ √ √ √ 1 𝑀𝑁 𝑥 =0 𝑦 =1 with 𝜇𝐼 𝐹 being the mean intensity of the fused image. Similar is the Root Mean Squared Error (RMSE), also widely used in many applications, included objective QA: (𝑅𝑀 𝑆𝐸 )𝐼 𝐼 , 𝐼 𝐹 = √ √ √ √ √ 1 𝑀 𝑁 𝑀−1 ∑𝑁−1 ∑][2 𝐼 𝐼 ( 𝑥, 𝑦 ) − 𝐼 𝐹 ( 𝑥, 𝑦 ) 𝑥 =0 𝑦 =1 (65) An additional measure based only on pixel intensities is the Sharp- ness (SP), that reflects the level of detail transferred to I F : )(𝐼 𝐼 , 𝐼 𝐹 𝑆𝑃 = 1 𝑀𝑁 𝑀−1 ∑𝑁−1 ∑𝑥 =0 𝑦 =1 √ { [1 2 ×]𝐼 𝐹 ( 𝑥, 𝑦 ) − 𝐼 𝐹 ( 𝑥, 𝑦 − 1 ) 2 } ][2 𝐼 𝐹 ( 𝑥, 𝑦 ) − 𝐼 𝐹 ( 𝑥 − 1 , 𝑦 ) + 𝑁,𝑗 and fusion images. ⃗𝐶 ( 𝑁,𝑗 ) , ⃗𝐼 represent N elements of the GSM model for the visual model ( C ), reference image ( I F ) in subband j . A more detailed explanation of the computation of these coefficients is found at Sheikh and Bovik [276] . I ) and fused image ( I 𝐹 , ⃗𝐼 𝑁,𝑗 𝐼 However, Hossny, Nahavandi [283] propose a new formulation of mutual information (MI), based on the joint statistical distribution of two random variables. To do so, we note the mutual entropy as: 𝐻 ( 𝑋, 𝑌 ) = 𝐿 −1 ∑𝑖,𝑗 𝑃 ( 𝑖, 𝑗 ∨ 𝑋, 𝑌 ) 𝑃 ( 𝑖, 𝑗 ∨ 𝑋, 𝑌 ) 𝑙𝑜 𝑔 2 𝑃 ( 𝑖 ∨ 𝑋 ) 𝑃 ( 𝑗 ∨ 𝑌 ) = 0 (73) where P ( i ∨X ) and P ( j ∨Y ) are the probability of intensity i and j on the images X and Y respectively, and P ( i, j ∨X, Y ) is their joint probability. Note that 𝐻( 𝑋, 𝑋 ) = 𝐸 𝑁( 𝑋 ) , identical to Eq. (68) . The Mutual Information (MI) is then obtained in [284] as: )(𝐼 𝐹 , 𝐼 𝐼 𝑀 𝐼 )(𝐼 𝐹 , 𝐼 𝐼 + 𝐻 )(𝐼 𝐹 + 𝐻 )(𝐼 𝐼 = 𝐻 (74) 1 , 𝐼 1 ) and H ( I with 𝐼 𝐼 = 𝐼 2 to obtain them with no reference images. However, the H ( I 2 ) are not guaranteed to be on the same scale. The F , I solution is the Normalized Mutual Information, devised in [284] and re-formulated in [283] for the fusion of two source images I F , I 1 , I 2 as: And finally, the Peak Signal-to-Noise Ratio (PSNR), which is perhaps (66) (1 , 𝐼 𝑁 𝑀 𝐼 𝐼 )2 , 𝐼 𝐹 [ )(1 , 𝐼 𝐹 𝑀 𝐼 𝐼 ()(+ 𝐻 𝐻 𝐼 𝐹 𝐼 1 = 2 ) + ] )(2 , 𝐼 𝐹 𝑀 𝐼 𝐼 )()(+ 𝐻 𝐻 𝐼 𝐹 𝐼 2 the most widely used objective quality assessment: )(𝐼 𝐼 , 𝐼 𝐹 𝑃 𝑆𝑁 𝑅 = 10 𝑙𝑜𝑔 ( ) ( 𝐿 − 1 ) 2 )(2 𝐼 𝐼 , 𝐼 𝐹 𝑅𝑀 𝑆𝐸 where L is the number of intensity levels, typically 256 for 8-bit images. Now there are many other measures based on information theory and entropy [282] . To perform this computation, let us note P ( i ∨I ) as the ratio of pixels with gray value equal to i over the total number of pixels N × M of image I . We define the Entropy (EN) as: 𝐸𝑁 ( 𝐼 ) = − 𝑃 ( 𝑖 ∨ 𝐼 ) 𝑙𝑜 𝑔 2 𝑃 ( 𝑖 ∨ 𝐼 ) 𝐿 −1 ∑𝑖 =0 (68) The difference of entropy (DEN) [282] quantifies the differences be- tween I I . The smaller, the better: F and I )|()(|𝐸 𝑁 − 𝐸 𝑁 𝐷𝐸 𝑁 = 𝐼 𝐼 𝐼 𝐹 ||||(67) The Spatial Frequency (SF) [285] is often used to measure the overall R ) clarity of the fused images. It is obtained from the row frequency ( F and column frequency ( F C ) of the image I as follows: 𝐹 𝑅 ( 𝐼 ) = [ 𝐼 ( 𝑗, 𝑘 ) − 𝐼 ( 𝑗, 𝑘 − 1 ) ] 2 𝐹 𝐶 ( 𝐼 ) = [ 𝐼 ( 𝑗, 𝑘 ) − 𝐼 ( 𝑗 − 1 , 𝑘 ) ] 2 𝑀𝑁 √ √ √ √ √ 1 √ √ √ √ √ 1 𝑀𝑁 𝑀−1 ∑𝑁−1 ∑𝑗=0 𝑘 =1 𝑁−1 ∑𝑀−1 ∑𝑘 =0 𝑗=1 and the SP is obtained by the harmonic mean of these two measures. √ 𝑆𝑃 ( 𝐼 ) = 𝐹 𝑅 ( 𝐼 ) 2 + 𝐹 𝐶 ( 𝐼 ) 2 (78) (75) (76) (77) (69) 6.2.2. Salient feature based metrics Another possibility when a reference image is available is to compute F : the Cross-Entropy (CE) between the reference I I and the fused image I (𝐶𝐸 )𝐼 𝐼 , 𝐼 𝐹 = (𝑃 )()|𝑃 𝑖 ∨ 𝐼 𝐼 𝑖 ∨ 𝐼 𝐼 𝑙𝑛 ||)|(𝑖 ∨ 𝐼 𝐹 ∕ 𝑃 ||(70) 𝐿 −1 ∑𝑖 =0 From CE we can derive the Overall Cross-Entropy (OCE), which mea- sures the entropy between several input images and the fused image. The formula below refers to K images, but the most common case is the one 2 : that uses just two images, I 1 and I (𝑂𝐶 𝐸 )𝐼 0 , … , 𝐼 𝑛 , 𝐼 𝐹 = 1 𝐾 𝐾 ∑𝑛 =0 (𝐶 𝐸 )𝐼 𝑛 , 𝐼 𝐹 (71) In Sheikh and Bovik [276] , the authors propose the Visual Informa- tion Fidelity (VIF) measure. This measure quantifies how much of the information at I F . It is based on a Gaussian Scale Mixture (GSM) random field source model and a modelling of the HVS as a distortion channel. It uses the information MI ( X, Y ) between two given images, and sums over all subbands as in: I can be extracted from I ∑𝑉 𝐼 𝐹 = ∑𝑗 ∈𝑠𝑢𝑏𝑏𝑎𝑛𝑑 𝑠 𝑀 𝐼 ( ⃗𝐶 ( 𝑁,𝑗 ) ; ⃗𝐼 𝑗 ∈𝑠𝑢𝑏𝑏𝑎𝑛𝑑 𝑠 𝑀 𝐼 ( ⃗𝐶 ( 𝑁,𝑗 ) ; ⃗𝐼 𝑁,𝑗 𝐹 𝑁,𝑗 𝐼 |𝑠 𝑁,𝑗 ) |𝑠 𝑁,𝑗 ) (72) Salient feature metrics assess whether the salient features of the source images have passed to the fused image, following the hypothesis that the HVS is highly adapted for the perception of structural informa- tion. The most widely used measure in this category is the Structural Similarity (SSIM) index [281] , which is based on the degradation of structural information. The SSIM compares local patterns of pixel intensities, based on lu- minance l , contrast c and structure s : ([𝐼 𝐼 , 𝐼 𝐹 𝑙 = )(𝐼 𝐼 , 𝐼 𝐹 𝑆 𝑆 𝐼 𝑀 𝐼 𝐼 , 𝐼 𝐹 )]𝛼[(𝑐 )]𝛽 [(𝑠 )]𝛾𝐼 𝐼 , 𝐼 𝐹 (79) weighted by some exponential variables that were set to 𝛼 = 𝛽 = 𝛾 = 1 in the original paper [281] . Several expressions are provided for s ( X, Y ), l ( X, Y ) and c ( X, Y ), with certain constraints, and after substituting on the previous equation, it becomes: ()()()= 𝐼 𝐹 + 𝐶 1 𝜇𝐼 𝐹 + 𝐶 1 )()(𝐼 𝐼 , 𝐼 𝐹 𝑆 𝑆 𝐼 𝑀 2 𝜇𝐼 𝐼 𝐼 𝐼 + 𝜇2 𝜇2 2 𝜎𝐼 𝐼 𝐼 𝐹 + 𝐶 2 𝐼 𝐼 + 𝜎2 𝜎2 2 are two constraints of the model, expressed by 𝐶 2 𝐿 ) 2 and K where C 1 = 1 𝐿 ) 2 , 𝐶 ( 𝐾 I corre- sponds to the mean intensity and unbiased standard deviation of the intensities of I , as in previous equations, and 𝜎𝐼 𝐼 𝐼 𝐹 is the covariance F . matrix of the intensities of I 2 ≪ 1. The notation 𝜇1 and C 2 = ( 𝐾 1 ≪ 1, K 𝐼 𝐹 + 𝐶 2 I and 𝜎I and I (80) 𝑁,𝑗 where 𝑀 𝐼 ( ⃗𝐶 ( 𝑁,𝑗 ) ; ⃗𝐼 |𝑠 𝑁,𝑗 ) represent the in- 𝐼 formation that could ideally be extracted by the brain in the reference 𝑁,𝑗 |𝑠 𝑁,𝑗 ) and 𝑀 𝐼 ( ⃗𝐶 ( 𝑁,𝑗 ) ; ⃗𝐼 𝐹 Finally, Mittal et al. proposed the Natural Image Quality Evaluator (NIQE) [286] , a QA model based on the construction of a Multivariate 171 Y.-D. Zhang, Z. Dong and S.-H. Wang et al. Information Fusion 64 (2020) 149–187 Gaussian Model (MGM) from a corpus of undistorted images with mean M , N ( 𝜇𝜇M and covariance matrix 𝜎M ). These features are “quality F is estimated as a distance between the aware ”, and the quality of I statistics of the model and the fused image. M , 𝜎)(𝑁 𝐼 𝑄𝐸 𝐼 𝐹 = √ (𝜇𝐼 𝐹 − 𝜇𝑀 )𝑇 ) −1 (( 𝜎𝐼 𝐹 + 𝜎𝑀 2 )𝜇𝐼 𝐹 − 𝜇𝑀 (81) with 𝜇𝐼 𝐹 and 𝜎𝐼 𝐹 the mean vector and covariance matrix of the MGM of F . I 7. Multimodal imaging data fusion: Benefits Multimodal neuroimaging and the fusion of multimodal data tackle the challenges of neuroimaging and the fundamental limitations of indi- vidual modalities, and therefore provide significant benefits to the over- arching aim to achieve higher image quality and reveal brain physiol- ogy. This part will review some of the main benefits with specific fusion examples. 7.1. Combination of physiological aspects of brain structures and processes 7.1.1. MR-PET MR-PET refers to a functional metabolic and molecular multimodal imaging method integrated through a combination of MRI and PET. It has the potential to achieve the maximum complementary advantages with the examination function of both PET and MRI [287] . MRI can not only display structural details through multi-parameter sequences but also perform a variety of functional imaging. In other words, it can be seen as a means of anatomical imaging. However, com- pared with PET, MRI still has certain limitations in metabolite imaging. PET imaging can show trace amounts of radiolabeled molecules, but its image resolution is poor and the anatomical structure is not clear. It is the complementary characteristics of MRI and PET that led to the birth of MR-PET imaging, which not only has high soft-tissue contrast and resolution but also can provide valuable functional information [288] . At the radiological society of North America meeting in November 2006, Siemens presented the first MR-PET images of the brain from their diagnostic machine. During the imaging process of MR-PET, PET and MR imaging can be performed simultaneously with minimal inter- ference; the PET scan detects the accumulation of fluorodeoxyglucose, while multiple sequences of MR images were obtained [289] . 7.1.2. Combination of different contrast images In neuroimaging studies of MRI, the common approach tends to ac- quire T1- and T2-weighted anatomical, T2 ∗ -weighted functional data within the same session and then make a combination of these differ- ent contrasts for further exploration and research. Here, T1 refers to the recovery time of longitudinal magnetization, and T2 refers to the de- cay time of transverse magnetization. Both of them are special values associated with the spin of the nucleus in the tissues. In humans, T1 and T2 values of diseased tissue and normal tissue are different, so diseases can be diagnosed by nuclear magnetic resonance imaging [290] . Magnetic resonance images are presented in different shades of gray, reflecting differences in the intensity of magnetic resonance signals, or in the length of relaxation times T1 and T2. Pure T2 dephasing is intrinsic to the sample. While T2 ∗ dephasing is relevant with true T2, field inhomogeneity (T2M) and tissue suscep- tibility (T2MS) as shown in Eq. (82) . 1 T 2 ∗ = 1 T2 + 1 T2M + 1 T2 MS (82) brain injury. T2 ∗ is mostly used in scanning brain activity. An increase in T2 ∗ weighted signal between baseline and an active condition is as- sociated with brain activation in studies using blood oxygenation-level dependent (BOLD) fMRI. For instance, as displayed in Fig. 21 , brain re- gions become oxygen-rich after activity, which leads to a decrease of the Hbr/HbrO2 ratio and the increase of fMRI signal. Consequently, for T1, T2 and T2 ∗ , each method provides a physiologically and physically filtered view on one or more brain processes of interest [291] . Thus, combining different contrasts has the general merit of getting a more comprehensive physiological view on brain processes than uti- lizing just one imaging method alone. 7.2. Improving temporal/spatial resolution In Fig. 4 , the spatial and temporal ranges for the most widely used non-invasive functional imaging methods are presented. Functional MRI, as the non-invasive functional imaging method, has the highest spatial resolution though the temporal resolution is relatively low com- pared to neuronal population dynamics. MEG and EEG can measure magnetic and electrical changes on millisecond time scales while the spatial resolution is beyond seven millimeters [15] . Ultra high-field MRI has been widely used for the mesoscopic level of neuroscience in humans [292-294] . As a consequence, the Spatio-temporal resolution can be im- proved by combining different imaging methods, especially through the combination of one modality that has a higher temporal resolution with another modality of superior spatial resolution. The fused images are called validation when Spatio-temporal resolutions are similar. 7.2.1. Nominal resolution and effective resolution When considering improving spatio-temporal resolution, the resolu- tion of each modality is not of the biggest concern. Each modality’s ef- fective resolution and the additional effect after the combination of data from different modalities should be considered instead. While the nom- inal resolution is generated according to fixed physical parameters of instruments, the effective resolution depends on the information of the data instead. In fMRI, field-of-view and the k-space acquisition matrix determine the nominal spatial resolution, while the effective resolution is largely affected by fMRI sequences and spread of the hemodynamic response [295] . Because of the slow development of hemodynamic re- sponse, the effective resolution is lower than nominal temporal resolu- tion in fMRI, while the latter resolution is determined by the repetition timeTR. The nominal temporal resolution of electrophysiological methods is usually in the millisecond range. The effective resolution, however, can vary from tens of milliseconds to hundreds of milliseconds due to the slow evolution of neuronal field potentials and statistical detectability. Also, many repetitions have to be implemented before a detectable sig- nal comes up for the evoked potentials in EEG, while a detectable hemo- dynamic response can be acquired through a single stimulus in fMRI. 7.2.2. EEG-fMRI EEG-fMRI, as the combination of EEG and fMRI, turns out to be the typical example of improving spatio-temporal resolution through mul- timodal neuroimaging. Epilepsy research facilitated the development of simultaneous EEG-fMRI recording [296] . In the case of localizing epileptic foci, simultaneously recorded fMRI help by connecting epilep- tic foci with interictal epileptiform discharges (IED) acquired by EEG. Simultaneous EEG-fMRI can also be utilized as neuronal oscillations in neuroscience [209, 297] . In these studies, the process of analyzing the recorded fMRI data takes power in the frequency domain of the EEG signal as a variable. According to the common neuroimaging protocols, T1-weighted scans have good resolution and gray-white matter contrast, so it is better for observation of anatomical structure. T2-weighted scans perform well in showing histologic lesions, so it is often used for checking permanent 7.3. Distortion correction An MRI machine uses a static, homogenous, external magnetic field B0, a radio-frequency magnetic field B1, and three orthogonal gradient 172 Y.-D. Zhang, Z. Dong and S.-H. Wang et al. Information Fusion 64 (2020) 149–187 Fig. 21. Comparison of Hbr/HbrO2 ratio in brain capillaries before and after activity. fields. However, magnetic field variation may result from imperfections of the main magnetic field coil, the exciting gradient coils, and suscep- tibility of the tissues [298] . Field inhomogeneity is one of the causes of blurring or spatial shifts in MRI images. A typical region of distor- tion is the borderline between tissue and air, where a difference in mag- netic susceptibilities exists. A standard process in neuroimage processing and fusion is the registration of multimodal images to standardized tem- plates. Hellier and Barillot [299] introduced 3D non-rigid registration of multimodal images by mapping the deformation through cost optimiza- tion. The registration process provides the foundation for higher quality fusion with less distortion. The fusion of the main imaging sequence with supplementary se- quences is also widely employed for distortion correction. As mentioned previously, a well-studied example is EPI, a high temporal resolution MRI technique that can collect multiple images per second. The high imaging frequency of EPI acquisition results in geometric distortions to its images. Acquisition of the static Bo fieldmap before or after EPI can provide additional information on local static field inhomogeneity and magnetic susceptibility. Holland, Kuperman [300] developed an effi- cient non-linear registration method by acquiring EPI of opposite phase encoding polarities, while Oh, Chung [213] applied PSF modeling to map the distortion field. Another example is the fusion of MRI and PET images in MR-PET systems. In these systems, apart from the combination of structural and metabolic information, the fusion of MRI and PET also allows enhanced distortion correction. In simultaneous MP-PET systems, motion distor- tions of PET can be corrected with the volumetric information provided by continuous EPI acquisitions or navigator sequences [301, 302] . Joint reconstruction of MRI and PET utilizes dependence between the two modalities for image reconstruction of one mode based on the other. Re- constructed images show sharper edges and less distortion [303] . This entire process can also be formulated as a single optimization problem [301] . the brain to assist surgical techniques. This work was later updated by a full printed three-dimensional atlas of the human brain, which was especially beneficial for clinical studies, electroencephalographic inves- tigations, and statistical computations [307] . Tzourio-Mazoyer, Landeau [308] developed an anatomical parcellation approach with the spatially normalized single-subject high-resolution T1 volume provided by the Montreal Neurological Institute (MNI) [309] . These developments have contributed to better define the relationships between brain structures and their functions in modern human neuroscience research, as well as to reduce the variability found between different subjects. The traditional approach for brain image segmentation is the man- ual annotation or delimitation of the regions of interest (ROIs) by a trained expert [304] . This process is subjective and strongly influenced by expert performance. It is then of limited applicability since it is time- consuming, prone to error and difficult to reproduce. Automated segmentation methods have been developed during the past decades. These methods can be classified into basic tissue classifi- cation and anatomical segmentation procedures [310] . Tissue classifica- tion methods segment a 3D image of the brain into different tissue types (Grey Matter, White Matter, CSF, etc.), while also correcting for spatial intensity variations (also known as bias field or RF inhomogeneities). These methods normally incorporate probabilistic tissue atlases to im- prove their performance and have been successfully automated for fMRI studies as well as integrated into several neuroimaging toolkits such as FSL FMRIB’s Automated Segmentation Tool (FAST) [311] and Statistical Parametric Mapping (SPM) [312] . However, anatomical segmentation procedures are much more difficult to automate, since different anatom- ical structures that consist of different tissue types may exhibit similar signal properties. This observation is the reason why automated anatom- ical segmentation of the brain into non-homogeneous regions needs to be guided by atlases. 8.1. Single-subject atlas-based segmentation 8. Multimodal imaging data fusion: atlas-based segmentation Segmentation has been one of the main challenges faced by neu- roimaging experts during the last decades. It refers to the process of tagging image pixels or voxels with biologically meaningful labels, such as anatomical structures and tissue types [304] . The segmentation task and data analysis are very often guided in most of the neuroimaging ex- periments by atlases that provide standardized, or stereotaxic, 3D coor- dinate systems for statistical data analysis and report of findings [305] . One of the earliest works in anatomical brain standardization was by Talairach, Tournoux [306] , who developed a 3D coordinate space for For atlas-based segmentation, an atlas is defined as the combination of a brain volume (atlas template) and its corresponding coregistered segmented volume (atlas labels). The atlas-based segmentation method registers the atlas template to the target image, and then the atlas labels are propagated to the target image using an effective image warping method [313] . Let I ( x ) be the volume to be segmented, with 𝑥 ∈ ℝ 3 representing a 3D voxel coordinate vector. For the purpose of single-subject atlas-based segmentation, a grey level atlas volume A ( x ), a labeled volume 𝐿 ( 𝑥 ) ∈ Λ = [ 1 , 2 , ..., 𝐿 ] (83) 173 Y.-D. Zhang, Z. Dong and S.-H. Wang et al. Information Fusion 64 (2020) 149–187 Fig. 22. Block diagram of multi-atlas segmentation based on image registration, label propagation, and label fusion. where L is the number of anatomical regions or labels defined in the atlas and, optionally, a probabilistic atlas P (x), all within the same spatial coordinates (the atlas space), are required. The segmentation process consists of a registration step and a label propagation step. In the registration step, the atlas volume A ( x ) is registered to the input image I ( x ) by means of a spatial transformation T ( x ), which opti- mizes a given cost function. In the label propagation step, labels defined in the tagged volume L ( x ) are assigned to each of the voxels of the input image I ( x ) by applying the normalization transformation T ( x ) to L ( x ), thus spatially aligning the atlas to the input image I ( x ). The atlas proba- bility maps P ( x ) are normally used for MRI since they enable to improve the segmentation accuracy of T1-weighted MRI into grey matter, white matter and cerebrospinal fluid tissues with higher accuracy when the re- gional tissue densities need to be quantified and compared for between different groups of subjects [314] . Medical image registration is routinely used in neuroimaging. It aims at determining the spatial alignment between images of the same or dif- ferent subjects by means of optimizing a cost function, which measures the similarity between the transformed input image and the reference image (template) [315] . The registration process involves a spatial trans- formation being global rigid and affine transformations usually enough for intra-subject image registration [313] . However, the atlas-based seg- mentation task requires intersubject matching or registration of an input image to an atlas image and, as a consequence of the variability of the anatomical structure across different subjects, non-rigid registration al- gorithms are widely used. 8.2. Multi-atlas segmentation Single-subject atlas-based segmentation approaches suffer from a re- duced ability to capture the variability of the spatial distribution of anatomical structures across different subjects. Multi-atlas segmentation was introduced in some pioneering works [310, 316, 317] to address this problem and to offer superior segmentation accuracy. Fig. 22 shows a block diagram of a multi-atlas segmentation method. Instead of a model-based average atlas representation, a number of expert-annotated image volumes of different subjects are required. The input image is coregistered to each one of the different atlases available, and label propagation is performed. The final label is obtained for each voxel of the input image through a label fusion technique. In a multi- atlas segmentation approach, each atlas is used in the parcellation of the input image separately, since they are not summarized in a single probabilistic model. 174 8.2.1. Atlas propagation For the purposes of reviewing the existing methods for atlas propa- gation and atlas fusion in multi-atlas based segmentation, a similar no- tation to the adopted ones in [318, 319] will be used. These works have addressed the atlas-based segmentation problem as a classification task where the atlas is the training set, and the training is associated with the process of computing the registration between the image and the atlas. Let I ( x ) be a 3D image to be segmented into L different classes be- longing to the atlas label set Λ = [ 1 , 2 , ..., 𝐿 ] . Multi-atlas segmentation methods use K 3D atlas images A k ( x ) and their corresponding atlas la- bels 𝐿 𝑘 ( 𝑥 ) ∈ Λ, 𝑘 = 1 , 2 ...., 𝐾 The coordinate transformation T (84) k : R 3 → R 3 defines a mapping from the coordinates of the k atlas A k (x) to the target image I (x). Once the registration transformation is obtained, the input image I ( x ) is automatically segmented for each one of the K atlases available by applying a label propagation technique, thus obtaining K different segmentations 𝐼 𝑠 𝑘 ( x ) ∈ Λ, 𝑘 = 1 , 2 , ..., 𝐾 (85) These candidate segmentations must be combined later into a final estimated segmentation I s (x) ∈ Λ by applying a label fusion technique, as shown in Fig. 22 . Once each of the K atlas images has been coregistered to the input image, the labels are then propagated to the space of the input image in a process called label propagation. Label propagation applies the regis- tration transformations to map each of the available atlas volumes L k ( x ) to the input image, and an image warping technique preserves the dis- crete nature of the labels. Note that the transformations T k : applied to the atlas label volumes L k (x) are 3D continuous transformations that do not match grid points in the atlas space to grid points in the target input image. The purpose of label propagation is to perform the interpolation of the transformed atlas label volume for grid points in the target image space [320] . Among the different label propagation techniques, the most widely used are nearest-neighbor interpolation [310] and linear interpolation [316, 320] . Nearest-neighbor provides the unique label of the nearest at- las grid point. Partial volume interpolation, a technique that was first in- troduced in [321] for image registration, is a more sophisticated method for label propagation that takes into account the contribution of adjacent grip points to the final propagated label. During the last decade, several Y.-D. Zhang, Z. Dong and S.-H. Wang et al. Information Fusion 64 (2020) 149–187 improvements have been proposed and reviewed for label propagation in multi-atlas segmentation [304] . Most of them incorporate additional information to improve the performance by augmenting the informa- tion with a tissue consistency map in nearest-neighbor interpolation [322] or introducing signed distance maps of the original atlas labels [323, 324] . 8.2.2. Atlas fusion The final step in atlas-based segmentation is atlas fusion. After reg- istration and label propagation for each of the K available atlases, a final unique segmentation I s (x) ∈ Λ is obtained by merging the informa- tion provided by each of the individual atlas-based segmentations into a single segmented image. This approach has been shown to be more ac- curate than an individual atlas segmentation [316] in the same manner as a combination of classifiers is generally more accurate than a single classifier in many pattern recognition scenarios [325-330] . The conventional method for combining individual segmentations is an equally weighted majority voting framework [319] . A more so- phisticated approach estimates the performances of the individual atlas segmentations and combines them by weighting them according to their estimated performance. Both approaches are described and discussed in this subsection. Majority voting atlas fusion. The combined multi-atlas segmentation output I s (x) ∈ Λ for a voxel 𝑘 (x) ∈ Λ, with sample x given the set of K single atlas segmentations 𝐼 𝑠 𝑘 = 1 , 2 , ..., 𝐾, is obtained through the vote rule decision function 𝐼 𝑠 ( x ) = arg max 𝐾 ∑[𝑖, 𝐼 𝑠 𝑄 ]𝑘 ( x ) 𝑖 𝑘 =1 where the Q function is defined to be [𝑖, 𝐼 𝑠 𝑄 ]𝑘 ( x ) = { 1 , 𝑖 = 𝐼 𝑠 𝑘 ( x ) 0 , otherwise (86) (87) Atlas label fusion based on majority voting considers all the seg- mentations equally accurate, and no prior knowledge of segmentation performance is required. Performance weighting atlas fusion. Majority voting equally weighs the individual atlas segmentation without using a segmentation performance model. In order to improve the performance of the multi-atlas segmentation, the combined segmen- tation output I s (x) ∈ Λ should be the class maximizing the probability, given all the individual segmentations 𝐼 𝑠 𝑘 (x) ∈ Λ, with 𝑘 = 1 , 2 , ..., 𝐾and some available segmentation performance model P [319] : 1 ( x ) , 𝐼 𝑠 2 ( x ) , … , 𝐼 𝑠 ]𝐾 ( x ) , 𝐏 ( x ) = 𝑖 |𝐼 𝑠 ( x ) = argmax [𝐼 𝑠 𝑃 (88) 𝐼 𝑠 𝑖 Using the Bayes rule, and assuming independence of the individ- ual classifiers, simplifies the problem and enables us to find an optimal segmentation based on a model of segmentation performance. Rohlf- ing, Russakoff [319] proposed different classifier performance models and used an expectation-maximization (EM) algorithm that simultane- ously estimated the performance parameters of the segmentations and provided an estimation of the unknown ground truth. This novel strat- egy enabled us to learn classifier performance parameters and to adopt weighted atlas combination for atlas label fusion in multi-atlas segmen- tation following a novel supervised training stage [331, 332] . 9. Multimodal imaging data fusion: quantification The application and improvement of the quantification in medical image allows to increase characteristics such as sensitivity and speci- ficity, among others, obtaining more accurate patient’s diagnoses. To perform this analysis, the emission computed tomography (ECT) is used, since it is the most important medical imaging modality in nuclear medicine. More specifically, the two image modalities analyzed are 175 positron emission tomography (PET) and single-photon emission com- puted tomography (SPECT), which differ in the radiotracer used and the nature of the emission measurement. It should be noted that the factors associated with quantification that affect PET and SPECT are also ex- trapolated to multimodal images. Furthermore, multimodal images can be of great interest to improve quantification. Both, PET and SPECT, have proven to be effective imaging techniques for the diagnosis and monitoring of treatments in different medical applications, offering in- formation about biological processes, which is very important for the study of brain activity [333] . The level of intensity in these types of images is bound to physical parameters, such as cerebral blood flow, glucose or receptor binding among others [334, 335] . Since these modalities were conceived in the 50’s and 60’s Jones and Townsend [336] , several improvements have been developed in terms of quantification. One of the most relevant improvements in this field is due to the development of dual-modality imaging in the 90 ′ s [337] . This type of imaging allows the combination of complementing func- tional information (PET and SPECT) with structural information (com- puted tomography (CT) and magnetic resonance imaging (MRI)), lead- ing to increases in sensitivity and specificity. The combination of dif- ferent characteristics that can be observed from each type of image al- lows us to obtain a better understanding of the structure and function of the human body. For example, PET/MRI combination offers remarkable advantages compared to the use of PET/CT since CT radiation dose is avoided and soft tissue images from MR could be acquired at the same time as the PET ones [338] . PET offers higher resolution and better quality than SPECT, partic- ularly in PET/CT. Furthermore, it allows for easier quantitative mea- surements [335] . For example, sensitivity could be up to two orders of magnitude greater with comparable axial fields of view [339] . Never- theless, the spatial resolution that can be obtained in both techniques tends to be low, due to its dependence on the radiation dose adminis- trated to the patients. Also, ECT images are usually degraded by several factors, such as photon attenuation, partial volume effect or scatter ra- diation [337] . Moreover, spatial resolutions associated with structural images continue to be higher ( ≈ 1 mm) than in functional images ( ≈4–6 mm) [340] . Regarding quantification, an increasing number of relevant research aims to propose new quantification techniques or improve previously ex- isting ones is observed in recent years. The possibility of quantification in nuclear medicine imaging is one of its successes. Due to the increas- ing use of nuclear images in therapies, the way of measuring functional images is changing. While historically, the use of relative and semiquan- titative measures was typical, the recent application of absolute quan- tification is gaining support. One of the first steps was considered ac- tivity concentration and normalized uptake using the standard uptake value (SUV) [341] . Nevertheless, to reach quantitative imaging as a use- ful and potential tool, several factors must be addressed. As Zaidi and Hasegawa [339] mentioned among these factors are the system sensitiv- ity and spatial resolution, dead-time and pulse pile-up effects, the linear and angular sampling intervals of the projections, the size of the object, photon attenuation, scatter, partial volume effects, patient motion, ki- netic effects, and filling of excretory routes (e.g., the bladder) by the radiopharmaceutical. In neuroimaging, PET and SPECT are a popular option to detect biomarkers associated with degenerative diseases. For Alzheimer’s dis- ease (AD), the accumulation of Amyloid- 𝛽 plaques and tau aggregates can be detected [342, 343] , while an increased diffusivity in the stria- tum and thalamus can be observed in Parkinson’s disease (PD) patients. A well-defined quantification of these biomarkers would allow more pre- cise and reliable diagnoses. This section is organized as follows. Firstly, quantification both in PET and SPECT is analyzed considering the associated effects and their correction, especially those related to photon attenuation, scatter, and partial volume effects. Then, novel developments focused on cerebral medical imaging are highlighted. Y.-D. Zhang, Z. Dong and S.-H. Wang et al. 9.1. PET and SPECT quantification Even though PET scans could be evaluated qualitatively through the visual examination of the tracer uptake in cortical regions by a trained radiologist [344] , the best way to analyze these images is quantita- tive. For that, automated or semi-automated localization methods can be used to evaluate regional levels of tracer uptake [345, 346] . Within automated studies, an essential step is to use spatial normalization to register subjects’ brain to a standardized template space, so that all sub- jects in the study can be compared [347] . Another procedure of great importance is intensity normalization, which is the object of study in this analysis. As Foster, Bagci [348] mentioned, several semi-quantitative and quantitative parameters that can be considered for intensity normal- ization exist, such as standardized uptake value (SUV), fractional up- take rate (FUR), tumor-to-background ratio (TBR), nonlinear regression techniques, total lesion evaluation (TLE) or the Patlak-derived methods. Nevertheless, the most widely used is SUV, which can also be used in SPECT [348] . The use of body weight (BW) in SUV has been discussed in the literature, and the general advice is to use more reliable measures such as body surface area (BSA) or lean body mass (LBM) [349, 350] . Moreover, a decay factor that depends on the particular radiotracer used may also be considered [351] . Several physiological and physical factors can influence the stan- dardized uptake value obtained [348, 352] . Regarding physiological fac- tors, some of them are weight and fat of the subject or blood glucose concentration, etc. Physical factors include partial volume effect (PVE), image manipulation (reconstruction, smoothing), and artifacts related to involuntary movements of the patient. The relevance of these factors lies in the variability of SUV. Studies carried out in the literature suggest that these factors may alter SUV in the range of 10%–30% [353, 354] . Nevertheless, the importance of correcting these effects depends on the clinical trial performed, since it can be a complex task and is not always worthwhile [355] . Moreover, these factors affect not only semi-quantitative measure- ments but also affect absolute quantification. There are several methods to consider within the absolute quantification, such as image reconstruc- tion, effects correction or calibration to obtain the measured activity distribution [356, 357] . Among the mentioned factors associated with imaging quantifica- tion, we analyzed three effects and their respective corrections, since they are popular bias sources for PET and SPECT quantification. These effects are PVE, scatter, and photon attenuation effects. Information Fusion 64 (2020) 149–187 RB methods are associated with regions of interest (ROIs) while VB methods are applied at a voxel level considering the recovery of the spatial resolution of the system. Usually, RB techniques tend to be used more frequently than VB ones since they include regional homogeneity assumptions, simplifying the problem [359] . Table 5 shows a summary of the different existing techniques. Among the several PVC methods, the one associated with recovery coefficients (RC) is the simplest and most popular in clinical trials. Nevertheless, the most common technique used in neuroimaging is PVE correction based on anatomical images, which was developed for neuroimaging. The first technique proposed by Videen, Perlmutter [364] in 2D and later ex- tended to 3D by Meltzer, Leal [365] was a segmentation in anatomy into two classes: brain and non-brain. Mullergartner, Links [366] proposed an improved version of this technique (known as GM algorithm) to use three instead of two classes: grey matter (GM), white matter (WM) and cerebrospinal fluid (CSF). Meltzer, Zubieta [367] added a fourth class to the previous algorithms in order to compensate for the real hetero- geneity in GM tissue. The importance of this method is that PVE can be corrected between high and low intensity brain structures. Regarding the iterative reconstruction algorithms associated to VB methods, as V. Bettinardi, Castiglioni [340] noted, some of the best known and used is the Van Cittert (VC) algorithm, the re-blurred Van Cittert (R-VC) and the Richardson–Lucy (RL) algorithm. For broader coverage, readers are referred to reviews related to PVE [340] and iterative reconstruction methods [368] . Finally, data extracted from the Alzheimer’s Disease Neuroimaging Initiative (ADNI) database (adni.loni.usc.edu) is used in order to show some PVE correction methods. This data consists of a patient diagnosed with Alzheimer’s disease from which FDG-PET and T1 weighted MR im- ages were taken, as shown in Fig. 23 . Both modalities are registered to respective templates of T1 and PET, and PET image was not normalized in intensity due to use only one subject in this manuscript. PVC tech- niques are applied by using PVElab [384, 385] , a platform developed by the EU sponsored PVEOut project. PVElab can facilitate PVE correction through a graphical interface with several steps, including registration, segmentation, reslicing, optional application of an atlas (none in our case), and PVE correction. Three methods discussed above are those an- alyzed: 3D Meltzer technique [365] and GM algorithm [366] regarding VB methods, and the RB method proposed by Rousset, Ma [374] . The large difference between methods is shown in Fig. 24 a. The dif- ference in the result between considering two ( Fig. 24 a) and three tissues ( Fig. 24 b) is highlighted. The method related to GTM ( Fig. 24 c) reflects intermediate results between the two images already commented. 9.1.1. Partial volume effect 9.1.2. Attenuation effect Regarding the quantitative accuracy of PET image, partial volume effect (PVE) is the most relevant effect [358] . PVE is related to the finite spatial resolution of PET scanners and its discrete nature. That discrete nature causes a voxel to could be composed of more than one tissue, which leads to a final signal that is an averaged mix of signals, which is also called tissue fraction effect. Moreover, the larger the voxel size, the more tissues can coexist in it. This effect, along with the point-spread effect (or spillover), is the cause of image blur [354, 359] . Also, it is an effect that often causes confusion among clinicians and researchers when analyzing the image, since it is necessary to distinguish between loss of radioactivity due to PVE and the true loss of tissue. Strategies to address this effect are called partial volume correction (PVC) methods. Distribution of both signal and noise are the main fac- tors to consider for the selection of algorithms for PVC to apply [359] . Several PVC techniques have been proposed in the literature for im- proving image quality and quantitative accuracy in PET [360-363] . Historically, these techniques have been classified in several forms. In this work, these methods are grouped as region-based (RB) and voxel- based (VB) techniques, based the most commonly used classifications [340, 355] . The most relevant differences between them are that VB methods produce PVE-recovered images while RB methods do not, and Another relevant effect to analyze is photon attenuation. This phe- nomenon occurs due to the interaction between the photon associated to the radiotracer and elements in the body such as tissue. Normally, this interaction leads to a scatter in the photon radiation. The prob- ability that a photon experiences an interaction is represented by the linear attenuation coefficient [386] . The situation of this phenomenon differs between PET and SPECT imaging. In PET, two antiparallel pho- tons are detected in the collimator, so the total tissue thickness crossed by them is the same body thickness that intersected the straight line between the two detections (line of response). Nevertheless, in SPECT imaging, the attenuation depends on the total tissue thickness crossed and its type (e.g., soft tissue, bone), which varies depending on where the points of emission and detection are [386] . Traditionally, this cor- rection was much more commonly performed in PET imaging than in SPECT. Nowadays, it is done in both to be able to achieve much more accurate quantitative results, although it is more difficult to apply in SPECT. Attenuation correction is necessary in order to obtain accurate quan- titative results and is widely implemented. For this, an attenuation map is needed, which Zaidi and Hasegawa [386] defined as a representation of the spatial distribution of linear attenuation coefficients and delin- 176 Y.-D. Zhang, Z. Dong and S.-H. Wang et al. Information Fusion 64 (2020) 149–187 Table 5 Classification of PVC methods (RB = region-based; VB = voxel-based). Category Method Definition Benefits RB Recovery coefficients (RC) PET raw data Geometric transfer matrix (GTM) method VB Image reconstruction Image deconvolution Multi-resolution approach Anatomical images They are numerical calculated in the image domain as a ratio of measured radioactivity concentration and actual concentration using spheres filled with a known radioactivity concentration Instead of using the image domain, the sinogram is used Average uptake is estimated considering multiple ROIs using co-registered anatomical images Spatial resolution is recovered within the image reconstruction process. It is highly recommended to use iterative reconstruction algorithms. The most relevant drawback of this is the high number of iterations needed Spatial resolution is recovered by using a post-reconstruction restoration technique (deconvolution) that applies the point spread function (PSF). Iterative algorithms are commonly used Spatial resolution is recovered by using information from spatially coregistered high-resolution anatomical images, which allows transfer high spatial frequencies from anatomical to functional images First, a segmentation of a coregistered anatomical image is done. Then, PVE correction is applied to the set of voxels associated with each region/class (tissue) Fairly simple Practical Popular within clinical trials Limitations More related to oncology Examples [369, 370] Low computational cost Commonly used Good accuracy Some methods require segmentation Requires segmentation Bias [371-373] [374-377] Increase the quality of reconstruction Computational cost [378-381] Compensation of spill-over effects Computational cost [382] Adjust of radioactivity concentration Used in brain imaging In poorly correlated areas the amount of artifacts increases [383] Highly used in brain imaging Need segmentation Two classes: [364, 365] Three classes: [366] Four classes: [367] Fig. 23. Original PET (left) and MR (right) im- ages. Fig. 24. Evolution of PVC techniques. 177 Y.-D. Zhang, Z. Dong and S.-H. Wang et al. Information Fusion 64 (2020) 149–187 Table 6 Classification of attenuation correction methods. Category Method Definition Benefit Limitations Transmission-less based Uniform fit-ellipse method (UFEM) Automated contour detection method (ACDM) Other methods Transmission-based Radionuclide transmission CT transmission MRI transmission Quick and easy Functional for brain studies Low precision Limited to homogeneous areas It is independent of the specialist Functional for brain studies No anatomical information is needed Available in most systems. Existence of complementary methods to reduce noise Quick Low noise Good spatial resolution Functional for brain studies High precision Popular for brain studies Low precision but higher than UFEM Only for homogeneous areas Possibility of cross-talk between emission data and attenuation map Virtually not used in clinical trials Need to modify the obtained attenuation coefficients due to be energy-dependent Possibility of errors due to cross-talk of data Misregistration due to respiratory movements Erroneus uptake due to patient’s possession of unnatural materials (e.g. prostheses) CT photonic energy usually differs from that of the radionuclide used for emission scanning Total dependence on co-registration success in the patient’s image Object outline is approximated as an ellipse around its edges. In order to generate the attenuation map, uniform attenuation is assigned Then, uniform attenuation is assigned inside the figure. Edge-detection algorithms are used to generate the shape of the object. This allows convex shapes Several techniques fit here, such as algebraic reconstruction–based techniques (MLAA or MLACF) or machine-learning techniques Apply an external source (PET, SPECT or SPECT/PET) interleaving transmission and emission scanning It can be addressed by segmenting the CT regions and assigning linear attenuation coefficients to each tissue or transforming the CT image to the attenuation map associated with the radiotracer photon’s energy (or a combination of both methods using different scale factors for bone and tissues) Segmentation-based techniques, where first the PET and MRI images are co-registered and then a segmentation technique is applied. Usually fuzzy is used to divide the image from two to five tissues, assigning to each tissue some attenuation coefficients Atlas-based techniques, where an MR template is used instead of multistep segmentation procedures Examples [389] [390, 391] [392-396] [397-400] [401-405] [370, 405–409] eates the body structures located in the image. Once the attenuation map is done, the reconstruction algorithm can be implemented with more information. Attenuation correction techniques can be classified into two major groups: transmission-less approaches and the ones based on transmission scanning. While the first group considers the measured emission data to develop the attenuation map or assumes a uniform dis- tribution for the coefficients, the second one uses transmission data of external sources such as CT and MRI, i.e., the use of anatomical data. The second group offers a more accurate solution. Nevertheless, there are situations in which the correction made by the first group is suf- ficient, without the need to complicate the applied technique. A brief introduction to the various existing methods for performing the attenu- ation map is shown in Table 6 . For a more extensive reading of this topic, readers are referred to reviews about attenuation correction [386-388] . Transmission-less based methods are easily applied in brain imag- ing because the brain is considered a practically homogeneous region composed mainly of soft-tissue. Moreover, these methods allow results regarding the skull [390] and optical tracking systems to be used to ob- tain head contours [391] . Despite being a typology that has not been used frequently, research on these methods has increased over the last years due to shift away from anatomical information. One of the first methods was proposed by Nuyts, Dupont [392] , which consists of a maximum likelihood approach known as MLAA (maximum likelihood reconstruction of attenuation and activity). It is commonly used in non- time-of-flight (TOF) PET images, and several studies have tried to im- prove or test it [393, 395, 396] . Another popular algorithm is MLACF (maximum likelihood attenuation correction factors) [394] , mostly used in TOF PET, which jointly estimates the attenuation sinogram and the activity image. Less popular than the previous one, this method has also been tested in other studies [410] . Moreover, machine learning tech- niques for attenuation correction are emerging, such as deep convolu- tional encoder-decoders [334] or deep convolutional neural networks [411] have also been applied in attenuation correction. For this last type of technique, there is considerable interest in this field of research, and new algorithms are constantly presented. Regarding transmission-based techniques, the added difficulty for MRI systems to obtain attenuation maps compared to CT systems should be highlighted. The reason for this is the connection between the atten- uation coefficients and the electron density of the tissue. In CT, the data is associated with electron density and photon attenuation properties of the tissues. In contrast, MRI data is correlated to proton density and mag- netic relaxation properties of the tissues [387] . As a challenge related to PET/MRI (or SPECT/MRI) systems, several methods have been proposed in literature regarding attenuation estimation. The MRI-based methods can be classified into two groups: segmentation-based and atlas-based methods. Of the two groups, the segmentation-based one tends to be used more on the literature. One of the first methods published in this area was that of Le Goff-Rougetet, Frouin [412] . This method aims to reduce the pa- tient dose associated with PET imaging without affecting the accurate quantification. This technique is based on a surface matching technique for coregistration of PET and MR images. Another relevant proposal was 178 Y.-D. Zhang, Z. Dong and S.-H. Wang et al. Information Fusion 64 (2020) 149–187 based on registered T1-weighted MRI. Zaidi, Montandon [407] used a supervised fuzzy C-means clustering segmentation technique, which de- pends on the density and composition of five tissues: air, skull, brain tissue, and nasal sinuses. Similar to the latter case, Wagenknecht, Kops [408] presented a method where tissue classification is done with neural networks. First, a voxel classification with five tissues (GM, WM, CFS, adipose tissue (AT) and background (BG)) is made, then a second classi- fication is done depending on the previous classes to detect extracerebral tissue and finally, segmentation is obtained. The main drawback of this method is the possibility of mis-segmentation or over-segmentation of bones, especially in the presence of abnormal anatomy or pathology. In order to improve bone detection, ultrashort echo time (UTE) MRI began to be investigated. Firstly, dual-echo ultra-short echo time and three tissue classification (bone, soft tissue and air) were used [370, 413] . In parallel, methods related to the Dixon technique were raised. Dixon-Water–Fat-segmentation (DWFS) allows the separation of soft and adipose tissues. The method was applied DWFS for the whole body in [414] . Considering both techniques (UTE and DWFS), Berker, Franke [415] proposed a method trying to reduce the drawbacks of these two techniques: time-consuming and complex image registration. This new technique applies UTE sampling for bone detection and uses gra- dient echoes for water-fat separation, obtaining a four-class PET atten- uation map. An example of DWFS application in neuroimaging is the study conducted by Andersen, Ladefoged [416] , where this technique is used to generate the attenuation maps. Taking into account the time- consuming problem with UTE, short echo-time (STE) has been tested as a method to obtain attenuation maps of three (cortical bone, air and soft tissue) [417] and four (cortical bone, air, soft tissue and fat tissue) tissues [418] , both in combination with fuzzy C-means (FCM) clustering method. Besides, the second study also used two-point Dixon sequences in image acquisition. The latest research in this field has been the use of zero echo time (ZTE), initially proposed by Wiesinger, Sacolick [419] as part of a segmentation method for cranial bone structures. All studies found in the literature, specially the ones related to ZTE, indicate an im- provement in results compared to the use of atlas-based methods [420- 423] . The basis of atlas-based approaches is the use of an MR template instead of multistep segmentation procedures, so atlas-based methods use a general map while segmentation-based methods generate a map for each individual. This template can be obtained from two sources: an image labeled as if it were a segmentation of the different tissues or a coregistered attenuation map from a PET or CT scan with contin- uous attenuation values [354] . As usual, it is obtained from an average of co-registered normal patients, and it has to be warped to the target patient image volume. In any case, most of the studies related to this approach combine atlas-based and segmentation-based methods since the use of an atlas can be an important source of information and can reduce computational cost [424–426] . Despite this, other studies have proposed methods purely based on atlas images [405, 409] , such as the one developed by Johanson, Garpebring [427] where linear attenuation coefficients are predicted from a Gaussian mixture regression algorithm. Once the attenuation map is generated, attenuation correction is ap- plied in the process. For that, two techniques are mainly used [386] . The first one multiplies the attenuation coefficients obtained by PET image data in the sinogram (or projection) space [428] . The other procedure is performed when PET image reconstruction is performed with an iter- ative algorithm, using attenuation coefficients as data weighting. While PET images can apply both methods, only iterative methods are used for SPECT [429-431] . 9.1.3. Scatter effect Scatter in PET and SPECT is another relevant effect for absolute quantification, especially in SPECT, and which is usually associated with Compton scattering. It consists of an energy loss and a change of direc- tion of a photon after an interaction with surrounding atoms. Never- theless, this effect is not highly relevant in the clinical environment, according to the literature. The reason for this is that the techniques implemented have little impact on the final result, and since the photon change of direction is practically zero, the energy loss is minimal. How- ever, several researchers are convinced that in order to obtain a high accuracy quantitative image, this artifact should be removed [432, 433] . Several methods have been proposed for scatter correction, but most of them were developed many years ago and are inefficient. However, a few recent methods are getting remarkable results. Regarding the cate- gorization of these techniques, a similar classification could be made for both PET and SPECT, considering that PET techniques began to be devel- oped much earlier. Following the review of Zaidi and Montandon [432] , the classification would consist of five groups: hardware approaches us- ing coarse septa or beam stoppers, multiple-energy-window approaches, convolution/deconvolution-based approaches, approaches based on di- rect estimation of scatter distribution and approaches based on statis- tical reconstruction. Due to the low clinical implementation and the diversity of existing methods, this work will only highlight the most innovative and relevant methods. Therefore, readers interested in this effect are advised to read the following reviews [389, 433, 434] . Table 7 summarizes the different existing categories indicating some examples. The first method proposed to narrow the photopeak energy window to avoid the acceptance of scattered photons. However, this technique has significant drawbacks, such as the elimination of unscattered pho- tons in the process, and therefore, a loss of intensity appears in the image [434, 435] . Thus, multiple-energy-window became much more popular, and it is one of the simplest and most used approaches. The techniques have been developed from two [436, 437] three [438, 439] or even multiple energy windows [440, 441] . Decades have passed since it is known that Monte Carlo techniques are ideal for scatter correc- tion [433-435] . Nevertheless, it has recently become a viable solution in the clinical environment, as the computational cost is reducing and techniques are faster. Moreover, the Monte Carlo technique can be ap- plied to several methods, either iterative reconstruction based or direct calculation methods. Finally, another factor to consider in the quantification of functional images is the voluntary and involuntary movement of the patient (e.g. breathing). However, since it does not have high relevance in neu- roimaging, its analysis has been dismissed in this study. 9.2. PET and SPECT in neurology Functional imaging is very useful for the diagnosis of neurodegen- erative diseases, such as Alzheimer’s disease or Parkinson’s disease due to differences in brain activity which can be observed in temporal and parietal lobes (AD) or the striatum (PD) with respect to healthy subjects. Therefore, the systems must allow a correct quantification in order to offer an accurate diagnosis of the patient’s condition. As already mentioned, the correction of the aforementioned effects improves the quantification of the images. For example, some studies associated with attenuation correction demonstrate this improvement. Delso, Kemp [421] achieved a bias reduction of − 0 . 5% using a CT-based correction instead of a regular ZTE attenuation correction in a PET/MR image. Also associated with PET/MR images, Berker, Franke [415] com- pared 4-class tissue segmentation and 3-class tissue segmentation, con- cluding that better results are obtained with a 4-class tissue segmenta- tion, and these results are also very similar to those that would be ob- tained with a PET/CT system. In the study developed by Sousa, Appel [422] , a comparison between using an attenuation correction method based on ZTE and atlas-based correction shows that the former produces less variability than the latter. However, bias correction is similar in an- alyzed brain regions. For example, the correlation coefficient associated with anterior cortical regions is 0.99 for ZTE-based correction and 0.92 for atlas-based correction. Similar results are obtained in the study by Sgard, Khalife [423] . Other interesting results are produced by those that apply machine learning methods. For example, the deep convolu- tional neural network used by Yang, Park [411] for both attenuation 179 Y.-D. Zhang, Z. Dong and S.-H. Wang et al. Information Fusion 64 (2020) 149–187 Table 7 Classification of scatter correction methods. Category Hardware-based techniques Multiple-energy window techniques Convolution and deconvolution-based techniques Direct calculation techniques Iterative reconstruction-based scatter-correction techniques Methods Description If coarse septa or beam stoppers are used. lines of response intercepted by the septa can be used to determine the scatter component The energy spectrum is estimated by using windows below and above the photopeak window In this case, the standard energy acquisition window is used. Data collected in it helps to estimate the distribution of scatter Extract information from emission data, or a combination of emission and transmission data for estimating scatter distribution. Monte Carlo technique and ToF information can achieve great progress Scatter distribution is obtained and used during image reconstruction Benefit No noise increase Limitations Unused Examples [442, 443] Highly used Simple Noise [444, 445] Good image contrast Good accuracy Not commonly used [446-448] The most popular High accuracy Computational cost [449-452] Parallel processing High contrast Low noise Computational cost [368, 453–455] and scatter correction designed for situations where it is difficult to use a combined CT or transmission source. The results were similar to the ones obtain with an CT-based scatter and attenuation correction. PVC methods are also used in brain images. For example, regarding PD studies, Du, Tsui [376] proved than using a modified GTM method in brain SPECT images, the underestimation of striatal activities could be reduced to 1 . 2% from an initial value of 30%. Finally, a correct normalization of the images can also highly in- crease the accuracy of the study. Salas-Gonzalez, Gorriz [456] proposed a method for intensity normalization of FP-CIT SPECT brain image based on 𝛼-stable distribution. This method was tested by Castillo-Barnes, Are- nas [457] , showing significant differences between the images before and after normalizing. For more information on intensity normalization, especially associated with PD, we recommend reading [458] . In conclusion, the possibility of improving the techniques exposed in this manuscript to reduce unwanted effects on images is highlighted. Despite being applied in clinical systems, they are not considered of high relevance due to the limited improvement they provide or, sometimes, the increase in noise they produce. Therefore, the area of absolute quan- tification must continue to be investigated for more accurate and faster solutions. 10. Conclusion This review presents an overview of multimodal data fusion in the field of neuroimaging, including current developments and challenges. We first outlined the fundamental limitations of individual modali- ties, which can include distortion, non-quantitative nature, and lim- ited temporal/spatial resolutions. These limitations are the general mo- tivators for the development of multimodal neuroimaging and fusion. Multimodal neuroimaging provides more comprehensive information on pathology. We have summarised the individual benefits and limitations of the current imaging technologies and modalities, including CT, PET, SPECT, MRI, fMRI, DWI, PWI, and MRF. Building upon the available individ- ual techniques, we summarised current development and application of multimodal neuroimaging and fusion in terms of neurological disorders and brain diseases, with a focus in three areas: developing brains, de- generative brains, and psychiatric disorders. The utilization of multiple modalities helps in clinical diagnosis, prevention of misdiagnosis, pro- gression analysis, and research-oriented studies that allow us to gain a more in-depth understanding of human brain pathologies. Nowadays the effects of COVID in the human body are not well-known and maybe we could find in the future some people affected in the brain structure (mi- cro ictus or ischemia). Nevertheless, the fusion techniques and strategies discussed in this survey may be transferred to COVID-19 multimodality image analysis [459] . AI can contribute to the information fusion [460] . The forms of multimodality fusion include multi-modal, multi-focus, multi-temporal, and multi-view. These forms combine images from dif- ferent instruments/acquisitions, acquisition focal lengths, time of ac- quisitions and conditions, respectively. Fusion rules were specified with respect to its components and three levels of fusion and theoretical foun- dation, i.e. rules derived from fuzzy logic, statistic models, and the hu- man vision system. Then we summarised conventional and novel im- age decomposition and reconstruction methods for the fusion process, including methods based on RGB-IHS, pyramid representations, multi- resolution analysis, sparse representation, and salient features. In addi- tion, we summarised both subjective and objective methods for fusion quality assessment. The major benefits of multimodal data fusion in neuroimaging in- clude distortion correction, higher temporal/spatial resolution, the com- bination of structural and functional information. We summarised these benefits with the current applications of multimodal fusion, e.g. MR- PET, EEG-fMRI, and EPI correction. This review also adds a particular focus on the application of multimodal image fusion in standardization, via atlas-based anatomical brain segmentation and the use of multi-atlas fusion. In addition, we summarised the effect of multimodal data fusion on the shift of neuroimaging diagnosis from qualitative analysis to quan- titative evaluation, with an example of the effect of multimodal data in photon attenuation, scatter, and partial volume effects of PET and SPECT quantification. Modern neuroimaging has seen significant improvements in acquisi- tion quality and a constant increase in the abundance of imaging modal- ities. The fusion of modalities combines complementary information, expands resolution limits, provides standardization, and improves data quality. It is expected that the effect of multimodal imaging fusion could also effectively scale the amount and quality of information accessible to radiologists for more both precise diagnosis and higher quality research in multiple aspects. Declaration of Competing Interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. 180 Y.-D. Zhang, Z. Dong and S.-H. Wang et al. Information Fusion 64 (2020) 149–187 The authors declare the following financial interests/personal rela- tionships which may be considered as potential competing interests. CRediT authorship contribution statement Yu-Dong Zhang: Conceptualization, Project administration, Re- sources, Supervision, Validation, Writing - original draft, Writing - re- view & editing. Zhengchao Dong: Validation, Writing - original draft, Writing - review & editing. Shui-Hua Wang: Methodology, Validation, Writing - original draft, Writing - review & editing. Xiang Yu: Valida- tion, Writing - original draft, Writing - review & editing. Xujing Yao: Validation, Writing - original draft, Writing - review & editing. Qinghua Zhou: Validation, Writing - original draft, Writing - review & editing. Hua Hu: Validation, Writing - original draft, Writing - review & editing. Min Li: Validation, Writing - original draft, Writing - review & editing. Carmen Jiménez-Mesa: Validation, Writing - original draft, Writing - review & editing. Javier Ramirez: Validation, Writing - original draft, Writing - review & editing. Francisco J. Martinez: Validation, Writing - original draft, Writing - review & editing. Juan Manuel Gorriz: Con- ceptualization, Methodology, Project administration, Resources, Super- vision, Validation, Writing - original draft, Writing - review & editing. Acknowledgments This study was partly supported by Royal Society International Ex- changes Cost Share Award, UK ( RP202G0230 ); Medical Research Coun- cil Confidence in Concept Award, UK ( MC_PC_17171 ); Hope Founda- tion for Cancer Research, UK ( RM60G0680 ); British Heart Founda- tion Accelerator Award, UK; the MINECO / FEDER under the RTI2018- 098913-B100 and A-TIC-080-UGR18 projects; FPU predoctoral grant ( FPU 18/04902 ) from Ministerio de Universidades, Spain; Fundamental Research Funds for the Central Universities ( CDLS-2020-03 ); Key Lab- oratory of Child Development and Learning Science (Southeast Univer- sity), Ministry of Education ; Guangxi Key Laboratory of Trusted Soft- ware ( kx201901 ). References [1] S.A. Trip , et al. , Imaging in multiple sclerosis, J. Neurol. Neurosurg. Psychiatry 76 (Suppl 3) (2005) iii11–iii18 . [2] R.W. Levenson , et al. , Emotional and behavioral symptoms in neurodegenerative disease: a model for studying the neural bases of psychopathology, Annu. Rev. Clin. Psychol. 10 (2014) 581–606 . [3] L. Bertram , et al. , The genetic epidemiology of neurodegenerative disease, J. Clin. Invest. 115 (6) (2005) 1449–1457 . [4] C. Liu , et al. , MR image features predicting hemorrhagic transformation in acute cerebral infarction: a multimodal study, Neuroradiology 57 (11) (2015) 1145–1152 . [5] B.J. Macintosh , et al. , Magnetic resonance imaging to visualize stroke and charac- terize stroke recovery: a review, Front. Neurol. 4 (2013) 60 . [6] E. Ercan , et al. , A multimodal MRI approach to identify and characterize mi- crostructural brain changes in neuropsychiatric systemic lupus erythematosus, Neuroimage Clin. 8 (2015) 337–344 . [7] S.J. Astley , et al. , Functional magnetic resonance imaging outcomes from a compre- hensive magnetic resonance study of children with fetal alcohol spectrum disorders, J. Neurodev. Disord. 1 (1) (2009) 61–80 . [8] V.D. Calhoun , et al. , Multimodal fusion of brain imaging data: a key to finding the missing link(s) in complex mental illness, Biol. Psychiatry Cognit. Neurosci, Neuroimaging 1 (3) (2016) 230–244 . [9] E.E. Tulay , et al. , Multimodal neuroimaging: basic concepts and classification of neuropsychiatric diseases, Clin. EEG Neurosci. 50 (1) (2019) 20–33 . [10] K. Uluda ğ, et al. , General overview on the merits of multimodal neuroimaging data fusion, Neuroimage 102 (2014) 3–10 . [11] T. Tang , et al. , PET/SPECT/MRI multimodal nanoparticles, in: Design and Appli- cations of Nanoparticles in Biomedical Imaging, Springer, 2017, pp. 205–228 . [12] Z. Hu , et al. , From PET/CT to PET/MRI: advances in instrumentation and clinical applications, Mol. Pharm. 11 (11) (2014) 3798–3809 . [13] G.D. Luker , et al. , Optical imaging: current applications and future directions, J. Nucl. Med. 49 (1) (2008) 1–4 . [14] N. Weiskopf , et al. , Principles of a brain-computer interface (BCI) based on real–time functional magnetic resonance imaging (fMRI), IEEE Trans. Biomed. Eng. 51 (6) (2004) 966–970 . [15] R. Hari , et al. , Magnetoencephalography: from SQUIDs to neuroscience: neuroim- age 20th anniversary special edition, Neuroimage 61 (2) (2012) 386–396 . [16] C.M. Michel , et al. , Towards the utilization of EEG as a brain imaging tool, Neu- roimage 61 (2) (2012) 371–385 . [17] B.M. Ances , et al. , Regional differences in the coupling of cerebral blood flow and oxygen metabolism changes in response to activation: implications for BOLD-fMRI, Neuroimage 39 (4) (2008) 1510–1521 . [18] N.P. Blockley , et al. , A review of calibrated blood oxygenation level ‐dependent (BOLD) methods for the measurement of task ‐induced changes in brain oxygen metabolism, NMR Biomed. 26 (8) (2013) 987–1003 . [19] P.A. Chiarelli , et al. , A calibration method for quantitative BOLD fMRI based on hyperoxia, Neuroimage 37 (3) (2007) 808–820 . [20] Hoge, R.D., Calibrated fMRI. NeuroImage, 2012. 62(2): p. 930–937. [21] A. Borogovac , et al. , Arterial spin labeling (ASL) fMRI: advantages, theoretical constrains and experimental challenges in neurosciences, Int. J. Biomed. Imaging (2012) 2012 . [22] H. Zeng , et al. , Image distortion correction in EPI: comparison of field map- ping with point spread function mapping, Mag. Reson. Med. 48 (1) (2002) 137–146 . [23] E. Musalar , et al. , Conventional vs invert-grayscale X-ray for diagnosis of pneu- mothorax in the emergency setting, Am. J. Emerg. Med. 35 (9) (2017) 1217–1221 . [24] S. Liu , et al. , Application of high-resolution CT images information in complicated infection of lung tumors, J. Infect. Public Health (2019) . [25] S. Zhao , et al. , Application of CT combined with electrocardiographic gating in hypertensive patients with brain and nerve diseases, World Neurosurg. (2020) . [26] K. Stepniak , et al. , Novel 3D printing technology for CT phantom coronary arteries with high geometrical accuracy for biomedical imaging applications, Bioprinting (2020) e00074 . [27] S.-H. Wang , in: Pathological Brain Detection, Springer, Germany, 2018, p. 222 . [28] J. Warman Chardon , et al. , MYO-MRI diagnostic protocols in genetic myopathies, Neuromuscul. Disord. 29 (11) (2019) 827–841 . [29] H. Zhang , et al. , Comparison of the clinical application value of mo-targeted X-ray, color doppler ultrasound and MRI in preoperative comprehensive evaluation of breast cancer, Saudi J. Biol. Sci. 26 (8) (2019) 1973–1977 . [30] X. Wang , et al. , Magnetic Fe3O4@PVP nanotubes with high heating efficiency for MRI-guided magnetic hyperthermia applications, Mater. Lett. 262 (2020) 127187 . [31] E. Kazemivalipour , et al. , Reconfigurable MRI technology for low-SAR imaging of deep brain stimulation at 3T: application in bilateral leads, fully-implanted systems, and surgically modified lead trajectories, Neuroimage 199 (2019) 18–29 . [32] H. Van As , et al. , MRI of plants and foods, J. Magn. Reson. 229 (2013) 25–34 . [33] Wang, S.-H., et al., Unilateral sensorineural hearing loss identification based on double-density dual-tree complex wavelet transform and multinomial logistic re- gression. 2019. 26(4): p. 411–426. [34] D.H. Lee , et al. , Mechanisms of contrast enhancement in magnetic resonance imag- ing, Can. Assoc. Radiol. J. 42 (1) (1991) 6–12 . [35] X. Wang , et al. , Magnetic properties and magnetization reversal process in (Pt/CoFe/MgO)10 multilayers at low temperature, J. Magn. Magn. Mater. 499 (2019) 166318 . [36] N. Parsons , et al. , Single-subject manual independent component analysis and rest- ing state fMRI connectivity outcomes in patients with juvenile absence epilepsy, Magn. Reson. Imaging 66 (2020) 42–49 . [37] F. Angenstein , The role of ongoing neuronal activity for baseline and stimulus-in- duced BOLD signals in the rat hippocampus, Neuroimage 202 (2019) 116082 . [38] M. Magdziarz , Lamperti transformation of scaled Brownian motion and related Langevin equations, Commun. Nonlinear Sci. Numer. Simul. 83 (2020) 105077 . [39] D. Xie , et al. , Denoising arterial spin labeling perfusion MRI with deep machine learning, Magn. Reson. Imaging (2020) . [40] D. Ma , et al. , Magnetic resonance fingerprinting, Nature 495 (7440) (2013) 187–192 . [41] M.H. Johnson , Functional brain development in humans, Nat. Rev. Neurosci. 2 (7) (2001) 475–483 . [42] N. Gogtay , et al. , Dynamic mapping of human cortical development during child- hood through early adulthood, Proc. Natl. Acad. Sci. U. S. A. 101 (21) (2004) 8174–8179 . [43] D.J. Siegel , The Developing Mind: How Relationships and the Brain Interact to Shape Who We Are, third ed., Guilford Press, New York, 2020 . [44] T.G. O’Connor , et al. , Maternal antenatal anxiety and behavioural/emotional prob- lems in children: a test of a programming hypothesis, J. Child Psychol. Psychiatry 44 (7) (2003) 1025–1036 . [45] A. Nyaradi , et al. , Diet in the early years of life influences cognitive outcomes at 10 years: a prospective cohort study, Acta Paediatr. 102 (12) (2013) 1165–1173 . [46] J. O’Muircheartaigh , et al. , White matter development and early cognition in babies and toddlers, Hum. Brain Mapp. 35 (9) (2014) 4475–4487 . [47] D.C. Dean 3rd , et al. , Modeling healthy male white matter and myelin development: 3 through 60months of age, Neuroimage 84 (2014) 742–752 . [48] S. Kulikova , et al. , Multi-parametric evaluation of the white matter maturation, Brain Struct. Funct. 220 (6) (2015) 3657–3672 . [49] D. Levine , et al. , Central nervous system abnormalities assessed with prenatal mag- netic resonance imaging, Obstet. Gynecol. 94 (6) (1999) 1011–1019 . [50] A.J. Barkovich , Techniques and methods in pediatric magnetic resonance imaging, Semin. Ultrasound CT MR 9 (3) (1988) 186–191 . [51] B.A. Holland , et al. , MRI of normal brain maturation, AJNR Am. J. Neuroradiol. 7 (2) (1986) 201–208 . [52] A.L. Reiss , et al. , Brain development, gender and IQ in children. A volumetric imag- ing study, Brain 119 (Pt 5) (1996) 1763–1774 . [53] T.L. Jernigan , et al. , Late childhood changes in brain morphology observable with MRI, Dev. Med. Child Neurol. 32 (5) (1990) 379–385 . 181 Y.-D. Zhang, Z. Dong and S.-H. Wang et al. Information Fusion 64 (2020) 149–187 [54] T.V. Phan , et al. , Processing of structural neuroimaging data in young children: bridging the gap between current practice and state-of-the-art methods, Dev. Cog- nit. Neurosci. 33 (2018) 206–223 . [55] C. Thieba , et al. , Factors associated with successful MRI scanning in unsedated young children, Front. Pediat.r 6 (2018) 146 . [56] Y. Chen , et al. , MR fingerprinting enables quantitative measures of brain tissue relaxation times and myelin water fraction in the first five years of life, Neuroimage 186 (2019) 782–793 . [57] P. de Blank , et al. , Magnetic resonance fingerprinting to characterize childhood and young adult brain tumors, Pediatr. Neurosurg. 54 (5) (2019) 310–318 . [58] K.M. Langa , et al. , The diagnosis and management of mild cognitive impairment: a clinical review, JAMA 312 (23) (2014) 2551–2561 . [85] P. Vannini , et al. , Anosognosia for memory deficits in mild cognitive impairment: insight into the neural mechanism using functional and molecular imaging, Neu- roimage Clin. 15 (2017) 408–414 . [86] M. Bailly , et al. , Precuneus and cingulate cortex atrophy and hypometabolism in pa- tients with alzheimer’s disease and mild cognitive impairment: MRI and (18)F-FDG PET quantitative analysis using freesurfer, Biomed. Res. Int. 2015 (2015) 583931 . [87] C. Marcus , et al. , Brain PET in the diagnosis of Alzheimer’s disease, Clin. Nucl. Med. 39 (10) (2014) e413–e422 quiz e423-6 . [88] A.D. Cohen , et al. , Early detection of Alzheimer’s disease using PiB and FDG PET, Neurobiol. Dis. 72 (Pt A) (2014) 117–122 . [89] M.P. Murphy , et al. , Alzheimer’s disease and the amyloid-beta peptide, J. Alzheimers Dis. 19 (1) (2010) 311–323 . [59] R.C. Petersen , et al. , Prevalence of mild cognitive impairment is higher in men. The [90] F. Wang , et al. , Prediction and characterization of protein-protein interaction net- Mayo Clinic Study of Aging, Neurology 75 (10) (2010) 889–897 . [60] C.R. Jack Jr. , Alzheimer disease: new concepts on its neurobiology and the clinical role imaging will play, Radiology 263 (2) (2012) 344–361 . [61] T.Y. Liu-Ambrose , et al. , Increased risk of falling in older community-dwelling women with mild cognitive impairment, Phys. Ther. 88 (12) (2008) 1482–1491 . [62] N. Ackl , et al. , Hippocampal metabolic abnormalities in mild cognitive impairment and Alzheimer’s disease, Neurosci. Lett. 384 (1-2) (2005) 23–28 . [63] R.C. Petersen , et al. , Current concepts in mild cognitive impairment, Arch. Neurol. 58 (12) (2001) 1985–1992 . [64] L.G. Apostolova , Use of magnetic resonance imaging to identify mild cognitive impairment: who should be imaged? CNS Spectr. 13 (10 Suppl 16) (2008) 18–20 . [65] A. Bartos , et al. , Brain volumes and their ratios in Alzheimer s disease on magnetic resonance imaging segmented using Freesurfer 6.0, Psychiatry Res. Neuroimaging 287 (2019) 70–74 . [66] R. Basiratnia , et al. , Hippocampal volume and hippocampal angle (a more practical marker) in mild cognitive impairment: a case-control magnetic resonance imaging study, Adv. Biomed. Res. 4 (2015) 192 . [67] M. Atmaca , et al. , Volumetric MRI study of orbito-frontal cortex and thalamus in obsessive-compulsive personality disorder, J. Clin. Neurosci. 64 (2019) 89–93 . [68] M. Bilello , et al. , Correlating cognitive decline with white matter lesion and brain atrophy magnetic resonance imaging measurements in alzheimer’s disease, J. Alzheimers Dis. 48 (4) (2015) 987–994 . [69] L. Huang , et al. , Inhibition of eukaryotic initiation factor 3B suppresses prolifer- ation and promotes apoptosis of chronic myeloid leukemia cells, Adv. Clin. Exp. Med. (2019) . [70] E. Saka , et al. , Linear measures of temporal lobe atrophy on brain magnetic res- onance imaging (MRI) but not visual rating of white matter changes can help discrimination of mild cognitive impairment (MCI) and Alzheimer’s disease (AD), Arch. Gerontol. Geriatr. 44 (2) (2007) 141–151 . [71] Q. Shen , et al. , Volumetric and visual rating of magnetic resonance imaging scans in the diagnosis of amnestic mild cognitive impairment and Alzheimer’s disease, Alzheimers Dement. 7 (4) (2011) e101–e108 . [72] A. Chandra , et al. , Magnetic resonance imaging in Alzheimer’s disease and mild cognitive impairment, J. Neurol. 266 (6) (2019) 1293–1302 . [73] L. Xu , et al. , Prediction of progressive mild cognitive impairment by multi-modal neuroimaging biomarkers, J. Alzheimers Dis. 51 (4) (2016) 1045–1056 . [74] A. Chiti , et al. , Functional magnetic resonance imaging with encoding task in pa- tients with mild cognitive impairment and different severity of leukoaraiosis, Psy- chiatry Res. Neuroimaging 282 (2018) 126–131 . [75] P. Forouzannezhad , et al. , A survey on applications and analysis methods of func- tional magnetic resonance imaging for Alzheimer’s disease, J. Neurosci. Methods 317 (2019) 121–140 . [76] B. Frederick , et al. , Brain proton magnetic resonance spectroscopy in Alzheimer disease: changes after treatment with xanomeline, Am. J. Geriatr. Psychiatry 10 (1) (2002) 81–88 . [77] P.J. Modrego , et al. , Conversion from mild cognitive impairment to probable Alzheimer’s disease predicted by brain magnetic resonance spectroscopy, Am. J. Psychiatry 162 (4) (2005) 667–675 . [78] J.M. Garcia Santos , et al. , Magnetic resonance spectroscopy performance for detec- tion of dementia, Alzheimer’s disease and mild cognitive impairment in a commu- nity-based survey, Dement. Geriatr. Cognit. Disord. 26 (1) (2008) 15–25 . [79] G.H. Jahng , et al. , Glutamine and glutamate complex, as measured by functional magnetic resonance spectroscopy, alters during face-name association task in pa- tients with mild cognitive impairment and alzheimer’s disease, J. Alzheimers Dis. 52 (1) (2016) 145–159 . [80] A.A. Vijayakumari , et al. , Glutamatergic response to a low load working memory paradigm in the left dorsolateral prefrontal cortex in patients with mild cognitive impairment: a functional magnetic resonance spectroscopy study, Brain Imaging Behav (2019) . [81] D. Wong , et al. , Reduced hippocampal glutamate and posterior cingulate N-acetyl aspartate in mild cognitive impairment and alzheimer’s disease is associated with episodic memory performance and white matter integrity in the cingulum: a pilot study, J. Alzheimers Dis. (2020) . [82] G. Oeltzschner , et al. , Neurometabolites and associations with cognitive deficits in mild cognitive impairment: a magnetic resonance spectroscopy study at 7 Tesla, Neurobiol. Aging 73 (2019) 211–218 . [83] K. Kantarci , Proton MRS in mild cognitive impairment, J. Magn. Reson. Imaging 37 (4) (2013) 770–777 . [84] A.M.N. Coutinho , et al. , Analysis of the posterior cingulate cortex with [18F]FDG-PET and Naa/mI in mild cognitive impairment and Alzheimer’s disease: correlations and differences between the two methods, Dement. Neuropsychol. 9 (4) (2015) 385–393 . works in swine, Proteome Sci. 10 (1) (2012) 2 . [91] D. Zhang , et al. , Multi-modal multi-task learning for joint prediction of multiple regression and classification variables in Alzheimer’s disease, Neuroimage 59 (2) (2012) 895–907 . [92] H. Liu , et al. , The impact of marine shipping and its DECA control on air quality in the Pearl River Delta, China, Sci. Total Environ. 625 (2018) 1476–1485 . [93] D. Kim , et al. , A graph-based integration of multimodal brain imaging data for the detection of early mild cognitive impairment (E-MCI), Multimodal. Brain Image Anal. 2013 (8159) (2013) 159–169 . [94] J. Young , et al. , Accurate multimodal probabilistic prediction of conversion to Alzheimer’s disease in patients with mild cognitive impairment, Neuroimage Clin. 2 (2013) 735–745 . [95] S.Y. Lin , et al. , Multiparametric graph theoretical analysis reveals altered struc- tural and functional network topology in Alzheimer’s disease, Neuroimage Clin. 22 (2019) 101680 . [96] D. Tromp , et al. , Episodic memory in normal aging and Alzheimer disease: insights from imaging and behavioral studies, Ageing Res. Rev. 24 (Pt B) (2015) 232–262 . [97] K. Werheid , et al. , Are faces special in Alzheimer’s disease? Cognitive conceptual- isation, neural correlates, and diagnostic relevance of impaired memory for faces and names, Cortex 43 (7) (2007) 898–906 . [98] S.P. Cass , Alzheimer’s disease and exercise: a literature review, Curr. Sports Med. Rep. 16 (1) (2017) 19–22 . [99] A. Alzheimer’s , 2014 Alzheimer’s disease facts and figures, Alzheimers Dement. 10 (2) (2014) e47–e92 . [100] A. Tucholka , et al. , An empirical comparison of surface-based and volume-based group studies in neuroimaging, Neuroimage 63 (3) (2012) 1443–1453 . [101] W.J. Henneman , et al. , Hippocampal atrophy rates in Alzheimer disease: added value over whole brain volume measures, Neurology 72 (11) (2009) 999–1007 . [102] G.A. Kerchner , et al. , Hippocampal CA1 apical neuropil atrophy in mild Alzheimer disease visualized with 7-T MRI, Neurology 75 (15) (2010) 1381–1387 . [103] F.L. De Winter , et al. , No association of lower hippocampal volume with alzheimer’s disease pathology in late-life depression, Am. J. Psychiatry 174 (3) (2017) 237–245 . [104] J. Chen , et al. , Can multi-modal neuroimaging evidence from hippocampus provide biomarkers for the progression of amnestic mild cognitive impairment? Neurosci. Bull. 31 (1) (2015) 128–140 . [105] G. Zamboni , et al. , Resting functional connectivity reveals residual functional ac- tivity in Alzheimer’s disease, Biol. Psychiatry 74 (5) (2013) 375–383 . [106] J. Zhou , et al. , Predicting regional neurodegeneration from the healthy brain func- tional connectome, Neuron 73 (6) (2012) 1216–1227 . [107] J. Wang , et al. , Disrupted functional brain connectome in individuals at risk for Alzheimer’s disease, Biol. Psychiatry 73 (5) (2013) 472–481 . [108] M. Jin , et al. , Aberrant default mode network in subjects with amnestic mild cog- nitive impairment using resting-state functional MRI, Magn. Reson. Imaging 30 (1) (2012) 48–61 . [109] E. Bayram , et al. , Current understanding of magnetic resonance imaging biomark- ers and memory in Alzheimer’s disease, Alzheimers Dement. 4 (2018) 395–413 . [110] C. Promteangtrong , et al. , Multimodality imaging approach in Alzheimer disease. Part I: Structural MRI, functional MRI, diffusion tensor imaging and magnetization transfer imaging, Dement. Neuropsychol. 9 (4) (2015) 318–329 . [111] M. Waser , et al. , Neuroimaging markers of global cognition in early Alzheimer’s dis- ease: a magnetic resonance imaging-electroencephalography study, Brain Behav. 9 (1) (2019) e01197 . [112] P. Harman , et al. , Technical note: can resting state functional MRI assist in routine clinical diagnosis? BJR Case Rep. 4 (4) (2018) 20180030 . [113] S. Basheera , et al. , Convolution neural network-based Alzheimer’s disease classifi- cation using hybrid enhanced independent component analysis based segmented gray matter of T2 weighted magnetic resonance imaging with clinical valuation, Alzheimers Dement. 5 (2019) 974–986 . [114] D. Hirjak , et al. , Multimodal Magnetic Resonance Imaging Data Fusion Reveals Dis- tinct Patterns of Abnormal Brain Structure and Function in Catatonia, Schizophr. Bull. 46 (1) (2020) 202–210 . [115] R. Chabiniok , et al. , Multiphysics and multiscale modelling, data-model fusion and integration of organ physiology in the clinic: ventricular cardiac mechanics, Inter- face Focus 6 (2) (2016) 20150083 . [116] T. Adali , et al. , Multi-modal data fusion using source separation: two effective mod- els based on ICA and IVA and their properties, Proc. IEEE Inst. Electr. Electron Eng. 103 (9) (2015) 1478–1493 . [117] B.L.B. Marino , et al. , Parkinson’s disease: a review from the pathophysiology to diagnosis, new perspectives for pharmacological treatment, Mini. Rev. Med. Chem. (2019) . [118] J.A. Driver , et al. , Incidence and remaining lifetime risk of Parkinson disease in advanced age, Neurology 72 (5) (2009) 432–438 . 182 Y.-D. Zhang, Z. Dong and S.-H. Wang et al. Information Fusion 64 (2020) 149–187 [119] J.H. Lee , et al. , The incidence rates and risk factors of Parkinson disease in patients with psoriasis: a nationwide population-based cohort study, J. Am. Acad. Dermatol. (2019) . [120] S.K. Van Den Eeden , et al. , Incidence of Parkinson’s disease: variation by age, gen- der, and race/ethnicity, Am. J. Epidemiol. 157 (11) (2003) 1015–1022 . [121] K. Bharti , et al. , Neuroimaging advances in Parkinson’s disease with freezing of gait: a systematic review, Neuroimage Clin. 24 (2019) 102059 . [122] A.M. Al-Radaideh , et al. , The role of magnetic resonance imaging in the diagnosis of Parkinson’s disease: a review, Clin. Imaging 40 (5) (2016) 987–996 . [123] M. Alegret , et al. , MRI atrophy parameters related to cognitive and motor impair- ment in Parkinson’s disease, Neurologia 16 (2) (2001) 63–69 . [124] S. Prasad , et al. , Three-dimensional neuromelanin-sensitive magnetic resonance imaging of the substantia nigra in Parkinson’s disease, Eur. J. Neurol. 25 (4) (2018) 680–686 . [125] J. Wang , et al. , Neuromelanin-sensitive MRI of the substantia nigra: an imaging biomarker to differentiate essential tremor from tremor-dominant Parkinson’s dis- ease, Parkinsonism Relat. Disord. 58 (2019) 3–8 . [126] L. Jin , et al. , Combined visualization of nigrosome-1 and neuromelanin in the sub- stantia nigra using 3T MRI for the differential diagnosis of essential tremor and de novo Parkinson’s disease, Front. Neurol. 10 (2019) 100 . [127] H. Takahashi , et al. , Comprehensive MRI quantification of the substantia nigra pars compacta in Parkinson’s disease, Eur. J. Radiol. 109 (2018) 48–56 . [128] Y. Wang , et al. , Quantitative susceptibility mapping (QSM): decoding MRI data for a tissue magnetic biomarker, Magn. Reson. Med. 73 (1) (2015) 82-101 . [129] R.G. Burciu , et al. , Imaging of motor cortex physiology in Parkinson’s disease, Mov. Disord. 33 (11) (2018) 1688–1699 . [130] M. Niethammer , et al. , Functional neuroimaging in Parkinson’s disease, Cold Spring Harb. Perspect. Med. 2 (5) (2012) a009274 . [131] S. Evangelisti , et al. , L-dopa modulation of brain connectivity in parkinson’s disease patients: a pilot EEG-fMRI study, Front. Neurosci. 13 (2019) 611 . [132] A. Tessitore , et al. , Sensorimotor connectivity in Parkinson’s disease: the role of functional neuroimaging, Front. Neurol. 5 (2014) 180 . [133] M. Amboni , et al. , Resting-state functional connectivity associated with mild cog- nitive impairment in Parkinson’s disease, J. Neurol. 262 (2) (2015) 425–434 . [134] P. Borghammer , et al. , Glucose metabolism in small subcortical structures in Parkin- son’s disease, Acta Neurol. Scand. 125 (5) (2012) 303–310 . [135] R. Hilker , Functional imaging of deep brain stimulation in idiopathic Parkinson’s disease, Nervenarzt 81 (10) (2010) 1204–1207 . [136] G. Berding , et al. , Resting regional cerebral glucose metabolism in advanced Parkin- son’s disease studied in the off and on conditions with [(18)F]FDG-PET, Mov. Dis- ord. 16 (6) (2001) 1014–1022 . [137] S.J. Son , et al. , Imaging analysis of Parkinson’s disease patients using SPECT and tractography, Sci. Rep. 6 (2016) 38070 . [138] M.C. Ruppert , et al. , Network degeneration in Parkinson’s disease: multimodal imaging of nigro-striato-cortical dysfunction, Brain (2020) . [139] F.D. Bowman , et al. , Multimodal imaging signatures of Parkinson’s disease, Front. Neurosci. 10 (2016) 131 . [140] Mental Illness, 2020 Available from: https://www.nimh.nih.gov/health/statistics/ mental-illness.shtml . [141] Mental Disorders Affect One in Four People, 2001 [cited 2020 9/March]; Available from https://www.who.int/whr/2001/media_centre/press_release . [142] J. Rehm , et al. , Global burden of disease and the impact of mental and addictive disorders, Curr. Psychiatry Rep. 21 (2) (2019) 10 . [143] W.W. Eaton , et al. , The burden of mental disorders, Epidemiol. Rev. 30 (2008) p. 1-14 . [144] Mental Illness Will Cost the World $16 USD Trillion by 2030, 2018 [cited 2020 9/3]; Available from https://www.psychiatrictimes.com/mental-health/mental- illness-will-cost-world-16-usd-trillion-2030 . [145] D.A. Silbersweig , et al. , Neuroimaging in psychiatry: a quarter century of progress, Harv. Rev. Psychiatry 25 (5) (2017) 195–197 . [157] A.C. Nugent , et al. , Multimodal imaging reveals a complex pattern of dysfunction in corticolimbic pathways in major depressive disorder, Hum. Brain Mapp. 40 (13) (2019) 3940–3950 . [158] N. Vasic , et al. , Baseline brain perfusion and brain structure in patients with major depression: a multimodal magnetic resonance imaging study, J. Psychiatry Neu- rosci. 40 (6) (2015) 412–421 . [159] A. Finkelmeyer , et al. , Altered hippocampal function in major depression de- spite intact structure and resting perfusion, Psychol. Med. 46 (10) (2016) 2157–2168 . [160] J. Yang , et al. , Development and evaluation of a multimodal marker of major de- pressive disorder, Hum. Brain Mapp. 39 (11) (2018) 4420–4439 . [161] L.A. Maglanoc , et al. , Multimodal fusion of structural and functional brain imaging in depression using linked independent component analysis, Hum. Brain Mapp. 41 (1) (2020) 241–255 . [162] J. Chen , et al. , Widespread decreased grey and white matter in paediatric obses- sive-compulsive disorder (OCD): a voxel-based morphometric MRI study, Psychia- try Res. 213 (1) (2013) 11–17 . [163] L. Lazaro , et al. , Brain changes in children and adolescents with obsessive-compul- sive disorder before and after treatment: a voxel-based morphometric MRI study, Psychiatry Res. 172 (2) (2009) 140–146 . [164] L. Qiu , et al. , Abnormal regional spontaneous neuronal activity associated with symptom severity in treatment-naive patients with obsessive-compulsive disorder revealed by resting-state functional MRI, Neurosci. Lett. 640 (2017) 99–104 . [165] L. Lazaro , et al. , Cerebral activation in children and adolescents with obsessive–compulsive disorder before and after treatment: a functional MRI study, J. Psychi- atr. Res. 42 (13) (2008) 1051–1059 . [166] X. Bu , et al. , Investigating the predictive value of different resting-state functional MRI parameters in obsessive-compulsive disorder, Transl. Psychiatry 9 (1) (2019) 17 . [167] S.E. Park , et al. , Metabolic abnormality in the right dorsolateral prefrontal cortex in patients with obsessive-compulsive disorder: proton magnetic resonance spec- troscopy, Acta Neuropsychiatr. 29 (3) (2017) 164–169 . [168] S. Fan , et al. , Abnormalities in metabolite concentrations in tourette’s disorder and obsessive-compulsive disorder-A proton magnetic resonance spectroscopy study, Psychoneuroendocrinology 77 (2017) 211–217 . [169] R. Tukel , et al. , Proton magnetic resonance spectroscopy in obsessive-compulsive disorder: evidence for reduced neuronal integrity in the anterior cingulate, Psychi- atry Res. 224 (3) (2014) 275–280 . [170] B.P. Brennan , et al. , A critical review of magnetic resonance spectroscopy studies of obsessive-compulsive disorder, Biol. Psychiatry 73 (1) (2013) 24–31 . [171] Y. Li , et al. , Investigation of anterior cingulate cortex gamma-aminobutyric acid and glutamate-glutamine levels in obsessive-compulsive disorder using magnetic resonance spectroscopy, BMC Psychiatry 19 (1) (2019) 164 . [172] Z. Zhang , et al. , Brain gamma-aminobutyric acid (GABA) concentration of the pre- frontal lobe in unmedicated patients with obsessive-compulsive disorder: a research of magnetic resonance spectroscopy, Shanghai Arch. Psychiatry 28 (5) (2016) 263–270 . [173] D.R. Rosenberg , et al. , Reduced anterior cingulate glutamate in pediatric major de- pression: a magnetic resonance spectroscopy study, Biol. Psychiatry 58 (9) (2005) 700–704 . [174] L. Lazaro , et al. , Proton magnetic resonance spectroscopy in pediatric obsessive–compulsive disorder: longitudinal study before and after treatment, Psychiatry Res. 201 (1) (2012) 17–24 . [175] S.P.H. Whiteside , et al. , The effect of behavior therapy on caudate N-acetyl-l-as- partic acid in adults with obsessive-compulsive disorder, Psychiatry Res. 201 (1) (2012) 10–16 . [176] M. Pico-Perez , et al. , Modality-specific overlaps in brain structure and function in obsessive-compulsive disorder: multimodal meta-analysis of case-control MRI studies, Neurosci. Biobehav. Rev. 112 (2020) 83–94 . [177] P.S. Moreira , et al. , The neural correlates of obsessive-compulsive disorder: a mul- [146] D.M. Cannon , Neuroimaging in psychiatry, Ir. J. Psychol. Med. 24 (3) (2007) timodal perspective, Transl. Psychiatry (2017) 7 . 86–88 . [147] P. Wibawa , et al. , Understanding MRI in clinical psychiatry: perspectives from neu- roimaging psychiatry registrars, Aust. Psychiatry 27 (4) (2019) 396–403 . [148] A. Todeva-Radneva , et al. , The value of neuroimaging techniques in the translation and trans-diagnostic validation of psychiatric diagnoses - selective review, Curr. Top. Med. Chem. (2020) . [149] C.H. Lai , Promising neuroimaging biomarkers in depression, Psychiatry Investig. 16 (9) (2019) 662–670 . [150] L.V. Kessing , et al. , Rate and predictors of conversion from unipolar to bipolar disor- der: a systematic review and meta-analysis, Bipolar Disord. 19 (5) (2017) 324–335 . [151] E. Vieta , et al. , Early intervention in bipolar disorder, Am. J. Psychiatry 175 (5) (2018) 411–426 . [152] R.C. Kessler , Epidemiology of women and depression, J. Affect. Disord. 74 (1) (2003) 5–13 . [153] G. Andrews , et al. , Why does the burden of disease persist? Relating the burden of anxiety and depression to effectiveness of treatment, Bull. World Health Organ. 78 (4) (2000) 446–454 . [154] L. Schmaal , et al. , Brain structural signatures of adolescent depressive symptom trajectories: a longitudinal magnetic resonance imaging study, J. Am. Acad. Child Adolesc. Psychiatry 56 (7) (2017) 593-601 e9 . [155] K. Vassilopoulou , et al. , A magnetic resonance imaging study of hippocampal, amygdala and subgenual prefrontal cortex volumes in major depression subtypes: melancholic versus psychotic depression, J. Affect. Disord. 146 (2) (2013) 197–204 . [156] M.D. Sacchet , et al. , Myelination of the brain in major depressive disorder: an in vivo quantitative magnetic resonance imaging study, Sci. Rep. 7 (1) (2017) 2200 . [178] J.S. Choi , et al. , Morphometric alterations of anterior superior temporal cortex in obsessive-compulsive disorder, Depress. Anxiety 23 (5) (2006) 290–296 . [179] J. Fan , et al. , Spontaneous neural activity in the right superior temporal gyrus and left middle temporal gyrus is associated with insight level in obsessive-compulsive disorder, J. Affect. Disord. 207 (2017) 203–211 . [180] W. Bruin , et al. , Diagnostic neuroimaging markers of obsessive-compulsive disor- der: initial evidence from structural and functional MRI studies, Prog. Neuropsy- chopharmacol. Biol. Psychiatry 91 (2019) 49–59 . [181] J.B. de Salles Andrade , et al. , An MRI study of the metabolic and structural abnor- malities in obsessive-compulsive disorder, Front. Hum. Neurosci. 13 (2019) 186 . [182] R.A. McCutcheon , et al. , Schizophrenia-an overview, JAMA Psychiatry (2019) 1–10 . [183] G. Davies , et al. , A meta-analytic review of the relationship between neurocog- nition, metacognition and functional outcome in schizophrenia, J. Ment. Health (2018) 1–11 . [184] M. Zamanpoor , Schizophrenia in a genomic era: a review from the pathogenesis, genetic and environmental etiology to diagnosis and treatment insights, Psychiatr. Genet. 30 (1) (2020) 1–9 . [185] R. Tandon , et al. , Schizophrenia, "Just the Facts": what we know in 2008 part 1: overview, Schizophr. Res. 100 (1-3) (2008) 4–19 . [186] T.G. van Erp , et al. , Subcortical brain volume abnormalities in 2028 individuals with schizophrenia and 2540 healthy controls via the ENIGMA consortium, Mol. Psychiatry 21 (4) (2016) 585 . [187] W. Cahn , et al. , Brain volume changes in first-episode schizophrenia: a 1-year fol- low-up study, Arch. Gen. Psychiatry 59 (11) (2002) 1002–1010 . 183 Y.-D. Zhang, Z. Dong and S.-H. Wang et al. Information Fusion 64 (2020) 149–187 [188] L. De Peri , et al. , Brain structural abnormalities at the onset of schizophrenia and bipolar disorder: a meta-analysis of controlled magnetic resonance imaging studies, Curr. Pharm. Des. 18 (4) (2012) 486–494 . [189] A. Vita , et al. , Progressive loss of cortical gray matter in schizophrenia: a meta-anal- ysis and meta-regression of longitudinal MRI studies, Transl. Psychiatry 2 (2012) e19 . [190] P.M. Thompson , et al. , Mapping adolescent brain change reveals dynamic wave of accelerated gray matter loss in very early-onset schizophrenia, Proc. Natl. Acad. Sci. U. S. A. 98 (20) (2001) 11650–11655 . [191] K.H. Karlsgodt , Diffusion imaging of white matter in schizophrenia: progress and future directions, Biol. Psychiatry Cognit. Neurosci. Neuroimaging 1 (3) (2016) 209–217 . [192] B.D. Peters , et al. , White matter fibertracking in first-episode schizophrenia, schizoaffective patients and subjects at ultra-high risk of psychosis, Neuropsychobi- ology 58 (1) (2008) 19–28 . [193] G. Price , et al. , The corpus callosum in first episode schizophrenia: a diffusion tensor imaging study, J. Neurol. Neurosurg. Psychiatry 76 (4) (2005) 585–587 . [194] S. Kelly , et al. , Widespread white matter microstructural differences in schizophre- nia across 4322 individuals: results from the ENIGMA Schizophrenia DTI Working Group, Mol. Psychiatry 23 (5) (2018) 1261–1269 . [195] B. Birur , et al. , Brain structure, function, and neurochemistry in schizophrenia and bipolar disorder-a systematic review of the magnetic resonance neuroimaging lit- erature, NPJ Schizophr. 3 (2017) 15 . [196] J.M. Fox , et al. , Default mode functional connectivity is associated with social func- [223] P. Burt , et al. , The Laplacian pyramid as a compact image code, IEEE Trans. Com- mun. 31 (4) (1983) 532–540 . [224] R. Vijayarajan , et al. , Discrete wavelet transform based principal component av- eraging fusion for medical images, AEU-Int. J. Electron. Commun. 69 (6) (2015) 896–902 . [225] R. Singh , et al. , Fusion of multimodal medical images using Daubechies complex wavelet transform–a multiresolution approach, Inf. Fusion 19 (2014) 49–60 . [226] S. Vulliemoz , et al. , Simultaneous intracranial EEG and fMRI of interictal epileptic discharges in humans, Neuroimage 54 (1) (2011) 182–190 . [227] J. Sui , et al. , A review of multivariate methods for multimodal fusion of brain imaging data, J. Neurosci. Methods 204 (1) (2012) 68–81 . [228] X Zuzhang , new_image_fusion, 2020 [cited 2020 2.23] . [229] K.A. Johnson, et al., Brain Image, 2020 [cited 2020 02.24]; Available from http://www.med.harvard.edu/AANLIB/cases/case9/mr1-tc1/020.html . [230] R. Shen , et al. , Cross-scale coefficient selection for volumetric medical image fusion, IEEE Trans. Biomed. Eng. 60 (4) (2012) 1069–1079 . [231] J.J. Lewis , et al. , Pixel-and region-based image fusion with complex wavelets, Inf. Fusion 8 (2) (2007) 119–130 . [232] D. Nandi , et al. , Principal component analysis in medical image processing: a study, Int. J. Image Min. 1 (1) (2015) 65–86 . [233] R. Vijayarajan , et al. , Iterative block level principal component averaging medical image fusion, Optik 125 (17) (2014) 4751–4757 . [234] H.-q. Wang , et al. , 2009 International Symposium on Computer Network and Mul- timedia Technology, IEEE (2009) 1–4 . tioning in schizophrenia, J. Abnorm. Psychol. 126 (4) (2017) 392–405 . [235] Krishn, A., et al., Medical Image Fusion Using Combination of PCA and Wavelet [197] Q. Wang , et al. , Anatomical insights into disrupted small-world networks in Analysis. schizophrenia, Neuroimage 59 (2) (2012) 1085–1093 . [198] R. Tarumi , et al. , Levels of glutamatergic neurometabolites in patients with se- vere treatment-resistant schizophrenia: a proton magnetic resonance spectroscopy study, Neuropsychopharmacology 45 (4) (2020) 632–640 . [199] Y. Iwata , et al. , Glutamatergic neurometabolite levels in patients with ultra-treat- ment-resistant schizophrenia: a cross-sectional 3T proton magnetic resonance spec- troscopy study, Biol. Psychiatry 85 (7) (2019) 596–605 . [200] S. Brugger , et al. , Proton magnetic resonance spectroscopy and illness stage in schizophrenia–a systematic review and meta-analysis, Biol. Psychiatry 69 (5) (2011) 495–503 . [201] J. Sui , et al. , In search of multimodal neuroimaging biomarkers of cognitive deficits in schizophrenia, Biol. Psychiatry 78 (11) (2015) 794–804 . [202] E.J. Cadena , et al. , A longitudinal multimodal neuroimaging study to examine re- lationships between resting state glutamate and task related BOLD response in schizophrenia, Front. Psychiatry 9 (2018) 632 . [203] M. Isobe , et al. , Multimodal neuroimaging as a window into the pathological physi- ology of schizophrenia: current trends and issues, Neurosci. Res. 102 (2016) 29–38 . [204] C.J. Aine , et al. , Multimodal neuroimaging in schizophrenia: description and dis- semination, Neuroinformatics 15 (4) (2017) 343–364 . [205] K. Zhang , et al. , Comparison of cerebral blood flow acquired by simultaneous [15O] water positron emission tomography and arterial spin labeling magnetic resonance imaging, J. Cereb. Blood Flow Metab. 34 (8) (2014) 1373–1380 . [206] K. Rosenkranz , et al. , Present and future of simultaneous EEG-fMRI. Magnetic res- onance materials in physics, Biol. Med. 23 (5-6) (2010) 309–316 . [207] R.I. Goldman , et al. , Simultaneous EEG and fMRI of the alpha rhythm, Neuroreport 13 (18) (2002) 2487 . [208] H. Laufs , et al. , EEG-correlated fMRI of human alpha activity, Neuroimage 19 (4) (2003) 1463–1476 . [209] P. Ritter , et al. , simultaneous EEG–fMRI, Neurosci. Biobehav. Rev. 30 (6) (2006) 823–838 . [210] S.B. Eickhoff, et al. , Assignment of functional activations to probabilistic cytoar- chitectonic areas revisited, Neuroimage 36 (3) (2007) 511–521 . [211] P.D. Acton , et al. , Quantification in PET, Radiol. Clin. 42 (6) (2004) 1055–1062 . [212] B.R. Zeeberg , et al. , Accuracy of in vivo neuroreceptor quantification by PET and review of steady-state, transient, double injection, and equilibrium models, IEEE Trans. Med. Imaging 7 (3) (1988) 203–212 . [213] S.H. Oh , et al. , Distortion correction in EPI at ultra ‐high ‐field MRI using PSF map- ping with optimal combination of shift detection dimension, Magn. Reson. Med. 68 (4) (2012) 1239–1246 . [214] J.L. Andersson , et al. , How to correct susceptibility distortions in spin-echo echo–planar images: application to diffusion tensor imaging, Neuroimage 20 (2) (2003) 870–888 . [215] M. Choi , A new intensity-hue-saturation fusion approach to image fusion with a tradeoff parameter, IEEE Trans. Geosci. Remote Sens. 44 (6) (2006) 1672–1682 . [216] G. Kaur , et al. , Survey on multifocus image fusion techniques, in: 2016 International Conference on Electrical, Electronics, and Optimization Techniques (ICEEOT), IEEE, 2016, pp. 1420–1424 . [217] Y.A.V. Phamila , et al. , Discrete Cosine Transform based fusion of multi-focus images for visual sensor networks, Signal Process. 95 (2014) 161–170 . [218] L. Cao , et al. , Multi-focus image fusion based on spatial frequency in discrete cosine transform domain, IEEE Signal Process Lett. 22 (2) (2014) 220–224 . [219] S. Li , et al. , Multifocus image fusion using region segmentation and spatial fre- quency, Image Vision Comput. 26 (7) (2008) 971–979 . [220] Y. Liu , et al. , Multi-focus image fusion with dense SIFT, Inf. Fusion 23 (2015) 139–155 . [221] T. Pu , et al. , Contrast-based image fusion using the discrete wavelet transform, Opt. Eng. (2000) 39 . [222] G. Singh , et al. , MHWT-a modified haar wavelet transformation for image fusion, Int. J. Comput. Appl. 79 (1) (2013) . [236] L. Wang , et al. , EGGDD: an explicit dependency model for multi-modal medical image fusion in shift-invariant shearlet transform domain, Inf. Fusion 19 (2014) 29–37 . [237] J. Yang , et al. , Image fusion using the expectation-maximization algorithm and a hidden Markov model, in: IEEE 60th Vehicular Technology Conference, IEEE, 2004, pp. 4563–4567. VTC2004-Fall. 2004. 2004 . [238] S. Yang , et al. , Contourlet hidden Markov Tree and clarity-saliency driven PCNN based remote sensing images fusion, Appl. Soft Comput. 12 (1) (2012) 228–237 . [239] G. Bhatnagar , et al. , Human visual system inspired multi-modal medical image fusion framework, Expert Syst. Appl. 40 (5) (2013) 1708–1720 . [240] S. Daneshvar , et al. , MRI and PET image fusion by combining IHS and retina-in- spired models, Inf. Fusion 11 (2) (2010) 114–123 . [241] J.H. Jang , et al. , Contrast-enhanced fusion of multisensor images using subband-de- composed multiscale retinex, IEEE Trans. Image Process. 21 (8) (2012) 3479–3490 . [242] S.M. Smith , et al. , SUSAN —a new approach to low level image processing, Int. J. Comput. Vision 23 (1) (1997) 45–78 . [243] C. He , et al. , Multimodal medical image fusion based on IHS and PCA, Proc. Eng. 7 (2010) 280–285 . [244] Y. Zheng , et al. , A new metric based on extended spatial frequency and its appli- cation to DWT based fusion algorithms, Inf. Fusion 8 (2) (2007) 177–192 . [245] Z. Wencang , et al. , Medical image fusion method based on wavelet multi-resolution and entropy, in: 2008 IEEE International Conference on Automation and Logistics, IEEE, 2008, pp. 2329–2333 . [246] S. Garg , et al. , Multilevel medical image fusion using segmented image by level set evolution with region competition, in: 2005 IEEE Engineering in Medicine and Biology 27th Annual Conference, IEEE, 2006, pp. 7680–7683 . [247] X. Li , et al. , Medical image fusion by multi-resolution analysis of wavelets trans- form, in: Wavelet Analysis and Applications, Springer, 2006, pp. 389–396 . [248] G. Bhatnagar , et al. , Directive contrast based multimodal medical image fusion in NSCT domain, IEEE Trans. Multimed. 15 (5) (2013) 1014–1024 . [249] X.L. Zhu , et al. , Investigation of remote sensing image fusion strategy applying PCA to wavelet packet analysis based on IHS transform, J. Indian Soc. Remote Sens. 47 (3) (2019) 413–425 . [250] B. Deepa , et al. , An intensity factorized thresholding based segmentation technique with gradient discrete wavelet fusion for diagnosing stroke and tumor in brain MRI, Multidimen. Syst. Signal Process. 30 (4) (2019) 2081–2112 . [251] P. Phillips , Detection of Alzheimer’s disease and mild cognitive impairment based on structural volumetric MR images using 3D-DWT and WTA-KSVM trained by PSOTVAC, Biomed. Signal Process. Control 21 (2015) 58–73 . [252] O. Prakash , et al. , CT and MR images fusion based on stationary wavelet trans- form by modulus maxima, in: I.K. Sethi (Ed.), Computational Vision and Robotics, Springer-Verlag, Berlin: Berlin, 2015, pp. 199–204 . [253] G.A. Pawar , et al. , Multi-focal image fusion with convolutional sparse repre- sentation and stationary wavelet transform, in: Computing, Communication and Signal Processing (ICCASP), Springer International Publishing Ag, Cham, 2019, pp. 865–873 . [254] Y. Li , Detection of dendritic spines using wavelet packet entropy and fuzzy support vector machine, CNS Neurol. Disord. 16 (2) (2017) 116–121 . [255] J. Yang , Preclinical diagnosis of magnetic resonance (MR) brain images via discrete wavelet packet transform with Tsallis entropy and generalized eigenvalue proximal support vector machine (GEPSVM), Entropy 17 (4) (2015) 1795–1813 . [256] K. Sreekala , et al. , Wavelet packet transform based fusion of misaligned images, in: International Conference on Circuit, Power and Computing Technologies, IEEE, Karnataka, India, 2016 . [257] P. Shah , et al. , Fusion of surveillance images in infrared and visible band using curvelet, wavelet and wavelet packet transform, Int. J. Wavel. Multiresol. Inf. Pro- cess. 8 (2) (2010) 271–292 . [258] A. Choubey , et al. , Novel data-access scheme and efficient parallel architecture for multi-level lifting 2-D DWT, Circ. Syst. Signal Process. 37 (10) (2018) 4482–4503 . 184 Y.-D. Zhang, Z. Dong and S.-H. Wang et al. Information Fusion 64 (2020) 149–187 [259] S.C. Shiralashetti , et al. , Wavelet-based lifting scheme for the numerical solution of some class of nonlinear partial differential equations, Int. J. Wavel. Multiresol. Inf. Process. 16 (5) (2018) 14 1850046 . [260] O. Prakash , et al. , Multiscale fusion of multimodal medical images using lift- ing scheme based biorthogonal wavelet transform, Optik 182 (2019) 995–1014 . [261] I. Haouam , et al. , MRI image compression using level set method and biorthogonal CDF wavelet based on lifting scheme, in: International Conference on Signal, Image, Vision and Their Applications, IEEE, Guelma, Algeria, 2018 . [262] E.T. Zemouri , et al. , Nonsubsampled contourlet transform and k-means clustering for degraded document image binarization, J. Electron. Imaging 28 (4) (2019) 19 Article ID. 043021 . [263] S.D. Ramlal , et al. , An improved multimodal medical image fusion scheme based on hybrid combination of nonsubsampled contourlet transform and stationary wavelet transform, Int. J. Imaging Syst. Technol. 29 (2) (2019) 146–160 . [264] L.L. Li , et al. , A practical medical image enhancement algorithm based on non- subsampled contourlet transform, J. Med. Imaging Health Inform. 9 (5) (2019) 1046–1056 . [265] C. Wang , et al. , Multi-modality anatomical and functional medical image fusion based on simplified-spatial frequency-pulse coupled neural networks and region en- ergy-weighted average strategy in non-sub sampled contourlet transform domain, J. Med. Imaging Health Inform. 9 (5) (2019) 1017–1027 . [266] L.L. Li , et al. , A novel medical image fusion approach based on nonsubsampled shearlet transform, J. Med. Imaging Health Inform. 9 (9) (2019) 1815–1826 . [267] A. Vishwakarma , et al. , Image fusion using adjustable non-subsampled shearlet transform, IEEE Trans. Instrum. Meas. 68 (9) (2019) 3367–3378 . [268] T. Akbarpour , et al. , Medical image fusion based on nonsubsampled shearlet trans- form and principal component averaging, Int. J. Wavel. Multiresol. Inf. Process. 17 (4) (2019) 21 Article ID. 1950023 . [269] B. Yang , et al. , Pixel-level image fusion with simultaneous orthogonal matching pursuit, Inf. Fusion 13 (1) (2012) 10–19 . [295] R.B. Buxton , Introduction to Functional Magnetic Resonance Imaging: Principles and Techniques, Cambridge University Press, 2009 . [296] K. Rosenkranz , et al. , Present and future of simultaneous EEG-fMRI, Magn. Reson. Mater. Phys. Biol. Med, 23 (5) (2010) 309–316 . [297] H. Laufs , A personalized history of EEG–fMRI integration, Neuroimage 62 (2) (2012) 1056–1067 . [298] J. Medi č, et al. , Off-resonance frequency filtered magnetic resonance imaging, Magn. Reson. Imaging 28 (4) (2010) 527–536 . [299] P. Hellier , et al. , Multimodal non-rigid warping for correction of distortions in func- tional MRI, in: International Conference on Medical Image Computing and Com- puter-Assisted Intervention, Springer, 2000, pp. 512–520 . [300] D. Holland , et al. , Efficient correction of inhomogeneous static magnetic field-in- duced distortion in Echo Planar Imaging, Neuroimage 50 (1) (2010) 175–183 . [301] Z. Chen , et al. , From simultaneous to synergistic MR ‐PET brain imaging: a re- view of hybrid MR ‐PET imaging methodologies, Hum. Brain Mapp. 39 (12) (2018) 5126–5144 . [302] M.G. Ullisch , et al. , MR-based PET motion correction procedure for simultaneous MR-PET neuroimaging of human brain, PLoS ONE 7 (11) (2012) e48149 . [303] M.J. Ehrhardt , et al. , Joint reconstruction of PET-MRI by exploiting structural sim- ilarity, Inverse Problems 31 (1) (2014) 015001 . [304] J.E. Iglesias , et al. , Multi-atlas segmentation of biomedical images: a survey, Med. Image Anal. 24 (1) (2015) 205–219 . [305] A.C. Evans , et al. , Brain templates and atlases, Neuroimage 62 (2) (2012) 911–922 . [306] J. Talairach , et al. , Atlas d’anatomie Stereotaxique du Telencephale: Etudes Anato- mo-Radiologiques, Masson, 1957 . [307] J. Talairach Tournoux, Co-planar stereotaxic atlas of the human brain, 3-Dimen- sional Proportional System: An Approach to Cerebral Imaging, 1988 1988 . [308] N. Tzourio-Mazoyer , et al. , Automated anatomical labeling of activations in SPM using a macroscopic anatomical parcellation of the MNI MRI single-subject brain, Neuroimage 15 (1) (2002) 273–289 . [309] D.L. Collins , et al. , Design and construction of a realistic digital brain phantom, [270] S. Li , et al. , Multimodal image fusion with joint sparsity model, Opt. Eng. 50 (6) IEEE Trans. Med. Imaging 17 (3) (1998) 463–468 . (2011) 067007 . [271] N. Yu , et al. , Image features extraction and fusion based on joint sparse represen- tation, IEEE J. Sel. Top. Signal Process. 5 (5) (2011) 1074–1082 . [272] Z.P. Xu , Medical image fusion using multi-level local extrema, Inf. Fusion 19 (2014) 38–48 . [273] H.R. Zhu , et al. , Infrared and visible image fusion based on contrast enhancement and multi-scale edge-preserving decomposition, J. Electron. Inf. Technol. 40 (6) (2018) 1294–1300 . [274] F. Kou , et al. , Edge-preserving smoothing pyramid based multi-scale exposure fu- sion, J. Visual Commun. Image Represent. 53 (2018) 235–244 . [310] R.A. Heckemann , et al. , Automatic anatomical brain MRI segmentation combining label propagation and decision fusion, Neuroimage 33 (1) (2006) 115–126 . [311] Y.Y. Zhang , et al. , Segmentation of brain MR images through a hidden Markov random field model and the expectation-maximization algorithm, IEEE Trans. Med. Imaging 20 (1) (2001) 45–57 . [312] J. Ashburner , et al. , Unified segmentation, Neuroimage 26 (3) (2005) 839–851 . [313] M. Cabezas , et al. , A review of atlas-based segmentation for magnetic resonance brain images, Comput. Methods Programs Biomed. 104 (3) (2011) E158–E177 . [314] J. Ashburner , et al. , Voxel-based morphometry - the methods, Neuroimage 11 (6) (2000) 805–821 . [275] V. Petrovi ć, Subjective tests for image fusion evaluation and objective metric vali- [315] D.L.G. Hill , et al. , Medical image registration, Phys. Med. Biol. 46 (3) (2001) dation, Inf. Fusion 8 (2) (2007) 208–216 . [276] H.R. Sheikh , et al. , Image information and visual quality, IEEE Trans. Image Pro- cess. 15 (2) (2006) 430–444 . [277] Y. Yang , et al. , User models of subjective image quality assessment on virtual viewpoint in free-viewpoint video system, Multimed. Tools Appl. 75 (20) (2016) 12499–12519 . [278] J. Du , et al. , An overview of multi-modal medical image fusion, Neurocomputing 215 (2016) 3–20 . [279] J. Du , et al. , An overview of multi-modal medical image fusion, Neurocomputing 215 (2016) 3–20 . [280] Y. Yang , et al. , Contourlet-based image quality assessment for synthesised virtual image, Electron. Lett. 46 (7) (2010) 492–493 . R1–R45 . [316] T. Rohlfing , et al. , Evaluation of atlas selection strategies for atlas-based image segmentation with application to confocal microscopy images of bee brains, Neu- roimage 21 (4) (2004) 1428–1442 . [317] A. Klein , et al. , Mindboggle: automated brain labeling with multiple atlases, BMC Med. Imaging 5 (2005) 7 . [318] X. Artaechevarria , et al. , Combination strategies in multi-atlas image segmentation: application to brain MR Data, IEEE Trans. Med. Imaging 28 (8) (2009) 1266–1277 . [319] T. Rohlfing , et al. , Performance-based classifier combination in atlas-based image segmentation using expectation-maximization parameter estimation, IEEE Trans. Med. Imaging 23 (8) (2004) 983–994 . [320] T. Rohlfing , et al. , Multi-classifier framework for atlas-based image segmentation, [281] Z. Wang , et al. , Image quality assessment: from error visibility to structural simi- Pattern Recognit. Lett. 26 (13) (2005) 2070–2079 . larity, IEEE Trans. Image Process. 13 (4) (2004) 600–612 . [321] F. Maes , et al. , Multimodality image registration by maximization of mutual infor- [282] Q.G. Miao , et al. , A novel algorithm of image fusion using shearlets, Opt. Commun. mation, IEEE Trans. Med. Imaging 16 (2) (1997) 187–198 . 284 (6) (2011) 1540–1547 . [283] M. Hossny , et al. , Comments on ’Information measure for performance of image fusion’, Electron. Lett. 44 (18) (2008) 1066–1067 . [284] Y. Horibe , Entropy and correlation, IEEE Trans. Syst. Man Cybern. SMC-15 (5) (1985) 641–642 . [285] A.M. Eskicioglu , et al. , Image quality measures and their performance, IEEE Trans. Commun. 43 (12) (1995) 2959–2965 . [286] A. Mittal , et al. , Making a "completely blind" image quality analyzer, IEEE Signal Process. Lett.. 20 (3) (2013) 209–212 . [287] H. Herzog , et al. , The current state, challenges and perspectives of MR-PET, Neu- roimage 49 (3) (2010) 2072–2208 . [288] H.-P.W. Schlemmer , et al. , Simultaneous MR/PET imaging of the human brain: feasibility study, Radiology 248 (3) (2008) 1028–1035 . [289] R. Grazioso , et al. , APD-based PET for combined MR-PET imaging, Proc. Intl. Soc. Mag. Reson. Med (2005) 408 . [290] B.E. Hamilton , et al. , Comparative analysis of ferumoxytol and gadoteridol en- hancement using T1-and T2-weighted MRI in neuroimaging, Am. J. Roentgenol. 197 (4) (2011) 981–988 . [291] M. Just , et al. , Tissue characterization with T1, T2, and proton density values: results in 160 patients with brain tumors, Radiology 169 (3) (1988) 779–785 . [292] S. Xie , Alcoholism identification based on an AlexNet transfer learning model, Front.Psychiatry 10 (2019) Article ID. 205 . [293] Y. Dawood , et al. , Novel imaging techniques to study postmortem human fetal anatomy: a systematic review on microfocus-CT and ultra-high-field MRI, Eur. Ra- diol. 30 (4) (2020) 2280–2292 . [294] E. Tuzzi , et al. , Ultra-high field mri in Alzheimer’s disease: effective transverse relaxation rate and quantitative susceptibility mapping of human brain in vivo and ex vivo compared to histology, J. Alzheimers Dis. 73 (4) (2020) 1481–1499 . [322] M. Sdika , Combining atlas based segmentation and intensity classification with nearest neighbor transform and accuracy weighted vote, Med. Image Anal. 14 (2) (2010) 219–226 . [323] A. Gholipour , et al. , Multi-atlas multi-shape segmentation of fetal brain MRI for volumetric and morphometric analysis of ventriculomegaly, Neuroimage 60 (3) (2012) 1819–1831 . [324] S. Gorthi , et al. , Weighted shape-based averaging with neighborhood prior model for multiple atlas fusion-based medical image segmentation, IEEE Signal Process Lett. 20 (11) (2013) 1036–1039 . [325] N. Garcia-Pedrajas , et al. , An empirical study of binary classifier fusion methods for multiclass classification, Inf. Fusion 12 (2) (2011) 111–130 . [326] H.F. Nweke , et al. , Data fusion and multiple classifier systems for human activity detection and health monitoring: review and open research directions, Inf. Fusion 46 (2019) 147–170 . [327] M.B. Yilmaz , et al. , Score level fusion of classifiers in off-line signature verification, Inf. Fusion 32 (2016) 109–119 . [328] P. Viswanath , et al. , Fusion of multiple approximate nearest neighbor classifiers for fast and efficient classification, Inf. Fusion 5 (4) (2004) 239–250 . [329] D. Castillo-Barnes , et al. , Robust ensemble classification methodology for I123-Ioflupane SPECT images and multiple heterogeneous biomarkers in the di- agnosis of Parkinson’s disease, Front. Neuroinform. 12 (2018) 16 Article ID. 53 . [330] J. Ramirez , et al. , Ensemble of random forests One vs. Rest classifiers for MCI and AD prediction using ANOVA cortical and subcortical feature selection and partial least squares, J. Neurosci. Methods 302 (2018) 47–57 . [331] L. Lam , et al. , Optimal combinations of pattern classifiers, Pattern Recognit. Lett. 16 (9) (1995) 945–954 . [332] K. Woods , et al. , Combination of multiple classifiers using local accuracy estimates, IEEE Trans. Pattern Anal. Mach. Intell. 19 (4) (1997) 405–410 . 185 Y.-D. Zhang, Z. Dong and S.-H. Wang et al. Information Fusion 64 (2020) 149–187 [333] G. Sedvall , et al. , Imaging of neurotransmitter receptors in the living human-brain, Arch. Gen. Psychiatry 43 (10) (1986) 995–1005 . [334] I. Shiri , et al. , Direct attenuation correction of brain PET images using only emission data via a deep convolutional encoder-decoder (Deep-DAC), Eur. Radiol. 29 (12) (2019) 6867–6879 . [335] I. Sarikaya , PET studies in epilepsy, Am. J. Nucl. Med. Mol. Imaging 5 (5) (2015) 416–430 . [336] T. Jones , et al. , History and future technical innovation in positron emission to- mography, J Med. Imaging 4 (1) (2017) 17 Article ID. 011013 . [337] B.H. Hasegawa , et al. , Dual-modality imaging: more than the sum of its com- ponents, in: H. Zaidi (Ed.), Quantitative Analysis in Nuclear Medicine Imaging, Springer US, Boston, MA, 2006, pp. 35–81. Editor. . [338] J. Lillington , et al. , PET/MRI attenuation estimation in the lung: a review of past, present, and potential techniques, Med. Phys. 47 (2) (2020) 790–811 . [339] H. Zaidi , et al. , Overview of nuclear medical imaging: physics and instrumentation, in: H. Zaidi (Ed.), Quantitative Analysis in Nuclear Medicine Imaging, Springer US, Boston, MA, 2006, pp. 1–34. Editor. . [340] V. Bettinardi , et al. , PET quantification: strategies for partial volume correction, Clin. Transl. Imaging 2 (3) (2014) 199–218 . [341] J. Dickson , et al. , Quantitative SPECT: the time is now, Ejnmmi Phys. 6 (2019) 7 64 . [342] A. Nordberg , et al. , The use of PET in Alzheimer disease, Nat. Rev. Neurol. 6 (2) (2010) 78–87 . [371] R.H. Huesman , A new fast algorithm for the evaluation of regions of interest and statistical uncertainty in computed-tomography, Phys. Med. Biol. 29 (5) (1984) 543–552 . [372] R.F. Muzic , et al. , A method to correct for scatter, spillover, and partial volume effects in region of interest analysis in PET, IEEE Trans. Med. Imaging 17 (2) (1998) 202–213 . [373] R.E. Carson , A maximum likelihood method for region-of-interest evaluation in emission tomography, J. Comput. Assist. Tomogr. 10 (4) (1986) 654–663 . [374] O.G. Rousset , et al. , Correction for partial volume effects in PET: principle and validation, J. Nucl. Med. 39 (5) (1998) 904–911 . [375] V. Frouin , et al. , Correction of partial-volume effect for PET striatal imaging: fast implementation and study of robustness, J. Nucl. Med. 43 (12) (2002) 1715–1726 . [376] Y. Du , et al. , Partial volume effect compensation for quantitative brain SPECT imag- ing, IEEE Trans. Med. Imaging 24 (8) (2005) 969–976 . [377] M. Sattarivand , et al. , Symmetric geometric transfer matrix partial volume correc- tion for PET imaging: principle, validation and robustness, Phys. Med. Biol. 57 (21) (2012) 7101–7116 . [378] F.C. Sureau , et al. , Impact of image-space resolution modeling for studies with the high-resolution research tomograph, J. Nucl. Med. 49 (6) (2008) 1000–1008 . [379] G. Akamatsu , et al. , Improvement in PET/CT image quality with a combination of point-spread function and time-of-flight in relation to reconstruction parameters, J. Nucl. Med. 53 (11) (2012) 1716–1722 . [380] F.L. Andersen , et al. , Clinical evaluation of PET image reconstruction using a spatial [343] N. Okamura , et al. , Brain imaging: applications of tau PET imaging, Nat. Rev. Neu- resolution model, Eur. J. Radiol. 82 (5) (2013) 862–869 . rol. 13 (4) (2017) 197–198 . [344] J. Seibyl , et al. , Impact of training method on the robustness of the visual assess- ment of 18F-Florbetaben PET scans: results from a phase-3 study, J. Nucl. Med. 57 (6) (2016) 900–906 . [345] A.D. Joshi , et al. , A semiautomated method for quantification of F 18 florbetapir PET images, J. Nucl. Med. 56 (11) (2015) 1736–1741 . [346] A. Marcoux , et al. , An automated pipeline for the analysis of PET data on the cor- tical surface, Front. Neuroinform. 12 (2018) 13 Article ID. 94 . [347] M. Tahmi , et al. , A fully automatic technique for precise localization and quantifi- cation of amyloid-beta PET scans, J. Nucl. Med. 60 (12) (2019) 1771–1779 . [348] B. Foster , et al. , A review on segmentation of positron emission tomography images, Comput. Biol. Med. 50 (2014) 76–96 . [349] K.R. Zasadny , et al. , Standardized uptake values of normal tissues at PET with 2-[fluorine-18]-fluoro-2-deoxy-D-glucose: variations with body weight and a method for correction, Radiology 189 (3) (1993) 847–850 . [350] C.K. Kim , et al. , Standardized uptake values of FDG: body surface area correction is preferable to body weight correction, J. Nucl. Med. 35 (1) (1994) 164–167 . [351] S. Basu , et al. , Quantitative techniques in PET-CT imaging, Curr. Med. Imaging Reviews 7 (3) (2011) 216–233 . [352] S.-C. Huang , Anatomy of SUV, Nucl. Med. Biol. 27 (7) (2000) 643–646 . [353] F.H. Fahey , et al. , Variability in PET quantitation within a multicenter consortium, Med. Phys. 37 (7) (2010) 3660–3666 . [354] B.F. Holman , et al. , Improved correction for the tissue fraction effect in lung PET/CT imaging, Phys. Med. Biol. 60 (18) (2015) 7387–7402 . [355] A. Rahmim , et al. , Resolution modeling in PET imaging: theory, practice, benefits, and pitfalls, Med. Phys. 40 (6) (2013) 064301 . [356] D.L. Bailey , et al. , Quantitative SPECT/CT: SPECT joins PET as a quantitative imag- ing modality, Eur. J. Nucl. Med. Mol. Imaging 41 (2014) S17–S25 . [357] P. Ritt , et al. , Absolute quantification in SPECT, Eur. J. Nucl. Med. Mol. Imaging 38 (1) (2011) 69–77 . [358] J.R. Yang , et al. , Partial volume correction for PET quantification and its impact on brain network in Alzheimer’s disease, Sci. Rep. 7 (2017) 14 Article ID. 13035 . [359] J.A.D. Aston , et al. , Positron emission tomography partial volume correction: esti- mation and algorithms, J. Cereb. Blood Flow Metab. 22 (8) (2002) 1019–1034 . [360] M. Soret , et al. , Partial-volume effect in PET tumor imaging, J. Nucl. Med. 48 (6) (2007) 932–945 . [361] O.G. Rousset , et al. , Correction for partial volume effects in emission tomography, in: H. Zaidi (Ed.), Quantitative Analysis in Nuclear Medicine Imaging, Springer US, Boston, MA, 2006, pp. 236–271 . [362] O. Rousset , et al. , Partial volume correction strategies in PET, PET Clin. 2 (2) (2007) 235–249 . [363] K. Erlandsson , et al. , A review of partial volume correction techniques for emission tomography and their applications in neurology, cardiology and oncology, Phys. Med. Biol. 57 (21) (2012) R119–R159 . [364] T.O. Videen , et al. , Regional correction of positron emission tomography data for the effects of cerebral atrophy, J. Cereb. Blood Flow Metab. 8 (5) (1988) 662–670 . [365] C.C. Meltzer , et al. , Correction of PET data for partial volume effects in human cerebral-cortex by MR imaging, J. Comput. Assist. Tomogr. 14 (4) (1990) 561–570 . [366] H.W. Mullergartner , et al. , Measurement of radiotracer concentration in brain gray–matter using positron emission tomography - MRI-based correction for partial vol- ume effects, J. Cereb. Blood Flow Metab. 12 (4) (1992) 571–583 . [367] C.C. Meltzer , et al. , MR-based correction of brain PET measurements for heteroge- neous gray matter radioactivity distribution, J. Cereb. Blood Flow Metab. 16 (4) (1996) 650–658 . [368] B.F. Hutton , et al. , Iterative reconstruction methods, in: H. Zaidi (Ed.), Quan- titative Analysis in Nuclear Medicine Imaging, Springer US, Boston, MA, 2006, pp. 107–140 . [369] S.M. Srinivas , et al. , A recovery coefficient method for partial volume correction of PET images, Ann. Nucl. Med. 23 (4) (2009) 341–348 . [370] C. Catana , et al. , PET/MRI for neurologic applications, J. Nucl. Med. 53 (12) (2012) 1916–1925 . [381] S.L. Bowen , et al. , Influence of the partial volume correction method on F-18-fluorodeoxyglucose brain kinetic modelling from dynamic PET images re- constructed with resolution model based OSEM, Phys. Med. Biol. 58 (20) (2013) 7081–7106 . [382] J.-B. Sibarita , Deconvolution microscopy, in: J Rietdorf (Ed.), Microscopy Tech- niques, Springer Berlin Heidelberg, Berlin, Heidelberg, 2005, pp. 201–243. Editor. . [383] N. Boussion , et al. , A multiresolution image based approach for correction of par- tial volume effects in emission tomography, Phys. Med. Biol. 51 (7) (2006) 1857–1876 . [384] M. Quarantelli , et al. , Integrated software for the analysis of brain PET/SPECT studies with partial-volume-effect correction, J. Nucl. Med. 45 (2) (2004) 192–201 . [385] C. Svarer , et al. , MR-based automatic delineation of volumes of interest in human brain PET images using probability maps, Neuroimage 24 (4) (2005) 969–979 . [386] H. Zaidi , et al. , Attenuation correction strategies in emission tomography, in: H. Zaidi (Ed.), Quantitative Analysis in Nuclear Medicine Imaging, Springer US, Boston, MA, 2006, pp. 167–204 . [387] A. Mehranian , et al. , Vision 20/20: magnetic resonance imaging-guided attenuation correction in PET/MRI: challenges, solutions, and opportunities, Med. Phys. 43 (3) (2016) 1130–1155 . [388] M. Hofmann , et al. , Towards quantitative PET/MRI: a review of MR-based attenu- ation correction techniques, Eur. J. Nucl. Med. Mol. Imaging 36 (2009) 93–104 . [389] H. Zaidi , et al. , Attenuation compensation in cerebral 3D PET: effect of the atten- uation map on absolute and relative quantitation, Eur. J. Nucl. Med. Mol. Imaging 31 (1) (2004) 52–63 . [390] B.T. Weinzapfel , et al. , Automated PET attenuation correction model for functional brain imaging, J. Nucl. Med. 42 (3) (2001) 483–491 . [391] H. Watabe , et al. , Acquisition of attenuation map for brain PET study using optical tracking system, in: J.A. Seibert (Ed.), IEEE Nuclear Science Symposium, Confer- ence Records, vols 1-4, Ieee, New York, 2002, pp. 1458–1461. Editor. . [392] J. Nuyts , et al. , Simultaneous maximum a posteriori reconstruction of attenuation and activity distributions from emission sinograms, IEEE Trans. Med. Imaging 18 (5) (1999) 393–403 . [393] J. Nuyts , et al. , Completion of a truncated attenuation image from the attenuated PET emission data, IEEE Trans. Med. Imaging 32 (2) (2013) 237–246 . [394] A. Rezaei , et al. , ML-reconstruction for TOF-PET with simultaneous estimation of the attenuation factors, IEEE Trans. Med. Imaging 33 (7) (2014) 1563–1572 . [395] D. Benoit , et al. , Optimized MLAA for quantitative non-TOF PET/MR of the brain, Phys. Med. Biol. 61 (24) (2016) 8854–8874 . [396] C.N. Ladefoged , et al. , A multi-centre evaluation of eleven clinically feasible brain PET/MRI attenuation correction techniques using a large cohort of patients, Neu- roimage 147 (2017) 346–359 . [397] D.L. Bailey , Transmission scanning in emission tomography, Eur. J. Nucl. Med. 25 (7) (1998) 774–787 . [398] T. Ichihara , et al. , Evaluation of SPET quantification of simultaneous emission and transmission imaging of the brain using a multidetector SPET system with the TEW scatter compensation method and fan-beam collimation, Eur. J. Nucl. Med. 23 (10) (1996) 1292–1299 . [399] K. Van Laere , et al. , Nonuniform transmission in brain SPECT using 201Tl, 153Gd, and 99mTc static line sources: anthropomorphic dosimetry studies and influence on brain quantification, J. Nucl. Med. 41 (12) (2000) 2051–2062 . [400] S. Brown , et al. , Investigation of the relationship between linear attenuation coef- ficients and CT Hounsfield units using radionuclides for SPECT, Appl. Radiat. Isot. 66 (9) (2008) 1206–1212 . [401] J.A. Patton , et al. , Image fusion using an integrated, dual-head coincidence camera with x-ray tube-based attenuation maps, J. Nucl. Med. 41 (8) (2000) 1364–1368 . [402] E.M. Kamel , et al. , Impact of metallic dental implants on CT-based attenuation correction in a combined PET/CT scanner, Eur. Radiol. 13 (4) (2003) 724–728 . [403] P.E. Kinahan , et al. , X-ray-based attenuation correction for positron emission tomography/computed tomography scanners, Semin. Nucl. Med. 33 (3) (2003) 166–179 . [404] J.P.J. Carney , et al. , Method for transforming CT images for attenuation correction in PET/CT imaging, Med. Phys. 33 (4) (2006) 976–983 . 186 Y.-D. Zhang, Z. Dong and S.-H. Wang et al. Information Fusion 64 (2020) 149–187 [405] S.D. Wollenweber , et al. , Evaluation of an atlas-based PET head attenuation cor- rection using PET/CT & MR patient data, IEEE Trans. Nucl. Sci. 60 (5) (2013) 3383–3390 . [406] R.Z. Stodilka , et al. , Scatter and attenuation correction for brain SPECT using at- tenuation distributions inferred from a head atlas, J. Nucl. Med. 41 (9) (2000) 1569–1578 . [407] H. Zaidi , et al. , Magnetic resonance imaging-guided attenuation and scatter correc- tions in three-dimensional brain positron emission tomography, Med. Phys. 30 (5) (2003) 937–948 . [408] G. Wagenknecht , et al. , Knowledge-based segmentation of attenuation-relevant re- gions of the head in T1-weighted MR images for attenuation correction in MR/PET systems, in: B. Yu (Ed.), 2009 IEEE Nuclear Science Symposium Conference Record, vols 1-5, Ieee, New York, 2009, p. 3338 . [409] J. Yang , et al. , Quantitative evaluation of atlas-based attenuation correction for brain PET in an integrated time-of-flight PET/MR imaging system, Radiology 284 (1) (2017) 169–179 . [410] H. Bal , et al. , Evaluation of MLACF based calculated attenuation brain PET imaging for FDG patient studies, Phys. Med. Biol. 62 (7) (2017) 2542–2558 . [411] J. Yang , et al. , Joint correction of attenuation and scatter in image space using deep convolutional neural networks for dedicated brain (18)F-FDG PET, Phys. Med. Biol. 64 (7) (2019) 075019 . [412] R. Le Goff-Rougetet , et al. , Segmented MR images for brain attenuation correction in PET, Med. Imaging. 2167 (1994) SPIE . [432] H. Zaidi , et al. , Scatter compensation techniques in PET, PET Clin 2 (2) (2007) 219–234 . [433] B.F. Hutton , et al. , Review and current status of SPECT scatter correction, Phys. Med. Biol. 56 (14) (2011) R85–R112 . [434] H. Zaidi , et al. , Scatter correction strategies in emission tomography, in: H. Zaidi (Ed.), Quantitative Analysis in Nuclear Medicine Imaging, Springer US, Boston, MA, 2006, pp. 205–235. Editor . [435] J. Kupferschlaeger , et al. , Absolute quantification in SPECT - a phantom study, Eur. J. Nucl. Med. Mol. Imaging 42 (2015) S148–S149 . [436] R.J. Jaszczak , et al. , Improved SPECT quantification using compensation for scat- tered photons, J. Nucl. Med. 25 (8) (1984) 893–900 . [437] S. Grootoonk , et al. , Correction for scatter in 3D brain PET using a dual energy window method, Phys. Med. Biol. 41 (12) (1996) 2757–2774 . [438] T. Ichihara , et al. , Compton scatter compensation using the triple-energy win- dow method for single- and dual-isotope SPECT, J. Nucl. Med. 34 (12) (1993) 2216–2221 . [439] L. Shao , et al. , Triple energy window scatter correction technique in PET, IEEE Trans. Med. Imaging 13 (4) (1994) 641–648 . [440] K.F. Koral , et al. , SPECT Compton-scattering correction by analysis of energy spec- tra, J. Nucl. Med. 29 (2) (1988) 195–202 . [441] M. Bentourkia , et al. , Energy dependence of scatter components in multispectral PET imaging, IEEE Trans. Med. Imaging 14 (1) (1995) 138–145 . [442] T. Hasegawa , et al. , A Monte Carlo simulation study on coarse septa for scatter [413] V. Keereman , et al. , MRI-based attenuation correction for pet/mri using ultrashort correction in 3-D PET, IEEE Trans. Nucl. Sci. 49 (5) (2002) 2133–2138 . echo time sequences, J. Nucl. Med. 51 (5) (2010) 812–818 . [414] A. Martinez-Moller , et al. , Tissue classification as a potential approach for atten- uation correction in whole-body PET/MRI: evaluation with PET/CT data, J. Nucl. Med. 50 (4) (2009) 520–526 . [415] Y. Berker , et al. , MRI-based attenuation correction for hybrid PET/MRI sys- tems: a 4-class tissue segmentation technique using a combined ultrashort-echo–time/dixon MRI sequence, J. Nucl. Med. 53 (5) (2012) 796–804 . [416] F.L. Andersen , et al. , Combined PET/MR imaging in neurology: MR-based attenu- ation correction implies a strong spatial bias when ignoring bone, Neuroimage 84 (2014) 206–216 . [417] A.F. Kazerooni , et al. , Generation of MR-based attenuation correction map of PET images in the brain employing joint segmentation of skull and soft-tissue from sin- gle short-TE MR imaging modality, in: F. Gao, K. Shi, S. Li (Eds.), Computational Methods for Molecular Imaging, Springer International Publishing: Cham, 2015, pp. 139–147. Editors. . [418] P. Khateri , et al. , Generation of a four-class attenuation map for MRI-based at- tenuation correction of PET data in the head area using a novel combination of STE/Dixon-MRI and FCM clustering, Mol. Imaging Biol. 17 (6) (2015) 884–892 . [419] F. Wiesinger , et al. , Zero TE MR bone imaging in the head, Magn. Reson. Med. 75 (1) (2016) 107–114 . [420] J. Yang , et al. , Evaluation of sinus/edge-corrected zero-echo-time-based attenua- tion correction in brain PET/MRI, J. Nucl. Med. 58 (11) (2017) 1873–1879 . [421] G. Delso , et al. , Improving PET/MR brain quantitation with template-enhanced ZTE, Neuroimage 181 (2018) 403–413 . [422] J.M. Sousa , et al. , Evaluation of zero-echo-time attenuation correction for in- tegrated PET/MR brain imaging-comparison to head atlas and (68)Ge-transmis- sion-based attenuation correction, EJNMMI Phys. 5 (1) (2018) 20 . [423] B. Sgard , et al. , ZTE MR-based attenuation correction in brain FDG-PET/MR: performance in patients with cognitive impairment, Eur. Radiol. 30 (3) (2020) 1770–1779 . [424] S. Roy , et al. , PET attenuation correction using synthetic CT from ultrashort echo–time MR imaging, J. Nucl. Med. 55 (12) (2014) 2071–2077 . [425] C.B. Poynton , et al. , Probabilistic atlas-based segmentation of combined T1-weighted and DUTE MRI for calculation of head attenuation maps in integrated PET/MRI scanners, Am. J. Nucl. Med. Mol. Imaging 4 (2) (2014) 160–171 . [426] G. Delso , et al. , Cluster-based segmentation of dual-echo ultra-short echo time im- ages for PET/MR bone localization, EJNMMI Phys. 1 (1) (2014) 7 . [427] A. Johanson , et al. , Improved quality of computed tomography substitute derived from magnetic resonance (MR) data by incorporation of spatial information - po- tential application for MR-only radiotherapy and attenuation correction in positron emission tomography, Acta Oncol. (Madr) 52 (7) (2013) 1369–1373 . [428] L.-T. Chang , A method for attenuation correction in radionuclide computed tomog- raphy, IEEE Trans. Nucl. Sci. 25 (1) (1978) 638–643 . [429] L.A. Shepp , et al. , Maximum likelihood reconstruction for emission tomography, IEEE Trans. Med. Imaging 1 (2) (1982) 113–122 . [430] K. Lange , et al. , EM reconstruction algorithms for emission and transmission to- mography, J. Comput. Assist. Tomogr. 8 (2) (1984) 306–316 . [431] G.T. Gullberg , et al. , An attenuated projector-backprojector for iterative SPECT reconstruction, Phys. Med. Biol. 30 (8) (1985) 799–816 . [443] K.S. Chuang , et al. , Novel scatter correction for three-dimensional positron emission tomography by use of a beam stopper device, Nucl. Instrum. Methods Phys. Res.h Section A 551 (2-3) (2005) 540–552 . [444] H.T. Chen , et al. , A fast, energy-dependent scatter reduction method for 3D PET imaging, in: S.D. Metzler (Ed.), IEEE Nuclear Science Symposium, Conference Record, Vols 1-5, IEEE, Portland, OR, 2004, pp. 2630–2634 . [445] L.M. Popescu , et al. , PET energy-based scatter estimation and image reconstruction with energy-dependent corrections, Phys. Med. Biol. 51 (11) (2006) 2919–2937 . [446] D.L. Bailey , et al. , A convolution-subtraction scatter correction method for 3d PET, Phys. Med. Biol. 39 (3) (1994) 411–424 . [447] S.R. Meikle , et al. , A transmission-dependent method for scatter correction in SPECT, J. Nucl. Med. 35 (2) (1994) 360–367 . [448] M. Lubberink , et al. , Non-stationary convolution subtraction scatter correc- tion with a dual-exponential scatter kernel for the Hamamatsu SHR-7700 an- imal PET scanner, Phys. Med. Biol. 49 (5) (2004) 833–842 Article ID. Pii s0031-9155(04)69622-9 . [449] B. Bendriem , et al. , A technique for the correction of scattered radiation in a PET system using time-of-flight information, J. Comput. Assist. Tomogr. 10 (2) (1986) 287–295 . [450] C.S. Levin , et al. , A Monte-Carlo correction for the effect of compton-scattering in 3-d PET brain imaging, IEEE Trans. Nucl. Sci. 42 (4) (1995) 1181–1185 . [451] C.C. Watson , New, faster, image-base , d scatter correction for 3D PET, IEEE Trans. Nucl. Sci. 47 (4) (2000) 1587–1594 . [452] R. Accorsi , et al. , Optimization of a fully 3D single scatter simulation algo- rithm for 3D PET, Phys. Med. Biol. 49 (12) (2004) 2577–2598 Article ID. PII s0031-9155(04)70798-8 . [453] F.J. Beekman , et al. , Efficient fully 3-D iterative SPECT reconstruction with Monte Carlo-based scatter compensation, IEEE Trans. Med. Imaging 21 (8) (2002) 867–877 . [454] A. Cot , et al. , Absolute quantification in dopaminergic neurotransmission SPECT using a Monte Carlo-based scatter correction and fully 3-dimensional reconstruc- tion, J. Nucl. Med. 46 (9) (2005) 1497–1504 . [455] D. Lazaro , et al. , Fully 3D Monte Carlo reconstruction in SPECT: a feasibility study, Phys. Med. Biol. 50 (16) (2005) 3739–3754 . [456] D. Salas-Gonzalez , et al. , Linear intensity normalization of FP-CIT SPECT brain images using the alpha-stable distribution, Neuroimage 65 (2013) 449–455 . [457] D. Castillo-Barnes , et al. , On a heavy-tailed intensity normalization of the parkin- son’s progression markers initiative brain database, in: J.M.F. Vicente, et al. (Eds.), Natural and Artificial Computation for Biomedicine and Neuroscience, Pt I, Springer International Publishing Ag, Cham, 2017, pp. 298–304 . [458] A. Brahim , et al. , Comparison between different intensity normalization methods in 123I-Ioflupane imaging for the automatic detection of parkinsonism, PLoS ONE 10 (6) (2015) e0130274 . [459] A. D’Andrea , et al. , The role of multimodality imaging in COVID-19 patients: from diagnosis to clinical monitoring and prognosis, Giornale Italiano Di Cardio Logia 21 (5) (2020) 345–353 . [460] J.M. Górriz, et al., Artificial intelligence within the interplay between natural and artificial Computation: advances in data science, trends and applications, Neuro- computing (2020), doi: 10.1016/j.neucom.2020.05.078 . 187 