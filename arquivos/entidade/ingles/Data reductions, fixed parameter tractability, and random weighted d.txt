Artificial Intelligence 173 (2009) 1343–1366Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintData reductions, fixed parameter tractability, and random weightedd-CNF satisfiability ✩Yong GaoDepartment of Computer Science, Irving K. Barber School of Arts and Sciences, University of British Columbia Okanagan, Kelowna, Canada V1V 1V7a r t i c l ei n f oa b s t r a c tArticle history:Received 19 December 2008Received in revised form 11 June 2009Accepted 13 June 2009Available online 17 June 2009Keywords:Weighted CNF satisfiabilityFixed parameter tractabilityData reductionRandom instancesPhase transitionsProbabilistic analysisResolution complexityData reduction is a key technique in the study of fixed parameter algorithms. In the AIliterature, pruning techniques based on simple and efficient-to-implement reduction rulesalso play a crucial role in the success of many industrial-strength solvers. Understandingthe effectiveness and the applicability of data reduction as a technique for designingheuristics for intractable problems has been one of the main motivations in studying thephase transition of randomly-generated instances of NP-complete problems.In this paper, we take the initiative to study the power of data reductions in the contextof random instances of a generic intractable parameterized problem, the weighted d-CNFsatisfiability problem. We propose a non-trivial random model for the problem and studythe probabilistic behavior of the random instances from the model. We design an algorithmbased on data reduction and other algorithmic techniques and prove that the algorithmsolves the random instances with high probability and in fixed-parameter polynomial timeO (dknm) where n is the number of variables, m is the number of clauses, and k is thefixed parameter. We establish the exact threshold of the phase transition of the solutionprobability and show that in some region of the problem space, unsatisfiable randominstances of the problem have parametric resolution proof of fixed-parameter polynomialsize. Also discussed is a more general random model and the generalization of the resultsto the model.© 2009 Elsevier B.V. All rights reserved.1. IntroductionThe theory of parameterized complexity and fixed-parameter algorithms is becoming an active research area in recentyears [24,46]. Parameterized complexity provides a new perspective on hard algorithmic problems and fixed-parameteralgorithms have found applications in a variety of research fields. Parameterized problems also arise in many areas ofartificial intelligence (AI) research, including satisfiability, automated reasoning, logic programming, constraint programming,and probabilistic inference [8,10,47,48]. We refer the reader to [34,35] for thorough survey of recent literature.Data reduction is a key technique in designing efficient algorithms for fixed parameter tractable problems [37,46] andexact exponential-time branch-and-reduce algorithms (also known as the search-tree method) for NP-hard problems [27].In several areas of AI, pruning techniques based on simple and efficient-to-implement reduction rules have also been widelyused, most notably in satisfiability testing and constraint processing where backtracking interleaved with the use of highly-efficient implementation of unit propagation and consistency propagation has played a key role in the success of most✩Part of the results appeared in the Proceedings of AAAI’08 [Y. Gao, Phase transitions and complexity of weighted satisfiability and other intractableparameterized problems, in: Proceedings of the 23th AAAI Conference on Artificial Intelligence (AAAI’08), 2008, pp. 265–270. [28]]. The research is supportedby National Science and Engineering Research Council of Canada (NSERC) RGPIN 327587-06 and RGPIN 327587-09.E-mail address: yong.gao@ubc.ca.0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2009.06.0051344Y. Gao / Artificial Intelligence 173 (2009) 1343–1366industrial-strength solvers, and in heuristic state space search where a heuristic function is usually employed to reducethe search space. The power of data reductions have also been demonstrated empirically for many NP-hard problems orintractable parameterized problems such as clique cover [36], dominating set [4], road network related problem [50], andHamiltonian cycle [49]. Experiments also revealed that simple data reduction rules usually have a much better performancethan those predicted by theoretical analyses [11,36,40].Despite the many success stories, our understanding of the effectiveness and the applicability of data reduction as atechnique for designing heuristics for intractable problems is far from complete. The continued interest over the past morethan ten years in the study of the phase transition phenomenon of random instances of NP-complete problems is largelymotivated by the expectation that such study will help shed lights on why simple heuristics work on typical probleminstances and in what situations. See [1,7,14,19,20,30–33,38,51] and references therein. Recently, the problem of detectingbackdoor sets has attracted much attention. The existence of small-sized backdoors naturally leads to efficient algorithms forproblems that are otherwise hard to solve. While the backdoor detection problem are NP-complete and/or fixed-parameterintractable for many types of backdoors, practical SAT-solvers have been found to be able to exploit the existence of small-sized backdoors effectively [23,48].In this work, we take the initiative to extend this line of research on phase transitions to intractable parameterized prob-lems. We hope that the current work on the fixed-parameter tractability of random instances of intractable parameterizedproblems, together with the previous work on the typical-case behavior of random NP-complete problems, will help shedfurther light on the power of data-reduction based heuristics and on the hardness of detecting small-sized backdoors.We study random instances of the weighted d-CNF satisfiability problem (WEIGHTED d-SAT).1 An instance (F , k) of theproblem consists of a d-CNF formula F and a fixed parameter k > 0. The question is to decide if there is a satisfyingassignment that has a Hamming distance k to the all-zero assignment.A random instance of weighted d-CNF satisfiability over n Boolean variables consists of a fixed parameter k and a randomd-CNF formula F n,pk,d generated as follows: for each subset of d variables and with probability p = p(n), a clause over the dvariables is selected uniformly at random from the set of 2d − 1 possible clauses that contain at least one negated literal.This random model of CNF formulas is similar to the various random models used in the study of the standard propositionalsatisfiability problem. Due to a recent result of Marx [41] on the complexity of parameterized Boolean constraint satisfac-tion problems, forbidding clauses that contain positive literals only is not a serious restriction as far as the parameterizedtractability is concerned. A more detailed argument about this will be given in Section 2.We also discuss a more general model F n,pWe design and analyze an algorithm based on data reduction and other algorithmic techniques. It is shown that thealgorithm solves random instances from F n,pk,d with high probability and in fixed-parameter polynomial time O (dknm) wheren is the number of variables and m is the number of clauses in the formula. We establish the exact threshold of the phasetransition of the solution probability and show that in some region of the problem space, unsatisfiable random instances ofthe problem have parametric resolution proof of fixed-parameter polynomial size. The results obtained in this paper give analmost complete characterization of the typical-case behavior of the random instances of WEIGHTED d-SAT.(cid:2)), 1 < dnegated literals areforbidden. Except for the exact threshold of the phase transition and the complexity of typical instances for certain rangeof p, this model seems to pose an interesting challenge for researchers in the areas of AI and theoretical computer science.To the best knowledge of the author, this work is the first in the literature on the fixed-parameter tractability of randominstances of intractable parameterized problems. We expect that the proposed random models and their analysis will helpfacilitate future studies on other parameterized problems such as the backdoor detection problem, on the solution spacegeometry of the standard satisfiability problem, and on the design of more effective neighborhood operators for local searchalgorithms.(cid:2) < d, where clauses containing less than dk,d (d(cid:2)1.1. Main resultsThroughout this paper, we will use n for the number of Boolean variables, m for the number of clauses, and d for theclause size in a CNF formula. We will use k for the parameter of the WEIGHTED d-SAT problem. The symbol p = p(n) isreserved for the clause probability and c for a constant usually appearing in the expression of p. All logarithms in this paperare natural logarithms, i.e., to the base e.The main results of this paper include(1) an algorithm and its analysis showing that instances from the random distribution F n,pcally” fixed-parameter tractable for any clause-probability p(n), in particularly for p = c log n(2) the exact threshold of the phase transition of F n,pk,d ,(3) results on the parametric resolution complexity of random unsatisfiable instances, and(4) extension of some of the above results to a more general model F n,p(cid:2)).k,d (dk,d of WEIGHTED d-SAT are “typi-nd−1 where c > 0 is a constant,1 In AI literature, k is usually used for clause size. Unfortunately, in the study of parameterized algorithms, k is always reserved for the parameter. Wedecide to use k as the parameter and use d for the clause size.Table 1The behavior of random instances from F n,punknown. c∗is the threshold for the corresponding model.k,d . A markY. Gao / Artificial Intelligence 173 (2009) 1343–13661345√indicates that the case is completely resolved. A question mark indicates that the case is completelyParametersThresholdFPT?d = 2d > 2d = 2d > 2d = 2d > 2√√√√(Th. 2)(Th. 2)(Th. 2)(Th. 2)N/A√(Th. 5)WEIGHTED d-SAT F n,pk,d√√(Th. 1)(Th. 1)Renormalized version of WEIGHTED d-SAT F n,pk,dWEIGHTED d-SAT F n,pk,d (d(cid:2)), 1 < d∗c > cc > kc(Th. 4)∗(Corol. 1.1)(cid:2) < dN/Ac > 2c∗(Th. 6)N/Ac > 2d(cid:2)(k − d(cid:2))2c∗(Th. 6)FPTProof size?√(Th. 4)∗c > 2k2c(Th. 3)∗c > c?(Th. 4)Theorem 1. There is an O (dknm)-time algorithm that solves with high probability a random instance (F n,pfor any p = p(n) (cid:2) 1 where m is the number of clauses in the formula.k,d , k) of WEIGHTED d-SATThe term dk in the above theorem is due to the fact that we need to solve subproblems that are equivalent to theparameterized (d − 1)-hitting set problem. In the case of d = 2, the term dk can be replaced by k. As the proof of Theorem 1indicates, if every variable is only involved in l clauses, the term dk can be replaced by 2ld, i.e. the running time of thebrute-force method for the relevant subproblems. Depending on the relation between l, k, and n, these bounds may beworse than O (dk), such as the case of p(n) ∈ Ω( k log nnd−1 ), or better than O (dk), such as the case of p(n) (cid:2) log nnd−1 .For random instances of the renormalized version of WEIGHTED d-SAT [46] where the question is to find a satisfyingassignment of weight k log n, we show that the same algorithm in the above theorem still works if the clause probabilityp(n) is in a certain range:Corollary 1.1. There is an O (dknm) algorithm that solves with high probability a random instance (F n,pof WEIGHTED d-SAT for any p = c log nnd−1 with c > k(2d − 1)(d − 1)!.k,d , k) of the renormalized versionTo get a clear picture of the behavior of random instances of F n,pk,d , it is helpful to understand the phase transition oftheir solution probability. We establish the following exact threshold of the phase transition. Note that the threshold doesnot depend on the fixed parameter k, which is somewhat surprising.Theorem 2. Let p = c log nnd−1 with c > 0 being a constant. Consider a random instance (F n,pk,d , k) of WEIGHTED d-SAT. We have(cid:2)Plimn→∞F n,pk,d is satisfiable(cid:4)(cid:3)=1,0,if c < cif c > c∗,∗,(1.1)where c∗ = (2d − 1)(d − 1)!. For the case of d = 2 and d = 3, the thresholds are respectively c∗ = 3 and c∗ = 14.For unsatisfiable instances, it is not clear whether or not the algorithm in Theorem 1 can be simulated by a resolutionproof. But a similar idea does lead to the followingTheorem 3. Let p = c log na resolution proof of size O (dkn), and can be constructed in O (dk)n O (1) time.nd−1 with c > 2k2(2d − 1)(d − 1)!. With high probability, a random instance (F n,pk,d , k) of WEIGHTED d-SAT hasFor the case of WEIGHTED 2-SAT and its renormalized version, random unsatisfiable instances can be shown to have aresolution proof of size O (kn):Theorem 4. For F n,pnand can be constructed in O (k)n O (1) time.k,2 where p = 3(log n+c1 log log n)with c1 > 1, a parametric resolution proof of size O (kn) exists with high probabilityIn Table 1, we summarize the results obtained in this paper on the behavior of F n,pk,d .13461.2. OutlineY. Gao / Artificial Intelligence 173 (2009) 1343–1366The next section contains preliminaries, a detailed description of the random model F n,pk,d , and related work. In Section 3,we present the details of our fixed-parameter algorithm, W-SAT. In Section 4, we prove that the algorithm W-SAT succeedswith high probability for random instances of WEIGHTED d-SAT. In Section 5, we establish the exact threshold of the phasetransition of the solution probability. In Section 6, we prove the results on the resolution complexity of random instances ofWEIGHTED d-SAT. In Section 7, we discuss how the algorithm and its analysis can be extended to random instances of the(cid:2)) and some results on itsrenormalized version of WEIGHTED d-SAT. In Section 8, we discuss a generalized model F n,pthreshold and resolution complexity. In the last section, we conclude and discuss directions for future work. Some necessarylemmas and their proof are included in the three appendices, which are interesting in their own right.k,d (d2. Preliminaries, random models, and related work2.1. Parameterized complexityAn instance of a parameterized decision problem [24,46] is a pair (I, k) where I is a problem instance and k is a fixedproblem parameter. Usually, the parameter k either specifies the “size” of the desired solution or is related to some structuralproperty of the underlying problem, such as the treewidth of a graph. For example, in an instance (I, k) of the parameterizedvertex cover problem, I is a graph and k is the size of the vertex cover. The question is to decide whether I has a vertexcover of size at most k.Whereas for fixed k, the vertex cover problem can be solved by brute-force in O (nk) time, the theory of parameterizedcomplexity is concerned with whether or not there is an algorithm whose worst-case running time avoids the exponentialdependency between the problem size n and the parameter k.A parameterized problem is fixed-parameter tractable (FPT) if there is an algorithm that solves any instance (I, k) inf (k)|I|O (1) time, where f (k) is a computable function that depends only on k. For example, it is known that the parame-terized vertex cover problem is FPT since it can be solved in O (1.28k + kn) time where n is the number of vertices of thegraph [46].Parameterized problems are inter-related by parameterized reductions, resulting in a classification of parameterized prob-lems into a hierarchy of complexity classesFPT ⊆ W[1] ⊆ W[2] ⊆ · · · ⊆ XP.At the lowest level is the class of FPT problems. The class W[1] contains all parameterized problems that can be reduced tothe weighted 2-CNF satisfiability problem to be defined in the next subsection. The top level XP contains all the problemsthat can be solved in time f (k)ng(k). It is widely believed that the containment is strict and the notion of completenesscan be defined via parameterized reductions [24,46]. Unless FPT = W[1], it is likely that no algorithm for WEIGHTED d-SAT(d (cid:3) 2) can be more efficient that the O (nk)-time brute-force algorithm that enumerates all theassignments. It has beenshown recently that under an even stronger assumption, it is unlikely to solve WEIGHTED d-SAT in time no(k) [16]. It canbe proved that “P = NP” implies “FTP = W[1]”.(cid:5)nk(cid:6)2.2. Weighted CNF satisfiability problemAs with the theory of NP-completeness, the satisfiability problem plays an important role in the theory of parameter-ized complexity. A CNF formula over a set of Boolean variables is a conjunction of disjunctions of literals. A d-clause is adisjunction of d-literals. A d-CNF formula is a CNF formula that consists of d-clauses only.Definition 2.1. An assignment to a set of n Boolean variables is a vector in {TRUE, FALSE}n. The weight of an assignment isthe number of the variables that are set to TRUE in the assignment.It is convenient to identify TRUE with 1 and FALSE with 0. Thus, an assignment can be regarded as a vector in {0, 1}nand the weight of an assignment is just its Hamming distance to the all-zero assignment.A representative W [1]-complete problem is the following weighted d-CNF satisfiability problem [46]:Problem 1 (WEIGHTED d-SAT).Instance: A CNF formula consisting of a collection of d-clauses.Parameter: A positive integer k.Question: Is there a satisfying assignment of weight k?Unlike the situation with the standard satisfiability problem, WEIGHTED d-SAT is already W[1]-complete for d = 2, andconsequently is intractable from the perspective of parameterized complexity. It is a recent interest to consider the renor-malization of a parameterized problem. The renormalized version of WEIGHTED d-SAT is as follows [46]:Y. Gao / Artificial Intelligence 173 (2009) 1343–13661347Problem 2 (MINI-WEIGHTED d-SAT).Instance: A CNF formula consisting of a collection of d-clauses.Parameter: A positive integer k.Question: Is there a satisfying assignment of weight k log n?2.3. Parameterized proof systems and parameterized DPLL algorithmsThe study of the parameterized proof complexity of weighted CNF satisfiability has been recently initiated by Dantchevet al. [22], who established lower bounds on the parameterized resolution proof for CNF formulas that encode some first-order combinatorial principle. A formal definition of a parameterized tree-like resolution proof system for weighted CNFsatisfiability is given in [22]. Basically, a parameterized resolution system for an instance of a co-W[2] problem can beregarded as a classical resolution system that has access for free to all clauses with more than k negated variables, wherek is the parameter of the weighted satisfiability. For instances of a co-W[1] complete problem, we also need the free accessto all clauses that contain more than n − k positive literals since a contradiction for a co-W[1] complete problem such asWEIGHTED d-SAT is “the formula doesn’t have a satisfying assignment of weight exactly k”.Accordingly, one can consider the parameterized version of the DPLL algorithm for the satisfiability problem. It proceedsin the same way as the standard DPLL algorithm with the exception that a node in the search tree fails if either(1) a clause has been falsified by the partial assignment, or(2) more than k variables have been assigned to true in the partial assignment.2.4. Random models for WEIGHTED d-SATWe use G(n, p) to denote the Erdös–Rényi random graph [12] where n is the number of vertices, p is the edge prob-(cid:5)edges appears independently with probability p. A random hypergraph G(n, p, d) is anability, and each of the possible(cid:6)(cid:5)2npossible hyperedges appears independently with probability p. Throughout this paper byhypergraph where each of thed“with high probability”, abbreviated as whp, we mean that the probability of the event under consideration is 1 − o(1) as ngoes to infinity.(cid:6)We will be working with the following random model for WEIGHTED d-SAT. The model is similar in spirit to the well-known random models in the study of the standard (constraint) satisfiability. See [30,33,44] and the references therein.Definition 2.2. Let X = {x1, . . . , xn} be a set of Boolean variables, p = p(n) be a function of n, and k and d be two positiveconstants. The random model F n,pk,d for WEIGHTED d-SAT is defined as follows:To generate an instance from F n,pk,d , we first construct a random hypergraph G(n, p, d) using X as the vertex set. For each}, we select a d-clause uniformly at random from the set of 2d − 1 non-monotone d-clauses defined}. (A monotone clause is a clause that contains positive literals only.)hyperedge {xi1 , . . . , xidover the variables {xi1 , . . . , xidNote that since monotone clauses are forbidden in F n,pnote that the range of the clause probability we are primarily interested in is p(n) = c log nnd−1explain in the following the rationale of doing so.k,d , the all-zero assignment is always a satisfying assignment. Alsofor some constant c > 0. We2.4.1. WEIGHTED d-SAT instances reduce to instances with monotone clauses forbiddenIn [41], Marx studied the complexity of general parameterized Boolean constraint satisfaction problems, which he callsWEIGHTED F -SAT. He proved that F -SAT is fixed-parameter tractable if either every variable has a bounded number ofoccurrences or the constraints are weakly separable. In the mean time, Marx showed the W[1]-completeness for the casewhere the implication clause x → y is the only type of constraints. In proving these results, Marx observed that it issufficient to consider constraints that are 0-valid, i.e., constraints that are always satisfied by the all-zero assignment. Westate in the following Marx’s observation in terms of WEIGHTED d-SAT:Lemma 2.1. (See Lemma 4.1, Marx [41].) An instance (F , k) of WEIGHTED d-SAT can be reduced to dk WEIGHTED d-SAT instances inwhich monotone clauses are forbidden.In view of the above lemma, we believe that F n,pk,d is a natural model that captures the essential characteristics of aWEIGHTED d-SAT instance.We also remark that when the clause-probability p(n) (cid:3) c log nfor some constant c, as is the case discussed in this paper,nd−1the number of variables that have a bounded number of occurrences is o(1) whp, so that Marx’s result [41] on the fixed-parameter tractability of F -SAT with bounded variable occurrences does not apply to the random instances we are dealingwith.1348Y. Gao / Artificial Intelligence 173 (2009) 1343–13662.4.2. Relation to planted models for standard SATEven though a random instance of F n,pk,d always has the all-zero assignment as a planted solution (in the sense of standardsatisfiability), what WEIGHTED d-SAT asks for is a weight-k satisfying assignment, i.e., a satisfying assignment with Ham-ming distance exactly k to the all-zero assignment. This is the major difference between the WEIGHTED d-SAT instancesconsidered in this paper and the standard SAT instances with hidden solutions studied in the literature. See, for example,[1,38,51] and references therein.2.4.3. Trivial random instancesWe note that without forbidding monotone clauses or for p(n) = o( log nnd−1 ), random instances of WEIGHTED d-SAT aretrivial. This can be proved by simple random-graph arguments. We state the following observations and give the proofin Appendix C.Lemma 2.2.(1) If in F n,pk,d monotone clauses are not forbidden, then whp there exist k disjoint monotone clauses unless p(n) is extremely small.Consequently, a random instance is unsatisfiable whp.(2) If p(n) = c log nnd−1 and c is a small enough constant2 or if p(n) ∈ o( log nk,d are trivially satisfiable dueto the existence of a large number of variables x that are “isolated” in the sense that x does not appear as a negated literal inany clause (or, we may want to call them positive pure literals). Simply setting k of these positive pure literals to TRUE and theremaining variables to FALSE gives us a weight-k satisfying assignment.nd−1 ), random instances from F n,p2.5. Relation to other random models for d-CNF formulasIn the study of the phase transition of the standard CNF satisfiability problem, several slightly different random modelshave been used. The most widely-studied model is F (n, m) on n Boolean variables where m clauses are selected from all(cid:5)nthed(cid:6)2d possible clauses uniformly at random, with or without replacement.A common aspect of these models is that for the range of m that is of interest, the likelihood is extremely low for arandom formula to contain two clauses over the same set of d variables. To convince the reader, we briefly show in thefollowing why this is the case. Let {C1, C2, . . . , Cm} be the m clauses selected with replacement uniformly at random from(cid:6)2d possible clauses. Then, for any i (cid:9)= j, the probability that Ci and C j are defined over the same set of d variables isthe(cid:5)nd2d(cid:6) .(cid:5)ndThe expected number of pairs of clauses that are over the same set of d variables is(cid:8)(cid:7)m22d(cid:6) .(cid:5)ndd2 ), d > 2, the probability that two clauses in F (n, m) are over the same setBy Markov’s inequality, we see that for m = o(nof d variables is asymptotically zero.(cid:6)(cid:5)n2In this paper, we study the random model F n,pIn the theory of random graphs, there are also two closely related random models G(n, p) and G(n, m). In G(n, p) eachedges appears independently with probability p. In G(n, m), m edges are selected uniformly at random(cid:6)of the possiblewithout replacement. It turns out that in most of the situations, it is more pleasant to work with the model G(n, p).(cid:5)ndpossible subsets of d variables appears in the formula with probability p. The decision to focus on this model is largelydue to technical convenience. Since all the properties we are concerned with in this paper, including the satisfiability, theexistence of k-frozen variables, and the size of the connected components of a CNF formula, are monotone, we can regardthe model F n,pclauses are selected uniformly at random as being equivalent, just as the case ofrandom graphs (Theorem 2.2 [12]).k,d where exactly one of the 2d − 1 clauses defined on each of thek,d and the model where p(cid:5)nd(cid:6)The fact that in all of these models, two clauses over the same set of variables rarely appear together is indeed a limi-tation. This is one of the reasons that in the study of the probabilistic behavior of standard CNF formulas, researchers alsostudy random models of the so-called generalized satisfiability problem where for each set of randomly selected variables,several clauses are selected. We believe that results similar to those in this paper can also be obtained for random instancesof the generalized satisfiability problem and the constraint satisfaction problem.2 For the case of d = 2, c < 32 .2.6. Residual graphs of CNF formulas and induced formulasY. Gao / Artificial Intelligence 173 (2009) 1343–13661349Associated with a CNF formula is its residual graph (also known as Gaifman graph) over the set of variables involvedin the formula. There is an edge between two variables if they both occur in some clause. The residual graph of a randominstance of F n,pk,d is the primal graph3of the random hypergraph G(n, p, d).k,2 is exactly the random graph G(n, p). The residual graph of a random instance of F n,pBy a connected component of a CNF formula F , we mean a maximal sub-formula F (cid:2)is a connected component of the residual graph of the CNF formula F .Let F be a d-CNF formula and V ⊂ X be a subset of variables. The induced formula FV over V is defined as a CNFsuch that the residual graph ofF (cid:2)formula FV that consists of the following two types of clauses:(1) the clauses of F that only involve the variables in V ;(2) the clauses of size at least 2 obtained by removing any literal whose corresponding variable is in X \ V .Note that for the case of 2-CNF formulas, FV contains clauses of the first type only. In the above definition of an inducedformula on V , we do not include “induced” unit clauses, i.e. clauses of size 1 obtained by removing any literal whosecorresponding variable is in X \ V . This makes it easier and more clear to describe our algorithm and its analysis. For moredetails see the proof of Theorem 1 at the end of Section 4.2.7. Related workThere is an extensive literature on the study of the phase transitions of random instances of NP-complete problems, theirimplication to the design of heuristics and practical solvers, and polynomial-time algorithms that solve random instanceswhp [2,19,30–33,43,44]. The threshold behavior of random CNF satisfiability, general constraint satisfaction problems, andgraph coloring on random graphs has attracted a lot of attention, and determining the exact threshold of their phasetransitions remains to be a challenging open problem [2].There have been many empirical studies on the power of data reduction as a heuristic for hard problems under differentsettings. Here, we mention two examples that are motivated by the study of phase transitions of random problem instances.In [49], a backtracking algorithm with reduction rules based on local vertex degree information is shown to be able to solverandom instances of the Hamiltonian cycle problem at phase transitions easily. One of the important observations made inthe study of the phase transition of hard problems is the existence of backbone variables i.e., variable whose value is fixedin all optimal solutions [13,21,45]. Whereas identifying backbone variables is not an easy task itself, it has been shown in[52] that even statistical information on the backbone variables can be utilized to guide the variable selection of local searchalgorithms to obtain great performance improvement.There has also been recent interest in designing whp polynomial-time algorithms for random instances with plantedsolutions (a.k.a. hidden solutions) [5,15,18,26,39] and using random instances with planted solutions for empirical studies[1,38,51]. In [30], random instances of the constraint satisfaction problem are designed that include a hidden consistencycore rather than a planted solution.Weighted CNF satisfiability is a generic intractable parameterized problem. In addition to the work of Marx [41] we havementioned in the previous subsection, other work that motivated the current research on random instances of intractableparameterized problems include the study of the parameterized proof complexity of weighted CNF satisfiability recentlyinitiated by Dantchev et al. [22] and the study of the backdoor set detection problem and its parameterized complexity in therecent AI literature [23,47,48].In the current work, we take the initiative to extend these lines of research to random instances of intractable parameter-ized problems. To the best knowledge of the author, this is the first work in the literature that studies the fixed-parametertractability of random instances of a W[1]-complete problem.3. A fixed-parameter algorithm for instances of F n,pk,dIn this section, we present the details of our algorithm for random instances of F n,pk,d and analyze its time complexity.The results in this section and in the next section together prove Theorem 1.3.1. General ideaThe algorithm W-SAT has two major steps. The first step is a “data reduction” step and the second step solves thereduced formula by enumeration + dynamic programming.3 The primal graph of a hypergraph is the graph where a pair of vertices is an edge if and only if the two vertices appear simultaneously in somehyperedge.1350Y. Gao / Artificial Intelligence 173 (2009) 1343–13663.1.1. STEP 1: Data reductionWe use a data reduction rule similar to Buss’s reduction for vertex cover [24,46]: If a variable x appears in a set of l (cid:3) kclauses of the form⎧⎪⎨⎪⎩x ∨ y11 ∨ · · · ∨ y1(d−1)x ∨ y21 ∨ · · · ∨ y2(d−1)· · ·x ∨ yl1 ∨ · · · ∨ yl(d−1)⎧⎪⎨such that the set of monotone clausesy11 ∨ · · · ∨ y1(d−1)y21 ∨ · · · ∨ y2(d−1)· · ·yl1 ∨ · · · ∨ yl(d−1)⎪⎩does not have a satisfying assignment of weight at most k − 1, then set x to FALSE. The correctness of the rule is obvious.For WEIGHTED 2-SAT, this rule can be implemented in O (n2) time — just count the number of the clauses of the formx ∨ y. For WEIGHTED d-SAT with d > 2, we will show later that there is an O (dknm)-time algorithm that implements thereduction correctly.Unlike the case of vertex cover, the above reduction rule does not result in a reduced formula of fixed size, which is ofcourse expected.3.1.2. STEP 2: Connected components and dynamic programmingWe make use of the observation that the reduced formula, while still not fixed in size, breaks up into “connectedcomponents” each of which contains at most log n variables. Section 4 is devoted to proving this observation.Let {Fi, 1 (cid:2) i (cid:2) N} where N (cid:2) n be the collection of connected components in the reduced formula. For each connectedassignmentcomponent Fi , we use brute-force to find the set of integers Li such that for each kto the variables in Fi that satisfies Fi .(cid:2) ∈ Li , there is a weight-k(cid:2)Finally, an O (k2n)-time dynamic programming algorithm can be used to find a collection of at most k positive integers(cid:4){ki j , 1 (cid:2) j (cid:2) k} such that∈ Li j ,+ ki2and+ · · · + kikki jki1= k.3.1.3. A further remarkA typical criticism to the above scheme is that it is more about the structure of the random instance distribution than thedesign of algorithms and heuristics. We argue that all algorithms, especially the efficient ones, are designed by exploitingspecial problem structures in one way or another such as those due to optimal subproblem structures, or restricted graphclasses, or restricted parameter size. Our algorithm and its analysis is exactly a demonstration of the kind of structures thatmay appear in a typical random instance of an intractable problem and can be exploited by reduction rules similar to thosethat have led to efficient algorithms for tractable problems.We note that similar structures have been exploited in many studies, most notably in N. Alon and N. Kahale’s seminalwork on algorithms for coloring random 3-colorable graphs [5] and its follow-ups [15,18,26,39]. In the author’s previouswork [29], similar connected-component structure also arises in a different setting.3.2. Definitions: k-frozen variablesWe formalize the concepts mentioned in Section 3.1 that will be used in the description and the analysis of the algorithm.Definition 3.1. Let (F , k) be an instance of WEIGHTED d-SAT where F is a d-CNF formula and k is the parameter. Considera variable x and a collection of subsets of variables Y = {Y i, 1 (cid:2) i (cid:2) l} whereY i = { yi j, 1 (cid:2) j (cid:2) d − 1}is a subset of X \ {x}. We say that the collection Y freezes x if the following two conditions are satisfied:(1) for each 1 (cid:2) i (cid:2) l, the clause x ∨ yi1 ∨ · · · ∨ yi(d−1) is in the formula F ;(2) the set of clauses { yi1 ∨ · · · ∨ yi(d−1), 1 (cid:2) i (cid:2) l} has no satisfying assignment of weight at most k − 1.The variable x is said to be k-frozen with respect to a subset V of variables if it is frozen by a collection of subsets ofvariables {Y i, 1 (cid:2) i (cid:2) l} such that Y i ⊂ V , ∀1 (cid:2) i (cid:2) l.A variable that is k-frozen with respect to the set of all variables is simply called a k-frozen variable.Y. Gao / Artificial Intelligence 173 (2009) 1343–13661351It is obvious that a k-frozen variable cannot be set to TRUE in any satisfying assignment.An important observation in the study of random instances of NP-complete problems is the existence of frozen variables(also known as backbone variables) [13,21,45]. Even though detecting backbone variables is usually a task that is no easierthan that of solving the original satisfiability problem, information on backbone variables can be utilized to guide thevariable selection heuristics in search algorithms [52]. The concept of a frozen variable (with respect to a partial assignment)and the concept of a core set of frozen variables have been used to study the geometric structure of the solution space atphase transitions [3]. Similar concepts also play an important role in the study of random CNF formulas with a plantedsolution [18,26,39].Our notion of k-frozen variables can be viewed as a fixed-parameter generalization of a stronger version of the concept ofbackbone variables. A k-frozen variable has a forced value in all satisfying assignments, but a variable that has a forced valuein all satisfying assignments is not necessarily k-frozen. As we will show later unlike general backbone variables, k-frozenvariables can be detected efficiently: For 2-CNF formulas, to see if a variable x is k-frozen, one only needs to count thenumber of clauses of the form x ∨ y. For d-CNF formulas with d > 2, k-frozen variables can be detected by an O (dknm)-timealgorithm.In the analysis of the probabilistic behavior of the algorithm in Section 4, we will make use of an even stronger notionof k-frozenness. We say that a variable x in a d-CNF formula F is strongly k-frozen4 if there is a collection of k clauses{x ∨ yi1 ∨ · · · ∨ yi(d−1), 1 (cid:2) i (cid:2) k} in F such that Y i = { yi1, . . . , yi(d−1)}, 1 (cid:2) i (cid:2) k, are variable-disjoint subsets. A stronglyk-frozen variable is obviously also k-frozen. The chief reason to focus on strongly k-frozen variables is that it is not clearif we can achieve the same or better bounds on some relevant probabilities by considering the k-frozen variables. We notethat the task of deciding a strongly k-frozen variable is equivalent to a (d − 1)-dimensional matching problem, which isNP-complete for d (cid:3) 4 and polynomial solvable for d = 2 or 3 if k is part of the input. For fixed k as we are dealing within this paper, the (d − 1)-dimensional matching problem is fixed parameter tractable, but the currently best algorithms allhave an exponential dependency on the parameter k which is worse than that of the straightforward bounded search-treealgorithm for the parameterized hitting set problem [17,25].The following is another concept that is necessary in the description of the algorithm:Definition 3.2. Let F be a CNF formula. We use LF to denote the set of integers between 0 and k such that for each kthere is a satisfying assignment of weight-kfor F .(cid:2)(cid:2) ∈ LF ,3.3. The algorithm W-SAT and its time complexityThe algorithm is described in Algorithm 1. We will explain the purpose of the subroutine REDUCE() in the next subsec-tion.Lemma 3.1. There is an O (dk L)-time algorithm that checks if a variable x is k-frozen where L is the number of clauses that contain x.The running time is O (n2) for a 2-CNF formula.Proof. Consider the set of all clauses in which x is the only negated literal: {x ∨ yi1 ∨ · · · ∨ yi(d−1), 1 (cid:2) i (cid:2) l}. According toour definition, x is k-frozen if and only if the collection of subsets {{ yi1, . . . , yi(d−1)}, 1 (cid:2) i (cid:2) l} has no hitting set5 of sizeat most k − 1, which can be solved by the bounded search tree method in time O (dk L) that branches on the element of asubset [46].In the case of 2-CNF formulas, one only needs to count the number of clauses of the form x ∨ y to see if x is k-frozen. (cid:2)We remark that for random instances from F n,pnd−1 , the above lemma is not really necessary since it canbe shown by Chernoff inequality and Markov inequality that whp every variable appears only in about c log n clauses.Consequently, a brute-force search to check k-frozen variables runs in O (ncm) time. Lemma 3.1 is necessary in order to dealwith the case of p = Ω(nd−1−(cid:3) ), (cid:3) > 0, and to avoid the exponential dependency on c of the running time.k,d with p = c log n1We now show that the algorithm W-SAT runs in fixed-parameter time and is correct whenever it returns a satisfyingassignment or reports “UNSAT”.Proposition 3.1. The algorithm W-SAT is correct when it returns a satisfying assignment or reports “UNSAT”. The running time ofW-SAT is in O (dknm) for any p(n) (cid:2) 1 where m is the number of clauses in the d-CNF formula.Proof. Since k-frozen variables are forced to take the truth value FALSE and since the subroutine REDUCE() never assignsTRUE to a variable (due to the fact that there is no monotone clause in the formula), a formula F has a weight-k satisfyingassignment if and only if the reduced formula F (cid:2)can behas one. Satisfying assignments to the connected components of F (cid:2)4 We thank one of the referees for suggesting this name.5 A hitting set H of a collection of subsets {S1, . . . , Sn} in a universe U is a subset H ⊂ U such that H contains at least one element from each subset S i .1352Y. Gao / Artificial Intelligence 173 (2009) 1343–1366Input: A random instance (F n,pOutput: A satisfying assignment of weight k, or UNSAT, or FAILUREk,d , k) of WEIGHTED d-SATif x is k-frozen, then set x to FALSE and let U = U ∪ {x}.1. for variable x do2.3. Let F (cid:2) = REDUCE(F, U ) be the reduced formula.4. Find the connected components {F1, . . . , FN } of F (cid:2)5. If there is a connected component that contains more than log n variables, return “FAILURE”.6. Otherwise, for each connected component Fi , use brute force to find LFi .7. Find a set of at most k indices {i j , 1 (cid:2) j (cid:2) k} and a set of integers {ki j , 1 (cid:2) j (cid:2) k} such that ki j.∈ LFi jandk(cid:13)j=1= k.ki jReturn “UNSAT” if there is no such index set.8. For each Fi j , use brute-force to find a weight-ki j assignment to the variables in Fi j that satisfies Fi j .9. Combine the assignments found in the above to form a weight-k satisfying assignment to the formula F .Algorithm 1. W-SAT.combined together without falsifying any clauses. So, as long as the sum of the weight of the assignments to the connectedcomponents is equal to k, W-SAT finds a weight-k satisfying assignment in Line 6 through Line 8.Due to Lemma 3.1 it takes O (dknm)-time to find all the k-frozen variables in Lines 1 and 2. Lines 3 through 5 take atmost O (nm)-time and do not depend on k. Line 6 can be finished in O (nm)-time to enumerate all the elements of LFisince each Fi contains no more than log n variables. Line 8 repeats part of the work done in Line 6.We now show that Line 7 can be done in O (k2n) time by dynamic programming. Consider an integer k and any collection{Li, 1 (cid:2) i (cid:2) m} where each Li is a subset of integers in {0, 1, . . . , k}. We say that an integer a is achievable by {Li, 1 (cid:2) i (cid:2) m}if there is a set of indices Ia = {i j, 1 (cid:2) j (cid:2) l} satisfying the following condition: for each i j , there is a ki j∈ Li j such thatl(cid:13)j=1= a.ki jWe call any such index set Ia a representative set for a. The purpose of Line 7 is to check if the integer k is achievable,and if YES, return a representative set for k. The next lemma shows how to implement this task.Lemma 3.2. Given an integer k and a collection {Li, 1 (cid:2) i (cid:2) l} of subsets of integers from {0, 1, . . . , k}, there is a dynamic programmingalgorithm that finds a representative set for k if k is achievable, or reports that k is not achievable. It runs in time O (k2l).Proof. Let A(t) = {(a, Ia): 0 (cid:2) a (cid:2) k} be the set of pairs (a, Ia) where 0 (cid:2) a (cid:2) k is an integer achievable by {Li, 1 (cid:2) i (cid:2) t}and Ia is a representative set for a.Let A(0) = ∅. We see that A(t + 1) is the union of A(t) and the set of pairs of the form ((a + b), Ia) where(cid:14)(a, Ia) ∈ A(t),b ∈ Lt+1Ia = Ia ∪ {t}.such that a + b (cid:2) k,andA typical application of dynamic programming computesA(0),A(1),. . . ,and A(l).The value k is achievable by {Li, 1 (cid:2) i (cid:2) l} if and only if there is a pair (k, Ik) in A(l). Since the size of A(t) is at most k, theabove algorithm runs in O (k2l) time. (cid:2)For the case of Line 7, there are at most n subsets of integers, each of which corresponds to the LFi of a connectedcomponent Fi . The running time of Line 7 is thus O (k2n). The proposition follows. (cid:2)3.4. The subroutine REDUCE(F , U )The purpose of the subroutine REDUCE(F , U ) is to simplify the formula F after the variables in U have been assignedFALSE. It works in the same way as the unit-propagation-based inference in the well-known DPLL procedure for the stan-dard satisfiability search: It removes any clause that is satisfied by the assignment to the variables in U , deletes all theoccurrences of a literal that has become FALSE due to the assignment, and assigns a proper value to the variables whosevalue is forced due to the literal-deletion. The procedure terminates when there is no variable whose value is forced.Y. Gao / Artificial Intelligence 173 (2009) 1343–13661353Due to the nature of WEIGHTED d-SAT and our random model, we note that REDUCE( ) never assigns TRUE to a variable.This is because it begins with a set of variables U that have been assigned FALSE, and the formula F contains no monotoneclause. As a consequence, REDUCE( ) will never create a contradiction either.It is possible that REDUCE( ) returns an empty formula F (cid:2), signifying that all the clauses have been satisfied during theprocess. However, since we are searching for a satisfying assignment of weight k, we are not done yet in this case. In thedescription of Algorithm 1, we have omitted this simple special case. The following lemma describes how this situation canbe handled:Lemma 3.3. If F (cid:2) = REDUCE(F , U ) is empty, then F has a weight-k satisfying assignment if and only if at least k variables have notbeen assigned after REDUCE returns.Proof. F (cid:2)fact that REDUCE( ) only sets variables to FALSE and the fact that if F (cid:2)assigned an arbitrary truth value. (cid:2)is obtained by assigning all the variables in U FALSE and simplifying the formula. The lemma follows from theis empty, then any variable not assigned yet can be4. The algorithm W-SAT succeeds with high probabilityIn this section, we prove that the algorithm W-SAT succeeds whp for random instances of F n,pk,d . Due to Proposition 3.1,we only need to show that the probability for W-SAT to report “FAILURE” is asymptotically zero. Recall that W-SAT failsonly when the reduced formula F (cid:2)obtained in Line 3 has a connected component that contains more than log n variables.nd−1 with c > 2k2(2d − 1)(d − 1)!, which will be used later in the proof ofTheorem 3. We show in the following lemma that whp all variables are k-frozen and have to be set to FALSE. Consequentlythe reduced formula is empty and the algorithm returns the correct answer “NO”.First, we present a result for the case of p(n) = c log nLemma 4.1. For random instances from F n,pk,d where p(n) = c log nnd−1 with c > 2k2(2d − 1)(d − 1)!, whp all variables are k-frozen.Proof. See Appendix A. (cid:2)We now focus on the case p(n) = c log nnd−1 with c (cid:2) 2k2(2d − 1)(d − 1)!.Proposition 4.1. Let F = F n,pk,d be the input random CNF formula to W-SAT and V be the set of variables that are not k-frozen. Withhigh probability, the residual graph of the induced formula FV on V decomposes into a collection of connected components each ofwhich contains at most log n variables.Proof. Let X = {x1, . . . , xn} be the set of Boolean variables, U be the set of k-frozen variables, and V = X \ U .Since p = c log nnd−1 with c > 0, there will be many k-frozen variables so that the size of U is large. If U were a randomly-selected subset of variables, the proposition is easy to prove. The difficulty in our case is that U is not randomly-selectedand consequently FV cannot be assumed to be distributed in the same manner as the input formula F .To get around this difficulty, we instead directly upper bound the probability Pas its subgraph, a tree T over a given set V T of log n variables such that every variable x ∈ V T is not k-frozen.Since the variables in FV are not k-frozen, an upper bound on the probability Pis also an upper bound on theprobability that the residual graph of FV contains, as its subgraph, a tree of the size log n. We then use this upper boundand Markov’s inequality to show that the probability tends to zero for the residual graph of FV to have a connectedcomponent over more than log n variables.∗∗that the residual graph of F n,pk,d contains,∗is that the two eventsLet T be a fixed tree over a subset V T of log n variables. A further complication in estimating P(1) F n,pk,d induces T and(2) no variable in T is k-frozenare not independent of each other. To further decouple the dependency, we consider the following two events(1) A: the event that the residual graph of F n,p(2) B: the event that in F n,pk,d contains the tree T as its subgraph; andk,d none of the variables in V T involves a set of k clauses of the following form:{x ∨ yi1 ∨ · · · ∨ yi(d−1), 1 (cid:2) i (cid:2) k}where yi j ’s are distinct variables and yi j ∈ X \ V T , ∀i, j.1354Y. Gao / Artificial Intelligence 173 (2009) 1343–1366By definition, the event that a variable x is not k-frozen implies the event that x is not k-frozen with respect to the subsetX \ V T of variables, which in turns implies the event that x is not involved in a set of k clauses of the form{x ∨ yi1 ∨ · · · ∨ yi(d−1), 1 (cid:2) i (cid:2) k}where yi j ’s are distinct variables and yi j ∈ X \ V T , ∀i, j. It follows that∗ (cid:2) P{A ∩ B}.PWe claim thatLemma 4.2. The two events A and B are independent, i.e.,P{A|B} = P{B}.(4.2)(4.3)Proof. Note that the event A depends only on those d-clauses that contain at least two variables in V T , and that the eventB depends only on those d-clauses that contain exactly one variable from V T . By the definition of the random model F n,pk,d ,the appearance of a clause defined over a d-tuple of variables is independent from the appearance of the other clauses. Thelemma follows. (cid:2)Based on Eq. (4.2) and Lemma 4.2, we only need to estimate P{A} and P{B} separately. To proceed, we need thefollowing Chernoff bound on the tail probability of a binomial random variable.Lemma 4.3. Let I be a binomial random variable with expectation μ. We have(cid:2)P|I − μ| > t(cid:3)(cid:2) 2e− t23μ .The following lemma bounds the probability that a variable is not k-frozen.Lemma 4.4. Let x be a variable and W ⊂ X such that x /∈ W and |W | = n − log n. Then, we haveP{x is not k-frozen with respect to W } (cid:2) O (1) max(cid:8)(cid:7)1nδ ,log2 nnwhere 0 < δ <c3(2d−1)(d−1)! .(4.4)Proof. Let Nx be the number of clauses of the form x ∨ y1 ∨ · · · ∨ yd−1 with { y1, . . . , yd−1} ⊂ W . Due to the definition ofF n,pk,d , the random variable Nx follows the binomial distribution Bin(p, m) where p = 1. Note that2d−1for any fixed constant (cid:3) > 0, there is an integer N((cid:3)) > 0 such that for n > N((cid:3))nd−1 and m =(cid:5)n−log nd−1c log n(cid:6)(cid:7)(cid:8)n − log nd − 1(cid:7)1 − log n + dn(cid:8)d−1pm = 12d − 1c log nnd−1c(2d − 1)(d − 1)!(1 − (cid:3))c(cid:3)(cid:3)(2d − 1)(d − 1)! log n.Write α =c(2d−1)(d−1)! . By Lemma 4.3 and for sufficiently large n such that(cid:3)P{Nx < k} (cid:2) P(cid:2)|Nx − pm| > pm − k− (pm−k)23pm(cid:2) 2e= 2e− 1(cid:2) 2e(cid:5)∈ On− 13 pm(1− kpm )23 (1−(cid:3))3α log n−δ(cid:6)kpm < (cid:3), we have(4.5)for some 0 < δ < α3 .Let D be the event that in the random formula F , there are two clauses(cid:4)x ∨ y11 ∨ · · · ∨ y1(d−1),x ∨ y12 ∨ · · · ∨ y2(d−1)andY. Gao / Artificial Intelligence 173 (2009) 1343–13661355such that { y11, . . . , y1(d−1)} ∩ { y12, . . . , y2(d−1)} (cid:9)= ∅. The total number of such possible pairs of clauses is at most(d − 1)(cid:7)n − log nd − 1(cid:8)(cid:7)(cid:8).n − log nd − 2The probability for a specific pair to be in the random formula is(cid:7)12d − 1c log nnd−1(cid:8)2.By Markov’s inequality, we have(cid:7)(cid:8)P{D} ∈ Olog2 nn.By definition, if a variable x is not k-frozen, then either Nx < k or the event D occurs. Therefore, the probability that thevariable x is not k-frozen is at most(cid:2)P{Nx < k} ∪ DThe lemma follows. (cid:2)(cid:3).From Lemma 4.4, we haveLemma 4.5. For sufficiently large n,(cid:5)P{B} < O (1)n(cid:6)−δlog nfor some 0 < δ < min(c3(2d−1)(d−1)! , 1).(4.6)Proof. Let E x be the event that a variable x ∈ V T is not k-frozen with respect to X \ V T . Since |V T | is log n, the boundobtained in Lemma 4.4 applies to W = X \ V T . Since for any x ∈ V T , the event E x only depends on the existence of clausesof the formx ∨ yi1 ∨ · · · ∨ yi(d−1)with { yi1, . . . , yi(d−1)} ⊂ X \ V T , we see that the collection of the events {E x, x ∈ V T } are mutually independent. The lemmafollows from Lemma 4.4. (cid:2)Next, we have the following upper bound on the probability P{A}. Its proof is based on a counting argument that slightlygeneralizes that used in [26,39]. See Appendix B for the details.Lemma 4.6. The probability of the event A can be bounded asP{A} (cid:2) (log n)d−1n f (d,c)+1(log n)2 log nn− log nwhere f (d, c) is a function that only depends on d and c.Continuing the proof of Proposition 4.1, we combine the results of Lemma 4.5 and Lemma 4.6 to getP{A ∩ B} (cid:2) (log n)d−1n f (d,c)+1(log n)2 log nn− log n(cid:6)−δ(cid:5)nlog n.Since the total number of trees of size log n over n vertices is at mostnlog n(log n)log n−2,the probability that the induced formula FV has a connected component over more than log n variables can be upperbounded bynlog n(log n)log n−2P{A ∩ B} (cid:2) (log n)d−1n f (d,c)+1(log n)3 log n(cid:6)−δ(cid:5)nlog n(4.7)which tends to zero since the first three terms on the right-hand side of the above are in o(n(cid:3) log n) for any (cid:3) > 0. Proposi-tion 4.1 follows. (cid:2)Proof of Theorem 1. Recall that by our definition the induced formula FV on the set V of variables that are not k-frozenconsists of two types of clauses:1356Y. Gao / Artificial Intelligence 173 (2009) 1343–1366(1) the clauses of F that only involve the variables in V ;(2) the clauses of size at least 2 obtained by removing any literal whose corresponding variable is in X \ V .We claim that the formula F (cid:2)obtained in Line 3 of the algorithm W-SAT is a sub-formula of FV and is thus sparser.This is because any clause that is still not satisfied after the application of REDUCE( ) must contain at least two literalsfrom the variables in V . Therefore by Proposition 4.1, with high probability F (cid:2)decomposes into a collection of connectedcomponents each of which contains at most log n variables. It follows that W-SAT succeeds whp.Combining all the above, we conclude that Algorithm W-SAT is a fixed-parameter algorithm and succeeds whp on ran-dom instances of F n,pk,d . This proves Theorem 1. (cid:2)5. The threshold behavior of the solution probabilityIn this section, we prove Theorem 2 to establish the exact threshold of the phase transition of the solution probability.Unlike the threshold for random instances of most NP-complete problems for which the exact threshold is still an openquestion, the exact threshold of the weighted satisfiability problem can be established by the first-moment method and thesecond-moment method.Proof of Theorem 2. Let T be the collection of all subsets of d variables and let s be an assignment to the variables. Wesay that a subset T = {x1, . . . , xd} ∈ T is s-good if either(1) T doesn’t contribute a clause to F n,p(2) the d-clause in F n,pk,d , ork,d contributed by T is satisfied by the assignment s.Let S be the set of all assignments of weight k. Recall that the weight of an assignment is the number of variables that} are set to TRUE.are set to TRUE in the assignment. Consider an assignment s ∈ S where the k variables Y = { yi1 , . . . , yikFrom the definition of F n,pk,d , the probability for T ∈ T to be s-good is(cid:14)P{T is s-good} =1,1 − p(n)if T ∩ Y = ∅;12d−1, otherwise.(5.8)Let Ts ⊂ T be the collection of subsets of d variables that have a non-empty intersection with Y . We have|Ts| =(cid:7)n − kd − jd(cid:13)j=1(cid:8)(cid:8)(cid:7)kj.Note that in the above summation, the first termF n,pk,d . We have(cid:6)(cid:5)n−kd−1(cid:6)(cid:5)k1dominates. Let X be the number of assignments in S that satisfyE[X] ===∼(cid:13)(cid:15)s∈S(cid:13)T ∈T(cid:15)P{T is s-good}P{T is s-good}T ∈Ts(cid:8)(cid:7)s∈S(cid:7)n(cid:8)(cid:7)k(cid:7)nk1 − c log nnd−1(cid:8)(cid:16)dj=1 (n−kd− j)(kj)12d − 1(cid:8)(n−kd−1)(k1)1 − c log nnd−112d − 1∼ nke− kc log n(2d −1)(d−1)!where ∼ means “is asymptotically equivalent to”. The upper bound on the threshold cand the above asymptotic expression of E[ X].∗, we use Chebyschev’s inequalityTo lower bound the threshold cP{ X = 0} (cid:2)E[X 2](E[X])2− 1.∗follows from Markov’s inequality(5.9)Y. Gao / Artificial Intelligence 173 (2009) 1343–13661357We say that two assignments s1, s2 ∈ S have i overlaps if exactly i variables are set to true in both assignments. Let D i bethe number of pairs of satisfying assignments in S that have i overlaps. We can represent E[ X 2] as(cid:18)(cid:17)EX 2=k(cid:13)i=1E[D i].Let (cid:3) > 0 be any number. We claim that for c =(cid:14)E[D i] ∈ olimn D0 =(cid:5)n2k(cid:3)−i(cid:3)(cid:6)(cid:5)E[X](cid:6)2.for i > 1,and1−(cid:3)2d−1(d−1)! ,(5.10)(5.11)By definition, we have(cid:13)(cid:15)E[D i] =P{T is both s1-good and s2-good},s1,s2Twhere the sum is over all (ordered) pairs of weight-k assignments with i overlaps, and the product is over all subsets T ofd variables.Consider two weight-k assignments s1, s2 ∈ S that have i overlaps. W.l.o.g., assume that the set of variables assignedTRUE in s1 is { y1, . . . , yk−i, yk−i+1, . . . , yk} and the set of variables assigned TRUE in s2 is { yk−i+1, . . . , yk, yk+1, . . . , y2k−i}.Write Y s1,s2= { y1, . . . , yk, . . . , y2k−i}.The probability for a set of d variables T ∈ T to be both s1-good and s2-good can be estimated as follows:(1) If T ∩ Y s1,s2(2) If T ∩ Y s1,s2= ∅, then P{T is s1-good and s2-good} = 1.(cid:9)= ∅, then P{T is s1-good and s2-good} is at most (1 − p(n)non-empty intersection with either { y1, . . . , yk}, or { yk−i+1, . . . , y2k−i}, or both. Therefore, either). To see this, note that in this case T has aP{T is s1-good} =1 − p(n),or P{T is s2-good} =1 − p(n)(cid:7)(cid:8)12d − 112d−1(cid:7)(cid:8)12d − 1As the total number of T ∈ T such that T ∩ Y (cid:9)= ∅ is(cid:8)(cid:7)(cid:8)(cid:7)d(cid:13)j=1n − (2k − i)d − j2k − ij,it follows that for i > 1,E[D i] =(cid:8)(cid:7)(cid:7)nkn − kk − i(cid:8) (cid:15)(cid:7)T : T ∩Y (cid:9)=∅(cid:8)1 − p(n)12d − 1(cid:8)(cid:16)dj=1 (n−(2k−i)d− j )(2k−ij )(cid:7)∼ n2k−i1 − p(n)12d − 1− (2k−i)c log n(2d −1)(d−1)!∼ n2k−ie∼ n2k(cid:3)−i(cid:3),.(5.12)where ∼ means “is asymptotically equivalent to”. For the case of i = 0, it can be shown that limn D0 = (E[ X])2. This provesthe claim. The theorem follows from Eqs. (5.9), (5.10), and (5.12).Finally, we note that all the calculations still hold for random instances of MINI-WEIGHTED d-SAT where the question isto find a satisfying assignment with Hamming distance k log n to the all-zero assignment. (cid:2)6. Parametric resolution complexity of unsatisfiable instances of F n,pk,dEven though the algorithm W-SAT solves both satisfiable and unsatisfiable instances, it is unclear to us how to simulatethe dynamic programming phase (Line 7) of W-SAT by a resolution proof.F n,pIn this section, we prove Theorems 3 and 4 on the parametric resolution complexity of random unsatisfiable instances ofk,d . We begin with Theorem 3 that deals with the case of d > 2. The proof is based on the fact that in certain range of p,every variable becomes k-frozen and that for a k-frozen variable x, a parametric resolution derivation of x of size O (dk) canbe constructed.1358Y. Gao / Artificial Intelligence 173 (2009) 1343–1366For random WEIGHTED 2-SAT, results on the minimum degree in a random graph (Theorem 3.5 in [12]) can be appliedwith c1 > k − 1, every variable is k-frozen whp. A parametric resolution proof based onto show that if p = 3(log n+c1 log log n)the k-frozenness of all the variables is immediate.nThe proof of Theorem 4 on the resolution complexity of random instances of WEIGHTED 2-SAT instead exploits theexistence of a Hamiltonian-cycle-like system of clauses so that the theorem holds for both WEIGHTED 2-SAT and MINI-WEIGHTED 2-SAT.The study of the parameterized proof complexity of weighted CNF satisfiability has been recently initiated by Dantchevet al. [22], who established lower bounds on the parameterized resolution proof for CNF formulas that encode some first-order combinatorial principle. Following their definition, a parameterized resolution proof system for unsatisfiable instancesof a co-W[1] complete problem is defined to be a classical resolution system that has access for free to all clauses thatcontains more than k negated literals or more than n − k positive literals where k is the problem parameter.6.1. Proof of Theorem 3 on the resolution complexity of F n,pk,d , d > 2Proof of Theorem 3. We establish Theorem 3 by making use of the fact established in Lemma 4.1 that for p = c log nc > 2k2(2d − 1)(d − 1)!, all the variables are k-frozen whp.nd−1 withSince all variables are k-frozen, one can construct a parametric (tree) resolution proof as follows. First, for each variable x,there is a parametric resolution derivation of size O (dk) as described in the following lemma:Lemma 6.1. If a variable x is k-frozen, then there is a parametric resolution derivation of x of size O (dk).Proof. We show that a parametric resolution derivation of size O (dk) can be obtained from the set C of k clauses⎧⎨⎩x ∨ y11 ∨ · · · ∨ y1(d−1)· · ·x ∨ yk1 ∨ · · · ∨ yk(d−1)that freeze x.Consider a DPLL-style search tree method that first assigns x TRUE and then, enumerates all the possible assignments tothe k variables, one from each set { yi j, 1 (cid:2) j (cid:2) (d − 1)}, 1 (cid:2) i (cid:2) k, in order to satisfy the k clauses in C with x removed. Thesize of the search tree is O (dk) and at each leaf node, some anti-monotone clause of size k + 1 will be made empty. Sincein a parametric resolution proof the proof system has free access to all anti-monotone clauses of size k + 1, in the sameway a tree resolution proof can be constructed from a DPLL search tree for the CNF satisfiability problem, a tree parametricderivation of x can be constructed from the above search tree. (cid:2)Continuing the proof of Theorem 3, it follows from the above lemma that there is a size O (dkn) parametric resolutionderivation of the set of single-literal clauses {x}, x ∈ X . From the set of clauses {x}, x ∈ X , together with the monotone(cid:19)ni=1 xi (which says that at least one variable has to be set to TRUE), a parametric resolution proof of size O (n) canclausebe easily constructed for the empty clause (i.e., the contradiction). (cid:2)6.2. The resolution complexity of F n,pk,2Proof of Theorem 4. We prove Theorem 4 on the resolution complexity of F n,pk,2 by exploiting an interesting connection be-tween the parameterized resolution complexity of WEIGHTED 2-SAT and the existence of a Hamiltonian cycle in a properlydefined directed graph. The following lemma establishes the connection.Lemma 6.2. Consider an instance (F , k) of WEIGHTED 2-SAT and an arbitrary ordering {x1, . . . , xn} of the variables. If F contains thefollowing cycle of “forcing” clauses,x1 ∨ x2,x2 ∨ x3,. . . ,xn−1 ∨ xn,xn ∨ x1,then there is a parametric resolution proof of size O (kn) for F . Furthermore, the parameterized version of the DPLL algorithm constructssuch a resolution proof.Proof. Since the parametric resolution proof system has access to all the clauses that contain more than k negated variablesor more than n − k positive variables, for each i (cid:3) 1, we can resolvexi ∨ xi+1,. . . ,xi+k ∨ xi+k+1and xi+1 ∨ · · · ∨ xi+k+1 to derive xi . These xi ’s together with x1 ∨ · · · ∨ xn−k+1 result in a contradiction. (cid:2)Y. Gao / Artificial Intelligence 173 (2009) 1343–13661359We emphasize that a cycle of forcing clauses, if exists, can be automatically exploited by DPLL-style algorithms. In arandom CNF formula generated from F n,pk,2 , the existence of a cycle of “forcing” clauses can be shown using a result ofMcDiarmid on the relation between the existence of a Hamiltonian cycle (or a long path) in a random graph and theexistence of a directed Hamiltonian cycle (or a directed long path) in the “directed random graph” defined as follows.Definition 6.1. (See Section 4, McDiarmid [42].) Let V be a vertex set and p > 0. The directed random graph D 2defined as a directed graph where each directed edge is in E with probability p under the constraints thatp(V , E) is(1) the appearance of directed edges on different unordered pairs are independent, and(2) for any pair of vertices u and v,(cid:2)(cid:3)P(u, v) ∈ E and (v, u) ∈ E= max{0, 2p − 1}.It is noted in [42] that if p < 12 , D2p can be obtained by randomly directing the edges in the undirected random graphG(n, 2p).Lemma 6.3. (See Theorem 4.4, McDiarmid [42].) Let 0 < p < 1 and D2p be a random directed graph on n vertices. Then(cid:2)(cid:3)p has a directed Hamiltonian cycleD2P(cid:2)(cid:3)G(n, p) has a Hamiltonian cycle.(cid:3) PBy Lemma 6.2, it is sufficient to show that there is a directed Hamiltonian cycle in the following directed graph(cid:2)): Each vertex corresponds to a variable. There is a directed edge from xi to x j if and only if the 2-clause xi ∨ x j isDF (n, pin the random formula F n,pk,2 .By the definition of F n,pk,2 , DF (n, p(cid:2) = 1probability pif either x ∨ y or x ∨ y is in F n,pfollows the distribution of a directed random graph by randomly directing the edge of G( X, E).p(cid:2) discussed in Lemma 6.3 with edge3 p. To see this, consider the random graph G( X, E) on the set of variables such that (x, y) ∈ E if and only(cid:2))3 p. The directed graph DF (n, pk,2 . Thus, G( X, E) is a random graph with edge probability 2(cid:2)) is exactly the directed random directed graph D2The result follows from Lemma 6.3 and the threshold of the existence of a Hamiltonian cycle in the random graphG(n, p(cid:2)): for edge probability p(cid:2) = log n+b log log nwith b > 1, G(n, p(cid:2)) is Hamiltonian (Theorem 8.9 in [12]). (cid:2)n7. W-SAT for MINI-WEIGHTED d-SATIn this section, we show that a simple modification of the algorithm W-SAT can solve whp random instances of MINI-WEIGHTED d-SAT from F n,pk,d when p = p(n) is in a certain range, and thus prove Corollary 1.1.Recall that for a random instance (F n,pk,d , k) of MIN-WEIGHTED d-SAT, we are looking for a satisfying assignment of weightk log n. Thus, the algorithm W-SAT needs to make use of the existence of k log n-frozen variables. To guarantee that W-SATstill succeeds whp, we need to prove a result similar to Proposition 4.1. This amounts to showing that the probability thata variable x is not k log n-frozen is small enough. For p = c log nnd−1 with c > k(2d − 1)(d − 1)!, this is the case.Proposition 7.1. Let p = c log nk,d be the input random CNF formula to W-SAT customized toMINI-WEIGHTED d-SAT (i.e., based on k log n-frozen variables) and V be the set of variables that are not k log n-frozen. With high prob-ability, the residual graph of the induced-formula FV decomposes into a collection of connected components each of which contains atmost log n.nd−1 with c > k(2d − 1)(d − 1)!. Let F = F n,pProof. The proof is almost the same as the proof of Proposition 4.1 except that we need to establish an upper bound onthe probability that a variable is not k log n-frozen. For c > k(2d − 1)(d − 1)!, Lemma 4.3 on the tail probability of a binomialrandom variable still works. Using the notation in the proof of Lemma 4.4, we haveP{Nx < k log n} (cid:2) P(cid:2)(cid:2) 2e= 2e(cid:2) 2e(cid:3)|Nx − pm| > pm − k log n− (pm−k log n)23pm− 13 pm(1− k log npm )2− 13 (1−(cid:3)) f (c,d,k) log nwhere f (c, d, k) depends on c, d, k only. The arguments made in the second half of the proof of Lemma 4.4 and in the proofof Lemma 4.5 are still valid. The only difference is the accuracy of the upper bound, but it is sufficient for the result tohold. (cid:2)1360Y. Gao / Artificial Intelligence 173 (2009) 1343–1366A further complication is the detection of k log n-frozen variables. Note that the bounded search-tree method inLemma 3.1 does not work since the resulting running time would be O (dk log n) = O (nk). To overcome this difficulty, wemake use of the fact that with p(n) = c log nnd−1 where c is a constant, the set of clauses in which a given variable x appearsalso decomposes into connected components each of which contains at most log n variables, and consequently we can checkwhether a variable is k log n-frozen by using brute-force on each of connected components. We make the observation precisein the following proposition.Proposition 7.2. Let F n,pclauses y1 ∨ · · · ∨ yd−1 such that x ∨ y1 ∨ · · · ∨ yd−1 is in F n,pvariables. We havek,d be a random d-CNF formula and x be a variable. Consider the (d − 1)-CNF formula F (x) consists of all thek,d . Let E be the event that F (x) has a connected component on log nP{E} (cid:2) n f (d,c)(log n)2 log nn− 1d−2 log n.Proof. Let T be a fixed tree on a vertex set V T ⊂ X \ {x} of size log n. Similar to the argument in the proof of Lemma 4.6,we have that the probability for the residual graph of the (d − 1)-CNF formula F (x) to contain the tree T as its subgraph isat most(log n)d−2n f (d,c)(log n)2 log nn− log n− 1d−2 log n.(7.13)As the number of trees of size log n is nlog n(log n)log n−2, the proposition follows. (cid:2)By Markov’s inequality and Proposition 7.2, we have that whp all the variables x are such that their corresponding(d − 1)-CNF formula F (x) has no connected component on more than log n variables.8. A more general model F n,pk,d (d(cid:2))In this section, we discuss how to generalize the model F n,p(cid:2)) definedas follows: instead of from the set of non-monotone clauses, we select uniformly at random from the set of clauses over{xi1 , . . . , xidk,d (1).First, we have the following result on the exact threshold of the phase transition:(cid:2) (cid:2) d and consider the model F n,pnegated literals. Note that F n,p} that contain at least dk,d is just F n,pk,d . Let 1 (cid:2) dk,d (d(cid:2)Theorem 5. Consider a random instance (F n,pαd(d − dk,d (d(cid:2)), k) of WEIGHTED d-SAT. Let p = c log nnd−d(cid:2) with c > 0 being a constant and let c∗ =(cid:2))! with αd being the number of d-clauses over a fixed set of d variables that contain at least d(cid:2)negated literals. We have(cid:2)P(cid:2)F n,pk,d (dlimn) is satisfiable(cid:4)(cid:3)=1,0,if c < cif c > c∗,∗.Proof. Same as the proof of Theorem 2. (cid:2)We have the following result on the parametric resolution complexity of unsatisfiable random instances of F n,pk,d (d(cid:2)).Theorem 6. Let p(n) = c log nnd−dd-SAT has a resolution proof of size O ((d − d(cid:2) with c > 2αdd(cid:2)(k − d(cid:2))k−dnd(cid:2))2(d − d), and can be constructed in O ((d − d(cid:2)(cid:2)(cid:2))!. With high probability, a random instance (F n,p(cid:2)(cid:2))k−dn O (1)) time.k,d , k) of WEIGHTED(cid:2)Proof. Extending the notion of a k-frozen variable, we call a set of dfollowing k − dclauses are in the random CNF formula:⎧⎨(cid:2) ∨ y11 ∨ · · · ∨ y1(d−d(cid:2))∨ · · · ∨ xidxi1· · ·xi1⎩∨ · · · ∨ xid(cid:2) ∨ y(k−d(cid:2))1 ∨ · · · ∨ y(k−d(cid:2))(d−d(cid:2))(cid:2)variables S = {xi1 , . . . , xid(cid:2) } a frozen tuple if thewhere yi j ’s are distinct variables. It is clear that no satisfying weight-k assignment is allowed to assign the dfrozen tuple to TRUE.We claim that for if c > 2αddvariable S = {xi1 , . . . , xid(cid:2)(k − d(cid:2))2(d − d(cid:2))!, whp all the d-tuples of variables are frozen tuples. For a given set of(cid:2) }, consider the sub-hypergraph G that contains all the hyperedges ( y1, . . . , yd−d(cid:2) ) such that the(cid:2)(cid:2)variables in a(cid:2)dclausexi1∨ · · · ∨ xid(cid:2) ∨ y1 ∨ · · · ∨ yd−d(cid:2)Y. Gao / Artificial Intelligence 173 (2009) 1343–13661361is in F n,pwe havek,d (d(cid:2)). We see that G follows the distribution of the random hypergraph G(n − d(cid:2), p, d − d(cid:2)). Applying Lemma A.2,P{S is not a frozen tuple} (cid:2) n−(1+(cid:3))c2αd (k−d(cid:2))2(d−d(cid:2))! .Since there are(cid:2)Similar to the proof of Theorem 3, for each frozen tuple S = {xi1 , . . . , xidpossible subsets of dvariables, the claim follows from Markov’s inequality.(cid:2) }, a parametric resolution derivation of size(cid:6)(cid:5)nd(cid:2)(d − d(cid:2))k−d(cid:2)exists for the clausexi1∨ · · · ∨ xidFrom the collection of(cid:2) .exists for the collection of(cid:6)(cid:5)nd(cid:2)(cid:5)nd(cid:2)−1clauses {xi1(cid:6)∨ · · · ∨ xidclauses of size d(cid:2) − 1(cid:2) , 1 (cid:2) i j (cid:2) n, i j (cid:9)= il}, a parametric resolution derivation of size(cid:5)nd(cid:2)−1(cid:6)n{xi1(cid:2)−1) , 1 (cid:2) i j (cid:2) n, i j (cid:9)= il}.∨ · · · ∨ xi(dContinuing in this way, we see that a parametric resolution derivation for all the clauses {xi, 1 (cid:2) i (cid:2) n} of size(cid:6)(cid:2) (cid:5)O ((d − dn) exists, from which a size-n parametric proof of size n exists for the contradiction. This completes thed(cid:2)proof. (cid:2)(cid:2))k−dFor satisfiable region, the best we currently have is that for clause probability p(n) = o( log nnd−1 ), random instances canbe shown to be satisfiable due to an observation similar to Lemma 2.2. In contrast, the phase transition occurs at p(n) =Θ( log n(cid:2) ). One possible approach to extending the idea of the algorithm W-SAT is to make use of the notion of a k-frozennd−dtuple in the proof of Theorem 6 and to reduce the random formula on those frozen tuples. We can show that there aremany such k-frozen tuples in a random formula, but are unable to show that the extended algorithm succeeds with highprobability.We leave it as a future work and challenge for researchers in AI and algorithms to make progress toward closing thishuge gap.9. ConclusionsData reduction is a powerful pruning technique that has been widely used in many areas of AI and algorithmics. Un-derstanding the effectiveness and applicability of data reduction as a technique for the design of heuristics for intractableproblems has been one of the main motivations behind the study of phase transitions of randomly-generated NP-completeproblems.The current paper takes the first step to extend this line of research to intractable parameterized problem. We proposeda non-trivial random model for a generic intractable parameterized problem, the weighted d-CNF satisfiability problem,and provided an almost complete characterization of the probabilistic behavior of the model. To the best knowledge ofthe author, our algorithm and its analysis present the first sound theoretical evidence on the effectiveness of using simplereduction rules to solve intractable parameterized problems.We believe that the results and insights obtained in this study have potential applications in characterizing the structureof the solution space of standard propositional satisfiability problem [3] and in improving the effectiveness and the efficiencyof local-search-based satisfiability algorithms. It is also interesting to use the models and ideas developed in this work tostudy other parametric problems, especially those related to backdoor detection problems and PSPACE-complete AI planningproblems.With regard to future work on the random models of weighted CNF satisfiability proposed in this paper, we list in thefollowing several interesting (and challenging) tasks:(1) In this paper, we only have a limited success in establishing lower bounds on the parametric resolution complexityof random instances of F n,pk,d for MINI-WEIGHTED d-SAT. Establishing lower bounds for the size of general parametric(tree) resolution proof systems seems to require new techniques other than those that have been shown to be powerfulin the study of (non-parametric) resolution complexity of random CNF formulas [9].(2) As has been mentioned in Section 3, for p = c log nnd−1 with c small enough, there will be sufficient number of “isolated”variables and by simply setting k of these variables to TRUE and the remaining variables to FALSE, we get a weight-ksatisfying assignment. It is interesting to see what will happen if these isolated variables are removed.(3) More importantly, we see that a thorough understanding of the general model F n,p(cid:2)) is a challenging task, requiringnew ideas, analytical techniques, and significant empirical studies. We leave it as a challenge for researchers in thefields of AI and algorithms to study the behavior of this general model.k,d (dAcknowledgementsI would like to thank the three anonymous referees for their careful reading of the paper and for their thoughtfulfeedbacks. Their detailed suggestions and criticisms have helped improve the paper significantly.1362Y. Gao / Artificial Intelligence 173 (2009) 1343–1366Appendix A. Proof of Lemma 4.1For the case of WEIGHTED 2-SAT, Lemma 4.1 is a statement similar to that on the minimum vertex degree is a randomgraph, and results in random graph literature can be applied (Theorem 3.5 in [12]).For the case of WEIGHTED d-SAT with d > 2, the complication is that we require the hyperedges that a variable belongsto are pairwise vertex-disjoint. Note that Lemmas 4.4 and 4.5 deal with the same complication, but because of the termlog2 nnin the bound, they are not strong enough to guarantee that whp all the variables are k-frozen. To achieve this, weresort to the extended Janson inequality (see, e.g., Theorem 8.1.2 in [6]), but note that this approach doesn’t work forMINI-WEIGHTED d-SAT instances.Lemma A.1 (The Extended Janson Inequality, Theorem 8.1.2 [6]). Let ({0, 1}Ω , P ) be an independent product probability space whereΩ is a finite set, I be a finite index set, and Ai , i ∈ I, be a subset of Ω . For each i ∈ I , let B i be the eventP{B i ∩ B j} where i ∼ j means that “i (cid:9)= j and Ai ∩ A j (cid:9)= ∅”. Assume that (cid:8) (cid:3) μ. We have(cid:16)μ =ω = (ω j) ∈ {0, 1}Ω : ω j = 1 ∀ j ∈ Ai(cid:16)P{B i}, and (cid:8) =(cid:4) (cid:20)(cid:21)i∼ ji(cid:3),(cid:2)P(cid:2) e− μ22(cid:8) .B iiWe will first establish a result on the existence of k-disjoint hyperedges in a random hypergraph which is interesting inits own right.Remark. We thank one of the referees who noticed that our original proof, given in the context of random CNF formulas,actually applies to the more general case of random hypergraphs. After checking the literature further, we see that the resultcan be regarded as a generalization of some result in random graphs on the bound of the lower tail probability of smallsubgraph counts (see, e.g., Theorem 8.7.2 in [6] and Theorem 4.1 in [12]).Lemma A.2. Let G(n, p, d) be a random hyper graph with edge probability p = p(n) = b log nnda set of k vertex-disjoint hyperedges in G(n, p, d) and M the complement of M. We haveand let M be the event that there existsP{M} (cid:2) n− (1+(cid:3))b2k2d!for some constant (cid:3) > 0.(A.1)Proof. We prove the lemma by using the extended Janson inequality. For this purpose, let P be the family of the collectionsof k pairwise disjoint subsets of d vertices, i.e.,(cid:2)P =(Y i, 1 (cid:2) i (cid:2) k): Y i ⊂ V , Y i ∩ Y j = ∅, |Y i| = d.(cid:3)We also require that the vertices in each collection (Y i, 1 (cid:2) i (cid:2) k) are distinct. Here, the set of all possible hyperedgesplays the role of Ω , the set P plays the role of I , and sets of k hyperedges play the role of Ai ’s in the extended Janson’sinequality.For a given Y = (Y i, 1 (cid:2) i (cid:2) k) ∈ P , let BY be the event that the hyperedges Y i , 1 (cid:2) i (cid:2) k, are in the random hypergraphG(n, p, d). We haveThere areP{BY } =(cid:5)nd(cid:6)(cid:5)|P| = 1k!(cid:5)(cid:6)k.p(n)(cid:5)(cid:6)n−(k−1)ddn − dd· · ·(cid:8)(cid:7)(cid:8)dn−dd(cid:7)n(cid:6)· · ·ways to choose k vertex-disjoint subsets of size d. Consequently, the size of P is(cid:7)(cid:8)n − (k − 1)ddsince there are 1k! ways to arrange the k subsets. It follows that the expected number of sets of k disjoint hyperedgesμ =(cid:13)Y∈PP{BY }can be bounded as(cid:7)1 − (k − 1)dn(cid:8)kd 1k!d!(cid:5)p(n)nd(cid:5)(cid:6)k (cid:2) μ (cid:2) 1k!p(n)nd(cid:6)k.(A.2)Y. Gao / Artificial Intelligence 173 (2009) 1343–13661363To apply the extended Janson inequality, we estimate the (cid:8) in Lemma A.1,(cid:13)(cid:8) =P{BY1∩ BY2},Y1∩Y2(cid:9)=∅where the sum is over all the ordered pairs (Y1, Y2) ∈ P × P such that Y1 ∩ Y2 (cid:9)= ∅.For any pair (Y1, Y2) such that |Y1 ∩ Y2| = i, we have(cid:6)p(n)2k−i.} =(cid:5)P{BY1∩ BY2(A.3)The total number of ordered pairs (Y1, Y2) with i overlaps, which is equal to the total number of ways to select i + (k −i) + (k − i) = 2k − i pairwise disjoint subsets of k variables where i of them play the special role of shared subsets, is(cid:8)(cid:8)(cid:7)(cid:8)(cid:7)1i!(k − i)!(k − i)!(cid:7)ndn − dd· · ·n − (2k − i − 1)dd,(A.4)where the term1i!(k−i)!(k−i)! takes care of the different ways to arrange the subsets in different parts of a pair of subsets.Letsi =(cid:13)|Y1∩Y2|=iP{BY1∩ BY2}.From Eqs. (A.3) and (A.4) with p(n) = b log n(cid:7)(cid:8)(cid:7)nd2k−isi (cid:2)1i!(k − i)!(k − i)!=1i!(k − i)!(k − i)!(cid:7)b log nndb log nd!(cid:8)2k−i., it follows that(cid:8)2k−indd!Write t = b log nd!so that si (cid:2)i!(k−i)!(k−i)! t2k−i . We have1k−1(cid:13)(cid:13)(cid:8) =P{BY1∩ BY2} =k−1(cid:13)i=1sii=1k−1(cid:13)i=1(cid:2)|Y1∩Y2|=i1i!(k − i)!(k − i)! t2k−i1=(k − 1)!(k − 1)! t2k−1= (k−1)!(k−1)!(cid:7)1 +g2kt+g3kt2+ · · · +(cid:8)gk−1ktk−1(A.5)where giki!(k−i)!(k−i)! is a constant since k is a constant.Since limn→∞ t = ∞, for any (cid:3) > 0 there is an integer N = N((cid:3)) > 0 such that for any n > N((cid:3)), the last term (1 + g2+ · · · + gk−1tk−1 ) in the above is upper bounded by 1 + (cid:3). Therefore, we havektkg2kt2+(cid:8) (cid:2) (1 + (cid:3))1(k − 1)!(k − 1)! t2k−1.Therefore,μ22(cid:8) is asymptotically lower bounded by(1 + (cid:3))b log n2k2d!.It follows from the extended Janson’s inequality that(cid:21)P{M} = PBY(cid:2) e− (1+(cid:3))b2k2d!log n = n− (1+(cid:3))b2k2d! .(cid:4)(cid:20)YThis completes the proof of lemma. (cid:2)An immediate application of Lemma A.2 is the following corollary on the minimum number of vertex-disjoint hyperedgeson a vertex in a random hypergraph.1364Y. Gao / Artificial Intelligence 173 (2009) 1343–1366Corollary A.1. Let G(n, p, d) be a random hyper graph with edge probability p = p(n) = b log nvertex-disjoint hyperedges on a vertex. We have for any b > 2k2(d − 1)!nd. Let δ be the minimum number ofP{δ < k} = 0.limn→∞(A.6)Note the extra term 2k2 in the lower bound for b, as compared to similar results for the minimum vertex degree in arandom graph (Theorem 3.5 in [12]). We believe this is due to the requirement of vertex-disjointness, and do not know if itcan be improved.Proof. For a given vertex, the sub-hypergraph on V \ x that contains all the hyperedges { y1, . . . , yd−1} such that{x, y1, . . . , yd−1} is a hyperedge in G(n, p, d) follows the distribution of the random hypergraph G(n − 1, p, d − 1). Ap-plying Lemma A.2 and using Markov’s inequality, we see that whp all vertices are incident to at least k vertex-disjointhyperedges in G(n, p, d). (cid:2)We are now ready to use Lemma A.2 to prove Lemma 4.1. Let x be a fixed variable. Consider the sub-hypergraph G onthe set of variables X \ {x} that contains all the hyperedges Y = ( y1, . . . , yd−1) such that x ∨ y1 ∨ · · · ∨ yd−1 is a clauseappearing in the random CNF formula F n,pk,d . We see that G is a random hypergraph G(n − 1, p, d − 1) with edge probabilityp(n) = c log n(n−1)d−1 where b = c, it follows from Lemma A.2nd−12d−1that. Applying Lemma A.2 to G(n − 1, p, d − 1) with p = b log(n−1)12d−1P{x is not k-frozen} (cid:2) P{G does not contain k disjoint hyperedges}(A.7)for any (cid:3) > 0. If c > 2k2(2d − 1)(d − 1)!, take an enough small (cid:3) > 0 such that (1 + (cid:3))c > 2k2(2d − 1)(d − 1)!. For n > N((cid:3))and by Markov’s inequality, the probability that all variables are k-frozen is at least−(1+(cid:3))c2k2(2d −1)(d−1)!(cid:2) elog n,−(1+(cid:3))c2k2(2d −1)(d−1)!1 − nelog n = 1 − o(1).This proves Lemma 4.1.Appendix B. Proof of Lemma 4.6Proof. Recall that A is the event that a random instance of F n,pk,d induces all the edge of a fixed tree T with vertex set V Tof size log n. We estimate the number of ways that a random formula induces a copy of the tree T . The counting argumentused below is a generalization of the one used in [26,39].Let F T be a set of clauses such that every edge of T is induced by some clause in F T . We say that F T is minimal ifdeleting any clause from it leaves at least one edge of T uncovered.Consider the different ways in which we can cover the edges of T by clauses. Treat the clauses in F T as being groupedinto d − 1 different groups {S i, 1 (cid:2) i (cid:2) (d − 1)}. A clause in the group S i is in charge of covering exactly i edges of T . Notethat a clause in the group S i may “accidently” cover other edges that are not its responsibility. As long as each clause hasits own dedicated set of edges to cover, there won’t be any risk of under-counting.Let si = |S i|, 1 (cid:2) i (cid:2) d − 1. Since there are log n − 1 edges in T and a clause in S i is dedicated to i edges of T , we have0 (cid:2) si (cid:2) log n/i andd−1(cid:13)isi = log n − 1.i=1ways to pick the dedicated sets of i edges for the si clauses in group S i .Counting very crudely, there are at most(cid:6)(cid:5)Since T is a tree, each set of i edges in T involves at least i + 1 variables, and consequently there are at most(2d − 1)nd−(i+1)ways to select a clause for a set of i edges. Given fixed si , 1 (cid:2) i (cid:2) d − 1, let E T (s1, . . . , sd−1) be the expected number ofclause sets F T that cover the edges of T such that each clause in the group S i is dedicated to i edges. We have(cid:6)si(cid:5)log ni(B.1)E T (s1, . . . , sd−1) (cid:2)(cid:7)d(cid:15)(cid:8)silog nii=1(cid:7)nd − (i + 1)(cid:8)(cid:5)(cid:7)(cid:6)2d − 1(cid:8)sic log n2d − 11nd−1(cid:2) (log n)(cid:16)d−1i=1 isi n(cid:16)d−1i=1 (d−i−1)si(cid:5)2d − 1(cid:6)(cid:16)d−1i=1 (d−i−1)si(cid:7)c log n2d − 11nd−1(cid:8)(cid:16)d−1i−1 si(cid:16)d−1i=1 (−isi )n f (d,c)(log n)log n(cid:2) (log n)log nn= n f (d,c)(log n)2 log nn− log n+1where f (d, c) is a function that only depends on d and c. By Markov’s inequality, the P{A} can be upper bounded asY. Gao / Artificial Intelligence 173 (2009) 1343–13661365P{A} (cid:2)log n(cid:13)log n(cid:13)log n(cid:13)· · ·E T (s1, . . . , sd−1)s1=1s2=1sd−1=1(cid:2) (log n)d−1n f (d,c)+1(log n)2 log nn− log n.This proves Lemma 4.6. (cid:2)Appendix C. Proof of Lemma 2.2We give a proof to Lemma 2.2 on the trivial random instances. First, consider the case where monotone clauses are notk,d . Let G be the hypergraph on the set X of n variables that contains only those edges Y = ( y1, . . . , yd) suchk,d . We see that G has the distribution of the random hypergraphforbidden in F n,pthat the monotone clause y1 ∨ y2 ∨ · · · ∨ yd appears in F n,pG(n, p. It follows from Lemma A.2 that for any p(n) (cid:3) b log n(cid:2), d) with edge probability p(cid:2) = p(n)12d−1nd(cid:2)PF n,pk,d contains k disjoint monotone clause(cid:3)(cid:3) 1 − n− (1+(cid:3))b2k2d! = 1 − o(1).is extremely small — with such a probability, the average number of clauses in F n,pk,d is O (log n). This provesNote that b log nndLemma 2.2(1).∗that a given variable does not appear as a negated literal in F n,pk,d .To prove Lemma 2.2(2), consider the probability pWe have(cid:7)(cid:5)∗ =p(cid:6)1 − p(n)+ p(n)(cid:8)( nd−1)2d−1 − 12d − 1(cid:7)1 − 2d−12−1(cid:2)(cid:8) nd−1(d−1)!p(n).For p = c log n∗is asymptotically greater thannd−1 , p−c 2d−12d −1n1(d−1)! .It follows that the expected number of variables that does not appear as a negated literal in F n,pk,d is∗pn (cid:3) n1−c 2d−12d −11(d−1)!which goes to infinity if(cid:7)c <2d−12d − 11(d − 1)!(cid:8)−1.Using Chebyschev’s inequality, it can be shown that whp there are more than k variables that does not appear as a negatedliteral in F n,pnd−1 with small enough c or p(n) ∈ o( log nnd−1 ).k,d whenever p = c log nReferences[1] D. Achlioptas, H. Jia, C. Moore, Hiding satisfying assignments: Two are better than one, Journal of Artificial intelligence 24 (2005) 623–639.[2] D. Achlioptas, Y. Peres, The random k-SAT threshold is 2k log 2−o(k), in: Proceedings of the 35th Annual Symposium on Theory of Computing (STOC’03),2003, pp. 223–231.[3] D. Achlioptas, F. Ricci-Tersenghi, On the solution-space geometry of random constraint satisfiability problems, in: Proceedings of the 38th AnnualSymposium on Theory of Computing (STOC’06), 2006, pp. 130–139.[4] J. Alber, N. Betzler, R. Niedermeier, Experiments on data reduction for optimal domination in networks, Annals of Operations Research 146 (2006)105–117.[5] N. Alon, N. Kahale, A spectral technique for coloring random 3-colorable graphs, SIAM J. Computing 26 (1997) 1733–1748.[6] N. Alon, J. Spencer, The Probabilistic Method, Wiley, 2000.[7] P. Beame, R. Karp, T. Pitassi, M. Saks, The efficiency of resolution and Davis–Putnam procedures, SIAM Journal on Computing 31 (4) (2002) 1048–1075.[8] A. Becker, R. Bar-Yehuda, D. Geiger, Randomized algorithms for the loop cutset problem, Journal of Artificial Intelligence (2000) 219–234.[9] E. Ben-Sasson, A. Wigderson, Short proofs are narrow-resolution made simple, Journal of ACM 49 (2) (2001) 149–169.[10] C. Bessiére, E. Hebrard, B. Hnich, Z. Kiziltan, C. Quimper, T. Walsh, The parameterized complexity of global constraints, in: Proceedings of the 23thAAAI Conference on Artificial Intelligence (AAAI’08), 2008, pp. 235–240.[11] S. Böcker, S. Briesemeister, G. Klau, Exact algorithms for cluster editing: Evaluation and experiments, in: Proceedings of the 7th International Workshopon Experiment Algorithms (WEA’08), 2008, pp. 289–302.1366Y. Gao / Artificial Intelligence 173 (2009) 1343–1366[12] B. Bollobas, Random Graphs, Cambridge University Press, 2001.[13] B. Bollobas, C. Borgs, J. Chayes, J. Kim, D. Wilson, The scaling window of the 2-SAT transition, Random Structures and Algorithms 18 (3) (2001)201–256.[14] P. Cheeseman, B. Kanefsky, W. Taylor, Where the really hard problems are, in: Proceedings of the 12th International Joint Conference on ArtificialIntelligence, Morgan Kaufmann, 1991, pp. 331–337.[15] H. Chen, A. Frieze, Coloring bipartite hypergraphs, in: Proc. of the 5th International IPCO Conference on Integer Programming and CombinatorialOptimization, 1996, pp. 345–358.[16] J. Chen, B. Chor, M. Fellows, X. Huang, D. Juedes, I. Kanj, G. Xia, Tight lower bounds for certain parameterized NP-hard problems, Information andComputation (2005) 216–231.[17] J. Chen, S. Lu, S. Sze, F. Zhang, Improved algorithms for path, matching, and packing problems, in: Proceedings of the 18th Annual ACM–SIAM Sympo-sium on Discrete Algorithms, 2007, pp. 298–307.[18] A. Coja-Oghlan, M. Krivelevich, D. Vilenchik, Why almost all satisfiable k-cnf formulas are easy, in: Proc. of the 13th International Conference onAnalysis of Algorithms, 2007, pp. 89–102.[19] S. Cook, D. Mitchell, Finding hard instances of the satisfiability problem: A survey, in: Du, Gu, Pardalos (Eds.), Satisfiability Problem: Theory andApplications, in: DIMACS Series in Discrete Mathematics and Theoretical Computer Science, vol. 35, American Mathematical Society, 1997.[20] N. Creignou, H. Daudé, U. Egly, Phase transition for random quantified XOR-formulas, Journal of Artificial Intelligence Research 29 (2007) 1–18.[21] J. Culberson, I. Gent, Frozen development in graph coloring, Theoretical Computer Science 265 (1–2) (2001) 227–264.[22] S. Dantchev, B. Martin, S. Szeider, Parameterized proof complexity, in: Proceedings of the 48th Annual Symposium on Foundations of Computer Science(FOCS’07), IEEE Press, 2007, pp. 150–160.[23] B. Dilkina, C. Gomes, A. Sabharwal, Tradeoffs in the complexity of backdoor detection, in: Proceedings of the 13th International Conference on Principlesand Practice of Constraint Programming (CP’07), 2007, pp. 256–270.[24] R. Downey, M. Fellows, Parameterized Complexity, Springer, 1999.[25] M. Fellow, C. Knauer, P. Ragde, F. Rosamond, U. Stege, D. Thilikos, S. Whitesides, Faster fixed-parameter tractable algorithms for matching and packingproblems, Algorithmica 2 (2008) 167–176.[26] A. Flaxman, A spectral technique for random satisfiable 3CNF formulas, in: Proc. of 14th ACM–SIAM Symposium on Discrete Algorithms, 2003, pp. 357–363.[27] F. Fomin, F. Grandoni, D. Kratsch, Some new techniques in design and analysis of exact (exponential) algorithms, Bulletin of EATCS 87 (2005) (Tech.rep.).[28] Y. Gao, Phase transitions and complexity of weighted satisfiability and other intractable parameterized problems, in: Proceedings of the 23th AAAIConference on Artificial Intelligence (AAAI’08), 2008, pp. 265–270.[29] Y. Gao, J. Culberson, An analysis of phase transition in NK landscapes, Journal of Artificial Intelligence Research 17 (2002) 309–332.[30] Y. Gao, J. Culberson, Consistency and random constraint satisfaction models, Journal of Artificial Intelligence Research 28 (2007) 517–557.[31] I. Gent, T. Walsh, Analysis of heuristics for number partitioning, Computational Intelligence 14 (3) (1998) 430–451.[32] C. Gomes, C. Fernandez, B. Selman, C. Bessiere, Statistical regimes across constrainedness regions, Constraints 10 (4) (2005) 313–337.[33] C. Gomes, T. Walsh, Randomness and structure, in: F. Rossi, P. van Beek, T. Walsh (Eds.), Handbook of Constraint Programming, Elsevier, 2006, pp. 639–664.[34] G. Gottlob, F. Scarcello, M. Sideri, Fixed-parameter complexity in AI and nonmonotonic reasoning, Artificial Intelligence 138 (1–2) (2002) 55–86.[35] G. Gottlob, S. Szeider, Fixed-parameter algorithms for artificial intelligence, constraint satisfaction, and database problems, The Computer Journal 51 (3)(2008) 303–325.[36] J. Gramm, J. Guo, F. Hüffner, R. Niedermeier, Data reduction, exact, and heuristic algorithms for clique cover, in: Proceedings of the 8th Workshop onAlgorithm Engineering and Experiments (ALENEX’06), 2006, pp. 86–94.[37] J. Guo, R. Niedermeier, Invitation to data reduction and problem kernelization, SIGACT News 38 (1) (2007) 31–45.[38] H. Jia, C. Moore, D. Strain, Generating hard satisfiable formulas by hiding solutions deceptively, Journal of Artificial Intelligence Research (2007) 107–118.[39] M. Krivelevich, D. Vilenchik, Solving random satisfiable 3CNF formulas in expected polynomial time, in: Proc. of 17th ACM–SIAM Symposium onDiscrete Algorithms, 2006, pp. 454–463.[40] M. Langston, A. Perkins, A. Saxton, J. Schaffer, B. Voy, Innovative computational methods for transcriptomic data analysis: A case study in the use ofFPT for practical algorithm design and implementation, The Computer Journal 51 (2008) 26–38.[41] D. Marx, Parameterized complexity of constraint satisfaction problems, Computational Complexity 2 (2005) 153–183.[42] C. McDiarmid, General percolation and random graphs, Adv. Appl. Prob. 13 (1981) 40–60.[43] M. Mezard, R. Zecchina, The random k-satisfiability problem: From an analytic solution to an efficient algorithm, Phys. Rev. E 66 (2002).[44] M. Molloy, Models and thresholds for random constraint satisfaction problems, in: Proceedings of the 34th ACM Symposium on Theory of Computing,ACM Press, 2002, pp. 209–217.[45] R. Monasson, R. Zecchina, Statistical mechanics of the random k-sat model, Phys. Rev. E 56 (1997) 1357.[46] R. Niedermeier, Invitation to Fixed-Parameter Algorithms, Oxford Univ. Press, 2006.[47] N. Nishimura, P. Ragde, S. Szeider, Detecting backdoor sets with respect to Horn and binary clauses, in: Proceedings of the Seventh InternationalConference on Theory and Applications of Satisfiability Testing (SAT’04), 2004.[48] S. Szeider, Backdoor sets for DLL subsolvers, Journal of Automated Reasoning 1–3 (2005) 73–88.[49] B. Vandegriend, J. Culberson, The Gn,m phase transition is not hard for the Hamiltonian Cycle problem, Journal of Artificial Intelligence Research 9(1998) 219–245.[50] K. Weihe, Covering trains by stations or the power of data reduction, in: Proceedings of the Workshop on Algorithm and Experiments (ALEX’98), 2006,pp. 86–94.[51] K. Xu, F. Boussemart, F. Hemery, C. Lecoutre, Random constraint satisfaction: Easy generation of hard (satisfiable) instances, ArtificialIntelli-gence 171 (8–9) (2007) 514–534.[52] W. Zhang, A. Rangan, M. Looks, Backbone guided local search for maximum satisfiability, in: Proceedings of the 18th International Joint Conference onArtificial Intelligence (IJCAI’03), 2003, pp. 1179–1184.