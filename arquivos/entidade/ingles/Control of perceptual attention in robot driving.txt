ELSEVIER Artificial Intelligence 78 (1995) 397-430 Artificial Intelligence Control of perceptual attention in robot driving Douglas A. Reeceaq*, Steve A. Shaferb “Institute for Simulation and Training, University of Central Florida, 3280 Progress Drive, Orlando, FL 328260.544, USA ‘Department of Computer Science, Carnegie Mellon University, Pittsburgh, PA 15213, USA Received March 1993; revised July 1994 Abstract difficult and computationally to solving fields of view, and relatively Computer vision research aimed at performing general scene understanding vision this problem. Active vision systems use optimized to be conceptually approach reduced information motivates research how active vision could be used for a realistic task in a dynamic domain. We are studying such a task: driving an autonomous vehicle in traffic. has proven is a promising sensor settings, to efficiently extract specific simple algorithms is only appropriate in the context of a task that to extract. While there has been a fair amount of from a scene. This approach the selection of the information that describes the extraction processes, there has been little work complex. Active investigates that process introduce that use a method the required and estimate for controlling visual attention three programs the efficiency gained this paper we present for driving, and analyze sensing with a general driving-scene understanding In reasoning describe a model of driving and the driving environment, performing then techniques routines, which use known second program, Ulysses-2, creates an inference data on action choices, and searches Ulysses-3 uses domain knowledge change over time; objects that do not move enough selected as perceptual to measure techniques orders of magnitude when compared as part of the in doing so. We first the complexity of system. We control increasingly to select perceptual actions. The first program, called Ulysses-l, uses perceptual the search for new objects. The to guide input to sense. Finally, to reason about how dynamic objects will move or to affect the robot’s decisions are not in simulation that the cost of perception by 9 to 12 the cost savings realized by using selective perception. We estimate included targets. For each technique we have run experiments the computational to a general perception tree to infer the effect of uncertain this tree to decide which data in Ulysses-3 reduce reference objects sophisticated perceptual system. * Corresponding author. E-mail: dreece@ist.ucf.edu. 0004-3702/95/$09.50 SSDZ 0004-3702(95)00029-l @ 1995 Elsevier Science B.V. All rights reserved 3% D.A. Keew. S.A. Shafer ’ Artificial lntelligencr 78 (1995) 397-430 1. Introduction I. 1. The need to control perceptuul attentiorl the real world. Computer robot of arbitrary Early mobile research These problems were expressed away from view of a robot by developing descriptions difficult cost. More robots with the information characterize not completely ters, the scene. information to accomplish, Such vision is needed. concentrated in symbolic vision general systems a robot on making solve problems. form, having already been abstracted research to match has attempted that can build complete this symbolic to be extremely scenes. This vision task has proven and when it is possible it is often at great computational recently, activr vision has been seen as a more feasible way to provide they need the entire to solve problems. Active vision systems do scene, but instead optimize sensor parame- field of view. and algorithms systems depend to extract specific information from on an external task to determine the what that active perception in a dynamic is essential for a mobile environment. In addition for such a robot must the to perform task. Thus perception select perceptual actions and action parts of the same control program control called Ulysses, drives a simulated integrates that function. in an environment that is dynamic robot performing actions, information should to choosing to get selection a a be research we have selec- and action that and visually complex. Driving In our perception robot in traffic-a task is encoded set of perceptual its choice of actions, currently Ulysses we developed in such a way that Ulysses can reason how actions. Ulysses considers requests appropriate sensory operates called PHAROS; in a world provided PHAROS simulates and carries out the maneuvers. PHAROS also controls it to select an could about traffic objects data, and commands by a detailed traffic the perceptual the other vehicles We believe task complex controller needed indistinguishable developed a robot tion. The program, is fairly complex, knowledge efficient affect maneuvers. simulator actions in the environment. a example. through an arbitrary shape, reflections, are illustrated following in Fig. 1. It shows a robot driving locations and poses. To recognize the by of this paper scene shown in various central themes vehicles the driving a perception The Consider scene containing vehicle, color. and illumination, surfaces, transparent the directions image of the scene. A perception scene would have the identify of these robot driver Fortunately, occlusions, and all other factors to do in a dynamic it is not necessary completely. robot, scene from system would have to consider variations in vehicle as well as anomalies due to surface markings, etc. The vehicles so appear system in different attempting are different locations distances the in to find all vehicles and robot’s in the to search all possible the perception locations, system would traffic objects, with similar variations. together make such exhaustive perception Even humans situation. ranges, for a robot driver and poses. To interpret to locate also have The combinatorics and of all for a far too expensive cannot to update do this. its world mode1 a throughout completely. Although traffic objects may be found in many locations D.A. Reece, S.A. Shafer / Artificial Intelligence 78 (1995) 397-430 399 Fig. 1. A driving scene. it is wasteful to look for all of them because they are not all important scene, the robot. As the robot considers etc. appropriate areas. Fig. 2 illustrates that affect its choice of actions, the various physical limitations, it can look for relevant this limited visual search. to traffic rules, in the objects 1.2. Driving and sensing with Ulysses The Ulysses driving program to understand many complex represents driving knowledge well enough allow Ulysses actions. Driving knowledge also allows Ulysses to reason about perception select perceptual perception. programs: Ulysses-l, to traffic situations and select safe and for controlling three in actions. We present specific methods These methods incrementally implemented have been -2 and -3. three (1) The Ulysses driving model encodes driving rules as a set of constraints and limit the robot’s choice of actions to safe maneuv- to to choose among safe maneuvers allow Ulysses some objective. The constraints and preferences are represented preferences. Constraints ers. The preferences further explicitly as an inference tree with sense inputs on the bottom and an Fig. 2. Selective visual search, 400 D.A. Kerce, S.A. Shafer Artijiclal fnrelligence 78 (19%) 397-430 (2) Ulysses-l input values propagate action output at the top. The tree acts as a constraint network which uncertain through to yield ranges of possible actions. looks only in the appropriate parts of the scene for traffic objects perceptual instead of looking everywhere. Ulysses-l uses task-dependent operators called perceptual routines to narrow its search area. The routines make use of the fact that the meaning of traffic objects depends on their spatial relations the closest car ahead in this lane). The routines search for objects only near specific reference objects. to other objects (e.g., it looks situation the current to determine the most critical traffic environment to constrain where it does not consider (3) Ulysses-2 constrains search areas and also tries to find the minimum set of the correct action. Although Ulysses-l uses for to determine which tree to objects necessary knowledge of the objects, objects are really important. Ulysses-2 reasons using the inference determine routine tree repeated until there perceptual to get the required data. The new information propagates up the is is no uncertainty about what action should be taken. (4) Ulysses-3 uses the same mechanism used in Ulysses-2 but also maintains a and Ulysses- persistent world model. Facts in the model are time-stamped, to reason about how object characteristics 3 uses domain knowledge reasoning process automatically change over determines when changing objects must be sensed again to reduce uncer- tainty. to constrain possible actions. This selection and sensing process input, and calls the appropriate time. The inference tree In this paper we first present an estimate of the complexity of perception for driving to demonstrate why it is necessary for a driving robot to actively focus its the encoding of the driving task and the perceptual this three perceptual reasoning traffic situations and measuring attention. We then describe techniques experimentally the simulated cost of its perceptual actions. used by running Ulysses in Ulysses. The is estimated impact of in various reasoning 1.3. Related work 1.3.1. Active vision that Ulysses performs The attention control is one aspect of active computer vision. Active vision comprises at least two levels of attention control, however. At a high level, active vision involves deciding which parts of the scene are most for the robot to be looking at given its task. This is the level that this important to look from a given viewpoint, paper addresses. Our system considers where than where to move a viewpoint. At a lower level, active vision concerns rather gaze stabilization, pointing control for object tracking, verging stereo, camera- focus, camera motion and localized optical flow, hand coordination, automatic the etc. [5, 71. Ulysses doesn’t consider any of these concept of perceptual routines from the lower-level visual routines of Ullman [65]. We will discuss routines more in Section 4. issues, but does borrow The need to focus perceptual attention has been addressed in a basic way in D.A. Reece, S. A. Shafer I Artificial Intelligence 78 (1995) 397-430 401 so sensing operations find specific objects that uncertainty verified [14, 251. These systems focus attention into plans many systems. Various planners have incorporated or operator to preconditions statically, and are not suitable for a dynamic domain like driving. Hayes-Roth’s patient monitoring limitations and adjusts jilters to system [38] reasons about computational reduce in applications with simple sensory processing requirements, filters are too simplistic for robotics applications. the data flow from the sensors. While they are effective could be resource reduced systems intelligent perception A number of robot systems have used task knowledge to limit visual searches to small portions of the scene. Mobile robots have used these small “windows” so that they have less data to process when looking for signs or other objects [4, 36, 44, 631. These control that the robot always look for the same object in though, since their tasks require about the same place-for example, monitoring a lane line or watching for speed limit signs. Burt [15] also advocates using small windows, but with the ability to move around the image to probe interesting areas. However, Burt did not present specific methods require only minimal for choosing where the windows should be placed. limit search to identify and Ulysses’ use of reference regions dy- for efficient object namically draws on the techniques used by other researchers [13, 31, 49, 601. In these systems a domain-specific model describes detection from spatial relationships between objects. After a hypothesis has been formed relationships information can indicate an effective place to look to confirm or refute the hypothesis. Garvey called this two-phase search indirect search. Wixson [67] performed an analysis of the cost of searching for one object with indirect search as compared with direct search; he found in this case by a factor of 2-8. indirect search to be more efficient in one part of the the spatial detected objects image, illustrate As a vision system, Ulysses is most similar to intelligent agent control systems that use task-directed sensing. For example, Firby’s RAP (for “Reactive Action Package”) system [29] controls both perception and action for a robot. However, while this system may theoretically to program complex visual allow a designer search strategies, the reactive nature of RAPS seems better suited for simple sensing actions, Firby’s examples that verify pre- sensing operations finding an object about to be manipulated. The RAP conditions of actions--e.g., system and Ulysses-3 both use a time-stamped data base and simple models of growing uncertainty in the RAP system is simpler, instead of modeling in position, velocity, etc. Chapman’s Sonja system [18] the related uncertainty also reactively generates sensory actions. In contrast, Ulysses deliberates to try to actions at each moment. We feel that this find the optimum set of perceptual finding good sensing policies in deliberation into complex reactive is a desirable step for automatically and that eventually it uses only the age of information the policies should be compiled to help select perceptual situations, rules. actions. The model though; Ulysses’ use of deliberation body of work on decision-theoretic to select perceptual actions is close in spirit to the [20, 31, 47, 591). These sensing (for example, 402 D.A. Keece, S.A. Shufer Artificiul Intelligence 78 (1995) 397-430 to find confidence in order increase deliberate that systems actions approach Ulysses. While a probabilistic hard constraints would collapse cost of having becomes computationally to a deterministic an accident contrasts with the deterministic approach in our driving model is infinite. expensive the most cost-effective the most in a hypothesis selection is attractive approach for a real-world that a probabilistic suggested one anyway. This perceptual actions- for the least cost. This and the tree the of RAPS, Sonja, problem, decision In addition, is because we assume the probabilistic that approach in a complex domain like driving. commands style, etc. 1.3.2. Driving The driving and operational provides driving the operational have made substantial respectively, symbolic operational sensing operations. task has been characterized as having three levels: strategic, [53]. These levels are illustrated to the level below; the strategic in Table 1. Each level provides to the tactical level, which in turn selects control behaviors level. While sophisticated planning programs progress in automating the strategic neither has addressed active perception. The strategic so does not require level does not require high-bandwidth complex input task planning from tactical in general level a route plan, a for systems levels is mostly the and can rely on fixed level sensors, while and control and operational Ulysses addresses the tactical the domain from driving models: of human task analysis, Tusk analysis models (e.g., a description each. Unfortunately. building relations a given might be performed a driving model. This between situation. tasks. The or whether simultaneously three identified flow control, driving. Michon information [SO]) divide driving of component level. Models of tactical driving have come mostly types of tactical [.53]. and describe into many subtasks tasks alone a task list does not address list does not specify how the driver chooses a task in tasks and motivational is not sufficient the dynamic is because interrupt another, one for task can (especially simulations, Information flow control models are computer [19]. TEXAS driving are incomplete such as SIMRO interleaving These capable However, these simulations of dynamically two or how actions). conflicting of driving behavior. [28, 681, are if they require simulations [33], and NETSIM as required subtasks as driving models. For example, by the situation. they I Table Characteristics Strategic (high level) Tactical (mid level) of three levels of driving Examples Characteristics Existing model Planning Estimating a route: trip tlmc Static; abstract Planning programs Determining of way: right Dynamic; physical Human driving models Passing another car Operational (low level) Tracking Following a lane: a car Feedback control Robot control systems D.A. Reece, S.A. Shafer I Artificial Intelligence 78 (1995) 397-430 403 typically allow cars to change lanes instantly without having to drive across lane such as road lines. These simulations do not represent other physical information geometry, of traffic control devices (TCDs). Finally, these simulations do not address perception and do not contain knowledge of how to interpret from observable objects. location, or the location and appearance traffic conditions accurate vehicle Motivational models are theories of human cognitive activity during driving. “expec- risk”, “target level of risk”, “need to hurry” or “distractions” the models reviewed by van der Molen [66]). These states are combined actions. However, motivational do not concretely These models generally describe mental states such as “intentions”, tancy”, “ perceived (e.g., with perceptions models are typically not computational-they represent driving knowledge, how to perceive information models of human driving (for example, Aasman cognitive process model, but not modeled on human cognition. show how to traffic situations, or how to process to choose actions. Some researchers are now building computational in various ways to produce [2]). Ulysses is essentially a 2. The computational cost of general perception As part of our study of selective perception, we have analyzed sensing the driving environment. This analysis serves two purposes: why selective perception evaluating qualitative impact of this approach magnitude of cost is known. the cost of it illustrates in this domain, and it provides a basis for intuitive, techniques we introduce. While the full indicate some benefits, the order of is essential the selective perception arguments is much more apparent when at least for selective perception For the purposes of this analysis, we have hypothesized a generic scene interpretation system techniques. Although cars directly no one has yet built a complete system that can find all the objects needed situation analysis (for example, directed at lane-keeping collision avoidance, and does not look for vehicles approaching side roads. that uses standard image processing there are now many vision systems that can find roads and in front of or behind a robot, and signs along side the robot’s road, for [16, 34, 51, 691. The road-finding work is mostly is used for car following and intersections on control; vehicle detection interpretation and We have analyzed the processing steps for exhaustively that is polynomial the coefficients of the polynomial and developed a complexity expression in the image. We estimated from characteristics of the scene and of the processing algorithms. The number of pixels was estimated to see and recognize by analyzing ranges. The result is a numeric estimate of the number of objects at the required operations necessary the sensing. A detailed explanation of our cost model the field of view and resolution necessary is contained to perform in [56]. complete perception in the number of pixels 404 D.A. Keece, S.A. Shafer ’ Artificial Intelligence 78 (lYY5) 397-430 2.1. The environment these objects A general perception system has to find all traffic objects of potential interest to include roads regions, the planner. For the Ulysses driving model, road markings, vehicles, traffic signs, and traffic signals. Road markings include lane lines, stop lines, arrows and letters. Vehicle velocity estimates are required. Traffic signs and signals must be detected even when they are turned away from recognize Stop and the line of sight by about 45”. The robot must sometimes features [58]. The size of the object Yield signs from the back at intersection the resolution needed determines them, and the number of variations determines the number of models that must be matched against scene regions. We took the object characteristics Since it is not practical the entire world, we arbitrarily it may be set a range desirable to be visible from 218m away on a road with 100 kph traffic [27, p. 4B-111, and the sight distance needed for passing is given as 30.5 m at this speed [l, p. 1471. While for this work we have Ulysses concentrated is more diverse. Since streets have lower speeds than highways, we have chosen 150 m as the range limit. perceptual to see long distances ahead; for example, signals are supposed is capable of driving on simulated highways, from a standard highway design manual [27]. on arterial urban streets where limit on the sensor system. In some driving situations to consider perceiving the environment to detect Our analysis of perceptual cost considers factors not explicitly represented the environment modeled by PHAROS. The environment shadows, trees, clouds, occluding objects, prevent us from using cheap recognition features. For example, although standard segmenting out sign regions, the same colors. Additional signs from the other regions in the image. in to have textures, and reflections. These factors algorithms based on single, uniform traffic sign colors will be useful for there may be other signs or other objects that have the traffic information will be needed to distinguish is assumed 2.2. Object recognition procedures Our generic perception system has three main steps: feature extraction, model matching, and secondary matching. image Image includes transformation transformation, Feature extraction region properties image segmentation, includes computation. region property transforming color space, detecting edges, converting nates, or making correlations computing require performing transformed comparisons pixels to regions. Based on experiments we have performed with outdoor scenes, we believe that the number of regions is generally proportional the number of pixels. Thus and steps such as range data to local coordi- image and the (e.g. texture, moments, average color, etc.) both the image to find regions not only involves operations on each pixel, but regions when assigning between pixels and regions and between images of to that the cost of segmentation image. Segmenting flow. Transforming has a component on each pixel for optical operations in the D.A. Reece, S. A. Shafer I Artificial Intelligence 78 (1995) 397-430 405 depends on the square of the number of pixels. We estimated the cost coefficients of these feature extraction algorithms from our experiences at CMU in perception for vehicle navigation and an examination of the literature 431. [ll, 22, 26, 30, 37, 39, [lo]. The complexity The model matching step involves matching S scene features to M object model features is M ’ in the worst case, but can be reduced substantially by introducing heuristics such as constraints and object hierarchies it [26, 351. The complexity of matching with heuristics that depends on how well the heuristics work in a given domain. We assumed heuristics would prune the search tree strongly so that after two model features were matched only one scene feature would match each remaining model feature. In is roughly proportional to the number of pixels cubed. is not fixed because is only proportional the complexity to S3, which this case We assume a secondary matching step to find details on traffic objects that have in the primary model matching step. Two-step matching avoids been recognized the entire scene at high resolution. The cost of secondary having to examine to primary matching, however, because the reduction matching is still comparable in scene area is almost countered by the increase in resolution. Surface markings in particular to detect at maximum range. require very high resolution The resulting complexity expression for general driving perception is approxi- mately lO$ + p2 + 10-5p3 ) where p is the number of pixels in the image. (1) 2.3. Pixel count The number of pixels in the processed image is basically determined by the that a general resolution. We assume field of view and the required system would have to see 360” around required driving perception the robot, but only 45” up and down. The angle subtended by a pixel must be no larger than the smallest required scene feature; we estimate that this will be a 30 cm patch of road. Such a patch subtends only (1.5 x 10-3)” at 150 m range when viewed from an assumed sensor height of 2m. We further assume system will take advantage of the fact that objects will be in a vertical range of about 0 to 7 m high. Thus when looking at that are very close (and therefore big). The system can thus use larger markings pixels at high and low sensor angles. The net result is that approximately 8.1 X lo7 to analyze the whole scene. Using this pixel count in Eq. (1) pixels are required above, 9 X lOi image the operations. the sensors are pointing down at 45”, they are that the perception is approximately to analyze total cost a single Ulysses is assumed require would perception. A “fast” computer about 10 ’ operations to process a new image every 100 milliseconds; so Ulysses if it used naive, exhaustive that can perform a billion operations per second per second 406 D.A. fleece. S.A. Shafer / Artificial Intelligence 78 ( 199-5) 397-430 thus be almost 11 orders of magnitude too slow to analyze would if these estimates approach its perceptual are off by several orders of magnitude, and that the driving is intractable to perception focus of attention. the scene. Even that a general limit it is clear robot must sharply 3. A model of robot driving We are studying selective perception in for selective sort of program linked driving. Actually. we are developing because driving this to the task. This section describes intimately is devoted mostly [%I. The discussion describe in later sections perception -2. or -3. We begin by describing Ulysses. Next we present PHAROS, here control the simulator to develop used and the and refer how some of the driving knowledge Finally, architecture of Ulysses. test Ulysses. the context perception real-world task: of a real-world together with a robot activity, perception is to the task of selecting maneuvers; our driving program, Ulysses we to the system as Ulysses-l, is encoded we describe in 3.1. Tactical driving knowledge task signals, Tactical of these objects varies depending is a complex signs. driving surface markings, meaning and each other. Some of this complexity to yield by the nearby robot the distance, whether consider intersection. it (the robot) its intended maneuver. is required likely constraints should speed, stop. and that requires the robot to consider and other vehicles in various they are relative in Fig. 3. In this figure, on where is illustrated sign, but it must make a judgment on the vehicle to the right if the robot does not stop, In addition, the signal and the approaching locations. roads, The to the robot the about to decide it must car at the next In our system, Ulysses controls and a lane command robot maneuvers for by repeatedly driving selecting knowledge an is acceleration encoded in constraints Constraints generally traffic the speed it can stop before For example, limit, actions. below have right of way, can slow down without hitting is constrained allowed are combined Preferences by the robot’s turn maneuvers logical by taking the remaining select among “go as fast as possible”. Of the allowed prefers intended relevant constraint- lanes, intersections the highest in adjacent with their at distant with turns preference and preference-based the highest one. For and preferences robot. Ulysses’ the for each of these commands. limit rules encode and that robot the so that is constrained acceleration when the robot does not enter an intersection traffic safety the robot’s stays speed it does not road, and it that car brake. Lane choice lanes’ (detected) of the the end of the known the car in front should lanes, and the compatibility intended maneuver. These constraints intersection. allowed actions acceleration values traffic flow speeds in different preferences. determine priority to make representation knowledge to further goals such as remaining, Ulysses and the selection. This scheme was inspired lanes uses Ulysses a final D.A. Reece, S.A. Shafer I Artificial Intelligence 78 (1995) 397-430 407 Fig. 3. Example of a tactical driving task. A robot driver (R) is approaching a crossroad. by similar action selection mechanisms Prodigy [ 171. in other systems such as Soar [45] and Constraints operationalize to avoid loss of control. For example, not only traffic laws but “self-preservation” goals as on the road and avoiding collisions. These goals introduce basic the robot’s speed is is within the limits of the vehicle. than safe driving often that conditions will change. Ulysses can do this by looking is not within the scope of operational control, well-staying acceleration constraints limited on curves so that the lateral acceleration This sort of constraint could be implemented requiring requires ahead for features. This prediction especially at the operational it. However, (e.g. by reading warning signs). if conditions are detected level to deliberate the tactical level rather recognizing indirectly about is a known The perception system may not be able to detect objects reliably beyond some first, that that this range. Ulysses deals with this uncertainty by making two assumptions: is certain; and second, range within which perception there just beyond objects and conditions range. The in conservative decisions. For example, Ulysses always assumes that the road ends just beyond road-detection that trigger constraints are always present is the worst case and results latter assumption range. While the Ulysses driving model produces from several suffers humans. limitations when compared fairly good driving behavior, it still to the general capabilities of l Range of objects. Ulysses only understands a finite set of objects. It would D.A. Reece, S. A. Shafer ! Artificial Intelligence 78 (1995) 397-430 to indicate an open parking It would be unable its meaning. Ulysses located signs and markings lanes. It also makes use of TCD conventions, be unable to figure out the meaning of, say, a new traffic signal that used text treats unknown objects or a new icon (including bicyclists and pedestrians, currently) as obstacles to be avoided. in Structural abstractions, Ulysses makes heavy use of the lane structure lot or take a roads. to understand and shortcut across traffic would miss unconventionally (as would many humans). For example, Ulysses does not look on the left side of the road for signs. Perception. Ulysses assumes perfect perception, within the limits mentioned above. Allowing increased uncertainty driving. Section 7 discusses this further. Fixed parameters. Ulysses uses many fixed parameters: bility of the vehicle, more sophisticated model would allow these to change as environmental traffic conditions changed. Reasonable driver behavior. While Ulysses watches for other drivers making assumes mostly sudden lane changes and running red lights, it nevertheless reasonable the driver of an oncoming car to suddenly swerve a few feet and cause a head-on collision. the Since there possibility. the braking capa- time margin to allow other drivers, etc. A and requires addressing the idea of risk in such behavior, Ulysses ignores is no way to accommodate is always possible driver behavior. the reaction for It Driving program architecture Fig. 4 shows the basic structure of Ulysses and how it interfaces and operational operational levels. The strategic level provides a route plan, while level implements commands. In the current implementation to the strategic the routes Strategic Level Outside World Ulysses-x Select perception + Look for traffic objects ;............. Ulysses . . Driving Model . . . . . . . . . . . . . . . . . . . . . . . . . Generate j ? constraints and j preferences Select accel and lane; update state ~...._....___...__........................ Operational Level *Maintain accel *Cross intersections *Follow lane *Change lane Fig. 4. Architecture of Ulysses and interface to other driving levels. D.A. Reece, S.A. Shafer I Artificial Intelligence 78 (1995) 397-430 409 to be based on an accurate map of the street network, are created by a human operator assumed maneuver at every intersection currently assumed drive to a lane across an intersection, architecture researchers example [6, 8, 32, 48, 521). is known ahead of time. The operational and given directly to Ulysses. The plan is so the desired level is follow a lane, and change lanes smoothly. This three-level by many other (for functions is analogous to connect symbolic planning and numerical control to robot control designs proposed to be able to maintain a specified acceleration, The tactical driving program takes information about traffic objects and selects -2, and -3, (see below). In Ulysses-l, actions using constraints and preferences information about what has been seen so far is used to help select additional sensing actions. The route plan is used both to select maneuvers at intersections and to guide the selection of relevant simple model of operational speeds, maximum braking rate, time to complete a lane change, etc.-so can produce commands traffic objects. The tactical level capabilities-maximum acceleration at different that the operational level can execute. level uses a that it For this research it chooses an action; and finally, it executes the tactical level of the robot is assumed to execute a simple cycle. At the beginning of the cycle, the robot senses the world; “sense-plan-act” the action. Ulysses maintains next, only a few bits of state between cycles, getting fresh information each cycle by sensing. The cycle period is 100 milliseconds. We assume that the system can look it wants and finish deliberating within the 100 milliseconds. Such an for whatever ideal system can respond perfectly to changing situations because the best possible reaction (that it knows). At the same time, this system is very simple and allows us to concentrate on the issues of selective perception. that changes and will determine it will quickly notice anything in this domain-both An important question about such a simple, ideal system is how it relates in 100 milliseconds that action selection that provide a coarse (e.g. [24]), reasoning about real systems. Can a robot really deliberate enough competently? AI planning research has dealt with deliberation variety of ways-guaranteeing [42]), using algorithms (e.g. [40]), or improve time (e.g. [12]). Robot builders, on the other speeding up performance hand, have often found that perceptual processing requires far more computation than “planning” on real mobile robots [61]. We have found that Ulysses’ decisions in this research we assume that tactical can easily be made in real time. Therefore driving decisions can be made about planning in a short period without metareasoning result at first and incrementally takes only bounded time required for planning complexity time, etc. over to to drive in a time (e.g. 3.3. Simulation environment In order to develop Ulysses, we have built a detailed, microscopic simulator PHAROS venience, controllability, called PHAROS provided (for Public Highway And Road Simulator) for experimentation: traffic [57]. con- and safety. It also allowed us to explore repeatability, the usual benefits of simulation 41u D.A. Reece. S. A. Shujer i Arr$ciul lntrlligence 78 (lYY.5) 397-430 for driving was to define such a model robot driving perception PHAROS Developing The environmental is abstracted, uses a fairly detailed information indicating location of signs, and and what in parallel with efforts by others (see for example of the model is a necessary [64]). Another the physical, step in modeling to develop operational important observable control function environment. and of the overall driving task. how the world model determines what objects are important, information description the shape of streets, the configuration can be obtained of the street environment, the appearance via perception. including PHAROS geometric of road markings, the of traffic signals at intersections. Vehicles in PHAROS (which we call “zombies”) basically driving model. There are two key differences, use perception, look directly and that would otherwise behave as humans would, to be inferred. in fact can so reaction have however. First, in the database Second, the zombies delays are incorporated use the Ulysses the zombies do not to find information intended are their behavior. into to PHAROS has a network-based in the simulation. interface The and acceleration commands. in the environmental PHAROS generates so that a robot driving program includes interface Ulysses therefore data base and cannot an animated, both perceptual has a limited “cheat” to get bird’s eye view display can one vehicle and lane to information control queries access unrealistic of the vehicles. evaluating information. This graphical output us with our primary means of the behavior of both zombies the robot. provides and 4. Ulysses-l: perceptual routines section describes Ulysses-l, a mechanism-perceptual actions This incorporates specific perceptual request to allow task-specific Below we explain what perceptual perceptual to sense the perception module routines in simulated driving cost situations. the simplest version routines-for important the of Ulysses. Ulysses-l reasoning module routines to are to search are and show how routines objects. These the scene more efficiently. reduced 4.1. What are perceptual routines? a driver might want test each car to see if it was on the road to the right” would driving requires intersection Tactical For example, downstream find the objects then road they connected to the robot’s would be very difficult because field of view, and each one in the desired Ulysses-l technique the (and to detect later specific objects. relations information about to know between is a car approaching spatial if there from the right. There are at least two ways for a robot a to relations. One way would be to detect all cars, and “The to see if itself be found by finding all roads and checking intersection to the right at the intersection. road at the in question. there may be many cars and roads This method in the robot’s requires implementations significant computation to find and test. objects in specific relations of Ulysses as well) uses a different The to one another. D.A. Reece, S.A. Shafer I Artificial Intelligence 78 (1995) 397-430 411 Table 2 Perceptual routines in Ulysses-l Find-current-lane Track-lane Find-next-car-in-lane Find-intersection-approach-roads Find-crossing-cars Profile-road Find-next-lane-marking Find-path-in-intersection Find-signal Distance-between-marks Mark-adjacent-lane Find-next-sign Find-next-car-in-intersection Find-back-facing-signs is thus limited subsystem uses the reference object and a relation by the location of the road. This perception the focus of attention moves across to focus its search In the example above the robot would use a routine perceptual perception for a new object. action to look along the corridor ahead to the intersection, look to the right of the intersection to find the approach road, and then look along the road for a car. The to a specific portion of the field of view, car detection process determined is inherently image from or along a sequential; reference object until a target is located. Ulysses-l uses about a dozen of these routines, as shown in Table 2. Most of the routines mark objects and locations when they finish, so Ulysses-l can continue finding objects later. For example, the (indicated Track-lane by the change in lane lines in the well-marked PHAROS world), but marks the intersection Find-signal, etc. can find objects relative routine stops scanning when an intersection so that Find-path-in-intersection, to that intersection. is encountered process the Our perceptual routines are related to the visual routines proposed by Ullman to explain human vision [65]. These visual’ routines are composed of operations such as shifting processing focus, finding unique locations in the image, tracing the filling a region to a boundary, and marking points. The boundary of a contour, tasks. Agre and routines are invoked from the top-down when needed in different in their video game-playing systems, Pengi [3] and Chapman used visual routines Sonja [18]. In these systems the visual routines find objects with certain spatial that the block I just kicked will collide relationships, processes are with”. The routines available the perceptual routines must understand how to look for a sign rather in Ulysses-l assume more domain-dependent than is the case in Pengi; for example, for example “the block than just any object. to the routines listed in Table 2 are specialized tasks would clearly have to use routines specialized The routines systems for other tasks. This described decisions could be made with simpler, more general sensing functions, generally for the driving task. Perception for those vision that driving this is not to “detect objects approaching true. For example, a low-level operator is similar [41]. Although to it may seem idea of task-specific vision by Ikeuchi and Hebert task-oriented the routines ” instead of “visual routines” ’ We use the term “perceptual they may include higher levels than just low-level vision, and that they may include other sensing technologies. in our work to emphasize that 412 D.A. Reece. S.A. Shufer / Artificial Intelligence 78 (1995) 397-430 from the right” could not determine which road the cars were on or whether had the right of way. they 4.2. The cost of using routines The perceptual general, naive perception However, routines are subject to the same environmental conditions as a system, so must pay the same feature extraction costs. the use of routines can reduce perception costs in several ways: l Reduced search area. The azimuth and elevation angles swept by the routine are much smaller than the area searched by the naive perception in the resolution. The maximum depth l Range-limited reached system. routine’s search area limits the resolution required. l Object-limited resolution. The routines look for only one type of object at a is determined by the size of that type, not by the smallest of time; resolution all types. l Limited features. Since the routines time, they may be able to use a small set of features object type. Only these features need to be extracted from the image. look for only one type of object at a that are specific to that if it resolution. The effectiveness of these reductions depends on the situation; for example, to search the same area for different objects, the robot used several routines would not get the benefit of limited features or object-limited the cost of perceptual We can estimate routines by developing an expression that is dependent on the number of pixels, as we did in the previous section. We use the same general assumptions about feature extraction sensor traffic object characteristics, pixel sizes at various ranges, etc. that we placement, looks for used for the general perception specific traffic objects, each uses different values for some parameters in the cost that search only for features on the road use equation. For example, terms to reflect the reduced complexity of smaller coefficients understanding in a plane. Further details of the cost expression for individual routines are given in [56]. routines for the p and p2 since each routine system. However, two-dimensional algorithms, features can be plugged Once we have an expression for the cost of each routine, in to compute cost. However, processed pixels depends on the area of the scene actually scanned, depends on the particular situation. The perceptual to determine required simulated driving situations. the number of pixels since the number of the cost of the routine is able the extent of a routine’s scan area and estimate the number of pixels in the dynamic cost of routines it; thus we can measure in PHAROS to examine interface 4.3. A driving scenario We can now show how the estimated perceptual cost varies continuously during in which the robot is driving on a four-lane to driving. We have created a situation artery and must turn left on a side road. The scenario the robot requires Fig. 5. Left side road scenario (not to scale). change lanes, wait for oncoming traffic to pass, and then make the left turn. Fig. 5 shows the situation and the path of the robot. Fig. 6 is a graph of the estimated perceptual cost over time for the left turn 4 l.owl8- i c .Q % P ii 8 9 8 8 3 2 l&+17- l.oHl6 - 1.00+15 - I.&+14 - 1.0.+12 l.oe+l2 I.&+11 l.lb+lO - - - - l.oa+os - 1.M (a/----.,._ -. ,‘I.&. I --. ‘. __....: i \.,‘---._.‘.A’--‘ ,_ _ . . . . . . . . . . . . _..._...... .-.-. -...- +- . . . . _r...-.-.-__..: ; . . . - . . ( ..- 1: . .._..._._._.... 20 25 40 45 50 55 - --- - . - -...- . . . . . . . . . Signal search cast Total cost Lanesaarchcosi Sign search cost Carsearchcosl , 65 Time (seconds) 60 Fig. 6. Perceptual costs during scenario. Numbers correspond reach robot’s destination street on far side of intersection; roads. Total cost is nearly the same as lane search cost. to figure above, except: (2) sensors (3) sensors reach all intersection approach 414 D.A. Reece. S.A. Shafer j Artificial Intelligence 78 (1995) 397-430 to reference points in Fig. 5. The is dominated by the lane search cost, which in the figure is the lane is the most lane and stop lines are the smallest in the environment. Since Ulysses-l sometimes has to search out to its scenario. The numbers in this figure correspond cost of perception indistinguishable costly type of activity because foreshortened objects sensor range limits, the cost of finding lanes can be very high. the “Total cost” curve. Searching from the adjacent this represents the sensors detect the cost of a four-lane highway without The perceptual cost before point (1) is approximately 1.5 X 1017 operations per intersections. At second; the intersection and trigger additional searches for point (l), roads, and blocking cars. The figure shows that the signal and signals, approach car search cost jumps up here. Ulysses-l also determines that the robot cannot turn left from the right lane and begins a lane change. During this time, the robot lanes drops stops searching sharply. At point (2), the sensors detect the robot’s corridor on the far side of the intersection for signs and cars on that road. At (3) the sensors can detect all approach roads, so the robot begins to search these roads for lanes, cars, and backward-facing Stop and Yield signs. After the lane change is complete at (4) the robot again watches both lanes of the road and the lane the intersection search cost increases accordingly. At point (5) the robot enters that would and ceases its search for signals. approaching cars, and other objects to look for its right-of-way decision. At (6) the robot no longer needs affect unexpected lane for traffic, so the cost of searching cross traffic in the intersection either. and begin searching In addition to this scenario, we have created several other driving situations and used Ulysses-l to drive a robot through them [56]. They include the following: l A four-way illustrates visual search for different intersection with no traffic control (unordered logic. right-of-way intersection). This l A four-lane l An intersection of four-lane highway with no the complication of intersections, but includes car following and passing actions. roads controlled by traffic lights. This scenario It includes many signs and markings and more cars than the other scenarios. also illustrates an intersection with completely different intersections. This scenario traffic control. removes l A set of closely spaced intersections of two-lane roads. This scenario includes of two on an and requires consideration is also an intersection the robot, at once. There Stop and Yield signs for downstream approach intersections road to complicate the search for conflicting cars. 4.4. Summary The Ulysses-l driving system introduces a language for controlling perception. limited perceptual is a collection of perceptual routines, each of which performs a This language specific, action. Routines do not search the entire scene for their target objects, but instead search in specific places relative to other objects. The routines are task-specific, because the reasoning component depends on the semantics of this relative in the scene. The reasoning component of the system can thus avoid doing the spatial reasoning by to get the right objects search D.A. Reece, S. A. Shafer I Artificial Intelligence 78 (1995) 397-430 41.5 the routines do the spatial reasoning pushing it off on the perception component; implicitly in their search of the physical world. reduce indicate routines in simulated driving situations The perceptual significantly per second, as compared with about 10” operations ments per second operations necessary for general, bottom-up perception. Thus even before Ulysses reasons about what the most critical objects are, perceptual cost can be reduced by three orders of magnitude by using perceptual routines. the cost of perception. Experi- that routines require about 1017 5. Ulysses-2: ignoring redundant constraints The previous section described how perceptual system has to look for specific objects still asks the perception the perception Ulysses-l system possibly generate a constraint or preference. driving system, Ulysses-2, the reasoning component to determine specificity of perceptual are called sequentially routines in an efficient order. a unique action for the robot. Ulysses-2 for everything to look In the second implementation routines can sharply limit where in the scene. However, that could of the requests only enough objects takes advantage of the routines to find one object at a time. Perceptual the intersection The main idea of Ulysses-2 can be illustrated with an example. Consider the in Fig. 7. The robot has not looked for robot driver approaching objects in the regions indicated with question marks-cars in the lane in front of it and on the side streets, and speed limit signs along the side of the road. Each of In the worst case, a these could generate constraints on the robot’s acceleration. “Speed Limit 15” sign would force the robot to drive at 15 mph starting at the beginning of the unknown region. For cars, the worst case would be a car stopped in the road in front of the robot, or committed from the in front of the robot at the beginning of the unknown side road. A car stopped area would impose the hardest constraint on the robot (i.e. force it to decelerate the robot should look there first. the most). to enter the intersection Intuitively, Continuing with the example, suppose that the robot looked and found a car in its lane stopped at the intersection. This is far enough away that the robot might be forced to look for a Speed Limit sign anyway; slowing to 15 mph nearby might require more deceleration than slowing to a stop near the intersection. However, since the robot has to stop before the intersection anyway, it does not yet have to look for cars on the cross streets. This section explains how Ulysses-2 implements the above reasoning process. 5.1. The corridor Ulysses-l generates constraints path down roads and through is made more explicit intersection intersections. in a network of frames from objects around a corridor-the intended In Ulysses-2 the concept of a corridor [54]. Each section of road and road is a frame with slots for signs, markings, cars, signals, adjacent 416 D.A. Reece. S.A. Shafer ! Arrificial lnreliigence 78 (1995) 397-430 Fig. 7. This marked by “‘?“. robot approaching the intersection has not yet looked for cars or signs in the regions sections and intersections. of these objects. The slots correspond and preferences; below. they are connected etc. Many slots point to lists to allow variable numbers that generate constraints trees described to the inputs of the inference to traffic objects At the beginning of every decision cycle, Ulysses-2 starts with frames with that various slots be filled selection process requests empty slots. The perceptual constraints. When such a the effects of the corresponding in order request is made, a demon in the slot requests an appropriate perceptual to look for an object. The results of the routine update slots and sometimes cause to be expanded as new road sections are discovered. the corridor frame network to determine routine 5.2. The inference tree trees that transform Ulysses-2 represents driving knowledge explicitly so that it can reason about in two is encoded (acceleration and that comprises many function nodes. Ulysses’ logical rules. In general such functions would how sensory data affects the choice of actions. The knowledge inference inputs (sensed data) to outputs lane choice). This transformation component inference relations, allow any action selection mechanism represent is a complex a tree of connected implement that include nodes trees set functions, and production functions--hence, operations, arithmetic function Nodes can uncertainty is represented functions, uncertainty discrete (symbolic) functions, uncertainty order to be implemented. in as an interval of values; their output values. For continuous for nodes with is represented with a set of symbols. In and to aid in to help keep the choice of perceptual actions unambiguous, D.A. Reece, S.A. Shafer I Artificial Intelligence 78 (1995) 397-430 417 representation it is possible to order the efficient nodes. For example, Green, Yield, Stop, Red. We have defined appropriate uncertain-value tion mechanisms of the sets, we used ordered traffic control for all of the continuous and discrete functions. The nodes at the input of the trees use default uncertainty bounds for their frame slots are empty. The default the bounds. input values when bounds are worst case, so that the sensed values will fall between These defaults are domain-dependent. sets of symbols in the indications as follows: propaga- the attached corridor Each node has an update demon attached to it which executes when the node value is updated. These demons can add new nodes to the tree to accommodate new parts of the corridor structure that are added when more of the environment is sensed. The inference trees can be viewed as one-way constraint propagation networks, the node with bounds on the inputs being propagated functions. The inputs are sensory data, so the inference trees in effect translate a range of possible world states into a range of robot actions. The goal of Ulysses-2 in is to find the minimum set of objects the output to sense that will reduce to one unique action. the uncertainty to the output through 5.3. The search algorithm Ulysses-2 begins each decision cycle with the worst-case, default input values propagated through the tree to the output. The output value thus presents a wide range of possible actions. As long as the output does not specify a unique action, to run to Ulysses-2 repeatedly get more information. The algorithm searches the tree to find another perceptual is as follows: routine procedure ChooseAction while tree (tree) is not a single { value { output next-rdutine+Evaluate Execute (next-routine); PropagateNewInputValues (tree); (tree); 1) where the next perceptual routine is chosen in a recursive tree evaluation: function Evaluate (node) { if node is an input return (demon else { node for corridor slot connected to this node); child-node+ChooseCriticalInput(node); return (Evaluate(child-node)) ; 31X D.A. Reece. S. A. Shafer i Artificial Intelligence 78 (1995) 397-430 The key part of the recursive tree evaluation is the selection of the critical node the input with the highest upper bound bound function, looks for an input of the Max node. Since input. Ulysses-2 the value of the node. For example, Maximum upper value of the Max node can be completely evaluation first. Not all node Ulysses-2 good performance of perceptual inputs. This fact is due preferences selects an input according to select actions. to the encoding actions because for this task). Ulysses-2 functions used that dominates of the inputs to a node all of the others in determining this input must be evaluated determined, that have such a dominating to a default ordering (which that computes alone determines before is selected input the the the for for these, to give input; is chosen can nevertheless find good sequences the nodes at the top of its trees do have dominating of knowledge Ulysses uses, with ordered 5.4. Experimental results The Ulysses-2 intent was for Ulysses-2 choice) same acceleration as the following as Ulysses-l. results system was run on the same scenarios the same decisions In all of the scenarios, Ulysses-2 to make and lane commands at exactly show. Ulysses-2 makes between scenario road used (for acceleration indeed produced The to test Ulysses-l. and lane the exact time as Ulysses-l. And requests. in Ulysses-l the same fewer perceptual the perceptual shown and in Fig. 5. Initially Ulysses-2 costs Fig. 8 provides the a comparison left-side in information lane as the preferred is detected. to the intersection Ulysses-2 cheaper because etc. The current intersection closer does not yet difference intersection. a car here allows Ulysses-2 lower are clear and enters the approach for Ulysses-l. Since than look at or beyond At the intersection; it does not needlessly Ulysses-2 examine early the adjacent the adjacent in collects and one, the cost decreases and looking the steadily at less and less road intersection because the decision lane because in the robot’s actions. At around the intersection t = 47, the approaching the approach to ignore is searched before the approach t = SO Ulysses has determined roads; hence roads are no longer being scanned. perceptual cost drops dramatically cycle the robot selects is ignored. When in is lane for traffic, signs, the the is getting in front of it. Ulysses-2 it would not make any the finding the cost is much the approaches because car enters roads, that 5.5. Related work Ulysses-2 makes use of bounds propagation and functions. While both of these mechanisms extends intervals tion” Simmons them and combines through [23]. For example. [62] implemented functions systems them in a novel way. The propagation extensively has been explored as part of a system the same arithmetic interval tree search to select sensing in previous work, Ulysses-2 of numerical propaga- reasoning, functions for arithmetic propagation in “constraint have roots D.A. Reece, S.A. Shafer I Art@cial Intelligence 78 (1995) 397-430 419 r __h4ust start analyzing intersection car enters intersection rOther car leaves intersection I ‘db+18 5 l.oe+17 - lMust _AZobot enters intersection . . .*.. ,....., *..._..: +l . . . downstream road start analyzing ,.,... i t 8 E t 8 8 & 8 c s L 1.&3+16 l&+15 l.owl4 l&+13 - - - - l.lb12 - l.l%+ll 1.olw10 '-%O - - I - 35 40 45 50 55 I 65 Time (seconds) 60 Fig. 8. Total perceptual cost of Ulysses-2 compared to Ulysses-l for left-side road scenario. used in Ulysses-2. He demonstrated handled with arithmetic and furthermore functions, conditional expressions, etc. the same basic functions, that unusual numerical ideas. Ulysses-2 also goes beyond includes Boolean operators, functions could be the basic predicate The tree search algorithm can be thought of as an extension of branch-and- the uncertainty of unexplored branches bound (BB) search [46]. BB represents with intervals and looks for dominating inputs. While BB trees have only Max (or only Min) nodes in them, B* [9] can search a game tree with both Min and Max nodes. Ulysses-2 used Min and Max nodes, and extends to other arithmetic and symbolic functions as well. the concept 420 D.A. Reece. S. A. Shafer i Artificial Intelligence 78 (19%) 397-430 5.6. Summary Ulysses-2 implements the Ulysses driving model with explicit data structures-a tree to encode the driving the tree the next most critical fact to sense. The most critical input is often inputs to functions such as Max and Min. the in, e.g., rank possible actions. Thus tree branches can be network of frames to model the world and an inference knowledge. Ulysses-2 selects perceptual actions by repeatedly evaluating to determine uniquely determined by the extreme This evaluation is very effective because at the top of the inference driving model always includes some prioritizing knowledge-+xpressed Min and Max functions-to pruned near the top, thereby eliminating a lot of potential sensing. We conjecture that many thus benefit share similarly from this search technique. this characteristic task descriptions and would trees, in the left-side road scenario. Fig. 8 shows the effectiveness of Ulysses-2 two-lane highway beyond over Ulysses-l. When there In in which there is little choice of action, and few constraints on the robot intersection), Ulysses-2 shows no is a choice of lanes, Ulysses-2 offers the lane. Ulysses-2 makes its biggest impact when the robot’s action. In all that contained an intersection, Ulysses-2 was at times able to find a in a cost savings of situations (such as the improvement about an order of magnitude of unnecessary there are several factors that could significantly constrain scenarios constraining condition quickly and stop sensing. This resulted from one to six orders of magnitude over Ulysses-l. search of the adjacent it prunes away improvement because the 6. Ulysses-3: modeling world dynamics The first two versions of the driving program reduce the perceptual load on the robot when it looks at the world each decision cycle. However, both Ulysses-l and Ulysses-2 throw away all information between cycles. The third implementa- tion of the driving program, Ulysses-3, takes advantage of coherence in the world it needs to sense. Knowledge about over time to further tee with the input node for how each object can change is stored in the inference that object, and Ulysses-3 automatically determines when to sense that object again. the robot needs the information reduce 6. I. Algorithm modifications Ulysses-3 uses almost the same data structures Ulysses-2. However, cycle empty. stamp is added to indicate their ages. The nodes at the inputs to the inference do not simply use default values (or uncertainty as frames do not start the decision their values from the previous cycle. A time tree intervals) at the beginning of the the slots in the corridor they retain and search algorithms Instead, D.A. Reece, S.A. Shafer I Artificial Intelligence 78 (1995) 397-430 421 cycle; now, an initialization program the associated slot value and its age and computes new uncertainty bounds. As in Ulysses-2, these bounds represent in the input node examines the worst case. The initialization programs encode knowledge about domain dynamics. Some time, while others may the type of a slots’ bounds can be fixed with high confidence over change predictably or unpredictably between cycles. For example, sign does not change over to the sign decreases predictably according to the motion of the robot. The range to the closest car ahead of the it is presumably possible for a car to change lanes and “cut robot is unpredictable; off” the robot at any time. The driving model cannot yet predict when such a lane change could occur, so Ulysses-3 must find the lead car from scratch every decision cycle. time. The range 6.2. Experimental results for Ulysses-l Ulysses-3 was used to drive the simulated robot through the same scenarios that the exact same the it with the costs were used acceleration perceptual cost during the left-side road scenario and compares using Ulysses-2. In general, Ulysses-3 reduces perceptual cost significantly. as the earlier versions. Fig. 9 shows and Ulysses-2. Ulysses-3 produced lane commands and there Before is detected is detected the intersection the intersection its sign horizon again. at t = 37.5, the Ulysses-3 search cost is usually between 1Or1 and 101’. This is much less than for Ulysses-2 (lOI or so) because Ulysses-3 is looking only for new pieces of road that it could not see in the last decision cycle (i.e., a piece of road at the sensor range limits). The spikes in cost occur when Ulysses-3 makes a search along the road ahead for the next sign. If this next sign is far ahead, then Ulysses-3 is able to wait some time before extending When is one decision cycle of high cost as lanes. Cost drops during the lane change because Ulysses-3 considers changing is Ulysses-3 temporarily lane change as another Ulysses-3 makes sure there to the left. Otherwise, Ulysses-3 does not have to look for lanes or signs or signals again until the intersection this point important becomes because Ulysses-3 intersection. However, Ulysses-3 looks only once for signs and signals at the intersection. After the spike, the cost drops again for several seconds. This indicates that although looking at the car Ulysses-3 has found because it knows the car cannot yet be at the intersection. Ulysses-3 does not look for the car again until about there for many objects while stops checking for an intersection is a sharp it analyzes car, it does not keep in the distance. There increase the is no lane farther the approaching spike at about t = 41.5 when at t = 43. At the robot finishes in cost t = 46. looks the When the car finally clears the intersection, Ulysses-3 makes one last check for the intersection. This check is to go through traffic before deciding approaching reflected lane, search costs have a similar character in the spike in cost at t = 48.5, When the robot enters the downstream road. to those on the approach 422 D.A. Reece. S.A. Shafer I Artificial Intelligence 78 (1995) 397-430 __lntersection detected -.Must start analyzmg intersection Approaching car enters intersection (no need to search approaches) -.-Other car leaves intersection _Robot enters intersectmn Must start analyzing downstream road . . . . I ‘Ja+” I l.Oe+14 - l.Oe+lS l.oe+lS I a 5 t I . I . . . .,_ ._ ‘. 8 3 8 1.00+13 - h l.Oe+lZ - 3 $ l.m+ll - l.oe+lO - l.Os+O9 - - 50 55 60 , 65 Time (seconds) Fig. 9. Total perceptual cost ot Ulysses-3 compared to Ulysses-2 for the left-side road scenario. However, because not Ulysses-3 The the cost on the two-lane is cheaper the robot does not have continually search for downstream extends its road or sign horizon changing intersections. in jumps. road to consider than on the four-lane therefore road does occur when spikes lanes and The impact of explicitly modeling world dynamics is quite significant. results show that most of the time, the cost for Ulysses-3 experimental 5 and 7 orders of magnitude of remembering result much better objects such as cross less than static objects-roads for Ulysses-2. This savings and signs. Ulysses-3 from come somewhat has cost spikes at intervals of also performs predictable is primarily the than Ulysses-2 when constraints traffic. Typically, Ulysses-3 The is between D.A. Reece, S.A. Shafer I Art$cial Intelligence 78 (1995) 397-430 423 several seconds that reach Ulysses-2 levels; these spikes occur when the program must analyze a new situation or when the uncertainty about a critical object has grown too large. The next section discusses possible ways to reduce the magnitude of these spikes. 7. Discussion 7.1. Net effect of selective perception Fig. 10 illustrates the average cost rate over is given for the three implementations. The minimum cost, incurred the cost of perception in the left-side road scenario for naive, and for all of the Ulysses implementations. On the right side (i.e., about 32 just in the figure. Most of general perception of the graph, seconds) to identify the time, Ulysses-3 requires about seven orders of magnitude than Ulysses-l, and about 10 orders of magnitude perception the whole scenario, Ulysses-3 Ulysses-l, less computation less than an unguided general system. When the cost of the “spikes” of Ulysses-3 is averaged over than and over five orders of magnitude cheaper is still two orders of magnitude the road in front of the robot, than general perception. the whole scenario is also indicated cheaper is also indicated The approximate power. The “fast” computer capabilities of some computers in the figure. We have placed the computers a little low in the plot because the perceptual cost estimates did not really address data transfer costs, which would occupy some computer lo9 for the Navlab with a Warp systolic operations per second. The approximation the “fast” computer array processor was taken from Clune et al. [21]. Although is almost fast enough of Ulysses-3 most of the in the cost is still too high by over five orders time, when the spikes are averaged should be of magnitude. This discrepancy found to keep up with the requirements the cost of the spikes. is a hypothetical that additional one delivering techniques to reduce suggests 7.2. Reducing peak costs in Ulysses-3 reach A comparison of the instantaneous that most of the cost is in the spikes, Furthermore, to have the capacity to handle the maximum instantaneous the same resources as the Ulysses-2 system; nothing would be gained trees, and average costs for Ulysses-3 in Fig. 10 the peaks of the indicates the cost levels of Ulysses-2. Thus if the robot were spikes load, it would required in need to Ulysses-3. However, the spikes over time and limit peak cost, For example, suppose that the amortize limited. The limit might computation available rate, zoom rate, etc. The represent processing action selection process would stop when it hit the limit, even if not complete. to worst-case values, and sensing only Since the sense nodes are always initialized it would not be difficult, using in each decision cycle were limits or mechanical limits-pan inference the 424 D.A. Reece. S.A. Shafer / Arfificial Intelligence 78 (lY95) 397-430 -- -. - ..-..- Ulysses-l Ulysses-2 average average average Ulysses-3 II_! le+ooL 30 35 40 45 50 55 60 65 Time (seconds) t 70 Fig. 10. Perceptual indicates control of Ulysses-2 the estimated cost for all implementations ot Ulysses in the left-side road scenario. Dotted cost or -3; thus for finding the it represents lane the minimum in front of the robot. This operation cost these implementations line is not under can achieve. the task, completion stopping before the performance (safe) constraints of leaves improves in the tree. Ulysses-3’ would select the available pessimistic the current action with the lowest currently possible preference this would be the highest upper value default preference). For acceleration allowed by the pessimistic constraints; for lane changing the result would often, but not always, be to stay in the same lane. The effect would be to slow the robot down until it could see all that it needed to proceed safely. just described, performs “lazy perception” to save it only looks for things when absolutely necessary. Another Ulysses-3, and the extension computation-i.e.. to in order priority (i.e., D.A. Reece, S.A. Shafer I Artificial Intelligence 78 (1995) 397-430 425 way to reduce peak costs would be to use excess capacity to look for things before it is strictly necessary. Advance estimates could avoid the need to slow the robot while the perception could be the value of uncertain sense nodes guided with the inference into the future and finding out which ones would impact the value of the top node. system is catching up. Such predictive perception tree by projecting Peak costs, and in some cases continuous costs, could also be reduced by using spatial routine continuously that simply watches one object since no scanning, and no complex model matching. By tracking a car ap- for example, Ulysses-3+ would not have to search for a tracking perceptual (between decision cycles). Tacking objects would be relatively it involves no reasoning about sequential proaching an intersection, the car again when pessimistic position estimates placed it near the intersection. Instead, Ulysses-3+ intersection Ulysses-3+ would not have to find and interpret tracking routine could easily fix itself on the appropriate could wait until the vehicle had actually look for more cars. Similarly, at signalized inexpensive, traffic objects, signals every decision cycle; a reached intersections relations between signal head. and then the 7.3. Balancing correctness, cost, and performance sensor or other is intended its performance- could get extreme; in the model. Ulysses limits, occhsion, some fact, Ulysses-3 would slow the robotaegrade The height of the sensing peaks in Fig. 10 could also be reduced by reducing the to Ulysses, instead of performance. Correct driving, according “correctness” means always considering all constraints to generate safe actions for the robot when all constraints are applied. If, because of limitations, Ulysses-3 could not resource determine rather than ignore a constraint. For example, if there was limited sight distance at an intersection and the robot could not see up a side road, Ulysses-3 would always the robot to stop. assume that there could be a car on the side road and prepare This conservatism the notion of children if Ulysses included spontaneously running into the street, Ulysses-3 would force the robot to creep by all parked cars just in case a child was hiding behind one. to note that humans often do not reduce in in the similar conditions. Humans clearly do not look at everything of importance that they could driving environment, have avoided them. There are two observations we can make about human visual search and Ulysses. For example, humans have a from limited field of view. The location of “human vision” in Fig. 10 (estimated [55]) also suggests that humans do much less processing than the Ulysses model to cover some situations by flagging requires. Human peripheral vision helps moving and colorful objects for attention, but it is doubtful that it can cover all of thoroughly. Second, humans make assumptions about the the Ulysses constraints ignore possibilities likelihood of various if they seem unlikely. Thus humans can choose the possibility of children the possibility of cars on minor side roads, hiding behind parked cars, ignore traffic situations, and selectively to ignore because if they had anticipated they have collisions with objects their performance It is interesting 426 D.A. Reece. S.A. Shafer 1 Artificial Intelligence 78 (1995) 397-430 that the car they are assume their headlights, etc. Of course, human expectations are occasionally violated and they have accidents. tailgating won’t stop suddenly, overdrive will also have If a driving robot in similar situations-it is ever to achieve human-level performance-i.e., drive at the risks that similar speeds to accept humans accept. This risk tradeoff could possibly be incorporated into a driving program using decision theory. Robot speed (or lack thereof) and accidents would to cost, and domain knowledge or learned experience would provide contribute In each decision cycle, the driving probability estimates for observable conditions. program would have to incrementally the most information given the time available, and then select the motor actions that were expected there are several approach. First, with many constraints and difficulties with a decision-theoretic the complexity of finding the best next action could be many sensing options, overwhelming. Second, probability distributions for various events and conditions could be very difficult to estimate. And finally, it is not clear what cost to assign the robot. The an accident, especially one that damages property other driving to infinite cost in accidents. This last question has philosophical the technical problems. to be the most cost-effective. Unfortunately, this paper effectively than assigned system described select perceptual that go beyond ramifications to provide actions 8. Conclusions defined operations and a mechanism This paper addresses reasoning and perception task. We have developed for integrating perception and provided that allows reasoning to request specific types of objects that are semantically the problem of efficiently controlling perception a driving control system for a that defines useful complex control with perceptual operations in three situation assessment and action selection. The system was implemented the basic the perceptual stages. Ulysses-l to request connection between routines, allow the reasoning sensing actions. These operations, called perceptual for component driving decisions. At the same time they guide the perception component in its physical search for these objects. Ulysses-2 reasons about worst-case bounds on in the world. Ulysses-2 looks for objects in the order of their unknown conditions information potential of the cannot affect for encoding perceptual tree to encode structure for efficiently selecting the action selection knowledge; and a search algorithm critical takes is retained between advantage of coherence decision cycles, and domain dynamics are encoded routines which increase the choice of action. There are three main components a frame-like a constraint-propagating impact on robot actions, and stops sensing when further in the domain over time. Information data structure inference to sense). Finally, Ulysses-3 in facts as they get older. reasoning mechanism: in the environment; the uncertainty to evaluate in update important (objects leaves tree The effect of these perceptual control mechanisms is dramatic. The three D.A. Reece, S. A. Shafer I Artificial Intelligence 78 (1995) 397-430 427 immediately dropped the estimated cost of perception there was often an obvious constraint on robot actions, versions of Ulysses were used to drive a simulated robot through several different situations. Ulysses-l by to four orders of magnitude compared with bottom-up perception. The three in situations near intersections impact of Ulysses-2 varied more with the moment; where the estimated perceptual cost dropped an additional three to six orders of magnitude. Ulysses-3 had an even bigger impact. Most of the time the estimated cost for Ulysses-3 was five to seven orders of magnitude below that for Ulysses-2, with momentary jumps every couple of seconds as the system looked around to reduce the growing uncertainty. On average, Ulysses-3 required about five orders of magnitude fewer arithmetic operations per second than did naive, bottom-up perception. to achieve Our eventual goal is to drive a real robot. Further reductions this goal. As discussed in the previous section, to limit the peak costs of perception in perceptual cost the and such as to reduce cost even further. The results of using these that the perception for driving is tractable and perhaps within the capability of computing will be necessary mechanism of Ulysses can be extended significantly tracking, have the potential perceptual problem systems of the near future. the average cost. Additional perceptual operations, attention control mechanisms give us confidence reduce References [l] AASHTO, A policy on geometric design of highways and streets, American Association of State Highway and Transportation Officials, Washington, DC (1984). Implementations [2] J. Aasman, Rothengatter Gorcum, Assert, 1988) 106-118. of car-driver behaviour and psychological and R.A. de Bruin, eds., Road User Behaviour: risk models, Theory and Practice in: J.A. (Van [3] P.E. Agre and D. Chapman, Pengi: an implementation of a theory of activity, in: Proceedings Seattle, WA (1987) 268-272. AAAI-87, [4] H. Akatsuka and I. Shinichiro, Road signposts International Congress (SAE, Detroit, MI, 1987). recognition system, in: Proceedings SAE [5] J. Aloimonos, 333-356. I. Weiss and A. Bandyopadhyay, Active vision, Int. J. Comput. Vision 1 (4) (1988) [6] R. Arkin, Motor schema based navigation for a mobile robot, in: IEEE International Conference on Robotics and Automation, Raleigh, NC (1987). [7] D.H. Ballard, Animate vision, Artif. Intell. 48 (1991) 57-86. [8] W. Becket and N. Badler, in: Proceedings Third Conference on Computer Generated Forces and Behavioral Representation, Orlando, FL (1993). [9] H. Berliner, The B* tree search algorithm: a best-first proof procedure, Artif. Intell. 12 (1979) Integrated behavioral agent architecture, 23-40. [lo] P.J. Besl and R.C. Jam, Three-dimensional object recognition, ACM Comput. Surv. 17 (1) (1985). [ll] T.O. Binford, Survey of model-based [12] J. Blythe and T.M. Mitchell, On becoming reactive, image analysis systems, Int. J. Rob. Res. 1 (1) (1982). in: Proceedings 6th International Workshop on Machine Learning, Ithaca, NY (1989). [13] R. Bolles, Verification vision for programmable assembly, in: Proceedings ZJCAZ-77, Cambridge, MA (1977). D.A. Reece. S. A. Shafer i Artificial Intelligence 78 (1995) 397-430 and robot planning, AI Memo 685, MIT, Cambridge, MA vision, in: H. Freeman, in Computing ed., Machine Vision: Algorithms, Press, San Diego, CA, 20 (Academic for outdoor navigation. in: Proceedings intelligent Vehicles 93 428 ]141 ]151 [161 [I71 [181 1191 PO1 WI PI error analysis R.A. Brooks. Symbolic (1982). P. Burt, sensing’ Architectures, and Systems, Perspectives l-30. 1988) M. Campani et al., Visual in machine routines ‘Smart (1993). C. Knoblock Symposium J. Carbonell. learning, 1991) Chapter D. Chapman, H.C. Chin, SIMRO: (1985) 109-113. L. Chrisman AAAI-91, Anaheim, E. Clune. vision system on a systolic array machine, J. Crisman CA (1991). J. Crisman, G. Klinker and C. Thorpe, Color vision and R. Simmons, a model and S. Minton, Prodigy: ed.. Architectures for Intelligence (Lawrence an integrated in: K. VanLehn. 9. Vision, Instruction, and Action (MIT Press, Cambridge, MA, 1991). architecture for planning and Erlbaum, Hillsdale, NJ, to simulate traffic at roundabouts, Traffic Eng. Control 26 (3) Sensible planning: and J. Webb. focusing perceptual attention, in: Proceedings Implementation and performance of a complex Future Gen. Comput. Syst. 4 (1988) 15-29. for road following, in: Proceedings of SPIE Conference on Mobile Robots (1988). E. Davis, Constraint u231 [24] T. Dean and M. Boddy. An analysis of time-dependent intervals, Artif. fnrell. 32 (1987) 281-331. planning, propagation with in: Proceedings AAAI-88, St. . and R. Doshi, Generating in: Proceedings AAAI-86, in: recognition object Vision and Pattern Recognition, Ann Arbor. MI (1988) perception Philadelphia. using libraries of parameterized and expectations PA (1986). sub-parts, to verify requests on Uniform Traffic Control Devices (Federal Highway Administration, U.S. DC. 1978). Traffic Network Analysis with NETSIM: A User Guide (Federal Highway Administra- Washington, WI v91 1251 sensing, [301 (281 (271 DC, 1980). of Transportation, Paul, MN (1988) 49-54. R. Doyle, D. Atkinson the execution of plans. G.J. Ettinger, Large hierarchical Proceedings Conference on Computer 32-41. FHWA, Man& Department FHWA, tion, Washington. R.J. Firby, Task directed 1989) 480-489. T. Fujimori Thorpe CMU-RI-TR-88-4. T. Garvey, Menlo Park. CA (1976). E. Gat, controlling D.R.P. Gibson, Available Traffic Simulation Models. TRB Special Report 12-22. V. Graefe, Vision (1993). Symposium W.E.L. Grimson, constrained [36] N.C. Griswold Carnegie Mellon University, for purposive planning real-world mobile and T. Kanade, Knowledge-based The combinatorics computer models and T. Kanade, and robots. Integrating of object Perceptual intelligent [311 strategies reacting 1321 (351 ]341 ]331 road for vehicles. search, Arfif. Intell. 44 (1990) 121-165. using morphological Station, TX (1989). in: Sensor Fusion II: Human and Machine Strategies (SPIE, in: C. eds., 1987 Year End Report for Road Following at Carnegie Mellon, interpretation of outdoor scenes, road Pittsburgh, vision, Technical Note 117, SRI PA (1988) 45-96. International, in a heterogeneous in: Proceedings AAAI-92, for traffic operations asynchronous San Jose, CA (1992). analysis, architecture for in: The Application of (1981) of Sciences 194, National Academy in: Proceedings of Intelligent Vehicles 93 recognition in cluttered environments using and B. Bergenback, filters and Stop sign recognition mapping, log-conformal for autonomous Texas A & M University, land vehicles (ALVS, College [37] A. Hanson Segmentation and E. Riseman, eds., Computer Vision Systems (Academic Making intelligent (381 B. Hayes-Roth, systems of natural scenes, Press, New York, 1978) 129-163. in: A. Hanson and E. Riseman, adaptive, in: K. Van Lehn, ed., Architectures for Intelligence (Lawrence Erlbaum. Hillsdale. NJ. 1991). D.A. Reece, S. A. Shafer I Artificial Intelligence 78 (1995) 397-430 429 ]39] M. Hebert and T. Kanade, 3-D vision for outdoor navigation by an autonomous vehicle, in: C. Thorpe and T. Kanade, ed., 1987 Year End Report for Road Following at Carnegie Mellon, CMU-RI-TR-88-4, Carnegie Mellon University, Pittsburgh, PA (1988) 29-41. ]40] E.J. Horvitz, Reasoning about beliefs and actions under computational in: L.N. Kanal, T.S. Levitt and J.F. Lemmer, eds., Uncertainty in Artificial Intelligence (Elsevier Science, Amsterdam, 1989) 301-324. resource constraints, [41] K. Ikeuchi and M. Hebert, Task oriented vision, in: Proceedings DARPA 1990 Image Understanding Workshop (1990) 497-507. ]42] IX Kaelbling, Gals as parallel program specifications, in: Proceedings AAAI-88, St. Paul, MN (1988) 60-65. ]43] K. Kluge and H. Kuga, Car recognition for the CMU Navlab, in: C. Thorpe and T. Kanade, eds., 1987 Year End Report for Road Following at Carnegie Mellon, CMU-RI-TR-88-4, Carnegie Mellon University, Pittsburgh, PA (1988) 88-115. ]44] K. Kluge and C. Thorpe, Explicit models for road following, in: Proceedings IEEE Conference on Robotics and Automation, Scottsdale, AZ (1989). ]45] J.E. Laird, A. Newell and P.S. Rosenbloom, Soar: an architecture for general intelligence, Artif. Intell. 33 (1987) l-64. [46] E. Lawler and D. Wood, Branch-and-hounds methods: a survey, Oper. Res. 14 (1966) 699-719. [47] T. Levitt, T. Binford, G. Ettinger and P. Gelband, Probability-based control for computer vision, in: Proceedings DARPA Image Understanding Workshop (1989) 355-369. [48] J. Malec and M. Morin, A pre-intelligent driver information unit, in: Proceedings Zntelligent Vehicles 93 Symposium ( 1993). [49] D.M. McKeown Jr and J.L. Denlinger, Cooperative methods for road tracking in aerial imagery, IUS Workshop (1988) 327-341. [50] J. McKnight and B. Adams, Driver education and task analysis, Volume I: task descriptions, in: Proceedings 1988 DARPA Final Report, Department of Transportation, National Highway Safety Bureau, Washington, DC (1970). [51] B. Mertsching et al., Interpretation of traffic scenes using a hierarchical data structure, in: Proceedings Intelligent Vehicles 93 Symposium (521 E. Mettala, The OSD tactical unmanned ground vehicle program, (1993). in: Proceedings 1992 DARPA Image Understanding Workshop (1992). [53] J.A. Michon, A critical view of driver behavior models: what do we know, what should we do? in: L. Evans and R. Schwing, eds., Human Behavior and Traffic Safety (Plenum, New York, 1985). [54] M. Minsky, A framework for representing knowledge, Computer Vision (McGraw-Hill, New York, 1975). [5.5] H.P. Moravec, Locomotion, vision and intelligence, in: P. Winston, ed., The Psychology of in: M. Brady and R. Paul, eds., Robotics Research (MIT Press, Cambridge, MA, 1984) 215-224. [56] D.A. Reece, Selective perception for robot driving, Technical Report CMU-CS-92-139, Carnegie Mellon University, Pittsburgh, PA (1992). [57] D.A. Reece and S.A. Shafer, An overview of the Pharos traffic simulator, in: J.A. Rothengatter and R.A. de Bruin, eds., Road User Behaviour: Theory and Practice (Van Gorcum, Assen. 1988). [58] D.A. Reece and S.A. Shafer, A computational model of driving for autonomous vehicles, Transportation Res. A 27A (1) (1993) 23-50. [59] R. Rimey and C. Brown, Control of selective perception using Bayes nets and decision theory, Int. J. Comput. Vision (submitted). [60] D. Russell, Constraint networks: modeling and inferring object locations by constraints, Technical Report 38, University of Rochester, Computer Science Department, Rochester, NY (1978). [61] S.A. Shafer, A. Stenz and C.E. Thorpe, An architecture for sensor fusion in a mobile robot, Technical Report CMU-RI-TR-86-9, Carnegie Mellon University, Pittsburgh, PA (1986). [62] R. Simmons, ‘Commonsense’ arithmetic reasoning, in: Proceedings AAAI-86, Philadelphia, PA (1986). 430 D.A. Reece. S.A. Shafer Artificial Intelligencr 78 (1WS) 397-430 163) U. Solder Advances and V. Graefe, Object detection in real time, m: Proceedings SPIE Symposium on in Intelligenr .Systems (1990) 121-165. [64] C. Thorpe. M. Hebert, T. Kanade and S. Shafer. Toward autonomous driving: the CMU Navlab. Part [EEE Expert (August routines, Cog&ion I: perception. 16.51 S. Ullman. Visual 1661 H.H. effort arzd Traffic Safety (Van Gorcum. Assert/Maastricht, van der Molen and A.M.T. Botticher. for theoretical operationalizations. 1991) 31-42. 18 (1984) 97-160. in: J.A. Rothengatter Risk models for Netherlands, search traffic participants: and R.A. de Bruin, Road Users a concerted 1987) 61-82. [67] L. Wixson, Exploiting world structure for objects, Technical Report 434, University of Rochester, [68] S.-Y. Wong. TRAF-NETSlM: [69] X. Yu et al., Road tracking, lane Computer how to efficiently Science Department. it works, what segmentation it does. Rochester. NY (1992). ITE J. 60 (4) (1990) 22-27. and obstacle recognition by mathematical morphology, in: Proceedings Intelligent Vehicles U? Symposium (lYY3). 