Artificial Intelligence 170 (2006) 472–506www.elsevier.com/locate/artintExperiment selection for the discrimination of semi-quantitativemodels of dynamical systemsIvayla Vatcheva a, Hidde de Jong b,∗, Olivier Bernard c, Nicolaas J.I. Mars da German Cancer Research Center (DKFZ), Im Neuenheimer Feld 280, 69120 Heidelberg, Germanyb Institut National de Recherche en Informatique et en Automatique (INRIA), Unité de recherche Rhône-Alpes, 655 avenue de l’Europe,Montbonnot, 38334 Saint Ismier Cedex, Francec Institut National de Recherche en Informatique et en Automatique (INRIA), Unité de recherche Sophia Antipolis, 2004 route des Lucioles,BP 93, 06902 Sophia Antipolis, Franced Materials Science Centre, Department of Mathematics and Natural Sciences, Rijksuniversiteit Groningen, Nijenborgh 4,9747 AG Groningen, the NetherlandsReceived 19 September 2005; received in revised form 13 November 2005; accepted 13 November 2005Available online 9 December 2005AbstractModeling an experimental system often results in a number of alternative models that are all justified by the available ex-perimental data. To discriminate among these models, additional experiments are needed. Existing methods for the selection ofdiscriminatory experiments in statistics and in artificial intelligence are often based on an entropy criterion, the so-called infor-mation increment. A limitation of these methods is that they are not well-adapted to discriminating models of dynamical systemsunder conditions of limited measurability. Moreover, there are no generic procedures for computing the information increment ofan experiment when the models are qualitative or semi-quantitative. This has motivated the development of a method for the selec-tion of experiments to discriminate among semi-quantitative models of dynamical systems. The method has been implemented ontop of existing implementations of the qualitative and semi-quantitative simulation techniques QSIM, Q2, and Q3. The applicabil-ity of the method to real-world problems is illustrated by means of an example in population biology: the discrimination of fourcompeting models of the growth of phytoplankton in a bioreactor. The models have traditionally been considered equivalent forall practical purposes. Using our model discrimination approach and experimental data we show, however, that two of them aresuperior for describing phytoplankton growth under a wide range of experimental conditions. 2005 Elsevier B.V. All rights reserved.Keywords: Qualitative and semi-quantitative modeling and simulation; Model discrimination; Information theory; Population biology;Computer-supported modeling* Corresponding author.E-mail addresses: I.Vacheva@dkfz-heidelberg.de (I. Vatcheva), Hidde.de-Jong@inrialpes.fr (H. de Jong), Olivier.Bernard@sophia.inria.fr(O. Bernard), N.J.I.Mars@fwn.rug.nl (N.J.I. Mars).0004-3702/$ – see front matter  2005 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2005.11.001I. Vatcheva et al. / Artificial Intelligence 170 (2006) 472–5064731. IntroductionFinding an adequate model of the functioning of a complex system—either natural or man-made—is a problemconfronting practitioners in many different domains. For instance, it arises when a population biologist studies anecosystem, an electrical engineer diagnoses a fault in an electronic circuit, or a medical doctor tries to infer the causesof the illness of a patient. Given the pre-eminence of modeling in human endeavor, it comes as no surprise thatmethods for computer-supported modeling have been subject to active research in artificial intelligence. For instance,machine learning techniques infer a model from observations of the system behavior [47], while automated modelingtechniques in qualitative reasoning are able to derive a model from a description of the system, a user question, and adomain theory [40,51,63].The complexity of the task of modeling is such that in many cases the available information does not allow oneto decide between alternative models of the system under study. In the above examples, several interactions betweenspecies in an ecosystem can be imagined, the fault in the electronic circuit may be due to the failure of differentcomponents, and the symptoms of the patient might have a variety of causes. The different assumptions on the structureand behavior of the system may result in a number of competing models, all justifiable by the available observations.The existence of this set of competing models gives rise to the problem of model discrimination.To discriminate between a number of competing models, and identify which of them most adequately describesthe actual situation, new observations are needed. These can be obtained by performing additional experiments onthe system. An experiment discriminates among the models, if the predictions of some of the models fit the newly-obtained data, whereas the predictions of others do not. Since in real-life applications a large number of experimentscan be performed, and the cost of each of them may be considerable, it is important that the experiments be selectedcarefully. In fact, it is desirable that experiments be selected in such a way that the set of competing models ismaximally reduced (systematic model discrimination) at minimal costs (efficient model discrimination). Notice thatthe efficiency requirement does not necessarily amount to minimizing the number of experiments, since several cheapexperiments may cost less than a single expensive experiment.The problem of model discrimination has received substantial attention in the statistical literature (see [28,29]for reviews). This has resulted in criteria for determining the experiment that optimally discriminates among differentmodels of the system. These criteria, based on concepts derived from information theory and optimization theory, havebeen applied to a variety of problems in biology and biotechnology (e.g., [15,37,55,57]), in physics (e.g., [16,45]),and in chemical engineering (e.g., [1,25]). Similar criteria have been developed in artificial intelligence, especially inthe field of model-based diagnosis (MBD) [31]. In this case, the criteria play a key role in reducing the number ofcandidate diagnoses generated, that is, the set of hypotheses accounting for the observed faulty behavior of a device.In order to discriminate among the candidate diagnoses, and thus find out what is actually wrong with the system,methods for selecting the optimal measurements or experimental conditions have been developed (e.g., [20,22,53]).All of the above methods share the same underlying intuition. To evaluate the discriminatory potential of an ex-periment, its outcome is predicted by each of the competing models. The experiment for which the model predictionsdiffer most will have the highest chance of discriminating among the models, and is therefore selected as the optimaldiscriminatory experiment. Often, this intuition is formalized by means of the optimal information increment, thatis, the maximal difference in entropy before and after the execution of an experiment. The expected value of thisinformation increment, for each of the available experiments, can be determined from the model predictions.A first problem with existing methods for model discrimination is that the information increment criteria beingused are not well-adapted to dynamical systems. The criteria take into account the possible states of the system, butnot their temporal ordering. It has been shown that under certain conditions, the temporal evolution of the state ofthe system is not necessary for model discrimination [53,54]. These conditions, however, are often not fulfilled inpractice. As a consequence, it becomes important to take into account the differences in temporal behavior.A second problem with existing methods is the difficulty of computing the expected value of the information incre-ment from the model predictions. This is especially true when qualitative or semi-quantitative models are used, likethose developed in the field of qualitative reasoning (QR) [26,56,62]. Qualitative models deal with incomplete or im-precise information by assigning symbolic values to its parameters and initial conditions [42]. In addition, qualitativemodels may contain incompletely specified functional relations between the variables, defined by their monotonicityproperties only. Qualitative models can be extended to semi-quantitative models by specifying numerical intervalsbounding parameter values as well as envelopes bounding monotonic functions [4,38]. The latter models are useful474I. Vatcheva et al. / Artificial Intelligence 170 (2006) 472–506in many scientific and engineering domains, which often deal with parametric and functional tolerances described byintervals and bounding curves. However, existing methods for model discrimination either focus on numerical modelsor, if they allow qualitative or semi-quantitative models, do not provide a generic, domain-independent computationalframework for computing the expected information increment.The above limitations of methods for model discrimination in statistics and in model-based diagnosis have mo-tivated the work described in this paper. We present a method for the systematic and efficient discrimination ofsemi-quantitative models of dynamical systems [58,59]. The selection of the optimal discriminatory experiment isbased on an entropy criterion that exploits the model prediction for the temporal evolution of the system state. Inaddition, the method provides computational procedures to actually calculate the entropy criterion from the modelpredictions. Overall, model discrimination proceeds iteratively, similarly to a sequential diagnosis strategy [22,30].The algorithm starts with a set of competing models to which initial probabilities have been assigned. At every step,the experiment with the highest discriminatory potential is determined, this experiment is executed, and the experi-mental outcome is then used to recompute the probabilities of the competing models and refine the parameter intervals.This process continues until one of the models has reached a cut-off probability, all models have zero probabilities,or the possible experiments have been exhausted. The method has been implemented in Common Lisp, on top of thequalitative and semi-quantitative simulators QSIM, Q2, and Q3.We will demonstrate the effectiveness of the method in the context of a real application in population biology. In thisdomain competing models are bound to occur due to the fact that most models are based on empirical relationshipsbetween the variables and have rarely been appropriately validated. More precisely, the problem is to discriminatebetween four competing models of nutrient-limited phytoplankton growth in a chemostat. The choice of optimaldiscriminatory experiments is critical in this application, because the experiments take several weeks to complete.Semi-quantitative models are appropriate because, as in the case of most biological systems, the available data isnoisy and fragmentary. The four models have traditionally been considered equivalent for all practical purposes. Byapplying our model discrimination approach and employing real experimental data we show, however, that two of themare superior for reproducing phytoplankton growth under a wide range of experimental conditions. These so-calledDroop and Caperon–Meyer models, which make closely related assumptions on the underlying growth processes,strike the right balance between empirical validity and mathematical simplicity.The article is organized as follows. In the next section, some basic concepts are defined, and the method for modeldiscrimination is informally introduced. The method is based on a generalized entropy criterion (Section 3) that guidesthe selection of optimal discriminatory experiments. In Section 4, the algorithm for model discrimination is presentedin detail. The results of the application of the method to the modeling of nutrient-limited phytoplankton growth in achemostat are presented in Section 5. In Section 6, the method for model discrimination is discussed in the context ofrelated work, while the last section summarizes the contributions and indicates directions for further research.2. Basic concepts and outlineThis section provides the framework for the method for model discrimination. The concepts of experimental sys-tem, experiment, observation, model, and competing models are introduced, and an outline of the method is given.2.1. Experimental systems and experimentsAn experimental system is a (physical, chemical, biological) system that is created and sustained in an experimentalset-up [18]. The experimental set-up defines how the system is put together and the range of experimental conditions.Characteristic properties of experimental systems are that their behavior can be controlled and observed. Control isachieved by maintaining the structure of the system and imposing the experimental conditions. Observations allowproperties of the system to be determined. Here, we are concerned with dynamical systems. That is, systems whosestate evolves over time.For example, consider the experimental system consisting of a phytoplankton culture in a chemostat (Fig. 1). Thechemostat is a type of bioreactor in which the nutrients required for cell growth are supplied at a fixed rate to a culturevessel whose contents are continuously mixed. Medium, cells, and by-products are continually removed, maintainingthe culture in the vessel at a constant volume. The experimenters can control, among other things, the inflow rate ofI. Vatcheva et al. / Artificial Intelligence 170 (2006) 472–506475Fig. 1. Schematic illustration of the chemostat.the growth medium, the light intensity, and the temperature. In addition, they can observe the phytoplankton biomassand the concentration of remaining nutrients over time.An experiment is an action, in which specific experimental conditions are imposed, and the temporal behavior ofthe system is observed under these conditions. In the context of phytoplankton growth, an experiment might consistof observing the evolution of the phytoplankton biomass from given initial conditions, while the concentration of thefeeding substrate is fixed.2.2. Observations of experimental systemsThe state of an experimental system evolves over time and can be described by a set of continuous variables, so-called state variables. More precisely, a state variable x is a function of time defined as x : R∗ → Dx , Dx ⊆ R∗.1In many cases, the state of the system cannot be completely determined because of its limited measurability. Thismeans that some state variables cannot be observed over the time-course of the experiment. Usually, only certainquantities that are (continuous) functions of the state variables can be observed, here called observed variables anddenoted by the vector y. In practice, the value of y is measured at specified sampling points only and the precision ofthe measurements is limited. Consequently, the available measurements are often restricted to qualitative and semi-quantitative properties of the behavior of the system, as defined more formally in the remainder of this section.Following [42], we define the domain of a variable y by its quantity space. The quantity space is a set of totally-ordered landmark values or landmarks, corresponding to qualitatively-significant values of the variable. Some of thelandmark values are defined at the beginning, such as initial values. Others may be introduced during the temporalevolution of the system, such as extreme values and equilibrium values. Most of the time, exact landmark values arenot known and we denote them by a symbol. The vector l denotes all the landmarks of the observed variables y.Time is also a variable, with a quantity space composed of landmarks of a special kind, so-called distinguishedtime-points. At each distinguished time-point tj , at least one variable changes its value to or from a landmark. Thequalitative value of y at a time-point tj , or in an interval between two successive time-points tj and tj +1, is expressedin terms of the landmarks in its quantity space and its direction of change (std, inc, or dec). The qualitative state of asystem at a time-point, or between two time-points, consists of a tuple of qualitative values, one for each variable ofthe system.The qualitative behavior of the system on a time-interval [t0, tn] is given by the sequence of qualitative statestraversed by the system on that interval. That is, a qualitative behavior is defined by a sequence of qualitative states,alternating between states that hold at a time-point and states that last over a time-interval (see [42] for details). Eachpoint state denotes a qualitatively significant event in the time evolution of the system, in the sense that a landmarkvalue of at least one variable is reached.As remarked above, landmark values are usually unknown. But it may be possible to bound the values by numericalintervals. In this case, the concept of qualitative behavior generalizes to that of semi-quantitative behavior [39,42,58].1 R∗represents the extended set of real numbers, including −∞ and ∞.476I. Vatcheva et al. / Artificial Intelligence 170 (2006) 472–506By extension, we sometimes speak of the semi-quantitative behavior of a subset of the variables instead of that of theentire system.An observation on a system in an experiment can now be formally defined.Definition 1 (Observation). An observation on an experimental system in an experiment e is a semi-quantitativebehavior of the observed variables y with landmark values l over the time-interval of the experiment.In many cases it is useful to adopt a slightly modified definition of observation. For example, we can have obser-vations in which only some of the landmarks in l are measured. In addition, landmarks that are defined as functionsof the landmarks in l could be measured, such as the amplitude and the period of an oscillation. In what follows,we make the assumption that the sampling frequency of the measurements is chosen in such a way that the observedqualitative behavior of y corresponds to the real qualitative behavior of y. That is, we exclude observation gaps.In the context of phytoplankton growth, the observed variables are the amount of biomass and the concentration ofremaining substrate. The observations thus consist of the semi-quantitative behavior of these variables. For instance,an observation may show that the biomass first reaches a maximum, followed by a steady state, while at the same timethe substrate concentration decreases to its steady state. This gives rise to the introduction of two landmark values,corresponding to the maximum and equilibrium values of the observed variables. The observation may also provideinterval bounds on these landmarks.2.3. Models of experimental systemsThe relations between the quantities of a dynamical system are traditionally modeled by ordinary differentialequations (ODEs), that is, by equations of the form˙x = f (x, u, p),x(t0) = x0,y = g(x, u, p)(1)where x is the vector of state variables of the system, u the vector of control variables, y the vector of observedvariables, x0 the vector of initial conditions, and p the parameter vector. The state variables and the observed variablesare functions of time. A control variable is generally a function of time as well, that is, u : R∗ → Du, Du ⊆ R∗.However, we restrict our attention here to time-invariant controls. The parameters are time-invariant by definition.Fig. 2 shows two ODE models describing the nutrient-limited growth of phytoplankton in a chemostat. The Monodmodel [48] assumes that the consumed nutrient is instantaneously transformed into biomass. This assumption is ex-pressed by the linear proportionality between the growth rate µ and the nutrient uptake rate ρ. The Droop model [11,23] uncouples growth rate from external nutrient concentration by introducing an intracellular store of nutrients. Thegrowth rate µ is hypothesized to depend on a quantity q called the cell quota, the average amount of stored nutrientsin each cell.In cases when knowledge on the experimental system is incomplete or imprecise, ODEs can be abstracted to qual-itative differential equations (QDEs) [42]. In a first step, the ODE is decomposed into a set of basic mathematicalequations, possibly introducing additional auxiliary variables besides the variables distinguished in (1). Second, allvariables and parameters are assigned a quantity space with landmarks, and the basic equations are mapped to con-straints between the qualitative values of the variables and parameters.˙x = µ(s)x − Dx˙s = D(sin − s) − ρ(s)xµ(s) = µmaxρ(s) = 1Y µ(s)ss+ks(Monod)˙x = µ(q)x − Dx˙q = ρ(s) − µ(q)q˙s = D(sin − s) − ρ(s)x(cid:1)1 − kqµ(q) = ¯µqsρ(s) = ρmaxs+ks(cid:2)(Droop)Fig. 2. Monod and Droop models describing the nutrient-limited growth of phytoplankton in a chemostat. x denotes the total amount of biomassper unit volume, s the concentration of remaining nutrient, q the internal cell quota. The following parameters are used: dilution rate D, inputnutrient concentration sin, maximum growth rate µmax, half-saturation constant ks , growth yield Y , maximum growth rate ¯µ, minimum cell quotakq , and maximum uptake rate of nutrients ρmax. See Fig. 8 for the units of the variables and parameters in the models.I. Vatcheva et al. / Artificial Intelligence 170 (2006) 472–506477Consider, for instance, the Monod model given in Fig. 2. The first equation ˙x = (µ(s) − D)x can be decomposedinto the following basic equations:˙x = a,a = bx,b = µ − D,˙D = 0,where a and b are auxiliary variables. Next, the equations can be mapped to constraints between the qualitative valuesof the variables and parameters:D/DT(x, a), MULT(b, x, a), ADD(b, D, µ), CONSTANT(D).Often, some quantitative information is available in the form of numerical ranges for parameters and initial conditions,or numerical envelopes for functional relations. In such cases, a QDE can be extended to a semi-quantitative differ-ential equation (SQDE). For instance, the QDEs obtained from the models in Fig. 2 can be converted into SQDEs byspecifying interval bounds on the parameters and initial conditions:µmax ∈ [1.2, 1.6],¯µ ∈ [1.7, 2.3],x0 ∈ [0.088, 0.165],ks ∈ [0.01, 0.2],ρmax ∈ [9.25, 9.55],s0 ∈ [44, 46],sin ∈ [80, 120],Y ∈ [0.15, 0.6],kq ∈ [1.6, 2.0], D ∈ [0.38, 0.42],q0 ∈ [1.6, 7.62].(2)More precisely, in an SQDE the intervals are associated with landmark values in the quantity space of the variablesand parameters. When this does not lead to ambiguities, we will often simply speak of the interval bounds on theparameters and initial conditions, as in (3). In the remainder of this article, we assume that experimental systems aremodeled by semi-quantitative differential equations.Predictions from SQDEs can be derived by means of semi-quantitative simulation. A variety of semi-quantitativeor interval simulation techniques have been developed (reviewed in [17,56,58]). Here, we employ techniques thathave been developed in the field of qualitative reasoning, in particular the technique QSIM [42], and its extensions Q2[17,42,43] and Q3 [4]. Essentially, semi-quantitative simulation consists of refining the predictions of the qualitativesimulator QSIM, through the integration of quantitative information by Q2 and Q3. In general, however, the modeldiscrimination method presented in this paper does not depend on the particular set of simulation techniques. The onlyrequirement is that the simulation techniques yield semi-quantitative behavior predictions of the observed variables.The QSIM algorithm predicts all possible qualitative behaviors of an experimental system based on its QDE de-scription. Q2 and Q3 exploit the semi-quantitative information in an SQDE to refine the qualitative behavior treeproduced by QSIM. More specifically, they rule out qualitative behaviors, or transform them into semi-quantitativebehaviors, by computing or refining numerical bounds for the landmark values. The behaviors of the observed vari-ables, resulting from the simulation of the Monod and Droop models (Fig. 2) with interval bounds (3), are shown inFig. 3. The table in the figure shows predicted interval bounds for the landmarks introduced during simulation.QSIM, Q2, and Q3 have been proven sound [4,42,43]. That is, all possible semi-quantitative behaviors consistentwith an SQDE are generated by the simulation algorithms. On the other hand, QSIM and its extensions are incom-plete, in the sense that spurious qualitative behaviors may be generated or landmark bounds overestimated.2 Given apredicted semi-quantitative behavior, the interval bounds on parameter values can be refined after execution of the ex-periment by integrating measurements of observed variables [24,39]. Measurements obtained in previous experimentscan be integrated as well, by deriving additional constraints from a comparison of the models describing the system indifferent experiments. This is achieved by means of SQCA, a technique for the semi-quantitative comparative analysisof dynamical systems described by SQDEs [58,60].2.4. Competing models of experimental systemsTo compare models with observations, we need to define what it means for a model and an observation to beconsistent. In what follows, let m denote an SQDE model. We define ym to be the observed variables occurring inmodel m. Note that in general ym will be a subset of the entire set of observed variables y.2 The use of the terms soundness and (in)completeness is consistent with the interpretation of simulation as a logical inference process [41].The disjunction of (qualitative or semi-quantitative) behaviors generated by simulation is true, in the sense that it includes all genuine behaviors(soundness). However, simulation may not be able to infer the true disjunction with only genuine and no spurious behaviors (incompleteness). See[52] for an alternative interpretation.478I. Vatcheva et al. / Artificial Intelligence 170 (2006) 472–506Definition 2 (Consistency of predictions and observations). A predicted and an observed semi-quantitative behaviorof an experimental system are consistent, if ym is not empty and(1) The observed sequence of qualitative values for ym is the same as the predicted sequence of qualitative values;(2) The interval bounds on the corresponding landmark values in the predicted and observed behavior overlap.By extension, the model m is consistent with an observed semi-quantitative behavior, if at least one of the predictedsemi-quantitative behaviors is consistent with the observation.If an SQDE model is consistent with the observed behavior in the entire range of possible experimental conditions,we say that the model is correct. This suggests which criteria an SQDE has to satisfy so as to qualify as a candidatemodel of the experimental system. In particular, we require that the SQDE be consistent with all available observations(which usually cover only a small fraction of the range of possible observations).Definition 3 (Candidate model). An SQDE model m is a candidate model of an experimental system, if for each al-ready performed experiment, the observed semi-quantitative behavior is consistent with the model, where consistencyis defined as in Definition 2.Consider again the example of phytoplankton growth in a chemostat. The observed variables include the amountof biomass x and the concentration of remaining nutrient s. These are state variables in the Monod model M, so= [x, s]T . If for all available experiments the predicted values for x and s are consistent with the observations,yMthen according to Definition 3, the Monod model qualifies as a candidate model of the experimental system.The problem of model discrimination arises when there are several candidate models, making different assumptionson the structure and behavior of the experimental system. The models are competing if they have common observedvariables. In addition, the candidate models have to yield different predictions for these variables in the range of theexperimental conditions under study. These criteria are summarized in the following definition.Definition 4 (Competing models). Let M be a set of candidate SQDE models. Furthermore, let yM denote the observedvariables shared by all models in the set. The models in M are competing, if(1) yM is not empty;(2) For every pair of models m, m(cid:6) ∈ M, one can find some experimental conditions for which the semi-quantitativebehavior predictions for yM differ.The definition states that m and m(cid:6) are competing if they predict different semi-quantitative behaviors for yM inthe same experiment. Difference here means that either the predicted sets of qualitative behaviors differ or, in case themodels predict exactly the same set of qualitative behaviors, that the numerical bounds on the corresponding landmarkvalues in at least one behavior do not completely overlap.In what follows, we assume for notational simplicity that the observed variables y occur in all models in M, thatis, y = yM .As can be seen from Fig. 2, the Monod and the Droop models share two observed variables, namely the amount ofbiomass x and the concentration of the limiting nutrient s. Furthermore, the simulation results of Fig. 3 show that forthe given experimental conditions, the models predict different sets of qualitative behaviors of these variables. Hence,according to Definition 4, the two models are competing.For each m in the set of competing models M, we define p(m) to stand for the probability that m is a correctmodel of the experimental system in the range of experimental conditions. A priori estimates of the probabilities canbe determined from available experimental data. If no such data exist, we assume that the models are equiprobablea priori. When new data become available, the probability estimates can be updated according to the match betweenthe model predictions and the observations, using the Bayes’ rule.I. Vatcheva et al. / Artificial Intelligence 170 (2006) 472–506479Monod b1Droop b1Droop b2Monod b1Droop b1Droop b2smax[47.75, 118.36][44.0, 115.17][44.0, 118.09]t1[0.71, 147.09][0.53, ∞][0, 0.15]−3)s∗(×10[3.11, 107.69][0.82, 27.43][0.82, 27.43]t2[1.21, ∞][1.16, ∞][0.52, ∞]xmin––[0.076, 0.165]t3––[1.17, ∞]x∗[11.98, 72.0][30.11, 62.61][30.11, 62.61]Fig. 3. Semi-quantitative behaviors of the amount of biomass x and the remaining substrate concentration s, as predicted by the Monod and Droopmodels with the numerical ranges (3). The Monod model predicts a single semi-quantitative behavior b1 in which x increases asymptotically to itsequilibrium x∗. The Droop model predicts two semi-quantitative behaviors b1and b2. Behavior b1 is qualitatively equivalent to the behavior predicted by the Monod model. In behavior b2, x first reaches a minimum, followedby a maximum of s, and then the equilibrium is approached. smax, s∗denote the corresponding landmark values, whose predictedinterval bounds are given in the table., and s passes through a maximum before reaching its equilibrium s∗, xmin, and x∗2.5. Experiment selection for model discriminationDiscrimination of the competing models in M can be achieved by selecting and performing experiments from apredetermined set of possible experiments E. The experiments in E are assumed to have been chosen from within therange of experimental conditions relevant to the problem under study.For each e ∈ E, every m ∈ M has to be simulated with the appropriate parameter values and initial conditions,in order to determine the predictions of m for the semi-quantitative behavior of the system in e. The predictions ofthe competing models, together with the current probability estimates of the models, are then used to compute theexpected information increment of e (Fig. 4). The expected information increment is a criterion that measures thediscriminatory potential of an experiment. Intuitively, an experiment for which the model predictions differ morecan be expected to lead to better discrimination, as the experimental outcome will generally agree with fewer of thepredictions. In Section 3 this intuition will be elaborated by means of an approach based on concepts from informationtheory.Once the optimal discriminatory experiment has been determined, it is executed. The observation thus obtainedis used to adjust the probability estimates p(m) of the models m ∈ M, as well as to refine the interval bounds onthe parameter values. The experiment discriminates between the models in M, if the observation has changed theprobability estimates of the models. Optimal discrimination will be achieved if the observation is consistent withthe predictions of a single model only. If the observation is consistent with the predictions of several models, furtherexperiments need to be selected and carried out. In this way, the problem of model discrimination becomes an iterativeprocess. The procedure of selecting an experiment, performing this experiment, and updating the probability estimatesof the competing models (Fig. 5) is repeated until one of the following happens: a model has a sufficiently highprobability, all models in M have zero probability (because they are inconsistent with the observations), or the set ofpossible experiments E is exhausted.480I. Vatcheva et al. / Artificial Intelligence 170 (2006) 472–506Fig. 4. Schematic overview of the selection of experiments for model discrimination.Fig. 5. Model discrimination as an iterative process.3. Criterion for experiment selectionIn this section we propose a criterion for the selection of experiments discriminating between competing semi-quantitative models [58,59]. The criterion is formalized by means of concepts from information theory and generalizesupon previous work in statistics and model-based diagnosis.3.1. Information increment of experimentLet M be a set of competing models of an experimental system with a priori probabilities p(m) for every m ∈ M.We make the common assumption that M contains a single correct model, in the sense of Section 2.4:(cid:3)m∈Mp(m) = 1.I. Vatcheva et al. / Artificial Intelligence 170 (2006) 472–506481(3)Although (3) is a strong assumption, the practical consequences are limited, because its violation can be tested. Wefurther assume that a set of possible experiments E on the experimental system is given, and let Oe denote theobservation made in experiment e ∈ E.A standard measure in information theory is the information increment of an experiment e ∈ E [9,28]. The infor-mation increment is defined as the difference in entropy before and after the execution of the experiment:(cid:3)(cid:3)(cid:2)H (Oe) = −p(m) ln p(m) +pe(m | Oe) ln pe(m | Oe),(4)m∈Mm∈Mwhere pe(m | Oe) denotes the a posteriori probability of m, given the observation Oe in e. As can be easily verified,(cid:2)H reaches its maximum when all posterior probabilities but one are zero. That is, when the observation madein e confirms the predictions of a single model. On the other hand, a minimal value is attained, when all posteriorprobabilities are equal.Recall that in our case the observation Oe has the specific form of a semi-quantitative behavior (Definition 1).Execution of an experiment gives rise to the tuple Oe = (cid:7)le, be(cid:8), where be denotes the observed qualitative behavior,and the vector le denotes measurements of the landmarks of the observed variables, for instance their minima, maxima,or equilibrium values. This allows us to write (4) as follows:(cid:3)(cid:3)(cid:2)H (le, be) = −p(m) ln p(m) +pe(m | le, be) ln pe(m | le, be),(5)m∈Mm∈Mwith pe(m | le, be) the a posteriori probability of m, given be is the qualitative behavior observed in e, and le thevector of measurements of landmark values.Criteria for evaluating the discriminatory potential of an experiment have also been proposed in statistics (e.g., [2,25,28,29,35]) and in model-based diagnosis (MBD) (e.g., [20,22,53]). But they are less general than the informationincrement (5) proposed here.In particular, work in statistics omits the qualitative behavior of the system, which means that (5) reduces to(cid:2)H (le) = −p(m) ln p(m) +pe(m | le) ln pe(m | le).(6)(cid:3)(cid:3)m∈Mm∈MThe most sophisticated criteria in MBD [53] take into account some qualitative features of the system dynamics, inthat they assume the value of a landmark to be measured while the system is in a certain qualitative state. This givesrise to the following expression of the information increment of an experiment:(cid:3)(cid:3)(cid:2)H (le, Se) = −p(m) ln p(m) +pe(m | le, Se) ln pe(m | le, Se),(7)m∈Mm∈Mwhere Se is the set of qualitative states observed in e, and le the vector of measurements of landmark values. Noticethat no temporal ordering of the qualitative states Se is specified, unlike for the qualitative behavior be occurringin (5). By disregarding to a greater or lesser extent the information provided by the semi-quantitative behavior of thesystem, the criteria (6) and (7) may underestimate the discriminatory potential of an experiment (Section 6.2).Since the a posteriori probabilities of the models depend on the outcome of an experiment that has not been per-formed yet, (cid:2)H cannot be computed directly. Instead, we can compute its expected value, or the expected informationincrement (cid:2)J of e:(cid:5)(cid:4)(cid:2)H (le, be)(cid:2)J (e) = E(8).The expected value of (cid:2)H is computed by averaging over the possible experimental outcomes as predicted by thecompeting models. This is not easy to achieve in the case of the model discrimination problems we are interestedin. First, the models in M are semi-quantitative differential equations and each SQDE may predict several semi-quantitative behaviors for the same experiment. Second, the measurements taken in the experiments are noisy, andtherefore best described as random variables with a certain probability distribution.Existing work in statistics and MBD does not provide much help in actually computing (cid:2)J in its general form (8).Statistical criteria are easily computable, but they are restricted to (algebraic) equations with exact numerical values482I. Vatcheva et al. / Artificial Intelligence 170 (2006) 472–506for the parameters and initial conditions. MBD approaches provide some help in calculating (cid:2)J from qualitativemodels in the case of measurement selection [20]. But they do not provide generic procedures to calculate (cid:2)J fromthe information contained in semi-quantitative differential equation models, a problem that is far from straightforwardin general.In Section 3.2, we derive an expression for the expected information increment applying to the discrimination ofcompeting semi-quantitative models of dynamical systems. This expression involves probability distributions that canbe estimated from semi-quantitative simulations of the experimental system. In Sections 3.3 and 3.4, we propose aprocedure for the actual computation of these probability distributions.3.2. Expected information increment of experimentRecall that the information increment (cid:2)H of an experiment e is defined by (5), while the expected informationincrement is given by (8). For clarity of presentation, we assume for the moment that only a single landmark l ofobserved variable y is measured in experiment e. The measured value is denoted by le. Obviously, the landmark valueis included in the domain of y, i.e., le ∈ Dy (or le ∈ D for short).The expected value of the information increment of an experiment e, (cid:2)J (e), can then be computed in two stages:first, by averaging over the predicted qualitative behaviors, and second, by taking for each behavior the average of themodel predictions for the landmark value. That is,(cid:2)J (e) = E(cid:5)(cid:4)(cid:2)H (le, be)=(cid:5)(cid:4)pe(b),(cid:2)H (le, b)(cid:3)Eb∈Bewhere Be is the set of possible qualitative behaviors b of the system in e, as predicted by the competing models, andpe(b) the probability that the system exhibits behavior b in e. E[(cid:2)H (le, b)] is the expected value of (cid:2)H relative tothe conditional distribution of the landmark value, given b is the system behavior. That is,(cid:4)(cid:5)(cid:2)H (le, b)E=(cid:2)H (l, b)f e(l|b) dl,(cid:6)l∈Dwhere f e(l|b) is the conditional probability density function (pdf) of the landmark value, given that b is the behav-ior of the system in experiment e. Substituting the expression for E[(cid:2)H (le, b)] in (9), we obtain for the expectedinformation increment of e:(cid:2)J (e) =(cid:2)H (l, b)f e(l|b)pe(b) dl.(10)According to the law of total probability, we can express the probability of b as a weighted sum of the conditional(9)(11)behavior probabilities pe(b|m):(cid:3)pe(b) =pe(b|m)p(m),(cid:6)(cid:3)b∈Bel∈Dm∈M(cid:3)where pe(b|m) is the probability that the system behavior observed in e is b, provided m is the correct model of thesystem. Similarly, according to the same law, we can express the conditional pdf f e(l|b) as follows:f e(l|b) =f e(l|b, m)pe(b, m),m∈Mwhere f e(l|b, m) is the model-specific pdf of the landmark value given b is the system behavior in e, and m the correctmodel of the system. pe(b, m) is the probability that model m is correct, and b is the system behavior in e. Accordingto Bayes’ rulepe(b, m) = pe(b|m)p(m).Hence, f e(l|b) becomes:(cid:3)m∈Mf e(l|b) =f e(l|b, m)pe(b|m)p(m).(12)I. Vatcheva et al. / Artificial Intelligence 170 (2006) 472–506483The model-specific pdfs f e(l|b, m), and the conditional behavior probabilities pe(b|m), satisfy the following nor-malization conditions:(cid:6)f e(l|b, m) dl = 1,l∈D(cid:3)pe(b|m) = 1,(13)(14)b∈Bemwhere Bedetermination of the model-specific pdfs and behavior probabilities in detail.m is the set of qualitative behaviors of the system in e, as predicted by m. Sections 3.3 and 3.4 consider theIn the following proposition, the probability density function f e(l|b), the probability pe(b), and the normalizationconditions (3), (13), and (14) are used to derive an expression for the expected information increment (cid:2)J .Proposition 1. The expected information increment of an experiment e ∈ E is given by(cid:2)J (e) =(cid:3)m∈Mp(m)(cid:3)b∈Bempe(b|m)f e(l|b, m) lnl∈D(cid:6)f e(l|b, m)pe(b|m)f e(l|b)pe(b)dl.Proof. By substituting the definition of (cid:2)H into (10), we get(cid:3)(cid:7) (cid:3)(cid:3)(cid:6)(cid:2)J (e) =pe(m|l, b) ln pe(m|l, b) −(cid:8)f e(l|b)pe(b) dl,p(m) ln p(m)m∈Mb∈Bel∈Dm∈Mwherepe(m|l, b) = f e(l, b|m)p(m)f e(l, b)= f e(l|b, m)pe(b|m)p(m)f e(l|b)pe(b),(15)(16)(17)via Bayes’ rule. Combining (16) and (17), we obtain:(cid:3)(cid:3)(cid:7)(cid:6)(cid:2)J (e) =p(m)b∈Be(cid:3)l∈Dm∈M(cid:3)p(m)=f e(l|b, m)pe(b|m)f e(l|b)pe(b)(cid:6)pe(b|m)f e(l|b, m) lnlnf e(l|b, m)pe(b|m)p(m)f e(l|b)pe(b)(cid:8)− ln p(m)f e(l|b)pe(b) dlf e(l|b, m)pe(b|m)f e(l|b)pe(b)dlb∈Bemp(m) ln p(m)m∈M+(cid:3)m∈Ml∈D(cid:3)(cid:6)b∈Beml∈Dpe(b|m)f e(l|b, m) dl −(cid:3)m∈Mp(m) ln p(m)(cid:6)(cid:3)b∈Beml∈Df e(l|b)pe(b) dl.Using the normalizations (3), (13), and (14) we obtain(cid:3)(cid:3)(cid:6)p(m) ln p(m)p(m) ln p(m)m∈M(cid:3)m∈Mpe(b|m)f e(l|b, m) dl =b∈Bem(cid:3)(cid:6)b∈Beml∈Dl∈Df e(l|b)pe(b) dl =(cid:3)m∈M(cid:3)m∈Mp(m) ln p(m),p(m) ln p(m).With these equalities, the second part of the expression for (cid:2)J becomes 0, and (15) is obtained. (cid:1)The criterion (cid:2)J ranks the experiments in E according to their expected information increment. The optimaldiscriminatory experiment is the experiment expected to be most informative, or the most informative experiment forshort. That is, the experiment for which (cid:2)J (e) is maximal.Occasionally, the model predictions can lead to a simplified expression for (cid:2)J . The following corollary of Propo-sition 1 provides an expression for (cid:2)J when all models predict the same qualitative behavior [61].484I. Vatcheva et al. / Artificial Intelligence 170 (2006) 472–506Corollary 1. Let all models in M predict the same qualitative behavior b of the system in some experiment e ∈ E.Then (15) takes the form(cid:6)(cid:2)J (e) =(cid:3)m∈Mp(m)f e(l|b, m) lnl∈Df e(l|b, m)f e(l|b)dl.(18)Proof. If all models predict the same qualitative behavior, (15) can be rewritten as(cid:2)J (e) =(cid:3)m∈Mp(m)pe(b|m)f e(l|b, m) lnl∈D(cid:6)f e(l|b, m)pe(b|m)f e(l|b)pe(b)dl.Moreover, since each model predicts a single qualitative behavior b, the conditional probability of this behavior equals1 for all models. That is, pe(b|m) = 1 for all m ∈ M. Consequently, the total probability of the behavior is also 1:(cid:3)(cid:3)pe(b) =pe(b|m)p(m) =p(m) = 1.m∈Mm∈MAfter replacing this value in the above expression for (cid:2)J (e), the result (18) is obtained. (cid:1)The following corollary derives an expression for (cid:2)J for the reverse situation in which each model predicts adifferent set of qualitative behaviors.Corollary 2. Assume that, for a given experiment e ∈ E, each model m ∈ M predicts a different set of qualitativebehaviors. Then,(cid:3)(cid:2)J (e) = −p(m) ln p(m).m∈M(19)Proof. Let m(cid:6) ∈ M and m (cid:9)= m(cid:6). From the given assumptions we have pe(b|m(cid:6)) = 0, if b ∈ Bewith the expression for f e(l|b) given in (12), yields(cid:3)f e(l|b)pe(b) =(cid:6)f e(l|b, m(cid:6))pe(b|m(cid:6))p(m) = f e(l|b, m)pe(b|m)p(m),m. This fact, togetherm(cid:6)∈Mfor all b ∈ Bem. Taking this result into account, (15) takes the form(cid:2)J (e) =(cid:3)m∈Mp(m)(cid:3)b∈Bempe(b|m)f e(l|b, m) lnl∈D1p(m)dl,(cid:6)or equivalently,(cid:2)J (e) = −(cid:3)m∈Mp(m) ln p(m)(cid:3)b∈Bem(cid:6)pe(b|m)f e(l|b, m) dl.l∈DBy applying the normalization conditions (13) and (14), expression (19) is obtained. (cid:1)Note that (19) indicates the maximum value that (cid:2)J (e) can take. This conforms to the intuition that e will be theoptimal discriminatory experiment, since its outcome is guaranteed to be consistent with the predictions of at mostone model.The criterion (15) also applies when the landmark to be measured is a function of the landmarks of the observedvariables (Section 2.2). In addition, it is easily generalizable to the case that multiple landmarks are measured. In thatcase we have to substitute the probability distributions by joint probability distributions, and the integral by a multipleintegral for all landmarks. In [21] it is described how the entropy criterion can be generalized so as to take into accountthe varying costs of experiments.I. Vatcheva et al. / Artificial Intelligence 170 (2006) 472–5064853.3. Estimation of probability density functionsThe computation of (cid:2)J (e) requires the model-specific probability density functions f e(l|b, m) of the landmarkvalues. The determination of f e(l|b, m) must be based on the predictions of m. Moreover, it is important that thedefinition f e(l|b, m) also incorporates the measurement uncertainty of the landmark.Let l be a landmark of an observed variable y measured in experiment e, typically a maximum, minimum, orequilibrium value of the variable. To account for experimental noise, the measurement of l is assumed to be a randomvariable with mean le and a probability density function he(l|le, be) of known analytic form (uniform, normal, . . .)over the interval D ⊆ R [28].The functions f e(l|b, m) required for the computation of (cid:2)J (e) are the model-specific estimations of the pdfhe(l|le, be). In the case of quantitative models, the single point-value prediction lem of the landmark value providedby m is usually interpreted as the mean of the measurement [28]. Hence, f e(l|b, m) can be defined as equal tohe(l|lem). In the case of semi-quantitative differential equations, however, the predictions of landmark values areintervals. Consequently, a different approach for estimating the functions f e(l|b, m) is needed.m, beWe assume that the predicted interval refers to the mean of the landmark value and that the probability densityfunction ge(x|b, m) of the mean within the predicted interval is known. ge(x|b, m) specifies how the mean of thelandmark measurement is distributed, given that b is the system behavior in e and m the correct model of the system.Then the pdf f e(l|b, m) of the landmark can be defined as the expected value of he:(cid:6)f e(l|b, m) =he(l|x, b), ge(x|b, m) dx.x∈D(20)In other words, we define f e(l|b, m) to be the average of the possible values he(l|x, b) weighted by their correspond-ing probabilities ge(x|b, m).The model-specific pdfs of the mean of the landmark ge(x|b, m) can be obtained directly from the model predic-tions. Recall that the predictions of the competing models for the landmark values, obtained by QSIM, Q2, and Q3,have the form of intervals (Section 2.3). Since nothing is known about the distribution within a predicted interval,⊆ D is the interval predicted by m for landmark l, thenwe assume a uniform distribution. More specifically, if Lemm, and 0 otherwise, where | · | denotes interval length.ge(x|b, m) = 1/|Lem| for x ∈ LeAssume for the moment that the measured value of the landmark is uniformly distributed on the confidence intervalof the measurement. That is, he(l|x, b) = 1/ε, for l ∈ [x − ε/2, x + ε/2], with ε the size of the confidence interval.The integral in (20) can then be computed exactly. More specifically, we havef e(l|b, m) =,+ε/2|l−Lemε|Lem1| ,|Lem+ε/2−l+Lem|ε|Lem0,l ∈ [Leml ∈ [Lem− ε/2, Lem+ ε/2, Lem+ ε/2],− ε/2],,l ∈ [Leml /∈ [Lem− ε/2, Lem− ε/2, Lem+ ε/2],+ ε/2],(21)m and Lem are the lower and the upper bound of the interval prediction Lewhere Lem, respectively. Fig. 6 shows theestimate of the model-specific pdf of x∗, the equilibrium value of the amount of biomass in behavior b1 as predictedby the Monod model (Fig. 3).The expression for f e(l|b, m) defined above assumes that the mean of the landmark value is uniformly distributedin the predicted interval. Better estimations of the probability density functions ge(l|b, m), and hence of f e(l|b, m),can be obtained in the following way. Let θ be the vector of landmarks corresponding to the parameters and initialconditions of m, given at the beginning of the experiment. Because of imprecise and incomplete knowledge aboutthe system, the landmark values θ in e are approximated by a corresponding interval vector Θ e. We partition Θ einto vectors of intervals Θ ej ). This results in anjapproximation of the probability distribution of θ in Θ e. Obviously, if we do not know anything about the probability⊆ Θ e, for each of which we specify the joint probability p(θ ∈ Θ e486I. Vatcheva et al. / Artificial Intelligence 170 (2006) 472–506Fig. 6. Plot of the function f e(l|b, m) for the equilibrium amount of biomass (labeled x∗(Fig. 3). The predicted interval for the equilibrium x∗is [11.98, 71.99]. (The size of the confidence interval ε has been set equal to 3.)) of the behavior b1 predicted by the Monod modeldistributions of the parameters and initial conditions, then we assume that they are independent and uniform on thecorresponding intervals. That is,(cid:2)(cid:13)(cid:1)θ ∈ Θ ejp(cid:1)θi ∈ Θ ej i(cid:2),=pi∈Iwhere I is the set of indices of the landmarks corresponding to the parameters and initial conditions, and(cid:2)(cid:1)θi ∈ Θ ej ip=(cid:14)(cid:14)Θ ej i(cid:14)(cid:14)(cid:14)Θ e(cid:14)/i(cid:14)(cid:14),with Θ ei denoting the interval bounds on θi in e.We now simulate m for each of the vectors Θ em bounding the landmark values. For each of the predicted intervals LeLej (x|b, m) = 1/|Lethe mean. That is, gemjmodel-specific pdf ge(x|b, m):j . As a result, we obtain a set of (usually overlapping) intervals Lemj⊆mj we again assume uniform distribution ofmj , and 0 otherwise. This results in the following estimate of the| for x ∈ Lege(x|b, m) =(cid:1)θ ∈ Θ ej(cid:2)gej (x|b, m),p(cid:3)j ∈Jwhere J is the set of indices of the subintervals of Θ e. By subdividing Θ e into ever finer subintervals Θ eprogressively better estimates of ge(x|b, m), and hence of f e(l|b, m).j , we obtainConsider, for instance, the Monod model given in Fig. 2. Assume the landmarks corresponding to the parametersY , sin, m, and ks are distributed in the corresponding intervals (3) as shown in Fig. 7(a). Every interval has beensubdivided into a number of subintervals and the Monod model has been simulated for each combination of thesubintervals. The resulting predictions have been used to estimate the model-specific pdf ge(x|b, m) of the equilibriumvalue x∗ of the biomass. In comparison with Fig. 6, where a uniform distribution of the mean in the predicted intervalfor x∗ was assumed, a refined estimate of f e(l|b, m) is obtained (Fig. 7(b)).Because the above approach arrives at more precise estimates of the model-specific pdfs, the prediction of optimaldiscriminatory experiments may be improved as well. But the improved predictions come at higher computationalcosts. In the example above, for instance, 1440 simulation runs were necessary to obtain the more precise estimateof (20). For more complex models involving many parameters, the benefit of the increased precision may not outweighthe computational costs (Section 6.3).The above approach can be straightforwardly generalized to the case that multiple landmarks are taken into account.For computational simplicity, we assume that they are independent. Hence, the corresponding joint pdf is obtained bythe product of the pdfs of the individual measured landmarks.I. Vatcheva et al. / Artificial Intelligence 170 (2006) 472–506487Fig. 7. (a) Approximate probability distributions of the landmarks corresponding to the parameters y, sin, m, and ks of the Monod model, given inthe form of histograms. (b) Estimation of the probability density of x∗(behavior b1 of the Monod model in Fig. 3) obtained by taking into accountthe distributions in (a).3.4. Estimation of behavior probabilitiesTo compute (cid:2)J (e), the model-specific behavior probabilities pe(b|m) must also be known. Obviously, if b is notm, then pe(b|m) = 0. If b is one of the behaviors predicted by m, thatpredicted by m for experiment e, that is, b /∈ Beis, b ∈ Bem, an estimate of pe(b|m) can be obtained by means of the following approach.As before, let θ be the vector of landmarks corresponding to the parameters and initial conditions of model m, given⊆ Θ e beat the beginning of the experiment, and let Θ e be the vector of interval bounds on θ in e. Furthermore, let Θ ebthe vector of interval bounds on θ giving rise to behavior b ∈ Bem, as obtained from the interval constraint propagationalgorithms of Q2 and Q3. The latter programs are launched during simulation to refine, for each of the behaviors, theintervals Θ e specified in the model.Assume the probability distributions of the parameters and initial conditions are given. Having determined theinterval vector Θ er e(b|m) = pb, for each b ∈ Be(cid:1)(cid:2)θ ∈ Θ e,bm, we define:where p(θ ∈ Θ eindependently distributed, thenb) is the probability that θ lies in Θ eb. If we assume that the parameters and initial conditions arer e(b|m) =(cid:1)θi ∈ Θ ebi(cid:2),p(cid:13)i∈Iwhere I is the set of indices of the landmarks corresponding to parameters and initial conditions, and p(θi ∈ Θ eprobability that the value of θi lies in the interval Θ eby normalizing the r e(b|m)s:r e(b|m)bi) thebi . The model-specific probability of behavior b is now estimated(22)pe(b|m) =(cid:15)r e(b(cid:6)|m).b(cid:6)∈BemIf the probability distributions of the θi s are unknown, we assume that they are uniform. That is,(cid:2)(cid:1)θi ∈ Θ ebip=|Θ e|bi||Θ ei.Intuitively, pe(b|m) is thus given by the fraction of the parameter volume giving rise to b. Notice that refined estimatesfor the behavior probabilities can be developed in a similar way as in Section 3.3. But this will be omitted here.488I. Vatcheva et al. / Artificial Intelligence 170 (2006) 472–506Consider the behaviors b1 and b2 in Fig. 3, generated by simulation of the Droop model. b1 is obtained for theinitial cellular quota q0 ∈ [1.92, 7.62], while b2 is obtained for q0 ∈ [1.6, 2.66]. If we assume that q0 is uniformly dis-tributed in the interval [1.6, 7.62], then the procedure outlined above gives r(b1|D) = 0.9468 and r(b2|D) = 0.1761,where D stands for the Droop model. After normalization, we obtain the probability estimates p(b1|D) = 0.8432 andp(b2|D) = 0.1568.Alternative approaches for estimating the probabilities of qualitative behaviors have been proposed by Berleant etal. [3] and Leitch and Shen [44]. In [3] the interval bounds on the parameters and the initial conditions are used toderive a lower and an upper bound on the probability of a qualitative behavior. We have not adopted this approach here,because the computation of the expected information increment requires that the model-specific behavior probabilitiesare real values. Leitch and Shen [44] have proposed an algorithm to prioritize the qualitative behaviors of a model. Themethod uses imprecise numerical information in the form of fuzzy numbers to define the distance between successorstates in the qualitative behavior tree. Each state is given a priority label according to the value of this distance. Thepriority of a behavior is estimated on the basis of the priorities of its states. For our purposes, a disadvantage of thisalgorithm is that it only orders the behaviors (i.e., b is more likely to occur than b(cid:6)), but does not derive a quantitativeestimate of their relative priorities (i.e., by how much b is more likely to occur than b(cid:6)).3.5. Properties of the expected information incrementThe criterion (cid:2)J has some important properties which are summarized in the theorems below.3The first theorem asserts that the expected information increment of any experiment is nonnegative. That is, everyexperiment is expected to be informative on the average. This property conforms to the intuition that the measurementsmade in an experiment will help us decide between the models.Theorem 1. The expected information increment of any experiment e ∈ E is nonnegative:(cid:2)J (e) (cid:1) 0.(23)Equality holds if all models have the same predictions.Assume that in an experiment e the landmark values l1 and l2 are determined. Theorem 2 below shows that (cid:2)Jhas another desirable property: measuring both l1 and l2 while performing e is expected to be more informative thanmeasuring only one of the landmarks.Theorem 2. Let (cid:2)J (e)1 = E[(cid:2)H (lemeasured, and (cid:2)J (e)1+2 = E[(cid:2)H (lel2 are taken into account. Then,1, be)] be the expected information increment of e ∈ E when landmark l1 is2, be)] the expected information increment of e when both landmarks l1 and1, le(cid:2)J (e)1+2 (cid:1) (cid:2)J (e)1.In summary, Theorem 2 says that if we measure two landmarks in an experiment, the expected information incre-ment of the experiment will be higher than if we measure only one. Or equivalently, we expect to better discriminatebetween the models when we observe more.The expected information increment (cid:2)J , as defined here, measures the discriminatory potential of a single experi-ment. In the next section, we formulate the method for model discrimination as a sequential approach. That is, at everystep the optimal discriminatory experiment is determined, this experiment is executed, and the model probabilities areupdated in the light of the experimental outcome.3 The proofs of the theorems are included in Appendix A.I. Vatcheva et al. / Artificial Intelligence 170 (2006) 472–5064894. Algorithm for model discrimination4.1. Description of the algorithmOn the basis of the (cid:2)J -criterion, a simple algorithm for the discrimination of competing models can be formulated.We assume that a model m ∈ M is correct, if its probability estimate is above a predefined threshold value α, 0 <α (cid:2) 1.Algorithm 1 (Model discrimination). Let p(m) be the a priori probabilities of the models m ∈ M and E a set ofpossible experiments to perform.While ∃m ∈ M: p(m) (cid:9)= 0 and ∀m ∈ M: p(m) < α and E (cid:9)= ∅ doStep 1 Determine the predicted behaviors of the system for every m ∈ M in the experiments e ∈ E.Step 2 Use the model predictions to compute (cid:2)J (e), e ∈ E. Select e ∈ E for which (cid:2)J (e) is maximal.Step 3 Perform experiment e, and determine be, le.Step 4 Compute the a posteriori probabilities pe(m|le, be) of the models. Set p(m) to pe(m|le, be).Step 5 Refine the interval bounds on the parameters of the models in M.Step 6 Remove e from E.The algorithm iterates until a model has a sufficiently high probability (p(m) (cid:1) α), all models have zero proba-bilities, or all possible experiments have been executed. Obviously, if the algorithm terminates with p(m) = 0 for allm ∈ M, the assumption that M contains a correct model is violated.In the first step of the algorithm, the competing models m ∈ M are simulated by QSIM, Q2, and Q3 (Section 2.3) inorder to derive the semi-quantitative behaviors of the system for every possible experiment e ∈ E. In step 2, the valueof the expected information increment (cid:2)J (e) is computed for every experiment e ∈ E. The computation of (cid:2)J (e)exploits the predictions of the system behavior in e obtained from the models in M. More specifically, the predictionsare used to determine estimations of the model-specific probability densities and behavior probabilities (Sections 3.3and 3.4). The experiment yielding the highest value of the expected information increment is performed in step 3. Theresults of the experiment, namely the qualitative behavior be of the observed variables and the measurements of thelandmarks le, are used in step 4 to compute the posterior model probabilities via Bayes’ rule:pe(m|le, be) = f e(le|be, m)pe(be|m)p(m)f e(le|be)pe(be).f e(le|be, m) is the model-specific pdf (Section 3.3) evaluated at the measurements of the landmarks le, and pe(be|m)is the probability of behavior be conditional to model m (Section 3.4). The total behavior probability pe(be) and thevalue of the conditional pdf f e(le|be) are computed as in (11) and (12), respectively.The measurements of the landmarks le are also used, in step 5, to refine the interval bounds on the parameters of themodels in M, using the interval constraint propagation algorithms of Q2 and SQCA. In the last step of the algorithm,the performed experiment is removed from the set of possible experiments E.4.2. Implementation and performanceThe algorithm for model discrimination has been implemented on a Sun Sparc-Station5 running SunOS 5.5.1.The program has been written in Common Lisp, on top of existing implementations of QSIM, Q2, and Q3 [27,58], and contains approximately 1200 lines of code.4 The core of the implementation is the module for computingthe expected information increment of an experiment. It also includes modules for determining the model-specificprobability density functions from the model predictions, and for computing the a posteriori model probabilities viaBayes’ rule. The program takes as input the behavior predictions of the competing models in the possible experiments,as generated by QSIM, Q2, and Q3, as well as a list of initial model probabilities. A teletype interface allows the user to4 Another, platform-independent implementation has been developed in Java.490I. Vatcheva et al. / Artificial Intelligence 170 (2006) 472–506specify the values of the probability threshold α and the type of distribution of the measurements. The implementationhas been used in the application described in Section 5.To evaluate the performance of the method for model discrimination, we have investigated whether the selectionof experiments according to the expected information increment criterion leads to efficient model discrimination.More specifically, we have studied the efficiency of the method by comparing the number of steps performed by thealgorithm when experiments are selected according to their expected information increment versus when experimentsare selected at random. For this purpose, the following strategy has been adopted [58,61]. First, one of the competingmodels has been arbitrarily selected. Exact parameter values have been randomly chosen from the correspondinginterval ranges. The resulting quantitative model has been used to make exact predictions of the system behavior bynumerical simulation.5 The predicted landmark values have been treated as the mean of the measurements. Finally,using the above ‘measurements’, the algorithm for model discrimination has been applied a number of times fordifferent values of ε and α.For this performance study, we have used six competing SQDE models of a mass-spring system, making differ-ent assumptions on the spring and friction forces. The results, reported in [58,61], have shown that, as expected,the average number of experiments performed is higher in the case of random experiment selection. These resultsdemonstrate the ability of the method to discriminate more efficiently between semi-quantitative models than throughthe random choice of experiments. The simulation study has also shown that the average number of performed ex-periments decreases considerably when more landmarks are taken into account. This confirms the intuition that whenmore measurements are made in an experiment, that is, when more information about the system behavior becomesavailable, better discrimination is achieved (Theorem 2). Interestingly, we also found, at least for the mass-spring ex-ample, that the use of the refined estimates of the pdfs described in Section 3.3 did not lead to a significant reductionof the number of experiments needed for model discrimination.5. Application: discrimination of models of phytoplankton growthThe method for model discrimination presented in the previous section has been applied to the selection of ex-periments for discriminating between competing models of phytoplankton growth in a chemostat. In this section wediscuss the results of the application.5.1. Biological backgroundPhytoplankton are microscopic plants playing a key role in marine ecosystems. Many phytoplankton species ex-ist, each with a characteristic size, shape, and growth properties [33]. Like terrestrial plants, phytoplankton containchlorophyll which is necessary for photosynthesis. In photosynthesis sunlight is used as an energy source to fuse wa-ter molecules and carbon dioxide into carbohydrates (plant food). In addition to light, phytoplankton require nutrientsfor their growth. A nutrient compound, if not present in sufficient concentrations, can become limiting to the growthof phytoplankton. Nutrient limitation is often the primary factor determining the abundance of phytoplankton in anyregion of the world ocean.As the processes regulating phytoplankton growth are difficult to study in the open sea, the growth conditions arerecreated in the laboratory by means of a type of bioreactor known as the chemostat (Fig. 1). It has the advantagethat certain of the biological parameters presumably influencing growth can be controlled by the experimenter. Thechemostat is mainly used to study the growth of populations under nutrient limitation.Chemostat experiments have been used to investigate the growth properties of the unicellular marine algaDunaliella tertiolecta under nitrate limitation. The population growth has been studied for different values of thedilution rate D = F /V , where F is the inflow rate and V denotes the volume of the culture vessel. After inoculationof the chemostat, the organisms undergo a stress phase in which adaptation to the new environmental conditions takesplace. After this initial adaptation phase, in which D = 0, the value of the dilution rate is modified, and the transientbehavior of the system towards a new equilibrium is observed. Once the system has reached this equilibrium, a furtherdilution rate experiment can be performed by changing the value of D again and observing the system evolve towards5 For the numerical simulations, the fourth-fifth order Runge–Kutta method implemented in Maple has been used.I. Vatcheva et al. / Artificial Intelligence 170 (2006) 472–506491the next equilibrium. Within the same run, a number of dilution rate experiments can thus be performed, each lastinga couple of weeks.The continuous supply of medium allows one to take frequent measurements of the biomass and the concentrationof the remaining nitrate in a computer-monitored environment without disturbing the behavior of the system. However,the data thus obtained are noisy, as in the case of most biological systems [7]. For instance, phytoplankton biomassis often estimated by phytoplankton biovolume, which is difficult to measure at high precision. Furthermore, themeasurements of the remaining substrate concentration become unreliable for small concentration values, which areunder the detection limit of the apparatus.5.2. Modeling phytoplankton growthA variety of models have been proposed for describing the growth of phytoplankton under nutrient limitation in achemostat. All available models share the same basic idea: (a) at low (intra or extracellular) nutrient concentrationsthe uptake rate ρ (the rate of the nutrient consumption) and the growth rate µ are limited by, and proportional to, thenutrient concentration, whereas (b) at high nutrient concentrations the uptake and growth rates saturate and becomeconstant [36]. In this study, four models for the growth of phytoplankton are considered. The models make differentassumptions about the consumption of nutrients, the influence of the biomass on the growth rate of the population,and the relation between growth and uptake rates.In addition to the Monod and Droop models [11,23,48] presented in Section 2, we consider two other modelsproposed by Contois [14] and Caperon and Meyer [12] (Fig. 8). The Contois model is a variant of the Monod modelin which the growth rate of the population (µ) is assumed to be inhibited by the amount of biomass x. Similarly to theDroop model, the Caperon–Meyer model assumes intracellular storage of nutrients. However, the model differs fromthe Droop model by assuming a different expression for the growth rate of the population.Because of coarse-grained and noisy data, precise numerical estimations of the values of the parameters cannot beobtained. This motivates the use of semi-quantitative models. The interval bounds on the parameter values have been˙x = µ(s)x − Dx˙s = D(sin − s) − ρ(s)xµ(s) = µmaxρ(s) = 1Y µ(s)ss+ks˙x = µ(s)x − Dx˙s = D(sin − s) − ρ(s)xµ(s, x) = µmaxρ(s, x) = 1ss+kx xY µ(s, x)(Monod)(Contois)˙x = µ(q)x − Dx˙q = ρ(s) − µ(q)q˙s = D(sin − s) − ρ(s)xµ(q) = ¯µ(1 − kqq )sρ(s) = ρmaxs+ks(Droop)˙x = µ(q)x − Dx˙q = ρ(s) − µ(q)q˙s = D(sin − s) − ρ(s)xµ(q) = µmaxρ(s) = ρmaxq−kqq−kq +k0ss+ks(Caperon–Meyer)ParameterUnitMeaningInterval valueDsinµmaxksYkx¯µkqρmaxk01/dayµmol/l1/dayµmol/lµm3/µmolµmol/µm31/dayµmol/µm3µmol/(µm3 day)µmol/µm3dilution rateinput nutrient concentrationmaximum growth ratehalf-saturation constantgrowth yieldhalf-saturation constantmaximum growth rateminimum cell quotamaximum uptake rate of nutrientshalf-saturation constant–[80, 120][1.20, 1.60][0.01, 0.20][0.15, 0.60][0.00, 0.02][1.70, 2.30][1.60, 2.00][9.25, 9.55][2.00, 2.40]Fig. 8. The Monod, Contois, Droop, and Caperon–Meyer models of nutrient-limited phytoplankton growth in the chemostat. The models containthe variables x, s, and q, where x [µm3/l] denotes the total amount of biomass per unit volume, s [µmol/l] the concentration of remaining nutrient,q [µmol/µm3] the internal cell quota. The parameters and their interval bounds are given in the accompanying table. The value of D depends onthe experiment under consideration.492I. Vatcheva et al. / Artificial Intelligence 170 (2006) 472–506estimated from data obtained in preliminary experiments [5]. All experiments have been carried out at the Laboratoired’Océanographie at Villefranche-sur-Mer (France).5.3. Experiment selection approachIn order to discriminate between the four competing models discussed in the previous section, we have consideredchemostat experiments consisting of changes in the value of the dilution rate D. In response to these changes, thepopulation attains a new equilibrium value (Section 5.1). We have considered 21 possible experiments, correspondingto equispaced values of D in the range [0, 1]: D = 0, D = 0.05, . . . , D = 1. Taking into account 5% measurementuncertainty, the values of D are bounded by intervals. During the experiments, the biomass x and the concentrationof the remaining nutrient s can be measured. We consider the following landmarks of the observed variables, if theyare above the detection limit of the apparatus: minima, maxima, and equilibria of x (xmin, xmax, and x∗), as well asminima, maxima, and equilibria of s (smin, smax, and s∗).To obtain the predictions required for computing the expected information increment of the experiments, the modelshave been simulated using the qualitative simulator QSIM and its semi-quantitative extensions Q2 and Q3. In general,semi-quantitative simulation leads to the prediction of multiple qualitative behaviors for each of the models. This is aconsequence of the complexity of the models and the large intervals for the parameters and the initial conditions. Wehave verified that none of the qualitative behavior predictions is spurious, by comparing the output of QSIM, Q2, andQ3 with the analysis of the models in [6].In the next sections, the simulation results are used to order the experiments according to their expected informationincrement. The criterion is computed as described in Section 3. In particular, we have used the standard instead ofthe refined estimates for the probability distributions, in order to reduce simulation costs. The predicted optimaldiscriminatory experiment is compared with the experiment that has actually been carried out. Next, data from thelatter experiment is taken into account to update the model probabilities and to refine the interval bounds on theparameters. The equilibrium data are also used as initial conditions to simulate the models again and predict the nextoptimal dilution rate experiment.5.4. Selection of initial experimentThe first experiment, performed by default, consists of an initial phase in which the cells adapt to the new exper-imental conditions at D = 0. In this section we investigate whether more discriminating experimental results wouldbe obtained by setting D to another value. For this purpose, we have simulated the four models with QSIM, Q2, andQ3 for each of the dilution rate experiments. The initial conditions being used (Table 1) have been determined frommeasurements of the biomass, the substrate concentration, and the internal quota at the beginning of the experiment.For D = 0, the models predict a single qualitative behavior in which x asymptotically increases towards its equilib-rium x∗, and s asymptotically decreases towards s∗ (behavior b1 in Fig. 9). For all other values of D, the four modelsTable 1Initial conditions and applied dilution rate for the three experiments considered in the text. The refined intervals for the parameters after applyingthe constraint propagation algorithms in Q2 and SQCA are presented as wellExperiment123Initial conditionsx0 ∈ [0.088, 0.165]s0 ∈ [50, 55]x0 ∈ [30.7, 36.2]s0 ∈ [0, 0.01]aq0 ∈ [1.39, 1.83]bx0 ∈ [25.3, 28.3]s0 ∈ [0, 0.01]aq0 ∈ [2.82, 4.74]ba Under the detection limit.b Computed from an auxiliary model based on mass conservation [8].Applied DD = 0D = 0.95D = 0.45New parameter intervalsM&C: Y ∈ [0.55, 0.6]D&CM: kq ∈ [1.6, 1.96]q0 ∈ [5.4, 7.6]D: kq ∈ [1.65, 1.9]CM: kq ∈ [1.6, 1.74]–I. Vatcheva et al. / Artificial Intelligence 170 (2006) 472–506493Fig. 9. Selection of initial experiment. Qualitative behaviors for the growth of Dunaliella tertiolecta predicted by the Monod (M), Contois (C),Droop (D), and Caperon–Meyer (CM) models for all dilution rate experiments, for the considered initial conditions. b1 is predicted by the fourmodels for the experiment D = 0, while b2 is predicted for the other dilution rate experiments (D > 0).Fig. 10. Selection of initial experiment. Expected information increment (cid:2)J for each of the dilution rate experiments. D = 1 is the predictedoptimal discriminatory experiment. Experiment D = 0 has been performed.predict a qualitative behavior in which the equilibrium of the biomass x is reached asymptotically, while the remainingsubstrate concentration s first reaches a maximum before decreasing towards its equilibrium (behavior b2 in Fig. 9).Because the models predict a single behavior, either b1 or b2, depending on the value of D, we have p(b1) = 1 andp(b2) = 1.The four models have been assumed equiprobable a priori, that is, p(M) = p(C) = p(D) = p(CM) = 0.25. Usingthese initial probability estimates, together with the interval predictions for x∗, s∗ and smax, as well as the behaviorprobabilities, the value of the expected information increment (cid:2)J has been computed for each of the dilution rateexperiments (Fig. 10).The figure shows that the optimal discriminatory experiment is D = 1, with expected information increment (cid:2)J =0.84. As explained above, a single qualitative behavior b2 is predicted. The interval predictions of the four models inthis experiment are shown in Fig. 11(a). The figure shows only the predictions for x∗ and s∗, because the predictionsfor smax are broad and largely overlapping for the four models. As can be seen, the predictions of the Droop andCaperon–Meyer models, although included in those of the Monod and Contois models, are much more precise. Theexperiment actually performed, D = 0, turns out to be the experiment with the lowest expected information increment((cid:2)J = 0.33). Fig. 11(b) displays the predictions for x∗ and s∗ when D = 0. Notice that all four models predict s∗ = 0,which explains the low (cid:2)J -value of this experiment in comparison with the experiment D = 1.We have taken into account the results of experiment D = 0 to update the probability estimates of the models. Ascan be seen in Fig. 12(a), x and s asymptotically reach their equilibrium, in agreement with the predicted qualitativebehavior b1 and with the interval predictions of all models. As a result, none of the models can be ruled out. UsingBayes’ rule, the a posteriori model probabilities can be computed:p(M) = 0.08,p(C) = 0.08,p(D) = 0.41,p(CM) = 0.41.(24)494I. Vatcheva et al. / Artificial Intelligence 170 (2006) 472–506(a)(b)Fig. 11. Selection of initial experiment. Interval predictions of the four competing models for s∗. In (a), the predictions for the optimaldiscriminatory experiment D = 1 are given, while (b) shows the predictions for the experiment that has been actually carried out, D = 0. In thefigures stronger shading designates more overlap between the predictions.and x∗The a posteriori model probabilities give an estimation of both the quality of the fit between the model predictionsand the observation, and the precision of these predictions. The predictions of the Droop and Caperon–Meyer modelsinclude the measurements for x∗. This is not the case for the predictions of the Monod and Contois models, whichexplains the lower probability of the latter.The measurements allow the numerical bounds on the parameters in the competing models to be refined by theinterval constraint propagation algorithms in Q2 and SQCA (Section 2.3), giving rise to the intervals in Table 1. Theserefined parameter intervals are used in the determination of the next optimal discriminatory experiment.5.5. Selection of second experimentAfter the system has reached equilibrium, the value of D can be changed, and the behavior of the system towardsits new equilibrium observed. In order to determine which dilution rate experiment would be optimal, we have againapplied QSIM, Q2, and Q3 to simulate the four competing models for each possible experiment. The new initialconditions have been determined from the equilibrium values of x, s, and q in the experiment D = 0 (Table 1).Obviously, for D = 0 the state of the system does not change, because we start from the equilibrium reached inthe previous step. For every other experiment, semi-quantitative simulation results in a single qualitative behavior forall four models (Fig. 13). The behavior consists of a minimum of x, followed by a maximum of s. Of course, theprobability of this behavior, p(b1), equals 1.Using the model probabilities (24) and the simulation results, the expected information increment of each of thedilution rate experiments has been computed (Fig. 14). The results show that the experiment D = 1 is optimal with(cid:2)J = 0.69. Fig. 15 summarizes the model predictions for x∗ and s∗ (xmin and smax have been omitted, because theyare not much discriminatory). As can be seen, the predictions of the Monod and Contois models on one hand, andthe Droop and Caperon–Meyer models on the other, do not overlap. Even when taking into account uncertainty inI. Vatcheva et al. / Artificial Intelligence 170 (2006) 472–506495Fig. 12. Plot of the measurements of the temporal evolution of the biomass x (approximated by biovolume) and the substrate concentration s(NO3) in (a) the initial experiment (D = 0), (b) the second experiment (D = 0.95), and (c) the third experiment (D = 0.45) (Bernard and Sciandra,unpublished data).Fig. 13. Selection of second experiment. Qualitative behavior for the growth of D. tertiolecta predicted by the four competing models for everydilution rate experiment. For all D, 0 < D (cid:2) 1, a single qualitative behavior b1 is predicted.the measurement of x∗, the performance of the experiment D = 1 is very likely to eliminate at least two of the fourmodels. This is not guaranteed to be the case for the other experiments!The experiment D = 1 has not been performed, but data from the experiment D = 0.95, with almost the same(cid:2)J -value, was available (Fig. 12(b)). The curve agrees with the predicted qualitative behavior, while the equilibriumvalues (Table 1) provide the following a posteriori model probabilities:p(M) = 0,p(C) = 0,p(D) = 0.56,p(CM) = 0.43.(25)Notice that the Monod and Contois model have been eliminated by the measurements, because their predictions lieoutside the measured interval for x∗. The Droop and Caperon–Meyer models are approximately equally probable,which is not surprising given that their predictions are overlapping to a large extent. As shown in Table 1, the experi-mental data refine the interval bounds for the parameter kq .496I. Vatcheva et al. / Artificial Intelligence 170 (2006) 472–506Fig. 14. Selection of second experiment. Expected information increment (cid:2)J for varying values of the dilution rate. Experiment D = 1 is theoptimal discriminatory experiment, whereas experiment D = 0.95 has been performed.Fig. 15. Selection of second experiment. Interval predictions of the four competing models for the experiments for D = 1 (optimal discriminatoryexperiment). The predictions concern the landmarks x∗and s∗.5.6. Selection of third experimentAfter the first two steps, we are left with only two models. Which experiment would be able to discriminate betweenthe Droop and the Caperon–Meyer models? As before, we simulate the models from the equilibrium attained in theprevious step. For every experiment, each of the models predicts two possible qualitative behaviors for the biomass x(Fig. 16). For D < 0.95, the biomass is expected to increase asymptotically towards its equilibrium (behavior b1), or tofirst pass through a maximum (behavior b2). For D > 0.95, the models predict that x either decreases asymptoticallyto its new equilibrium (behavior b3), or first passes through a minimum (behavior b4). Estimation of the model-specificbehavior probabilities, as explained in Section 3.3, shows that p(b1) = p(b2) = 0.5, and p(b3) = p(b4) = 0.5 for allmodels and experiments.Computation of the expected information increment (not shown) indicates that D = 0.9 is the optimal discrimina-tory experiment. In reality, D = 0.45 was performed. In that experiment x was found to reach its equilibrium afterpassing through a maximum (Fig. 12(c)). As a consequence, behavior b1 is ruled out. The landmark values xmax andx∗ were measured to lie within [41.3, 43.7] and [34.8, 38.3], respectively. These results are in agreement with thepredictions of the two models, and yield the following a posteriori probabilities:p(D) = 0.41,p(CM) = 0.59.I. Vatcheva et al. / Artificial Intelligence 170 (2006) 472–506497Fig. 16. Selection of third experiment. Qualitative behaviors for the growth of Dunaliella tertiolecta predicted by the four competing models forevery dilution rate experiment. Behaviors b1 and b2 are predicted for the experiments D < 0.95, while behaviors b3 and b4 are predicted for theexperiment D > 0.95.That is, the experiment has not succeeded in discriminating between the models. The predictions of the Caperon–Meyer model are more precise than those of the Droop model (not shown), which explains the slightly higherprobability of the former. We will break off the model discrimination process at this point, since no further dataare available for this run of experiments. We remark just in passing that the theory would predict D = 0.05 as the nextoptimal discriminatory experiment.In summary, the application illustrates that the choice of experiments plays a crucial role in model discrimination.If we had chosen the experiment D = 1 instead of D = 0 in the initial experiment, we might have obtained negligiblea posteriori probabilities for the Monod and Contois model in the first step. This would have made the subsequentsteps unnecessary. Also, if we had chosen an experiment with a low D value in the second experiment, the Monodand Contois models would probably not have been ruled out. This complements the results obtained in Section 4.2,where we showed by a simulation study that selecting experiments according to their expected information incrementleads to more efficient discrimination than random selection of experiments.Two of the four models were ruled out in the model discrimination process, using data from experiments actuallyperformed instead of predicted to be optimally discriminatory. In the process, the interval bounds on one of theparameters in the remaining two models were considerably refined. Although the Monod model, and its variantslike the Contois model, are widely used in practice, the results of our study demonstrate that they are not suitable torepresent a broad range of phytoplankton growth conditions. Instead, the Droop model or the closely-related Caperon–Meyer model should be preferred. The difficulty to discriminate between the latter two models reflects their similarity.Further experiments, performed under conditions for which the predictions of the two models diverge, are needed todiscriminate between the models.6. Discussion and related workThe method described in this paper does not make any domain-specific assumptions, which guarantees that it canbe used for the discrimination of competing models of a wide range of experimental systems in a variety of scientificdomains. However, there are some requirements for the method to be applicable, determined by the assumptionsunderlying each of the key elements of Figs. 4 and 5: the models, the experiments, the simulation techniques, themodel discrimination criterion, and the model discrimination strategy. These assumptions are discussed below, in thecontext of related work.6.1. ModelsMost model discrimination methods have been developed for quantitative models, in particular algebraic equationand ordinary differential equation (ODE) models. These models allow precise numerical predictions of the systembehavior to be made, but their use requires precise numerical values of the parameters and exact functional relations498I. Vatcheva et al. / Artificial Intelligence 170 (2006) 472–506between the variables. In many situations, the available information on the system is incomplete or imprecise, thusimpeding the application of quantitative models. This is especially so in domains in which mathematical modelinghas been less widespread thus far, like biology, medicine, and chemistry. The inability to quantitatively monitor thesystem behavior over time, another frequently-occurring problem, may further complicate the use of ODE models.In response to these problems, researchers in qualitative reasoning (QR) have proposed qualitative models of dy-namical systems, typically qualitative differential equation (QDE) models [17,26,56,62]. These models have beenwidely used in domains where ODE models are difficult to formulate. For model discrimination, the qualitative be-haviors produced by QSIM and other qualitative simulators may not be sufficiently precise though. In addition, theyexperience upscaling problems due to the explosion of the number of qualitative behaviors, some of which may bespurious.The semi-quantitative models used here strike a compromise between the precision of quantitative models and theapplicability of qualitative models, in situations where the available information is incomplete or imprecise. Moreparticularly, semi-quantitative differential equations (SQDEs) extend qualitative differential equations by specifyinginterval bounds on parameter values and numerical envelopes for monotonic functions [4,38]. The use of this weaknumerical information also helps alleviate the upscaling problems experienced by qualitative simulation, in the sensethat the number of qualitative behaviors generated may be reduced and some of the spurious behaviors ruled out. Butupscaling problems still remain, partly due to the lack of suitable computer tools (Section 6.3).6.2. Criteria for experiment selectionIn order to discriminate among competing models of a dynamical system, we have to establish a criterion thatallows ranking of the possible experiments according to their discriminatory potential. Criteria for the determinationof optimal discriminatory experiments have been developed in statistics and in AI. They have been used for a widerange of problems in different domains of application, such as in biology and biotechnology (e.g., [15,37,55,57]), inphysics (e.g., [16,45]), in chemical engineering (e.g., [1,25]), and in model-based diagnosis (e.g., [20,22,53]).Most criteria for experiment selection are based on the principle of maximum divergence [2,25,28,29,35]. Intu-itively speaking, this means that a measure for the difference in model predictions in response to different experimentalconditions is defined, followed by a search for the conditions under which this measure is maximized. Here we havefocused on one particular type of maximum divergence criterion, the maximum entropy criterion, but other examplescan be found in the references given above. The basic idea underlying the maximum entropy criterion is to find theexperiment with the highest information increment (cid:2)H (4), that is, the experiment for which the difference in entropybefore and after execution is maximal. The expected value (cid:2)J of this information increment, for each of the availableexperiments, can be determined from the model predictions.The specific form that the maximum entropy criterion (4) takes, and therefore the resulting ranking of the experi-ments, is critically dependent on the characteristics of the behavior of the dynamical system we wish to consider. Inthis article, we have proposed a criterion, given by (5), that is specifically adapted to a semi-quantitative descriptionof the dynamics: it takes into account the qualitative behavior of the system as well as interval bounds on the land-mark values of the variables. This generalizes upon the maximum entropy criteria found in the statistical and MBDliterature, given by (6) and (7), respectively. While the former omits the qualitative behavior of the system, the latteronly considers qualitative states and not their temporal ordering in qualitative behaviors.The use of the generalized maximum entropy criterion may increase the discriminatory potential of the method.Consider the case that two competing models predict the single observed variable of a system to reach an equilibriumvalue in an experiment. If the two models predict overlapping values for the equilibrium value, then the experiment willbe assigned a low expected information increment according to (6). However, this is not appropriate when the modelspredict different qualitative behaviors of the system, e.g., an asymptotic increase versus decrease of the observedvariable towards its equilibrium value. The criterion we propose here, given by (5), would in this case assign a highexpected information increment for the experiment, as desired, by taking into account this predicted difference inqualitative behavior.It can be argued that, in order to discriminate between two models, it is not necessary to take into account quali-tative behaviors. In fact, information on the observed qualitative states only, leaving aside their temporal ordering inqualitative behaviors, would already suffice to refute one of the models. This idea is based on the insight that twomodels predicting different qualitative behaviors of a system will also differ on the possible qualitative states theyI. Vatcheva et al. / Artificial Intelligence 170 (2006) 472–506499predict [54]. It underlies the maximum entropy criterion (7), proposed by Struss [53] in the context of MBD, gener-alizing upon earlier work by de Kleer and Williams [22] and de Kleer [20]. The criterion (7) has the advantage thatit is computationally less expensive than criterion (5), because it does not require the transitions between qualitativestates to be computed. However, it relies on the capability to observe the qualitative states predicted to be differentfor the two models. This may not be possible if only some of the variables are observed, a situation not uncommonin practice. In that case, an experiment might be assigned a low expected information increment according to (7),whereas it should receive a high expected information increment. The additional computational costs of criterion (5)may therefore pay off. They can increase the discriminatory potential by exploiting information on the time evolutionof the system, in particular under conditions of limited measurability.To be practically useful, the information increment (5), or rather its expected value (8), has to be computed from thepredictions of the models. To this end, we have proposed a problem-independent computational framework appropriatefor SQDE models, more specifically a framework based on semi-quantitative simulation. Several technical difficultieswere solved to achieve this, notably the computation of the model-specific probability density functions f e(l|b, m) ofthe landmark values (Section 3.3) and of the model-specific behavior probabilities pe(b|m) (Section 3.4). We are notaware of any existing work addressing these problems. Methods in statistics deal with quantitative models only. WhileMBD methods allow qualitative or semi-quantitative models, they either do not specify computational procedures ordevelop procedures specific for a certain type of problem (see [20,22] for an example of the latter case).The development of an expression for the expected information increment in Section 3.2 implicitly assumes that indetermining the optimal next experiment we only need to look one step ahead. However, one can imagine that a betterestimate of (cid:2)J would be obtained by evaluating the consequences of carrying out several consecutive experiments,in the limit proceeding until only a single model remains [22]. The increase in discriminatory potential of the optimalnext experiment thus obtained, by using a multi-step lookahead instead of a one-step lookahead approach, needs to becarefully balanced against the additional computational costs involved. de Kleer et al. [21] show that, in the contextof the diagnosis of electronic circuits, one-step lookahead leads to near-optimal results.6.3. Simulation techniquesSimulation is a crucial step in the method for model discrimination. The expected information increment of eachexperiment is evaluated on the basis of the predictions derived from the competing models. As a consequence, thetechniques should derive all possible predictions, and these predictions must be as precise as possible. Omitted pre-dictions may cause a model to be falsely ruled out when the predictions derived from this model do not match theobservation in an experiment. Precise predictions are important to efficiently discriminate between the models, sinceoverestimation of the real solutions may, for instance, cause a model to be corroborated when it should be ruled out.The techniques employed in this work satisfy the first requirement: QSIM, Q2, Q3, and SQCA have been provensound (Section 2.3). As a consequence, models are only ruled out when they should be. But due to the incompletenessof the simulation techniques, spurious behaviors may be generated and the interval predictions may overestimatethe real solutions. This leads to imprecise estimates of the model-specific probability density functions and behaviorprobabilities, and hence to imprecise estimates of (cid:2)J . Moreover, spurious predictions may lead to imprecise estimatesof the posterior model probabilities.The simulation techniques employed in this paper aim at obtaining interval predictions of the landmarks that are asprecise as possible. Q2 adds quantitative information to the output of the qualitative simulator QSIM, by propagatingnumerical bounds on parameter values and functions. Q3 may improve the results of Q2 by refining the time-step inthe simulation. Within the same computational framework, Q2 also may refine interval bounds on parameter valuesby propagating the results of conducted experiments. The refinement of parameter values through the integrationof measurements can be further improved by SQCA, which infers additional constraints from the comparison withmodels describing the system in previously performed experiments.As noted previously, the increased precision of the predictions obtained by the above techniques has a cost. Forexample, the algorithm underlying Q3, step-size refinement, interpolates new states in a given semi-quantitative behav-ior, leading to an expansion of the constraint network derived from the corresponding SQDE. Consequently, constraintpropagation needs more time and may strain memory resources. These and similar problem make simulation the com-putational bottleneck of the approach presented in this article, especially in the case of large models and refined500I. Vatcheva et al. / Artificial Intelligence 170 (2006) 472–506estimates of the model-specific probability density functions (Section 3.3) and model-specific behavior probabilities(Section 3.4).The upscaling problems are partly due to the lack of high-performance computer tools for semi-quantitative sim-ulation. But even if efficient computer tools existed, there remains a fundamental trade-off between the precision ofpredictions on one hand and the computational costs on the other. In some cases the price of intensive simulationstudies aimed at high-precision predictions may be too high, whereas in others the benefits of avoiding costly andtime-consuming experiments may outweigh the computational costs.6.4. Discriminatory experimentsThe ability to discriminate between competing models of a system strongly depends upon the set of experimentsthat can be carried out. This set has been assumed to consist of a restricted number of experiments selected by thedomain expert, taking into account constraints of feasibility and safety.Sometimes it is difficult or even impossible to intervene with the system behavior. In such cases experiment se-lection for model discrimination is restricted to measurement selection [22,46,49]. In measurement selection, onedetermines the optimal measurement to perform next. Obviously, experiment selection goes beyond measurementselection in that one can determine not only the optimal measurement to perform but also the optimal experimentalconditions to apply. In fact, measurement selection makes sense only when costs of individual measurements are takeninto account. Indeed, as shown by Theorem 2 and the computer experiments mentioned in Section 4.2, if one measuresmore landmarks in an experiment, the expected information increment of the experiment increases. If measurementsare costly, one can select the most informative subset that obeys specified cost limits, using techniques that are similarto those used for experiment selection.Experiment selection starts with a set of available experiments. One can argue, however, that this provides no guar-antee that the optimal experiment is included in this set. If (cid:2)J is known or suspected to be a non-smooth function,then the discretization of a continuous range of experimental conditions may introduce a bias, and experiment designmay become an option. The basic idea of experiment design is to define the expected information increment (cid:2)J as afunction of the experimental conditions that need to be fixed in the experiment. The problem of finding the optimalexperiment is then mapped to an optimization problem: one has to find the experimental conditions for which the func-tion reaches its maximum [1,13,25,28]. By determining optimal experimental conditions within a continuous range,experiment design offers a greater discriminatory capability. But this further increases the computational complex-ity of the model discrimination problem, since global optimization approaches require a large amount of simulationruns [34]. Given that simulation is the computational bottleneck in the discrimination of semi-quantitative models(Section 6.3), experiment design may become unfeasible in practice.Even more ambitiously, experiment design can go beyond fixing a certain parameter value or initial condition,and apply to broader aspects of the experimental conditions and experimental set-up. A few explorations of this formof experiment design can be found in the AI literature, for instance in the work of Rajamoney [50] and Bradley etal. [10]. Generally speaking, experiment design thus conceived requires an explicit representation of the elements ofthe experimental set-up, as well as methods to construct a model of the experimental system from a domain theory anda description of the experimental set-up. This introduces issues in knowledge representation and automated reasoningthat fall outside the scope of this article.6.5. Model discrimination strategyIn order to discriminate a set of models, we have adopted a method that iterates the selection and execution ofexperiments, where the selection step is based on the expected information increment criterion (5). We have carriedout an extensive simulation study to test the performance of this strategy in the case of the discrimination of semi-quantitative models of a simple mechanical system (Section 4.2). Under a wide range of conditions, this approachtowards model discrimination turned out to be more efficient than the random choice of experiments, in the sensethat the average number of experiments required to discriminate between the models is lower when criterion (5) isemployed.The iteration of the selection and execution of experiments amounts to a sequential strategy for model discrim-ination [22,30]. One could imagine another strategy, consisting first of the determination a priori, not of a singleI. Vatcheva et al. / Artificial Intelligence 170 (2006) 472–506501discriminatory experiment, but of a sequence of experiments guaranteed to discriminate between all models. Oncethis experimental plan has been computed, it could be executed in a second step. As Struss [53] observes, the sequen-tial approach can save computational time, because refuted models need not be simulated when determining furtheroptimal experiments. In addition, it can render some experiments unnecessary when the models they are supposed todiscriminate have already been ruled out by previous experiments.Bradley and colleagues have proposed another strategy for a problem related to model discrimination: find thesimplest model that is valid under a representative range of experimental conditions [10]. Instead of starting with anexplicitly-defined set of possible models, the approach starts with the simplest model consistent with user-specifiedhypotheses and a domain theory. This model is tested against available observations using increasingly precise andsophisticated techniques to analyze the model, ranging from qualitative simulation to numerical parameter estimation,simulation, and bifurcation analysis. If the model fails to reproduce the data, a more detailed model is constructed. Onthe other hand, if the model succeeds in reproducing the data, further experiments to corroborate or refute the modelare proposed and executed. The method terminates when a model is found that is globally valid across the rangeof experimental conditions. The idea of the hierarchical testing of model validity, postponing the computationally-intensive tests until the model has successfully passed simpler tests, might be profitably used for model discriminationas well. However, testing one model at a time may significantly raise computational costs if the model space is large,in particular when many simple models are inconsistent with the data. For model discrimination, the strategy adoptedin this article, which consists in finding optimal experiments that refute as many models as possible at once, will ingeneral be more efficient both computationally and experimentally.7. Conclusions and further workDifferent assumptions on the structure and behavior of a system may result in a number of competing models,all justifiable by the available observations. This gives rise to the problem of model discrimination, which occurs inmany guises in practically every domain of science and engineering. To discriminate between the models new exper-iments are needed. Most experiment selection methods developed in statistics and in artificial intelligence are basedon the information increment of an experiment, that is, the difference in entropy before and after the execution ofthe experiment. Existing model discrimination methods are limited in two respects. First, the information incrementcriteria being used are not well-adapted to the discrimination of models of dynamical systems under conditions of lim-ited measurability. Second, there are no generic, domain-independent procedures for the computation of the expectedinformation increment when the models are qualitative or semi-quantitative. Many applications, however, concerndynamical systems in which variables cannot be measured, unless with great difficulty. Moreover, the informationrequired to specify numerical models is often absent.The above situation has motivated the development of a method for the selection of experiments to discriminatebetween semi-quantitative models of dynamical systems. The method has been implemented on top of existing imple-mentations of the qualitative and semi-quantitative simulation techniques QSIM, Q2, and Q3, which are used to derivemodel predictions. The method and its implementation are independent of a particular application, as they do not em-ploy any domain-specific knowledge about the experimental system. In fact, if numerical bounds on the parametersand functional relations can be formulated, and a set of discriminatory experiments exists, the method described inthis paper is applicable.The practical applicability of the method has been demonstrated on a real problem in the field of population biology.In particular, it has been shown that the method predicts the most informative experiments to discriminate between fourcompeting models of the growth of phytoplankton in a chemostat. This has been achieved in the presence of severalcomplicating factors, in particular the complexity of the models, the crude estimations of the parameter values, andthe difficulty to observe the system behavior. Our results show that the widely-used Monod model and its variants arenot valid for a broad range of phytoplankton growth conditions and that the Droop or Caperon–Meyer model shouldbe preferred. In addition, the model discrimination process has led to refined interval bounds on a key parameter ofthese models.Several directions for further work can be identified. First of all, the discussion in the previous section has broughtto the fore the central role of semi-quantitative simulation in the model discrimination method. In particular, the useof simulation involves a fundamental trade-off between experimental and computational costs. On one hand, refine-ment of the interval bounds may lead the method to propose better discriminatory experiments, due to more precise502I. Vatcheva et al. / Artificial Intelligence 170 (2006) 472–506estimations of (cid:2)J . On the other hand, the application of more sophisticated simulation techniques may cause the timespent on computing (cid:2)J to explode. More efficient implementations of current semi-quantitative simulation techniquescould relieve some of the upscalability problems. Another possible solution would be to combine semi-quantitativeand Monte Carlo simulation. Semi-quantitative simulation could be used to derive guaranteed, but probably overes-timated intervals for the values of the model variables, while Monte Carlo simulation could be used to derive fastapproximations of the probability distributions.More generally, the method for model discrimination described in this paper can be integrated with other tools forcomputer-supported modeling, such as tools for model building, model validation, and model revision, thus givingrise to integrated environments for computer-supported modeling [10,19]. Model building, conceived of as either thecomposition of a model from a set of reusable model fragments or as the induction of a model from the observedbehavior of the experimental system [40,51,63], may lead to a large set of competing models. The selection of optimalexperiments will help in determining the correct model systematically and efficiently. The explicit representation ofthe domain knowledge and knowledge on the experimental set-up would also provide the necessary prerequisites fordeveloping more ambitious forms of experiment design.AcknowledgementsThe authors would like to thank Jean-Luc Gouzé for his contributions to the work presented here and the reviewersfor their comments on previous versions of the article. Most of the work described here was accomplished while IvaylaVatcheva was a Ph.D. student at the Department of Computer Science, University of Twente, the Netherlands. Hiddede Jong, Nicolaas Mars, and Ivayla Vatcheva acknowledge financial support of the Programme d’actions intégréesfranco-néerlandaises Van Gogh (dossier 99033).Appendix A. Proofs of theoremsThis appendix details the proofs of the theorems given in Section 3.5.Theorem 5. The expected information increment of any experiment e ∈ E is nonnegative:(cid:2)J (e) (cid:1) 0.Equality holds if all models have the same predictions.(A.1)Proof. From Theorem 204 in [32] the following inequality can be established:(cid:6)(cid:3)b∈Bem(cid:1)ξm(l, b)f e(l|b)pe(b) ln ξm(l, b) dll∈D(cid:3)(cid:6)b∈Beml∈Dξm(l, b)f e(l|b)pe(b) dl ln(cid:15)b∈Be(cid:15)m(cid:16)l∈D ξm(l, b)f e(l|b)pe(b) dll∈D f e(l|b)pe(b) dl(cid:16)b∈Bem,(A.2)where pe(b) is the probability of behavior b ∈ Bem, f e(l|b) is the conditional pdf of the landmark as given by (12),and ξm(l, b) a bounded function. Equality holds only if ξm(l, b) is constant, that is, if it is independent of a particularb and l. Defineξm(l, b) = f e(l|b, m)pe(b|m)f e(y|b)pe(b),m, and f e(l|b, m) is the model-specific pdf of the landmark.where pe(b|m) is the model-specific probability of b ∈ BeHence, we can rewrite the right-hand side of (A.2) as follows(cid:6)(cid:3)b∈Beml∈Df e(l|b, m)pe(b|m) dl lnb∈Be(cid:15)m(cid:15)(cid:16)l∈D f e(l|b, m)pe(b|m) dl(cid:16)l∈D f e(l|b)pe(b) dlb∈Bem.(A.3)I. Vatcheva et al. / Artificial Intelligence 170 (2006) 472–506503Taking into account the normalization conditions(cid:6)f e(l|b, m) dl = 1andl∈D(cid:3)b∈Bempe(b|m) = 1given in (13) and (14), and using that f e(l|b) =(cid:3)(cid:3)(cid:3)(cid:6)(cid:6)f e(l|b)pe(b) dl =(cid:15)m(cid:6)∈M f e(l|b, m(cid:6))pe(b|m(cid:6))p(m(cid:6))/pe(b) from (12), we obtain(cid:6)f e(l|b, m(cid:6))pe(b|m(cid:6))p(m) = 1.b∈Beml∈Db∈Beml∈Dm(cid:6)∈MConsequently, the argument of the logarithmic function becomes 1, and the expression in (A.3) simplifies to zero.Hence,(cid:3)(cid:6)b∈Beml∈Dξm(l, b)f e(l|b)pe(b) ln ξm(l, b) dl (cid:1) 0.Since the expression for the expected information can be rewritten in the form(cid:6)(cid:3)p(m)b∈Beml∈D(cid:2)J (e) =(cid:3)m∈Mwe finally obtain(cid:2)J (e) (cid:1) 0.ξm(l, b)f e(l|b)pe(b) ln ξm(l, b) dl,Equality holds if ξm(l, b) is constant for all m. This happens only if the pe(b|m)s and the f e(l|b, m)s are the same forall behaviors and models. That is, if all models give rise to identical predictions. (cid:1)Theorem 6. Let (cid:2)J (e)1 = E[(cid:2)H (lelandmark l1 is measured, and (cid:2)J (e)1+2 = E[(cid:2)H (lelandmarks l1 and l2 are taken into account. Then,1, be)] be the expected information increment of some experiment e ∈ E when2, be)] the expected information increment of e when both1, le(cid:2)J (e)1+2 (cid:1) (cid:2)J (e)1.Proof. In this theorem, we consider landmarks of a single behavior. The formula for the expected information incre-ment therefore simplifies to the expression given in Corollary 1.By Corollary 1, we have(cid:6)(cid:2)J (e)1 =(cid:3)m∈Mp(m)f e(l1|b, m) lnl1∈D1f e(l1|b, m)f e(l1|b)dl1.Using the normalization condition(cid:6)f e(l2|l1, b, m) dl2 = 1,l2∈D2and the definition of the joint pdf of l1 and l2 as the product of the individual pdfs:f e(l1, l2|b, m) = f e(l2|l1, b, m)f e(l1|b, m),we can rewrite (A.4) as(cid:2)J (e)1 =(cid:3)m∈MGiven that(cid:6)(cid:6)p(m)f e(l1, l2|b, m) lnl1∈D1l2∈D2f e(l1, l2|b) = f e(l2|l1, b)f e(l1|b),f e(l1, l2|b, m)f e(l2|l1, b, m)f e(l1|b)dl1 dl2.(A.4)(A.5)(A.6)(A.7)504I. Vatcheva et al. / Artificial Intelligence 170 (2006) 472–506Eq. (A.6) can be written as(cid:2)J (e)1 =(cid:3)m∈M(cid:6)(cid:6)l2∈D2l1∈D1(cid:6)(cid:6)p(m)f e(l1, l2|b, m) ln−(cid:3)m∈Mp(m)f e(l1, l2|b, m) lnl1∈D1l2∈D2f e(l1, l2|b, m)f e(l1, l2|b)dl1 dl2f e(l2|l1, b, m)f e(l2|l1, b)dl1 dl2.(A.8)Notice that the first expression on the right-hand side of (A.8) equals (cid:2)J (e)1+2, by Corollary 1. The second expressioncan be rewritten by means of (A.5), using the function ζ defined as follows:ζ (l1) =(cid:3)m∈MThis results in(cid:6)p(m)f e(l2|l1, b, m) lnl2∈D2(cid:6)f e(l2|l1, b, m)f e(l2|l1, b)dl2.(cid:2)J (e)1 = (cid:2)J (e)1+2 −ζ (l1)f e(l1|b, m) dl1.l1∈D1(A.9)(A.10)In fact, ζ (l1) is an expected information increment of the form (18), so that ζ (l1) (cid:1) 0 by Theorem 1. As a consequence,the integral in the second expression on the right-hand side of (A.10) is greater than or equal to zero, since it representsthe expected value of ζ . This results in(cid:2)J (e)1+2 (cid:1) (cid:2)J (e)1.(cid:1)References[1] S. Asprey, S. Macchietto, Designing robust optimal dynamic experiments, J. Process Control 12 (2002) 545–556.[2] A. Atkinson, D. Cox, Planning experiments for discriminating between models, J. Roy. Statist. Soc. 36 (1974) 321–348.[3] D. Berleant, A. Chandra, K. Bognaes, C.-G. Liaw, L. Sheng, J. Ch’ng, Probabilities of qualitative behaviors for dependability analysis of afault-tolerance model, in: Proceedings of the ACM/SIGAPP Symposium on Applied Computing, ACM Press, New York, 1992, pp. 883–889.[4] D. Berleant, B. Kuipers, Qualitative and quantitative simulation: Bridging the gap, Artificial Intelligence 95 (2) (1997) 215–256.[5] O. Bernard, Étude expérimentale et théorique de la croissance de Dunaliella tertiolecta soumise à une limitation variable de nitrate, Ph.D.thesis, Université Pierre & Marie-Curie, Paris, France, 1995.[6] O. Bernard, J.-L. Gouzé, Global qualitative description of a class of nonlinear dynamical systems, Artificial Intelligence 136 (1) (2002) 29–59.[7] O. Bernard, G. Malara, A. Sciandra, The effects of a controlled fluctuating nutrient environment on continuous cultures of phytoplanktonmonitored by computers, J. Experimental Marine Biology and Ecology 197 (2) (1996) 263–278.[8] O. Bernard, G. Sallet, A. Sciandra, Nonlinear observers for a class of biological systems: Application to validation of a phytoplanktonic growthmodel, IEEE Trans. Automat. Control 43 (8) (1998) 1056–1065.[9] G. Box, W. Hill, Discrimination among mechanistic models, Technometrics 9 (1) (1967) 57–71.[10] E. Bradley, M. Easley, R. Stolle, Reasoning about nonlinear system identification, Artificial Intelligence 133 (1–2) (2001) 139–188.[11] D. Burmaster, The unsteady continuous culture of phosphate-limited Monochrysis lutheri Droop: Experimental and theoretical analysis,J. Experimental Marine Biology and Ecology 39 (2) (1979) 167–186.[12] J. Caperon, J. Meyer, Nitrogen-limited growth of marine phytoplankton I: Changes in population characteristics with steady-state growth rate,Deep-Sea Research 19 (1972) 601–618.[13] B. Chen, S. Asprey, On the design of optimally informative dynamic experiments for model discrimination in multiresponse nonlinear situa-tions, Industrial and Engineering Chemistry Research 42 (7) (2003) 1379–1390.[14] D. Contois, Kinetics of bacterial growth: Relationship between population density and specific growth rate of continuous cultures, J. GeneralMicrobiology 21 (1959) 40–50.[15] M. Cooney, K. McDonald, Optimal dynamic experiments for bioreactor model discrimination, Applied Microbiology and Biotechnol-ogy 43 (5) (1995) 826–837.[16] C. Dariva, J. Oliveira, J. Pinto, Experimental design for model discrimination of thermodynamic models, Fluid Phase Equilibria 146 (1–2)(1998) 35–50.[17] H. de Jong, Qualitative simulation and related approaches for the analysis of dynamical systems, Knowledge Engineering Review 19 (2)(2005) 93–132.[18] H. de Jong, N.J.I. Mars, P. van der Vet, Computer-supported resolution of measurement conflicts: A case-study in materials science, Founda-tions of Science 4 (4) (1999) 427–461.[19] H. de Jong, A. Rip, The computer revolution in science: steps towards the realization of computer-supported discovery environments, ArtificialIntelligence 91 (2) (1997) 225–256.I. Vatcheva et al. / Artificial Intelligence 170 (2006) 472–506505[20] J. de Kleer, Using crude probability estimates to guide diagnosis, Artificial Intelligence 45 (3) (1990) 381–391.[21] J. de Kleer, O. Raiman, M. Shirley, One step lookahead is pretty good, in: W. Hamscher, L. Console, J. de Kleer (Eds.), Readings in Model-based Diagnosis, Morgan Kaufmann, San Mateo, CA, 1992, pp. 138–142.[22] J. de Kleer, B. Williams, Diagnosing multiple faults, Artificial Intelligence 32 (1) (1987) 97–130.[23] M. Droop, Vitamin B12 and marine ecology IV: The kinetics of uptake growth and inhibition in Monochrysis lutheri, J. Marine BiologicalAssoc. 48 (3) (1968) 689–733.[24] D. Dvorak, B. Kuipers, Process monitoring and diagnosis, a model-based approach, IEEE Expert 6 (2) (1991) 67–74.[25] D. Espie, S. Macchietto, The optimal design of dynamic experiments, AIChE 35 (2) (1989) 223–229.[26] B. Faltings, P. Struss (Eds.), Recent Advances in Qualitative Physics, MIT Press, Cambridge, MA, 1992.[27] A. Farquhar, B. Kuipers, J. Rickel, D. Throop, Q.R. Group, QSIM: The program and its use, Technical report UT-AI-90-123, University ofTexas, Austin, TX, 1993.[28] V. Fedorov, Theory of Optimal Experiments, Academic Press, New York, 1972.[29] V. Fedorov, P. Hackl, Model-Oriented Design of Experiments, Springer, New York, 1997.[30] G. Gorry, G. Barnett, Experience with a model of sequential diagnosis, Computers and Biomedical Research 1 (1968) 490–507.[31] W. Hamscher, L. Console, J. de Kleer (Eds.), Readings in Model-Based Diagnosis, Morgan Kaufmann, San Mateo, CA, 1992.[32] G. Hardy, J. Littlewood, G. Pólya, Inequalities, Cambridge University Press, Cambridge, MA, 1967.[33] G. Harris, Phytoplankton Ecology Structure, Function and Fluctuation, London, New York, 1986.[34] R. Horst, P. Pardalos (Eds.), Handbook of Global Optimization, Kluwer, Dordrecht, 1995.[35] T. Hsiang, P. Reilly, A practical method for discriminating among mechanistic models, Canadian J. Chemical Engineering 49 (1971) 865–871.[36] S. Hsu, S. Hubbell, P. Waltman, A mathematical theory for single-nutrient competition in continuous cultures of microorganisms, SIAM J.Appl. Math. 32 (2) (1977) 366–383.[37] T. Ideker, V. Thorsson, R. Karp, Discovery of regulatory interactions through perturbation: Inference and experimental design, in: R. Altman,K. Lauderdale, A. Dunker, L. Hunter, T. Klein (Eds.), Proceedings of the Pacific Symposium on Biocomputing, PSB, 2000, vol. 5, WorldScientific Publishing, Singapore, 2000, pp. 302–313.[38] H. Kay, SQSIM: A simulator for imprecise ODE models, Computers and Chemical Engineering 23 (1) (1998) 27–46.[39] H. Kay, B. Rinner, B. Kuipers, Semi-quantitative system identification, Artificial Intelligence 119 (1–2) (2000) 103–140.[40] J. Keppens, Q. Shen, On compositional modelling, Knowledge Engineering Review 16 (2) (2001) 157–200.[41] B. Kuipers, Qualitative simulation: Then and now, Artificial Intelligence 59 (1–2) (1993) 133–140.[42] B. Kuipers, Qualitative Reasoning: Modeling and Simulation with Incomplete Knowledge, MIT Press, Cambridge, MA, 1994.[43] B. Kuipers, D. Berleant, Using incomplete quantitative knowledge in qualitative reasoning, in: Proceedings of the 7th National Conference onArtificial Intelligence, AAAI-88, Morgan Kaufmann, Los Altos, CA, 1988, pp. 324–329.[44] R. Leitch, Q. Shen, Prioritising behaviors in qualitative simulation, in: J. McDermott (Ed.), Proceedings of the 13th International Joint Con-ference on Artificial Intelligence, IJCAI-93, Morgan Kaufmann, San Mateo, CA, 1993, pp. 1523–1528.[45] C. Lund, C. Surko, M. Maple, S. Yamamoto, Model discrimination in oscillatory CO oxidation on platinum catalysts at atmospheric pressure,Surface Science 459 (2000) 413–425.[46] S. McIlraith, R. Reiter, On tests for hypothetical reasoning, in: Readings in Model-Based Diagnosis, Morgan Kaufmann, San Mateo, CA,1992, pp. 89–96.[47] T. Mitchell, Machine Learning, McGraw-Hill, New York, 1997.[48] J. Monod, Recherches sur la croissance des cultures bactériennes, Hermann, Paris, 1942.[49] S. Narasimhan, P. Mosterman, G. Biswas, A systematic analysis of measurement selection algorithms for fault isolation in dynamic systems,in: Working Notes of the 8th International Workshop on Principles of Diagnosis, DX-98, Cape Cod, MA, 1998, pp. 94–101.[50] S. Rajamoney, The design of discrimination experiments, Machine Learning 12 (1993) 185–203.[51] C. Schut, B. Bredeweg, An overview of approaches to qualitative model construction, Knowledge Engineering Review 11 (1) (1996) 1–25.[52] P. Struss, Mathematical aspects of qualitative reasoning, Artificial Intelligence in Engineering 3 (3) (1988) 156–169.[53] P. Struss, Testing for discrimination of diagnoses. In: Working Notes of the 5th International Workshop on Principles of Diagnosis, DX-94,New Paltz, NY, 1994.[54] P. Struss, Fundamentals of model-based diagnosis of dynamic systems, in: M. Pollack (Ed.), Proceedings of the Fifteenth International JointConference on Artificial Intelligence, IJCAI-97, Morgan Kaufmann, San Francisco, CA, 1997, pp. 480–485.[55] R. Takors, W. Wiechert, D. Weuster-Botz, Experimental design for the identification of macrokinetic models and model discrimination,Biotechnology and Bioengineering 56 (5) (1997) 564–576.[56] L. Travé-Massuyès, P. Dague (Eds.), Modèles et raisonnements qualitatifs, Hermès, Paris, 2003.[57] G. Treitz, G. Maria, F. Giffhorn, E. Heinzle, Kinetic model discrimination via step-by-step experimental and computational procedure in theenzymatic oxidation of D-glucose, J. Biotechnology 85 (3) (2001) 271–287.[58] I. Vatcheva, Computer-supported experiment selection for model discrimination, Ph.D. thesis, University of Twente, Enschede, the Nether-lands, 2001.[59] I. Vatcheva, O. Bernard, H. de Jong, J.-L. Gouzé, N. Mars, Discrimination of semi-quantitative models by experiment selection: Methodand application in population biology, in: B. Nebel (Ed.), Proceedings of the 17th International Joint Conference on Artificial Intelligence,IJCAI-01, Morgan Kaufmann, San Mateo, CA, 2001, pp. 74–79.[60] I. Vatcheva, H. de Jong, Semi-quantitative comparative analysis, in: T. Dean (Ed.), Proceedings of the 16th International Joint Conference onArtificial Intelligence, IJCAI-99, Morgan Kaufmann, San Francisco, CA, 1999, pp. 1034–1040.506I. Vatcheva et al. / Artificial Intelligence 170 (2006) 472–506[61] I. Vatcheva, H. de Jong, N.J.I. Mars, Selection of perturbation experiments for model discrimination, in: W. Horn (Ed.), Proceedings of the14th European Conference on Artificial Intelligence, ECAI-2000, IOS Press, Amsterdam, 2000, pp. 191–195.[62] D. Weld, J. de Kleer (Eds.), Readings in Qualitative Reasoning about Physical Systems, Morgan Kaufmann, San Mateo, CA, 1990.[63] S. Xia, N. Smith, Automated modelling: A discussion and review, Knowledge Engineering Review 11 (2) (1996) 137–160.