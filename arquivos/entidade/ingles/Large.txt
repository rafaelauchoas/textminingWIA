Published in "Medical image analysis", 2018, vol. 43, pp. 66-84, which should be cited to refer to this work.DOI: 10.1016/j.media.2017.09.007Large-scale Retrieval for Medical Image Analytics: AComprehensive ReviewZhongyu Lia, Xiaofan Zhanga, Henning M¨ullerb, Shaoting Zhanga,∗aDepartment of Computer Science, University of North Carolina at Charlotte, USAbUniversity of Applied Sciences Western Switzerland (HES-SO), Sierre, SwitzerlandAbstractOver the past decades, medical image analytics was greatly facilitated by theexplosion of digital imaging techniques, where huge amounts of medical im-ages were produced with ever-increasing quality and diversity. However, con-ventional methods for analyzing medical images have achieved limited suc-cess, as they are not capable to tackle the huge amount of image data. In thispaper, we review state-of-the-art approaches for large-scale medical imageanalysis, which are mainly based on recent advances in computer vision, ma-chine learning and information retrieval. Specifically, we first present the gen-eral pipeline of large-scale retrieval, summarize the challenges/opportunitiesof medical image analytics on a large-scale. Then, we provide a comprehen-sive review of algorithms and techniques relevant to major processes in thepipeline, including feature representation, feature indexing, searching, etc.On the basis of existing work, we introduce the evaluation protocols andmultiple applications of large-scale medical image retrieval, with a variety ofexploratory and diagnostic scenarios. Finally, we discuss future directions oflarge-scale retrieval, which can further improve the performance of medicalimage analysis.Keywords: Medical image analysis, information retrieval, large scale,computer aided diagnosis∗Corresponding author, rutgers.shaoting@gmail.comPreprint submitted to Medical Image AnalysisSeptember 21, 2018123456789101112131415161718192021222324252627282930313233343536371. IntroductionMedical image analytics plays a central role in clinical diagnosis, image-guided surgery and pattern discovery. Many protocols and modalities ofdigital imaging techniques have been adopted to generate medical images,including magnetic resonance imaging (MRI) (Slichter, 2013), computed to-mography (CT) (Hsieh, 2009), photon emission tomography (PET) (Baileyet al., 2005), ultrasound (Szabo, 2004), fluorescence microscopy (Lichtmanand Conchello, 2005), X-ray (Lewis, 2004) and others. Generally, these med-ical images reflect specific aspects (anatomy, function) of tissue types/organsthat require an accurate interpretation and analysis from either domain ex-perts or computer-aided decision support. In comparison with domain ex-pert analysis that is labor intensive and time-consuming, computer-aidedapproaches are efficient and its accuracy has increased continuously withthe rapid development of computer vision, machine learning and relatedfields (Doi, 2014; Katouzian et al., 2012; May, 2010). To support computer-aided medical image analytics, one important task is content-based imageretrieval (CBIR) (Akg¨ul et al., 2011; Lehmann et al., 2004; M¨uller et al.,2004), i.e., indexing and mining images that contain a similar visual con-tent (e.g., shape, morphology, structure, etc). For a new medical image tobe analyzed, a CBIR system can first retrieve visually similar images in anexisting dataset. Then, its high-level descriptions and interpretations can beexplored based on the retrieved images.Over the past 25 years, CBIR has been one of the most vivid researchtopics in the field of computer vision. Many CBIR methods were developedfor accurate and efficient image retrieval. Especially in recent years, withthe ever-increasing number of digital images (e.g., ImageNet (Russakovskyet al., 2015), COCO (Lin et al., 2014), PASCAL VOC (Everingham et al.,2010), etc), CBIR has moved towards the era of big data. Massive amounts ofimages can provide rich information for comparison and analysis, and thusfacilitate the generation of new algorithms and techniques that can tackleIn general, large-scale image retrievalimage retrieval in large databases.can be divided into two stages, i.e., feature extraction to represent imagesand feature indexing. Deep learning (LeCun et al., 2015) is one of the mostpopular methods for feature representation that is particularly suitable forlarge image databases, where massive amounts of data can boost the retrievalperformance by training deep and complex neural networks with millions ofparameters (Babenko and Lempitsky, 2015; Wan et al., 2014). For the feature238394041424344454647484950515253545556575859606162636465666768697071727374indexing at a large-scale, the key problem is computational efficiency, i.e.,similarity searching in millions of images with thousand dimensional featuresvectors. Methods such as vocabulary trees (Nister and Stewenius, 2006) andhashing (Wang et al., 2016) can efficiently tackle this problem, either throughchanging the indexing structure or compressing the original features.Despite the current large-scale methods having achieved many successesin generic image retrieval problems, how to best tackle the retrieval in large-scale medical image databases is still a very challenging topic (Zhang andMetaxas, 2016). On the one hand, the meaning of large-scale in the medicalimage field is somewhat different from large-scale in the generic image do-main. Generally, each patient can generate hundreds to thousands of imageslices using different protocols, modalities (e.g., CT, MRI, X-ray) and multi-ple dimensions (e.g., volumetric 3D, time series). These volumes are usuallystored in many single images (as slices) in the DICOM (Digitla Imaging andCommunications in Medicine) format (Kahn et al., 2007). Besides this, thesize of some medical images can be extremely large. For example, the whole-slide histopathological images can include more than 100, 000×100, 000 pixelsand thus each is usually split into millions of small patches for processing.On the other hand, medical images are usually more difficult to analyze com-pared to generic images. The complex imaging parameters (contrast agents,machine settings), anatomic difference and interactions between different dis-eases result in a more complex analysis compared with natural images, wherebroad object categories are recognized and used for similarity calculations.The relevant changes of some medical images can be very subtle, which re-quire more fine-grained and detailed analysis. Therefore, directly employingtraditional CBIR methods may not suitable for the large-scale medical imageretrieval problem. In recent years, many efforts have been made to achievelarge-scale medical image analytics, aiming to improve the efficiency andaccuracy of image retrieval.1.1. Related WorkThere have been multiple reviews focusing on content-based medical im-age retrieval. The first review in the field was (Tang et al., 1999) but thetext only contained few systems with a limited scope. Muller et al. (M¨ulleret al., 2004) presented a first complete review that concentrates on imageretrieval in the medical domain, where the techniques used in medical im-age retrieval, including visual feature extraction, image comparison, systemevaluation, etc. are summarized. Subsequently, Long et al. (Long et al.,3757677787980818283848586878889909192939495969798991001011021031041051061071081091101112009) introduced four medical CBIR systems, i.e., CervigramFinder (Xueet al., 2008), SPIRS (Hsu et al., 2007), IRMA (IRMA), SPIRS-IRMA (An-tani et al., 2007). The authors also discussed future directions of medicalimage retrieval. Akgul et al. (Akg¨ul et al., 2011) presented a comprehensivereview about recent techniques of content-based image retrieval in radiol-ogy until 2011, including image features/descriptors, similarity measures andstate-of-the-art systems. Additionally, they discussed challenges and futuredirections for the coming decade. Hwang et al. (Hwang et al., 2012) reviewedboth text-based and content-based medical image retrieval systems, drawinga conclusion that the image retrieval service will be more effective if CBIRand semantic systems are combined. In 2013, Kumar et al. (Kumar et al.,2013) surveyed several applications and approaches to medical CBIR thatfocus on clinical imaging data that are multidimensional or acquired usingmultiple modalities such as combined PET-CT images.Besides the abovementioned survey articles, the image retrieval task ofthe Conference and Labs of the Evaluation Forum, named ImageCLEF (Im-ageCLEF; M¨uller et al., 2010), has held several medical image retrieval tasksfrom 2004-2014. ImageCLEF provides a platform for research groups sub-mitting results and competing on the performance of their medical imageretrieval methods. After each ImageCLEF medical image retrieval task, anoverview is provided to summarize the methods and results of each compe-tition groups (de Herrera et al., 2013; Kalpathy-Cramer et al., 2015, 2011;M¨uller et al., 2012), which demonstrates the state-of-the-art in the medicalimage retrieval field. A benchmark for case-based retrieval including full vol-umetric images of more than 300 patients was run as part of the VISCERALbenchmark Jimenez-del-Toro et al. (2015).1.2. Contributions and Organization of this ArticleThis survey provides a structured and extensive overview of large-scaleretrieval for medical image analytics. Despite existing reviews having sum-marized varieties of medical retrieval systems and methods, none of themfocused on the retrieval techniques for large-scale medical data, which is cur-rently the main challenge in the field of medical analytics. This survey offersa focused overview of the retrieval approaches for the large-scale medical im-age data by expanding multidisciplinary components that involve a nexusof the idea from machine learning, computer vision, information retrieval,and bioinformatics. It explains the entire process from scratch and presentsa comprehensive pipeline that discusses every processing step from feature4Figure 1: A general pipeline of large-scale medical image retrieval.extraction to knowledge discovery and decision support. Fig. 1 illustrates ageneral pipeline of large-scale medical image retrieval. Given a set of medi-cal images (e.g., MRI, CT, microscopy, etc.), feature extraction methods areemployed to represent each image. Unlike traditional medical retrieval meth-ods that directly compare the image similarity via original feature vectors,large-scale approaches often first train a retrieval model, e.g., organizing andtransforming image features that can improve the performance of feature in-In the query phase, the query image is compared only to similardexing.images based on the well-designed retrieval model rather than an exhaustivesearch of the whole database. The retrieval results can be provided to usersfor further analysis. According to Fig. 1, retrieval with large-scale medicalimage databases is different compared with classical CBIR systems. In recentyears, many researchers in the medical domain have moved their attention tothe analytical questions of large-scale image analysis (Zhang and Metaxas,2016). Therefore, in this era of big data, it is necessary to present a com-prehensive review of recent advances in large-scale medical image analytics.In this paper, we organize the survey into five parts: challenges/opportunities,methodology review, evaluation protocols, applications, and future direc-tions. In Section 2, challenges and opportunities related to big data in medi-cal image analytics are provided. Section 3 and 4 discuss the methodology de-1121131141151161171181191201211221231241251261271281291301311325Biomedical DatabasesQuery ImageTraining PhaseQuery PhaseFeature ExtractionTraining Images......Feature Vectors...Model TrainingMapping Model...Feature ExtractionFeature ExtractionMapping ModelIndexing...Retrieved Images133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167tails relevant to the large-scale medical image retrieval, which mainly includestwo parts, i.e., feature representation, feature indexing and search. FollowingSection 5 introcudes evaluation protocols in medical image retrieval. Basedon the existing approaches, Section 6 reviews several applications of large-scale medical image retrieval. Finally, Section 7 explores potential directionsfor future work on large-scale medical retrieval.2. Challenges and OpportunitiesThe challenges of large-scale medical image retrieval can be summarizedas a good trade-off between efficiency and accuracy. Despite traditional meth-ods having already achieved good performance in many very specific medicalscenarios, keeping efficiency and accuracy in large-scale approaches still facesmany problems. Additionally, in the era of big data, large-scale medical im-age analysis provides many opportunities for both academia and industry.2.1. ChallengesOne major concern in the bigdata era is system efficiency. Giventhe huge amount of medical imagedata (WPS, 2010), how to repre-sent and search in an efficient waystill has many challenges. Countingthe data from The Cancer ImagingArchive (TCIA), a large-scale med-ical image repository, Fig. 2 illus-trates the number of images with thesix most common anatomical sites.According to Fig. 2, these data setshave hundreds of thousands to mil-lions of medical images, which arehard to analyze in real-time. Formedical image retrieval, each imageis usually represented by a featurevector with often thousands of di-mensions. An exhaustive search of millions of images with large featurevectors is very time-consuming (Zhang et al., 2015c).In clinical applica-tions, for a single patient tens to hundreds/thousands of images are collectedFigure 2: Number of medical images forthe six most common anatomical area in theTCIA (The Cancer Imaging Archive) reposi-tory.6BreastBrainLungProstateLiverRenalAnatomical Site00.511.522.5Number of Images#106168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205(large MRI studies can easily contains tens of thousand of single image slicesfor a single patient) and an efficient retrieval of these images is required forcomputer-assisted diagnosis. Accordingly, to achieve medical retrieval withmassive amounts of images, two aspects need to be explored for improvement, i.e., 1) reducing the dimension of the feature vectors (or creating very sparsespaces), 2) improving the strategy of similarity search or data indexing. Bothchallenges are hard to tackle using conventional methods.Another concern of medical retrieval is system accuracy.In the infor-mation retrieval field, precision is one of the most important criteria forperformance evaluation, which is defined as the fraction of retrieved im-ages that are relevant to the query image (Powers, 2011). For a queryimage, higher retrieval precision indicates more reliable analysis and explo-ration results, since most of the retrieved images share (hopefully) similarsemantic content with the query image. Retrieval precision plays a criticalrole in medical analytics, where clinical diagnoses can depend on decisionsupport that is based on the retrieved images. However, achieving highprecision in medical retrieval is not an easy task, especially with the largeamount of volumetric image data, where most parts of the images/volumesare not important for similarity calculations but small, local anomalies are.Fig. 3 illustrates a common problemin the classification of histopatho-logical images, which are obtainedfrom intraductal breast lesions inthis case. The two images to theleft (with the blue bounding box)belong to the same category,i.e.,both are actionable (indicating thecells/tumors are pathogenic). How-ever, they have quite different ex-pressions. On the other side,forthe bottom two images (with thered bounding box), despite the vi-sual similarity, they belong to dif-ferent categories (the right image isbenign, indicating the cell’s/tumor’slack of the ability to invade neigh-boring tissue and create metastasis).This problem can be summarized as large intra-class variation and smallFigure 3: Three histopathology imagesofintraductal breast lesions. Classifyingthe breast histopathology images into be-nign or malignant is a challenge due to theirinter-large intra-class variation and smallclass variation.7Same CategoryDifferent CategoryVisually SimilarMalignantBenign206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241inter-class variation (Zhang et al., 2016b). Not only in histopathological im-age analysis, most medical image analytics tasks encounter similar problems.More critically, when dealing with massive medical data, this problem be-comes more challenging since more noisy images are included and influencethe retrieval performance.In addition to measuring efficiency and accuracy, the detailed evalua-tion protocol is also a challenging question in large-scale medical image re-trieval. Most of the traditional methods simply use class labels to evaluatethe retrieval performance, which is not suitable for large-scale medical imagedatabases, as they are most often not fully labeled and there can be differentrelevance expectations depending on the query images. Besides this, the datastorage, access, organization, and computing techniques may also influencethe retrieval performance of large-scale medical images. In this article, wereview relevant methods and techniques that can tackle large-scale medicalimage retrieval.2.2. OpportunitiesLeaving aside the above challenges, large-scale image data brings unprece-dented opportunities to the medical field. In 2014, Siemens released a reportsaying that the market for medical imaging systems will grow from 32.3 bil-lion in 2014 to 49 billion in 2020 (Siemens). Without doubt, in the era ofbig data the development of large-scale medical analytics will accelerate thisprocess.In a medical retrieval system, massive image data generally pro-vides more samples for similarity search, which can improve the accuracyand reliability of the system (Fang et al., 2016). More importantly, it alsofacilitates the research of knowledge discovery and pattern exploration inbiomedical informatics. We illustrate two major opportunities that benefitfrom large-scale medical retrieval, i.e., computer-aided diagnosis and visualpattern exploration:1. computer-aided diagnostics (CAD): CBIR methods have been proposedas an effective technology for CAD systems, which have the capacityof relieving the workload of doctors and to offer more reliable and con-sist analysis of medical images (Akg¨ul et al., 2011; Depeursinge et al.,2011). Despite most retrieval systems are not routinely used, CBIRbased CAD are rather research prototypes for medical image analytics.Given an image database with diagnosis information, CBIR methodsaim to retrieve and visualize images with morphological profiles most8242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276relevant to and consistent with the query image. This can provide deci-sion support, for example for pathologists (Kumar et al., 2013; M¨ulleret al., 2004). When the CBIR-based CAD systems meet large-scaleimage databases, this benefit is enlarged by searching more relevantimages with fine-grained content and morphologies. Retrieval resultsfrom large-scale databases can help pathologists to have accurate anddeep understanding of query images, when they are unsure about spe-cific patterns.2. visual pattern exploration: medical images contain a wealth of struc-tures and patterns that may convey information about underlying mech-anisms in biology (Peng et al., 2010; Schindelin et al., 2012). Generally,individuals with similar structures, shapes, morphologies will also ex-press similar functions and properties, such as neurons, tissue cells,etc. (Li et al., 2017a; Xing and Yang, 2016). By establishing largemedical databases of visual data, CBIR systems can be used to iden-tify and explore unknown individuals based on the retrieval results.Massive image data are the basic requirement for such a medical ex-ploration. As individuals usually have complex shapes and varieties inthe images, large-scale databases can provide more reliable results forpattern exploration, as it is more likely that similar patients exist ofwhich images were taken with similar protocols.Large-scale image databases bring new opportunities to innovate the tradi-tional medical retrieval systems, and some of the large-scale medical systemshave already achieved good performance in clinical practice. In Section 6,we review relevant applications of large-scale medical retrieval.3. Feature RepresentationTo achieve medical analytics from large-scale image databases, the firststep is visual feature extraction, i.e., using feature vectors to represent eachdigital image. Generally, feature vectors are representing the low-level im-age content and can be linked to high-level perceptions of the images. Agood feature representation is the prerequisite to achieve good performancein medical image retrieval. In recent years, a variety of feature representa-tions have been developed based on computer vision and machine learning.This section reviews recent advances in feature vectors in medical images.Specifically, the feature representation is classified into two categories, i.e.,9277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313hand-crafted and learned features. This is mainly based on whether the fea-tures are obtained through domain expert knowledge (model-driven) or apurely data-driven procedures.3.1. Hand-crafted FeaturesGenerally, hand-crafted features are sequentially extracted from each im-age according to algorithms based generally on expert knowledge (Antipovet al., 2015), where each feature models a specific information such as color,texture or shape. Before the strong use of deep learning, hand-crafted meth-ods dominated the feature extraction field for several decades. Most currentmedical retrieval systems still employ hand-crafted methods for feature rep-resentation. In this subsection, we review typical hand-crafted features thathave been used in medical image retrieval.The most widely used hand-crafted features for image retrieval are basedon the Scale-Invariant Feature Transform (SIFT) (Lowe, 2004). SIFT de-tects scale-invariant key points by finding local extrema in the difference-of-Gaussian (DoG) space. It describes each key point by a 128-dimensionalgradient orientation histogram. Subsequently, all SIFT descriptors are mod-eled/quantized using a bag-of-words (BoW) (Sivic and Zisserman, 2003). Thefeature vector of each image is computed by counting the frequency of thegenerated visual words in the image. SIFT is a local texture feature thathas achieved success in medical image retrieval (e.g., it was the most pop-ular feature in the ImageCLEF medical image retrieval task (M¨uller et al.,2012)). Besides SIFT descriptors, many local descriptors can use the BoWsto generate local features for medical images, such as SURF (Speeded Up Ro-bust Features) (Bay et al., 2008), LBP (Local Binary Patterns) (Ojala et al.,1996) and others. In contrast to features extracted locally, holistic featuresare also widely adopted in medical image retrieval. These kinds of featurescan directly represent the global information of the entire image. For exam-ple, GIST (Oliva and Torralba, 2001) is a holistic feature which is based ona low dimensional representation of the scene that does not require any formof segmentation, and it includes a set of perceptual dimensions (naturalness,openness, roughness, expansion, ruggedness) that represent the dominantspatial structure of a scene (Douze et al., 2009). GIST has been applied inmany medical image retrieval problems (Kalpathy-Cramer and Hersh, 2008;Liu et al., 2014a). Other holistic features such as HOG (Histogram of Gaus-sians) (Dalal and Triggs, 2005), color histograms (Siggelkow, 2002) are alsofrequently used in medical image retrieval (M¨uller and Deserno, 2010; Yu10MethodSIFT (Lowe, 2004)CategoryLocal, textureSURF (Bay et al., 2008)Local, textureLBP (Ojala et al., 1996)Local, textureGIST (Oliva and Torralba, 2001)Holistic, shapeHOG (Dalal and Triggs, 2005)Holistic, textureColor Histogram (Siggelkow, 2002)Holistic, colorMoments (Stricker and Orengo, 1995)Holostic, shapeGabor filters (Manjunath and Ma, 1996)Local, textureTamura (Tamura et al., 1978)Local, texture3D Riesz (Chenouard and Unser, 2011)Local, textureApplicationBreast cancer (Zhang et al., 2015c),Basal-cell carcinoma (Wang et al., 2011a), etcLung CTs (Haas et al., 2011),Body portion (Feulner et al., 2011), etc2D-HeLa (Nanni et al., 2010),Brain MR (Murala et al., 2012), etcMammogram (Liu et al., 2014a),Breast-tissue (Jiang et al., 2016a), etc.Cortical (Unay and Ekin, 2011),Lung (Song et al., 2012), etcOrgan (Caicedo et al., 2007),Dermatology (Bunte et al., 2011), etc.Multi-modalities (Rahman et al., 2007),Liver CT (Gletsos et al., 2003), etc.Multi-modalities (Lim and Chevallet, 2005),Prostate Histopathology (Doyle et al., 2007), etc.Mammogram (Zhou et al., 2012),Multi-modalities (G¨uld et al., 2005), etc.Epileptogenic Lesion (del Toro et al., 2013),3D Multi-modalities (Jim´enez-del Toro et al., 2015), etcTable 1: Commonly used hand-crafted features and their applications in medical imageretrieval.314315316317318319320321322323324325326327328329330331332333334335et al., 2013). Table 1 lists some of the most commonly used hand-craftedfeatures and their corresponding applications in medical image retrieval.In addition to the common features mentioned above that can be usedfor the retrieval of both natural and medical images, there are many otherhand-crafted features that are designed specifically for medical image data.In histopathology image analysis, the shape and texture information play animportant role in the representation of cell/nuclei. Basavanhally et al. (Basa-vanhally et al., 2010) designed three graph-based features, i.e., Voronoi dia-gram, Delaunay triangulation, and minimum spanning tree, to describe thearrangement of the lymphocytes. Filipczuk (Filipczuk et al., 2013) employed25 kinds of features to represent cytological images, including the size of thenuclei, the texture features based on gray-level pixels, and the distribution ofnuclei in the image. In general, these specific features are more discriminativethan the general hand-crafted features. They achieved good performance inthe detection, retrieval and analysis of cells and nuclei (Xing and Yang, 2016).Besides the histopathological images, specific features are also widely usedfor the representation of 3D medical image data, such as 3D brain tumors,neuronal morphology. For example, Cai et al. (Cai et al., 2010) developedPCM-based volumetric texture features for 3D neurological image retrieval,and Wan et al. (Wan et al., 2015) employed quantitative measurements andgeometrical moments as features to represent the 3D neuron morphologicaldata. Both achieved good performance in the retrieval task. A more general11336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370system that creates many quantitative measurements of the brain includingshape features is FreeSurfer (Fischl, 2012).In order to achieve better retrieval performance, many researchers employmultiple hand-crafted features and combine them to represent each image.For example, Song et al. (Song et al., 2012) employed HOG and LBP featuresfor retrieval and to recognize lung lesions. In general, combining multiple fea-tures (e.g., local and holistic features, common and specific features) obtainsbetter performance compared with single feature systems (Lisin et al., 2005;Zhang et al., 2016a). Many groups in the ImageCLEF medical retrieval taskshave adopted this strategy (Simpson et al., 2012). However, when dealingwith massive amounts of medical images, the combined features are often toolarge for scalable retrieval and may adversely affect the retrieval efficiency.Although a variety of features has been discussed above, for the medical re-trieval problem, there are no universal features that are suitable for all kindsof medical images. This is the case, as medical images are generated bydifferent imaging techniques and tissues/organs usually have specific colors,textures and shapes. Even for the same tissue/organ, features may visu-ally differ under multiple dimensions and modalities (Kumar et al., 2013).Therefore, employing suitable hand-crafted features for a given kind of imagedata is an important and challenging step during medical retrieval. Featureselection can also be a step to create a subset of the features for a specifictask.Despite hand-crafted features having achieved many good results in medi-cal image retrieval, they have shortcomings when tackling large-scale medicaldata:1. hand-crafted features need expert knowledge but expert knowledge usu-ally does not work well when the dataset is large as there may be out-liers and cases not covered by standardized rules;2. feature extraction using hand-crafted methods is time-consuming andcomputationally expensive, especially when dealing with massive amountsof images;3. many hand-crafted methods are only designed for specific medical dataand can not be extended to other domains.Accordingly, more automatic, efficient and extensible feature representationmethods are required for the large-scale medical retrieval.12Figure 4: A general framework of convolutional neural networks.3713723733743753763773783793803813823833843853863873883893903913923933943953963.2. Learned FeaturesIn recent years, deep learning has become a hot topic and has achievedvery good results in feature representation, image classification, retrieval,detection and other related fields. Compared with hand-crafted methodsusing domain expert knowledge, deep learning requires only a set of train-ing data that allows to discover the feature representations in a self-taughtmanner (Bengio, 2009; LeCun et al., 2015). For the learned feature rep-resentation, a variety of deep neural networks are designed nonlinearly andhierarchically, i.e., mapping features from fine to abstract with multiple layersof neural networks (e.g., tens to hundreds) and a large number of parameters(e.g., thousands to millions) (Shen et al., 2016). In general, the prevalenceof deep learning mainly benefits from the availability of large training datasets that make it possible to optimize the parameters. Accordingly, due tothe availability of current large-scale medical image databases, deep learningcan also be adopted to solve analytics tasks of medical images. Specifically,both supervised and unsupervised deep neural networks have been exploredfor creating feature representations of medical images.Fig. 4 illustrates a general framework of a supervised deep neural net-work, i.e., a Convolutional Neural Network (CNN) (LeCun et al., 1998).The input images with fixed size are convolved with multiple learned ker-nels using shared weights. Then, the pooling layers down-sample the inputrepresentation nonlinearly and preserve the feature information in each sub-region. Afterwards, the extracted features are weighted and combined in thefully-connected layer, and these features are sent to a pre-defined classifierfor prediction. Finally, by comparing the output class with the image label,the CNN parameters (e.g., kernels, weights, bias) are updated in each iter-13 Input imagesConvolutionPoolingFully ConnectedOutputFeature LearningClassification397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433ation. Recent results, as on the ImageNet Large Scale Visual RecognitionChallenge (ILSVRC) (Russakovsky et al., 2015) have shown the excellentperformance of very deep neural networks, where more convolution, poolingand fully connected layers are employed than before, and more complicatednetwork structures are developed, e.g., AlexNet (Krizhevsky et al., 2012),GoogLeNet (Szegedy et al., 2015), VGG Net (Simonyan and Zisserman, 2014)and ResNets (He et al., 2015).Supervised deep neural networks require a large amount of labeled im-ages to train the parameters in each layer. However, in the medical field,the amount of labeled images is typically limited. Simply training deepneural networks from scratch using small-sized labeled data can easily re-sult in overfitting (Srivastava et al., 2014). Thus, researchers have proposedseveral methods to accommodate medical image analysis with deep neuralnetworks. For example, Bar et al. (Bar et al., 2015) learned features for chestpathology detection using a Decaf pre-trained CNN model (Donahue et al.,2014), and the parameters are trained from non-medical datasets such as Im-ageNet (Deng et al., 2009). In ImageCLEFmed 2016, NovaSearch adoptedCNN models that are trained from scratch using only the provided medi-cal data (Semedo and Magalh˜aes). They employed several techniques (e.g.,Dropout (Srivastava et al., 2014), data augmentation) to deal with the un-balanced and small data sets. According to (Shin et al., 2016), there arethree major techniques that can successfully learn feature representation ofmedical images through CNNs:1. pre-training the CNN model on natural images and fine-tuning on med-ical target images; this technique has been used for lung images (Hof-manninger and Langs, 2015; Li et al., 2014a; Schlegl et al., 2014), brainMRI (Li et al., 2014b), etc.;2. training the CNN model from scratch using only medical images, andemploying several measures to avoid overfitting; this technique has beenused in cardiac CT (Wolterink et al., 2015), on lung nodules (Shenet al., 2015d), etc.;3. using a pre-trained CNN model to extract features, employing thesefeatures as complementary information and combining them with hand-crafted features; these combined features have been used on chest X-rays (Bar et al., 2015), pulmonary peri-fissural nodules (Ciompi et al.,2015), etc.Although supervised deep neural networks have demonstrated excellent per-14434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471formance in feature representation, they require a large amount of manuallylabeled training data. However, unlike the annotation of natural images thatis easy to achieve, the labels of many medical images can only be annotatedIn many cases, theby physicians or domain experts, which is expensive.ground truth labels are simply unavailable, as the exact patterns of someabnormalities are still unidentified or very subjective in nature (e.g., neuronimages, precise tumor regions). To overcome the limitations of supervisedfeature learning, multiple unsupervised deep neural networks have been pro-posed for feature representation (Bengio et al., 2012). Fig. 5 illustrates atypical unsupervised neural network, i.e. an Auto-Encoder (Bourlard andKamp, 1988). Given the input images Xm, it learns the feature represen-tations h(2) by minimizing the reconstruction error between the input andthe output, i.e., Ym ≈ Xm, which indicates the decoder results should ap-proximate the input. Despite the single layer auto-encoder being too shallowto learn features, the representation power improves significantly when sev-eral auto-encoders are stacked to form deep stacked auto-encoders (SAEs).For example, Wu et al. (Wu et al., 2013, 2016) developed an unsupervisedfeature selection method using a convolutional stacked auto-encoder to iden-tify intrinsic deep feature representations in image patches. The methodis demonstrated on 7.0-tesla brain MR images, validating that unsupervisedfeature learning is effective for brain MR registration. Besides this, Shin (Shinet al., 2013) employed stacked auto-encoders for unsupervised feature learn-ing and organ identification in magnetic resonance images, where visual andtemporal hierarchical features are learned to categorize object classes froman unlabeled multimodal DCE-MRI data set (Collins and Padhani, 2004).In addition to auto-encoders,restricted Boltzmann machines (RBM) (Smolen-sky, 1986) can also construct un-supervised deep neural networks,e.g. deep belief networks (Hintonand Salakhutdinov, 2006) and deep(Salakhutdi-Boltzmann machinesnov, 2015). These deep neural net-works are also the common choiceto tackle medical feature represen-tations and other medical analyt-ics tasks. For example, Brosch andTam (Brosch et al., 2013) performedFigure 5: The hierarchical structure of anauto-encoder.15. . .. . .. . .. . .. . .EncoderFeatureDecodermX(1)h(2)hmY472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507manifold learning by reducing thedimensionality of brain images usinga deep belief network that can dis-cover patterns of similarity in groups of images. Cao et al. (Cao et al., 2014)developed a multimodal approach for medical image retrieval that is based ondeep Boltzmann machines. Experimental results demonstrate that the newdeep Boltzmann machine-based multimodal learning model is a promisingsolution for next-generation medical image indexing and retrieval systems.For large-scale medical image analytics, learned feature representationsare a clear trend, since more and more images are available to train thedeep neural networks. However, the usage of deep learning for medical im-age retrieval is not frequent. One reason is that previously most medicalimage retrieval tasks only had to tackle small-sized data sets (e.g., hundredsto thousands of images at the most), which does not allow the training ofdeep neural networks. The other reason is that for some specific medical im-ages the hand-crafted features designed by domain experts can achieve verygood performance when the data sets are not too large (e.g., the holisticfeatures of histopathological images (Basavanhally et al., 2010)). Due to themulti-modality, complexity (e.g., diverse medical imaging techniques, com-plex structures and morphology of tissues/organs) and also quickly changingimage acquisition devices, the specified hand-crafted features are still usefulin many medical image retrieval scenarios. Additionally, the deep-learningbased methods are capable to learn different types of features compared withhand-crafted methods. Thus the learned features also play a critical rolein the feature representation of medical images, particularly when the datasets are large. In the ImageCLEF Challenges (Garc´ıa Seco de Herrera et al.,2016), many groups employed both learned features and hand-crafted fea-tures to represent medical images. Then, these features are fused for moreaccurate retrieval and classification results.4. Feature Indexing and SearchAfter feature extraction, each image is represented by a feature vec-tor. The medical image retrieval problem can now be treated as a nearest-neighbor search among these feature vectors, i.e., computing and rankingthe distance between the query image(s) or volume(s) and all images in thedatabases. However, when handling large-scale databases, exhaustive searchamong long feature vectors is time-consuming. Sequentially computing the16Figure 6: A framework for vocabulary tree based image retrieval.508509510511512513514515516517518519520521522523524525526527528529530531532533distance of millions of high-dimensional feature vectors is unfeasible. In thissection, we review recent advances that can efficiently and accurately tacklefeature indexing in large-scale medical retrieval.4.1. Vocabulary TreeThe vocabulary tree was first proposed by Nist´er and Stew´enius (Nisterand Stewenius, 2006). It is widely used for scalable image retrieval (Wanget al., 2011b; Zhang et al., 2015b). It builds a tree-structure to acceleratesimilarity indexing. Compared with traditional methods based on exhaus-tive search of image features, vocabulary tree based methods employ a hi-erarchical tree and inverted files that can significantly improve the retrievalefficiency. Fig. 6 presents the framework of vocabulary tree based imageretrieval. The framework can be divided into two phases, i.e., the trainingphase (offline) and the query phase (online). The training phase builds theindexing model (hierarchical tree-structure) from given image sets and thequery phase returns images that are similar to the query image.Training Phase: For a set of training data, vocabulary tree methodsfirst detect key points in each image (denoted as the cyan circles in Fig. 6).The key points can be defined as corners with scale and rotation invariance,as well as interest points specified by domain experts. Subsequently, thesekey points are represented by local feature vectors (e.g., SIFT (Lowe, 2004)),and the descriptors from all training images are collected for hierarchical k-means clustering. Specifically, instead of defining k as the final number ofclusters, k is defined as the number of children centers in each cluster. AfterL recursive clustering, a tree-structure of depth L and branch factor k isbuilt, where each tree node (also referred to as the visual word) correspondsto a cluster center. Each leaf node includes several key points that are close17Training ImagesHierarchical ClusteringVocabulary Tree...Score RankingRetrieval ResultsQuery ImageTraining PhaseQuery Phase534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571to each other visually. Accordingly, all images in the database are added toinverted files attached to the leaf nodes with respect to their correspondingkey points. Afterwards, the vocabulary tree-structure and the inverted fileare used for the indexing of the images.Query Phase: Given a query image q, its key points are extracted andset as the input in the vocabulary tree. By comparing with nodes in each hi-erarchy, each key point can reach a leaf node attached to an inverted file. Aseach inverted file records images relevant to the leaf node, the similarity scorescan be computed between q and the images in corresponding inverted files.Normally, the term frequency-inverse document frequency (TF-IDF) (Saltonand Buckley, 1988) is adopted as the similarity score to balance the im-portance of a visual word to an image in a collection. By ranking all thesimilarity scores in descending order, the top ranked images can be consid-ered as the retrieval results. Unlike previous methods simply comparing thesimilarity of all the key points between two images, vocabulary tree methodsconstruct the hierarchical tree-structure and index similar images using theinverted files. For each key point vector, only a total of kL dot productsare needed, which is very efficient if k is not large. More importantly, theinverted file strategy can significantly improve the indexing process since itdoes not need to traverse the whole image database.Vocabulary trees and its variants have been applied for large-scale med-ical image retrieval. They do not only improve the computational efficiencybut are also often more accurate compared with traditional retrieval methods.For example, Jiang et al. (Jiang et al., 2015a,c) proposed an adaptive weight-ing strategy in the vocabulary tree based framework to tackle mammogramimage retrieval. As the features with high frequencies in a mammogram areless informative than those with low frequencies, to avoid overcounting, theyincorporate mammogram-specific node frequencies into the IDF scheme todown-weight the high-frequency features. The adaptive weighting techniqueis very effective to retrieve these specific images, i.e., mammographic masses.Wang et al. (Wang et al., 2015) designed a discriminative and generativevocabulary tree for the authentication and recognition of finger vein images.This method considers both the discriminative appearance of local imagepatches and their generative spatial layout. The training process remains thesame as building a conventional vocabulary tree, while the prediction processuses a proposed point set matching method to support non-parametric patchlayout matching. This joint discriminative and generative model can achievegood performance in finger vein images, since the employed vocabulary tree18572573574575576577578579580581582583584585586587588589590591592593594595596597598599600model can retain the efficiency for the whole system. More importantly, thepoint set matching strategy considers the geometrical layout of local imagepatches, which is more accurate compared with previous vocabulary treebased methods that only consider the description of local key points.By changing the similarity indexing strategy, vocabulary tree based meth-ods have achieved efficient retrieval in large-scale databases. As these kindsof methods directly employ local feature descriptors instead of the globalfeatures, it can be applied to most medical images, including both 2D and3D images where local key points can be detected and described. However,vocabulary tree based methods also have several limitations. For example,simply using local features is not enough to represent and discriminate somespecific medical types of images, e.g., for some lung images, the global shapeshould be considered during retrieval.In addition, the training phase inbuilding the hierarchical vocabulary tree is usually time-consuming, espe-cially when tackling very large image databases (search on a database withmillions of images). In practical applications, to achieve good results, vo-cabulary tree based methods also rely heavily on parameter tuning, i.e., thenumber of each cluster center k, total levels of the hierarchical tree L. Thus,more efficient and accurate methods need to be developed for large-scalemedical image retrieval.4.2. HashingIn recent years, hashing methods have been intensively investigated inthe machine learning and computer vision fields for indexing big data (Wanget al., 2016). Instead of directly searching nearest neighbors from an originaldata set, hashing methods first compress the original data into short binarycodes (e.g., tens to hundreds of bits) based on the defined hashing functions.Then, the nearest-neighbor search is more efficient by computing the similar-ity distances in binary Hamming space rather than in the high-dimensionalfeature space.6014.2.1. Hashing FrameworksFig. 7 presents the framework of hashing-based image retrieval. Assum-ing we have n medical images in the database, after feature representa-tion these n images are represented by d dimensional feature vectors, i.e.,X = {x1, x2, . . . , xn} ⊂ Rd×n (denoted as the blue points in Fig. 7). For theimage xi ⊂ Rd×1, its feature space can be split by a set of hashing functionsH = {h1, h2, . . . hK} ⊂ Rd×K, and each hashing function encodes xi into one19Figure 7: The framework of hashing-based image retrieval.bit of binary code hk(xi). Therefore, the corresponding K bits of binary codeof xi can be denoted as:yi = H(xi) = {h1(xi), h2(xi), . . . , hK(xi)}(1)In practice, for computational convenience, the above hashing functions areusually substituted by the projected matrix w ⊂ Rd×K and the interceptvector b ⊂ RK×1:yi = sgn (cid:0)f (wTxi + b)(cid:1)(2)602603604605606607608609610611612613614615616617618where f (·) is a pre-specified function that can be linear or nonlinear. Then,all images in the database are represented by the mapped binary codes. Thequery image xq (denoted as the red point in Fig. 7) can also be mapped intobinary codes through Eq. 2. Subsequently, the similarity search betweenthe query and each image in the database is transformed as the Hammingdistance ranking of their corresponding binary codes, which is very fast. Thekey question of hashing methods is how to obtain good hashing functionsthat can not only split the feature space via binary encoding but also keepsimilarities and diversity among the original data.4.2.2. Categories of Hashing MethodsThe methods to compute hashing functions can be roughly divided intotwo categories, i.e., data-independent and data-dependent. Data-independentmethods usually design generalized hashing functions that can compact anygiven data set into binary codes. Locality-Sensitive Hashing (LSH) and itsvariants are the most popular data-independent methods (Gionis et al., 1999;Kulis et al., 2009; Raginsky and Lazebnik, 2009). LSH-based methods com-pute hashing functions via maximizing the probability of collision for similar203h2h1h4h1x2xnx00101...01001100...10010110...110...Hashing EncodingBinary Codes10100...001qxIndexingFeature RepresentationBiomedical Images...Retrieved Images619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656items, which can keep the originally nearby data points mapping into thesame bit with high probability. However, this type of method often needslong binary codes and many hashing functions to ensure the desired retrievalprecision, which dramatically increases the storage costs and the query time.More importantly, as these hashing functions are designed independentlyfrom the training data sets, it is hard to ensure the retrieval performance forany given data set.Another category are the data-dependent methods (also called learning tohash methods) that learn the hashing functions from a given training data set.In general, compared with data-independent methods, data-dependent meth-ods can achieve comparable or even better retrieval accuracy with shorterbinary codes. Currently, many learning-based hashing methods have beenapplied for large-scale medical image retrieval, including but not limited to,Iterative Quantization (ITQ) (Gong et al., 2013), Kernel-Based SupervisedHashing (KSH) (Liu et al., 2012), Anchor Graph Hashing (AGH) (Liu et al.,2011), Asymmetric Inner-product Binary Coding (AIBC) (Shen et al., 2015a)and others. Accordingly, the taxonomy of data-dependent hashing methodscan be defined in multiple viewpoints. For example, based on whether thetraining data sets have labels or not, hashing methods can be divided intosupervised, unsupervised and semi-supervised methods. Supervised methodsemploy advanced machine learning techniques such as kernel learning, metriclearning, and deep learning to compute the hashing functions from labeledtraining data. Many supervised hashing methods have achieved good per-formance since they can shorten the semantic gap between the compactedbinary codes and the image labels (Fan, 2013; Gordo et al., 2014; Norouziet al., 2012; Shen et al., 2015b). Without label information, unsupervisedmethods explore the properties of training data sets such as distributionsand manifold structures to design effective hashing functions. Representa-tive methods include spectral hashing (Weiss et al., 2009), graph hashing (Liuet al., 2014b), manifold hashing (Shen et al., 2013), etc. Additionally, semi-supervised methods design hashing functions using both labeled and unla-beled data. These kinds of methods can improve the binary encoding per-formance by leveraging semantic similarity with limited image labels whileremaining robust to overfitting (Jain et al., 2009, 2008; Wang et al., 2012).Another taxonomy of data-dependent methods is based on the form of thehashing functions, i.e., linear and nonlinear. Linear hashing functions sep-arate and map the original feature space with simple projections (as shownin Fig. 7, {h1, h2, . . . hK}). They are computationally efficient and easy to21MethodPCA Hashing(Gong and Lazebnik, 2011; Yu et al., 2013)Kernelized Hashing(Liu et al., 2012)Composite Hashing(Gong et al., 2013; Liu et al., 2011)Hashing Forest(Conjeti et al., 2016a)MIPS Binary Coding(Shen et al., 2015a)Deep Autoencoder(Sze-To et al., 2016; Vincent et al., 2010)TaxonomyUnsupervisedLinearSupervisedNonlinearUnsupervisedNonlinearUnsupervisedLinearUnsupervisedNonlinearUnsupervisedNonlinearApplicationMulti-modality images (Yu et al., 2013)Brest histopathology (Zhang et al., 2015c)Cell-level histopathology (Zhang et al., 2015d)Digital mammogram (Liu et al., 2016b)Neuron morphology(Mesbah et al., 2015; Yu and Yuan, 2014)Neuron morphology (Li et al., 2017a)X-ray images (Sze-To et al., 2016)Table 2: Existing hashing based large-scale medical image retrieval methods with theirtaxonomies and applications657658659660661662663664665666667668669670671672673674675676677678679680optimize (Gong et al., 2012; He et al., 2012; Trzcinski and Lepetit, 2012).However, linear hashing functions can not handle the situation when thedifference among image data are subtle and linearly inseparable. Thus, non-linear hashing was developed to override such limitations. Such methodslearn hashing functions based on kernel matrixes or manifold structures andcan embed the intrinsic structure in a high-dimensional space and nonlin-early map feature vectors into binary codes (Kulis and Grauman, 2012; Liuet al., 2012; Shen et al., 2015c).4.2.3. Methodology ReviewTable. 2 summarizes the existing hashing-based medical retrieval meth-ods, as well as their corresponding taxonomies and applications. Accordingto Table. 2, both supervised and unsupervised, linear and nonlinear hashingmethods have been developed for medical retrieval. In this subsection, webriefly review the above hashing methods and also discuss their advantagesand drawbacks.PCA Hashing (Yu et al., 2013): it first linearly projects raw image fea-tures into uncorrelated dimensions via Principal Component Analysis (PCA),where each new feature dimension is orthogonal to each other. Then, it learnsthe hashing function (i.e. a rotation matrix) by minimizing the binarizationerror between the new feature matrix and the corresponding binarized fea-ture matrix (Gong and Lazebnik, 2011). PCA Hashing demonstrates highcomputational efficiency and comparable retrieval precision compared withtraditional feature-based nearest-neighbor search. However, since both PCAprojection and hashing function optimization are linear, PCA hashing can-22681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718not achieve good performance when tackling medical images that are complex(e.g., image differences are subtle, the feature space is not linearly separable).Kernelized Hashing (Zhang et al., 2015c): for most medical images,linear inseparability is a critical constraint that needs to be taken into accountduring large-scale retrieval. To tackle this challenge, Kernelized Hashing con-siders the hashing function with kernels, since kernel methods can map thefeature vectors into a high-dimensional space and make the linearly insepara-ble images easy to differentiate. Accordingly, the learned binary codes fromkernelized hashing are also able to differentiate complex medical images. Inaddition, Kernelized Hashing designs a supervised framework by collaborat-ing kernel functions with medical labels (e.g., labeling the histopathologicalimage with benign or malignant). The supervised information significantlyboosts the retrieval performance since it can bridge the semantic gap betweenlow-level features and high-level clinical analytics.Composite Hashing (Liu et al., 2016b): this algorithm can generatemore effective hash codes by integrating global features (e.g. GIST (Oliva andTorralba, 2001)) and local features (e.g. SIFT (Lowe, 2004)) with differentdistance metrics. In general, single types of features can not comprehensivelyrepresent a medical image. On the other side, simply combining multiplefeatures may also fail to achieve accurate image retrieval, since each typeof feature has its specific meaning and representation. Thus, CompositeHashing improves the Anchor Graph with multiple features and fuses themby distance metric and local manifold. Then, it learns the hashing functionusing iterative quantization.Hashing Forests (Conjeti et al., 2016a): this approach learns binarycodes by training independent hashing trees. For the internal node in eachtree, locality preserving projections are employed to project data into a la-tent subspace, where separability between dissimilar points is enhanced. Foreach input image, each trained tree generates several bits of binary codes,and the combination of these binary codes in the forest is used to representthe input image. Additionally, it employs an inverse-lookup search schemeto improve the efficiency of similarity comparisons. Hashing Forests cangenerate any given length of binary codes, which is particularly suitable forlow-dimensional image features.MIPS Binary Coding (Li et al., 2017a): as demonstrated in (Liu et al.,2012; Shen et al., 2015a), the Hamming distance and the inner code producthave a one-to-one correspondence. Thus, unlike the above methods basedon the Hamming distance metric, MIPS (Maximum Inner Product Search)23719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753Binary Coding introduces a new objective based on the inner code product,which is more likely to learn non-linear hashing functions. Specifically, byadopting an alternative iteration strategy, it learns two asymmetric hashingfunctions for the image database and the query image respectively. Thisstrategy can make the inner product based objective easy to optimize. It alsopromotes the hashing functions to map binary codes into a high-dimensionalnon-linear space.Deep Autoencoders (Sze-To et al., 2016): this algorithm employs deeparchitectures to hash medical images into binary codes without class labels.Specifically, it uses a specific unsupervised deep architecture, namely deep de-noising autoencoders (DDA) (Vincent et al., 2010) to enhance feature learn-ing and binary coding with four steps:image pre-processing, unsupervisedlayer-by-layer training, unsupervised fine-tuning with dropout, and decoderremoval. Finally, a threshold (> 0.5) is applied on the real-valued featurevectors to obtain binary codes. Deep Autoencoders learn binary codes with-out using any supervised information, which is suitable for medical imageswhere labels are hard to obtain.When using hashing methods to tackle large-scale medical image retrievalproblems, we should not only focus on the hashing methods itself but alsoneed to consider their possible adaptations for different medical image datasets. When the annotation of all medical images in data sets are available, su-pervised hashing methods are more suitable and are generally more accuratethan unsupervised and semi-supervised hashing. For example, Kernel-BasedSupervised Hashing (KSH) (Liu et al., 2012), Supervised Discrete Hashing(SDH) (Shen et al., 2015b), Deep Supervised Hashing (DSH) (Liu et al.,2016a) can achieve excellent performance in many public data sets. However,in many cases when the medical image annatations are not easy to acquire,semi-supervised/unsupervised hashing is a more reasonable choice (e.g., Dis-crete Graph Hashing (DGH) (Liu et al., 2014b), MIPS (Shen et al., 2015a),Semi-Supervised Hashing (SSH) (Wang et al., 2012)). In addition, for somemedical images that are not easy to differentiate, non-linear hashing meth-ods can usually achieve much better retrieval performance, such as InductiveManifold-Hashing (IMH) (Shen et al., 2013), AGH (Liu et al., 2011), de-spite training non-linear hashing functions being more time-consuming thantraining linear hashing functions.247547557567577587597607617627637647657667677687697707717727737747757767777787797807817827837847857867877887897904.3. Other MethodsBesides the vocabulary tree and hashing, there are many other methodsthat have been designed to tackle the feature indexing of large-scale medicalimage databases. These methods can be either accelerating the similaritysearch or improving the retrieval accuracy. We briefly introduce and discussthese methods.4.3.1. Feature CompressionIndexing in large medical databases is usually very time-consuming, es-pecially when the images are represented by high dimensional features. Toaccelerate the indexing process, one kind of methods is feature compression,which can compress long image features into a smaller size. Hashing belongsto the category of feature compression that is discussed above. In addition tohashing, many other compression methods have been employed for efficientmedical image retrieval.Principal components analysis (PCA) is one of the most popular methodfor feature compression. After feature extraction, medical images can berepresented by single or multiple feature vectors that have high dimension.Many medical image retrieval methods have employed PCA to reduce thefeature dimensionality. For example, Tian et al. (Tian et al., 2008) first pre-sented a global and local texture feature combination for the description ofmedical images. Then, they adopted PCA to reduce the dimension of thecombined features.In the analytics of histopathological images, Sertel etal. (Sertel et al., 2009) introduced a novel color-texture analysis approachthat combines a model-based intermediate representation with low level tex-ture features. Then, PCA and LDA (linear discriminant analysis (Fukunaga,2013)) are employed for feature dimensionality reduction. PCA-based med-ical image retrieval can significantly reduce the feature dimensionality andusually demonstrates comparable performance with the methods using theoriginal features.In addition to PCA, multiple methods have been proposed for medicalfeature compression in recent years. In (Foncubierta-Rodr´ıguez et al., 2013),Foncubierta-Rodriguez et al. presented a medical image retrieval method us-ing a bag of meaningful visual words. As visual vocabularies are often redun-dant, over-complete and noisy, they presented a pruning technique based onprobabilistic latent semantic analysis (PLSA) (Hofmann, 2001). The PLASpruning can enormously reduce the feature dimension when describing a med-ical image data set with no significant effect on accuracy. More recently, Lan25791792793794795796797798799800801802803804805806807808809810811812813814815816817818819820821822823824825826827and Zhou (Lan and Zhou, 2016) proposed a simple yet discriminant feature,called histogram of compressed scattering coefficients (HCSCs) for medicalimage retrieval. They first performed a particular variation of deep convo-lutional networks, i.e., the scattering transform, to yield high dimensionalfeatures. Then a compression operation is carried out on the obtained coef-ficients for a dimensionality reduction.4.3.2. Re-rankingAfter the similarity indexing through feature compression and other large-scale methods, a set of top ranked medical images can be efficiently computedbased on a distance measure. However, these retrieved images may not alwayscorrespond to what a human would want and the retrieval precision can varystrongly using different features. Therefore, re-ranking of the coarse resultsis expected to further improve the retrieval performance for more accurateretrieval. Particularly, re-ranking methods can reorder the initially retrievedimages to move the most relevant images to the top or optimise diversiy inthe top results.In recent years, multiple methods have been proposed for re-ranking indifferent image retrieval applications. In the medical domain, based on theinformation employed for re-ranking, the re-ranking methods can be roughlydivided into three categories, i.e., textual-visual based, multi-feature basedand user-feedback based. In the following, we briefly review relevant articlesabout the three categories respectively:1. Textual-visual based: these kinds of methods first retrieve relevantmedical images through textual indexing, then the initial results arere-ranked by considering the visual similarity. Textual-visual based re-ranking was adopted by many groups in the ImageCLEF medical imageretrieval tasks. For example, Radhouani et al. (Radhouani et al., 2009)introduced their work at ImageCLEF 2009. They first leveraged textualdata to search relevant images in three domain dimensions, anatomy,pathology and modality. Then, they employ the visual data to re-rank the document lists based on the extracted features, including acolor and intensity histogram, gray-level co-occurrence matrices andother features. Besides this, Depeursinge and M¨uller (Depeursinge andM¨uller, 2010) described several fusion techniques for combining textualand visual information that were used in ImageCLEF.2. Multi-feature based: this kind of method first computes the retrievalresults from multiple kinds of features, then the final results are ob-26828829830831832833834835836837838839840841842843844845846847848849850851852853854855856857858859860861862863tained by fusing and re-ranking the above retrieved images. Recently,Zhang et al. (Zhang et al., 2016a) presented a method for histopathol-ogy image analysis by re-ranking the results from multiple features.Specifically, after obtaining several top ranked relevant images frommultiple kinds of features, they employed a graph-based query-specificfusion approach where multiple retrieval results are integrated and re-ordered based on a fused graph (Zhang et al., 2015b). In general, suchre-ranking methods can significantly improve the retrieval performancesince they consider the image similarity and discrimination from severalviewpoints using multiple features, e.g., local and holistic features.3. User-feedback based: after receiving the initial results, this kind ofmethod re-ranks the retrieved images based on relevance feedback fromusers. The relevance feedback can specify which image is relevant/irrelevant.Agarwal and Mostafa (Agarwal and Mostafa, 2011) employed the user-feedback based re-ranking for the Alzheimer’s disease detection. Theyfirst described a content-based image retrieval system, i.e., ViewFinderMedicine (vfM), to combine visual and textual features for initial in-dexing. Then the retrieval system employed the user-provided feed-back to perform re-ranking, including inter-session and intra-session re-ranking. This re-ranking process improved the system precision from0.8 to 0.89. The importance of negative feedback in this process ishighlighted in (Muller et al., 2000).In most cases, re-ranking methods are only required to consider the topranked initial retrieval results, e.g., most truly relevant images are includedin the top-K results, and K is much smaller than the number of images in thewhole database. Therefore, re-ranking can be very efficient as it only needsto process a few images. More importantly, by considering and comparingthe similarity using multiple information sources, the retrieval precision canbe improved for further exploration and analysis.4.3.3. High-performance ComputingIn addition to the above large-scale methods which belong to the fields ofimage processing, computer vision and machine learning, High-performanceComputing (HPC) also plays an important role in medical image analytics.HPC is the use of parallel processing techniques to execute programs effi-ciently, reliably and quickly. The HPC techniques include parallel comput-ing, distributed computing, cloud computing, etc. that are useful for tackling27864865866867868869870871872873874875876877878879880881882883884885886887888889890891892893894895896897898899large databases. Particularly in the medical field, some large databases areusually stored in different locations and they are essential to be processedbased on parallel systems.Recently, HPC techniques have been widely employed for the large-scalemedical retrieval. Foran et al. (Foran et al., 2011) proposed a software sys-tem based on parallel and distributed computing, namely ImageMiner, toefficiently retrieve and analyze the expression patterns of tissue microarrays(TMAs). The ImageMiner system embedded a data analysis component forefficient retrieval, i.e., DataCutter (Kumar et al., 2006), which the data pro-cessing pipeline can be composed as a network of interacting components.Images received by ImageMiner were distributed and processed by the com-putation cluster using a master-slave parallelization scheme. Subsequently,Qi et al. (Qi et al., 2014) investigated large-scale histopathological image re-trieval using the CometCloud (Kim et al., 2011), an automatic cloud frame-work that allows dynamic, on-demand federation of distributed infrastruc-tures. They first formulated the histopathological image retrieval problem asa set of heterogeneous and independent tasks. Then these tasks can be par-allelized and solved using the aggregated computational power of distributedresources. More recently, Markonis et al. (Markonis et al., 2015b) proposedsolutions for the large-scale medical image analysis based on parallel com-puting and algorithm optimization. Specifically, a MapReduce framework isemployed to speed up the medical image analysis in three tasks, i.e., lungtexture segmentation using support vector machines, content-based medicalimage indexing and 3D directional wavelet analysis for solid texture classifi-cation.High-performance computing can well be used to handle large-scale re-trieval tasks, especially for clinical systems, where the parallelized processingcan achieve similarity retrieval in real-time. More importantly, as presentedin Fig. 1, high-performance computing can be adopted in both the feature ex-traction/indexing and retrieval, which can dramatically improve the retrievalefficiency in these time-consuming steps.5. EvaluationAfter receiving similar samples from medical image retrieval systems,evaluating the retrieval performance and the whole retrieval system are alsocritical tasks. Especially for large-scale medical image sets, simply using class28900901902903904905906907908909910911912913914915916917918919920labels is usually not adequate to evaluate the retrieval performance in fine-grained levels. In the past decades, challenges and tasks such as ImageCLEF,VISCERAL, etc. have made great efforts for the evaluation of medical im-age retrieval (Kalpathy-Cramer et al., 2015; Langs et al., 2012). This sectionreviews related work of evaluation protocols which are relevant to medicalimage retrieval, including evaluation measures, criteria, and public medicalimage data sets.5.1. Evaluation MeasuresWe first introduce the evaluation measures for medical image retrievalthat can provide a quantitative analysis, comparison, and validation of dif-ferent retrieval methods. In general, the evaluation measures in large-scalemedical image retrieval are similar with the measures in generic informationretrieval, i.e., evaluating the precision, recall, efficiency and several othermeasures.Precision: retrieval precision is the main indicator for performance eval-uation, which can be denoted as the fraction of the images retrieved that arerelevant to the query image:precision =|{relevant images} ∩ {retrieved images}||{retrieved images}|(3)In information retrieval, precision can evaluate the capability of a methodfor searching similar or relevant samples. It has also been widely used for theevaluation of medical image retrieval methods, especially for some medicalanalytical tasks where the image used as query can be better interpretedwith similar/relevant images (Li et al., 2017b; Zhang et al., 2015c,d). Thisis similar to asking a colleague for help or searching similar images/patternsin books.Besides precision, mean average precision (MAP) is most commonly usedfor the evaluation of retrieval methods and for the comparison of search inlarge-scale medical image sets. MAP is relatively stable and include aspectsof precision and recall, as it averages over positions of all relevant items. Itis defined as the mean of the average precision scores of all relavnt items ofa query averaged over all queries. The MAP can be formulated as:M AP =1|M |M(cid:88)m=11|K|K(cid:88)k=129precision(Qm,k)(4)921922923924925926927928929930931932933934where M is the number of query images (i.e., testing data), K indicatesthe top-K ranked relevant images for each query image, and Qm,k denotesthe top-k retrieval precision of the mth query image. For large-scale retrievalmethods, the MAP can evaluate their performance with massive testing data(e.g., hundreds to thousands of query images), and thus alleviate the biasduring precision evaluation.Recall:in image retrieval, recall is the fraction of relevant retrievedimages with all relevant images in databases, i.e.:recall =|{relevant images} ∩ {retrieved images}||{all relevant images}|(5)Recall reflects the sensitivity of a retrieval system, i.e., whether it can com-pletely find all relevant samples in top-K ranked results, keeping K as smallas possible. Thus, for medical retrieval tasks that need to find all relevantsamples for analysis (such as a systematic review), recall is a critical evalu-ation criterion. Normally, recall is associated with precision, i.e., precision-recall curve, for the evaluation and comparison of different retrieval methodswith a global view on the performance (Davis and Goadrich, 2006; M¨ulleret al., 2001).Efficiency: as directly indexing massive images with high dimensionalfeatures are usually very time-consuming, one important evaluation indicatorfor large-scale retrieval is efficiency. Currently, in most large-scale retrievalcases, efficiency is denoted as the time for the feature indexing phase, i.e.,given a query image (or its features), the time for returning a set of relevantimages after searching in large-scale databases. For medical image retrievalwith many testing images, their accumulated and average run time are thecommonly used efficiency measures, where the average run time can be for-mulated as:AvgT ime =1MM(cid:88)m=1tm,K(6)935936937938939940tm,K indicates the time cost of retrieving K relevant images for the mthquery image. The average/accumulated run time has been widely adoptedfor the evaluation, comparison and validation of large-scale medical imageretrieval (Jiang et al., 2016a, 2015c; Zhang et al., 2015c,d). Still, run timesneed to be put in relationship to hardware resources available and are thusnot always easy to interpret. Sometimes the run time for the offline parts30941942943944945946947948949950951952953954955956957958959960961962963964965966967968969970971972973974975976977(data indexation) and the online parts (interactive search) are separatelycompared.Additionally, there are several other commonly employed measures formedical image retrieval evaluation. For example, the precision after the firstNR images are retrieved (i.e., P (NR)), recall at 0.5 precision, rank first rele-vant, etc.). These measures were discussed in previous articles (M¨uller et al.,2001; Muller et al., 2004).5.2. Evaluation CriteriaIn addition to evaluation measures, the criteria of deciding similarity/relevanceare also important and challenging tasks in large-scale medical image re-trieval. Here, we introduce two kinds of evaluation criteria: annotation-basedand user-based, which are the commonly employed criteria in medical imageretrieval.Annotation-based Criteria: when class labels of medical images areavailable, their annotations are a commonly used evaluation criterion. As theclass labels of all medical images in the database are provided, the similar orrelevant images can be determined quickly by comparing their class labels.Thus, given testing images, the retrieval precision and recall can be mea-sured by sequentially comparing the labels between each test image and theretrieved images. Currently, several large-scale medical image retrieval casesadopted annotation-based criteria for performance evaluation. For example,Zhang et al. (Zhang et al., 2015d) evaluated the large-scale histopatholog-ical image retrieval through the class label of two type lung cancers (i.e.,adenocarcinoma and squamous carcinoma) for each image. The annotation-based evaluation criteria are only suitable for the cases that image classes areidentified and the similarity of images are simply determined by class labels.User-based Criteria: despite the annotation-based criteria being a sim-ple way for retrieval evaluation, it may not suitable in many practical cases oflarge-scale medical image retrieval. One reason is that the annotation of med-ical images is usually hard to obtain. Some medical images are still classifiedand do not have unified classification rules. Moreover, annotating every med-ical image in large databases is extremely labor expensive,time-consuming,and sometimes impossible. Another reason is the similarity/relevance mea-sure. In large-scale medical image retrieval, one query image may have thou-sands of images with the same label. For some analytical tasks, simply usingclass labels is not adequate to identify relevant images.319789799809819829839849859869879889899909919929939949959969979989991000100110021003100410051006100710081009101010111012Compared with annotation-based criteria, users or domain experts canprovide more fine-grained retrieval evaluations in the form of relevance judge-ments for specific tasks. Many medical image retrieval systems have em-ployed users for the performance evaluation. In general, users can observethe retrieved images and assign them with different relevance levels duringevaluation. For example, the medical ImageCLEF challenges used three lev-els of relevance, i.e., relevant, partly-relevant, and non-relevant (Kalpathy-Cramer et al., 2011; M¨uller et al., 2012, 2009). These relevance judgmentswere employed for the retrieval performance evaluation of the database with300, 000 medical images. Besides ImageCLEF challenges, considering neu-rons is usually hard to classify and identify, Wan et al. (Wan et al., 2015)asked two users for the visual comparison of morphological neuron retrievalresults. In medical image retrieval, user-based criteria rely on user’s domainknowledge and may be partly subjective based on the user’s background.Thus, the retrieval results are usually judged by two or more users for morereliable evaluation.The evaluation of system design also plays an important role in medi-cal image retrieval, especially for the retrieval systems where users are in-teractively involved. Markonis et al. (Markonis et al., 2015a) reported theuser-orientied evaluation of a text- and content-based medical image retrievalsystem. In total, 16 radiologists participated in the user tests with a work-ing image retrieval system in an iterative manner. Such analyses in clinicalpractice are really needed to advance the practical use of image retrieval inhospitals5.3. Public DatasetsWith the increasing availability of digital imaging techniques, a largenumber of medical images are generated and well organized in many repos-itories. Some of the repositories are publicly available for users and re-searchers. The medical image repositories usually include thousands to mil-lions of images. Images are collected for different purposes, such as cancergrading/staging and treatment planning. We briefly introduce some of thepublic data sets that are widely used for medical image retrieval:• ImageCLEF (ImageCLEF): ImageCLEF provides an evaluation forumfor the cross-language annotation and retrieval of images. ImageCLEFhas held 14 years of medical image retrieval challenges, with the number32101310141015101610171018101910201021102210231024102510261027102810291030103110321033103410351036103710381039104010411042104310441045of images in the dataset having increased from 6, 000 to 300, 000 (Kalpathy-Cramer et al., 2015). The datasets in ImageCLEF include multiplemodalities of medical images, e.g., radiology, microscopy and also gen-eral photography.• DDSM (of South Florida): The digital database for screening mammog-raphy (DDSM) is a public mammogram database. It includes 2, 604breast cases and every case consists of four views, with two cranio-caudal views and two mediolateral oblique views. The mammographicmasses have different shapes, sizes, margins and breast densities aswell as the patient race and age, which provide rich information fordiagnosis.• MedPix (of Medicine): MedPix is a fully web-enabled cross-platformdatabase, integrating images and text information. This medical imagedatabase includes over 53, 000 indexed and curated images, from morethan 13, 000 patients. The merit of this database is that it recordsdetailed descriptions of patients and their corresponding diagnosis.• TCGA (Institute, a): The Cancer Genome Atlas (TCGA) collects ahuge amount of cancer images (currently around 10, 000, 000 imagesand increasing quickly) from multiple projects funded by National Can-cer Institute. It records many types of cancer images, including but notlimited to, brain, esophageal, lung, thyroid and rectum. All TCGAdata reside in the Genomic Data Commons (Institute, b).• TCIA (TCIA): The Cancer Imaging Archive (TCIA) is organized intocollections with a variety of cancer types and/or anatomical areas. Sim-ilar to TCGA, it collects cancer images from many projects and insti-tutes. The cancer types include breast, prostate, liver, lung, brain, etc.and the image modalities include CT, MR, PET and others.• VISCERAL (VISCERAL): VISCERAL is the abbreviation for VisualConcept Extraction Challenge in Radiology, which provides a bench-mark for the retrieval in the medical domain. This dataset consists2, 311 medical 3D volumes originating from various modalities (CT,MRT1, MRT2 with and without contrast agent) and each volume con-sists 200 − 2000 images (slices). The VISCERAL project has organized33Public data setsImageCLEF (ImageCLEF)DDSM (of South Florida)MedPix (of Medicine)TCGA (Institute, a)TCIA (TCIA)Retinopathy (EyePACS)DREAM (Bionetworks)VISCERAL (VISCERAL)LIDC-IDRI (Armato III et al., 2011)ADNI (of Southern California)NBIA (NBIA)CAMELYON 17 (, DIAG)PubMed Center (NCBI)NLST (Institute, c)Number of images or or size Image categoryMulti-modalities300,000Mammogram10,480, 231GBMulti-modalities53,000Cancer Images, Multi-modalities470TBCancer Images, Multi-modalities10,000,000, 3TBRetinal Photographs35,000, 82GBScreening Mammograms640,0003D CT, MRI volume2,300Lung CT, DX, and CR240,000, 124GBAlzheimer’s MR, PET, etcUnknownCancer Images, Multi-modalities76,000Whole-slide Histopathological Images1,000, 2TBMulti-modalities4,000,000Lung CT, Pathology Images76,000Table 3: Current publicly available medical image data sets.1046104710481049105010511052several challenges, workshops and provided multiple benchmarks re-lated to large-scale data in medical image analysis and retrieval (Langset al., 2012; M¨uller et al., 2014; Zhang et al., 2015a).In addition to the above data sets, Table. 3 presents a summary of publiclyavailable data sets with many medical images, including number of images,size and categories if available. Due to the fast growth of medical images, weonly provide a small subset of commonly used data sets in Table. 3.10536. Applications1054105510561057105810591060106110621063106410651066After reviewing the above large-scale techniques, we introduce their ap-plications for medical image analytics in this section. Large-scale retrievalmethods have demonstrated impressive improvement on many medical imagetypes, including CT, MRI, X-ray, microscopy and others. In the following, weillustrate their applications in clinical diagnosis, cancer grading, and neuronexploration.6.1. Mammographic Retrieval and SegmentationBreast cancer remains the second leading cause of cancer-related deathamong women (Society, 2013). Early diagnosis based on mammography is awidely adopted approach to improving the chances of recovery, which is recog-nized as a gold standard for breast cancer detection by the American CancerSociety (Society, 2013). However, the detection of masses in a mammogramis a challenging task, as masses have a large variation in shape, margin, and341067106810691070107110721073107410751076107710781079108010811082108310841085108610871088108910901091109210931094109510961097109810991100110111021103size. They are often indistinguishable from surrounding tissue (Cheng et al.,2006; Oliver et al., 2010). For an undetected mammogram, computer-aideddiagnosis (CAD) with content-based image retrieval (CBIR) is an effectivesolution by returning a limited number of the most similar mammograms inthe pre-built image database, where the retrieved mammograms were alreadyannotated with the class labels of mass and normal. Nevertheless, with theever increasing number of mammograms generated and added to the pre-built database, scalable CBIR techniques have become one of the importantproblems for mammogram based breast cancer diagnosis (Langs et al., 2012).Jiang et al. (Jiang et al., 2015c) successfully solved the scalable mammo-gram retrieval problem based on a vocabulary tree with adaptive weighting.For a query with a mammographic region of interest (ROI), it can achieveefficient retrieval in a dataset with 11, 553 ROIs. Specifically, in the experi-ment, this method reported an 88.4% retrieval precision with 500 mass ROIsand 500 normal ROIs as queries. This demonstrates good accuracy com-pared with other methods including NMI (Tourassi et al., 2007), BoW (Andr´eet al., 2012), and VocTree (Nister and Stewenius, 2006). The method alsoachieved highest classification accuracy (90.8%) for whether the query ROIsare masses or normal. Additionally, this method is 3 to 10 times faster thanother methods and the advantage is larger when the size of image databaseincreases.(Jiang et al., 2016b) propose to learn online shape and appearance priorsvia image retrieval, i.e., setting an input mass as the query, its visuallysimilar training masses can be obtained by image retrieval. Then, the querymass can be segmented using the retrieval priors and graph cuts. Extensiveexperiments on a mammography database demonstrate that the method canimprove the segmentation accuracy and outperform several widely used masssegmentation methods.6.2. Cell-Level Histopathological Image AnalysisHistopathological image analysis is widely used for cancer grading. Com-pared to mammography, CT and others, histopathology slides provide morecomprehensive information for diagnosis and the diseases are analyzed bydetecting tissue and cells in lesions (Gurcan et al., 2009). On the other handan invasive biopsy is necessary, which is often tried to be avoided. CBIR sys-tems are commonly employed to analyze histopathological images (Caicedoet al., 2009, 2011; Doyle et al., 2007). In CBIR systems, the returned visuallysimilar images can be used to identify and classify the query images (e.g.,35Figure 8: Examples of hashing-based histopathologicalillustratedin (Zhang et al., 2015c) (query marked in red and retrieved images marked in blue).The first two rows are benign tissue; the last two rows are malignant tissue.image retrieval110411051106110711081109111011111112111311141115111611171118111911201121classifying them as benign or malignant), and further assist pathologists todescribe the tissue samples.Hashing methods were first employed by Zhang et al. (Zhang et al., 2015c,2014) to tackle large histopathological image databases for CBIR. They de-signed a comprehensive CBIR framework to analyze histopathological imagesby leveraging high-dimensional texture features and kernelized hashing withsupervised information.In the experiment, this hashing method demon-strated significant improvement in histopathological image classification andretrieval tasks. Compared to methods such as SVM (Caicedo et al., 2009),Adaboost (Doyle et al., 2012), KNN (Tabesh et al., 2007), and Graph Em-bedding (Basavanhally et al., 2010), its accuracy was 5 to 10 percent higher.The method achieved histopathological retrieval for 700-900 images within0.01 seconds (3121 images in the database), which is 1000 times faster thanthe given baseline. Fig. 8 illustrates four queries (two benign images, twomalignant images) and their corresponding top five retrieval results basedon this hashing-based CBIR framework. Despite the difference between be-nign and malignant images being subtle, the proposed method is effectiveto retrieve images in the same category. The authors extended the CBIR361122112311241125112611271128112911301131113211331134113511361137113811391140114111421143114411451146114711481149115011511152115311541155115611571158system for more accurate diagnosis by examining the cells in histopathologyimages (Zhang et al., 2015d). As each histopathology image usually includesthousands of cells, examining every cell by traditional retrieval methods is al-most impossible when the image databases are large. Thus, a hashing-basedframework is proposed that enables cell-level analysis in real-time with highaccuracy, i.e., indexing 96, 000 cells within 1.68 seconds (the whole databaseincludes 484, 136 cells), and achieving 87.3% accuracy for the classification ofhistopathology lung images (i.e., two types of lung cancers, adenocarcinomaor squamous carcinoma).In histopathological image analysis, it is a common practice to employmultiple features to improve performance. To embed multiple features ina hashing framework, Jiang et al. (Jiang et al., 2015b, 2016a) employedjoint kernel-based supervised hashing (JKSH) for scalable histopathologicalimage analysis, where multiple features are linearly combined by individualkernels (Liu et al., 2014c). Experiments on breast cancer histopathologyimages demonstrate the effectiveness in both retrieval and classification.6.3. Exploration of a Neuron DatabasesAnalyzing single neuron properties, such as cell types, brain regions, func-tions and development stages is usually a fundamental task to understandthe nervous system and brain mechanisms. In general, neuron morphologyplays a major role in determining the neuron’s functional and physiologi-cal properties. Recent approaches in neuroscience (e.g., BigNeuron (big, a))have facilitated the research in neuron morphology. An increasing number ofneurons are reconstructed and added to the public repositories (big, b; Neu-roMorpho). Therefore, given an unknown neuron, it is reasonable to exploreits properties through the morphological retrieval in neuron databases.Conjeti et al. (Conjeti et al., 2016b; Mesbah et al., 2015) developed anadvanced tool for morphological search and retrieval in large-scale neurosci-entific image databases, namely Neuron-Miner. Neuron-Miner first employsquantitative measurements as neuron features, such as soma surface, thenumber of branches and the neuron’s total length. Then, it adopts a novelhashing method, i.e., hashing forests, to compact the features into binarycodes. In the experiment, Neuron-Miner demonstrates the effectiveness inmorphological retrieval with a database including 31, 266 neurons. Given aquery, this tool is able to return several visually similar neurons from thedatabase. The ground truth (using normalized Euclidean distance) showsthat returned neurons are relevant to the query.37Figure 9: Results of morphological neuron retrieval shown in (Li et al., 2017a). For eachneuron on the left (red), the top-5 retrieved neurons on the right (blue) are shown. Thisillustrates the morphological similarity between query neurons and retrieved neurons.11591160116111621163116411651166116711681169117011711172117311741175More recently, Li et al. (Li et al., 2017a, 2016) explored large-scale mor-phological neuron databases based on a novel search strategy, the maxi-mum inner product search (MIPS). Based on MIPS, nonlinear hashing func-tions are learned by embedding the inner code product rather than the con-ventional Hamming distance. The nonlinear hashing functions are partic-ularly suitable for the morphological neuron retrieval problem, since theneurons’ tree-topological structure makes them hard to be discriminativein low-dimensional linear space. Fig. 9 demonstrates that the MIPS-basedmethod is able to retrieve morphologically similar neurons in the large-scaledatabase. To evaluate the retrieval precision, it employed projection neuronsin the olfactory bulb as queries. The retrieval results validated that mostreturned neurons have the same properties as the queries (with a reported90.48% average precision in the top-5 relevant neurons). Additionally, theauthors demonstrated the application of morphological retrieval in neuronexploration. By collecting properties of the top-K relevant neurons (e.g.,a neurons’ brain regions, cell types, transmitters). Properties of the queryneuron can be inferred in real-time based on this MIPS hashing framework.3811767. Future Directions117711781179118011811182118311841185118611871188118911901191119211931194119511961197119811991200120112021203120412051206120712081209121012111212After reviewing the above methods and applications of large-scale med-ical image analytics, we discuss possible future directions in this section.Despite varieties of advanced large-scale techniques being employed for re-trieval, there are still many directions to explore and improve the retrievalperformance.Multi-features:in general, only employing a single kind of feature isnot enough to represent and discriminate medical images. Especially whena database is large, the difference with some irrelevant images can be sub-tle. One intuitive solution is using multiple features to represent each image,e.g., local, holistic, and texture features. These features can be fused andembedded in a large-scale retrieval framework. According to existing work,multi-feature fusion can be conducted on three levels during retrieval, i.e.,feature level (Atrey et al., 2010), training level (Liu et al., 2014c), and deci-sion level (Zhang et al., 2012). Jiang et al. (Jiang et al., 2016a) fuse threetypes of features (SIFT (Lowe, 2004), HOG (Dalal and Triggs, 2005), andGIST (Oliva and Torralba, 2001)) in the training level when learning hashingfunctions; Zhang et al. (Zhang et al., 2016a) employ a graph-based query-specific fusion approach to integrating local and holistic features at the deci-sion level. Despite the two methods having achieved good performance, theseare far from enough for large-scale medical image retrieval. With the ever-increasing techniques in feature representation, employing more features toretrieve complex medical images is a clear trend (e.g. the ImageCLEF med-ical image retrieval tasks in recent years). However, as diverse features havedifferent meanings and representations, deciding on the importance of eachfeature is a challenging task. User specified feature importance is usuallynot reliable, and automatically computing each feature’s importance is time-consuming, especially when dealing with many features in a large database.Thus, successfully handling multi-feature fusion in a large-scale database fur-ther improves the accuracy and efficiency of medical image retrieval.Online updating: as more medical images are being generated, the sizeof the corresponding databases are continuously increasing. For example, theaforementioned ImageCLEF database increased the number of images from600 to 300, 000, and the NeuroMorpho database usually releases 1, 000 to2, 000 reconstructed neuron cells in each update. The newly added imagesshould be considered to train new models for retrieval, since employing moretraining data can accordingly improve the retrieval accuracy. However, if we3912131214121512161217121812191220122112221223122412251226122712281229123012311232123312341235123612371238123912401241124212431244124512461247124812491250re-train a large-scale model every time from scratch, using both the originaland the newly added images, it is time-consuming and adversely affects theefficiency of medical retrieval. On the other side, when the medical imagedatabases are extremely large (e.g., including millions of images), currentstorage techniques are not able to arrange and process all the images withinone batch. More importantly, both the vocabulary tree and hashing basedmethods cannot efficiently train models for the huge amount of images at agiven time, e.g., building a hierarchical tree or learning hashing functions withmillions of feature vectors. To tackle these problems, one possible solutionis to divide huge databases into several batches, and then develop an onlineupdating strategy to train the retrieval model with one-by-one image batchesin a streaming manner. The newly added images can also be treated asa batch to update the retrieval model. Currently, several online hashingmethods have been developed for computer vision tasks (Cakir and Sclaroff,2015; Huang et al., 2013; Leng et al., 2015).In medical image analytics,the merit of the online updating strategy is beneficial in the future with acontinuously increasing number of images and extremely large databases.Bringing humans in the loop: for the retrieval of large-scale medicalimage databases, lacking label information is the main limitation to achievegood retrieval results. As medical images usually have different modalitiesand appearances, their intra-class variations can be large, and their inter-class variations can be small. The image labels are useful to handle thisproblem, since it can embed supervised information in retrieval models andbridge the low-level features with high-level image semantics. However, label-ing images is not an easy task. Especially for some medical images, assigningtheir labels requires domain experts with proper training. Crowdsoucing canbe used when very precisely defined tasks allow for quick training times (Fon-cubierta Rodr´ıguez and M¨uller, 2012). Deciding whether a histopathologyimage contains benign or malignant lesions is complex and time-consuming,for example. Moreover, large-scale databases make this task even harder.To tackle these problems, one feasible solution is to bring humans in theretrieval loop. They can interactively give feedback to improve the retrievalperformance (Feng et al., 2013; Rui et al., 1998). After acquiring a set ofsimilar images from unsupervised retrieval, users/domain experts can specifyimages relevant to the query and those that are not. Such feedback can bereturned to the retrieval system to improve the final results (Bulo et al., 2011;Sahbi et al., 2007). The feedback can be treated as supervised informationbut it is more efficient than labeling all medical images. Theoretically, such40125112521253an interactive strategy can achieve two goals: 1) it presents retrieval resultsto users/domain experts to help them analyze medical images; 2) it receivesand uses the interactive feedback to improve the retrieval system.12548. Conclusions125512561257125812591260126112621263126412651266126712681269127012711272In this review, we summarize recent advances of large-scale retrieval formedical image analytics. By introducing the pipeline of large-scale retrieval,we presented a comprehensive review of relevant techniques that can improvethe efficiency and accuracy of medical image analysis, including feature rep-resentation, feature indexing and searching. We also reviewed clinical appli-cations and discussed the future directions of large-scale medical analytics.With the ever-increasing amount of newly generated medical images, we be-lieve that the algorithms and methods of large-scale medical image analyticswill lead to new ideas for knowledge discovery and decision support.Currently, only few systems have been exposed to detailed user test-ing (Markonis et al., 2015a) and such user tests are clearly needed for verylarge scale systems. Many currently CBIR systems only use small databasesand not update mechanisms and this is required for real application includingan integration of the systems into the standard clinical workflow, which isoften neglected. Many technical approaches are now available for large-scaleapplications but more work is needed to actually integrate the tools for clin-ical impact, an this includes the use of deep learning and explaining theseresults to physicians.1273Acknowledgement1274127512761277127812791280This work is partially supported by the National Science Foundation un-der grant ABI-1661280, CNS-1629913 and IIP-1439695.References, a. Bigneuron project. http://www.alleninstitute.org/bigneuron/. Accessed June28, 2016., b. Bigneuron released data. https://github.com/BigNeuron/Data/releases. AccessedJune 28, 2016.41128112821283128412851286128712881289129012911292129312941295129612971298129913001301130213031304130513061307130813091310131113121313131413151316, 2010. Riding the wave: How europe can gain from the rising tide of scientific data.Submission to the European Comission, available online at http://cordis.europa.eu/fp7/ict/e-infrastructure/docs/hlg-sdi-report.pdf. URL: http://cordis.europa.eu/fp7/ict/e-infrastructure/docs/hlg-sdi-report.pdf.Agarwal, M., Mostafa, J., 2011. Content-based image retrieval for alzheimer’s diseasedetection, in: Content-Based Multimedia Indexing (CBMI), 2011 9th InternationalWorkshop on, IEEE. pp. 13–18.Akg¨ul, C.B., Rubin, D.L., Napel, S., Beaulieu, C.F., Greenspan, H., Acar, B., 2011.Content-based image retrieval in radiology: current status and future directions. Journalof Digital Imaging 24, 208–222.Andr´e, B., Vercauteren, T., Buchner, A.M., Wallace, M.B., Ayache, N., 2012. Learningsemantic and visual similarity for endomicroscopy video retrieval. IEEE Transactionson Medical Imaging 31, 1276–1288.Antani, S.K., Deserno, T.M., Long, L.R., G¨uld, M.O., Neve, L., Thoma, G.R., 2007. In-terfacing global and local cbir systems for medical image retrieval, in: Bildverarbeitungf¨ur die Medizin 2007. Springer, pp. 166–171.Antipov, G., Berrani, S.A., Ruchaud, N., Dugelay, J.L., 2015. Learned vs. hand-craftedfeatures for pedestrian gender recognition, in: Proceedings of the 23rd ACM Interna-tional Conference on Multimedia, ACM. pp. 1263–1266.Armato III, S.G., McLennan, G., Bidaut, L., McNitt-Gray, M.F., Meyer, C.R., Reeves,A.P., Zhao, B., Aberle, D.R., Henschke, C.I., Hoffman, E.A., et al., 2011. The lungimage database consortium (lidc) and image database resource initiative (idri): a com-pleted reference database of lung nodules on ct scans. Medical Physics 38, 915–931.Atrey, P.K., Hossain, M.A., El Saddik, A., Kankanhalli, M.S., 2010. Multimodal fusionfor multimedia analysis: a survey. Multimedia Systems 16, 345–379.Babenko, A., Lempitsky, V., 2015. Aggregating local deep features for image retrieval, in:Proceedings of the IEEE international conference on computer vision, pp. 1269–1277.Bailey, D.L., Townsend, D.W., Valk, P.E., Maisey, M.N., 2005. Positron emission tomog-raphy. Springer.Bar, Y., Diamant, I., Wolf, L., Lieberman, S., Konen, E., Greenspan, H., 2015. Chestpathology detection using deep learning with non-medical training, in: 2015 IEEE 12thInternational Symposium on Biomedical Imaging (ISBI), IEEE. pp. 294–297.Basavanhally, A.N., Ganesan, S., Agner, S., Monaco, J.P., Feldman, M.D., Tomaszewski,J.E., Bhanot, G., Madabhushi, A., 2010. Computerized image-based detection andgrading of lymphocytic infiltration in her2+ breast cancer histopathology. IEEE Trans-actions on Biomedical Engineering 57, 642–653.42131713181319132013211322132313241325132613271328132913301331133213331334133513361337133813391340134113421343134413451346134713481349Bay, H., Ess, A., Tuytelaars, T., Van Gool, L., 2008. Speeded-up robust features (surf).Computer Vision and Image Understanding 110, 346–359.Bengio, Y., 2009. Learning deep architectures for ai. Foundations and trends R(cid:13) in MachineLearning 2, 1–127.Bengio, Y., Courville, A.C., Vincent, P., 2012. Unsupervised feature learning and deeplearning: A review and new perspectives. CoRR, abs/1206.5538 1.Bionetworks, S., . The digital mammography dream challenge. https://www.synapse.org/Synapse:syn4224222/wiki/. Accessed October 23, 2016.Bourlard, H., Kamp, Y., 1988. Auto-association by multilayer perceptrons and singularvalue decomposition. Biological Cybernetics 59, 291–294.Brosch, T., Tam, R., Initiative, A.D.N., et al., 2013. Manifold learning of brain mrisInternational Conference on Medical Image Computing andby deep learning,Computer-Assisted Intervention, Springer. pp. 633–640.in:Bulo, S.R., Rabbi, M., Pelillo, M., 2011. Content-based image retrieval with relevancefeedback using random walks. Pattern Recognition 44, 2109–2122.Bunte, K., Biehl, M., Jonkman, M.F., Petkov, N., 2011. Learning effective color featuresfor content based image retrieval in dermatology. Pattern Recognition 44, 1892–1902.Cai, W., Liu, S., Wen, L., Eberl, S., Fulham, M.J., Feng, D., 2010. 3d neurological imageretrieval with localized pathology-centric cmrglc patterns, in: 2010 IEEE InternationalConference on Image Processing, IEEE. pp. 3201–3204.Caicedo, J.C., Cruz, A., Gonzalez, F.A., 2009. Histopathology image classification usingbag of features and kernel functions, in: Conference on Artificial Intelligence in Medicinein Europe, Springer. pp. 126–135.Caicedo, J.C., Gonzalez, F.A., Romero, E., 2007. Content-based medical image retrievalusing low-level visual features and modality identification, in: Workshop of the Cross-Language Evaluation Forum for European Languages, Springer. pp. 615–622.Caicedo, J.C., Gonz´alez, F.A., Romero, E., 2011. Content-based histopathology imageretrieval using a kernel-based semantic annotation framework. Journal of BiomedicalInformatics 44, 519–528.Cakir, F., Sclaroff, S., 2015. Adaptive hashing for fast similarity search, in: Proceedingsof the IEEE International Conference on Computer Vision, pp. 1044–1052.Cao, Y., Steffey, S., He, J., Xiao, D., Tao, C., Chen, P., M¨uller, H., 2014. Medical imageretrieval: A multimodal approach. Cancer Informatics 13, 125.4313501351135213531354135513561357135813591360136113621363136413651366136713681369137013711372137313741375137613771378137913801381138213831384Cheng, H., Shi, X., Min, R., Hu, L., Cai, X., Du, H., 2006. Approaches for automateddetection and classification of masses in mammograms. Pattern Recognition 39, 646–668.Chenouard, N., Unser, M., 2011. 3d steerable wavelets and monogenic analysis for bioimag-ing, in: 2011 IEEE International Symposium on Biomedical Imaging: From Nano toMacro, IEEE. pp. 2132–2135.Ciompi, F., de Hoop, B., van Riel, S.J., Chung, K., Scholten, E.T., Oudkerk, M., de Jong,P.A., Prokop, M., van Ginneken, B., 2015. Automatic classification of pulmonaryperi-fissural nodules in computed tomography using an ensemble of 2d views and aconvolutional neural network out-of-the-box. Medical Image Analysis 26, 195–202.Collins, D.J., Padhani, A.R., 2004. Dynamic magnetic resonance imaging of tumor perfu-sion. IEEE Engineering in Medicine and Biology Magazine 23, 65–83.Conjeti, S., Katouzian, A., Kazi, A., Mesbah, S., Beymer, D., Syeda-Mahmood, T.F.,Navab, N., 2016a. Metric hashing forests. Medical Image Analysis .Conjeti, S., Mesbah, S., Negahdar, M., Rautenberg, P.L., Zhang, S., Navab, N., Katouzian,A., 2016b. Neuron-miner: An advanced tool for morphological search and retrieval inneuroscientific image databases. Neuroinformatics 14, 369–385.Dalal, N., Triggs, B., 2005. Histograms of oriented gradients for human detection, in:2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition(CVPR’05), IEEE. pp. 886–893.Davis, J., Goadrich, M., 2006. The relationship between precision-recall and roc curves,in: Proceedings of the 23rd international conference on Machine learning, ACM. pp.233–240.Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L., 2009. Imagenet: A large-scale hierarchical image database, in: Computer Vision and Pattern Recognition, 2009.CVPR 2009. IEEE Conference on, IEEE. pp. 248–255.Depeursinge, A., Fischer, B., M¨uller, H., Deserno, T.M., 2011. Suppl 1: Prototypes forcontent-based image retrieval in clinical practice. The open medical informatics journal5, 58.Depeursinge, A., M¨uller, H., 2010. Fusion techniques for combining textual and visualinformation retrieval, in: ImageCLEF. Springer, pp. 95–114.(DIAG), D.I.A.G., . The camelyon challenge. https://camelyon17.grand-challenge.org/. Accessed March 23, 2017.Doi, K., 2014. Current status and future potential of computer-aided diagnosis in medicalimaging. The British journal of radiology 78.4413851386138713881389139013911392139313941395139613971398139914001401140214031404140514061407140814091410141114121413141414151416Donahue, J., Jia, Y., Vinyals, O., Hoffman, J., Zhang, N., Tzeng, E., Darrell, T., 2014.Decaf: A deep convolutional activation feature for generic visual recognition., in: ICML,pp. 647–655.Douze, M., J´egou, H., Sandhawalia, H., Amsaleg, L., Schmid, C., 2009. Evaluation ofgist descriptors for web-scale image search, in: Proceedings of the ACM InternationalConference on Image and Video Retrieval, ACM. p. 19.Doyle, S., Feldman, M., Tomaszewski, J., Madabhushi, A., 2012. A boosted bayesianmultiresolution classifier for prostate cancer detection from digitized needle biopsies.IEEE Transactions on Biomedical Engineering 59, 1205–1218.Doyle, S., Hwang, M., Naik, S., Feldman, M., Tomaszeweski, J., Madabhushi, A., 2007.Using manifold learning for content-based image retrieval of prostate histopathology,in: MICCAI 2007 Workshop on Content-based Image Retrieval for Biomedical ImageArchives: Achievements, Problems, and Prospects, Citeseer. pp. 53–62.Everingham, M., Van Gool, L., Williams, C.K., Winn, J., Zisserman, A., 2010. Thepascal visual object classes (voc) challenge. International journal of computer vision88, 303–338.EyePACS,.Diabeticretinopathy detection.https://www.kaggle.com/c/diabetic-retinopathy-detection/. Accessed October 23, 2016.Fan, L., 2013. Supervised binary hash code learning with jensen shannon divergence, in:Proceedings of the IEEE International Conference on Computer Vision, pp. 2616–2623.Fang, R., Pouyanfar, S., Yang, Y., Chen, S.C., Iyengar, S., 2016. Computational healthinformatics in the big data age: a survey. ACM Computing Surveys (CSUR) 49, 12.Feng, D., Siu, W.C., Zhang, H.J., 2013. Multimedia information retrieval and man-agement: Technological fundamentals and applications. Springer Science & BusinessMedia.Feulner, J., Zhou, S.K., Angelopoulou, E., Seifert, S., Cavallaro, A., Hornegger, J., Co-maniciu, D., 2011. Comparing axial ct slices in quantized n-dimensional surf descriptorspace to estimate the visible body region. Computerized Medical Imaging and Graphics35, 227–236.Filipczuk, P., Fevens, T., Krzy˙zak, A., Monczak, R., 2013. Computer-aided breast cancerIEEEdiagnosis based on the analysis of cytological images of fine needle biopsies.Transactions on Medical Imaging 32, 2169–2178.1417Fischl, B., 2012. Freesurfer. Neuroimage 62, 774–781.1418141914201421Foncubierta-Rodr´ıguez, A., Garc´ıa Seco de Herrera, A., M¨uller, H., 2013. Medical imageretrieval using bag of meaningful visual words: unsupervised visual vocabulary pruningwith plsa, in: Proceedings of the 1st ACM International Workshop on MultimediaIndexing and Information Retrieval for Healthcare, ACM. pp. 75–82.4514221423142414251426142714281429Foncubierta Rodr´ıguez, A., M¨uller, H., 2012. Ground truth generation in medical imaging:a crowdsourcing-based iterative approach, in: Proceedings of the ACM multimedia 2012workshop on Crowdsourcing for multimedia, ACM. pp. 9–14.Foran, D.J., Yang, L., Chen, W., Hu, J., Goodell, L.A., Reiss, M., Wang, F., Kurc, T., Pan,T., Sharma, A., et al., 2011. Imageminer: a software system for comparative analysisof tissue microarrays using content-based image retrieval, high-performance computing,and grid technology. Journal of the American Medical Informatics Association 18, 403–415.1430Fukunaga, K., 2013. Introduction to statistical pattern recognition. Academic press.1431143214331434143514361437143814391440144114421443144414451446144714481449145014511452145314541455145614571458Gionis, A., Indyk, P., Motwani, R., et al., 1999. Similarity search in high dimensions viahashing, in: VLDB, pp. 518–529.Gletsos, M., Mougiakakou, S.G., Matsopoulos, G.K., Nikita, K.S., Nikita, A.S., Kelekis,D., 2003. A computer-aided diagnostic system to characterize ct focal liver lesions: de-sign and optimization of a neural network classifier. IEEE Transactions on InformationTechnology in Biomedicine 7, 153–162.Gong, Y., Kumar, S., Verma, V., Lazebnik, S., 2012. Angular quantization-based binarycodes for fast similarity search, in: Advances in Neural Information Processing Systems,pp. 1196–1204.Gong, Y., Lazebnik, S., 2011. Iterative quantization: A procrustean approach to learn-ing binary codes, in: Computer Vision and Pattern Recognition (CVPR), 2011 IEEEConference on, IEEE. pp. 817–824.Gong, Y., Lazebnik, S., Gordo, A., Perronnin, F., 2013. Iterative quantization: A pro-crustean approach to learning binary codes for large-scale image retrieval. IEEE Trans-actions on Pattern Analysis and Machine Intelligence 35, 2916–2929.Gordo, A., Perronnin, F., Gong, Y., Lazebnik, S., 2014. Asymmetric distances for binaryembeddings. IEEE Transactions on Pattern Analysis and Machine Intelligence 36, 33–47.G¨uld, M.O., Thies, C., Fischer, B., Lehmann, T.M., 2005. Content-based retrieval ofmedical images by combining global features, in: Workshop of the Cross-LanguageEvaluation Forum for European Languages, Springer. pp. 702–711.Gurcan, M.N., Boucheron, L.E., Can, A., Madabhushi, A., Rajpoot, N.M., Yener, B., 2009.Histopathological image analysis: A review. IEEE Reviews in Biomedical Engineering2, 147–171.Haas, S., Donner, R., Burner, A., Holzer, M., Langs, G., 2011. Superpixel-based interestpoints for effective bags of visual words medical image retrieval, in: MICCAI Inter-national Workshop on Medical Content-Based Retrieval for Clinical Decision Support,Springer. pp. 58–68.46145914601461146214631464146514661467146814691470147114721473147414751476147714781479He, J., Kumar, S., Chang, S.F., 2012. On the difficulty of nearest neighbor search, in:Proceedings of the 29th international conference on machine learning (ICML-12), pp.1127–1134.He, K., Zhang, X., Ren, S., Sun, J., 2015. Deep residual learning for image recognition.arXiv preprint arXiv:1512.03385 .Garc´ıa Seco de Herrera, A., Schaer, R., Bromuri, S., M¨uller, H., 2016. Overview of theImageCLEF 2016 medical task, in: Working Notes of CLEF 2016 (Cross LanguageEvaluation Forum), pp. 1–13.de Herrera, A.G.S., Kalpathy-Cramer, J., Demner-Fushman, D., Antani, S., M¨uller, H.,2013. Overview of the imageclef 2013 medical tasks., in: CLEF (Working Notes).Hinton, G.E., Salakhutdinov, R.R., 2006. Reducing the dimensionality of data with neuralnetworks. Science 313, 504–507.Hofmann, T., 2001. Unsupervised learning by probabilistic latent semantic analysis. Ma-chine Learning 42, 177–196.Hofmanninger, J., Langs, G., 2015. Mapping visual features to semantic profiles for re-trieval in medical imaging, in: Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition, pp. 457–465.Hsieh, J., 2009. Computed tomography: principles, design, artifacts, and recent advances,SPIE Bellingham, WA.Hsu, W., Long, L.R., Antani, S., et al., 2007. Spirs: a framework for content-based imageretrieval from large biomedical databases. MedInfo 12, 188–192.1480Huang, L.K., Yang, Q., Zheng, W.S., 2013. Online hashing., in: IJCAI, Citeseer.148114821483148414851486148714881489149014911492Hwang, K.H., Lee, H., Choi, D., 2012. Medical image retrieval: past and present. Health-care Informatics Research 18, 3–9.ImageCLEF, . Image retrieval task of the conference and labs of the evaluation forum.http://www.imageclef.org/. Accessed October 23, 2016.Institute, N.C., a. The cancer genome atlas. https://tcga-data.nci.nih.gov/. Ac-cessed October 23, 2016.Institute, N.C., b. Genomic data commons. https://gdc.cancer.gov/. Accessed October23, 2016.Institute, N.C., c. The national lung screening trial (nlst). https://biometry.nci.nih.gov/cdas/nlst/. Accessed March 23, 2017.IRMA,.Image retrievalin medical applications project.http://ganymed.imib.rwth-aachen.de/irma/. Accessed October 23, 2016.471493149414951496149714981499150015011502150315041505150615071508150915101511151215131514151515161517151815191520152115221523152415251526152715281529Jain, P., Kulis, B., Dhillon, I.S., Grauman, K., 2009. Online metric learning and fastsimilarity search, in: Advances in Neural Information Processing Systems, pp. 761–768.Jain, P., Kulis, B., Grauman, K., 2008. Fast image search for learned metrics, in: Com-puter Vision and Pattern Recognition, 2008. CVPR 2008. IEEE Conference on, IEEE.pp. 1–8.Jiang, M., Zhang, S., Fang, R., Metaxas, D.N., 2015a. Leveraging coupled multi-index forscalable retrieval of mammographic masses, in: 2015 IEEE 12th International Sympo-sium on Biomedical Imaging (ISBI), IEEE. pp. 276–280.Jiang, M., Zhang, S., Huang, J., Yang, L., Metaxas, D.N., 2015b. Joint kernel-basedsupervised hashing for scalable histopathological image analysis, in: International Con-ference on Medical Image Computing and Computer-Assisted Intervention, Springer.pp. 366–373.Jiang, M., Zhang, S., Huang, J., Yang, L., Metaxas, D.N., 2016a. Scalable histopatho-logical image analysis via supervised hashing with multiple features. Medical ImageAnalysis 34, 3–12.Jiang, M., Zhang, S., Li, H., Metaxas, D.N., 2015c. Computer-aided diagnosis of mam-IEEE Transactions on Biomedicalmographic masses using scalable image retrieval.Engineering 62, 783–792.Jiang, M., Zhang, S., Zheng, Y., Metaxas, D.N., 2016b. Mammographic mass segmenta-tion with online learned shape and appearance priors, in: International Conference onMedical Image Computing and Computer-Assisted Intervention, Springer. pp. 35–43.Jimenez-del-Toro, O., Hanbury, A., Langs, G., Foncubierta-Rodr´ıguez, A., M¨uller, H.,2015. Overview of the VISCERAL Retrieval Benchmark 2015, in: Multimodal Retrievalin the Medical Domain: First International Workshop, MRMD 2015, Vienna, Austria,March 29, 2015, Revised Selected Papers, Springer. pp. 115–123.Kahn, C.E., Carrino, J.A., Flynn, M.J., Peck, D.J., Horii, S.C., 2007. Dicom and radiology:past, present, and future. Journal of the American College of Radiology 4, 652–657.Kalpathy-Cramer, J., de Herrera, A.G.S., Demner-Fushman, D., Antani, S., Bedrick, S.,M¨uller, H., 2015. Evaluating performance of biomedical image retrieval systemsanoverview of the medical image retrieval task at imageclef 2004–2013. ComputerizedMedical Imaging and Graphics 39, 55–61.Kalpathy-Cramer, J., Hersh, W., 2008. Effectiveness of global features for automatic med-ical image classification and retrieval–the experiences of ohsu at imageclefmed. PatternRecognition Letters 29, 2032–2038.Kalpathy-Cramer, J., M¨uller, H., Bedrick, S., Eggel, I., de Herrera, A.G.S., Tsikrika, T.,2011. Overview of the clef 2011 medical image classification and retrieval tasks., in:CLEF (notebook papers/labs/workshop), pp. 97–112.48153015311532153315341535153615371538153915401541154215431544154515461547154815491550155115521553Katouzian, A., Angelini, E.D., Carlier, S.G., Suri, J.S., Navab, N., Laine, A.F., 2012. Astate-of-the-art review on segmentation algorithms in intravascular ultrasound (ivus)images. IEEE Transactions on Information Technology in Biomedicine 16, 823–834.Kim, H., El-Khamra, Y., Rodero, I., Jha, S., Parashar, M., 2011. Autonomic managementof application workflows on hybrid computing infrastructure. Scientific Programming19, 75–89.Krizhevsky, A., Sutskever, I., Hinton, G.E., 2012. Imagenet classification with deep con-volutional neural networks, in: Advances in Neural Information Processing Systems,pp. 1097–1105.Kulis, B., Grauman, K., 2012. Kernelized locality-sensitive hashing. IEEE Transactionson Pattern Analysis and Machine Intelligence 34, 1092–1104.Kulis, B., Jain, P., Grauman, K., 2009. Fast similarity search for learned metrics. IEEETransactions on Pattern Analysis and Machine Intelligence 31, 2143–2157.Kumar, A., Kim, J., Cai, W., Fulham, M., Feng, D., 2013. Content-based medical imageretrieval: a survey of applications to multidimensional and multimodality data. Journalof Digital Imaging 26, 1025–1039.Kumar, V.S., Rutt, B., Kurc, T., Catalyurek, U., Saltz, J., Chow, S., Lamont, S., Martone,M., 2006. Large image correction and warping in a cluster environment, in: SC 2006Conference, Proceedings of the ACM/IEEE, IEEE. pp. 38–38.Lan, R., Zhou, Y., 2016. Medical image retrieval via histogram of compressed scatteringcoefficients. IEEE Journal of Biomedical and Health Informatics .Langs, G., Hanbury, A., Menze, B., M¨uller, H., 2012. Visceral: Towards large datain medical imagingchallenges and directions, in: MICCAI International Workshop onMedical Content-Based Retrieval for Clinical Decision Support, Springer. pp. 92–98.1554LeCun, Y., Bengio, Y., Hinton, G., 2015. Deep learning. Nature 521, 436–444.1555155615571558155915601561156215631564LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., 1998. Gradient-based learning applied todocument recognition. Proceedings of the IEEE 86, 2278–2324.Lehmann, T.M., Gold, M., Thies, C., Fischer, B., Spitzer, K., Keysers, D., Ney, H.,Kohnen, M., Schubert, H., Wein, B.B., 2004. Content-based image retrieval in medicalapplications. Methods of Information in Medicine 43, 354–361.Leng, C., Wu, J., Cheng, J., Bai, X., Lu, H., 2015. Online sketching hashing, in: Pro-ceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp.2503–2511.Lewis, R., 2004. Medical phase contrast x-ray imaging:prospects. Physics in medicine and biology 49, 3573–3584.current status and future4915651566156715681569157015711572157315741575157615771578157915801581158215831584158515861587158815891590159115921593159415951596159715981599Li, Q., Cai, W., Wang, X., Zhou, Y., Feng, D.D., Chen, M., 2014a. Medical imageclassification with convolutional neural network, in: Control Automation Robotics &Vision (ICARCV), 2014 13th International Conference on, IEEE. pp. 844–848.Li, R., Zhang, W., Suk, H.I., Wang, L., Li, J., Shen, D., Ji, S., 2014b. Deep learning basedimaging data completion for improved brain disease diagnosis, in: International Con-ference on Medical Image Computing and Computer-Assisted Intervention, Springer.pp. 305–312.Li, Z., Fang, R., Shen, F., Katouzian, A., Zhang, S., 2017a. Indexing and mining large-scale neuron databases using maximum inner product search. Pattern Recognition 63,680–688.Li, Z., Metaxas, D.N., Lu, A., Zhang, S., 2017b. Interactive exploration for continuouslyexpanding neuron databases. Methods 115, 100–109.Li, Z., Shen, F., Fang, R., Conjeti, S., Katouzian, A., Zhang, S., 2016. Maximum innerproduct search for morphological retrieval of large-scale neuron data, in: BiomedicalImaging (ISBI), 2016 IEEE 13th International Symposium on, IEEE. pp. 602–606.Lichtman, J.W., Conchello, J.A., 2005. Fluorescence microscopy. Nature Methods 2,910–919.Lim, J.H., Chevallet, J.P., 2005. Vismed: a visual vocabulary approach for medical imageindexing and retrieval, in: Asia Information Retrieval Symposium, Springer. pp. 84–96.Lin, T.Y., Maire, M., Belongie, S., Bourdev, L., Girshick, R., Hays, J., Perona, P., Ra-manan, D., Zitnick, C.L., Dollar, P., 2014. Microsoft coco: Common objects in context.arXiv preprint arXiv:1405.0312 .Lisin, D.A., Mattar, M.A., Blaschko, M.B., Learned-Miller, E.G., Benfield, M.C., 2005.Combining local and globalin: 2005IEEE Computer Society Conference on Computer Vision and Pattern Recognition(CVPR’05)-Workshops, IEEE. pp. 47–47.image features for object class recognition,Liu, H., Wang, R., Shan, S., Chen, X., 2016a. Deep supervised hashing for fast imageretrieval, in: Proceedings of the IEEE Conference on Computer Vision and PatternRecognition, pp. 2064–2072.Liu, J., Zhang, S., Liu, W., Deng, C., Zheng, Y., Metaxas, D.N., 2016b. Scalable mammo-gram retrieval using composite anchor graph hashing with iterative quantization. IEEETransactions on Circuits and Systems for Video Technology PP, 1–11.Liu, J., Zhang, S., Liu, W., Zhang, X., Metaxas, D.N., 2014a. Scalable mammogramretrieval using anchor graph hashing, in: 2014 IEEE 11th International Symposium onBiomedical Imaging (ISBI), IEEE. pp. 898–901.50160016011602160316041605160616071608160916101611161216131614161516161617161816191620Liu, W., Mu, C., Kumar, S., Chang, S.F., 2014b. Discrete graph hashing, in: Advances inNeural Information Processing Systems, pp. 3419–3427.Liu, W., Wang, J., Ji, R., Jiang, Y.G., Chang, S.F., 2012. Supervised hashing withkernels, in: Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conferenceon, IEEE. pp. 2074–2081.Liu, W., Wang, J., Kumar, S., Chang, S.F., 2011. Hashing with graphs, in: Proceedingsof the 28th International Conference on Machine Learning (ICML-11), pp. 1–8.Liu, X., He, J., Lang, B., 2014c. Multiple feature kernel hashing for large-scale visualsearch. Pattern Recognition 47, 748–757.Long, L.R., Antani, S., Deserno, T.M., Thoma, G.R., 2009. Content-based image re-trieval in medicine: retrospective assessment, state of the art, and future directions.International Journal of Healthcare Information Systems and Informatics 4, 1.Lowe, D.G., 2004. Distinctive image features from scale-invariant keypoints. InternationalJournal of Computer Vision 60, 91–110.Manjunath, B.S., Ma, W.Y., 1996. Texture features for browsing and retrieval of imagedata. IEEE Transactions on Pattern Analysis and Machine Intelligence 18, 837–842.Markonis, D., Holzer, M., Baroz, F., De Castaneda, R.L.R., Boyer, C., Langs, G., M¨uller,H., 2015a. User-oriented evaluation of a medical image retrieval system for radiologists.International journal of medical informatics 84, 774–783.Markonis, D., Schaer, R., Eggel, I., M¨uller, H., Depeursinge, A., 2015b. Using mapreducefor large-scale medical image analysis. arXiv preprint arXiv:1510.06937 .1621May, M., 2010. A better lens on disease. Scientific American 302, 74–77.1622162316241625162616271628162916301631163216331634of Medicine, T.N.L., . Medpix. https://medpix.nlm.nih.gov/home. Accessed October23, 2016.Mesbah, S., Conjeti, S., Kumaraswamy, A., Rautenberg, P., Navab, N., Katouzian, A.,2015. Hashing forests for morphological search and retrieval in neuroscientific imagedatabases, in: International Conference on Medical Image Computing and Computer-Assisted Intervention, Springer. pp. 135–143.M¨uller, H., Clough, P., Deselaers, T., Caputo, B., CLEF, I., 2010. Experimental evaluationin visual information retrieval. The Information Retrieval Series 32.M¨uller, H., Deserno, T.M., 2010. Content-based medical image retrieval, in: BiomedicalImage Processing. Springer, pp. 471–494.M¨uller, H., de Herrera, A.G.S., Kalpathy-Cramer, J., Demner-Fushman, D., Antani, S.,Eggel, I., 2012. Overview of the imageclef 2012 medical image retrieval and classificationtasks., in: CLEF (online working notes/labs/workshop), pp. 1–16.51163516361637163816391640164116421643164416451646164716481649165016511652165316541655165616571658165916601661166216631664166516661667166816691670M¨uller, H., Kalpathy-Cramer, J., Eggel, I., Bedrick, S., Radhouani, S., Bakke, B., Kahn,C.E., Hersh, W., 2009. Overview of the clef 2009 medical image retrieval track, in:Workshop of the Cross-Language Evaluation Forum for European Languages, Springer.pp. 72–84.M¨uller, H., Menze, B., Langs, G., Montillo, A., Kelm, M., Zhang, S., Cai, W.T., Metaxas,D., 2014. Overview of the 2014 workshop on medical computer visionalgorithms for bigdata (mcv 2014), in: International MICCAI Workshop on Medical Computer Vision,Springer. pp. 3–10.M¨uller, H., Michoux, N., Bandon, D., Geissbuhler, A., 2004. A review of content-basedimage retrieval systems in medical applicationsclinical benefits and future directions.International Journal of Medical Informatics 73, 1–23.Muller, H., Muller, W., Marchand-Maillet, S., Pun, T., Squire, D.M., 2000. Strategies forpositive and negative relevance feedback in image retrieval, in: Pattern Recognition,2000. Proceedings. 15th International Conference on, IEEE. pp. 1043–1046.M¨uller, H., M¨uller, W., Squire, D.M., Marchand-Maillet, S., Pun, T., 2001. Performanceevaluation in content-based image retrieval: overview and proposals. Pattern Recogni-tion Letters 22, 593–601.Muller, H., Rosset, A., Vallee, J.P., Geissbuhler, A., 2004. Comparing features sets forcontent-based image retrieval in a medical- case database, in: Proceedings of SPIE, pp.99–109.Murala, S., Maheshwari, R., Balasubramanian, R., 2012. Directional binary wavelet pat-terns for biomedical image indexing and retrieval. Journal of Medical Systems 36,2865–2879.Nanni, L., Lumini, A., Brahnam, S., 2010. Local binary patterns variants as texturedescriptors for medical image analysis. Artificial Intelligence in Medicine 49, 117–125.NBIA, . National biomedical imaging archive. https://imaging.nci.nih.gov/ncia/login.jsf. Accessed October 23, 2016.NCBI, . Pubmed central. https://www.ncbi.nlm.nih.gov/pmc/. Accessed March 23,2017.NeuroMorpho, . Neuron morphological database. http://neuromorpho.org/. AccessedOctober 23, 2016.Nister, D., Stewenius, H., 2006. Scalable recognition with a vocabulary tree, in: 2006IEEE Computer Society Conference on Computer Vision and Pattern Recognition(CVPR’06), IEEE. pp. 2161–2168.Norouzi, M., Fleet, D.J., Salakhutdinov, R.R., 2012. Hamming distance metric learning,in: Advances in Neural Information Processing Systems, pp. 1061–1069.52167116721673167416751676167716781679168016811682168316841685168616871688168916901691169216931694169516961697169816991700170117021703170417051706Ojala, T., Pietik¨ainen, M., Harwood, D., 1996. A comparative study of texture measureswith classification based on featured distributions. Pattern Recognition 29, 51–59.Oliva, A., Torralba, A., 2001. Modeling the shape of the scene: A holistic representationof the spatial envelope. International Journal of Computer Vision 42, 145–175.Oliver, A., Freixenet, J., Marti, J., P´erez, E., Pont, J., Denton, E.R., Zwiggelaar, R., 2010.A review of automatic mass detection and segmentation in mammographic images.Medical Image Analysis 14, 87–110.Peng, H., Ruan, Z., Long, F., Simpson, J.H., Myers, E.W., 2010. V3d enables real-time 3dvisualization and quantitative analysis of large-scale biological image data sets. NatureBiotechnology 28, 348–353.Powers, D.M., 2011. Evaluation: from precision, recall and f-measure to roc, informedness,markedness and correlation. Journal of Machine Learning Technologies 2, 37–63.Qi, X., Wang, D., Rodero, I., Diaz-Montes, J., Gensure, R.H., Xing, F., Zhong, H.,Goodell, L., Parashar, M., Foran, D.J., et al., 2014. Content-based histopathologyimage retrieval using cometcloud. BMC Bioinformatics 15, 1.Radhouani, S., Kalpathy-Cramer, J., Bedrick, S., Bakke, B., Hersh, W.R., 2009. Mul-timodal medical image retrieval: Improving precision at imageclef 2009., in: CLEF(Working Notes).Raginsky, M., Lazebnik, S., 2009. Locality-sensitive binary codes from shift-invariantkernels, in: Advances in Neural Information Processing Systems, pp. 1509–1517.Rahman, M.M., Bhattacharya, P., Desai, B.C., 2007. A framework for medical imageretrieval using machine learning and statistical similarity matching techniques withrelevance feedback. IEEE Transactions on Information Technology in Biomedicine 11,58–69.Rui, Y., Huang, T.S., Ortega, M., Mehrotra, S., 1998. Relevance feedback: a power tool forinteractive content-based image retrieval. IEEE Transactions on Circuits and Systemsfor Video Technology 8, 644–655.Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy,A., Khosla, A., Bernstein, M., Berg, A.C., Fei-Fei, L., 2015.ImageNet Large ScaleVisual Recognition Challenge. International Journal of Computer Vision (IJCV) 115,211–252. doi:10.1007/s11263-015-0816-y.Sahbi, H., Audibert, J.Y., Keriven, R., 2007. Graph-cut transducers for relevance feed-back in content based image retrieval, in: 2007 IEEE 11th International Conference onComputer Vision, IEEE. pp. 1–8.Salakhutdinov, R., 2015. Learning deep generative models. Annual Review of Statisticsand Its Application 2, 361–385.5317071708170917101711171217131714171517161717171817191720172117221723172417251726172717281729173017311732173317341735173617371738173917401741Salton, G., Buckley, C., 1988. Term-weighting approaches in automatic text retrieval.Information Processing & Management 24, 513–523.Schindelin, J., Arganda-Carreras, I., Frise, E., Kaynig, V., Longair, M., Pietzsch, T.,Preibisch, S., Rueden, C., Saalfeld, S., Schmid, B., et al., 2012. Fiji: an open-sourceplatform for biological-image analysis. Nature Methods 9, 676–682.Schlegl, T., Ofner, J., Langs, G., 2014. Unsupervised pre-training across image domainsimproves lung tissue classification, in: International MICCAI Workshop on MedicalComputer Vision, Springer. pp. 82–93.Semedo, D., Magalh˜aes, J., . Novasearch at imageclefmed 2016 subfigure classificationtask, in: CLEF2016 Working Notes. CEUR Workshop Proceedings, ´Evora, Portugal,CEUR-WS. org (September 5-8 2016).Sertel, O., Kong, J., Catalyurek, U.V., Lozanski, G., Saltz, J.H., Gurcan, M.N., 2009.Histopathological image analysis using model-based intermediate representations andcolor texture: Follicular lymphoma grading. Journal of Signal Processing Systems 55,169–183.Shen, D., Wu, G., Suk, H.I., 2016. Deep learning in medical image analysis. AnnualReview of Biomedical Engineering 19.Shen, F., Liu, W., Zhang, S., Yang, Y., Shen, H.T., 2015a. Learning binary codes formaximum inner product search, in: 2015 IEEE International Conference on ComputerVision (ICCV), IEEE. pp. 4148–4156.Shen, F., Shen, C., Liu, W., Tao Shen, H., 2015b. Supervised discrete hashing, in: Pro-ceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp.37–45.Shen, F., Shen, C., Shi, Q., van den Hengel, A., Tang, Z., Shen, H.T., 2015c. Hashing onnonlinear manifolds. IEEE Transactions on Image Processing 24, 1839–1851.Shen, F., Shen, C., Shi, Q., Van Den Hengel, A., Tang, Z., 2013. Inductive hashing onmanifolds, in: Proceedings of the IEEE Conference on Computer Vision and PatternRecognition, pp. 1562–1569.Shen, W., Zhou, M., Yang, F., Yang, C., Tian, J., 2015d. Multi-scale convolutional neuralnetworks for lung nodule classification, in: International Conference on InformationProcessing in Medical Imaging, Springer. pp. 588–599.Shin, H.C., Orton, M.R., Collins, D.J., Doran, S.J., Leach, M.O., 2013. Stacked autoen-coders for unsupervised feature learning and multiple organ detection in a pilot studyusing 4d patient data. IEEE Transactions on Pattern Analysis and Machine Intelligence35, 1930–1943.541742174317441745174617471748174917501751175217531754175517561757175817591760176117621763176417651766176717681769177017711772177317741775Shin, H.C., Roth, H.R., Gao, M., Lu, L., Xu, Z., Nogues, I., Yao, J., Mollura, D., Sum-mers, R.M., 2016. Deep convolutional neural networks for computer-aided detection:Cnn architectures, dataset characteristics and transfer learning. IEEE Transactions onMedical Imaging 35, 1285–1298.Siemens, . Great growth potential for medical imaging systems. http://www.siemens.com/innovation/en/home/pictures-of-the-future/health-and-well-being/medical-imaging-facts-and-forecasts.html. Accessed October 23, 2016.Siggelkow, S., 2002. Feature histograms for content-based image retrieval. Ph.D. thesis.Universit¨at Freiburg.Simonyan, K., Zisserman, A., 2014. Very deep convolutional networks for large-scale imagerecognition. arXiv preprint arXiv:1409.1556 .Simpson, M.S., You, D., Rahman, M.M., Demner-Fushman, D., Antani, S., Thoma, G.R.,2012. Iti’s participation in the imageclef 2012 medical retrieval and classification tasks.,in: CLEF (Online Working Notes/Labs/Workshop).Sivic, J., Zisserman, A., 2003. Video google: A text retrieval approach to object matchingin videos, in: Computer Vision, 2003. Proceedings. Ninth IEEE International Confer-ence on, IEEE. pp. 1470–1477.Slichter, C.P., 2013. Principles of magnetic resonance. volume 1. Springer Science &Business Media.Smolensky, P., 1986. Information processing in dynamical systems: foundations of har-mony theory, in: Parallel Distributed Processing: Explorations in the Microstructureof Cognition, vol. 1, MIT Press. pp. 194–281.Society, A.C., 2013. Breast Cancer Facts & Figures 2013-2014. volume 1. American CancerSociety.Song, L., Liu, X., Ma, L., Zhou, C., Zhao, X., Zhao, Y., 2012. Using hog-lbp features andmmp learning to recognize imaging signs of lung lesions, in: Computer-Based MedicalSystems (CBMS), 2012 25th International Symposium on, IEEE. pp. 1–4.of South Florida, U., . Usf digital mammography homepage. http://marathon.csee.usf.edu/Mammography/. Accessed October 23, 2016.of Southern California, U., . Alzheimer’s disease neuroimaging initiative. http://adni.loni.usc.edu/. Accessed October 23, 2016.Srivastava, N., Hinton, G.E., Krizhevsky, A., Sutskever, I., Salakhutdinov, R., 2014.Dropout: a simple way to prevent neural networks from overfitting. Journal of Ma-chine Learning Research 15, 1929–1958.55177617771778Stricker, M.A., Orengo, M., 1995. Similarity of color images, in: IS&T/SPIE’s Symposiumon Electronic Imaging: Science & Technology, International Society for Optics andPhotonics. pp. 381–392.1779Szabo, T.L., 2004. Diagnostic ultrasound imaging: inside out. Academic Press.178017811782178317841785178617871788178917901791179217931794179517961797179817991800180118021803180418051806180718081809Sze-To, A., Tizhoosh, H.R., Wong, A.K., 2016. Binary codes for tagging x-ray images viadeep de-noising autoencoders, in: Neural Networks (IJCNN), 2016 International JointConference on, IEEE. pp. 2864–2871.Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Vanhoucke,V., Rabinovich, A., 2015. Going deeper with convolutions, in: Proceedings of the IEEEConference on Computer Vision and Pattern Recognition, pp. 1–9.Tabesh, A., Teverovskiy, M., Pang, H.Y., Kumar, V.P., Verbel, D., Kotsianti, A., Saidi,O., 2007. Multifeature prostate cancer diagnosis and gleason grading of histologicalimages. IEEE Transactions on Medical Imaging 26, 1366–1378.Tamura, H., Mori, S., Yamawaki, T., 1978. Textural features corresponding to visualperception. IEEE Transactions on Systems, Man, and Cybernetics 8, 460–473.Tang, L.H.Y., Hanka, R., Ip, H.H.S., 1999. A review of intelligent content–based indexingand browsing of medical images. HIJ 5, 40–49.TCIA, . The cancer imaging archive. http://www.cancerimagingarchive.net/. Ac-cessed October 23, 2016.Tian, G., Fu, H., Feng, D.D., 2008. Automatic medical image categorization and anno-tation using lbp and mpeg-7 edge histograms, in: 2008 International Conference onInformation Technology and Applications in Biomedicine, IEEE. pp. 51–53.Jim´enez-del Toro, O.A., Cirujeda, P., Cid, Y.D., M¨uller, H., 2015. Radlex terms and localtexture features for multimodal medical case retrieval, in: Multimodal Retrieval in theMedical Domain. Springer, pp. 144–152.del Toro, O.A.J., Foncubierta-Rodriguez, A., G´omez, M.I.V., M¨uller, H., Depeursinge, A.,2013. Epileptogenic lesion quantification in mri using contralateral 3d texture com-parisons, in: International Conference on Medical Image Computing and Computer-Assisted Intervention, Springer. pp. 353–360.Tourassi, G.D., Harrawood, B., Singh, S., Lo, J.Y., Floyd, C.E., 2007. Evaluation ofinformation-theoretic similarity measures for content-based retrieval and detection ofmasses in mammograms. Medical Physics 34, 140–150.Trzcinski, T., Lepetit, V., 2012. Efficient discriminative projections for compact binarydescriptors, in: European Conference on Computer Vision, Springer. pp. 228–242.56181018111812181318141815181618171818181918201821182218231824182518261827182818291830183118321833183418351836183718381839184018411842184318441845Unay, D., Ekin, A., 2011. Dementia diagnosis using similar and dissimilar retrieval items,in: 2011 IEEE International Symposium on Biomedical Imaging: From Nano to Macro,IEEE. pp. 1889–1892.Vincent, P., Larochelle, H., Lajoie, I., Bengio, Y., Manzagol, P.A., 2010. Stacked denoisingautoencoders: Learning useful representations in a deep network with a local denoisingcriterion. Journal of Machine Learning Research 11, 3371–3408.VISCERAL, . Visual concept extraction challenge in radiology. http://www.visceral.eu/benchmarks/retrieval2-benchmark/. Accessed October 23, 2016.Wan, J., Wang, D., Hoi, S.C.H., Wu, P., Zhu, J., Zhang, Y., Li, J., 2014. Deep learningfor content-based image retrieval: A comprehensive study, in: Proceedings of the 22ndACM international conference on Multimedia, ACM. pp. 157–166.Wan, Y., Long, F., Qu, L., Xiao, H., Hawrylycz, M., Myers, E.W., Peng, H., 2015. Blast-neuron for automated comparison, retrieval and clustering of 3d neuron morphologies.Neuroinformatics 13, 487–499.Wang, J., Kumar, S., Chang, S.F., 2012. Semi-supervised hashing for large-scale search.IEEE Transactions on Pattern Analysis and Machine Intelligence 34, 2393–2406.Wang, J., Li, Y., Zhang, Y., Wang, C., Xie, H., Chen, G., Gao, X., 2011a. Bag-of-featuresbased medical image retrieval via multiple assignment and visual words weighting. IEEETransactions on Medical Imaging 30, 1996–2011.Wang, J., Liu, W., Kumar, S., Chang, S.F., 2016. Learning to hash for indexing big dataasurvey. Proceedings of the IEEE 104, 34–57.Wang, J., Xiao, J., Lin, W., Luo, C., 2015. Discriminative and generative vocabularytree: With application to vein image authentication and recognition. Image and VisionComputing 34, 51–62.Wang, X., Yang, M., Cour, T., Zhu, S., Yu, K., Han, T.X., 2011b. Contextual weighting forvocabulary tree based image retrieval, in: 2011 International Conference on ComputerVision, IEEE. pp. 209–216.Weiss, Y., Torralba, A., Fergus, R., 2009. Spectral hashing, in: Advances in NeuralInformation Processing Systems, pp. 1753–1760.Wolterink, J.M., Leiner, T., Viergever, M.A., Iˇsgum, I., 2015. Automatic coronary cal-cium scoring in cardiac ct angiography using convolutional neural networks, in: Interna-tional Conference on Medical Image Computing and Computer-Assisted Intervention,Springer. pp. 589–596.Wu, G., Kim, M., Wang, Q., Gao, Y., Liao, S., Shen, D., 2013. Unsupervised deep featurelearning for deformable registration of mr brain images, in: International Conference onMedical Image Computing and Computer-Assisted Intervention, Springer. pp. 649–656.57184618471848184918501851185218531854185518561857185818591860186118621863186418651866186718681869187018711872187318741875187618771878187918801881Wu, G., Kim, M., Wang, Q., Munsell, B.C., Shen, D., 2016. Scalable high-performanceimage registration framework by unsupervised deep feature representations learning.IEEE Transactions on Biomedical Engineering 63, 1505–1516.Xing, F., Yang, L., 2016. Robust nucleus/cell detection and segmentation in digital pathol-IEEE Reviews in Biomedicalogy and microscopy images: a comprehensive review.Engineering 9, 234–263.Xue, Z., Long, L.R., Antani, S., Jeronimo, J., Thoma, G.R., 2008. A web-accessiblecontent-based cervicographic image retrieval system, in: Medical Imaging, InternationalSociety for Optics and Photonics. pp. 691907–691907.Yu, G., Yuan, J., 2014. Scalable forest hashing for fast similarity search, in: Multimediaand Expo (ICME), 2014 IEEE International Conference on, IEEE. pp. 1–6.Yu, X., Zhang, S., Liu, B., Zhong, L., Metaxas, D., 2013. Large scale medical image searchvia unsupervised pca hashing, in: Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition Workshops, pp. 393–398.Zhang, F., Song, Y., Cai, W., Depeursinge, A., M¨uller, H., 2015a. Usyd/hes-so in thevisceral retrieval benchmark, in: Multimodal Retrieval in the Medical Domain. Springer,pp. 139–143.Zhang, S., Metaxas, D., 2016. Large-scale medical image analytics: Recent methodologies,applications and future directions. Medical Image Analysis 33, 98–101.Zhang, S., Yang, M., Cour, T., Yu, K., Metaxas, D.N., 2012. Query specific fusion forimage retrieval, in: Computer Vision–ECCV 2012. Springer, pp. 660–673.Zhang, S., Yang, M., Cour, T., Yu, K., Metaxas, D.N., 2015b. Query specific rank fusionfor image retrieval. IEEE Transactions on Pattern Analysis and Machine Intelligence37, 803–815.Zhang, X., Dou, H., Ju, T., Xu, J., Zhang, S., 2016a. Fusing heterogeneous featuresfrom stacked sparse autoencoder for histopathological image analysis. IEEE Journal ofBiomedical and Health Informatics 20, 1377–1383.Zhang, X., Liu, W., Dundar, M., Badve, S., Zhang, S., 2015c. Towards large-scalehistopathological image analysis: Hashing-based image retrieval. IEEE Transactionson Medical Imaging 34, 496–506.Zhang, X., Liu, W., Zhang, S., 2014. Mining histopathological images via hashing-basedscalable image retrieval, in: 2014 IEEE 11th International Symposium on BiomedicalImaging (ISBI), IEEE. pp. 1111–1114.Zhang, X., Xing, F., Su, H., Yang, L., Zhang, S., 2015d. High-throughput histopathologicalimage analysis via robust cell segmentation and hashing. Medical Image Analysis 26,306–315.58188218831884188518861887Zhang, X., Zhou, F., Lin, Y., Zhang, S., 2016b. Embedding label structures for fine-grained feature representation, in: The IEEE Conference on Computer Vision andPattern Recognition (CVPR).Zhou, J., Feng, C., Liu, X., Tang, J., 2012. A texture features based medical image retrievalsystem for breast cancer, in: Computing and Convergence Technology (ICCCT), 20127th International Conference on, IEEE. pp. 1010–1015.59