Artificial Intelligence 132 (2001) 39–103Computer Go: An AI oriented surveyBruno Bouzy a,∗, Tristan Cazenave ba Université René Descartes (Paris V), UFR de mathématiques et d’informatique, C.R.I.P.5, 45,rue des Saints-Pères, 75270 Paris Cedex 06, Franceb Université Paris 8, Département Informatique, Laboratoire IA 2, rue de la Liberté,93526 Saint-Denis Cedex, FranceReceived 4 May 2000; received in revised form 21 November 2000AbstractSince the beginning of AI, mind games have been studied as relevant application fields. Nowadays,some programs are better than human players in most classical games. Their results highlight theefficiency of AI methods that are now quite standard. Such methods are very useful to Go programs,but they do not enable a strong Go program to be built. The problems related to Computer Go requirenew AI problem solving methods. Given the great number of problems and the diversity of possiblesolutions, Computer Go is an attractive research domain for AI. Prospective methods of programmingthe game of Go will probably be of interest in other domains as well. The goal of this paper is topresent Computer Go by showing the links between existing studies on Computer Go and differentAI related domains: evaluation function, heuristic search, machine learning, automatic knowledgegeneration, mathematical morphology and cognitive science. In addition, this paper describes boththe practical aspects of Go programming, such as program optimization, and various theoreticalaspects such as combinatorial game theory, mathematical morphology, and Monte Carlo methods. 2001 Elsevier Science B.V. All rights reserved.Keywords: Computer Go survey; Artificial intelligence methods; Evaluation function; Heuristic search;Combinatorial game theory; Automatic knowledge acquisition; Cognitive science; Mathematical morphology;Monte Carlo methods1. IntroductionSince the beginning of AI, mind games, such as Checkers [114,115] or Chess [121],have been studied as application fields for AI. Nowadays, some programs are better than* Corresponding author.E-mail addresses: bouzy@math-info.univ-paris5.fr (B. Bouzy), cazenave@ai.univ-paris8.fr (T. Cazenave).0004-3702/01/$ – see front matter  2001 Elsevier Science B.V. All rights reserved.PII: S 0 0 0 4 - 3 7 0 2 ( 0 1 ) 0 0 1 2 7 - 840B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–103human players in most classical games: Deep Blue in Chess [4,67], Chinook in Checkers[117,118], Logistello in Othello [25], Victoria in Go-moku [3]. These results highlight theefficiency of AI methods that are now quite standard.These methods are very useful to Go programs. However, by themselves, they donot enable the AI community to build a strong Go program. The problems related toComputer Go require new AI problem solving methods. Given the abundance of problems,and the diversity of possible solutions, Computer Go is an attractive research domainfor AI. Prospective methods of programming the game of Go will probably be of interestin other domains—for example tree search in classical games is related to AND-ORtree solving, theorem proving, and constraint satisfaction. The current cornerstone ingame programming is the Alpha-Beta algorithm. It was discovered in the early stages ofAI research, and has been regularly improved ever since. Computer Go programmers arestill looking for their cornerstone, which will certainly be more complex than for othergames. The Computer Go community has reached an agreement on some unavoidablelow level modules such as tactical modules, but specialists still disagree on some otherimportant points. Future programs will probably use the best of all the current possibilities,and link them together in a harmonious way.The goal of this paper is to present Computer Go by showing the links between existingstudies on Computer Go and different AI related domains: evaluation function, heuristicsearch, machine learning, automatic knowledge generation, mathematical morphology andcognitive science.To show where the difficulty of Go programming lies, it is first necessary to comparethe game of Go to other classical games in a conventional way. In Section 2, we showthat the combinatorial complexity is much higher in Go than in other two-player, completeinformation, games. We also point out that the evaluation of a position can be very complex.Therefore, unlike other games, Section 3 shows that Go programs have poor rankings inthe human ranking system and deals with the results obtained when computers competeagainst human players and when computers play against other computers.As usual with computer games, we introduce the architecture of a Go program. Weexamine: the evaluation function, in Section 4; move generation, in Section 5; and treesearch, in Section 6. After expounding the key concepts of the evaluation function, basedon numerous concepts and viewpoints, we focus on the relationships between tree searchand the evaluation function. Tree search is used, both to find a good move in using theevaluation function, and to perform tactical computations useful to calculate the evaluationfunction.However, the architecture of a Go program is not composed of these two parts alone.The notion of abstraction plays an important role in Go, and Go programs exhibit structureat different levels, the highest level being the strategic level, and the lowest level being thetactical level. In order to be competitive, every level of a Go program has to be optimized.Therefore Go programmers spend much of their time on optimizations. In Section 7, wepresent some examples of possible optimizations at different levels of abstraction.In Section 8, closely related with mathematics, we examine combinatorial gametheory [43], which deals with games as the sum of independent sub-games. The game ofGo is a global game that can be broken down into many local sub-games. Although localsub-games are generally dependent, this theory offers an appropriate model for the gameB. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–10341of Go. More precisely, the strategic level of a program may represent each tactical gameby a combinatorial game. This theory is better applied to the end of the game, when localsub-games become independent, and it enables the calculation of the value of the very lastmoves of the endgame with greater accuracy. In some positions devised to illustrate thistheory, some programs play better than the best professional players. The major currentdifficulty in applying this theory to other sub-games of Go arises from the high dependencebetween local sub-games.A problem inherent in Computer Go is that the models with the best results use a lot ofknowledge. This need for knowledge makes machine learning, and automatic generationof knowledge, attractive. The best method to obtain an average Go program very rapidlyis undoubtedly the temporal difference method. Some symbolic approaches have alsobeen tried, in an attempt automatically to generate tactical knowledge. The two symbolicmethods which yield good results are retrograde analysis of small patterns, and logicmetaprogramming. By using them, a large number of tactical rules can be generated forthe tactical levels of a Go program. We present the different methods that automaticallygenerate Go knowledge in Section 9.In Section 10, we present a surprisingly effective technique that works quite well for Go:Monte Carlo Go. This technique uses hardly any Go knowledge. However, a very simpleprogram, using this technique, beats classical, and much more complex, programs on smallboards (9 × 9).The game of Go is a very visual game. Since the beginning of Computer Go, manymodels of influence have been set up. We provide a formalization of these models withsome classical operators of mathematical morphology, in Section 11.Go is so complex that it can be used to perform interesting cognitive experiments, withina formal setting imposed by the rules of the game. Section 12 centers on the studies carriedout on Go, using a cognitive approach.The material used in this survey is based on existing Computer Go publications andon the authors’ own experience of writing Go programs. Unfortunately, programs whoseauthors do not describe their algorithms and, furthermore, keep them secret, do notexplicitly appear in this survey. Nevertheless, for the strongest commercial programsin this category, we tried to gather some personal communications that were sent tothe Computer Go mailing list. We could then mention these programs, and give shortdescriptions of them. We also base descriptions of the main components of this surveyon our own experience of writing Go programs: Indigo [15,17,18,20,21], Gogol [28–30]and Golois [32–34]. We think that Computer Go remains a new domain for computerscience, and so far, no clear theoretical model has emerged. The domain greatly benefitsfrom studies based on practical experiments. For instance, the Evaluation Function sectionmainly refers to the Indigo program, and the Automatic Knowledge Generation section toGolois. Nevertheless, we do not limit our descriptions to these programs, and enlarge uponthem using the relevant Computer Go publications.We choose not to include the rules of the game of Go in this paper. If the reader wishesto know them, he can refer to http://www.usgo.org/resources/whatisgo.html where he willfind the definitions of “intersection”, “stone”, “string”, “liberty”, “atari”, “ko”, “group”,“eye”, “tsumego”, “life”, “death”, “territory”, “influence”, “handicap”, “kyu” and “dan”which are Go concepts used by our paper.42B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–1032. Other games2.1. IntroductionThis section centers on the current achievements in computer implementations of othertwo-player, complete information, and zero-sum, games, which we also call “other games”.Our aim is to show that the game of Go is more complex than these “other games”. First, wefocus on the detailed results for each game. Secondly, we review the theoretical complexityof some of these games. Then we study the space states, and game tree complexity [1] ofthese games, correlate these with the level reached on the human scale. Lastly, we outlinethe complexity of Go.2.2. Results achieved in other gamesIn this paragraph, we choose several games within the class of “other games”: Go-moku,Othello, Checkers, Draughts, Chess, and Shogi. Although it does not belong to this class,we also add Backgammon to our study.Go-mokuGo-moku is the game in which you must put five beads in a row—either horizontally,vertically, or diagonally. Several variants exist depending on the size of the board, and theoptional use of capture rules. The simplest variant (no capture) is worth considering forimplementation as a Computer Game because it is an example of a solved game, since [3]exhibited the winning strategy. Victoria is the best Go-moku program.BackgammonBackgammon is not a complete information game (because the players throw two dice)but the techniques used to program Backgammon are interesting, therefore we include itin our set of other games. The best Backgammon program, TD-Gammon, is a Neural Netprogram, which learned the game only by playing against itself. This program is on a parwith the best human players. It was developed at IBM by Tesauro [127,128,130]. It isclearly stronger than other Backgammon programs and it uses the Temporal Differencealgorithm [125]. As early as 1980, thanks to some lucky throws of dice, a program [11]beat the human world champion Luigi Villa.OthelloLogistello [25] is by far the best Othello program. It is based on a well-tuned evaluationfunction, which was built by using example-learning techniques; on an opening book; andon a selective search. It won numerous computer tournaments. In August 1997, it beat theworld champion Mr. Murakami with a straight win 6–0. But in January 1998, MichaelBuro, its author, decided to work on different challenges.CheckersComputer Checkers met with very early success because. As early as 1959, Samueldeveloped a Checkers program which won against a “strong” Checkers player [114]. ThisB. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–10343program was a learning program. However, it is hard to assess its result because the strengthof the “strong” player is debatable. This program is also described in [115].Since 1988, Jonathan Schaeffer, and several researchers at the Alberta University, havebeen developing the Chinook program [117]. This program is the Computer CheckersWorld champion which played a match against the human world champion, MarionTinsley, in 1992 (4 defeats, 2 wins and 33 draws). Marion Tinsley had been the worldchampion since 1954 and was very fond of Checkers programs. After 6 draws, the 1994series was interrupted because Marion Tinsley was very seriously ill. Then, Chinookcompeted against Don Lafferty in 1994 (1 victory, 1 defeat and 18 draws), and in 1995(1 victory and 31 draws). Ever since, Chinook has been considered as the world champion,both in the human, and in the machine categories. Chinook uses an endgame database,with all the positions containing fewer than 8 pieces. Chinook uses parallelism, an openingbook, and an extended Checkers knowledge base. A complete history of this developmentcan be found in [118].DraughtsThe best Draughts program is Dutch. Its name is Truus, and it can be ranked at a nationallevel. New programs (Flits 95 and Dios 97) are now threatening Truus. Flits 95 won thelatest two Dutch Computer Draughts championships, although Truus did not participate inthe most recent tournament.ChessShannon [121] showed that computer Chess was a good problem for AI to solve becauseof the cleverness of its rules and the simplicity of the winning goal. For Shannon, thisproblem was neither too simple nor too difficult. Since then, intensive research has beendone, and the paradigm is clearly tree search, and Alpha-Beta [4]. In 1988, Gary Kasparov,the world champion, claimed that a computer had no chance of beating him before theyear 2000. At that time, Deep Thought—IBM hardware and software—had in fact only aninternational Grandmaster rating. Deep Thought was using tree search with Alpha-Beta.It was exploring about 500,000 positions per second [67]. In May 1997, Deep Blue—themassively parallel descendant of Deep Thought—beat Kasparov with a score of 3.5–2.5. Itwas also using Alpha-Beta, but exploring around one billion positions per second. Giventhe popularity of Chess, and the increasing use of computers in everyday life, this successmade a strong impression on everybody. Moreover, experiments in Chess have establisheda correlation between tree search depth, and the level of the resulting program.ShogiAfter the success obtained in Chess, the game of Shogi, or Japanese Chess, was, and stillis, the next target for Computer Games [84]. Its complexity is greater than the complexityof Chess because of the possible re-introduction, on the board, of previously capturedpieces. The branching factor is about 100 in Shogi, as against 35 in Chess. The position isvery difficult to evaluate. The best program [143] uses a variant of iterative deepening treesearch, and can be ranked at an average level on the human scale.44B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–1032.3. Theoretical complexityWhen discussing the complexity of games, it is necessary to mention published resultsabout the theoretical complexity of games. Checkers [109] and Go [110] are exponentialtime complete, as a function of the size of the board. Fraenkel and Lichtenstein [54]have shown that playing a perfect strategy in n by n Chess requires exponential time.Lichtenstein and Sipser [82] have shown that Go is polynomial-space hard. Thesetheoretical results show that Go seems to be even more complex than Checkers and Chess,because these two games have not been proved polynomial-space hard.2.4. Space states and game tree complexity of other gamesBy taking the complexity of games into account, a very good classification of two-player,complete information, zero-sum, games has been established by Allis [1] and van den Heriket al. [63]. This section briefly sums up this classification. Allis [1] defined the space statescomplexity (E) as the number of positions you can reach from the starting position, andthe game tree complexity (A) as the number of nodes in the smallest tree necessary tosolve the game. For a given game, it is possible to compute these numbers accurately butapproximations may provide useful information. Allis gave rough estimations of E and Afor each game, as shown in Table 1. In this table, ‘>’ (respectively ‘>=’, and ‘< <’) mean “isstronger than” (respectively “is stronger than or equal to”, and “is clearly weaker than”).‘H’ represents the best human player.At first glance, Table 1 shows a correlation between game complexity, and the resultsobtained by computers on the human scale. Chinook and Logistello are clearly betterthan the best human player, in Checkers and Othello respectively. Deep Blue has a ranksimilar to the best Chess player, and Handtalk is clearly weaker than the best humanGo players. All these games have increasing complexity. The classical model may besaid to consist of the set: evaluation function, move generation, and tree search. This hasbeen used successfully in Chess, Othello and Checkers. Its relative success depends on thecomplexity of the game to which it is applied. One can observe a correlation between agame’s complexity, and a program’s results on the human scale. This correlation can beexplained by the fact that the same model is being applied to similar games with differentcomplexities.Table 1GameCheckersOthelloChessGolog10(E)log10(A)Computer–human results1730501603258123400Chinook > HLogistello > HDeep Blue >= HHandtalk < < HB. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–10345Table 2GameCheckersOthello9 × 9 GoChess15 × 15 Go-moku19 × 19 Go2.5. Complexity of Golog10(E)log10(A)Computer–human results1730405010016032588512380400Chinook > HLogistello > HStrongest Go program < < HDeep Blue >= HThe game is solvedStrongest Go program < < HIt is important that the previous correlation be re-evaluated with respect to Go. First, theclassical model cannot work in Go without major adaptations. Moreover, we now add twoother games—9 × 9 Go and 15 × 15 Go-moku—to elaborate Table 2.We can see that, on the one hand, 15 × 15 Go-moku is complex by Allis’ standards,and yet Allis’ program succeeded in solving this game. On the other hand, 9 × 9 Go isless complex than Chess by Allis’ standards, but the 9 × 9 programs are still weak whencompared with human players. 1 The complexity–result correlation has vanished, and thisis difficult to explain. Of course, one might argue that Computer 9 × 9 Go has not beenstudied enough because of the limited interest that 9 × 9 Go enjoys compared to Chess.We do not share this viewpoint—9 × 9 Go is an obstacle for the computer because there iscomplexity inherent in the Evaluation Function.For other games, like Othello, Checkers and Chess, good solutions have already beenfound, using the classical model. To program these games, there is no reason to change themodel, which consists in an effective tree search, using a simple move generation heuristic,and a simple evaluation function. With Go, however, researchers have to look for a newmodel that enables programs to overcome the complexity of the game. They must reversethe model, focus on the complexity of the evaluation function, and on move generation,and only use tree search for verification.3. ResultsThis section contains the results achieved by Computer Go since 1960. It first traces thehistory of Computer Go, and then deals with the current competitions between programs.In a third part, confrontations between man and machine are examined, and lastly we focuson the results obtained with sub-problems of the game of Go such as Tsume-Go and lateendgames.1 It is difficult to determine which program is the best on 9×9 boards, because of the lack of 9×9 competitions.Nevertheless, Go4++ is at the top of the 9 × 9 Computer Go ladder on the Internet.46B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–1033.1. History of Computer GoIt seems that the first Go program was written by D. Lefkovitz [81]. The first scientificpaper about Computer Go was published in 1963 [106], and it considered the possibility ofapplying machine learning to the game of Go. The first Go program to beat a human player(an absolute beginner at that time) was the program created by Zobrist [147,149]. It wasmainly based on the computation of a potential function that approximated the influence ofstones. Zobrist made another major contribution to computer games by devising a general,and efficient, method for hashing a position. It consists of associating a random hash codewith each possible move in a game, the hash of a position being the XOR of all the movesmade to reach the position [148]. The second thesis on Computer Go is Ryder’s [111]. Thefirst Go programs were exclusively based on an influence function: a stone radiates influ-ence on the surrounding intersections (the black stones radiate by using the opposite valuesof the white stones), and the radiation decreases with the distance. These functions are stillused in most Go programs. For example, in Go Intellect [36–38], the influence is propor-tional to 1/2distance, whereas it is proportional to 1/distance, in Many Faces of Go [50,51].Since the early studies in this field, people have worked on sub-problems of the gameof Go—either small boards [133,134], or localized problems like the life and death ofgroups [7].The first Go program to play better than an absolute beginner was a program designedby Bruce Wilcox. It illustrates the subsequent generation of Go programs that used abstractrepresentations of the board, and reasoned about groups. He developed the theory of sectorlines, dividing the board into zones, so as to reason about these zones [105,137]. The useof abstractions was also studied by Friedenbach [55].The next breakthrough was the intensive use of patterns to recognize typical situationsand to suggest moves. Goliath exemplifies this approach [13].State-of-the-art programs use all these techniques, and rely on many rapid tacticalsearches, as well as on slower searches on groups, and eventually on global searches. Theyuse both patterns and abstract data structures.Current studies focus on combinatorial game theory [70,90], learning [30,48], abstrac-tion, and planification [65,107,108], and cognitive modeling [15].The eighties, saw Computer Go become a field of research, with internationalcompetitions between programs. They also saw the first issue of a journal devoted toComputer Go, as well as the release of the first versions of commercial programs. In thenineties, many programs were developed, and competitions between programs flourished,being regularly attended by up to 40 participants of all nationalities [53]. An analysis of thecurrent state of the Computer Go community has been published by Martin Müller [93].3.2. Computer Go competitionsThe oldest international Computer Go competition is the Ing cup. It has been organizedevery year from 1987 until 2000. The winner of the Ing cup plays against young talentedGo players (see Section 3.3 below). Year 2000 was, unfortunately, the last year for theIng competition. A lot of programs were attracted to a recent competition, the FOSTcup, which takes place every year in Tokyo (except for 1997, when it was in Nagoya).B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–10347Table 3Winners of Ing cupsTable 4Winners of FOST cupsYear19951996199719981999WinnerHandtalkHandtalkHandtalkHandtalkKCC IgoYear19871988198919901991199219931994199519961997199819992000WinnerFridayCodanGoliathGoliathGoliathGo IntellectHandtalkGo IntellectHandtalkHandtalkHandtalkMany Faces of GoGo4++WuluOther competitions, like the Mind Sport Olympiad, the European, and the American,championships, are organized on a regular basis.The winners of the Ing cups and FOST cups are shown in Tables 3 and 4, respectively.As well as the competitions, there is a permanent Internet Computer Go tournament—the Computer Go ladder (http://www.cgl.ucsf.edu/go/ladder.html). It is a “handicap”ladder; where the number of handicap stones that each participant can give to theimmediate lower program is explicitly tracked. Whenever the author of a program feels thathis program has been improved, he can issue a challenge, either to the program below (toincrease the number of handicap stones), or to the program above (to decrease the numberof handicap stones). New programs can join the ladder by challenging the program on the“bottom rung” (no handicap). If the new program wins the challenge, it can successivelychallenge higher programs until it loses. It can then start playing handicap challengesto determine its exact ranking. Challenges are normally played on the IGS (Internet GoServer, http://igs.joyjoy.net/) or NNGS (No Name Go Server, http://nngs.cosmic.org/). IGSand NNGS provide any Go player in the world with an opponent to play games with, aswell as the opportunity to watch games, or comment on them, at any time. They are similarto world wide Go clubs. Of course, Go programs may get an account. Many Faces of Go,and GnuGo, are very often connected to these servers.3.3. Programs versus human playersIn addition to the confrontations that are organized every year, after the Ing cup, otherconfrontations are organized, in an attempt to understand better the strengths and weak-nesses of the programs. For example, after each FOST cup, the three best programs playagainst human players. Handtalk received a Japanese 3rd Kyu diploma for winning its48B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–103games. However, an opponent who knows the weaknesses of a program can use this knowl-edge to win easily. For example, during AAAI-98, Janice Kim beat Handtalk, despite anenormous handicap of more than twenty stones. Recently, Martin Müller beat Many Facesof Go, despite a huge handicap of twenty-nine stones. Although Go programs have beenimproved over the last few years, they are still much weaker than human players.3.4. Tsume-GoMost Go programs have Tsume-Go problem solvers. Some other programs areentirely dedicated to Tsume-Go. The best Tsume-Go problem solver is Thomas Wolf’sGoTools [140,142]. GoTools is a very strong Tsume-Go problem solver. It can solve 5-danproblems (an amateur 5-dan is roughly equivalent to a professional 1-dan Go player). Ithas even spotted an error in a dictionary of Tsume-Go problems. It can analyze complexsituations completely, and find unique winning moves that Go players find with greatdifficulty. The problem solver has been used to generate thousands of Tsume-Go problems.GoTools relies on Alpha-Beta searching, search heuristics, and numerous hand-coded,and tuned, patterns for directing search, and for evaluating positions. Many heuristics usedin GoTools, including forward pruning, are well described in [142]. However, GoTools isrestricted to completely enclosed problems that contain thirteen or fewer empty intersec-tions [141]. This restriction makes GoTools of little use for programs that play the entiregame, and for Tsume-Go problems that are to be solved in real games.3.5. Combinatorial game theoryIn some late endgame positions of the game of Go, where combinatorial game theoryapplies, Wolfe’s program finds a sequence one point better than the sequence found byprofessional players [8,9]. Müller’s [94] is another demonstration of the power of com-binatorial game theory applied to Go endgames. It shows how Decomposition Search, atree search algorithm based on combinatorial game theory, gives clearly better results thanAlpha-Beta, when applied to specific endgame positions. Combinatorial game theory hasalso been used by Howard Landman to find the number of eyes of a group [79], thus en-abling a program to break down a life and death problem into a sum of games, so as toreduce its complexity. Furthermore Müller [95] described a method for modeling “fights”in Go, and computing their game values.4. Evaluation4.1. IntroductionThis section deals with the major difficulty of Computer Go—building the EvaluationFunction (EF). The evaluation of a position is necessary for a program that wants toassociate a score with a game. Finding a “good” EF is very hard, and is undoubtedly thebiggest obstacle in Computer Go. Whenever Chess programmers—very confident in thepower and generality of tree search methods, and willing to try their chance in anotherB. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–10349game—ask Go programmers, very innocently, to give them the EF of Go, they are verysurprised to see that Go programmers cannot provide them with a simple, clear, andefficient EF, as is the case in Chess. Instead of tree search optimizations, it is the discoveryof the EF for the game of Go that is the main task of Go programmers. Of course, each Goprogrammer has their own EF. Every EF results from intensive modeling, programming,and testing activities. Consequently, each EF is different from every other one, and noagreed model has clearly emerged in the community. Therefore the task of presenting a GoEF is far from being easy.To be as clear as possible, we choose to proceed in two steps. First, we focus on the ideathat comes naturally to the new Go programmer’s mind—the concrete EF. It is simple,and quick, but very inefficient when integrated into tree search algorithms. Then, we showthe conceptual EF of a Go program. More precisely, we choose to present the conceptualEF of the program Indigo [15,17]. This has two advantages. First, it is clear—because weare the programmers of this EF. Secondly, it works—since it is actually integrated into aplaying program that regularly attends the current Computer Go tournaments. To simplifythe reader’s task, we focus only on the main features of this EF. We have intentionallyhidden those parts which are needed to make the EF work in practice, but which are notrequired for an overall understanding. We mention other formal descriptions, such as thebest programs’ ones [14,36,39], when they have been published. Given that most program-mers wish to keep their algorithms secret, descriptions of the best commercial programsare scarce. They are often personal communications [41,52,103,138,139].4.2. Concrete evaluationThe first idea consists of defining a concrete EF by giving one value to each intersectionof the board: +1 for black intersections, and for empty intersections with black neighboringintersections only; −1 for white intersections, and for empty intersections with whiteneighboring intersections only; 0 elsewhere. Obviously, this EF cannot be simpler.Explicit-control and implicit-control endgame positionsIn Fig. 1 the intersections are explicitly controlled: an intersection controlled by onecolor has the property of either having one stone of this color on it, or the impossibility ofputting another color stone on it. Such a position is reached after a large number of moves,and the two players may have agreed on the control of the whole board a long time before.Fig. 2 shows a board where the game stops earlier. In this position, the control is implicit.Human players stop playing in this kind of implicit-control position. When considering thepositions that belong to the set of explicit-control endgame positions, the concrete EF givescorrect results, and is quickly computed. Unfortunately, this EF is relevant to positions ofthis set only.When considering implicit-control endgame positions, this concrete EF gives erroneousresults because human players use a large amount of knowledge to recognize themas controlled. The knowledge contained in the concrete evaluation is not sufficient torecognize them as terminal positions. For example, the empty intersections in the bottomright of Fig. 2, and the “isolated” white stone in the same figure are considered as belongingto Black by almost all Go players. Clearly, the concrete EF gives a false evaluation for50B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–103Fig. 1.Fig. 2.Table 5Implicit-control endgame depthExplicit-control endgame depth9 × 960160Board size13 × 1319 × 19120340250720them, and the knowledge necessary to explain why these intersections belong to Blackwould take too long to explain.But, one should see whether this concrete EF could be used, within a tree searchalgorithm, so that the EF is invoked in explicit-control endgame positions only. Let usdefine the depth of a position as the distance between the root node of the game tree andthe node of the position. Because human players stop their games on reaching agreementon implicit control, the length of games between human players gives a rough estimateof the depth of implicit-control endgame positions on different board sizes. In addition,a program using the concrete EF, and playing against itself, enables us to estimate thedepth of explicit-control endgame positions. Computer experiments show that the averagedepth of explicit-control endgame positions is twice the board size. These estimates aresummarized in Table 5. Although the concrete EF can be computed very quickly, moderncomputers cannot complete searches down to this depth with the branching factor of Go.As we are again confronted with the combinatorial obstacle, we must give up this approach.Then, the next step is to try tree search with a conceptual EF. This EF will enable theprogram to evaluate some positions at every stage of the game (in particular the set ofimplicit-control endgame positions). Of course, because of the numerous possibilities, thenext obstacle is the definition of this EF. Anyway, this approach is used by the best currentGo programs.B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–10351Fig. 3.4.3. Conceptual evaluationA worthwhile approach to finding a conceptual EF is to observe human players, to cap-ture the useful concepts, and to transform them into computational ones. Some impor-tant human concepts may be equated with their expressions inside game commentaries orGo books. The main Go terms are “group”, “inside”, “outside”, “territory”, “interaction”,“life” and “death”. Other important concepts, such as “inversion” and aggregation” corre-spond to computational tasks, and we also present them. To illustrate our description, weuse Fig. 3.We present the useful concepts in a bottom-up fashion. We start with small shapes whichenable the program to build abstract groups, and we end up with the whole EF. First,we show topological concepts such as “connected group”, then we show morphologicalconcepts such as “territory”, “influence”, “morphological group”, “inside” and “outside”.Finally, we show the concepts of “interaction”, “life” and “death”,together with“inversion” and “aggregation”. These concepts will allow us to finish the presentation withthe full conceptual EF. Fig. 3 is used as a reference point to show examples of the differentconcepts presented in this section.“Connected group”In this paragraph, the goal is to define “connected group”. The rules of the game definestrings of stones as same-colored 4-connex sets (one intersection has up to 4 neighbors),but, in fact, “connected groups” are what players reason about.Let us consider two neighboring strings of the same color. Two tree searches may beperformed (one search with Black playing first, and another search with White playingfirst—see “Tree Search” or “Combinatorial Game Theory” sections of this paper) to52B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–103Fig. 4.Fig. 5.Fig. 6.Fig. 7.Fig. 8.Fig. 9.Fig. 10.determine whether these strings are virtually connected or not. When two strings arevirtually connected, they belong to the same “connected group”.In Fig. 4, the two black strings are virtually connected. Even if White plays first, Blackwill be able to connect (see Fig. 5). If Black plays first, the two strings will obviously beconnected. Fig. 4 is called a “connector”. Its notation will be ‘>’, so as to indicate thatthe outcome of this elementary game is an effective connection whoever plays first. Moregenerally, two strings sharing two liberties are also part of the same connected group [36,38] because if one player plays on one of them, the other player plays on the other one.The two black strings in Fig. 6 are also virtually connected, as proved by the sequenceof Fig. 7. (White 3 is a forced move because White 1 is in “atari” after Black 2.) Fig. 6 isanother example of connector ‘>’.Fig. 8 is not a connector, as previously described. If White plays first (Fig. 9), thetwo black strings are actually disconnected by White 1 and White 3. If Black plays first(Fig. 10), the two black strings are connected because Fig. 10 equals Fig. 4. In this case(Fig. 8), the final state of the connector depends on who moves first, and we give thevalue ‘*’ to the connector.Then, the “connected groups” are defined as groups of strings linked with connectors ‘>’.In our example, our program recognizes the connected group of Fig. 11.A very important point to underline here is the fact that the construction of connectedgroups implies the use of results from local tree searches having the goal of connection.We will take up this point in the “Tree Search” section of this paper because this is specificto the game of Go: the EF uses Tree Search. This is one important aspect of the EF in Go.B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–10353Fig. 11.Fig. 12.“Inside”, “outside” and “morphological group”The concepts “group”, “territory”, and “influence” are very closely linked to mathe-matical morphology. We warmly invite the reader to refer to the “Mathematical morphol-ogy” section of the paper so as to be familiar with some mathematical morphology opera-tors [120], and with the operators X and Y used in this paragraph.Let B (respectively W ) be the set of black (respectively white) intersections of theGo board. The “morphological groups” are the connected sets of X(B) and of X(W ).Let G be a given morphological group. First, we call S(G) the “skeleton” of G as thesubset of G with intersections of the same color as G. Then we define the “inside” of G,In(G), as the set G − S(G). Lastly, we call Out(G) the “outside” of G, and define it as theset Y (S(G)) − G.All these operations lead to a morphological view of positions. Fig. 12 shows themorphological view of our example (Fig. 3). The big dark (respectively light) greysquares correspond to the “insides” of black (respectively white) morphological groups,and the small dark (respectively light) grey squares correspond to the “outsides” of black(respectively white) morphological groups. The stones correspond to the skeletons.54B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–103The building of groupsThe notion of “group” is of paramount importance in modeling a Go position. For humanplayers, the notion of group corresponds neither to the connected group notion nor to themorphological group notion, but to a certain extent to both notions. For programs, thequestion of knowing which notion is better remains an open problem. Besides, decidingwhich is the better notion, is a matter of integration within the whole program [14,36,50,51].The connected group notion may be used because the connection patterns betweenstones can be demonstrated by tree searches. But this notion also raises diverse questions.First, the program’s response time may be excessive because of the number of local treesearches that have to be completed to determine the existence of connectors. Nevertheless,this may be speeded up by using patterns, but then the problem is how to handle the patternsdatabase. Some learning techniques may be used to foster the expansion of the patternsdatabase. We shall discuss this point in the “Automatic knowledge generation” section ofthis paper. Furthermore, another problem linked to the connected group notion is the factthat the connection concept is given undue value. Thus, we might obtain a program whichsystematically connects its groups before doing anything else.However, the morphological group notion may also be chosen because it is moreintuitive, quicker to compute, and more remote from the connection notion. Unfortunately,it is accurate only in some quiet positions. Therefore tree searches using this notion mustreach these quiet positions, if they are, to provide significant results. The more powerfulthe computer is, the more successful it will be in reaching these quiet positions.Go4++ uses another idea for building groups: instead of using connection whose valuesare game-like values: >, *, <, it uses a probability value for each connection and builds aconnection map.Number of “eyes”The “inside” of a given group is crucial to the life of the group. Its vital contribution isassessed by counting the number of “eyes” of the inside. The number of eyes depends onwho plays first. When an inside has more than two eyes, it is alive. For each connected setof the inside, the vital contribution depends on its possibility to be split into other connectedsets. On the whole, for size-one-two-or-three connected sets, the number of eyes dependson its boundary, and opponent stones. For sizes from four to about six, it also depends on itsshape and on the shape of prisoners. For example, Go players say that “straight 4 is alive”and “square 4 is dead”. For size bigger than about six, the number of eyes becomes greaterthan two. Each Go program must contain such expertise in counting eyes of a connectedset. It is very difficult to define complete and adequate rules for determining the number ofeyes of groups. Most of the current Go programs use heuristic rules. The most complete andrecent description of these rules are described in a reference paper [39] by Chen and Chen,the authors of two of the best Go programs, Handtalk and Go Intellect. Landman’s [79] isa combinatorial game approach study of eyes. Benson’s [7] is a mathematical study of reallife without alternating play.Furthermore, the heuristic rules must be computed quickly. Therefore, Go programssometimes use tricks. For example, one heuristic rule says that a connected set whoseexterior has a length smaller than 6 has zero or one eye, and when greater than 10, hasB. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–10355Fig. 13.Fig. 14.Fig. 15.two eyes at least [14,39]. After assessing the number of eyes of each connected set, theproblem is to count the number of eyes of the whole group. When the connected sets ofthe inside are not dependent on one another Chen and Chen [39] provide a clever methodusing binary trees. Each connected set of the inside is a binary tree whose leaves containthe number of eyes, depending on who plays first. The group side selects a binary tree andreplaces it by its left sub-tree. The opponent selects a binary tree and replaces it by its rightsub-tree and so on. The group side wants to maximize the number of eyes whereas theopponent wants to minimize it. This abstract minimax search is simpler and faster than aregular one on a concrete board.“Interaction”A group has friendly and opposing neighbors. For each couple of opposing groups,“interaction” expresses the possibility for one group to dominate the other. The evaluationof interaction between two opposing groups is determined by a set of rules whoseexpression is very complicated and domain-dependent. Therefore, we shall limit thepresentation of an interaction to a single example as simple as possible. Let us examine theblack group in the middle right-hand side of the example of Fig. 3 (this group correspondsto Fig. 13) and the white group located just above (see Fig. 14).These two groups are opposing, their number of eyes and the size of their outside are notsufficient. Therefore, we consider these groups as “weak”. It is important for the programto compare the number of liberties of each weak group. In our example, the white group hasfour liberties, and so has the black group. The player who plays first will either delete one ofhis opponent’s liberties, or give more liberties to his own group, or do both. The differencebetween the number of liberties of the two groups will be crucial in deciding which groupdominates the other. When the value (relative to zero) of the interaction depends on whoplays first, its value is designated ‘*’. Such is the case in our example. When one groupdominates the other whoever plays first, the interaction is ‘>’ for the dominating color.For example, the interaction between the black group (corresponding to Fig. 15) which islocated at the bottom right of the position of Fig. 3, and the big white group encirclingit, is ‘>’ for White. In the next paragraph, we shall see that this fact will contribute to the“death” of this black group.“Death”, “inversion”, aggregationThe next important point consists of detecting dead groups—this constitutes the maindifference between the concrete EF and the conceptual EF. An error in the judgementof life and death of one group brings about tremendous consequences in calculating thevalue of the EF. Exact conditions for the death of a group should be given, or when this isimpossible, very restrictive conditions should be given to the program. In such conditions,56B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–103Fig. 16.the program must not conclude that a group is dead when it is not. A “death” happenswhen a group answers all the following conditions: its number of eyes is not big enough;its outside is not big enough; it has no friendly group to connect with; it has no interactionwith an opponent group whose value is different from ‘<’.In our example, the group in Fig. 15 fulfils all these conditions. Therefore, it is “dead”.On the contrary, the two weak groups in Figs. 13 and 14 have an interaction whose valueis ‘*’. They are not dead.Once a group is dead, an “inversion” happens: the dead group changes its colorand merges with its neighbors. Fig. 16 shows the conceptual description followingthe inversion, consequent upon the death of the black group in the bottom rightcorner.Here, the black group has disappeared, becoming part of a big new white group that islocated in the bottom edge. After an inversion, the program performs an aggregation tocluster the dead group with its opponent groups into a bigger group.SummaryHaving identified the basic tools, we are now able to describe the general form of aGo EF:While dead groups are still being detected, perform the inversion and aggregationprocesses.Return the sum of the value of each intersection of the board (+1 for Black, and −1for White).At the end of a loop, if a death is detected, the program inverts and aggregates the deadgroup to give birth to a new group. If no death is detected, the loop ends and the programcomputes the addition of the value of each intersection of the board. (+1 if the intersectionB. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–10357has a black group on it, −1 if the intersection has a white group on it, and 0 in the othercases.)Each loop gives rise to one, or zero, dead groups. Successive loops are necessary todetect several dead groups. The evaluation process may alter the life and death status ofgroups previously examined in response to new information determined in later cycles ofthe evaluation process.“Life and death” of groups, “tsumego”. . .We have just seen the building process of an EF. However, human players also use theterms “life” and “death”. Furthermore, they call the question of determining whether agroup is dead or alive, a “tsumego” problem. It is now time to link these human terms withthe previous discussion of concepts of our EF.Let us first provide a few precise definitions. On the one hand, a general tsumegoproblem arises when a group is weak by our standards. (This means that the number ofeyes, and the “outside” of the group, are not sufficient, and that the group has no interactionwhose value is not equal to ‘<’.) Such problems consist of finding a solution with thefollowing varying parameters: number of eyes of the inside, outside, and interactions.On the other hand, basic tsumegos are problems where the outside and the interactionsare attached to insufficient values, hence the basic tsumego problem consists of finding asolution to make only one parameter vary: the inside of the group.Consequently, it can be easily understood that there is a considerable gap between thetwo categories of tsumego. General tsumego problems are far more complex than the basicones. Nowadays, GoTools solves basic tsumego problems at dan level very smartly, andquickly. (Here, basic does not necessarily mean simple: a lot of basic tsumego problemscan be situated at a professional level.) Chen and Chen [39] give a set of heuristic rulesto count the number of eyes of the inside of a group. However, Go playing programs arenot efficient enough to solve general tsumego problems, and unfortunately these problemsare the ones that are frequently met in actual games. The inability of Go programs to solvethese general tsumego problems constitutes the major obstacle to Computer Go.4.4. ConclusionIn this section, we have dwelt on the simple case of the concrete EF. This EF cannot beused within tree search because of the very small subset of positions in which it givescorrect answers: the explicit-control endgame positions subset. Then we presented theconceptual EF. We highlighted the main features of an EF in Go: “group”, “inside”, “eye”,“outside”, “interaction”, “life” and “death”. In spite of our effort to describe this function assimply as possible, it remains quite complex. The first reason is to be found in the conceptof “group” which is crucial to Go and has many variants. The Computer Go community stillholds different views on its definition. The second reason lies in the difficulty in definingintuitive, and visual, concepts such as “inside” and “outside”. Another explanation is thevery marked importance of interaction between groups. It is very difficult to determinethe state of a group without considering its surroundings. Lastly, as regards tree search, aunique feature of an EF in Go is that it uses local tree searches. This aspect is new whenconsidering the other two-player, zero-sum, and complete information games where tree58B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–103search simply uses the EF. The setting up of an efficient, correct, and complete, EF is themajor difficulty inherent in Computer Go.5. Move generation5.1. IntroductionSection 2 showed that a full global search was not possible in Go, and Section 4 pointedout the complexity of the EF. However, the aim of a game playing program is neitherto search within trees nor to evaluate boards—these two activities are only means. Theaim is to generate moves, and to select only one. Therefore, after leaving tree search andEF aside, the first trend in Computer Go was to generate moves by giving them a “priority”or “urgency”, and then to select the move with the highest priority. The first Go programslooked like expert systems which had neither evaluation nor tree search. That was the rightapproach to try at that time, within such a complex domain [81,105]. Section 5.2 shows thatMove Generation (MG) still occupies a special place in current Go programs. In Section5.3, we show the relevance of Goal Generation (GG). Then we present some examples ofMG associated to specific goals in Section 5.4, and we illustrate global MG, with the helpof another example, in Section 5.5.5.2. The specific position of MG in current Go programsTo help MG in the first Go programs, two other components were necessary: an EF tostop playing at the end of the game correctly; and a tree search module to check the tacticalstatus of some local sub-positions, or to find the biggest global move. Therefore, the crucialquestion is to know the position of MG in connection with the EF and tree search. The EFof a position is complex, and uses a lot of knowledge to describe the abstract objects whichare on the board. It is appropriate to try extending this knowledge, beyond descriptionsof objects to the description of actions, or moves, performed on the objects. In such acase, the evaluation helps MG, and applies to both positions and moves. This approach isused in contemporary Go programs—for example in Go Intellect [37], and also in Shogiprograms [60]. In this case, MG of Go programs is still very important.5.3. Goal GenerationMoreover, when the programmer makes more extensive use of knowledge to describemoves, he naturally enters the domain of Goal Generation. Instead of generating moves,the program first generates the goals which may prove useful in winning the game. Oncethe goal has been selected, a specific evaluation function adapted to this goal is chosen,and a specific move generator is associated with this goal. A goal-oriented approach hasthe advantage of reducing the complexity of the problem to be solved, but the drawbackmay be the lack of global balance when more than one goal is relevant to winning thegame. Current programs such as Go Intellect [37,38], Goliath [14], and Many Faces of Gouse such a goal-oriented approach. Other explicit goal-oriented studies in Go are [55,65,66,B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–10359108]. Decisive goals to be generated in a position are: “occupy big empty points”, “kill”,“live”, “attack”, “defend” “groups” [38], “expand”, “reduce”, and “invade” “territories”.Furthermore, the sub-goals may be “make eyes”, “destroy eyes”, “connect”, “cut groups”,“capture”, “save strings”, and so on. [52] proposes a hierarchy of goals, which can be usedto build a Go program. For each goal, or sub-goal, the program generates special moves,and performs goal-oriented tree search.5.4. Goal-oriented MGThis subsection provides an example of moves generated according to the context ofgoal-oriented MG. Let us consider the position in Fig. 3 and to its evaluation shown byFig. 16. The evaluation identifies three “weak” groups: the middle left white group, the topright black group, and the top right white group. It also identifies territories to be expandedor reduced: the bottom white territory, the middle left black territory, and the top blackterritory. Each “weak” group, and each territory, generates goals to be pursued: attack ordefend a “weak” group; expand or reduce a territory.Expanding/reducing territoriesMG is quite simple in such a case. A program has a pattern database suggesting movesaccording to this goal. Let us assume the database has the patterns shown in Figs. 17–20.Let ‘X’ be the good move, and ‘Y’ the bad one. Then the MG generates the moves ofFig. 21 for expanding or reducing the territories.Fig. 17.Fig. 18.Fig. 19.Fig. 20.When such generated moves are used, tree search allows one to select the bestexpanding/reducing move. In the case of territory, when assuming that the depth-onepositions are still quiet, tree search selects the “best” expanding/reducing move. However,in actual cases, depth-one positions are not necessarily quiet. Therefore, evaluations ofterritory are not significant, and a quiescence search must be performed [40]. Instead ofperforming tree search to select one move, another possibility is to refine the patterns forexpanding/reducing territory by specializing them as much as possible, and to associateeach of them with a value to be used by the move selector. In such cases, the programselects the generated move with the best value. The approach of knowledge refinement isperformed manually in most Go programs, when their authors are strong Go players wholike introspection. However, this difficult refinement task can be achieved by the computeritself. This aspect will be discussed in the “Automatic Knowledge Generation” section.60B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–103Fig. 21.Fig. 22.Attacking/defending groupsThe other relevant goal-oriented MG is the attack and defense of groups. A programcontains a pattern database suggesting moves relevant to this goal. Let the database containthe patterns of Figs. 17–20, plus a rule advising to capture/defend the strings which belongto the group, and whose Conway’s state is ‘*’ (see Combinatorial Game Theory section).The generated moves are those of Fig. 22.B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–10361Move ‘C’ is generated by the rule advising to save the white string whose state is ‘*’,and belonging to the middle left white group. Other moves are generated by the patterndatabase. Beyond this simple example, Go programs contain many more complex patterns.For instance, the move generation is not symmetrical, and the pattern must also specifywhich stones of the pattern belong to the “weak” group. A very good description of attackand defense in Go Intellect can be found in [38]. In this section we have presented onlysimple rules. In fact, rules are more complex in current Go programs: rules may advise aset of moves for each side; they may contain information about the number of liberties ofthe string; or they can make use of logical expressions.5.5. Global MGThis subsection illustrates an example of moves generated at the global level. Wekeep the example of Fig. 16. We assume that the global level considers only the twokinds of goals described in the previous subsection: “expanding/reducing territories” and“attacking/defending groups”.First, in a Go program that, for speed performance, avoids tree search, the previousMG may be used simply to provide a priority to each goal. For each goal, this prioritymay be proportional both to the size (or size variation, in the case of territory) of theobject associated with the goal, and to a factor specific to the goal class. Therefore, a veryrough and simple method consists in selecting the move with the highest priority, whichis associated with the goal with the highest priority. This move decision process suffersfrom a lack of coherence because the program does not verify whether the selected moveactually achieves its goal or not.In our example, we assume that the priority of group is significantly higher than thepriority of territory. In such a case, the program decides to attack/defend the middle leftwhite group. Then, assuming that the rule which advises saving the string whose state is ‘*’,has a higher priority than the patterns’ priority, the program chooses to play move ‘C’.This method may be sharper with the help of a goal-oriented Tree Search so as toeliminate the ineffective moves. For example, move ‘C’ will not work for White and theTS will select ‘A’ or ‘D’. TS may eliminate all the moves of the goal-oriented MG. Inthis case, the goal is unreachable. For instance, if the program is strong enough, it maywant to defend its white group and check that the moves ‘A’, ‘C’, ‘D’ do not reach thegoal. Therefore, the program will switch to the top right fight, and try moves ‘E’, ‘F’, ‘G’.Another TS will conclude ‘E’ and ‘G’ are good moves to select at the global level.5.6. ConclusionThe previous description of MG is similar to the plausible move heuristic, which is well-known in computer games, together with selective search. It was used in the early days ofComputer Chess [58]. It is currently used in Computer Shogi [60,69,144], and it will still beused for a long time in Computer Go. An explicit contribution to MG in Go is the referencepaper [37], which describes the move decision process of Go Intellect, and fits very wellwith the above description. Like other programs, Go Intellect contains about 20 movegenerators. Most of them are goal-oriented and heuristic. A “move coordinator” combines62B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–103all the values by using linear combinations dynamically determined by the status of thegame. A “move checker” is provided to avoid obvious errors in the choice of candidatemoves. If a candidate move has a significantly higher value than the other ones, and ifit passes the move checker, then it is selected without look-ahead. But, when they areseveral highly recommended candidate moves, Go Intellect uses global look-ahead onthese candidate moves, and selects the best one. Once more, the example of Go Intellectshows how important static MG is. In some cases, MG may be sufficient to select the movewithout global tree search, or, in other cases, sufficient to order the moves for tree search.6. Tree search6.1. IntroductionThis section describes the link between Computer Go and Tree Search (TS). In classicalgames like Chess, the goal of TS is to find a move among many moves, using an EF asa black box. Numerous publications deal with this problem, and study the well-knownminimax and Alpha-Beta algorithms, as well as their variants [10,26,73,76,124]. A recenttrend has favored new approaches, such as the conspiracy numbers approach [83,116], andproof-number search [2]. Computer Go follows this trend. But in Go, TS is completelydifferent because of the importance of locality. Until now, few methods have emerged. Thefundamental issue in Computer Go TS is selectivity. Section 6.2 deals with the differentTS methods used in current programs, and Section 6.3 focuses on the new parameters of TSin Go.6.2. Current use of tree searchTo begin with, let us give the relevant information related to TS in the currentGo programs (Handtalk, Many Faces of Go, Go4++, Go Intellect, and GoAhead).Handtalk generates very few (about 4) moves at the global level, and performs onlylittle tree search. Handtalk’s author believes that there are many more important thingsthan TS [42].The author of Many Faces of Go underlines that his program has multiple TSengines [52]: capturing a string, connecting two strings, making an eye, making a groupdead or alive, performing a global quiescence search. An important feature is that TS givesa degree of reliability concerning the result of the search.Michael Reiss says that Go4++ tries about 40 candidate moves, evaluates the score foreach move, and plays the move with the highest value [103].Ken Chen [40] has recently given some heuristics that enable his program, Go Intellect,to perform an efficient global selective search. His first heuristic consists in cutting off thesearch at quiescence, returning the value of the evaluation function for stable positions inthe global game tree. The second one is to cut off search when a target value is reached.The last heuristic is to associate an urgency value with a move, and to take this value intoaccount when evaluating the position. The author concludes that a balanced combinationof global selective search, and decomposition search [94] may well be the best approach toComputer Go.B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–10363Peter Woitke [138] says that his program does not calculate variations except for stringcaptures, life and death, and endgame positions.6.3. Main featuresIn this section, we depict the main features of TS in Go, concentrating on the featuresthat make TS in Go different from TS in other games. To us, the most important elementis locality, since all moves in Go are played at a precise location on the board—in otherwords, an intersection. We shall later examine other features, such as the goal of TS, thedefinition of terminal positions, the initiative, abstraction, the dependency between localsituations, and finally uncertainty. All these features are linked to TS.LocalityGiven the size of a board, searching by selecting the moves localized on a part of theboard only is called a local TS. It is very similar to what human players do when theyexamine different sequences of moves, at different places on the board, in a separate,and independent, way. Local TS is a kind of selective search. It is an approximation ofthe usual TS, which is called global TS. In practice, owing to current computer power,global TS, unlike local TS, cannot be completed, and local TS becomes mandatory.Even with greater computer power, a brute-force global search would not be an efficientapproach. There are too many clearly sub-optimal, or even bad, moves in a Go position.A detailed analysis of a position can eliminate many useless moves. A goal-oriented globalsearch, or the splitting of the search into different local searches, are two options whichmay be worth considering. Splitting the game into sub-games was proved to be useful inthe endgame, when used with decomposition search [94]. Applying this technique to themiddle game is a promising, but difficult, research area.However, several obstacles arise when using local TS. First, the locality criterion hasto be defined. The problem of defining the ‘distance’, that discriminates between a ‘near’move and a ‘far’ move, is open. Each Go program employs its own distance. It dependson the data structures chosen in the program. Apart from problem in defining distance,the second obstacle is to know when to stop the local TS. Unfortunately, a local TS oftengoes beyond its departure point. This happens when all the local moves have been played,and when the local situation is still uncertain and, therefore, impossible to evaluate. Inpractice, the search has to be stopped. Consequently, the result of a local TS containssome uncertainty. The last problem in using local TS is in the reconstruction of theglobal result, given the results of local TS. To address this issue, the program simplifiesthe problem by assuming that they are relatively independent of each other. Althoughthis hypothesis is wrong in theory, it is essential to make this assumption if we are toget results. Assuming independence between local situations, the game of Go can beconsidered as a sum of independent sub-games. It makes global TS look like a set oflocal TS. Conway’s combinatorial game theory gives some clues for dealing with localresults. One of the most popular strategies among programs is based on thermographs (seethe section on combinatorial game theory). It consists of playing in the ‘hottest’ local game.This particularity of Go is also used in decomposition search [94] that drastically reducesthe size of the global search.64B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–103In short, locality allows TS to obtain a result otherwise impossible with a uniqueglobal TS. Current difficulties linked to the locality criterion relate to the definition ofa good distance, the criterion for stopping a search, the specification of a measure ofuncertainty in the result of search, and the evaluation of the global result once the results oflocal search are obtained. To circumvent these obstacles, formulating the hypothesis aboutthe independence between local games makes it possible to use Conway’s combinatorialgame theory.Use, and goal, of tree searchIn classical game programs, TS calls EF at the terminal nodes of the tree. In Go, EFis complex and its value relies on the state of the board’s abstract elements. Moreover,knowledge of the state of these elements relies on the results of local and abstract TS.So, EF uses the results yielded by some TS. The usual order—whereby TS calls EF, asin Chess—is reversed in Go. TS, which was the user in Chess, also becomes the supplierin Go. Unlike in Chess, the precision of the result of EF in Go makes it necessary to performtactical TS, so as to find the state of the elements of the evaluation (connections, eyes, lifeand death of groups, etc.). Here again, the goal of TS in Go is not, as in Chess, to select amove, but to prove the value of a situation.Problems specific to Minimax search in GoMüller [96] identifies difficulties specific to Minimax search in Go: recognizing terminalpositions, pass moves, and local position repetitions, or ko. In Go, a position is terminal ifno more points are contested, and all points can be classified as black, white, or neutral.Such classification is hard because of the complexity of the evaluation. A terminal position,and a non-terminal position, may be very similar. In Go, passing is legal, and pass movesmust be generated during search. In positions where there is no good move, players areallowed to pass instead of damaging their position. Adding pass moves to a tree search,increases the size of the search space. Global position repetitions are forbidden by the rules,but a local tree search must cope with local position repetitions, or ko. A local repetitionis produced by the possibility of playing outside the local position at any time during thesearch. Ignoring the possibility of ko gives misleading results.InitiativeGiven the multiplicity of local situations, either one player or the other can play first in agiven local situation. To cope with this property, current programs are required to performat least two TS on a given local situation, the initiative being taken each time by a differentplayer. We can indicate that a local situation is described by two TS, using a notation suchas {B | W} where B (respectively W) is the situation found if Black (respectively White)plays first. When the opponent does not answer to a move in a local situation, but ratherplays in a different local situation, the player can play a second move in a row in the firstlocal situation. There is a possibility that a player may play multiple moves in a row onthe same local situation. So, theoretically, multiple TS should be performed. In practice,current Go programs do not consider all these possibilities that increase computationtime. The combinatorial game theory that takes these problems into account is used asa reference. Recently some progress has been made in the safe cutting of combinatorialB. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–10365game trees [71]. This improvement is comparable to the improvement of Alpha-Beta overMinimax, and is a breakthrough in the computation of the mean, and the temperature ofcombinatorial games in which there is a dominant move at each stage.Abstraction and local tree search with a goalWe have shown that the locality criterion reduces the global evaluation to a sum of localevaluations, thus greatly reducing the complexity of the corresponding TS. But, to avoidcombinatorial explosion, the Computer Go programmer can also use abstraction in additionto locality. Rather than locally evaluating a position, the program can first identify a typedlocal goal—for example the connection of two strings, or the life of a group—and thenperform a TS with this goal. It reduces the complexity of the EF, as it only takes threevalues (‘0’ if the goal cannot be achieved, ‘1’ if the goal is achieved, ‘?’ in other cases).The EF is therefore rapidly computed. For a lot of typed local goals—such as connection,eyes, and life and death of completely encircled groups—the corresponding TS is achievedin a short time, and the program has certainties that are better than the non-terminationof the local evaluation TS. Moreover, the three-value EF enables the program to use theProof-Number Search algorithm, which generally obtains better results than Alpha-Beta.However, it is impossible to obtain these abstract results without the inherent counterpartto abstraction: simplification, and consequently inaccuracy.Fig. 23 gives an example of a proof tree for the goal connect. Black is the friendly color,and the goal is to connect the two black stones. The first move works (the leftmost arrow)and, as it is an OR node, the other branches are cut. The moves at the OR nodes are givenby rules terminating on moves that can achieve the goal if two moves are played in a row bythe friendly color. This heuristic is used because these moves lead to positions containingthreats of winning by the friendly player, and therefore forced moves for the other player.The rules of Fig. 24 indicate the moves to try at the OR levels of the proof trees. Thisis visually explained in the first diagram of Fig. 24, where a tree is represented with thecolor of the moves associated to the branches. The only available information is that Blackcan reach the goal if it plays two moves in a row (state W of the first diagram). Otherwise,Fig. 23.66B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–103Fig. 24.Fig. 25.the three other combinations lead to unknown situations (state U). When Black plays themoves advised by the rule, it switches to a threatening situation, represented by the treeon the right of the first diagram. Black can now win the goal if it plays one move, andtherefore White now has to play to prevent Black from doing so.The first rule of Fig. 24 is used to find the upper left move of the proof tree of Fig. 23.Black plays on a liberty of the right black string; this liberty is neighboring a liberty of theleft Black string. So, if Black plays another move on the liberty of the left Black string,the left and the right Black strings will be connected. The second rule of Fig. 24 advisesa move to threaten to make an eye, if Black plays another move on the empty lower rightintersection, it will then make an eye.Fig. 25 gives the second proof tree developed by the Go program when White plays first,and searches with the goal “Disconnect the two black stones”. In order to save space, wehave numbered the sequences of moves at the leaves of the tree (odd numbered moves areblack moves, and even numbered moves are white, single forced, moves). The two forcedwhite moves—at the root of the proof tree—are refuted by Black. As a result of the twoproof trees, Black can connect its two stones even if White plays first: the two black stonesare virtually connected.B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–10367Fig. 26.The last rule of Fig. 26 is used to find the forced move at the lowest AND node ofFig. 25. The first rule of Fig. 26 is used to find the two forced moves at the root of the prooftree of Fig. 25: these two moves are the only ones to be considered out of all the possiblemoves. The second rule is used to find the only possible forced move to prevent an eye.The visual definition of a forced move is given in the first diagram: a White move leads toan unknown state (state U), whereas a Black move leads to a lost state for White (a loststate L for White is a winning state W for Black: White loses if Black is connected in ourexample).Dependency/independence of local situationsSome local situations are highly dependent on one another—a move can influence twolocal situations simultaneously. A local TS cannot be reduced to finding a good move, butalso has to take into account all the answers to the first move. Otherwise, the global movechoice will rely on incomplete information. At the top of the local TS, all the moves haveto be played. The dependency of neighboring local situations also implies the existence ofmoves that do not work in any situation, but that are threats for each of them. These movesenable the player to change one of the situations, thereby they are proved to be efficient.A good program should be able to find them.UncertaintyGiven the complexity of local situations, numerous local TS terminate without findingthe good move, or proving the goal. The results of the local TS remain uncertain. Theglobal level of the program has to handle the uncertainty of the non-terminated TS. Thereare many ways to represent, and use, uncertainty in Go programs. For example, Gogol [30]represents the uncertainty about the result of a game using a taxonomy of games. Themost general game is ‘U’—its value is unknown whoever plays first. A ‘WU’ game is agame where one player can win the game if he plays first, and the result is unknown ifthe other one plays first. A ‘WU’ game is a sub-class of the U games. ‘UL’ games can bedefined similarly. Other sub-classes of games can be defined such as ‘WUUU’ or ‘WL’.This representation of uncertainty in games is useful to describe the elementary sub-games68B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–103of the game of Go such as the game of capturing a string, the game of making an eye, thegame of connecting two strings, and so on. Indigo [18] also represents uncertainty in itsevaluation function using the local uncertainties identified in the local fights. Many Facesof Go uses a confidence degree for the result of an evaluation during its TS.6.4. Which algorithms?To perform searches, some already existing techniques can be used, each offeringits advantages and drawbacks, depending on the context of the TS. For connection, orTsume-Go, problems, a three-value evaluation function can be used, as well as Proof-Number Search (PN-Search) [2]. The drawback of PN-Search is the time used to copypositions, and the memory required to store them. For all the problems with uncertainties,quiescence search algorithms [6] are recommended. Other TS can use Alpha-Beta. Depth-First search, which offers the advantage of looking at positions in such an order that theresults of the evaluation of the former position can be reused in order to evaluate the currentposition rapidly. The incrementality principle (see the optimization section) can be used.At depth zero, a local TS has to consider all the moves, so that the global TS can detectthose moves that may help achieve two goals simultaneously. The game of Go, as a sumof games, shows that programs need both to perform an efficient TS, and to know how touse its results. Combinatorial game theory solves some of the problems that arise whencombining the results of multiple TS (see the Combinatorial Game Theory section).Many heuristics can be used when developing search trees. Thomas Wolf [142] givessome heuristic search techniques used in GoTools. For example, at each node of the searchtree, the relevant moves are tried, and their usefulness is then evaluated. Other heuristicsconsist in giving low priorities to moves that are forbidden for the opponent, in trying asthe second move the move of the opponent that has refuted the first move. Some heuristicsto improve global search are given by Ken Chen [40].6.5. ConclusionIn this section, we have shown the specificity of tree search in Go. We have identifiedmany important features of tree search: locality, strong links with the evaluation function,initiative, abstraction, dependency, and uncertainty. Computer Go enriches the classicalparadigm of tree search with new viewpoints. Moreover, the large branching factor ofGo calls for clever selective search techniques, either in tactical search (GoTools), or inglobal search (Go Intellect). An increase in computer power will not allow an efficientbrute force global search. The special properties of the game of Go make selective [40],and decomposition search [94], much more efficient than brute force global search.7. Optimization7.1. IntroductionAs in other games, the speed of a program is of paramount importance in the gameof Go. Even if current problems are mainly linked to a good modeling of the Go player, itB. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–10369is still very important to do a fast tactical search, and to use knowledge efficiently, to havea competitive Go program. Computer Go optimization techniques range from very lowlevel considerations, like the raw representation of the board, to high level considerations,like the use of abstract strategic representations, so as to choose which search trees todevelop. Some mid-level optimizations are also used—for example calculations of thesearch dependencies, can indicate whether, or not, to recalculate the search tree, if the moveplayed does not modify its result. Optimizations are time-consuming for the programmer.Section 7.2 presents some possible optimization for pattern matching. Section 7.3 givessome hints on how to stop tactical search early. Section 7.4 deals with the ordering ofthe different loops, and tests that occurs in both manually, and automatically, generatedGo programs. Section 7.5 is about the choice of search algorithms. Section 7.6 explainshow to optimize the operators of mathematical morphology. Section 7.7 sheds light on theoptimization of string capture. Section 7.8 details the use of incrementality, and, finally,Section 7.9 says a word about high level optimizations.7.2. Pattern matchingThe representation of the patterns, and the board to match the patterns on, is a problemthat every Go programmer has to face. The patterns represent small parts of the board. Oneessential property of a string of stones lies in its number of liberties, so that patterns areassociated with conditions on the liberties of strings.Fig. 27 gives examples of some patterns associated with a set of conditions. Thesepatterns represent an eye. Boon described how he optimized the pattern matcher of hisprogram, Goliath [13]. He represented 5 ×5 patterns, and 5 ×5 parts of the board, using 32-bit strings, which enabled the program to perform very fast logical operations on integers tomatch patterns with parts of the board. Other algorithms have been used to optimize patternmatching. For example, the Explorer program uses Patricia trees to match patterns [90].Gogol [34] represents the patterns in one or two 32-bit integer, and performs a binarysearch on its sorted patterns list, so as to match them rapidly.7.3. Stopping search earlyThe patterns and rules are used, both to select possibly interesting moves, and to stopsearch early. The following trees are developed to prove that the two black stones areconnected. The left tree is developed by using only simple rules to find interesting moves,whereas the right tree is developed by using more clever rules and patterns.Fig. 27.70B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–103Fig. 28.Fig. 29.The left tree of Fig. 28 has 31 nodes whereas the right tree has only 7 nodes. In the gameof Go, the overhead of matching simple patterns is largely compensated for by the timegained thanks to search savings. Fig. 29 gives two patterns to cut the right tree. The firstpattern shows that there are only two moves to try at the root of the tree, and the secondone shows that Black can connect the two stones if he plays first.7.4. Ordering the conditions of rulesAnother approach to speed up the use of rule-based knowledge is program transforma-tion. A metaprogram can make a program faster by automatically ordering the conditionsof the rules, or by partially evaluating the rules [28,33]. While reordering conditions isvery important for the performance of rules generated by a metaprogram, it is also im-portant when hand-writing rules for a Go program. The following two rules are simpleexamples that show how important a good order of conditions is.connect(S1, S2, I1) : - color_intersection(I1, empty),color_string(S1, C), color_string(S2, C),liberty(I1, S1), liberty(I1, S2).connect(S1, S2, I1) : - color_string(S1, C), color_string(S2, C),liberty(I1, S1), liberty(I1, S2),color_intersection(I1, empty).B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–10371The two rules give the same results but do not have the same efficiency when I1 isunknown, because there are more empty intersections than liberties of the string S1. Whenbased only on the number of free variables in a condition, reordering does not always workwell. Conditions, and therefore variables, are ordered once only, and not dynamically ateach match, because it saves more time. Reordering the conditions of a given rule optimallyis an NP-complete problem. To reorder conditions in our generated rules, a simple andefficient algorithm can be used. It is based on the estimated number of subsequent nodes,which the firing of a condition will create in the semi-unification tree. Here is a metaruleused to reorder conditions of generated rules:branching( ListAtoms, ListBindVariables,neighbor(X, Y), 3.76) : -member(neighbor(X, Y), ListAtoms),member_term(X, ListBindVariables),non_member_term(Y, ListBindVariables).A metarule evaluates the branching factor of a condition based on the estimated meannumber of facts which match the condition in working memory. Metarules are fired eachtime the system has to give a branching estimation for all the conditions left to be ordered.When reordering a rule containing N conditions, the metarules will be fired N times—the first time to choose the first condition, and at T time to choose the T th condition.In the first reordering metarule above, the variable X is already present in some of theconditions preceding the condition to be chosen. The variable Y is not present in thepreceding conditions. The condition ‘neighbor(X,Y)’ is therefore estimated to havea branching factor of 3.76 which is the mean number of bindings of Y (that is, the meannumber of neighboring intersections of another intersection on a 19×19 grid—this numbercan vary from 2 to 4).The branching factors of all the conditions to be reordered are then compared, andthe condition with the lowest branching factor is chosen. The algorithm is very efficientbecause it orders rules better than programmers do and because it runs fast, even for rulescontaining numerous conditions.7.5. Alpha-Beta or PN-Search: a difficult choiceAnother practical problem lies in the use of an appropriate search algorithm for theproblem at hand. For example, during a tactical search, Alpha-Beta enables the program toreuse the abstract information of the parent node (such as the numbers of liberties, or thelist of adjacent strings), in order incrementally to calculate information about the currentnode, without occupying too much memory. On the contrary, a Best-First algorithm, likeProof-Number Search, uses a lot of memory if incremental information is kept. Moreover,it takes time to copy the information for each node. However, the trees developed withPN-Search are often smaller than the trees developed with Alpha-Beta, because the sub-games of the game of Go have a variable number of moves at each node. The choicebetween these two algorithms depends on the data structures used, and on the sub-gamesat hand. For example, Many Faces of Go uses Alpha-Beta incrementally, and updates the72B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–103liberties of the strings at each move. On the contrary, Gogol uses PN-Search, copies theraw board, and recalculates only the useful sets of liberties at each node.7.6. Dilation and erosionDilation and erosion are crucial operations in a Go program. They are very often usedto calculate liberties, influence, territories, and, more generally, the neighborhood of anobject. Howard Landman uses an optimization to calculate the dilatation and erosionoperations of mathematical morphology. These operations are useful in calculating boththe influence of stones, and their associated territories. To assess dilatations and erosionsrapidly, the board can be represented as a bit string—an erosion corresponds to somestandard bit-string operations: SHIFT and OR.7.7. String captureAn optimization used by Goliath [14] is to put many moves simultaneously in a tacticalsearch. When a given program calculates a ladder, it has to play the same two movesrepeatedly. Goliath plays all the moves at the same time.For example in the left position of Fig. 30, to calculate whether the white stone—markedwith a triangle—in the lower left can be captured, the program tries, first, to play the libertyof the stone that has the greatest number of second order liberties, and secondly, to play onthe other liberty to avoid capture. These same two moves are played repeatedly across theboard until the position in the second diagram of Fig. 30 is reached. Instead of analyzingthe position at each ply and playing the same moves every two plies, the program can beoptimized to go directly to the position of the second diagram of Fig. 30. This optimizationenables the program to save time in 80 percent of the ladders calculated by Goliath. Insteadof analyzing the position for each move of the ladder, Goliath analyzes the position onlyonce.Another optimization, specific to string capture, consists of ordering moves during atactical search. For example, when trying to save a string by playing on its liberties, it isFig. 30.B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–10373usually better to try first the moves on the intersections likely to give the string as manyliberties as possible.7.8. IncrementalityBouzy [20] introduces the concept of the “incrementality” of a tactical search.Incrementality is an example of a mid-level optimization, which aims at associating atactical search with a “track” that represents parts of the board involved in the result ofthe search. If a move is played in the track of an object, then the object must be deleted.If a move is played outside the track of an object, then the object remains unmodified.Whenever a move is played, the program knows which search remains unchanged, andthus saves time. In practice, incrementality of tactical search enables a program to playtwice as fast on a 19 × 19 board. With the track mechanism, the programming task isnicely simplified, but the incrementality problem has become a definition problem. If theprogrammer defines a track bigger than the optimal one, then the behavior of the programremains correct but is slower than it could be. If the programmer defines a smaller trackthan the optimal one, then the program forgets to destroy some objects and the programquickly adopts an erratic behavior. The problem of correctly specifying the tracks of objectsis difficult to solve.7.9. High-level optimizationsAn example of a high level optimization is the use of an abstract strategic representationof the board that allows the program to focus on some important tactical computations, andto neglect useless ones that might be time-consuming [31,66,107,108].8. Combinatorial game theory8.1. IntroductionThis section deals with those basic features of combinatorial game theory which haveso far been useful to Computer Go. The reader may refer to [43] or [64] to have amathematical overview, to [44] for a recreational presentation, and to [8] or [89] for thepractical applications of the theory to Computer Go. These different viewpoints will allowthe novice to understand the surprising differences between this theory and classical gamestheory [136]. Combinatorial game theory is also called Conway’s game theory.8.2. The results of combinatorial game theory when applied to Computer GoThe results of applying the theory to the problem of playing the whole game are few,and limited. However, with specific sub-problems, like late endgame positions, this theoryis highly successful. This section deals with these excellent results, and then points outthe difficulties in extending them to other well-identified concepts of Go—“eyes”, “ko” or“fights”—and to complete games.74B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–103Late endgame positions or “yose”During the endgame phase, it is partly possible to model a position as the sum of games.We list four key features of such a model. The first feature corresponds to the identificationof “groups” and “territories”. As a game nears its end, the identification of “groups” and“territories” becomes easier, and thus, the transformation from the position into a listof sub-games becomes possible. In addition, when moves are played, the identificationof “groups” and “territories” becomes more stable. Stability is our second feature. It isfundamental because, if not verified, the local tree searches in each sub-game wouldbecome pointless. Furthermore, as a game nears its end, the moves played in one sub-game have less influence on other sub-games. Therefore, near the end of the game, thesub-games become independent. Independence of sub-games constitutes the third feature.Besides, as a game nears its end, local searches become shorter. Therefore local searchescan be fully completed and the sub-games described. Completion of tree searches is thefourth feature.Thereby, in positions in which criteria for the use of these four features are fulfilled,Berlekamp and Wolfe have obtained outstanding results. When an abstract descriptionof the positions, in terms of groups and territories, is given to Berlekamp’s model, itfinds moves that have the same result, or even one point more, than professional players’moves [8,9]. This result had a tremendous impact in the Go community because everybodythought professional players were playing the endgame optimally. Berlekamp’s modellucidly demonstrated the contrary. It would take too long to dwell on the mathematicaldetails explaining why the result is so good. In outline, one can simply say thatcombinatorial game theory employs infinitesimal numbers (like up, down and *) whichdescribe the sub-games. They transform themselves into one point when the number ofsub-games is odd. The proof, and the test positions, can be found in [9].This result is correct, of course, when the four sets of criteria are fulfilled, and itshould be capable of being extended to the endgame with the help of more robusttools than Berlekamp’s model. Martin Müller has been working on applying this theoryto Go endgames for several years [89–92]. Müller’s [94] describes DecompositionSearch, which is an algorithm which identifies safe groups, and territories, in a position,finds the sub-games, computes their value, and selects the sub-game. In test positions,Decomposition Search performs much better than a classical alpha-beta. This paper is avery nice demonstration of the power of the combinatorial game theory applied to theendgame in Go.Recently Kao [71] described a method for computing the mean, and the temperature,of combinatorial games, where each player can have only one option at each local non-terminal position. This method is based on the stable theorem, and on the algorithmMT-Search (Mean-Temperature Search). Although the method can be applied to gamesother than Go endgames, MT-Search works very well with endgame positions. Theimprovements in the computation of mean and temperature, due to this method, arecomparable to the improvement of Alpha-Beta over Minimax.“Eyes”After the success in the endgame, mathematicians have investigated other sub-problemsto be found in actual games. Eyes are very useful for life and death problems.B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–10375Landman’s [79] is the reference paper that shows the link between Conway’s theory andthe eye concept of the game of Go.“Ko”Game theory is far more complex in loopy games. A loopy game is a game whose graphcontains loops. In the game of Go, loops are forbidden by the rules, but when you modelthe whole game as a sum of sub-games, its sub-games may be loopy. For a given sub-gamecontaining a “ko”, the first player takes the ko; as the rules do not allow the second playerto take the ko again, he plays elsewhere—in another sub-game. If the first player also playselsewhere with the following move, then the global position has changed, and the secondplayer is now allowed to take the ko in the given sub-game, whose sub-position is the sameas two moves before. Therefore, the given sub-game must be considered as loopy undersuch modeling. Not only does Berlekamp’s model encompass ko, but also studies aboutko and combinatorial game theory classify the different contexts of ko [92]. Spight [122]extended the thermograph theory to process multiple-ko positions.“Fights”Müller [95] described a method for modeling “fights” in Go, and computing their gamevalues. In order to test the validity of the approach, this method was integrated into hisprogram, Explorer, and tested on specific fight positions. The results were very impressive:its system outperformed the current best programs such as Go4++ and Many Faces of Go.This illustrates the power of describing of Go local situations by game values.The whole gameUnfortunately, the conditions for applying Conway’s theory to the whole game arenot fulfilled. In brief, even if you have a sub-games model of the global game, the sub-games are greatly dependent on one another. Each model of a global position into sub-games already contains an approximation. Nevertheless, Conway’s theory is a source ofinspiration to model the game of Go for the computer. This paragraph shows the workaccomplished using this perspective.Goliath [14]—three times world champion in 1989, 1990 and 1991—modeled localsearches with switches. Explorer [89,90] is, by far, the program that uses the theory inthe most efficient way. For example, Explorer contains tools to compute thermographsof games. In addition, Indigo [15] uses Conway’s classification (positive, negative, fuzzyor zero). Unfortunately, local searches in some sub-games cannot be completed, and suchsub-games are placed in the ‘unknown’ category. Furthermore, Gogol [30] does not strictlyfollow this classification. It defines a taxonomy of games. ‘U’ games correspond to gameswhose searches are unknown, or not completed. ‘W’ games correspond to won games,and ‘L’ games to lost games. Then, ‘U’ games can be classified into ‘WU’, ‘WL’, or‘UL’ games. A ‘WU’ game is a game where the left outcome is ‘W’, and its right outcomeis ‘U’, and so on. This classification cannot be justified from a theoretical viewpoint,nevertheless it is preferable to Conway’s in practice, because it takes the unknown sub-games into account and gives results, even when a local search is not fully completed.76B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–1038.3. ConclusionUntil now, classical game theory [136] has been very well adapted to Chess, Checkers,and Othello, but has lacked power sufficient to model the game of Go. Combinatorial gametheory partly makes up for this weak point by giving optimal strategies for playing in somespecific endgame positions [9]. It also gives ideas for defining sub-optimal strategies forplaying the whole game. Before this theory can be used for the whole game, extensiveresearch has to be done. Future researches might focus on the splitting of the global gameinto dependent sub-games (rather than independent ones). In addition, experiments shouldbe carried out which relate to searches that may not end. Needless to say, this theoryremains to be put into practice, and adapted to all phases of the game.9. Automatic generation of knowledgeWriting a Go program is difficult because the most efficient programs use a lot ofknowledge. Consequently, methods that generate Go knowledge automatically offer greatadvantages. Research into automatic generation of knowledge in mind games has mainlyconcentrated on the generation of an evaluation function. However, the evaluation of aposition in the game of Go requires many specific concepts, and extensive reasoning. Asthe game of Go can be divided into subgames, a reasonable goal for knowledge generatingsystems is to generate knowledge for these subgames, and not for the whole game of Go.Knowledge can be generated through various techniques. Neural networks learningcan be used to learn to select good tactical moves with backpropagation, as shown inSection 9.1. With the help of temporal difference methods, it can also be used to learn toevaluate the probability of an intersection becoming territory. In Section 9.2 we will showhow neural networks have learned enough Go knowledge to enable some neural-network-based programs to be competitive. Knowledge is a key component of Go programs—inSection 9.3 we describe the kind of knowledge used in Go programs, and we insist on thedifficulty in acquiring and maintaining it. The problems related to knowledge maintenance,and knowledge acquisition, are partially solved by the declarative learning techniquespresented in Sections 9.4 (retrograde analysis), and 9.5 (logic metaprogramming). Thesetechniques have proved useful in generating many useful tactical rules that increase thetactical problem-solving abilities of Go programs. Some other techniques for patterngeneration have also been tried, such as the ecological algorithm of Kojima [75]—discussed in Section 9.6.9.1. BackpropagationGolem [47] is a program that learns to select tactical moves by using neural networks.Golem starts by doing a tactical search to find the status of strings having three liberties,or fewer—the goal of the search being to find whether, or not, the string can be captured.Golem uses a neural network to discard moves when they are too numerous. The inputsof the neural network correspond to those abstract concepts of the game of Go which arelikely to influence the capture of strings.B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–10377The results of the tactical searches, and some abstract concepts, are used as inputs ofanother neural network. This network is trained on games between professional players.For each position, the goal of Golem is to rank the professional move above another movechosen randomly. After 2000 attempts, it ranks the moves in the test database correctly87 percent of times. Golem has learnt to beat Many Faces of Go at the latter’s low level.9.2. Temporal Differences (TD) learningTD learning has been successfully applied to Backgammon by Tesauro [129]. It mightalso be applied successfully to other games. Two fundamentally different abilities can bedefined in games. The first one is to foresee the likely continuation of a game, either bytree search, or by reasoning. The second one is the ability to assess a position accurately,using patterns and some features of the position, but without calculating explicit move.Backgammon is a suitable game for TD learning because positional judgements are moreimportant. Unlike Chess it does not require the ability to see many moves ahead. Thegame of Go is also played by using a lot of positional judgement, and knowledge aboutthe shape of stones. The application of TD methods to the game of Go has yieldedreasonable results, but Go programs based only on TD learning do not play as well asthe best Go programs. However, the TD method has great potential to improve programsthat already have a lot of knowledge. Two programs have so far used this method for thegame of Go. Chronologically, the first one is the program designed by Schraudolph, Dayanand Sejnowski, the second one—that plays better but relies on more Go knowledge—isNeuroGo by Markus Enzenberger.The program of Schraudolph, Dayan and SejnowskiSchraudolph, Dayan and Sejnowski have applied TD learning to Go in the same way thatTesauro applied it to Backgammon [119]. Their first experiment was to train a completelyconnected 82–40–1 network by letting it play stochastically against itself.As the game of Go is deterministic, moves are chosen stochastically, so as to exploreenough state space. The best moves have an exponentially higher probability of beingchosen than the worse ones. The output of the network learned to forecast the numberof points by which Black or White would win. This network had to play 659,000 gamesbefore beating Wally, the worst public domain Go program. The direct application of TD toGo yields disappointing results in comparison to Backgammon. However, improvementscan be made to enable TD to learn better. These improvements concern the architecture,the inputs, and the output of the network.The first improvement consists of changing the output. The goal of the game of Go isto occupy as much territory as possible. Each intersection occupied by a color, at the endof the game, counts as one point. It is therefore worthwhile to make the network learnthe final destiny of each intersection. It is easier to find the destiny of an intersectionthan the final score. Moreover, the game of Go has properties that make it possible toconstrain the architecture of the network. For example, when colors are reversed, or whena reflection, or a rotation, of the board is performed, the properties of the shape of stonesremain unchanged. Color symmetry is taken into account by giving opposite values tothe inputs for Black and White (+1 for Black, −1 for White), and by putting the bias78B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–103neuron to −1 when White has to play first. Weight adjustments take into account rotationsand symmetries by sharing equivalent weights, and by adding the errors resulting fromdifferent, but equivalent, intersections.The improved network was trained against three opponents: a random move generator,as well as the Wally program (a very weak, and simple, public domain Go program), andMany Faces of Go. The program learned to beat Wally after 2000 games, and Many Facesof Go, at its weak level, by playing 1000 games. Another network playing against itselflearned to beat Wally after 3000 games. To date, these programs have never participated inany Computer Go competitions.The NeuroGo programNeuroGo is a program that uses more elaborate inputs than the former program [48].In NeuroGo too, the goal of learning is to foresee whether an intersection will be friendlyterritory at the end of the game. The input of the network is constituted of units. One unitcan be either an empty intersection, or a string of stones. The architecture of the networkis therefore dependent on the position being considered.Each unit has its own properties. Each string possesses four properties: having 1, 2, 3, 4,or (cid:1) 5 liberties; having 1, 2, 3, or (cid:1) 4 stones; the possibility of being captured if the colorof the string moves first; the possibility of being captured if the color of the string playssecond. The properties of empty intersections are: Black has 1, 2, 3, 4, or (cid:1) 5 libertiesif he plays on the intersection; White has 1, 2, 3, 4, or (cid:1) 5 liberties if he plays on theintersection; Black can be captured if he plays on this intersection; White can be capturedif he plays on this intersection; eye for Black in 0, 1, 2, or (cid:1) 3, unanswered moves; eye forWhite in 0, 1, 2, or (cid:1) 3 moves.In addition to calculating the properties of the units, NeuroGo detects groups of stones(sets of connected strings), and the distances between strings (connectable in one moveor in two moves). It uses this information to link units with weights corresponding to therelations between the units. The set of units of a position is converted into a graph. Thisgraph enables the program to build relations within the neural network. There cannot bemore than one relation between two units. If there is more than one, NeuroGo decideswhich one is the most important, and selects it. Two neurons of adjacent layers thatcorrespond to two units are linked by the weight corresponding to their relation.Neurogo has learned to beat ‘Many Faces of Go’ at an average level (8/20) after 4500games against itself whereas the program by Schraudolph & al. only beat it at a weaklevel (3/20). NeuroGo participates in the Internet Computer Go ladder. It plays on small9 × 9 boards as well as on 19 × 19 boards. It is currently situated in the top third of theladder of Computer Go programs.Conclusion and future workTo learn how to play well against another program, TD based programs have to playthousands of games, but they have a considerable advantage: they do not require much workfrom their programmer (NeuroGo is 5000 lines of C). As often with this type of learning,it is facilitated by the quality of the inputs of the neural network. Such is the case withNeuroGo, which learns better than another program which has only a physical descriptionof the board. An interesting study would be to use the elaborate knowledge of the bestB. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–10379programs as an input of networks trained by TD methods. This might greatly upgrade thelevel of programs. A problem might arise with the learning time, which would be muchlonger than with a simple representation. However, this approach offers the advantage ofhaving the highest ratio Level of the program/Time to develop it.9.3. Knowledge in Go programsKnowledge in Go programs is constituted of specialized procedures to compute somespecific Go concepts, and of pattern databases. The Go knowledge contained in theprocedures ranges from simple concepts, such as the number of liberties of a string, tohigh level ones, such as the safety of a group. Ken Chen, the author of Go Intellect (oneof the best Go programs), provides a good description of the knowledge contained in acompetitive Go program [38]. Go Intellect has 3 types of frames: Blocks (i.e., strings in ourterminology), Chains (sets of strongly connected strings), and Groups (loosely connectedstrings), each with about 30, 10, and 50 slots, respectively. The knowledge of Go Intellect ismade up of the frame updating procedures, of about twenty goal-oriented move generators,and two pattern libraries. A good example of the heuristic rules used to evaluate the lifeand death of a group can be found in [39]. The rules combine patterns, conditions onthe intersections, and exceptions. Approximately forty rules are described in this paper.They rely on other knowledge, such as knowledge about the possibility of connecting astring to an intersection. A typical Go program contains approximately 3000 patterns. Thenumber of patterns in a program is highly dependent on the design, and the architecture, ofthe program. For example, Goemate has only 40 patterns, whereas Golois has millions ofpatterns.Acquiring this specialized knowledge is very difficult. The traditional way for theprogrammer is to add knowledge. The difficulty lies in performing introspection.New knowledge interacts with existing knowledge in unpredictable ways. Whenever aprogrammer tries to improve his program by adding knowledge relating to a particularsub-problem, this new knowledge often interacts with other knowledge in another partof the program, and finally produces bad results. Furthermore, even if the programmer isa very good Go player, he has difficulties in finding rules without exceptions. He ofteninserts new rules, forgetting the exceptions, and produces bad results again.A potential solution to the knowledge acquisition problem is declarative knowledgelearning. Some Go knowledge can be formalized, and can be considered independentlyof other knowledge. The insertion of a new rule into a declarative setting does not interferewith previous knowledge. Moreover, the use of automatic generating techniques produces alarge amount of knowledge, which would take too long to write down for any programmer.The following two subsections highlight these techniques.9.4. Generation of rules using retrograde analysisRetrograde analysisRetrograde analysis has already been used for one-and-two-player games. Given somefinal positions, retrograde analysis enumerates all the positions, and associates them witha value that can be Won, Lost, or Drawn for two players games, as well as with the80B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–103minimal distance to the final position. Well-known results of retrograde analysis are theChess endgame databases [123,131,132], and the Checkers endgame databases of Chinook.The Chess endgame databases have enabled the Chess community to discover new Chessknowledge [98], and they enable programs to play perfectly some endgames that are hardfor human players. The endgame databases of Chinook, for Checkers, have contributed toits world champion title [78,118].For single agent problems, retrograde analysis has been used to reduce the number ofnecessary nodes to solve standard 15-Puzzle problems. The generated database enables theprogram to divide the number of explored nodes by 1000 [45]. Retrograde analysis has alsobeen used to find optimal solutions to Rubik’s Cube [77]. The dynamic creation of patterndatabases has been used as real time learning to accelerate Sokoban problem solving [68].Generation of tactical Go rules by retrograde analysisThe generation of simple patterns by retrograde analysis has been performed for thegame of Go regarding life, eyes, and connection [27,29]. The work has been extendedto tactical rules—in other words, patterns associated with external conditions [34]. Thegenerated patterns (and associated rules) fit in small rectangular shapes (2 × 2 to 6 × 3) thatrepresent parts of the board. The external conditions correspond to constraints on relationswith objects that are outside the rectangle. The possible objects are friendly strings, enemystrings, and empty intersections.Each intersection in a pattern can take on three different values (black, white orempty). An empty intersection can be associated with two different external conditions: theminimum number of liberties a friendly move would have when played on the intersection,and the maximum number of liberties an enemy move would have when played on theintersection. Each string in a pattern can be associated with one condition: the minimumnumber of liberties for a friendly string, and the maximum number of liberties for an enemystring. Each of the external conditions can take on three different values. The three possibleconditions associated to enemy strings are : 0 external liberties, <=1 external liberties, andother (>1 external liberties). The three possible conditions associated to friendly stringsare: 0 external liberties, >=1 external liberties, and >=2 external liberties. Therefore, thereare three possibilities for each string, and nine possibilities for each empty intersection.A pattern that contains two empty intersections on the edge of the pattern and two stringsgenerates 9 × 9 × 3 × 3 = 729 different rules.One can compare the number of rules covered by this representation with the number ofendgame positions in Checkers [78]. There are 406,309,208,481 endgame positions, with8 pieces, in Checkers, whereas the number of possible rules in a 5×3 rectangle in the centerof a Go board is 59,241,069,331,995. The number of possible patterns is much lower, asthere are at most three possible values for each intersection of a pattern (Friend, Enemy,and Empty). Therefore there are 315 possible patterns for a 5 × 3 rectangle pattern in thecenter. Table 6 provides the total number of possible patterns and rules corresponding tothe size of the pattern and its location.The algorithms used to generate these rules are slightly different from those used togenerate endgame databases.Usually, when one generates a pattern database, or an endgame database, only one ortwo bits are used to code each element (these two bits are used to code one of the threeB. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–10381Table 6Size of thepatternLocationTotal number ofpossible patternsTotal number ofpossible rules2 × 23 × 24 × 23 × 35 × 24 × 36 × 25 × 33 × 24 × 23 × 35 × 24 × 36 × 23 × 45 × 33 × 34 × 35 × 3CornerCornerCornerCornerCornerCornerCornerCornerSideSideSideSideSideSideSideSideCenterCenterCenter817296,56119,68359,049531,441531,4415,133184,1376,498,16523,719,791228,469,8573,238,523,0498,023,996,89314,348,907464,991,949,6597296,56119,68359,049531,441531,441531,441541,10118,513,177191,890,599631,651,05320,752,761,34521,555,306,68168,094,804,36914,348,9072,353,796,975,87119,683531,441663,693,159239,111,765,60114,348,90759,241,069,331,995values: Won, Lost or Drawn) [45,68,77,78]. The bit arrays can be compressed by usingstandard compressing methods, such as Run-Length Encoding, which is used by Chinook.The positions are sometimes associated with a byte that stores the minimal number ofmoves before winning, or the maximal number of moves before losing [118,131,132].Given the large number of possible rules, this representation is not used for databases ofrules. Instead, each pattern is represented by a 32-bit unsigned integer, associated with aset of conditions. The only rules that are kept are the rules about won and winning states,since they represent only a small proportion of the possible rules. This allows one to storethe generated rules within a reasonable space. Table 7 provides the number of generatedrules for eyes on the side.A simple algorithm to generate pattern databases consists of going through all possiblerules, and for each rule testing whether it is in the Won state for the given goal. After eachtraverse of the possible rules, any new rules can be found only one move before the alreadydiscovered rules. So, to discover all the possible rules, the algorithm has to traverse all thepossible rules many times, as long as there are new rules discovered during the previouscrossing. This algorithm is not suited to Go rules’ databases since the number of possible82B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–103Table 7Size of thepattern3 × 24 × 23 × 35 × 24 × 33 × 46 × 2LocationNumber ofwon rulesNumber ofwinning rulesSideSideSideSideSideSideSide111717271,66138,90914,96618,1941081,0815,5705,952146,27262,32931,500Fig. 31.rules is very high. A more appropriate algorithm starts from the already generated rules,and undoes the previous rules so as to find the new rules directly, and without looking atall the possible rules to find them.Fig. 31 shows some generated rules whose aim is to make the black group live in thecorner. The use of generated rules greatly enhances the life and death problem solvingabilities of Golois for open groups [34].9.5. Explanation-based generalization and metaprogrammingFor domains—like the game of Go—that have a strong underlying theory, a deductivelearning method has been developed. It is called Explanation-Based Generalization(EBG) [88], and also Explanation-Based Learning (EBL) [46]. Many studies havefocused on the application of this method to planning [86,87]. This type of learning isparticularly useful for games. Many programs using deductive learning for games havebeen described [85,100], the work by Pitrat on Chess [101] marking the onset of thesestudies.The application of EBG to the game of Go has been partially formalized by Kojima [74],and has been developed for, and efficiently applied to, many subproblems of the gameof Go, using the Introspect system [30].Explanation-based generalizationThe use of EBG for the game of Go has been attempted by Kojima [74] for the captureof stones. As shown in Fig. 32, the program starts with the positions where stones arecaptured, and undoes moves to find positions where stones are captured some moves ahead.B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–10383Fig. 32.The information used by the generated rules concerns only the colors of stones and theirpositions. There is other, more abstract, and potentially very useful information which isnot used to generate interesting rules: e.g., the number of liberties of the strings, or thenumber of shared liberties between strings. The system does not find the forced movesby itself. On the contrary, they are given to it. Despite its limits, this approach offers theadvantage of uncovering a way to apply EBG to the game of Go.IntrospectIntrospect is a system for metaprogramming, and for EBG, that creates tactical rulesfor multiple games, and more particularly for the game of Go. It uses predicate logic—forexample a rule to connect two strings is represented as:connect(S1, S2, I, Color) : -color_string(S1, Color), color_string(S2, Color),liberty(I, S1), liberty(I, S2).This rule shows that the two strings of stones, S1 and S2, can be connected with a move ofcolor Color, on intersection I, if S1 and S2 are also of color Color, and if intersection Iis a liberty of S1, and a liberty of S2.The generated rules deal with the tactical sub-goals of the game of Go: capturing a string,making a string live, connecting two strings, disconnecting two strings, making an eye, andremoving an eye. They are used to develop tactical tree searches, and to stop search at anearlier stage, as well as to reduce the number of moves to be examined. Their originalitycomes from the fact they are theorems of the game of Go. Thanks to this characteristic,the set of forced moves they conclude on is complete. In this way, if we can prove thatnone of this limited number of forced moves works, then we have proved that no moveworks. Similarly, when at some node a rule concludes that a goal is achieved, search canbe stopped, with the certainty that the goal is effectively achieved whatever the surroundingsituation.The rules that are used to develop the OR nodes of the search trees are created, either byunfolding rules concluding on a won goal, or a winning goal [5,56,126], or by EBG [30,46,62,88,101].As well as the classical operations on logic programs that enable Introspect to generaterules for the OR nodes, Introspect also uses metaprograms, which are specific to games,to generate rules about forced moves for the AND nodes of the search trees [32]. Thesespecific metaprograms analyze a winning rule, and find all the moves that invalidate acondition of this rule. All these invalidating moves constitute the complete set of forcedmoves that prevent the opponent from achieving the goal that the winning rule concludeson.84B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–103But EBG systems create too much knowledge, and sometimes useless rules that slowthe system down. To avoid this phenomenon, called the utility problem, and to enable thesystem to limit itself, Introspect only generates rules that contain fewer than 200 conditions,and that do not conclude on sets of more than 5 forced moves. Unlike other domains, wherethe utility problem is a major obstacle, good results can be obtained for the game of Gowith quite simple utility knowledge.The following rule is generated by Introspect regarding the capture of a string. Itconcludes on the capture of the string represented by variable S. The color of the moveto capture is represented by variable C, and the intersection on which the move should beplayed to capture the string is represented by variable I:move_to_capture(C, S, I) : -opposite_color(C1, C),color_string(S, C1),number_of_liberties_of_string(S, 2),minimum_number_of_liberties_of_adjacent_strings(S, 2),liberty_string(I, S),minimum_number_of_liberties_if_move(I, C, 2),liberty_string(I1, S),I = \ = I1,number_of_liberties_of_string_if_move(S, [I, C], [I1, C1], 1).The condition minimum_number_of_liberties_of_adjacent_strings(S,2) verifies that all the strings adjacent to the string S have at least two liberties.The condition minimum_number_of_liberties_if_move(I,C,2) checks thata move of color C, on the intersection I, has at least two liberties. The conditionnumber_of_liberties_of_string_if_move(S,[I,C],[I1,C1],1) veri-fies that a move of color C, on intersection I, followed by a move of color C1, on in-tersection I1 has only one liberty. An illustration of this rule is Fig. 33 where Black cancapture the White string by playing one of its liberties.The tactical programs generated by Introspect are used by the Go program Gogol. Theyhave enabled it to obtain decent results in Computer Go competitions [53]. Once generated,the rules are gathered in a tree of conditions, and compiled into C. When they are integratedinto Gogol, they amount to one million lines of C.Introspect is also a general game, and a metaprogramming, system [100,102] that hasgenerated knowledge for domains other than the game of Go [30].Fig. 33.B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–103859.6. Pattern generation by an ecological algorithmKojima has also used an ecological algorithm to discover patterns for the game ofGo [75]. He uses games between professional players as examples. The rules containconditions on the relative positions of the stones (friendly or enemy stones, relativecoordinates), and on their location on the board (on the edge or not). Each rule is consideredas an individual, and has an activation value. A learning example is considered as food, thatcan be eaten by the rules which match this example. If no rule matches, then a new rule,that matches the example, is created. When a rule has an activation value above a giventhreshold, it gives birth to a more specific rule. Each rule eats at each step of the algorithm,so its activation value decreases. The rules with an activation value of 0 die. This approachto pattern generation has not yet generated a competitive Go program.9.7. ConclusionMany learning methods have been tried for the game of Go. So far, none has givenvery astonishing results. However, the temporal differences method, and the programspecialization method (either by retrograde analysis or by metaprogramming), giveinteresting results, when compared to more classical methods for game programming: theyare undoubtedly the most promising learning methods for the game of Go.The automatic generation of knowledge still needs to be investigated more: the game ofGo is the domain, ‘par excellence’, where learning, and program specialization, methodscan be very useful. One of the principal difficulties in programming the game of Go lies infinding knowledge, and then in writing a relevant program that represents this knowledge.Such is the current task of learning Go programs.10. Monte Carlo Go10.1. Monte Carlo methods in physicsThe variation principle lies at the heart of theoretical physics. The path taken by a systemin a state space is an extremum. The mechanisms used to find extrema are fundamental inclassical physics, in relativistic physics, and in quantum physics, as well. Monte Carlomethods [72,99] are derived from statistical physics. A statistical system is composed ofa large number of particles. The problem is to know how the speed, and the position,of particles evolve over time. A feature of the evolution of the system is that a quantity,such as the energy, or the activity, is minimized. For example, at high temperatures, ametal is liquid, and its atoms move randomly, but when the metal is cooled, the atomsput themselves into a configuration that minimizes energy—a crystalline structure. Thisprocess is called annealing. The longer the cooling, the closer to the minimum of energythe cooled structure is.To do Monte Carlo simulations, one has to choose a representation of the possible statesof a system. Then, one has to define a set of ergodic, elementary, moves, that allows one togo through the state space of configurations, step by step. For a given configuration, moves86B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–103are generated randomly. The evolution of the system is approximately assessed by choosinga move with a probability that depends on the growth in activity resulting from the move.For example, the probability p(E) that a particle has the energy E at a temperature Tis p(E) = exp(−E/kT ), k being the Boltzmann constant. The move that increases theenergy by (cid:19)E is accepted with the probability p = exp(−(cid:19)E/kT ).10.2. Simulated annealingFor a function of many variables, algorithms that follow the gradient, to find lower valuesof the function enable us to find a local minimum of the function. However, if we look fora global minimum of a complex, and possibly non-differentiable, function, there is littlechance of finding it by using such a method. Simulated annealing is more appropriateto find global minima of complex functions that contain many variables, because it alsogenerates moves that increase the value of the function.To find a global minimum, simulated annealing plays moves randomly in state space.If the value of the function decreases after the move, the move is accepted. If the moveincreases the value of the function, the move is accepted with a probability that decreasesexponentially with the increase of the value of the function, and with the temperature. Thetemperature decreases with time, depending on the time given to the algorithm to find asolution.Simulated annealing has been applied to combinatorial optimization problems like thetraveling salesman problem. There are N! different paths between the N cities. Simulatedannealing finds a solution, close to the optimal solution, in a polynomial time. Thealgorithm begins with a random ordering of the cities. There are two types of possiblemoves. The first type of move is to reverse the order of several cities, which are nextto one another on the path. The other type of move is to move several neighboring citiessomewhere else on the path. Simulated annealing has also been used to find an arrangementof 25 cards, in a 5 × 5 table, so that the values of the rows, columns, and diagonals, wheninterpreted as hands in Poker, are maximized. Simulated annealing is successful, and bothmuch faster, and simpler, than other methods.10.3. The Gobble programThe Gobble program [22] uses simulated annealing to find an approximation of thebest move on a 9 × 9 board. The principle is the same as the Go-moku program designedby Grigoriev [59]. It consists of randomly developing the different possible games, andin calculating statistics based on the results of the sequences of moves, after each possiblenext move. The goal of the program is to find an approximation of the value of the differentpossible moves. To this end, it plays each sequence of moves until the last moves that donot fill eyes. In case of captures, many moves can be played at the same intersection. Atthe end of a sequence of moves, it counts the number of points for Black, and for White.The final values, associated to an intersection, are the mean of the results corresponding tothe sequences of moves in which Black has been the first to play at the intersection.The problem consists of finding the order in which to play the possible moves in thedifferent sequences. The order of moves must be different, and must bring information forB. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–10387each sequence. Therefore, Gobble uses a different vector of moves for each sequence. Thefirst legal move in the sequence of moves is chosen to continue the sequence, each vector ofmoves corresponds to a sequence. For all sequences, the initial order of the vector of movesis found by sorting the moves according to their approximate values calculated with theformer sequences. This initial order is then modified by going through the vector of movesand by swapping two neighboring moves with a probability that depends on temperature.As sequences are being played, temperature decreases, and the probability that two movesare swapped also decreases.The moves are sorted according to their values. The value is initialized to 0, for thefirst iteration, and then it is updated for each sequence of moves. Then, the program goesthrough the list of moves, and swaps two neighboring moves with the probability pswap.The probability p(n) that a move is moved n steps down is:p(n) = (pswap)n = exp(−n/T ),soT = −1/ ln(pswap).pswap decreases linearly down to 0, depending on the number of sequences. Then, for somesequences, pswap remains at 0, in order to find the nearest local extremum. The usefulinformation obtained from random sequences is proportionate to the number of sequencesalready played. The mean error, (cid:19)v, is proportional to the square root of the number ofsequences:√(cid:19)v ∼ 1/n.Therefore, to calculate the value of a move to a precision of within one-point, and given thatthe possible values for the results of the sequences can vary by 100 points, approximately10,000 sequences have to be played.Gobble uses two strategies: strategy A: play between 500 and 1000 sequences to find themoves; strategy B: play 400 sequences, retain the 4 best moves, and play 400 sequencesfor each of these 4 moves. Using strategy A, and despite giving/receiving three handicapstones, Gobble plays equal games against Many Faces of Go. Using strategy B, and despitegiving/receiving two handicap stones, Gobble plays correctly against Many Faces of Go.A specific property of the game of Go, which is taken into account by Gobble to evaluatethe moves, lies in the localization of the moves. Locally, the game of Go is more stablethan Chess, for example. However, the results are only an approximation of the real result,since the localization of moves is not always verified, and the state space of Go not alwaysregular.The Gobble approach is original, because it relies on a very limited knowledge of Go—‘do not fill your own eyes’—and yet it results in an average Go program. Given thesimplicity of the program, its performances are amazing. This approach can undoubtedlybe improved, and conclusions can be drawn from these experiments for other gameprogramming problems.88B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–10311. Mathematical morphology11.1. IntroductionThis section highlights the link between image processing and Computer Go. The sizeof the board (19 × 19) on which the game is played, is much smaller than the sizeof the pictures (more than 1000 × 1000) processed in the pattern recognition domain.Therefore, the complexity of the game of Go is situated far below the complexity ofimage processing. Nevertheless these two domains have a common, and efficient, tool—mathematical morphology [120]. Hence, this section shows how to use mathematicalmorphology within Computer Go, and, more specifically, within the EF of a Go program.11.2. Mathematical morphology and the game of GoMathematical morphology is a very useful technique in the field of image processing.For example, some operators enable systems to delete the details whose size ranks belowa given scale. Fuzzy mathematical morphology [12] is another refinement that also givesgood results. Besides, some Go programmers use it in their program. At the very beginningof Computer Go, the Zobrist model [147], without using it explicitly, already performedmathematical morphology. This model was composed of iterative dilations. It enabledthe programs to recognize “influence” as human players do. This model is the ancestorof the refinements used today in Go programs. For example, the Indigo program makesexplicit use of mathematical morphology [15,16] for territory-, and influence-modeling.GnuGo [57] also uses this model. This section focuses on “territories”, and “influence”,recognition, and provides information to help understand the Evaluation Function section.First, let us mention some basic operators of mathematical morphology. Let A be a setof elements, and let D(A) be the morphological dilation of A—composed of A, plus theneighboring elements of A. E(A) is the morphological erosion of A. It is composed of A,minus the elements which are neighbors of the complement of A. ExtBound(A) is themorphological external boundary of A; given by ExtBound(A) = D(A) − A. IntBound(A)is the morphological internal boundary of A; given by IntBound(A) = A − E(A).Closing(A) is the morphological closing of A; where Closing(A) = E(D(A)). Opening(A)is the morphological opening of A; given by Opening(A) = D(E(A)). The opening andclosing operators are very helpful in image processing.We can then adapt these operators by adding two refinements: numerical inputsand outputs, and two colors (Black and White). We start by assigning values of +64(respectively −64) to black (respectively white) intersections, and 0 elsewhere. TheD operator now consists of adding to the absolute value of an intersection of one color,the number of neighboring intersections of this color, provided that all the neighboringintersections are empty, or of that color. For an empty intersection, which has neighboringintersections of the same color, D also adds the number of neighboring intersectionsof this color to the absolute value of the intersection. D is a numerical refinement ofthe classical dilation operator mentioned above. Similarly, the E operator now consistsof subtracting from the absolute value of an intersection of one color, the number ofneighboring intersections whose value is either zero, or whose value corresponds to theB. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–10389Fig. 34.Fig. 35.opposite color of the intersection. E also makes sure that the sign of the value does notchange—otherwise, the value becomes zero. E is therefore a numerical refinement ofclassical morphological erosion.Once these refinements are added, we use the operators X = E ∗ E ∗ · · · ∗ E ∗ D ∗ D ∗· · · ∗ D, and Y = D ∗ D ∗ · · · ∗ D where E is composed ‘e’ times, and D, ‘d’ times. So as togive the same result as the identity operator in positions where no “territory” is recognized,a link between ‘e’ and ‘d’ must be established. For example, in the trivial position, withonly one stone located in the middle of the board, X must give the same result as theidentity operator. Bouzy [16] has shown that e = d ∗ (d − 1) + 1, in which ‘d’ is a scalingfactor. The bigger ‘d’ is, the larger the scale of recognized territories is.90B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–103Fig. 36.Fig. 34 illustrates an example position on which we applied operators X and Y . Fig. 35shows the result of Y , with d = 5, and e = 0. Fig. 36 shows the result of X, withd = 5 and, e = 21. Fig. 35 shows what Go players call “influence” and Fig. 36 showsthe “territories” quite accurately. These two points explain the success of mathematicalmorphology in the game of Go [15]. This technique was part of the EF of the Indigoprogram [15,16], and now has been integrated in the GnuGo program [57].12. Cognitive science12.1. IntroductionThis section deals with studies carried out in Cognitive Science which use the game ofGo as an investigation aid. After showing that the game of Go is an appropriate domain forcognitive science studies, this section investigates the different studies conducted so far.12.2. The game of Go is appropriate for carrying out cognitive science studiesCognitive science experiments, aiming at exploring the human cognitive system when itinteracts with the real world, have to be set up inside sufficiently complex domains. Thus,the subjects will be able to use their cognitive faculties that will be studied through theexperiment. So as to be effective in practice, the experiments must not be too complex.Therefore, domains whose complexity is neither too low, nor too high, are perfectlyadapted. Furthermore, the knowledge used by the subjects during the experiments mustbe representative of common sense knowledge used by human beings in the real world.Therefore, the domain to be studied must also keep real world features. To sum up,Cognitive Science requires domains which are representative of the real world, and whoseB. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–10391complexity lies between the complexity of recreational experiments and the complexity ofreal-world, but technically ineffective, experiments.Langston [80] defends the idea that the game of Go is a simplification of the real worldwhile keeping its main features by the following arguments. The Go universe has twospatial dimensions and one temporal dimension whereas the real world has three spatialdimensions and one temporal dimension. In addition, the Go universe is finite—there are361 intersections on a Go board, and these are endowed with a color which has a discretevalue (black, white, or empty). However, the real world is made up of an infinity of points.Furthermore, an infinity of viewpoints describes each point, and each viewpoint takes ona value belonging to an infinite set. Unlike the real world, the Go universe is formal: therules of the game define the characteristics of the game with great accuracy.Actually, the main advantage of the game of Go compared to other games is that it isvisual: a position with its black, white, or empty intersections must not be perceived simplyas such, but rather in an abstract way. In these conditions, the player may identify complexobjects. The strength of a player relies on his skill in recognizing complex objects whereonly concrete information (black, white, and empty intersections) can be found. This aspectdoes not exist, as markedly, in other games such as Chess, Checkers, or Othello, where theobjects of the reasoning process are similarly defined by the rules of the game.Therefore, it is quite justifiable to choose the game of Go as a domain to performcognitive experiments [15,112]. We shall now see which studies, using the game of Go,have been done so far within the cognitive science community.12.3. Related worksThe different studies in cognitive science that have been carried out using the game ofGo may be classified according to the chosen method: on the one hand measuring responsetimes for re-building observed, and hidden, positions—on the other hand analyzing verbalreports.Measuring response timesIn Chess, Chase and Simon [35] measured time intervals separating the actions of thesubjects who were reconstructing positions, once seen, but later hidden. They showedthat expert players use information organized in “chunks”. A chunk can be defined asa cluster of information. The authors observed that, because Chess experts build actualChess positions more quickly, they seem to have a greater memory capacity than non-experts. However, with random positions, the authors observed that the experts’ and thenon-experts’ performances were equal. The explanation given by the authors was thatthe number of memorized chunks is equal for experts and non-experts, but that expertsmemorize more specialized chunks. This argument would explain the time differenceswhen building actual Chess positions.In Go, this experiment has been done again [104]. As in Chess, the experiment showsthat experts use more specialized chunks than non-experts. Nevertheless, the conclusionswere more difficult to reach in Go. Unlike in Chess, the chunks in Go are more complex,as they are not linearly structured, but may be chosen differently, according to differentviewpoints.92B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–103Burmeister and Wiles [23] describe experiments which use “inferential” informationto build Go positions. This contrasts with “perceptual” information which was used inprevious experiments [35,61]. A more detailed study of strong Japanese players (6 to8 dan) was then conducted [24]. The authors conclude that the explanation for moves is animportant factor in memorizing positions, and sequences of moves. Thus, strong playersclearly remember their games against other strong players, but they have more difficultyremembering their games against weak players, because weak moves have no meaningfor them. Consequently, the strong player must use a representation that he is not familiarwith—this reduces his memorizing capacities.Analyzing verbal reportsScores of cognitive studies rely on natural language production. First, let us sum upthe arguments for, and against, both the use, and the study, of such types of information,irrespective of the domain. On the methodological side, Ericsson and Simon [49] proposea method to set up cognitive models relying on verbal reports. The success of the methodsimply lies in a verbal production model included within the cognitive model. Thus, thevalidation of the cognitive model is simply performed by comparing the verbal productionof the cognitive model with that of the subjects. Concerning the results obtained inanalyzing verbal reports, Vermersch [135] defends the idea that it is possible to extractknowledge from many everyday life experiments such as driving a car, and baking a cake.The author thinks that the extraction can be done with such precision that accurate cognitivemodels could be built. On the contrary, Nisbett and Wilson [97] argue that psychologicalexperiments in general, and verbal reports in particular, are strongly distorted by theexperimenters themselves. For the authors, such experimenters uncover only what theyare looking for, and if the experimenters could make other experiments aiming at provingthe contrary, they would do so. As a result, there are many divergent opinions as to theeffectiveness of experiments which are based on verbal reports.In Go, Saito and Yoshikawa [112,113,115] showed that human players use naturallanguage terms to play their games. The authors recorded the players’ voices when theywere playing games, or solving Go problems. They also used specialized hardware torecord the subjects’ eye movements, as they looked at the Go board. The authors observedthat friendly and opposing moves are very often named. Small tree searches appear inverbal expressions, and proverbs can be found. The authors conclude that natural languageplays an important role in playing Go. They also show that the use of terms dependson the players’ rankings [145]. So as to demonstrate this, they developed the “icebergmodel” [146], which shows that most knowledge is implicit, and not conscious, while littleinformation is explicitly present in verbal reports.Bouzy [15] presents a cognitive model of the Go player. It was designed using thefollowing steps. First, a cognitive model was based on strong players’ verbal reports. Thecognitive model had to be validated with the construction of a computational model. But,unfortunately, the results of that computational model were not conclusive. Therefore, thecognitive model was simplified, in a second stage, by using novice players’ verbalizations.Surprisingly, the level of the computational model based on verbal reports by noviceplayers was higher than the level of the program based on experts’ verbal reports. Thisobvious paradox may be explained by the fact that the expert verbalization-based modelB. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–10393used high level knowledge, without referring to the low-level knowledge. Therefore, thismodel—with high level knowledge—was not grounded on solid foundations, and thecorresponding program had poor results. The low-level knowledge of the other programenabled it to play at a novice level with better results.Nevertheless, the most significant conclusion of this work was to be found elsewhere.Of course, the program’s implementation required the use of concepts explicitly expressedin the reports, but it also required the use of further concepts, which are called hiddenconcepts, because they cannot be explicitly identified in the reports. Thereby, it wasassumed that a correspondence existed between the hidden concepts, on the one hand,and the implicit knowledge used by human players, on the other hand. This hypothesisbears great similarity to the iceberg model of [146]. This correspondence hypothesis beingassumed, Bouzy [15,19] has shown the existence of human players’ implicit knowledgesuch as, the group concept, the inside/outside concept (see “Evaluation Function” section),and the incrementality concept [20] (see “Optimization” section). Incidentally, theseconcepts are very intuitive, and very useful in helping to play Go. They do not appearvery clearly in Go players’ verbal reports, thus making it difficult to set up a correct modelin Go. Nevertheless, this approach may let researchers obtain insights into the way thathumans use implicit knowledge. In [19] the author argues that when one tries a computerimplementation in a complex domain, such as Go, one uncovers concepts, which make iteasier to model the domain. These concepts do not correspond, either to verbal reports, orto natural language terms in that domain. As these concepts does not correspond to explicitknowledge, the hypothesis is that they correspond to implicit knowledge.12.4. ConclusionThe game of Go, as a real world simplification that keeps its essential features, is anappropriate domain in which to conduct cognitive studies [80]. Reitman [104] reproducedthe Chess experiment [35] in Go; their conclusions were far from being obvious becausethe chunks were not “linearly” organized, but corresponded to different viewpoints whichwere difficult to classify. Bouzy [15] has shown that the bulk of Go players’ knowledge isnot conscious, by extracting this knowledge through the implementation on the computer.Yoshikawa et al. [146] not only argue that natural language plays an important role in Go,but also maintain that Go players’ knowledge is implicit, to a large extent.13. Conclusion13.1. SummaryIn this paper, we have presented Computer Go, and its numerous links with AI. First, wehave shown, in Section 2, that the complexity of Go is much higher than the complexity ofthe other two-player complete information games. This complexity is not only due to thenumber of possible moves in a given position, but also to the cost of the evaluation of aposition.In Section 3, we mentioned that the best Go programs obtain average results, althoughit took several years to develop these programs. The best current programs are Goemate,94B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–103In contrastGo4++, Many Faces of Go, Wulu and Go Intellect. However, with sub-problems of Go(life and death problems, and endgame problems), the results are excellent. GoTools [140,142] solves life and death problems whose level corresponds to the best amateur players.Berlekamp and Wolfe [9] describe a mathematical model that finds move sequences betterthan professional players’ sequences, in some specific late endgame positions.to the excellent results obtained with these sub-problems,the weakperformance of programs in a complete game might be explained by the difficultyin extending the problem solving tools to become more general tools. It is vital thatGo programs find good solutions in cases which occur in actual games. For example, itis difficult to solve life and death problems for groups that are not completely surrounded,although GoTools solves them very well for completely surrounded groups [142]. Section 4described a Go evaluation function whose complexity is due to its many inter-dependentconcepts: grouping, inside and outside, interaction, territory, influence, life, and death.Numerous definitions of these concepts are possible. The choices made in the designof each program bring about a loss of information. Moreover, these choices have to beimplemented in an efficient fashion, thus making the design of an evaluation function evenmore difficult.As described in Section 4, a characteristic of the evaluation function is the use of localtree searches on simple goals. To build the EF, TS on tactical goals, such as string capture,connection between strings, and eye verification, are commonly performed. The results ofthese tactical goals are used to build groups at the upper abstraction level. Other TS—onmore abstract goals, such as life and death of groups, and interactions between groups—may be performed at a second stage. All these results are processed to build the EF atthe global abstraction level. The EF calculation is slow enough to prevent a classical TS.Contrary to other games in which TS uses EF, in Go EF uses TS.Section 5 mentioned that the first Go programs were expert systems with a single MoveGeneration module, but with neither an Evaluation Function, nor Tree Search. So far,although Evaluation Function, and Tree Search, modules have been necessary to writethe current Go programs, the Move Generation module has occupied and still occupies aspecial position. Instead of being used by Tree Search, it can be used to select the movedirectly. Because TS can only be performed locally, or in a goal-oriented way, it must beperformed after the computation of a static strategic position evaluation which requires animportant amount of knowledge. Therefore, it is worth keeping the knowledge method, andhaving some static goal, and/or move evaluations, after the position evaluation. This time-saving approach is far from being simple. Move selection undoubtedly remains complex,and needs accurate domain-dependent knowledge. Global move generation has multiplefacets, and must be supplemented by a tree search module, which is used to check thatgoals have been achieved.Section 6 considered the characteristics of TS. First, the local situations of a positionmay be viewed as independent of one another, and the global TS may be approximatedby several local TS—-that is why a local TS is a selective TS, where moves sufficientlyfar away from preceding ones are discarded. Another important feature of the game of Gois that, for each local situation, each player may be the first to play, which necessitatesthe computation of at least two TS for each local situation. The evaluation function is theresult of local TS on simple goals, and can contain some uncertainty. A quiet position canB. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–10395be defined as a position in which there is no uncertainty. Quiescence search algorithms arethus appropriate in this approach.The programmer can choose between many search algorithms. For the goals that usedata structures, which can be incrementally updated, Alpha-Beta is the algorithm of choice.When the number of moves for each position varies a lot, it may be better to use PN-Search.For a given sub-problem, the search algorithm is chosen according to its characteristics.Given the computational complexity of Go playing programs, it is important to performcomputations as fast as possible. It is then possible to compute longer sequences ofmoves, and to obtain more information about the position, so as to make a more accurateevaluation. Section 7 listed the numerous possible optimizations at each level of abstractionof a program. For example, incrementally calculating the liberties of strings has become awidely accepted technique at the lowest level of the program. When computing a tacticalsearch, the same sequences of moves are often repeated. An interesting optimizationconsists of playing sequences of moves, rather than playing one move at a time, andreanalyzing the position after each move. Another example of low level optimizationcenters on the use of bit-string operations, to calculate the dilation, and erosion, operatorsof mathematical morphology. Other optimizations are useful at more abstract levels. Theobjects related to the results of each local TS can be memorized, and the only local TS tobe computed after a move are the ones that contain objects modified by the move. At thehighest level, a program can be optimized by eliminating beforehand some computationsof the lower levels, leaving the choice of move unchanged.As presented in Section 8, the possibility of splitting the global position into severalsub-positions enables programmers to apply the sum of game theory. Berlekamp achievedexcellent results by applying this theory to the late endgame. This result can be explainedby the specificity of the test positions in which local situations are totally independent fromone another. In real game positions, the local situations are not independent, and the sumof game theory does not apply directly, although several attempts have been performed sofar. Explorer is undoubtedly the program which uses this theory in the best way, thanksto thermograph calculations. Other studies on eyes [79], fights between groups [95], ortemperature calculations [71] have also been performed.Neural network learning methods, described in Section 9, and more specifically thetemporal difference method, allow the program to automate most of the creation of anevaluation function, and to replace the strategic level of a Go program at a low cost.NeuroGo uses quickly defined, and quickly computed, inputs, and it successfully competesagainst some programs based on more elaborate methods and concepts. An interestingattempt would consist of using more elaborate inputs, but the learning time may then beprohibitive. So far, programs using EF, based on the TD method, have not reached thelevel of the best programs. However, they give very good results when comparing thedesign complexity of classical programs to the low complexity of programs based on thismethod. Other approaches, which aim to transfer the work of knowledge generation fromthe programmer to the computer, are logical metaprogramming, and retrograde analysisapplied to tactical patterns. These approaches generate millions of rules that enable tacticalproblems to be solved more quickly, and more accurately. In well-defined sub-problems,like life and death of groups, Golois uses this automatically generated knowledge, andranks at a similar, if not better, level than the other programs.96B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–103Very different problem solving methods may be adapted to the game of Go. InSection 10, Monte Carlo methods surprisingly provides average level Go programs, on9 × 9 boards. Based on this method, Gobble is designed in a simple way, but, like NeuroGo,it competes effectively against far more complex programs.Since the game of Go is visual, it is normal to explore the usual techniques of imageprocessing to see whether they can be useful for Computer Go. This was examinedin Section 11. Although 19 × 19 boards are much smaller than images processed inComputer Vision, mathematical morphology enables Go programs, like Indigo or GnuGo,to recognize territories, and influence by using dilation, erosion and closing operators.Section 12 showed that Go is a domain, well-suited to the performance of cognitiveexperiments. In order to obtain significant results, without being confused by thecomplexity of the real world, cognitive science requires clearly formalized domains likegames. So as to extract intuitive, and non-conscious, knowledge from human beings, thedomain has to be sufficiently complex. The game of Go, with its intermediate complexity,is a good domain for experiments. The Indigo program has been devised to validate thecognitive model, based on the verbal reports of novice players. Saito and Yoshikawa [112]have shown, on the one hand, that Go players use natural language to guide their thinkingprocess, and, on the other hand, that they use implicit knowledge in a way similar to the“iceberg model”. Some experiments, already done in Chess, were repeated, for Go, byReitman [104]. As in Chess, they show that expert players recognize real game positionsbetter than do novice players, while obtaining comparable results on random positions.13.2. Future workGiven the present state of Computer Go programming, we may wonder how ComputerGo is likely to evolve over the next few years. We have mentioned many different studies,and we can try to figure out which paradigm will result from all these studies.Computer Go programmers currently agree on very few concepts and tools. All theprograms have modules to compute the capture of strings. They also have modules forconnecting strings, for killing groups, and for making groups live. But, even at thisrelatively low level of abstraction, the underlying concepts of the modules differ fromone program to another. For example, Many Faces of Go uses an incremental Alpha-Beta to compute strong connections, whereas Go4++ uses a connectivity probability map.Since a Go program is an interconnected whole, it is difficult to argue about the best wayto compute a connection. The choice of method for solving a sub-problem depends onthe global architecture of the program, and on the choices made in other modules. Theproblem of comparing the pros and cons of the different architectures currently in useremains unsolved.The EF computation is complex, because of its many interacting concepts. An attractiveapproach might be to design a multi-valued EF, each value corresponding to a concept.A bi-valued EF has been applied to fights between groups [95], whereas a multi-valued EFcould be applied to other sub-problems of the game of Go. One problem will be to use thismulti-valued EF in a TS.We have shown that an automatic knowledge generator has been successfully appliedto the tactical levels of a program. We can ask whether this technique will also giveB. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–10397good results at more abstract levels. TD learning techniques, and simulated annealingtechniques, have been used in programs using simple data structures, to reach a globalgoal. Some parts of the best programs might be improved by using such tools. First, theycould be used at low abstraction levels, for instance to estimate the connectivity. Second,they could be used at the global levels, using more abstract information. Third, the MonteCarlo methods could be applied to sub-problems, such as life and death.In 1995, Handtalk—the Computer Go world champion—played moves almost instantly.The speed might be due to assembly coding, and to limited tree search, associated withvery good heuristics for finding good moves. The goal of a program is to select a move, TSbeing one way to find it. Unlike in Chess, TS in the game of Go can be partly replaced byother tools, that select good moves in some positions. In quiet positions, where tree searchis not useful, a method based on a very abstract description of the board can give goodresults.After obtaining results relating to the late endgame, eyes, and fights, combinatorial gametheory will probably be successfully applied to other Go sub-problems. Concerning the fullgame: as some local computations do not reach their end, the global level of a programneeds tools to represent uncertainty. A good program has to use an uncertainty description,which is not to be found in Conway’s theory. In addition, the local games of an actualgame are not independent of one another. On the contrary, they are very dependent oneach other. At the moment, some programs use the simple idea of increasing the priorityof those moves which contribute to several local dependent games. But, so far, no studyhas been performed on this idea, and a formalization of the different independence classeshas yet to be set up. An interesting idea would be to formalize, both the use of one goalby another, and the interaction between several games. The problem of performing TS onconjunctions, and disjunctions, of goals remains to be solved.The promising results of GoTools with life and death problems, containing completelysurrounded groups, offer some attractive prospects of developing a life and death problemsolver for partially surrounded groups. This kind of problem arises in actual games, andsuch a problem solver would be very useful. The number of possible moves may increase,while the search deepens, and this constitutes the major obstacle to building this solver.Search in life and death of completely surrounded groups is easier, because the numberof possible moves decreases as the depth increases. Another obstacle to be taken intoaccount is the dynamic definition of the goal to be reached (making two eyes, escaping,and fighting).Another possibility in the evolution of programs might be the use of parallelism. Thedistributed nature of the game of Go makes this idea appealing. At present, no programuses parallelism.Lastly, we have to mention the likely evolution of the level of Go programs, in the yearsto come. In the late 1980s, Mr. Ing decided to award prizes to any programs which couldbeat a professional player, in a series of even games, before the year 2000. Today, youngprofessional players still give 9 handicap stones to the best programs, and players whoare used to playing against programs, are able to give as many as 29 handicap stones tothese programs. This difference in terms of number of handicap stones can be explained asfollows. During the first few games—when its human opponent confronts the strengths ofthe computer—the program may give the illusion of being stronger than it actually is, and it98B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–103plays at its “high” level. Some games later, the human opponent discovers the weaknessesof the computer, and still later, the human opponent identifies almost all the weaknesses ofthe computer, whose level generally drops to its “low” level. Nowadays, the “high” levelof the best programs may be assessed at 5th kyu—this corresponds to an average player ina Go club. However, their “low” level ranks at 15th kyu, namely a beginner level. As longas this gap, between the low and the high levels, is not reduced, it is risky to make anyprediction about the evolution of the level of Go programs.References[1] L.V. Allis, Searching for solutions in games and artificial intelligence, Ph.D. Thesis, Vrije Universitat,Amsterdam, 1994, http://www.cs.vu/∼victor/thesis.html.[2] L.V. Allis, M. van der Meulen, H.J. van den Herik, Proof-number search, Artificial Intelligence 66 (1994)91–124.[3] L.V. Allis, H.J. van den Herik, M. Huntjens, Go-moku solved by new search techniques, Comput.Intelligence 11 (4) (1995).[4] T.S. Anantharaman, M. Campbell, F.H. Hsu, Singular extensions: Adding selectivity to brute forcesearching, Artificial Intelligence 43 (1) (1989) 99–109.[5] J. Barklund, Metaprogramming in logic, UPMAIL Technical Report 80, Uppsala, Sweden, 1994.[6] D. Beal, A generalised quiescence search algorithm, Artificial Intelligence 43 (1) (1989) 85–98.[7] D. Benson, Life in the game of Go, Inform. Sci. 10 (1976) 17–29. Reprinted in: D.N.L. Levy (Ed.),Computer Games, Vols. 1 and 2, Springer, New York, 1988.[8] E. Berlekamp, Introductory overview of mathematical Go endgames, in: Proceedings of Symposia inApplied Mathematics, 43, 1991.[9] E. Berlekamp, D. Wolfe, Mathematical Go Endgames, Nightmares for the Professional Go Player, IshiPress International, San Jose, CA, 1994.∗[10] H.J. Berliner, The Btree search algorithm: A best-first proof procedure, Artificial Intelligence 12 (1979)23–40.[11] H.J. Berliner, Backgammon computer program beats world champion, Artificial Intelligence 14 (1980)205–220.[12] I. Bloch, H. Maître, Ensembles flous et morphologie mathématique, Télécom Paris 92 D007, DépartementImages, Groupe Image, 1992.[13] M. Boon, A pattern matcher for Goliath, Computer Go 13 (1990) 13–23.[14] M. Boon, Overzicht van de ontwikkeling van een Go spelend programma, Afstudeer Scriptie Informaticaonder begeleiding van Prof. J. Bergstra, Amsterdam, 1991.[15] B. Bouzy, Modélisation cognitive du joueur de Go, Ph.D. Thesis, University Paris 6, 1995,http://www.math-info.univ-paris5.fr/∼bouzy.[16] B. Bouzy, Les ensembles flous au jeu de Go, in: Actes des Rencontres Françaises sur la Logique Floue etses Applications LFA-95, Paris, France, 1995, pp. 334–340.[17] B. Bouzy, The Indigo program, in: Proceedings of the Second Game Programming Workshop in Japan,Hakone, 1995, pp. 197–206.[18] B. Bouzy, There are no winning moves except the last, in: Proceedings IPMU-96, Granada, Spain, 1996,pp. 197–202.[19] B. Bouzy, Explicitation de connaissances non conscientes par modélisation computationnelle dans undomaine complexe: le jeu de Go, in: Actes du 2eme Colloque Jeunes Chercheurs en Sciences CognitivesGiens, France, 1996, pp. 276–279.[20] B. Bouzy, Incremental updating of objects in Indigo, in: Proceedings of the fourth Game ProgrammingWorkshop in Japan, Hakone, 1997, pp. 179–188.[21] B. Bouzy, Complex games in practice, in: Proceedings of the Fifth Game Programming Workshop in Japan,Hakone, 1999, pp. 53–60.[22] B. Brugmann, Monte Carlo Go, ftp://www.joy.ne.jp/welcome/igs/Go/computer/mcgo.tex.Z.B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–10399[23] J. Burmeister, J. Wiles, The use of inferential information in remembering Go positions, in: Proceedingsof the Third Game Programming Workshop in Japan, Hakone, 1996, pp. 56–65.[24] J. Burmeister, Y. Saito, A. Yoshikawa, J. Wiles, Memory performance of master Go players,in:Proceedings of the IJCAI Workshop Using Games as an Experimental Testbed for AI Research, Nagoya,Japan, 1997.[25] M. Buro, Methods for the evaluation of game positions using examples, Ph.D. Thesis, University ofPaderborn, Germany, 1994.[26] M. Campbell, T. Marsland, A comparison of minimax tree search algorithms, Artificial Intelligence 20 (4)(1983) 347–367.[27] T. Cazenave, Apprentissage de la résolution de problèmes de vie et de mort au jeu de Go, Rapport du DEAd’Intelligence Artificelle de l’Université Paris 6, 1993.[28] T. Cazenave, Automatic ordering of predicates by metarules, in: Proceedings of the 5th InternationalWorkshop on Metareasoning and Metaprogramming in Logic, Bonn, Germany, 1996.[29] T. Cazenave, Automatic acquisition of tactical Go rules, in: Proceedings of the Third Game ProgrammingWorkshop in Japan, Hakone, 1996, pp. 10–19.[30] T. Cazenave, Système d’Apprentissage par Auto-Observation. Application au Jeu de Go, Ph.D. Thesis,University Paris 6, 1996, http://www.ai.univ-paris8.fr/∼cazenave.[31] T. Cazenave, R. Moneret, Development and evaluation of strategic plans, in: Proceedings of the FourthGame Programming Workshop in Japan, Hakone, 1997, pp. 75–79.[32] T. Cazenave, Metaprogramming forced moves, in: Proc. ECAI-98, Brighton, England, 1998, pp. 645–649.[33] T. Cazenave, Metaprogramming domain specific metaprograms, in: Proceedings of Meta-Level Architec-tures and Reflection, Reflection’99, Lecture Notes in Computer Science, Vol. 1616, Springer, Berlin, 1999,pp. 235–249.[34] T. Cazenave, Generation of patterns with external conditions for the game of Go, in: H.J. van den Herik,B. Monien (Eds.), Advances in Computer Games, Vol. 9, Univ. of Limburg, Maastricht, 2001.[35] W. Chase, H. Simon, Perception in chess, Cognitive Psychology 4 (1973) 81.[36] K. Chen, Group identification in computer Go, in: D.N. Levy, D.F. Beal (Eds.), Heuristic Programming inArtificial Intelligence: The First Computer Olympiad, Ellis Horwood, Chichester, 1989, pp. 195–210.[37] K. Chen, The move decision process of Go intellect, Computer Go 14 (1990) 9–17.[38] K. Chen, Attack and defense, in: H.J. van den Herik, L.V. Allis (Eds.), Heuristic Programming in ArtificialIntelligence, Vol. 3: The Third Computer Olympiad, Ellis Horwood, Chichester, 1992, pp. 146–156.[39] K. Chen, Z. Chen, Static analysis of life and death in the game of Go, Inform. Sci. 121 (1–2) (1999)113–134.[40] K. Chen, Some practical techniques for global search in Go, ICGA J. 23 (2) (2000) 67–74.[41] Z. Chen, E-mail sent on 5th January 1997 to the Computer Go mailing list, http://www.cs.uoregon.edu/∼richard/computer-go/.[42] Z. Chen, E-mail sent on 11th May 1997 to the Computer Go mailing list, http://www.cs.uoregon.edu/∼richard/computer-go/.[43] J.H. Conway, On Numbers and Games, Academic Press, New York, 1976.[44] J.H. Conway, E.R. Berlekamp, R.K. Guy, Winning Ways, Academic Press, New York, 1982.[45] J.C. Culberson, J. Schaeffer, Pattern databases, Computational Intelligence 14 (3) (1998) 318–334.[46] G. Dejong, R. Mooney, Explanation based learning: An alternative view, Machine Learning 2 (1986).[47] H. Enderton, The Golem Go program, Carnegie Mellon University, CMU-CS-92-101, Pittsburgh, PA,1992. Technical Report available at ftp://www.joy.ne.jp/welcome/igs/Go/computer/golem.sh.Z.[48] M. Enzenberger, The integration of a priori knowledge into a Go playing neural network, 1996,http://www.markus-enzenberger.de/compgo_biblio.html.[49] K.A. Ericsson, H. Simon, Protocol Analysis, Verbal Reports as Data, MIT Press, Cambridge, MA, 1980.[50] D. Fotland, The program G2, Computer Go 1 (1986) 10–16.[51] D. Fotland, Knowledge representation in The Many Faces of Go, 2nd Cannes/Sophia-Antipolis GoWorkshop, February 1993, ftp://www.joy.ne.jp/welcome/igs/Go/computer/mfg.Z.[52] D. Fotland, Computer Go Design Issues, E-mail sent on 1st October 1996 to the Computer Go mailing list,http://www.cs.uoregon.edu/∼richard/computer-go/.[53] D. Fotland, A. Yoshikawa, The 3rd FOST cup world-open computer-go championship, ICCA J. 20 (4)(1997) 276–278.100B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–103[54] A. Fraenkel, D. Lichtenstein, Computing a perfect strategy for n by n Chess requires time exponential,J. Combin. Theory, Serie A 31 (2) (1981) 199–214.[55] K.J. Friedenbach, Abstraction hierarchies: A model of perception and cognition in the game of Go, Ph.D.Thesis, University of California, Santa Cruz, CA, 1980.[56] J. Gallagher, Specialization of logic programs, in: D. Schmidt (Ed.), Proceedings of the ACM SIGPLANSymposium on PEPM’93, ACM Press, Copenhagen, 1993.[57] Gnu Go home page, http://www.gnu.org/software/gnugo/devel.html, 1999.[58] R. Greenblatt, D. Eastlake, S. Croker, The Greenblatt chess program, in: Proceedings of the Fall JointComputer Conference, 1967, pp. 801–810.[59] A. Grigoriev, Artificial Intelligence or stochastic relaxation: Simulated annealing challenge, in: D.N.L.Levy, D.F. Beal (Eds.), Heuristic Programming in Artificial Intelligence, Vol. 2, Ellis Horwood, Chichester,1991, pp. 210–216.[60] R. Grimbergen, A plausible move generator for Shogi using static evaluation, in: Proceedings of the FifthGame Programming Workshop in Japan, Hakone, 1999, pp. 9–15.[61] A. de Groot, Psychological Studies, T4, Thought and Choice in Chess, Mouton, La Hague, 1965.[62] F. van Harmelen, A. Bundy, Explanation based generalisation = partial evaluation, Artificial Intelli-gence 36 (1988) 401–412.[63] H.J. van den Herik, L.V. Allis, I.S. Herschberg, Which games will survive?, in: D.N.L. Levy, D.F. Beal(Eds.), Heuristic Programming in Artificial Intelligence, Vol. 2: The Second Computer Olympiad, EllisHorwood, Chichester, 1991, pp. 232–243.[64] R. High, Mathematical Go, Computer Go (1990) 14–24.[65] S. Hu, Multipurpose adversary planning in the game of Go, Ph.D. Thesis, George Mason University,Fairfax, VA, 1995.[66] S. Hu, P. Lehner, Multipurpose strategic planning in the game of Go, IEEE Transactions on PatternAnalysis and Machine Intelligence 19 (3) (1997) 1048–1051.[67] F.H. Hsu, T.S. Anantharaman, M. Campbell, A. Nowatzyk, A grandmaster chess machine, ScientificAmerican 263 (4) (1990).[68] A. Junghanns, J. Schaeffer, Single-agent search in the presence of deadlocks, in: Proc. AAAI-98, Madison,WI, 1998.[69] G. Kakinoki, The search algorithm of the Shogi program K3.0, in: H. Matsubara (Ed.), Computer ShogiProgress, Kyoritsu Shuppan Co, Tokyo, 1996, pp. 1–23 (in Japanese).[70] Y.K. Kao, Sum of hot and tepid combinatorial games, Ph.D. Thesis, University of North Carolina atCharlotte, NC, 1997.[71] Y.K. Kao, Mean and temperature search for Go endgames, Inform. Sci. 122 (2000) 77–90.[72] S. Kirkpatrick, C. Gelatt, M. Vecchi, Optimisation by simulated annealing, Science 220 (1983) 671–680.[73] D.E. Knuth, An analysis of alpha-beta pruning, Artificial Intelligence 6 (4) (1975) 293–326.[74] T. Kojima, K. Ueda, S. Nagano, A case study on acquisition and refinement of deductive rules based onEBG in an adversary game: How to capture stones in Go, in: Proceedings of the Game ProgrammingWorkshop in Japan, 1994, pp. 34–43.[75] T. Kojima, K. Ueda, S. Nagano, An evolutionary algorithm extended by ecological analogy and itsapplication to the game of Go, in: Proc. IJCAI-97, Nagoya, Japan, 1997, pp. 684–689.[76] R. Korf, Depth-first iterative deepening: An optimal admissible tree search, Artificial Intelligence 27 (1985)97–109.[77] R. Korf, Finding optimal solutions to Rubik’s Cube using pattern databases,in: Proc. AAAI-97,Providence, RI, 1997, pp. 700–705.[78] R. Lake, J. Schaeffer, P. Lu, Solving large retrograde-analysis problems using a network of workstations,in: H.J. van der Herik, I.S. Herschberg, J.W.H.M. Uiterwyk (Eds.), Advances in Computer Chess, Vol. 7,University of Limburg, Maastricht, Netherlands, 1994, pp. 135–162.[79] H. Landman, Eyespace values in Go, in: R.J. Nowakowski (Ed.), Games of No Chance, CambridgeUniversity Press, Cambridge, 1996, pp. 227–257.[80] R. Langston, Perception in Go as a problem in AI, Computer Go 6 (1988).[81] D. Lefkovitz, A strategic pattern recognition program for the game of Go, University of Pennsylvania, TheMoore School of Electrical Engineering, Wright Air Development Division, Technical Note 60-243, 1–92,1960.B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–103101[82] D. Lichtenstein, M. Sipser, Go is polynomial-space hard, J. ACM 27 (2) (1980) 393–401.[83] D. McAllester, Conspiracy numbers for min-max search, Artificial Intelligence 35 (1988) 287–310.[84] H. Matsubara, Shogi (Japanese chess) as the AI research target next to chess, Technical Report of theElectrotechnical Laboratories, 93-23, Japan, September 1993.[85] S. Minton, Constraint-based generalization learning game-playing plans from single examples,Proceedings of AAAI-84, Austin, TX, William Kaufmann, Los Altos, CA, 1984, pp. 251–254.in:[86] S. Minton, J. Carbonell, C. Knoblock, D. Kuokka, O. Etzioni, Y. Gil, Explanation-based learning:A problem solving perspective, Artificial Intelligence 40 (1989) 63–118.[87] S. Minton, Quantitative results concerning the utility of explanation-based learning, Artificial Intelli-gence 42 (2–3) (1990) 363–391.[88] T.M. Mitchell, R.M. Keller, S.T. Kedar-Kabelli, Explanation-based generalization: A unifying view,Machine Learning 1 (1) (1986).[89] M. Müller, Games Theories and Computer Go, Computer Go Workshop, Cannes, 1993.[90] M. Müller, Computer Go as a sum of local games: An application of combinatorial game theory, Ph.D.Thesis of the Swiss Federal Institute of Technology Zürich, 1995, http://web.cs.ualberta.ca/∼mmueller.[91] M. Müller, L. Gasser, Experiments in computer Go endgames, in: R.J. Nowakowski (Ed.), Games of NoChance, Cambridge University Press, Cambridge, 1996, pp. 273–284.[92] M. Müller, E. Berlekamp, W. Spight, Generalized thermography: Algorithms,implementation andapplication to Go endgames, TR-96-030 Berkeley, CA, 1996.[93] M. Müller, Computer Go: A research agenda, in: H.J. van den Herik, H. Iida (Eds.), Proc. CG-98, LectureNotes in Computer Science, Vol. 1558, Springer, Heidelberg, 1998, pp. 252–264.[94] M. Müller, Decomposition search: A combinatorial games approach to game tree search, with applicationsto solving Go endgames, in: Proc. IJCAI-99, Stockholm, Sweden, 1999, pp. 578–583.[95] M. Müller, Race to capture: Analyzing Semeai in Go, in: Proceedings of the Fifth Game ProgrammingWorkshop in Japan, Hakone, 1999, pp. 61–68.[96] M. Müller, Not like other games—Why tree search in Go is different, in: Proceedings of the 5th JointConference on Information Sciences, 2000.[97] R.E. Nisbett, T.D. Wilson, Telling more than we can know: Verbal reports on mental processes,Psychological Review 84 (1977) 231–259.[98] J. Nunn, Extracting information from endgame databases, ICCA J. (1993) 191–200.[99] R. Otten, L. van Ginneken, The Simulated Annealing Algorithm, Kluwer Academic, Dordrecht, 1989.[100] B. Pell, Metagame: A new challenge from games and learning, in: H.J. van den Herik, L.V. Allis (Eds.),Heuristic Programming in Artificial Intelligence, Vol. 3, The Third Computer Olympiad, University ofLimburg, Maastricht, 1992, pp. 237–251.[101] J. Pitrat, A program for learning to play chess, in: Chen (Ed.), Pattern Recognition and ArtificialIntelligence, Academic Press, 1976, pp. 399–419.[102] J. Pitrat, Games: The next challenge, ICCA J. 21 (3) (1998) 147–156.[103] M. Reiss, E-mail sentin January 1995 to the Computer Go mailing list, http://www.cs.uoregon.edu/∼richard/computer-go/.[104] J. Reitman, Skilled perception in Go: Deducing memory structures from inter-response times, CognitivePsychology 8 (3) (1976) 336–356.[105] W. Reitman, B. Wilcox, The structure and performance of the INTERIM.2 Go program, in: Proc. IJCAI-79, Tokyo, Japan, 1979, pp. 711–719. Reprinted in: D.N.L. Levy (Ed.), Computer Games, Vols. 1 and 2,Springer, New York, 1988.[106] H. Remus, Simulation of a learning machine for playing Go, in: C.M. Popplewell (Ed.), Proceedings ofIFIP Congress, North-Holland, Amsterdam, 1963. Also in: Information Processing (1962) 428–432.[107] P. Ricaud, Gobelin: Une approche pragmatique de l’abstraction appliquée à la modélisation de la stratégieelémentaire au jeu de Go, Ph.D. Thesis, Paris 6 University, 1995.[108] P. Ricaud, A model of strategy for the game of Go using abstraction mechanisms, in: Proceedings IJCAI-97, Nagoya, Japan, 1997, pp. 678–683.[109] J.M. Robson, N by N checkers is exptime complete, TR-CS-82-12, Australian National University,Department of Computer Science, 1982.[110] J.M. Robson, The Complexity of Go, TR-CS-82-14, Australian National University, Department ofComputer Science, 1982. Also in: Proceedings of the IFIP, 1983, pp. 413–417.102B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–103[111] J. Ryder, Heuristic analysis of large trees as generated in the game of Go, Ph.D. Thesis, Department ofComputer Science, Stanford University, 1971.[112] Y. Saito, A. Yoshikawa, Do Go players think in words? Interim report of the analysis of Go players’protocol, in: Proceedings of the Second Game Programming Workshop in Japan, Hakone, 1995, pp. 118–127.[113] Y. Saito, A. Yoshikawa, An analysis of strong Go-players’ protocols, in: Proceedings of the Third GameProgramming Workshop in Japan, Hakone, 1996, pp. 66–75.[114] A.L. Samuel, Some studies in machine learning using the game of checkers, IBM J. Res. Develop. 3 (3)(1959).[115] A.L. Samuel, Some studies in machine learning using the game of checkers II, IBM J. Res. Develop. 11 (6)(1967).[116] J. Schaeffer, Conspiracy numbers, Artificial Intelligence 33 (1) (1990) 67–84.[117] J. Schaeffer, J. Culberson, N. Treloar, B. Knight, P. Lu, D. Szafron, A world championship caliber checkersprogram, Artificial Intelligence 53 (1992) 273–289.[118] J. Schaeffer, One Jump Ahead—Challenging Human Supremacy in Checkers, Springer, Berlin, 1997.[119] N. Schraudolph, P. Dayan, T. Sejnowski, Temporal difference learning of position evaluation in the gameof Go, Neural Information Processing Systems, Vol. 6, Morgan Kaufmann, San Mateo, CA, 1994.[120] J. Serra, Image Analysis and Mathematical Morphology, Academic Press, London, 1982.[121] C.E. Shannon, Programming a computer to play chess, Philosoph. Magazine 41 (1950) 256–275.[122] W. Spight, Extended thermography for multiple Kos in Go, in: H.J. van den Herik, H. Iida (Eds.), FirstInternational Conference on Computer and Games 98, Lecture Notes in Computer Science, Vol. 1558,Springer, Berlin, 1998, pp. 232–251.[123] L. Stiller, Multilinear algebra and chess endgames, in: R.J. Nowakowski (Ed.), Games of No Chance,MSRI Publication, Vol. 29, Cambridge University Press, Cambridge, 1996.[124] G. Stockman, A minimax algorithm better than alpha-beta?, Artificial Intelligence 12 (1979) 179–196.[125] R. Sutton, Learning to predict by the method of temporal differences, Machine Learning 3 (1988) 9–44.[126] H. Tamaki, T. Sato, Unfold/fold transformations of logic programs, in: Proceedings of the 2nd Internat.Logic Programming Conference, Uppsala University, 1984.[127] G. Tesauro, T.J. Sejnowski, A parallel network that learns to play Backgammon, Artificial Intelligence 39(1989) 357–390.[128] G. Tesauro, Practical issues in temporal difference learning, Machine Learning 8 (1992) 257–277.[129] G. Tesauro, TD-Gammon, a self teaching backgammon program, achieves master-level play, NeuralComput. 6 (2) (1994) 215–219.[130] G. Tesauro, Temporal difference learning and TD-Gammon, Comm. ACM 38 (1995) 58–68.[131] K. Thompson, Retrograde analysis of certain endgames, ICCA J. 9 (3) (1986) 131–139.[132] K. Thompson, 6-piece endgames, ICCA J. (1996) 215–226.[133] E. Thorpe, W. Walden, A partial analysis of Go, Computer J. 7 (3) (1964) 203–207.[134] E. Thorpe, W. Walden, A computer assisted study of Go on M × N boards, Inform. Sci. 4 (1972) 1–33.[135] P. Vermersch, Les connaissances non conscientes de l’homme au travail, Le Journal des Psychologues 84(1991).[136] J. von Neumann, O. Morgenstern, Theory of Games and Economic Behavior, Princeton Univ. Press,Princeton, NJ, 1944.[137] B. Wilcox, Computer Go, American Go J. 13 (4,5,6) (1978), 14 (1,5,6) (1979), 19 (1984). Reprinted in:D.N.L. Levy (Ed.), Computer Games, Vols. 1 and 2, Springer, New York, 1988.[138] P. Woitke, New ladder participant, E-mail sent on 11th March 1996 to the Computer Go mailing list,http://www.cs.uoregon.edu/∼richard/computer-go/.[139] P. Woitke, Computer Go summary, E-mail sent on 5th October 1996 to the Computer Go mailing list,http://www.cs.uoregon.edu/∼richard/computer-go/.[140] T. Wolf, The program GoTools and its computer-generated tsume-go database, in: Proceedings of the FirstGame Programming Workshop in Japan, Hakone, 1994, p. 84.[141] T. Wolf, About problems in generalizing a tsumego program to open positions, in: Proceedings of the ThirdGame Programming Workshop in Japan, Hakone, 1996, pp. 20–26.[142] T. Wolf, Forward pruning and other heuristic search techniques in tsume go, Inform. Sci. 122 (2000) 59–76.B. Bouzy, T. Cazenave / Artificial Intelligence 132 (2001) 39–103103[143] H. Yamashita, Half extension algorithm, in: Proceedings of the Fourth Game Programming Workshop inJapan, Hakone, 1997, pp. 46–54.[144] H. Yamashita, YSS: About its datastructures and algorithm, in: H. Matsubara (Ed.), Computer ShogiProgress 2, Kyoritsu Shuppan Co, Tokyo, 1998, pp. 112–142 (in Japanese).[145] A. Yoshikawa, Y. Saito, The difference of the knowledge for solving Tsume-Go problem according to theskill, in: Proceedings of the Fourth Game Programming Workshop in Japan, Hakone, 1997, pp. 87–95.[146] A. Yoshikawa, T. Kojima, Y. Saito, Relations between skill and the use of terms—An analysis of protocolsof the game of Go, in: H.J. van den Herik, H. Iida (Eds.), Proceedings of the First International Conferenceon Computer and Games 98, Lecture Notes in Computer Science, Vol. 1558, Springer, Berlin, 1998,pp. 282–299.[147] A. Zobrist, A model of visual organization for the game of Go, in: Proc. AFIPS Spring Joint ComputerConference, Boston, AFIPS Press, Montvale, NJ, 1969, pp. 103–111.[148] A. Zobrist, A new hashing method with application for game playing, Technical Report 88, University ofWisconsin, April 1970. Reprinted in: ICCA J. 13 (2) (1990) 69–73.[149] A. Zobrist, Feature extractions and representation for pattern recognition and the game of Go, Ph.D. Thesis,Graduate School of the University of Wisconsin, Madison, WI, 1970.