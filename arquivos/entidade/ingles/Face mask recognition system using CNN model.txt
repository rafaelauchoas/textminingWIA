Since January 2020 Elsevier has created a COVID-19 resource centre with free information in English and Mandarin on the novel coronavirus COVID-19. The COVID-19 resource centre is hosted on Elsevier Connect, the company's public news and information website. Elsevier hereby grants permission to make all its COVID-19-related research that is available on the COVID-19 resource centre - including this research content - immediately available in PubMed Central and other publicly funded repositories, such as the WHO COVID database with rights for unrestricted research re-use and analyses in any form or by any means with acknowledgement of the original source. These permissions are granted for free by Elsevier for as long as the COVID-19 resource centre remains active.   Neuroscience Informatics 2 (2022) 100035Contents lists available at ScienceDirectNeuroscience Informaticswww.elsevier.com/locate/neuriNaaSFace mask recognition system using CNN modelGagandeep KaurPrabhash Pandey, Rohit Raj, Anshu Vashisth, Manik Rakhra, Ritesh Sinha, Puneet Kumar Tiwari, Srijan Kumar Yadav, ∗Department of Computer Science and Engineering, Lovely Professional university Phagwara, Punjab 144411, Indiaa r t i c l e i n f oa b s t r a c tArticle history:Received 29 September 2021Received in revised form 4 December 2021Accepted 6 December 2021Keywords:Artificial Intelligence (AL)Machine learning (ML)Deep neural learning (DL)Convolutional Neural Network Model (CNN)Artificial Neural Networks (ANN)SecurityCOVID-19 epidemic has swiftly disrupted our day-to-day lives affecting the international trade and movements. Wearing a face mask to protect one’s face has become the new normal. In the near future, many public service providers will expect the clients to wear masks appropriately to partake of their services. Therefore, face mask detection has become a critical duty to aid worldwide civilization. This paper provides a simple way to achieve this objective utilising some fundamental Machine Learning tools as TensorFlow, Keras, OpenCV and Scikit-Learn. The suggested technique successfully recognises the face in the image or video and then determines whether or not it has a mask on it. As a surveillance job performer, it can also recognise a face together with a mask in motion as well as in a video. The technique attains excellent accuracy. We investigate optimal parameter values for the Convolutional Neural Network model (CNN) in order to identify the existence of masks accurately without generating over-fitting.© 2021 The Authors. Published by Elsevier Masson SAS. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).1. IntroductionThe field of Artificial Intelligence (AI) research has advanced significantly in recent years, especially in the area of machine learning. Any newly developed technology is inseparable from the term AI. Without AI it is very difficult nowadays to make any significant progress in terms of technical innovation. AI is be-ing considered as the next big thing that will change the world tremendously. The use of neuroscience in marketing research is a new field that offers a tremendous promise, and how neuro-sciences require discipline that discipline requires great experience and costly technology, which is generally not found in marketing research companies [39].2. Artificial intelligenceThe term “AI” or “artificial intelligence” refers to the process of simulating human intelligence in a machine designed to think like a human being and imitate its actions. It can also be used in a machine that exhibits human-like characteristics like learn-ing and problem-solving. Building an intelligent machine that can solve any problem rapidly is not what AI entails, but rather build a machine that can-do things like human beings. Building machines * Corresponding author.E-mail address: gagandeep.23625@lpu.co.in (G. Kaur).that imitate humans, on the other hand, does not sound very excit-ing. From a contemporary perspective, whenever we talk about AI, we mean machines that can do one or more tasks: understand hu-man language, perform complex mechanical tasks, solve complex computer problems that may capture big data very quickly, and then respond with human-like responses, etc. In the future, smart machines will replace or improve people’s skills in various depart-ments. The ability of computers or software to show intelligence is known as Artificial intelligence (AI). Because AI has revolution-ized human life in so many ways, it is quickly becoming a popular field of Computer Science. Over the past couple of decades, “In-stallation ingenuity” has resulted in tremendous improvement in the performance of production and service systems. Artificial in-telligence research has resulted in the Expert system, which is a rapidly growing technology. Artificial Intelligence app areas have a significant effect on different aspects of life, as the professional system is now commonly used to solve complex problems in a va-riety of fields, including science, engineering, medicine, business, weather forecasting, and so on. Artificial Intelligence (AI)-enabled areas have witnessed a rise in quality and efficiency. AI technology has grown to the point where it offers real benefits to many of its programs. The primary disciplines of Artificial Intelligence include Natural Language Processing (NLP), Speech Understanding, Robotic, Expert Systems and Sensory Systems, Computer Vision and Scene Recognition, Intelligent Computer Assisted Instruction, and -Neural Computing. Expert Systems is a rapidly emerging technology that has a significant effect on many aspects of life. AI methods include https://doi.org/10.1016/j.neuri.2021.1000352772-5286/© 2021 The Authors. Published by Elsevier Masson SAS. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).G. Kaur, R. Sinha, P.K. Tiwari et al.Neuroscience Informatics 2 (2022) 100035neural networks, fuzzy logic, evolutionary computing, and hybrid artificial intelligence. Artificial intelligence has many benefits over natural intelligence, including the ability to be robust, standard-ised, cheap, repetitive, and distributed, as well as the ability to be written down and perform certain tasks much quicker and better than humans [1].2.1. Artificial intelligence applicationstainty is not taken into account, it is impossible to assess the quality of ANN predictions, greatly limiting their effectiveness. Although more work is required in the field of Artificial intel-ligence. A new ANN development process is required which should provide guidance for the selection of data sets and recommend the use of three statistically consistent but inde-pendent data sets, one for each training, test and validation [25–28].i. Artificial intelligence applications in the intensive care units.3. Machine learningIn recent years, many completely new intelligent systems have been developed and entered the market which can act as smart assistants for doctors and medical staff and assistants that can monitor the data flow. Data and manage the settings of various electronic devices. Although the devices used in the past were designed for medical use. Individual AI tools are in-volved in performing various tasks, such as data flow, device control, or waveform analysis. The deployment of these artifi-cial intelligence (AI) applications in intensive care units (ICUs) could reduce costs and improve demographics.ii. Artificial intelligence applications in finance.See current trends in marketing and change over time along with the increasingly uncertain and non-linear behaviour of the market. As a result, the need to solve unstructured and time-bound problems is growing rapidly. Other issues as well as traditional models have sparked growing interest in artifi-cial intelligence. There are three different artificial intelligence techniques used in financial markets namely artificial neu-ral networks, expert systems and hybrid intelligence systems. Three areas where financial markets have been classified: port-folio management, credit scoring, forecasting, and financial planning.2.2. Artificial intelligence challengesKey issues that have received recent attention and that will re-quire further research in the future include the development of approaches that: ensure the development of robust models, in-crease the transparency of the model and allow the extraction of knowledge from the trained ANNs, improve extrapolation capacity and deal with uncertainty. Each of these is covered below.i. Robustness of the modelANNs must find wider acceptance and exploit their full po-tential robust in a variety of conditions While ANNs that have only been validated against errors can provide accurate pre-dictions for situations that are contained in the training data, may not be robust under other conditions unless the relation-ship that generated the data has been reasonably estimated. Therefore, it is also important to evaluate the relationship that was modelled during the validation of an ANN, rather than to base its solely on a measure of error.ii. Transparency of the model and extraction of knowledgeOne of the main criticisms that is often expressed to the ANN is its lack of transparency, that is, they are often called “box models black” because they do not consider or explain the un-derlying physical processes.iii. ExtrapolationIt is generally accepted that ANNs perform better when they do not extrapolate beyond the range of the data used for cali-bration. Although it is not different from other models, it is an important limitation of ANNs, since it limits their usefulness and applicability.iv. UncertaintyFinally, another limitation of ANNs is that the uncertainty in the generated predictions is rarely quantified. If this uncer-2By definition, machine learning is a branch of computer science that originated from the study of pattern recognition and comput-erized learning theory in artificial intelligence. It is the learning and construction of algorithms that can learn and perform predic-tions on data sets. Rather than following rigid system instructions, these processes use model creation from model inputs to create data-driven predictions or selections. Arthur Samuel coined the term Machine Learning, or ML for short, in the sense of solving a test machine with a machine. This idea refers to a computer pro-gramme that can learn to exhibit behaviour that is not explicitly stated by the program’s designer. It can reflect the character the author is utterly ignorant of. This behaviour is learnt from three factors:• Data that the system makes use of,• ii. A metric that evaluates the error or type of distance be-tween present behaviour and ideal behaviour, and• A response mechanism that uses a measured error to lead the system to generate better behaviour at later events.As is shown, the last two factors easily abstract the definition and emphasise the deep roots of mathematics. Machine learning techniques are essential to building intelligent programs.Machine learning (ML) involves two types of activities:i. Supervised machine learning: The system is trained in a pre-determined set of training models, enhancing its capacity to reach a correct conclusion when presented with fresh data.ii. Unsupervised machine learning: The system is given a large amount of data and is required to identify patterns and corre-lations within it [1,2].3.1. Machine learning applicationsi. Computer visionComputer vision is a versatile area of machine learning that trains machines to process, analyse, and recognize visual data.ii. Speech recognitionSpeech recognition is a process of converting speech into text. It offers advantages for the healthcare, military, vehicle sys-tems or the creation of voice interfaces and voice assistants in everyday life, as it helps to improve accessibility.iii. Future PredictionsMachine learning can be used to create predictions based on historical data. Various use cases include stock price forecasts, research, marketing, and many other scenarios.iv. Email Spam and Malware FilteringThe email client uses a variety of spam filtering methods. Ma-chine learning is used to ensure that these spam filters are constantly updated.v. Online Fraud DetectionMachine learning has shown the ability to make cyberspace safer, one example being the detection of online financial crimes. For example, PayPal uses ML to combat money laun-dering. The organization uses a combination of techniques that G. Kaur, R. Sinha, P.K. Tiwari et al.Neuroscience Informatics 2 (2022) 100035enable the comparison of millions of transactions and the dis-tinction between legal and illegal transactions between buyers and sellers [30].3.2. Machine learning challengesi. Machine learning challenges in manufacturing• Implementation of advanced production technologies.• Sustainable production (processes) and products.• New paradigms in production management.• Efficient and flexible business and supply chain capabilities.• Close cooperation between industry and scientists to intro-duce new technologies.• Growing importance of the production of products with high added value.• The use of advanced knowledge, information management systems and artificial intelligence.• Innovation in products, services and processes.These main challenges highlight the continuing trend towards more complex and dynamic development in the manufactur-ing sector. Machine learning technology is well suited to meet some of the major challenges of today’s complex manufactur-ing systems [29].ii. Machine learning challenges in Big Dataa. VolumeOne of the biggest challenges in big data computing stems from the simple principle that scaling, or volume, increases computational complexity. As a result, even trivial opera-tions can become expensive as they grow. Also, as the size of the data increases, the performance of the algorithms de-pends more on the architecture used to store and move data. Several classes of algorithms are designed based on strategies and building blocks that depend on the valid-ity of this assumption. However, when the size of the data leads to the failure of this premise, the entire family of algo-rithms suffers. As data sets get larger, the assumption that the data is uniformly distributed across all classes is often broken. This leads to a challenge known as class imbalance: The performance of machine learning algorithms can be ad-versely affected when the dataset contains data from classes with different occurrence probabilities. Another problem as-sociated with large volumes of data is the dimensional curse, which refers to the difficulties encountered when working in a multi-dimensional space. The high dimension-ality is closely related to another volume challenge: feature engineering. This is the process of building functionality, often using domain knowledge, to improve machine learn-ing performance. The problem of nonlinearity in large data sets also arises from the difficulty of estimating linearity. Linearity is often assessed using graphical techniques such as scatter plots; however, in the case of big data, a large number of points often creates a large cloud, which makes it difficult to observe the relationship and assess linearity [16,17,19,31,32].b. VarietyBig Data Variety describes not only the variability in the structure of the data set and the types of data it contains, but also the variety of what it represents, its semantic in-terpretation, and its sources. The first challenge associated with diversity is the locality of the data. Machine learn-ing algorithms, in turn, assume that the entire data set is in memory or in a single file on disk. In the case of big data, however, this may not be possible due to its large size; Not only does the data not fit in memory, it is often spread across a large number of files that are in differ-ent physical locations. Machine learning typically requires a pre-processing and data cleaning step to configure data to fit a particular model. However, with data from differ-ent sources, that data may be formatted differently. Fur-thermore, the data to be processed can be of completely different types; for example, it may be necessary to pro-cess images with categorical and numerical data. This poses challenges for machine learning algorithms, as they are not designed to recognize different types of representations at the same time and to generate efficient uniform general-izations. Large datasets can be too noisy to get meaningful results [20,21,31,32].c. VelocityMeasuring the velocity of big data refers not only to the speed at which data is generated, but also to the speed at which it must be analysed. Many machine learning methods depend on data availability, which means that before train-ing starts, the dataset has been assumed to be available. However, in the context of data transmission, where new data is constantly arriving, such a request cannot be met. In addition, even data arriving in non-real-time intervals can be an issue. Similar to the demand for data availability al-ready discussed, traditional machines learning approaches are not designed to handle constant data flows, resulting in another speed dimension required by a real-time require-ment. Big data is not stationary; new data is constantly coming in. Hence, it is not possible to obtain the entire dataset prior to processing, which means that it is not pos-sible to establish whether the current data has the same distribution as the future data. This leads to another in-teresting big data machine learning problem: concept drift. Concept drift can be formally defined as changes in the con-ditional distribution of the target output of a given input, while the distribution of the input itself may remain un-changed [15,17,18,22,31,32].d. VeracityThe veracity of big data is related not only to the reliability of the data that make up a data set, but also to the inher-ent unreliability of data sources. In the context of big data, the source data set becomes too large. While this data pro-vides great context for machine learning, the sheer volume of this metadata creates its own challenges. In the context of big data, the source data set becomes too large. While this data provides great context for machine learning, the sheer volume of this metadata creates its own challenges. There are inherent uncertainties in various types of data, such as meteorological or economic data, and even the most sophisticated methods of data pre-processing cannot elimi-nate this inherent unpredictability. Again, machine learning algorithms are not designed to deal with this type of in-accurate data, creating other unique challenges for machine learning with big data [18,23,24,31,32].4. Deep learningDeep learning is classified as a joint domain of machine learn-ing. It is a field that takes information from the past and provides the desired output through the analysis of advanced computer al-gorithms. Machine learning uses concepts like data mining and configuration, while deep learning is more concerned with artifi-cial neural networks that are designed to function and mimic hu-man behaviour to act like humans. Modern computing techniques restrict neural networks and each problem has its own complexity. Fortunately, advances in big data and tools have made more re-sources available to decipher new advancements in the technology3G. Kaur, R. Sinha, P.K. Tiwari et al.Neuroscience Informatics 2 (2022) 100035sector. Deep learning has done a great job in image classification, speech processing, and speech recognition. It is used to solve any problem without human intervention.An artificial ANN neural network is made up of the vast amount of data used for modern technologies such as VRV systems, and the goal of developing the ANN was to create a neural network capa-ble of doing things that a human being can do. Studies have shown that the artificial neural network is capable of running large data sets in large quantities. Deep learning uses two layers, which is why the term deep got its name because it delves into the dataset and analyses it, while the artificial neural network lacks these, if machine learning algorithms can perform a certain task, the Deep learning can go beyond steps to develop results and achieve de-sired results and establish a framework for artificial neural network models [3].4.1. Deep learning applicationsi. Self-driving carsCompanies that develop this type of driver assistance services, as well as fully-fledged autonomous cars such as Tesla. Digital sensor systems take over important parts (or the whole) of driving rather than the human senses that Tesla has to teach a computer to. Organizations generally use a large amount of data to start training algorithms [33].ii. Deep Learning in HealthcareDeep learning is the only way to use computers to detect and diagnose disease. Deep learning is widely used for medical science, drug discovery, and the diagnosis of life-threatening diseases such as cancer and diabetic retinopathy through the medical imaging mechanism.iii. Voice Search and voice activated assistantsOne of the coolest and most popular deep learning assistants are voice assistants. They understand natural language and do the work for us. Voice assistants can be found on almost ev-ery smartphone, because the giants of big technologies have already invested a lot in this area.iv. Machine TranslationIt automatically Translates words, phrases or sentences from one language to another language automatically. Machine translation has been around for a long time, but thanks to deep learning, we can now achieve the best in two areas:• Automatic Text Translation• Automatic Image Translationv. ChatbotsIt’s an AI-powered online chat application that uses text or text-to-speech. Chatbots can solve customer problems in sec-onds. He can act and behave like a human. Chatbots are mainly used for customer interaction, advertising on social media and messaging. It automatically responds to data entered by the user. It uses deep learning and machine learning algorithms to generate various kinds of reactions.4.2. Deep learning challengesi. Opacity of Neural NetworksSince deep learning neural networks are usually smeared, it’s impossible to explain the results we’re seeing. Each neural net-work has millions of parameters, or neurons, and each one is unique.ii. Ensuring Data qualityThe models which we use in machine learning and the deep learning require data and lots of data which should be of a very high quality to be able to perform the heavy tasks like image recognition or face detection. The second and the most important thing which is required is the amount of accuracy which is one of the main reasons to use the deep learning concepts in computer.iii. Data SecurityData security is a major concern when we talk about the ma-chine learning technologies in the current time. If any system which is not capable to ensure that the data in that is not safe and if any third party can access it then the data is un-safe. The intelligent systems are widely used over the world to make sure that the data is safe inside the system and no other has access to it.iv. Production Grade AIProduction-grade AI can be implemented if the system is ca-pable of performing and delivering the output of result in a certain amount of time, required that both hardware and software should work. The systems should be reliable on the optimal conditions if the system goes into a failure if they are based on the cloud. Other concerns are the data security and these things will increase the production grade AI and solve the real-world problems (Fig. 1).Fig. 1. CNN Architecture.4G. Kaur, R. Sinha, P.K. Tiwari et al.5. Literature reviewP. Gupta, N. Saxena, M. Sharma, J. Tripathi (2018) has published the paper on face recognition that introduces a new way of us-ing a deep neural network (another type of deep network). In this proposed approach, only the extracted facial features are provided instead of providing raw pixel values as input. Facial features are being extracted with the help of Haar Cascade and feeding these facial features rather than raw pixel values. As the number of re-dundant input features has been decreased, the complexity of the neural network-based recognition framework is also decreased. It also makes the process lighter and faster by using DNN instead of Convolutional Network. The proposed method does not com-promise the accuracy of the framework, as average accuracy so obtained is 97.05% [4].K. J. Bhojane, S. S. Thorat (2018) has make use of embedding face detection and face tracking system algorithm found in MAT-LAB with the help of Raspberry pi B, for face recognition system. To create a safe environment for ignition and access to the car, it uses the Haarlike function that was used to recognize and recog-nize the authenticated user’s face. The face of an individual is the main aspect of the car ignition in secure environment. The ges-ture identification and control research are taken into account for future work [5].M. Rahman, S. Mahmud, J. Kim, Md. M. Manik, Md. M. Islam (2020) published a document aimed at developing a system for determining whether a person uses a mask or not and informing the relevant authority in the smart city network. It makes use of real-time filming of various public places of the city to capture the facial images. The facial images extracted from this video is be-ing used to identify the masked faces. The convolutional neural network (CNN) learning algorithm is used to extract features from images, after which those features are learned through multiple hidden layers. Whenever the architecture identifies people with-out a mask, this information is passed through the city network to the appropriate authority in order to take the necessary actions. The proposed system assessed promising results based on data col-lected from various sources. In these documents, they also set out a system that can ensure proper law enforcement against people who do not follow basic health guidelines in this pandemic situa-tion [6].A. Chavda, J. Dsouza, S. Badgujar, A. Damani (2020) in these pa-per authors have proposed a two-stage architecture. Stage 1 is a face detector that acts as the first stage of the system. A raw RGB image is transferred as input to this stage. The face detector ex-tracts and generates all recognized faces in the image with their bounding box coordinates. Accurate facial recognition is very im-portant to our architecture. Training a high-precision face detector requires a great deal of tagged data, time, and computational re-sources. Level 2 The second level of the system is a mask sorter. In this phase, the processed ROI is taken from the intermediate processing block and classified in such a way that the dataset also contains images of misused face masks or hands covering the face, which are classified as unmasked faces [7].J. Sunny, S. George & J. Kizhakkethottam (2015) has published this paper to impart light on the usage of sensors of sensible de-vices as an alternative to the recognition of human action (HAR). Automatic physical activity detection, commonly known as Human Action Recognition (HAR), has become a key analytical space in human-computer interaction (HCI) and contemporary mobile com-puting. One of the goals of activity detection is to provide data on user behaviour that enables computer systems to proactively assist users in their tasks. Recognition of human actions requires continuous classification algorithms derived from statistical ma-chine learning techniques. Most of the time, supervised or semi-supervised learning techniques are used and these techniques are Neuroscience Informatics 2 (2022) 100035based on labelled data, i.e., related to a selected category or activ-ity. This is not without its disadvantages and limitations. Subject sensitivity, Location Sensitivity, Activity complexity are a number of the issues in totally realizing this technology [8].Francesca Nonis et al. (2019) in this paper, numerous usages and challenges of the facial recognition System (FRS) for the aim of serving to in communicating human emotions by the authors. Of all facial features, fifty-fifths of feelings and attributes are ex-pressed through facial features, which were reported by Mehrabian et al. to be shown. Few symptoms of depression are dampened fa-cial expressions, avoiding direct eye contact. Numerous states like happiness, anger, sadness, surprise, disgust and worry are totally different facial expressions as classified by Ekman. Driver safety like sleepiness detection, Pain analysis in health care, video con-ferencing, MasterCard verification, criminal identification, facial ac-tion synthesis for animation business and cognitive sciences are its application. The challenges Janus-faced are occlusion (It happens because of beard, cap, mask, etc.), unhealthy lighting conditions, movement of head while capturing of image [9].D. Bhamare & P. Suryawanshi (2019) summarize and analyze many well-known techniques in the multiple steps of the pattern recognition system and identify the analysis and application top-ics that are at the forefront of this exciting and complex area, is the target of this review paper. In the literature, pattern recogni-tion frameworks are approached through closer machine learning strategies. Application like data processing, retrieval of multimedia information, internet searching, face recognition and cursive hand-writing recognition, need strong and economical pattern recogni-tion techniques. A number of the challenges faces in totally real-izing this area unit information assortment, Segmentation, Feature Extraction etc. [10].Vinitha & Velantina (2020) published one article in which, using a deep learning algorithm and computer vision, they proposed a system that focuses on how to distinguish a person with a masked face in an image / video stream. Libraries like Tensor flow, Open CV, Keras and PyTorch are being used. The project is being imple-mented in two stages. The phase one consists of training a deep learning model followed by the second phase where mask detector is applied on live image/video stream. The framework used to do real-time face detection from a live stream via webcam is OpenCV. With computer vision using Python, COVID-19 face mask detector has been build using a dataset [11].R. Bhuiyan, S. Khushbu, S. Islam (2020) have published one pa-per in which the proposed system aims for recognizing the masked and faces are rendered using the advanced YOLOv3 architecture. YOLO (You Only Look Once), uses the learning algorithm Convo-lution Neural Network (CNN). YOLO establishes a connection with CNN through hidden layers, through research, easy algorithm re-trieval, and can detect and locate any type of image. Execution be-gins by taking 30 unique images of the dataset into the model after combining the results to derive action-level predictions. It gives ex-cellent imaging results and also good detection results. This model is applied to a live video to check if the fps rate of the model inside the video and its detection performance with masked/un-masked two layers. Inside video, our model has impressive outputs with an average fps of 17. This system is more efficient and faster than other methods using their own data set [12].T. Meenpal, A. Balakrishnan, A. Verma (2019) has introduced a semantic segmentation, a model for face detection using in an image by categorising each of pixel into face and non-face. It effi-ciently creates a binary classifier and then recognize that fragment into chunks. The design allows you to create accurate face masks for human objects from RGB images containing localized objects. The author demonstrated the results on the Multi Human Parsing Dataset with an average accuracy at the pixel level. In addition, the problem of erroneous predictions is resolved and the correct 5G. Kaur, R. Sinha, P.K. Tiwari et al.Neuroscience Informatics 2 (2022) 100035Table 1Comparison of already existing models.REFERENCEYEARACCURACYTECHNOLOGY /TOOL USEDOPTIMIZATIONP. Gupta, N. Saxena, M. Sharma, J. Tripathi (2018)K. J. Bhojane, S. S. Thorat (2018)M. Rahman, S. Mahmud, J. Kim, Md. M. Manik, Md. M. Islam (2020)Vinitha & Velantina (2020)R. Bhuiyan, S. Khushbu, S. Islam (2020)[4][5][6][11][12]20182018202020202020HIGH (97.05%)HIGHMEDIUMMEDIUMHIGHHaar Cascade DNNMATLAB, Raspberry pi BCNN ModelComputer Vision, Deep LearningYOLOYESYESNONOYESbounding box is drawn around the segmented area. The proposed network can detect non-frontal faces and multiple faces in one im-age. The method can be used for complex tasks such as detecting parts of the face [13].and without mask. The same model can be used for different pur-poses related to image processing in neuroscience using dataset containing images related to that task.6. DatasetThe dataset used in this project is a Face dataset (with/without mask dataset) [14] from Kaggle.com. The dataset consists of 3,832 images divided into two mask classes:• images taken with a mask:1914,• images taken without a mask:1918Dataset is the major part for building the CNN model (Table 1). More the amount of dataset images is, the more accurate the model will be.7. ScopeEven if several case studies have been enrolled to demonstrate the real-time scenario of the COVI-19 issue, the deployment of the systems in real-time is extremely difficult. Developing a sys-tem that is adaptive to all contexts and surroundings is becoming a difficulty. The proposed device might be deployed in high-traffic areas to keep a close eye on people. If we consider the cost esti-mation for implementing the project, it will be almost of no cost as most of the metropolitan cities already have cameras installed in public places. Camera; which is the only main requirement of the proposed model is already available. Our model is based on neural networks. A neural network is a network or circuit of neu-rons, which is also called an artificial neural network and is made up of artificial neurons or nodes. Some of the important types of neural networks are Artificial Neural Networks (ANN), Convolution Neural Networks (CNN), Recurrent Neural Networks (RNN). Differ-ent fields including Math, Physics, and Neuroscience have all had an impact on Artificial Neural Networks. Neuroscience made a sig-nificant contribution to the original inspiration for Artificial Neural Networks. Consider the recent success of biologically inspired Con-volutional Neural Networks (CNN).• Learning Dynamic is the same as Cost Function Optimization in the brain.• Task Specificity is required for both architectures and cost functions to reach a satisfactory level of performance.These are some of the ANN inspired speculations in the Compu-tational Neuroscience field. CNN is well versed in neuroscience field. To extract characteristics from MRI images, a CNN was used. CNN creates a link between medical and technology fields. The discipline of neuroscience informatics focuses on multidisciplinary, translational, and technological research that is fuelled by imag-ing. While in image and video processing tasks, CNN is extremely common. There is so much of scope for CNN in neuroscience in-formatics. The face mask recognition system, which is based on CNN model uses dataset consists of different facial images with 8. MethodologyWe used python script, tensor flow, and CNN as deep learn-ing architecture to develop an efficient network for recognising facemasks. Our objective is to train a specialised CNN model to detect whether or not someone is wearing a mask. This project can instantly recognise the faces of the mask from any angle. It generates output from an RGB input image of any orientation. The primary responsibility of this function is to extract characteris-tics from photographs and predict which class they belong to. The feature extraction approach sketches the image and transforms it into a new image, which is more efficient than the previous im-age. The dimensionality of photographs is reduced to an efficient representation in this section. In our recommended concept, the camera might be utilised to recognise the mask face. To begin, re-size the input image to 100*100 then extract and forecast features. We are provided some model data with their accuracy level when the training phase is done.The implementation of the project is carried out in python notebook. Libraries like pandas, NumPy, matplotlib, sklearn, etc. are used. To train the CNN model (Fig. 2) and to run the python code for the project the following libraries with the given or higher ver-sion is required:TensorFlow 1.15.2, Keras 2.3.1, NumPy 1.18.2, Matplotlib 3.2.1, SciPy 1.4.1, Imutils 0.5.3, OpenCV-python 4.2.0.*To train the face mask detector, we have to divide our project into two stages:Training: We will collect our facial mask detection record of a hard drive to form a model (with keras / tensorflow) and finally serial-ize the facial mask detector on the disk.Deployment: After the face mask detector has been trained, we charge the mask detector, perform face recognition, and then de-cide whether each face is equipped with or without a mask. Also, it will require a webcam [34–36].The above two phases have their own sub-steps which is show in Fig. 3.9. ResultThe results are more of what was expected of the model. The mask recognition is implemented using the camera as a medium and shows accurate results. When the persons face is in the cam-era frame, model will detect the face and a green or a red frame will appear over the face (Figs. 4.1 and 4.2). A person who is not wearing mask will get a red frame over his face in camera while the person who is wearing mask will get a red frame. The result is also visible written on top left of the result frame. A percentage match can also be seen on the top of the result frame. The model works even if the side view of the face is visible to the camera. It can also detect more than one face in single camera frame. Overall, the model shows the accurate results [40–45].6G. Kaur, R. Sinha, P.K. Tiwari et al.Neuroscience Informatics 2 (2022) 100035Fig. 2. Steps in building the CNN model.Fig. 3. Process flow of data.10. Future scopeAcross the globe more than 70 countries have made it manda-tory to wear masks at all public places. If you want to go out you have to cover your face in schools, supermarkets, transports, offices, stores and at all public places. Most retail stores use soft-ware to count the total number of customer visit to the store. For this reason, we plan to update the mask recognition system and announce it as an open source project. This system can be im-plemented in these retail shops and the result can be seen on the 7digital and promotional screens [46–52]. This app can be used with any current USB, IP, or CCTV cameras for identifying people who do not wear a mask. The live video mask detection function can be in-troduced in web and desktop applications so that the operator may know whether users are not wearing masks and warning messages can be lost. If anyone isn’t wearing a mask, images should be sub-mitted to software operators. Furthermore, we can mount an alarm device that will emit a beep sound if anyone enters the area with-out wearing a mask. Only people wearing face masks can enter using this software, which can be linked to the entrance gates. This G. Kaur, R. Sinha, P.K. Tiwari et al.Neuroscience Informatics 2 (2022) 100035Fig. 4.1. Testing with Mask.Fig. 4.2. Testing without mask.system could be connected in hospital gates, schools, malls and at many more public places [37,38].11. ConclusionMeasures must be taken to control the spread of the COVID19 pandemic. This face mask recognition system is a very good and efficient way to do so. The system will separate the people from the crowd who are not wearing mask. The identification of peo-ple, violating the COVID norms increases the adaptability of the face mask detection system for the public sake. If applied in a cor-rect way, the face mask detection system could be used to make sure our safety and for others too. This approach gives not only helps in achieving high precision but also enhance the face detec-tion tempo considerably. The system can be applied in many areas like metro stations, markets, schools, railway stations and many other crowded places to monitor the crowd and to ensure that ev-eryone is wearing mask. Finally, this work can be used for future researchers and enthusiasts. Firstly, this model can be used in any high-definition camcorders, this will make sure that this model is not limited to only face mask detection system. Secondly, this can be used for biometric scans with a mask on the face.Declaration of competing interestThere is no any Conflict of Interest.References[1] Z. Zhang, B. Bowes, The future of artificial intelligence (AI) and machine learn-ing (ML) in landscape design: a case study in coastal Virginia, USA, J. Digital Landscape Arch. 2019 (4) (2019) 2–9, https://doi .org /10 .14627 /537663001.[2] S.Y. Kung, M.W. Mak, Machine learning for multimodality genomic signal pro-cessing, IEEE Signal Process. Mag. 23 (3) (2006) 117–121, https://doi .org /10 .1109 /MSP.2006 .1628886.[3] D. Duarte, F. Nex, N. Kerle, G. Vosselman, Satellite image classification of build-ing damages using airborne and satellite image samples in a deep learning approach, in: ISPRS Annals of the Photogrammetry, Remote Sensing and Spa-tial Information Sciences, vol. 4(2), 2018, pp. 89–96.[4] P. Gupta, N. Saxena, M. Sharma, J. Tripathi, Deep neural network for human face recognition, Int. J. Eng. Manufact. 8 (1) (2018) 63–71, https://doi .org /10 .5815 /ijem .2018 .01.06.[5] K.J. Bhojane, S.S. Thorat, A review of face recognition based car ignition and security system, Int. Res. J. Eng. Technol. 05 (01) (2018) 532–533.[6] S. Mahmud, J. Kim, An Automated System to Limit COVID-19 Using Facial Mask Detection in Smart City Network, 2021, pp. 11–15.[7] Sushovan Chaudhury, Manik Rakhra, Naz Memon, Kartik Sau, Melkamu Teshome Ayana, Breast cancer calcifications: identification using a novel segmentation approach, Comput. Math. Methods Med. 2021 (2021) 9905808, https://doi .org /10 .1155 /2021 /9905808, 13 pages.8[8] J.T. Sunny, S.M. George, Applications and challenges of human activity recogni-tion using sensors in a smart environment, 2 (04) (2015) 50–57.[9] M. Rakhra, R. Singh, Economic and social survey on renting and hiring of agri-cultural equipment of farmers in Punjab, in: 2021 9th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Di-rections) (ICRITO), 2021, pp. 1–5.[10] D. Bhamare, P. Suryawanshi, Review on reliable pattern recognition with ma-chine learning techniques, Fuzzy Inf. Eng. 10 (1) (2019) 1–16, https://doi .org /10 .1080 /16168658 .2019 .1611030.[11] V. Vinitha, V. Velantina, COVID-19 Facemask Detection with Deep Learning and Computer Vision, 2020.[12] R. Bhuiyan, A Deep Learning Based Assistive System to Classify COVID-19 Face Mask for Human Safety with YOLOv3, 2020.[13] T. Meenpal, Facial mask detection using semantic segmentation, in: 2019 4th International Conference on Computing, Communications and Security (ICCCS) (October), 2019, pp. 1–5.[14] https://drive .google .com /drive /folders /1Dm2sV8UrMd6OKzjVkW859WznhfSXFZF8.[15] K. Grolinger, M. Hayes, W.A. Higashino, A. L’Heureux, D.S. Allison, M.A.M. Capretz, Challenges for MapReduce in big data, in: Proc. IEEE World Congr. Services (SERVICES), Jun. 2014, pp. 182–189.[16] M.M. Najafabadi, F. Villanustre, T.M. Khoshgoftaar, N. Seliya, R. Wald, E. Muharemagic, Deep learning applications and challenges in big data analytics, Big Data 2 (1) (Feb. 2015) 1.[17] K.F. Tasneem, et al., Affordable black box: a smart accident detection system for cars, in: 2021 9th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO), 2021, pp. 1–5.[18] S. Takkar, et al., Advanced ATM security system using Arduino Uno, in: 2021 9th International Conference on Reliability, Infocom Technologies and Opti-mization (Trends and Future Directions) (ICRITO), 2021, pp. 1–5.[19] M. Rakhra, et al., E-commerce assistance with a smart chatbot using artificial intelligence, in: Proc. 2021 2nd Int. Conf. Intell. Eng. Manag. ICIEM 2021, 2021, pp. 144–148.[20] M. Rakhra, R. Singh, T.K. Lohani, M. Shabaz, Metaheuristic and Machine Learning-Based Smart Engine for Renting and Sharing of Agriculture Equip-ment, Vol. 2021, 2021.[21] J. Wang, D. Crawl, S. Purawat, M. Nguyen, I. Altintas, Big data provenance: chal-lenges, state of the art and opportunities, in: Proc. IEEE Int. Conf. Big Data (Big Data), Oct. 2015, pp. 2509–2516.[22] M. Schroeck, R. Shockley, J. Smart, D. Romero-Morales, P. Tufano, Analytics: the real-world use of big data, Tech. Rep. GBE03519-USEN00, IBM Global Business Services Saïd Business School Univ. Oxford, 2012, pp. 1–20.[23] M. Rakhra, R. Singh, Internet based resource sharing platform development for agriculture machinery and tools in Punjab, India, in: ICRITO 2020 - IEEE 8th Int. Conf. Reliab. Infocom Technol. Optim. (Trends Futur. Dir., 2020, pp. 636–642.[24] Y. ting Zhuang, F. Wu, C. Chen, Y. he Pan, Challenges and opportunities: from big data to knowledge in AI 2.0, Front. Inf. Technol. Electron. Eng. 18 (1) (2017) 3–14, https://doi .org /10 .1631 /FITEE .1601883, Zhejiang University.[25] M.B. Jaksa, H.R. Maier, M.A. Shahin, Future Challenges for Artificial Neural Net-work Modelling in Geotechnical Engineering, 2008.[26] D.J. Musliner, J.A. Hendler, A.K. Agrawala, E.H. Durfee, J.K. Strosnider, C.J. Paul, U. Maryland, The Challenges of Real-Time AI, 1994.[27] T. Wuest, D. Weimer, C. Irgens, K.D. Thoben, Machine learning in manufac-turing: advantages, challenges, and applications, Product. Manufact. Res. 4 (1) (2016) 23–45, https://doi .org /10 .1080 /21693277.2016 .1192517.G. Kaur, R. Sinha, P.K. Tiwari et al.Neuroscience Informatics 2 (2022) 100035[28] N. Sharma, R. Sharma, N. Jindal, Machine learning and deep learning applications-a vision, Global Trans. Proc. 2 (1) (2021) 24–28, https://doi .org /10 .1016 /j .gltp .2021.01.004.[29] Machine learning on big data: opportunities and challenges, http://www.elsevier.com /open -access /userlicense /1.0/, 2017.[30] A. L’Heureux, K. Grolinger, H.F. Elyamany, M.A.M. Capretz, Machine learning with big data: challenges and approaches, IEEE Access 5 (2017) 7776–7797, https://doi .org /10 .1109 /ACCESS .2017.2696365.[31] K.J. Bhojane, S.S. Thorat, A review of face recognition based car ignition and security system, Int. J. Res. Eng. Technol. 9001 (2008), http://www.irjet .net.[32] S.R. Karanam, Y. Srinivas, M.V. Krishna, Study on image processing using deep learning techniques, in: Materials Today: Proceedings, 2020.[33] P. Gupta, N. Saxena, M. Sharma, J. Tripathi, Deep neural network for human face recognition, Int. J. Eng. Manufact. 8 (1) (2018) 63–71, https://doi .org /10 .5815 /ijem .2018 .01.06.[34] Y. Duan, J. Lu, J. Zhou, UniformFace: learning deep equidistributed represen-tation for face recognition, in: IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), 2019, pp. 3415–3424.[35] R. Ramachandra, S.K. Venkatesh, K.B. Raja, S.K. Bhattacharjee, P.S. Wasnik, S. Marcel, C. Busch, Custom silicone face masks: vulnerability of commercial face recognition systems & presentation attack detection, in: 2019 7th International Workshop on Biometrics and Forensics (IWBF), 2019, pp. 1–6.[36] P.P. Raut, N.R. Borkar, M.E. Student, S. Kamlatai Gawai, Techniques and imple-mentation of face spoof recognition: perspectives and prospects, Int. J. Eng. Sci. Comput. (2018), http://ijesc .org/.[37] T. Abe, I. Kinsella, S. Saxena, L. Paninski, J.P. Cunningham, Neuroscience cloud analysis as a service, BioRxiv. (2020), https://doi .org /10 .1101 /2020 .06 .11.146746.[38] S. Balaji, B. Balamurugan, T. Ananth Kumar, R. Rajmohan, P. Praveen Kumar, A brief survey on AI based face mask detection system for public places, Irish Interdiscipl. J. Sci. Res. 5 (1) 108–117, http://www.iijsr.com.[39] Y. Chen, M. Hu, C. Hua, G. Zhai, J. Zhang, Q. Li, S.X. Yang, Face mask assistant: detection of face mask service stage based on mobile phone, http://arxiv.org /abs /2010 .06421, 2020.[40] P. Nagrath, R. Jain, A. Madan, R. Arora, P. Kataria, J. Hemanth, SSDMNV2: a real time DNN-based face mask detection system using single shot multibox detector and MobileNetV2, Sustain. Cities Soc. 66 (2021) 102692, https://doi .org /10 .1016 /j .scs .2020 .102692.[41] S. Teboulbi, S. Messaoud, M.A. Hajjaji, A. Mtibaa, Real-time implementation of AI-based face mask detection and social distancing measuring system for COVID-19 prevention, Sci. Program. 2021 (2021) 8340779, https://doi .org /10 .1155 /2021 /8340779.[42] J.S. Talahua, J. Buele, P. Calvopina, J. Varela-Aldas, Facial recognition system for people with and without face mask in times of the covid-19 pandemic, Sus-tainability (Switzerland) 13 (12) (2021), https://doi .org /10 .3390 /su13126900.[43] M. Shabanian, E.C. Eckstein, H. Chen, J.P. DeVincenzo, Classification of neu-rodevelopmental age in normal infants using 3D-CNN based on brain MRI, in: 2019 IEEE International Conference on Bioinformatics and Biomedicine (BIBM), November 2019, pp. 2373–2378.[44] S. Winzeck, S.J.T. Mocking, R. Bezerra, M.J.R.J. Bouts, E.C. Mcintosh, I. Diwan, P. Garg, A. Chutinet, W.T. Kimberly, W.A. Copen, P.W. Schaefer, H. Ay, A.B. Singhal, K. Kamnitsas, B. Glocker, A.G. Sorensen, O. Wu, Ensemble of convolutional neu-ral networks improves automated segmentation of acute ischemic lesions us-ing multiparametric diffusion-weighted MRI, Am. J. Neuroradiol. 40 (6) (2019) 938–945, https://doi .org /10 .3174 /ajnr.A6077.[45] A. Radmanesh, A. Derman, Y.W. Lui, E. Raz, J.P. Loh, M. Hagiwara, M.J. Borja, E. Zan, G.M. Fatterpekar, COVID-19–associated diffuse leukoencephalopathy and microhemorrhages, Radiology 297 (1) (2020) E223–E227, https://doi .org /10 .1148 /radiol .2020202040.[46] M. Wintermark, L. Coombs, T.J. Druzgal, A.S. Field, C.G. Filippi, R. Hicks, R. Horton, Y.W. Lui, M. Law, P. Mukherjee, A. Norbash, G. Riedy, P.C. Sanelli, J.R. Stone, G. Sze, M. Tilkin, C.T. Whitlow, E.A. Wilde, G. York, J.M. Provenzale, Trau-matic brain injury imaging research roadmap, Am. J. Neuroradiol. 36 (3) (2015) E12–E23, https://doi .org /10 .3174 /ajnr.A4254.[47] G.C. Chiang, J.C. Cruz Hernandez, K. Kantarci, C.R. Jack, M.W. Weiner, Cerebral microbleeds, CSF p-tau, and cognitive decline: significance of anatomic distri-bution, Am. J. Neuroradiol. 36 (9) (2015) 1635–1641, https://doi .org /10 .3174 /ajnr.A4351.[48] G. Zaharchuk, E. Gong, M. Wintermark, D. Rubin, C.P. Langlotz, Deep learning in neuroradiology, Am. J. Neuroradiol. 39 (10) (2018) 1776–1784, https://doi .org /10 .3174 /ajnr.A5543, American Society of Neuroradiology.[49] C.H. Suh, W.H. Shim, S.J. Kim, J.H. Roh, J.H. Lee, M.J. Kim, S. Park, W. Jung, J. Sung, G.H. Jahng, Development and validation of a deep learning-based au-tomatic brain segmentation and classification algorithm for Alzheimer disease using 3D T1-weighted volumetric images, Am. J. Neuroradiol. 41 (12) (2020) 2227–2234, https://doi .org /10 .3174 /ajnr.A6848.[50] A. Traboulsee, J.H. Simon, L. Stone, E. Fisher, D.E. Jones, A. Malhotra, S.D. New-some, J. Oh, D.S. Reich, N. Richert, K. Rammohan, O. Khan, E.W. Radue, C. Ford, J. Halper, D. Li, Revised recommendations of the consortium of MS centers task force for a standardized MRI protocol and clinical guidelines for the diagnosis and follow-up of multiple sclerosis, Am. J. Neuroradiol. 37 (3) (2016) 394–401, https://doi .org /10 .3174 /ajnr.A4539, American Society of Neuroradiology.[51] W. Lin, T. Tong, Q. Gao, D. Guo, X. Du, Y. Yang, G. Guo, M. Xiao, M. Du, X. Qu, Convolutional neural networks-based MRI image analysis for the Alzheimer’s disease prediction from mild cognitive impairment, Front. Neurosci. 12 (V) (2018), https://doi .org /10 .3389 /fnins .2018 .00777.[52] P. Pandiyan, Social distance monitoring and face mask detection using deep neural network, https://www.researchgate .net /publication /347439579.9