Artificial Intelligence 259 (2018) 52–90Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintMeasuring inconsistency with constraints for propositional knowledge basesKedian MuSchool of Mathematical Sciences, Peking University, Beijing 100871, PR Chinaa r t i c l e i n f oa b s t r a c tArticle history:Received 16 May 2016Received in revised form 12 February 2018Accepted 20 February 2018Available online 2 March 2018Keywords:InconsistencyConstraintsCausalityBipartite graphMeasuring inconsistency has been considered as a necessary starting point to understand the nature of inconsistency in a knowledge base better. For practical applications, however, we often have to face some constraints on resolving inconsistency. In this paper, we propose a graph-based approach to measuring the inconsistency for a propositional knowledge base with one or both of two typical types of constraints on modifying formulas. Here the first type of constraint, called the hard constraint, describes a pair of sets of formulas such that all the formulas in the first set should be protected from being modified on the condition that all the formulas in the second set must be modified in order to restore the consistency of that base, while the second type, called the soft constraint, describes a set of pairs of formulas that are not allowed to be modified together. At first, we use a bipartite graph to represent the relation between formulas and minimal inconsistent subsets of a knowledge base. Then we show that such a graph-based representation allows us to characterize the inconsistency with constraints in a concise way. Based on this characterization, we thus propose measures for the degree of inconsistency and for the responsibility of each formula for the inconsistency of a knowledge base with constraints, respectively. Finally, we show that these measures can be well explained based on Halpern and Pearl’s causal model and Chockler and Halpern’s notion of responsibility.© 2018 Elsevier B.V. All rights reserved.1. IntroductionInconsistency is one of the important issues in knowledge and information systems. Techniques for inconsistency han-dling have been given much attention in the community of artificial intelligence and its application domains. Recently, measuring inconsistency has been considered as a useful way of better understanding the nature of inconsistency, and then provides a promising starting point to promote the process of inconsistency handling in knowledge and information systems in many applications such as requirements engineering [22,23], network security and intrusion detection [18,19], and med-ical experts systems [29]. A growing number of inconsistency measures have been proposed so far. Hunter et al. classified these inconsistency measures into two categories, i.e., base-level measures and formula-level ones [8]. Roughly speaking, the base-level measures focus on describing how inconsistent a knowledge base is, while the formula-level ones aim to grasp the responsibility (or contribution) of each formula of a knowledge base for the inconsistency in that base.In particular, minimal inconsistent subsets of a knowledge base are attractive to measuring inconsistency in applications of syntax-based inconsistency handling [7]. Here a minimal inconsistent subset (MIS for short) refers to an inconsistent E-mail address: mukedian @math .pku .edu .cn.https://doi.org/10.1016/j.artint.2018.02.0030004-3702/© 2018 Elsevier B.V. All rights reserved.K. Mu / Artificial Intelligence 259 (2018) 52–9053subset without an inconsistent proper subset. Please note that minimal inconsistent subsets of a knowledge base may be considered as a natural characterization of inconsistency in that base, since we only need to remove one formula from each minimal inconsistent subset in order to restore the consistency of that base [30]. In this sense, inconsistency measures built upon minimal inconsistent subsets may help us link measuring inconsistency with resolving inconsistency in a natural way. Along this line, minimal inconsistent subsets have been used to develop base-level inconsistency measures [7,8,24,26,9] as well as formula-level measures [7,8,21,9].Theoretically, removing any formula of a minimal inconsistent subset can break the minimal inconsistent subset. Then removing a minimal part that contains at least one formula for each minimal inconsistent subset may be considered as a potential proposal for resolving the inconsistency. However, not all of such proposals for resolving inconsistency are interesting to a given practical application. For example, in requirements engineering, changing different sets of software requirements may involve different stakeholders with their own demands and benefit expectations, then a final proposal is often a trade-off between different stakeholders [22]. Generally, domain experts and users often have a good sense of which proposals are more appropriate for resolving inconsistency in that application. They may also have a sense of “conditions” for acceptable proposals for the application domain, which would rule out the proposals that they know would not be of interest. Thus, a good heuristic is to specify such intuition or expectations on resolving inconsistency as constraints to facilitate inconsistency handling in practical applications. For example, the integrity constraints in merging an inconsistent multiset of information from different sources are used to characterize the behavior that any expected merging operator has to obey [15]. In requirements engineering, essential requirements are not allowed to be involved in any feasible proposal for resolving contradictions between requirements in general case [27].Besides that such constraints can help us to select proposals we want, they may be pushed deep into the process of inconsistency handling to improve the effectiveness of related activities involved in resolving inconsistency. In particular, incorporating such constraints in measuring inconsistency can help us establish more practical relations between measuring inconsistency and resolving inconsistency.In this paper, we focus on two typical kinds of constraints on modifying formulas of a knowledge base. A constraint of the first type is a pair of sets of formulas such that all the formulas in the first set should be protected from being modified, on the condition that all the formulas in the second must be changed in resolving inconsistency. We call such a constraint a hard constraint. Generally, a hard constraint represents some partial compromise on resolving inconsistency in practical applications. In contrast, a constraint of the second type is given as a set of pairs of formulas that are not allowed to be modified together in resolving inconsistency. We call such a constraint a soft constraint.(cid:2)(cid:2)As mentioned above, minimal inconsistent subsets can be considered as a promising starting point to connect inconsis-tency measures and syntax-based inconsistency handling. However, selecting formulas that have to be modified to break minimal inconsistent subsets from their own respective perspectives does not necessarily lead to an effective proposal for resolving inconsistency. Intuitively, overlaps between minimal inconsistent subsets are often of interest to breaking all the minimal inconsistent subsets by removing as few formulas as possible. Then such two overlapping minimal inconsistent subsets should be associated with each other when we want to break them. Along this line, given a minimal inconsistent subset, any two minimal inconsistent subsets that have their own respective overlaps with the minimal inconsistent subset will be also associated with each other even if the two subsets have no overlap. More generally, two minimal inconsistent are associated with each other if there is a chain of minimal inconsistent subsets M1, M2, · · · , Mn with subsets M and MM1 = M and Mn = Msuch that Mi+1 and Mi overlap each other for all i = 1, 2, · · · , n − 1. Evidently, these associations bring a partition of the set of minimal inconsistent subsets such that only minimal inconsistent subsets in the same part (called a cluster in this paper) are associated with one another (but not necessarily overlap), moreover, they should be broken as a whole instead of from their own respective perspectives. Then we need to know how the minimal inconsistent subsets in a cluster are associated with each other in order to break them together. That is, we need to capture both the interconnection relation between minimal inconsistent subsets and formulas that play important roles in the interconnection so as to help us understand the role of each formula in causing the inconsistency from a perspective of causality. To address this, we con-struct a bipartite graph for a knowledge base, which represents both the inner structure of each minimal inconsistent subset and the interconnection between minimal inconsistent subsets due to their overlaps. Then we show that such a graph-based representation allows us to incorporate the two types of constraints in characterizing inconsistency in a concise way. Based on this incorporation, we propose approaches to measuring inconsistency with one or both of the two types of constraints, respectively. In particular, both our base-level and formula-level measures can be reduced to their respective corresponding measures presented in [21] when there is no constraint. Some intuitive logical properties and complexity issues for these inconsistency measures are also discussed, respectively.On the other hand, it is often expected that an inconsistency measure under development will be interpretable. That is, inconsistency measures may need to be tied in with some specific interpretations that can help us gain an intuitive insight into the inconsistency. Generally, causality plays an important role in analyzing and resolving inconsistency in practical applications. Formulas identified as causes of the inconsistency of a knowledge base are of interest when we take some actions for restoring the consistency of that base. Thus causality-based explanations for inconsistency measures can help us establish a significant linkage between inconsistency measuring and inconsistency resolving. However, causality is a subtle topic in itself. The counterfactual dependence is considered as a common ground of many attempts presented to define causality from Hume to the present [2]. Informally speaking, A counterfactually depends on B if it is the case that if B had not happened, then A would not have happened. Recently, Halpern and Pearl’s structural causal model [5], one of 54K. Mu / Artificial Intelligence 259 (2018) 52–90the influential causal models in the computer science community, uses the notion of counterfactual dependence under some contingency instead of just counterfactual dependence, i.e., this model considers that A is a cause of B if B counterfactually depends on A under some contingency. Furthermore, Chockler and Halpern defined the degree of responsibility of A for B based on the counterfactual dependence of B on A under some contingency [2]. Essentially, the introduction of contingency makes these models more powerful to capture the subtlety of causality. Interestingly, we show that these measures for inconsistency with constraints can be well explained in the framework of Halpern and Pearl’s causal model and Chockler and Halpern’s notion of responsibility.The rest of this paper is organized as follows. In Section 2, we introduce some necessary notions about the inconsistency in knowledge bases, the notion of bipartite graph, Halpern and Pearl’s causal model and Chockler and Halpern’s notion of responsibility, respectively. In Section 3, we construct a bipartite graph, termed the MIS-graph, for a knowledge base to represent the relation between formulas and minimal inconsistent subsets, and show that this graph fully grasps the nature of inconsistency of a knowledge base. In Section 4, we incorporate the hard and soft constraints in the MIS-graph for a knowledge base, respectively. Then we propose a family of inconsistency measures with constraints based on the incorpo-ration in Section 5. In Section 6, we provide causality-based explanations for these inconsistency measures. In Section 7, we discuss logical properties and complexity issues for these inconsistency measures. We compare our approach with some closely related work in Section 8. In Section 9, we present an example to illustrate the application of the measures in the domain of requirements engineering. Finally, we conclude this paper in Section 10.2. PreliminariesWe provide some basic notions about the inconsistency in knowledge bases firstly. Then we introduce some necessary notions about the bipartite graph. Finally, we give introductions to Halpern and Pearl’s causal model [5] and Chockler and Halpern’s notion of responsibility [2], respectively.2.1. Knowledge bases and inconsistencyWe use a finite propositional language in this paper. Let P be a finite set of propositional symbols (atoms or variables) and L a propositional language built from P under connectives {¬, ∧, ∨, →}. We use a, b, c, · · · to denote the propositional atoms, and α, β, γ , · · · to denote the propositional formulas.A knowledge base K is a finite set of propositional formulas. Just for simplicity, we assume that each knowledge base is non-empty. For example, both {a} and {a, ¬a ∨ b, c} are knowledge bases.K is inconsistent if there is a formula α such that K (cid:6) α and K (cid:6) ¬α, where (cid:6) is the classical consequence relation. We abbreviate α ∧ ¬α as ⊥ when there is no confusion. Then we use K (cid:6) ⊥ (resp. K (cid:2) ⊥) to denote that a knowledge base Kis inconsistent (resp. consistent).An inconsistent subset Kof K is called a minimal inconsistent subset (or minimal unsatisfiable subset) of K if no proper (cid:2)subset of Kis inconsistent. We use MI(K ) to denote the set of all the minimal inconsistent subsets of K , i.e.,(cid:2)MI(K ) = {K(cid:2) ⊆ K |K(cid:2) (cid:6) ⊥ and ∀K(cid:2)(cid:2) ⊂ K(cid:2), K(cid:2)(cid:2) (cid:2) ⊥}.In syntax-based application domains, MI(K ) could be considered as a characterization of the inconsistency in K in the (cid:2)sense that one needs to remove only one formula from each minimal inconsistent subset to resolve the inconsistency [30].MI(K ) is the abbrevi-Let Sub(K ) be a set of some subsets of K , we abbreviate Sub(K ). For example, as (cid:2)(cid:2)K(cid:2)ation of (cid:2)M∈MI(K )M. It denotes the set of formulas involved in minimal inconsistent subsets.K (cid:2)∈Sub(K )A formula in K is called a free formula if this formula does not belong to any minimal inconsistent subset of K [6]. That is, free formulas have nothing to do with any minimal inconsistent subset of K . We use FREE(K ) to denote the set of free formulas of K , i.e.,FREE(K ) = {α ∈ K |∀M ∈ MI(K ), α /∈ M}.Evidently, K = (MI(K )) ∪ FREE(K ).(cid:2)Given a knowledge base, each of its minimal inconsistent subsets describes a minimal set of formulas needed to cause the inconsistency in that base. On the other hand, we are also interested in identifying a minimal set of formulas that need to be changed to restore the consistency of that base. Such a minimal set is referred to as a minimal correction subset.Given an inconsistent knowledge base K , a subset R of K is called a correction subset of K if K \ R (cid:2) ⊥. A correction (cid:2) (cid:6) ⊥. Please note that R is a minimal subset R of K is called a minimal correction subset of K if for any Rcorrection subset of K if and only if K \ R is a maximal consistent subset (a consistent subset without a consistent proper superset) of K . We use MC(K ) to denote the set of all the minimal correction subsets of K i.e.,(cid:2) ⊂ R, K \ RMC(K ) = {R ⊆ K |K \ R (cid:2) ⊥ and ∀R(cid:2) ⊂ R, K \ R(cid:2) (cid:6) ⊥}.The following relation between minimal inconsistent subsets and minimal correction subsets has been addressed in K. Mu / Artificial Intelligence 259 (2018) 52–9055computing minimal inconsistent subsets [17]:(cid:3)MI(K ) =(cid:3)MC(K ).It implies that formulas involved in the minimal inconsistent subsets are exactly ones involved in the minimal correction subsets.Now we use the following example to illustrate these notions.Example 2.1. Consider K = {a, ¬a, ¬a ∨ b, ¬b, c, d, ¬d}. ThenMI(K ) = {M1, M2, M3}, FREE(K ) = {c},MC(K ) = {R1, R2, R3, R4, R5, R6},whereM1 = {a, ¬a}, M2 = {a, ¬a ∨ b, ¬b}, M3 = {d, ¬d},R2 = {¬a, ¬a ∨ b, d},R1 = {a, d},R4 = {a, ¬d}, R5 = {¬a, ¬a ∨ b, ¬d}, R6 = {¬a, ¬b, ¬d}.R3 = {¬a, ¬b, d},2.2. The bipartite graph and Its Y -dominating setsHere we introduce some necessary notions about the bipartite graph. A graph is an ordered pair G = (V , E) comprising a nonempty finite set V together with a set E of 2-element subsets of V .1 The elements of V are called vertices and the elements of E are called edges. If e = {u, v} ∈ E, we say that the edge e joins u and v and that u and v are adjacent. Also we say that e is incident with u. Just for simplicity of discussion, we abuse the notation and use (u, v) instead of {u, v} to denote an edge joining u and v from now on. The number of edges incident with a vertex u is called the degree of u and is denoted as degG (u). In particular, u is called an isolated vertex if degG (u) = 0.Let G = (V , E) be a graph and u, v ∈ V two (not necessarily distinct) vertices. A path from u to v is an alternating sequencev 1, e1, v 2, e2, v 3, · · · , vn, en, vn+1of vertices and edges, where v 1 = u, vn+1 = v, and ei = (v i, v i+1) for i = 1, 2, · · · , n. Moreover, the number of edges listed in this sequence is called the length of this path. Further, if the path has no repeated vertices, then it is called a simple path. The smallest length of simple paths from u to v is called the distance from u to v and is denoted as DistG (u, v).A graph is called connected if there is a path between every pair of vertices. Given a graph G = (V , E), a graph G(cid:2), E(cid:2) =(cid:2) ⊆ E. A connected component (or just component) of G is a maximal (cid:2)) is called a subgraph of G if V(cid:2) ⊆ V and E(Vconnected subgraph of G.A graph G = (V , E) is isomorphic to a graph G(cid:2) = (V(cid:2), E(cid:2)) if there is a one-to-one mapping f from V to V(cid:2)such that the vertices u and v are adjacent in G if and only if the vertices f (u) and f (v) are adjacent in G(cid:2).Let G be a graph and V (G) and E(G) the set of vertices and the set of edges of G, respectively. A subset Vof V (G) is a maximal independent set of G if no (cid:2)(cid:2), (u, v) /∈ E(G) holds. Furthermore, we call Vcalled an independent set of G if ∀u, v ∈ V(cid:2)proper superset of Vis an independent set.(cid:2)Let G be a graph and V(cid:2) = {(u, v) ∈ E(G)|u ∈ V(cid:2) ⊆ V (G), then G − V(cid:2)or v ∈ V(cid:2)is defined as the graph G(cid:2)}.(cid:2)such that V (G(cid:2)) = V (G) \ V(cid:2)and E(G(cid:2)) =E(G) \ E(cid:2), where EA bipartite graph is a graph whose vertices can be divided into two disjoint nonempty sets X and Y such that every edge in E joins a vertex in X to one in Y . In this paper, we use G = ( X, Y , E) to denote a bipartite graph. Given a bipartite graph G, we use X(G), Y (G), and E(G) to denote the first set of vertices, the second set of vertices, and the set of edges of G, respectively.Let G 1 = ( X1, Y 1, E 1) and G 2 = ( X2, Y 2, E 2) be two components of G = ( X, Y , E) such that Xi ⊆ X and Y i ⊆ Y for i = 1, 2, then we use G 1 ∪ G 2 to denote the bipartite graph ( X1 ∪ X2, Y 1 ∪ Y 2, E 1 ∪ E 2). Obviously, G 1 ∪ G 2 is also a subgraph of G.Given a bipartite graph G = ( X, Y , E) and two vertices v 1, v 2 ∈ Y , we say that v 1 and v 2 are Y -adjacent if ∃u ∈ X such that (v 1, u) ∈ E and (v 2, u) ∈ E, otherwise v 1 and v 2 are Y -independent [16].For a bipartite graph G = ( X, Y , E) without isolated vertices in Y , a subset D of X is a Y -dominating set for G if ∀v ∈ Y , ∃u ∈ D such that (u, v) ∈ E [16]. Further, a Y -dominating set D is called a minimal Y -dominating set for G if no proper subsets of D is a Y -dominating set. The Y -domination number of G, denoted γY (G), is defined as the cardinality of the smallest minimal Y -dominating sets of G [16]. In addition, we use LY (G) to denote the largest cardinality of minimal 1 Just for convenience of discussion, we call G = (∅, ∅) an empty graph, and abbreviate it as G = ∅.56K. Mu / Artificial Intelligence 259 (2018) 52–90Fig. 1. The minimal Y -dominating sets of G 1.Y -dominating sets of G. In particular, ∅ is considered as the minimal Y -dominating set of an empty set, and then both γY (G) and LY (G) are defined as 0 if G is an empty graph.We use the following example to illustrate the notion of minimal Y -dominating set.Example 2.2. Consider a bipartite graph G 1 = ( X, Y , E) illustrated by Fig. 1, whereX = {u1, u2, u3} , Y = {v 1, v 2},andE = {(u1, v 1), (u2, v 1), (u2, v 2), (u3, v 2)}.From now on, we use circles and solid circles to denote vertices in Y and in X , respectively. In addition, we use a solid circle nested in a circle to denote a vertex in X involved in a minimal Y -dominating set.Evidently, both D1 = {u3, u1} and D2 = {u2} are minimal Y -dominating sets. So,γY (G 1) = 1, and LY (G 1) = 2.We propose a variant of the minimal Y -dominating set of G as follows:Definition 2.1. Let G = ( X, Y , E) be a bipartite graph and U be a subset of X . Let D be a minimal Y -dominating set of G. We call D a minimal Y |U -dominating set of G if U ⊆ D.We call a subset U of X a quasi-Y -dominating set if there exists at least one minimal Y |U -dominating set of G. Essentially, quasi-Y -dominating sets are exactly subsets that can be extended to minimal Y -dominating sets.Definition 2.2. Let G = ( X, Y , E) be a bipartite graph and U a quasi-Y -dominating set. Then the Y |U -domination number of G, denoted γY |U (G), is defined as the cardinality of a smallest minimal Y |U -dominating set of G.Obviously, γY |∅ (G) = γY (G). Just for simplicity of discussion, the Y |U -domination number γY |U (G) of G is defined as 0 if U is not a quasi-Y -dominating set.Example 2.3. Consider G 1 again. ThenγY |{u1} (G 1) = γY |{u3} (G 1) = 2, γY |{u2} (G 1) = γY (G 1) = 1.2.3. Causality and responsibilityHere we give introductions to Halpern and Pearl’s causal model [5] and Chockler and Halpern’s notion of responsibil-ity [2], respectively. This subsection is essentially identical to the corresponding introduction in [21]. Both are largely based on notions, definitions and explanations taken from Section 2 and Section 3 in [2].The variables involved in a causal model introduced by Halpern and Pearl can be classified into two kinds, the exogenous variables, whose values are determined by factors outside the model, and the endogenous variables, whose values are ultimately determined by the exogenous variables [5].A signature is a tuple S = (cid:15)U , V, R(cid:16), where U is a finite set of exogenous variables, V is a finite set of endogenous variables, and R associates with every variable Y ∈ U ∪ V a finite nonempty set R(Y ) of possible values for Y [2,5].A causal model over signature S is a tuple M = (cid:15)S, F (cid:16), where F associates with every endogenous variable X ∈ V a function F X such that F X : ((×U ∈U R(U )) × (×Y ∈V\{ X}R(Y ))) → R( X) [2,5]. In particular, M is called a binary causal modelif R(Y ) contains only two values for each Y ∈ U ∪ V [2,5].As explained in [2,5], F X describes how the value of the endogenous variable X is determined by the values of all other variables in U ∪ V . Then the equations determined by all functions of endogenous variables describe mechanisms for assigning values to variables in M. These equations also provide counterfactual information given a setting for exogenous variables. Here we use the following example taken from [2,5] to illustrate these explanations. Suppose that F X (Y , Z , U ) =U + Y ( X = U + Y for short) and U is the exogenous variable, then if U = 2 and Y = 3, then X = 5. On the other hand, if K. Mu / Artificial Intelligence 259 (2018) 52–9057the value of Y were forced to be 4 given U = 2, then the value of X would be 6, regardless of what values X , Y and Zactually take in the real world.Given a causal model M, its causal network is a directed graph with vertices corresponding to the endogenous variables and an edge from a vertex labeled X to one labeled Y if F Y depends on the value of X [2,5]. If the associated causal network of M is a directed acyclic graph, then we call M a recursive model [2,5]. It has been stated in [2] that if M is a recursive causal model, then there is always a unique solution to the equations in M, given a setting for the variables in U . We are more interested in binary recursive causal models in this paper.Let (cid:17)X and (cid:17)x be (possibly empty) vectors of variables in V and values for the variables in (cid:17)X , respectively. We use (cid:17)X ← (cid:17)xto denote the case of setting the values of the variables in (cid:17)X to (cid:17)x. In particular, a setting for the variables in U , denoted (cid:17)u, is called a context [2,5]. Roughly speaking, a context gives some background information [5].Given (cid:17)X ← (cid:17)x, a new causal model denoted M (cid:17)X←(cid:17)x over the signature S (cid:17)X=is obtained from F Y by setting the values of the variables in (cid:17)X to (cid:17)x [2,5]. For example, suppose (cid:16), is defined as M (cid:17)X←(cid:17)x= (cid:15)U , V − (cid:17)X, R|V− (cid:17)X(cid:15)S (cid:17)X , F (cid:17)X←(cid:17)x(cid:16), where Fthat F Y ( X, Z , U ) = X + Z + U , then F X←3(cid:17)X←(cid:17)xYY= 3 + Z + U .Given a signature S = (cid:15)U , V, R(cid:16), a primitive event is a formula of the form X = x, where X ∈ V and x ∈ R( X) [2,5]. In general, for (cid:17)X = ( X1, X2, · · · , Xn) and (cid:17)x = (x1, x2, · · · , xn), we abbreviate ( X1 = x1) ∧ ( X2 = x2) ∧ · · · ∧ ( Xn = xn) as (cid:17)X = (cid:17)x.A basic causal formula defined in [2,5] is in the form of[Y 1 ← y1, · · · , Yk ← yk]ϕ,where• ϕ is a Boolean combination of primitive events;• Y 1, · · · , Yk are distinct variables in V ; and• yi ∈ R(Y i).As explained in [2,5], [Y 1 ← y1, · · · , Yk ← yk]ϕ (abbreviated as [ (cid:17)Y ← (cid:17)y]ϕ) means that ϕ holds in the counterfactual world that would arise if Y i is set to yi , i = 1, 2, · · · , k [2,5].A causal formula is a Boolean combination of basic causal formulas [2,5]. We use (M, (cid:17)u) |= ϕ to denote that a causal formula ϕ is true in causal model M given a context (cid:17)u. Given a recursive model M, (M, (cid:17)u) |= [ (cid:17)Y ← (cid:17)y]( X = x) if the value of X is x in the unique vector of values for the endogenous variables that simultaneously satisfies all equations , Z ∈ V − Y under the setting (cid:17)u of U [2,5]. As pointed out in [2,5], this definition can be extended to arbitrary causal (cid:17)Y ←(cid:17)yZFformulas in the usual way.Definition 2.3 (Cause [5]). We say that (cid:17)X = (cid:17)x is a cause of ϕ in (M, (cid:17)u) if the following three conditions hold:AC1. (M, (cid:17)u) |= ( (cid:17)X = (cid:17)x) ∧ ϕ.AC2. There exists a partition ( (cid:17)Z , (cid:17)W ) of V with (cid:17)X ⊆ (cid:17)Z and some setting ((cid:17)x(cid:2), (cid:17)w(cid:2)) of the variables in ( (cid:17)X, (cid:17)W ) such that if ∗for Z ∈ (cid:17)Z , then(M, (cid:17)u) |= Z = z(a) (M, (cid:17)u) |= [ (cid:17)X ← (cid:17)x(cid:2), (cid:17)W ← (cid:17)w(b) (M, (cid:17)u) |= [ (cid:17)X ← (cid:17)x, (cid:17)W ← (cid:17)wshould have no effect on ϕ as long as (cid:17)X has the value (cid:17)x, even if all the variables in an arbitrary subset of (cid:17)Z are set to their original values in the context (cid:17)u.of (cid:17)Z − (cid:17)X . That is, setting (cid:17)W to (cid:17)w(cid:2)(cid:2)]¬ϕ. That is, changing ( (cid:17)X, (cid:17)W ) from ((cid:17)x, (cid:17)w) to ((cid:17)x(cid:2), (cid:17)Z∗]ϕ for all subsets (cid:17)Z(cid:2) ← (cid:17)z(cid:2)(cid:2), (cid:17)w(cid:2)) changes ϕ from true to false.AC3. ( (cid:17)X = (cid:17)x) is minimal, that is, no subset of (cid:17)X satisfies AC2.As explained in [2,5], AC1 is used to capture the intuition that A cannot be a cause of B unless both A and B are true. As the core of the definition of cause, AC2 emphasizes the important role of the contingency, which makes a distinction between the definition and the traditional counterfactual ones. As pointed out in [5], AC3 is a minimality condition ensuring that only the elements of the conjunction (cid:17)X = (cid:17)x that are essential for changing ϕ in AC2(a) are considered part of a cause; inessential elements are pruned [5]. In particular, if there is no variable in (cid:17)W , then we call (cid:17)X = (cid:17)x a counterfactual cause of ϕ in (M, (cid:17)u) [20].Definition 2.4 (Degree of responsibility [2]). The degree of responsibility of X = x for ϕ in (M, (cid:17)u), denoted dr((M, (cid:17)u), ( X =k+1 if X = x is a cause of ϕ in (M, (cid:17)u) and there exists a partition x), ϕ), is 0 if X = x is not a cause of ϕ in (M, (cid:17)u); it is 1( (cid:17)Z , (cid:17)W ) and setting x(cid:2), (cid:17)wthan they do in the context (cid:17)u and (b) there is no partition ( (cid:17)Z(cid:2) < k variables have different values in (cid:17)wfor which AC2 holds such that (a) k variables in (cid:17)W have different values in (cid:17)wthan they do in the context (cid:17)u.satisfying AC2 such that only k(cid:2)) and setting x(cid:2), (cid:17)W(cid:2)(cid:2), (cid:17)w(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)As stated in [2], the degree of responsibility of X = x for ϕ in (M, (cid:17)u) captures the minimal number of changes that have to be made in (cid:17)u in order to make ϕ counterfactually depend on X .We use the following example taken from [2] to illustrate the notion of degree of responsibility.58K. Mu / Artificial Intelligence 259 (2018) 52–90Fig. 2. The general MIS-graph of K .Example 2.4 (Example 3.3 in [2]). Consider a causal model on Mr. B winning an election with 11 voters against Mr. G. Voter iis represented by a binary variable Xi , i = 1, 2, · · · , 11, which is 1 if voter i votes for Mr. B and 0 if voter i votes for Mr. G; the outcome is represented by the variable O , which is 1 if Mr. B wins and 0 if Mr. G wins. If the vote is 11-0, then each voter is a cause of Mr. B winning (that is, Xi = 1 is a cause of O = 1 for each i). The degree of responsibility of Xi = 1 for 6 , because at least five other voters must change their votes before changing Xi to 0 results in O = 0. But if the O = 1 is 1vote is 6-5, then each voter who votes for Mr. B is a counterfactual cause of Mr. B winning. The degree of responsibility of each of these voters for O = 1 is 1. This means that each voter who votes for Mr. B is crucial.3. The MIS-graphThe process of resolving the inconsistency of a knowledge base is exactly a process of breaking all the minimal incon-sistent subsets of that base from a perspective of syntax-based inconsistency handling. As mentioned earlier, the set of minimal inconsistent subsets can be grouped into several separate clusters such that each cluster should be considered as a whole to be broken. Moreover, we need to look inside each cluster to understand the role of each formula in causing the inconsistency so as to identify formulas that have to be changed, especially in the presence of constraints. Here we use a bipartite graph to represent the relation between formulas and minimal inconsistent subsets of a knowledge base, in which each non-isolated component corresponds to such a cluster.Definition 3.1. Let K be a knowledge base and MI(K ) the set of minimal inconsistent subsets of K . The general MIS-graph of K , denoted G 0K , is defined as follows:K ) = K , and Y (G 0• X(G 0• (α, M) ∈ E(G 0K ) = MI(K );K ) if and only if α ∈ M.The two sets of vertices of the general MIS-graph of a knowledge base are exactly the knowledge base itself and the set of minimal inconsistent subset of the knowledge base, respectively. The general MIS-graph of a knowledge base provides a hierarchical representation for the inconsistency of that base:• Formula-level: all the connections between a formula and minimal inconsistent subsets grasp which minimal inconsis-tent subsets the formula is involved in.• MIS-level: a minimal inconsistent subset only joins each of its formulas in the graph. Then all the connections between a minimal inconsistent subset and formulas grasp the inner structure of that minimal inconsistent subset. That is, this graph allows us to look inside minimal inconsistent subsets from their own perspectives.• Inter-MIS-level: any two minimal inconsistent subsets overlap each other if and only if they are Y -adjacent in G 0K . Furthermore, any two minimal inconsistent subsets are associated with each other if and only if there is a path between them in the graph, i.e., they are in the same component, moreover, the chain of formulas involved in such a path provides an intuitive explanation of the association. That is, this graph also allows us to look inside these separate clusters of minimal inconsistent subsets.The inter-MIS-level representation shows that the interconnected structure of the set of minimal inconsistent subsets can be captured by this graph.We use the following example to illustrate the notion of general MIS-graph.Example 3.1. Consider K = {a, ¬a, ¬a ∨ b, ¬b, c, d, ¬d} again. Then the general MIS-graph of K is illustrated by Fig. 2. Obvi-ously, G 0K has three components including C1, C2 and C3. In particular, C3 consists of only one isolated vertex corresponding to the free formula c. In addition, we can find that M3 is Y -independent of both M1 and M2, while M1 and M2 and Y -adjacent.Evidently, we have the following observations about G 0K for a knowledge base K :K. Mu / Artificial Intelligence 259 (2018) 52–9059(O1) |Y (G 0(O2) degG 0(O3) degG 0(O4) degG 0KKKK )| = |MI(K )|;(M) = |M| for each M ∈ MI(K );(α) = |{M|M ∈ MI(K ) s.t. α ∈ M}| for each α ∈ K ;(α) = 0 if and only if α ∈ FREE(K ).The first three observations show that the number of minimal inconsistent subsets, the size of each minimal inconsis-tent subset, and the number of minimal inconsistent subset containing a given formula are all represented by the general MIS-graph. The last one states that isolated vertices in G 0K exactly correspond to the free formulas of K . Allowing for this, we define a simplified graph as follows:Definition 3.2. Let K be a knowledge base and MI(K ) the set of minimal inconsistent subsets of K . The MIS-graph of K , denoted G K , is defined as follows:• X(G K ) = K \ FREE(K ), and Y (G K ) = MI(K );• (α, M) ∈ E(G K ) if and only if α ∈ M.(cid:2)Essentially, the MIS-graph is the maximum subgraph of the general MIS-graph that has no isolated vertex. Please note that X(G K ) =MI(K ), thus it only describes the relation between minimal inconsistent subsets and formulas involved in minimal inconsistent subsets. Moreover, each component of the MIS-graph corresponds to a cluster of minimal inconsistent subsets associated with one another.The following proposition shows that the MIS-graph of a consistent knowledge base is an empty graph.Proposition 3.1. Let K be a knowledge base and G K the MIS-graph of K . Then G K = ∅ if and only if K is consistent.This proposition implies that the MIS-graph cannot make a distinction between consistent knowledge bases. From now on, we consider MIS-graphs for inconsistent knowledge bases. The following proposition shows that minimal correction subsets can also be represented by the MIS-graph.Proposition 3.2. Let K be an inconsistent knowledge base and G K the MIS-graph of K . Then a subset R of K is a minimal correction subset of K if and only if R is a minimal Y -dominating set of G K .Proof. Let K be an inconsistent knowledge base and G K the MIS-graph of K .(cid:2)• Necessity. Let R be a minimal correction subset of K , then R ⊆MI(K ) = X(G K ) and K \ R (cid:2) ⊥. Moreover, we show that(c1) ∀M ∈ Y (G K ), ∃α ∈ R s.t. (α, M) ∈ E(G K ). On the contrary, suppose that there exists M ∈ MI(K ), s.t. (α, M) /∈ E(G K )for all α ∈ R. Then M ⊆ K \ R. So, K \ R (cid:6) ⊥. This contradicts that K \ R (cid:2) ⊥.(c2) The minimality of R ensures that no proper subset of R satisfies (c1).Therefore, R is a minimal Y -dominating set of G K .• Sufficiency. Let R be a minimal Y -dominating set, then ∀M ∈ MI(K ), ∃α ∈ R s.t. (α, M) ∈ E(G K ) (i.e., α ∈ M). So, K \ R (cid:2)⊥. Therefore, R is a correction subset of K .(cid:2) ⊂ R, R(cid:2)Furthermore, ∀Rthen ∀M ∈ Y (G K ), ∃β ∈ Rthat R is a minimal Y -dominating set.Hence, R is a minimal correction subset of K . (cid:2)is not a correction subset of K . On the contrary, suppose that R(cid:2)is a correction subset of K , is also a Y -dominating set of G K . This contradicts s.t. β ∈ M, i.e., (β, M) ∈ E(G K ). Then R(cid:2)(cid:2)In particular, the following corollary shows that each minimal Y |C -dominating set of G K is exactly a minimal correction subset of K that subsumes C .Corollary 3.1. Let K be an inconsistent knowledge base and G K the MIS-graph of K . Let C be a subset of K , then a subset R of K is a minimal correction subset of K such that C ⊆ R if and only if R is a minimal Y |C -dominating set of G K .Proof. This is a direct consequence of Proposition 3.2. (cid:2)The following lemma shows that any connected component of G K is also a MIS-graph.Lemma 3.1. Let K be an inconsistent knowledge base and G K the MIS-graph of K . Let G be a connected component of G K , then G is the MIS-graph of X(G).60K. Mu / Artificial Intelligence 259 (2018) 52–90Proof. It is a direct consequence of the definition of MIS-graph. (cid:2)Fig. 3. The connected components of G K .Essentially, this lemma shows that a component of the MIS-graph fully represents a separate cluster of minimal inconsis-tent subsets. That is, both the inner structure of each minimal inconsistent subset of the cluster and all the associations with these minimal inconsistent subsets are represented by the component. From now on we call the set of formulas involved in a component of G K a MIS-component of K if there is no confusion. The following lemma shows that the union of minimal correction subsets of two distinct MIS-components is exactly a minimal correction subset of the combination of the two MIS-components.Lemma 3.2. Let G 1 and G 2 be two distinct components of G K . Suppose that R1 and R2 are minimal Y -dominating sets of G 1 and G 2, respectively, then R1 ∪ R2 is a minimal Y -dominating set of G 1 ∪ G 2.Proof. Let G 1 and G 2 be two distinct components of G K , then X(G 1) ∩ X(G 2) = ∅ and Y (G 1) ∩ Y (G 2) = ∅. Suppose that R1and R2 are minimal Y -dominating sets of G 1 and G 2, respectively. Then ∀M ∈ Y (G 1) ∪ Y (G 2),• if M ∈ Y (G 1), ∃α ∈ R1 s.t. (α, M) ∈ E(G 1);• else ∃β ∈ R2 s.t. (β, M) ∈ E(G 2).So, R1 ∪ R2 is a Y -dominating set of G 1 ∪ G 2.(R1 ∪ R2) \ {α}, thenRecall that X(G 1) ∩ X(G 2) = ∅ and Y (G 1) ∩ Y (G 2) = ∅, then R1 ∪ R2 must be minimal. Otherwise, ∀α ∈ (R1 ∪ R2), consider • if α ∈ R1, ∃M ∈ Y (G 1) s.t. ∀β ∈ (R1 ∪ R2) \ {α}, (β, M) /∈ E(G 1);• else ∃M ∈ Y (G 2) s.t. ∀β ∈ (R1 ∪ R2) \ {α}, (β, M) /∈ E(G 2).So, (R1 ∪ R2) \ {α} is not a Y -dominating set of G 1 ∪ G 2. (cid:2)Proposition 3.3. Let K be an inconsistent knowledge base and G K the MIS-graph of K . Let {G 1, G 2, · · · , Gm} be the set of components of G K and R ⊆ K . Then• R is a minimal Y -dominating set of G K if and only if R ∩ X(G i) is a minimal Y -dominating set of G i for each i = 1, 2, · · · , m.• R is a minimal correction subset of K if and only if R ∩ X(G i) is a minimal correction subset of X(G i) for each i = 1, 2, · · · , m.Proof. It is a direct consequence of Proposition 3.2, Lemma 3.1 and Lemma 3.2. (cid:2)The first item of this proposition shows that a minimal Y -dominating set of G K is exactly a combination of minimal Y -dominating sets of all its components. The second item shows that a minimal correction subset of K is exactly a combi-nation of minimal corrections subsets of all MIS-components of K .Example 3.2. Consider K = {a, ¬a, ¬a ∨ b, ¬b, c, d, ¬d} again. As illustrated by Fig. 3, there are two connected components C1 and C2 of the MIS-graph of K . For C1, the corresponding cluster and MIS-components are {M3} and {d, ¬d}, respectively. For C2, the corresponding cluster and MIS-component are {M1, M2} and {¬a, a, ¬a ∨ b, ¬b}, respectively.Note that both {d} and {¬d} are the smallest minimal Y -dominating sets of C1, and {a} is an unique smallest minimal Y -dominating set of C2. Then both R1 = {d, a} and R2 = {¬d, a} are the smallest minimal Y -dominating sets of G K .Next we define the MIS-equivalence relation between knowledge bases as follows:Definition 3.3 (MIS-equivalence). Let K1 and K2 be two knowledge bases. Let G K1 and G K2 be the MIS-graphs of K1 and K2, respectively. If there is a one-to-one mapping f from X(G K1 ) ∪ Y (G K1 ) to X(G K2 ) ∪ Y (G K2 ) such thatK. Mu / Artificial Intelligence 259 (2018) 52–9061(1) ∀α ∈ X(G K1 ), f (α) ∈ X(G K2 );(2) ∀M ∈ Y (G K1 ), f (M) ∈ Y (G K2 );(3) ∀α ∈ X(G K1 ), ∀M ∈ Y (G K1 ), (α, M) ∈ E(G K1 ) iff ( f (α), f (M)) ∈ E(G K2 ),then we say that K1 and K2 are MIS-equivalent to each other.Roughly speaking, the MIS-equivalence relation describes the case that two knowledge bases have the same (inner and interconnected) structure of minimal inconsistent subsets. Obviously, if K 1 is MIS-equivalent to K2, then(cid:2)• |MI(K1)| = |MI(K2)|, and | • G K1 is isomorphic to G K2 ,• γY (G K1 ) = γY (G K2 ).(cid:2)MI(K1)| = | MI(K2)|,In summary, given an inconsistent knowledge base, the MIS-graph provides a representation of the inconsistency in that base from multiple perspectives, including the inner structure of each minimal inconsistent subset, the separate clusters of minimal inconsistent subsets, the inner structure of each cluster, the MIS-components of the base, and the minimal correction subsets of that base.4. Representing inconsistency with constraints(cid:2)In this section, we incorporate hard constraints and soft constraints on modifying formulas in the MIS-graph, respectively. MI(K ) is considered as the set of candidates of formulas that have to be modified to restore the consistency Generally, of K . Then both the hard and the soft constraints are given based on MI(K ) in this paper.(cid:2)4.1. Hard constraints(cid:2)Given a knowledge base K , a hard constraint on modifying formulas is a pair H = (P , Q ) of P , Q ⊆MI(K ) such that all the formulas in P must be protected from being modified on the condition that each of formulas in Q must be excluded from any consistent revision of that knowledge base obtained by removing as few formulas as possible. Especially, we say that a minimal correction subset R of K is compatible with H = (P , Q ) if R ∩ P = ∅ and R ⊇ Q . Essentially, a compatible minimal correction subset R protects P from being modified by removing formulas in Q together with other formulas in R. Furthermore, if there exists at least one minimal correction subset compatible with (P , Q ), we say that (P , Q ) is a valid hard constraint. Evidently, if H = (P , Q ) is valid, then P ∩ Q = ∅ and P ∪ FREE(K ) (cid:2) ⊥. Moreover, the validness of (cid:2) ∩ Q = ∅ if P (cid:22)= ∅. H = (P , Q ) also implies that there exists at least one consistent subset KNote that for any minimal correction subset R of an inconsistent knowledge base K , (P , Q ) is a valid hard constraint for MI(K )) and Q ⊆ R. This implies that valid hard constraints always exist for an inconsistent knowledge all P ⊆ (K \ R) ∩ (base. In this paper, we focus on valid hard constraints.of K such that P ⊆ KAt first, we consider a special kind of hard constraint H = (P , ∅), where P is a consistent proper subset of MI(K ). We call such a hard constraint a protected-formulas constraint, and abbreviate (P , ∅) as P N. We adapt the MIS-graph to the case with a protected-formulas constraint.and K(cid:2)(cid:2)(cid:2)(cid:2)Definition 4.1. Let K be a knowledge base with a protected-formulas constraint P N. The MIS-graph with constraint P N of K , denoted G K |P N , is defined as follows:G K |P N= G K − P .From the definition of the operation G K − P introduced in Section 2.2, V (G K |P N ) = V (G K ) \ P and E(G K |P N ) =E(G K ) \ {(α, M) ∈ E(G)|α ∈ P }. Please note that P (cid:2) ⊥, then ∀M ∈ MI(K ), ∃β ∈ M such that β /∈ P . Therefore, every minimal inconsistent subset connects to at least one formula in G K |P N . Evidently, we have the following observations:• X(G K |P N ) = X(G K ) \ P , and Y (G K |P N ) = Y (G K );• degG K |PN• degG K |PN(α) = degG K (α) for all α ∈ X(G K |P N );(M) = degG K (M) − |M ∩ P | for all M ∈ Y (G K ).Compared to G K , G K |P N focuses on characterizing both the inner structure of each minimal inconsistent subset and the interconnected structure of these minimal inconsistent subsets in the presence of constraint P N. To be more precise, the inner structure of each minimal inconsistent subset only describes which formulas not in P belong to the minimal inconsis-tent subset, and only the Y -adjacency relation between minimal inconsistent subsets not depending on P are represented by G K |P N .62K. Mu / Artificial Intelligence 259 (2018) 52–90Fig. 4. The MIS-graph with constraint {a}N.Example 4.1. Consider K = {a, ¬a, ¬a ∨ b, ¬b, c, d, ¬d} again. Suppose that P = {a}. Then the MIS-graph with constraint {a}Nof K is illustrated by Fig. 4. There are three connected components C1, C2, and C3 of G K |{a}N .Please note that the Y -adjacency between M1 and M2 in G K is fully based on the shared formula a. However, this Y -adjacency is destroyed by the constraint {a}N. So, M1 and M2 are Y -independent of each other in G K |{a}N .The following proposition shows that the MIS-graph with constraint P N grasps the impact of P N on inconsistency re-solving.Proposition 4.1. Let K be a knowledge base with a protected-formulas constraint P N. Then a subset R of K is a minimal Y -dominating set of G K such that R ∩ P = ∅ if and only if R is a minimal Y -dominating set of G K |P N .Proof. This is a direct consequence of the definition of G K |P N . (cid:2)Next we consider how to incorporate the condition Q of a hard constraint H = (P , Q ) in the MIS-graph.Proposition 4.2. Let K be a knowledge base and H = (P , Q ) a hard constraint. Then R is a minimal correction subset of K such that Q ⊆ R if and only if R is a minimal Y |Q -dominating set of G K .Proof. This is a direct consequence of Proposition 3.2. (cid:2)Now we are ready to adapt the MIS-graph to the case with a hard constraint H as follows:Definition 4.2. Let K be a knowledge base and H = (P , Q ) a hard constraint. The MIS-graph with constraint H of K , denoted G K |H, is defined asG K |H = G K |P N= G K − P .Now we are more interested in minimal Y |Q -dominating sets rather than just minimal Y -dominating sets of G K |H when we consider the role of Q in the hard constraint H. The following proposition shows that the MIS-graph with constraint Hcaptures the nature of inconsistency in the presence of H.Proposition 4.3. Let K be an inconsistent knowledge base and H = (P , Q ) a hard constraint. Then a subset R of K is a minimal correction subset of K such that P ∩ R = ∅ and Q ⊆ R if and only if R is a minimal Y |Q -dominating set of G K |H.Proof. This is a direct consequence of Proposition 4.1 and 4.2. (cid:2)Example 4.2. Consider K = {a, ¬a, ¬a ∨ b, ¬b, c, d, ¬d} again. Suppose that H = ({d}, {a}). Then the MIS-graph with con-straint H of K is illustrated by Fig. 5. There are two connected components C1 and C2 of the MIS-graph with constraint Hof K . Evidently, {¬d, a} is a unique minimal Y |{a}-dominating set of G K |H.4.2. Soft constraintsIn this subsection, we consider the soft constraint on modifying formulas of a knowledge base, which describes a special relation of exclusiveness on modifying formulas of that knowledge base. To be more precise, let C be a set of 2-element MI(K ) such that α and β are not allowed to be modified together if {α, β} ∈ C, then we call C a subsets of a subset (cid:6) of soft constraint on modifying formulas. Here we abuse the notation and write {α, β} as (α, β) in a soft constraint. If we use the graph GC = ((cid:6), C) to represent the soft constraint C, then a maximal independent set of GC is exactly a maximal set of formulas in (cid:6) that are allowed to be removed together from K in the presence of C.(cid:2)K. Mu / Artificial Intelligence 259 (2018) 52–9063Fig. 5. The MIS-graph with constraint H.Fig. 6. GC and G K .Definition 4.3. Let K be a knowledge base with a soft constraint C. A minimal Y -dominating set R of G K is compatible with C if for all α, β ∈ R, (α, β) /∈ C. Further, we call a minimal Y -dominating set R a minimal Y-dominating set if R is compatible with C.[C]Proposition 4.4. Let K be a knowledge base and C a soft constraint. Then R is a minimal Ya minimal correction subset of K such that (α, β) /∈ C for all α, β ∈ R.[C]-dominating set of G K if and only if R is Proof. It is a direct consequence of Proposition 3.2. (cid:2)We say that a minimal correction subset R of K is compatible with a soft constraint C if for all α, β ∈ R, (α, β) /∈ C. We say that C is satisfiable if there exists at least one minimal correction subset of K compatible with C. In this paper, we only focus on satisfiable soft constraints.Example 4.3. Consider K = {a, ¬a, ¬a ∨ b, ¬b, c, d, ¬d} again. Suppose that (cid:6) = {a, ¬a, d, ¬d, ¬a ∨ b} and C = {(a, d), (a, ¬d),(¬a, d), (¬a, ¬a ∨ b), (¬a ∨ b, d)}. Then GC and G K are illustrated by (1) and (2) of Fig. 6, respectively. Here we use a solid circle nested in double circles to denote a vertex involved in a maximal independent set. Please note that all of D1 = {¬a, ¬d}, D2 = {a, ¬a}, D3 = {a, ¬a ∨ b}, D4 = {d, ¬d}, and D5 = {¬d, ¬a ∨ b} are the maximal independent sets of GC . However, only D1 can be extended to a minimal Y -dominating set R = D1 ∪ {¬b} = {¬a, ¬b, ¬d}. Actually, R is a unique minimal Y-dominating set of G K .[C]Furthermore, we call a minimal Y |U -dominating set R of G K a minimal Y |[C]with C for a given quasi-Y -dominating set U . Moreover, we use γY |[C]imal Y |[C]Y |[C]U -dominating set of G K . Just for simplicity of discussion, we define γY |[C]U -dominating set.UUU -dominating set if R is compatible (G K ) to denote the cardinality of a smallest min-(G K ) as 0 if there is no minimal 5. Measuring inconsistency with constraintsIn this section, we propose both base-level and formula-level inconsistency measures for knowledge bases in the pres-ence of constraints.5.1. The base-level measure for inconsistency with constraintsThe size of a minimal correction subset of a knowledge base may be considered as an evaluation of effort to resolve the inconsistency by removing the minimal correction subset from that base from a syntax-based perspective. However, Konieczny et al. have argued that the cost of some actions (tests) needed to render a knowledge base classically consistent can be used to quantify the degree of inconsistency [13]. Inspired by this, given a knowledge base with a (hard or soft) constraint, the smallest size of its minimal correction subsets compatible with the constraint can be considered as an inconsistency measure for the base in the presence of the constraint. On the other hand, as shown previously, given a knowledge base with a constraint on modifying formulas, each minimal correction subset compatible with the constraint is 64K. Mu / Artificial Intelligence 259 (2018) 52–90exactly a minimal Y -dominating set for the MIS-graph with constraint. Allowing for this, we define the following base-level measure for inconsistency in the presence of a hard constraint firstly.Definition 5.1. Let K be a knowledge base with a hard constraint H = (P , Q ). Then the degree of inconsistency of K with constraint H, denoted Idr (K |H), is defined asIdr(K |H) = γY |Q (G K |H),where G K |H is the MIS-graph with constraint H of K .Note that γY |Q (G K |H) − |Q | is exactly the minimal number of formulas that have to be removed together with Q from Kto break all the minimal inconsistent subsets of K when all the formulas of P must be protected from being modified. Then Idr(K |H) grasps the minimal number of formulas that have to be removed from K to break all the minimal inconsistent subsets of K in the presence of H.In particular, if there is no constraint, thenIdr(K |(∅, ∅)) = γY (G K ) = minR∈MC(K )|R|.Generally, we abbreviate Idr(K |(∅, ∅)) as Idr(K ), which can be considered as a measure for the inconsistency of K [21].Example 5.1. Consider K = {a, ¬a, ¬a ∨ b, ¬b, c, d, ¬d} again. Suppose that H1 = ({d}, {a}) and H2 = ({a}, {d}), thenIdr(K ) = 2, Idr(K |H1) = 2, and Idr(K |H2) = 3.If there is only a protected-formulas constraint P , then the degree of inconsistency of K in the presence of this constraint, denoted Idr(K |(P , ∅)), is exactly the Y -domination number of G K |P N , i.e.,Idr(K |(P , ∅)) = γY (G K |P N ).By Proposition 4.1, γY (G K |P N ) is the minimal number of formulas not in P that have to be removed from K to break all the minimal inconsistent subsets of K . From now on we abbreviate Idr (K |(P , ∅)) as Idr(K |P N).Example 5.2. Consider K = {a, ¬a, ¬a ∨ b, ¬b, c, d, ¬d} again. Suppose that P 1 = {a} and P 2 = {¬a}. ThenIdr(K |P 1N ) = 3, and Idr(K |P 2N ) = 2.Now we consider the case with a soft constraint.Definition 5.2. Let K be a knowledge base with a soft constraint C. Then the degree of inconsistency of K in the presence of C, denoted Idr(K |C), is defined asIdr(K |C) = γY [C] (G K ).Essentially, Idr(K |C) is the minimal number of formulas that have to be removed from K to break all the minimal inconsistent subsets of K in the presence of constraint C.Example 5.3. Consider K = {a, ¬a, ¬a ∨ b, ¬b, c, d, ¬d} again. Suppose that C = {(a, d), (a, ¬d), (¬a, d), (¬a, ¬a ∨ b), (¬a ∨b, d)}. ThenIdr(K |C) = 3.Lastly, we consider the case with a mixture of hard and soft constraints. We call a pair (H, C) of a hard constraint H = (P , Q ) and a soft constraint C of K a mixed constraint. We say that (H, C) is satisfiable if there exists at least one minimal correction subset of K compatible with both H and C. Here we only consider satisfiable mixed constraints.Definition 5.3. Let K be a knowledge base with a mixed constraint (H, C), where H = (P , Q ). Then the degree of inconsis-tency of K in the presence of (H, C), denoted Idr(K |H, C), is defined asIdr(K |H, C) = γ(G K |H).[C]QYK. Mu / Artificial Intelligence 259 (2018) 52–9065Essentially, Idr(K |H, C) is the minimal number of formulas that have to be removed from K to break all the minimal inconsistent subsets of K in the presence of the mixed constraint (H, C). Evidently, Idr(K |H, C) is reduced to Idr(K |H)(resp. Idr(K |C)) when the soft (resp. hard) constraint is empty in the mixed constraint (H, C), i.e.,Idr(K |H, ∅) = Idr(K |H),andIdr(K |(∅, ∅), C) = Idr(K |C).Example 5.4. Consider K = {a, ¬a, ¬a ∨ b, ¬b, c, d, ¬d} again. Suppose that H = ({a}, {¬d}) and C = {(a, d), (a, ¬d), (¬a, d),(¬a, ¬a ∨ b), (¬a ∨ b, d)}. Then {¬a, ¬b, ¬d} is a unique minimal Y[C]{¬d}-dominating set of G K |H. So,Idr(K |H, C) = 3.5.2. Responsibility for inconsistency with constraintsFrom a perspective of syntax-based inconsistency handling, we are more interested in identifying the degree of responsi-bility of each formula of a knowledge base for the inconsistency of that base. In our previous paper [21], we have presented the following measure for the degree of responsibility of each formula for the inconsistency, which is given in terms of minimal correction subsets of a knowledge base.Definition 5.4. Let K be a knowledge base and α ∈ K . Then(cid:4)dr(K , α) =max{ 10,|R| |R ∈ MC(K ) s.t. α ∈ R}, if α ∈(cid:2)MI(K ),otherwise.Moreover, as shown in [21], this measure can be well explained in the context of causality and responsibility presented by Chockler and Halpern [2].As shown by Corollary 3.2, every minimal correction subset R that α belongs to is exactly a minimal Y |{α}-dominating set for G K . Then this measure can be given in terms of Y |{α}-domination number of G K alternatively. That is,(cid:5)dr(K , α) =1γY |{α} (G K ) , if α ∈0,otherwise.(cid:2)MI(K ),Now we are ready to adapt this measure for the degree of responsibility for inconsistency to the cases with constraints. At first, we consider the case that there is only one protected-formulas constraint.Definition 5.5. Let K be a knowledge base with a constraint P N and α a formula of K . Then the degree of responsibility of α for the inconsistency of K in the presence of P N , denoted dr(K , α|P N), is defined as(cid:5)dr(K , α|P N) =1γY |{α} (G K |PN ) , if α ∈ X(G K |P N ) and γY |{α} (G K |P N ) (cid:22)= 0,0,otherwise.According to this definition, the degree of responsibility of any free formula for the inconsistency is 0. It coincides with the intuition that free formulas are not involved in any minimal inconsistent subset of K . In addition, the degree of responsibility of any formula of P for the inconsistency is 0, i.e., all the formulas of P needn’t bear any responsibility for the inconsistency of K . This grasps the nature of P being a protected-formulas constraint. If a formula not in P ∪ FREE(K )is assigned to 0, then that formula is not involved in any minimal Y -dominating set for G K |P N . This is the case that there is no need to remove that formula from K to break all the minimal inconsistent subsets in the presence of P N . Essentially, such formulas are indirectly protected by the constraint from being modified.On the other hand, any smallest minimal Y |{α}-dominating set for G K |P N is exactly a smallest minimal correction subset of K that contains α in the presence of the protected-formulas constraint P . Let R be such a smallest minimal Y |{α}-dominating set for G K |P N , then R \ {α} is exactly a minimal set of formulas that have to be removed together with αfrom K to break all the minimal inconsistent subsets of K in the presence of P N. As shown later, R \ {α} characterizes a minimal set of formulas that have to be changed to obtain a contingency where the inconsistency of K counterfactually de-pends on α in the presence of the constraint P N. In this sense, this measure also captures the intuition of the responsibility presented by [2].66K. Mu / Artificial Intelligence 259 (2018) 52–90Example 5.5. Consider K = {a, ¬a, ¬a ∨ b, ¬b, c, d, ¬d} again. Suppose that P 1 = {a} and P 2 = {¬a}. Thendr(K , a) = 1dr(K , a|P 1N ) = 0,dr(K , a|P 2N ) = 1;2 ,dr(K , ¬a|P 2N ) = 0;dr(K , ¬a|P 1N ) = 1dr(K , ¬a) = 13 ,3 ,3 , dr(K , ¬a ∨ b|P 2N ) = 0;3 , dr(K , ¬a ∨ b|P 1N ) = 1dr(K , ¬a ∨ b) = 1dr(K , ¬b|P 2N ) = 0;dr(K , ¬b|P 1N ) = 1dr(K , ¬b) = 13 ,3 ,dr(K , c|P 2N ) = 0;dr(K , c|P 1N ) = 0,dr(K , c) = 0,dr(K , d|P 2N ) = 1dr(K , d|P 1N ) = 1;dr(K , d) = 12 ,3 ,2dr(K , ¬d|P 2N ) = 1dr(K , ¬d|P 1N ) = 1dr(K , ¬d) = 12 .3 ,2 ,2Obviously, only the unique free formula c bears no responsibility for the inconsistency of K in the case that there is no constraint. In contrast, in the presence of P 1N , both c and a bear no responsibility for the inconsistency of K . Moreover, the degree of responsibility of d decreases from 13 , because we have to remove at least two formulas together with d from K to break all the minimal inconsistent subsets in the case that a is not allowed to be removed from K .2 to 1On the other hand, in the case with constraint P 2N , removing a is a unique choice to break M1. This makes both removing ¬a ∨ b and removing ¬b unnecessary because a is shared by M1 and M2. Hence, neither ¬a ∨ b nor ¬b need to bear any responsibility for the inconsistency for K in the presence of P 2N .Now we consider the general case that there is a hard constraint.Definition 5.6. Let K be a knowledge base with a hard constraint H = (P , Q ) and α a formula of K . Then the degree of responsibility of α for the inconsistency of K in the presence of H, denoted dr(K , α|H), is defined asQ ∪{α} (G K |H) , if α ∈ X(G K |H) and γY |Q ∪{α} (G K |H) (cid:22)= 0,(cid:5)1dr(K , α|H) =γY |0,otherwise.Evidently, only formulas involved in minimal Y |Q -dominating sets for G K |H are assigned to nonzero values. In addition to free formulas and ones involved in protected-formulas constraint of H, if a formula is assigned to 0, then the presence of H must make removing this formula unnecessary to break all the minimal inconsistent subsets.Example 5.6. Consider K = {a, ¬a, ¬a ∨ b, ¬b, c, d, ¬d} again. Suppose that H = ({d}, {a}), then {¬d, a} is a unique minimal Y |{a}-dominating set for G K |H. So,dr(K , a|H) = dr(K , ¬d|H) = 12dr(K , ¬a|H) = dr(K , ¬a ∨ b|H) = dr(K , ¬b|H) = dr(K , d|H) = 0,dr(K , c|H) = 0.,Please note that besides the free formula c and the protected-formulas formula d, all of formulas in {¬a ∨ b, ¬b, ¬a} have no responsibility for the inconsistency in the presence of H.Now we consider the case that there is a soft constraint.Definition 5.7. Let K be a knowledge base with a soft constraint C and α a formula of K . Then the degree of responsibility of α for the inconsistency of K in the presence of C, denoted dr(K , α|C), is defined as(cid:5)dr(K , α|C) =1[C]{α}(G K ) , if α ∈ X(G K ) and γotherwise.γY |0,(G K ) (cid:22)= 0,Y |[C]{α}[C]Evidently, except formulas involved in minimal Yresponsibility for the inconsistency in the presence of C.-dominating sets for G K , all other formulas don’t need to bear any Example 5.7. Consider K = {a, ¬a, ¬a ∨ b, ¬b, c, d, ¬d} again. Suppose that C = {(a, d), (a, ¬d), (¬a, d), (¬a, ¬a ∨ b),(¬a ∨ b, d)}. Then {¬a, ¬b, ¬d} is a unique minimal Ydr(K , ¬a|C) = dr(K , ¬b|C) = dr(K , ¬d|C) = 1,3dr(K , a|C) = dr(K , ¬a ∨ b|C) = dr(K , d|C) = 0,dr(K , c|C) = 0.-dominating set of G K . So,[C]K. Mu / Artificial Intelligence 259 (2018) 52–9067Please note that besides the free formula c, all the formulas in {¬a ∨ b, a, d} have no responsibility for the inconsistency in the presence of C.Lastly, we extend the two measures to the case with a mixed constraint.Definition 5.8. Let K be a knowledge base with a mixed constraint (H, C) and α a formula of K , where H = (P , Q ). Then the degree of responsibility of α for the inconsistency of K in the presence of (H, C), denoted dr(K , α|H, C), is defined as(cid:5)dr(K , α|H, C) =[C]Q ∪{α}γY |0,1(G K |H) , if α ∈ X(G K |H) and γotherwise.(G K |H) (cid:22)= 0,Y |[C]Q ∪{α}Evidently, only formulas involved in minimal Y |[C]Q -dominating sets for G K |H are assigned to nonzero values.Example 5.8. Consider K = {a, ¬a, ¬a ∨ b, ¬b, c, d, ¬d} again. Suppose that H = ({a}, {¬d}) and C = {(a, d), (a, ¬d), (¬a, d),(¬a, ¬a ∨ b), (¬a ∨ b, d)}. Then {¬a, ¬b, ¬d} is a unique minimal Y[C]{¬d}-dominating set of G K |H. So,dr(K , ¬a|H, C) = dr(K , ¬b|H, C) = dr(K , ¬d|H, C) = 1,3dr(K , a|H, C) = dr(K , ¬a ∨ b|H, C) = dr(K , d|H, C) = 0,dr(K , c|H, C) = 0.Please note that the soft constraint focuses on the pairs of formulas that are not allowed to be modified together. However, we can generalize the soft constraint to describe the pairs of sets of formulas that are not allowed to be modified together. Moreover, the notions about the soft constraint defined above, including the compatibility of minimal correction subsets with the soft constraint, the minimal Y-dominating set, and the related measures can be generalized to this case in a natural way.[C]6. Causality-based explanationsPlease note that the inconsistency of a knowledge base counterfactually depends on each minimal correction subset of that base. Then the base-level measures with constraints proposed above can be interpreted as the minimum size of subsets of a knowledge base that the inconsistency counterfactually depends on in the presence of their own respective constraints from a causality-based perspective.Next we explain the measures dr(K , α|H), dr(K , α|C), and dr(K , α|H, C) from a perspective of causality by using Halpern and Pearl’s causal model and Chockler and Halpern’s notion of responsibility, respectively.6.1. A causal model for inconsistency with a hard constraintGiven an inconsistent knowledge base K with a hard constraint H = (P , Q ), to construct a causal model MK |H for the inconsistency of K in the presence of H,• we associate every formula α ∈ K with a binary variable Tα , whose value is 1 if α keeps unchanged and 0 if α is deleted from K . We use (cid:17)T to denote the vector of all the variables corresponding to formulas.• we associate with every minimal inconsistent subset M ∈ MI(K ) a binary variable S M , whose value is 1 if M keeps un-changed and 0 if M is broken. We use (cid:17)S to denote the vector of all the variables corresponding to minimal inconsistent subsets.• the problem of inconsistency in K in the presence of constraint is represented by the binary variable I , whose value is • the satisfaction of the constraint P is represented by the binary variable H P , whose value is 0 if all the formulas in P• the satisfaction of the constraint Q is represented by the binary variable H Q , whose value is 0 if all the formulas in Q1 if K is inconsistent and 0 otherwise.keep unchanged and 1 otherwise.are deleted from K and 1 otherwise.Let VK |H = {Tα|α ∈ K } ∪ {S M |M ∈ MI(K )} ∪ {I, H P , H Q }. Then RK |H(V ) = {0, 1} for each V ∈ VK |H.Without loss of generality, we associate every variable Tα with a binary exogenous variable U α . Moreover, we assume that the value of Tα depends on only the value of U α . Let UK = {U α|α ∈ K }. We use (cid:17)U to denote the vector of all the exogenous variables corresponding to formulas.In addition, we use (cid:17)T − Tα (resp. (cid:17)S − S M ) to denote a vector that results from deleting Tα from (cid:17)T (resp. deleting S Mfrom (cid:17)S).68K. Mu / Artificial Intelligence 259 (2018) 52–90We define the following functions:• F Tα ((cid:17)T − Tα, (cid:17)S, I, H P , H Q , (cid:17)U ) = U α (Tα = U α for short) for every formula α ∈ K .• F S M ((cid:17)T , (cid:17)S − S M , I, H P , H Q , (cid:17)U ) =• F H P ((cid:17)S, (cid:17)T , I, H Q , (cid:17)U ) =(1 − T β ) for short), where Tα (S M =α∈M(cid:7)(cid:7)(cid:7)(cid:6)(cid:6)• F H Q ((cid:17)S, (cid:17)T , I, H P , (cid:17)U ) =short).• F I ((cid:17)S, (cid:17)T , H P , H Q , (cid:17)U ) =α∈M(1 − T β ) (H P =(cid:8)β∈P(cid:6)Tγ ⊕β∈P(cid:7)γ ∈Q(cid:8)M∈MI(K ),γ ∈M(cid:9)α∈M,α(cid:22)=γ(cid:8)S M⊕ H P ⊕ H Q (I =(cid:7)M∈MI(K )(cid:7)M∈MI(K )(cid:9)S M⊕ H P ⊕ H Q for short).Tα for short) for every minimal inconsistent subset M ∈ MI(K ).is the Boolean addition.(cid:9)(cid:8)(cid:6)(1 −Tα)( H Q =(cid:7)γ ∈QTγ ⊕(cid:6)M∈MI(K ),γ ∈M(1 −(cid:6)α∈M,α(cid:22)=γ(cid:9)Tα)for Roughly speaking, the function F T α describes our assumption that the value of Tα depends on only the value of the ex-ogenous variable U α . In particular, F Tα ((cid:17)T − Tα, (cid:17)S, I, H P , H Q , (cid:17)U ) = 1 if and only if U α = 1. Then the context (cid:17)u = (1, 1, · · · , 1)((cid:17)u = (cid:17)1 for short) describes the case that none of the formulas is deleted from K .The function F S M aims to capture the fact that we need to remove at least one formula from the minimal inconsistent subset M to break M.The function F H P aims to capture the constraint that all the formulas in P are not allowed to be removed from K . Here H P = 0 if and only if T β = 1 for all β ∈ P .The function F H Q aims to capture the condition that all the formulas in Q must be removed from K in order to break all the minimal inconsistent subsets. Here H Q = 0 if and only if for each γ ∈ Q , Tγ = 0 and there exists at least one minimal inconsistent subset M such that γ ∈ M and (cid:6)Tα = 1.α∈M,α(cid:22)=γThe function F I accords with the fact that we need to break all the minimal inconsistent subsets of K to restore consistency in K under the constraint H. In summary, these functions capture the inherent features of inconsistency char-acterization in terms of minimal inconsistent subsets in the presence of a hard constraint.Now we are ready to construct a causal model for inconsistency in the presence of a hard constraint. Let K be a knowl-edge base, then a causal model for the problem of inconsistency of K in the presence of constraint H, denoted MK |H, is defined as MK |H = (cid:15)SK |H, FK |H(cid:16), whereSK |H = (cid:15)UK , VK |H, RK |H(cid:16)andFK |H = {F Tα|α ∈ K } ∪ {F S M|S ∈ MI(K )} ∪ {F I , F H P , F H Q}.The number of endogenous variables in MK |H is |K | + |MI(K )| + 3, which is considered as the size of MK |H in compu-tational complexity analysis.We use the following example to illustrate the notion of causal model for the inconsistency in the presence of a hard constraint.Example 6.1. Consider K = {a, ¬a, ¬a ∨ b, ¬b, c, d, ¬d} again. Suppose that H = ({d}, {a}), then we construct the causal model MK |H as follows:• Let U α and Tα be the exogenous and endogenous binary variables corresponding to α for α ∈ K , respectively. ThenTα = U α for all α ∈ K .• Let S Mi be the binary variable corresponding to Mi for i = 1, 2, 3. ThenS M1= Ta × T ¬a, S M2= Ta × T ¬a∨b × T ¬b, S M3= Td × T ¬d.• Let H P and H Q be the binary variable corresponding to constraints P = {d} and Q = {a}, respectively. ThenH P = 1 − Td, H Q = Ta ⊕ ((1 − T ¬a) × (1 − T ¬a∨b × T ¬b)) .• Let I be the binary variable corresponding to the inconsistency of K , thenI = S M1⊕ S M2⊕ S M3⊕ H P ⊕ H Q .K. Mu / Artificial Intelligence 259 (2018) 52–9069Fig. 7. The causal model MK |H.Given a context (cid:17)u = (cid:17)1 (i.e., U α = 1 for all α ∈ K ), then(MK |H, (cid:17)u) |= (Tα = 1) for α ∈ K ;(MK |H, (cid:17)u) |= (S Mi(MK |H, (cid:17)u) |= (I = 1).= 1), for i = 1, 2, 3;Furthermore, consider the counterfactual world arising from (T ¬b, T ¬a, T ¬d) ← (cid:17)0, then(MK |H, (cid:17)u) |= [(T ¬b, T ¬a, T ¬d) ← (cid:17)0](S M1(MK |H, (cid:17)u) |= [(T ¬b, T ¬a, T ¬d) ← (cid:17)0](H P = 0);(MK |H, (cid:17)u) |= [(T ¬b, T ¬a, T ¬d) ← (cid:17)0](H Q = 1).= 0) ∧ (S M2= 0) ∧ (S M3= 0);The first one states that all the three minimal inconsistent subsets will be broken if we delete the formulas ¬b, ¬a, and ¬dfrom K . The second states that the constraint P is satisfied by (T ¬b, T ¬a, T ¬d) ← (cid:17)0, while the third states that the constraint Q cannot be satisfied by (T ¬b, T ¬a, T ¬d) ← (cid:17)0.Consider another counterfactual world arising from (Ta, T ¬d) ← (cid:17)0, then(MK |H, (cid:17)u) |= [(Ta, T ¬d) ← (cid:17)0)](S Mi(MK |H, (cid:17)u) |= [(Ta, T ¬d) ← (cid:17)0)](I = 0).= 0), for i = 1, 2, 3;These coincide with the intuition that all the minimal inconsistent subsets will be broken if we delete the formulas a and ¬d from K under the constraint H.This causal model for the inconsistency of K can be also represented by the causal network illustrated in Fig. 7.The following proposition provides an explanation for the measure dr(K , α|H) from the point of view of causality.Proposition 6.1. Let K be an inconsistent knowledge base with a hard constraint H = (P , Q ) and α a formula of K . Then1. Tα = 1 is a cause of I = 1 in (MK |H, (cid:17)1) if and only if there is at least one minimal Y |{α}∪Q -dominating set of G K |H.2. dr((MK |H, (cid:17)1), (Tα = 1), (I = 1)) = dr(K , α|H).Proof. Let K be an inconsistent knowledge base with a hard constraint H = (P , Q ) and MK |H = (cid:15)SK |H, FK |H(cid:16) the causal model for the inconsistency of K in the presence of H. Given (cid:17)u = (cid:17)1, then (cid:17)T = (cid:17)1. So, (MK |H, (cid:17)1) |= (H P = 0).1. Sufficiency. If there is at least one minimal Y |{α}∪Q -dominating set of G K |H, we only need to check AC2.Consider a smallest minimal Y |{α}∪Q -dominating set R of G K |H. Then {α} ∪ Q ⊆ R and P ∩ R = ∅. Let (cid:17)W = (cid:17)T R\{α}, where (cid:17)T R\{α} is the vector of variables corresponding to the formulas in R \ {α}.• AC2 (a). If Tα = 0, then S M = 0 for every M s.t. α ∈ M. Moreover, if (cid:17)W = (cid:17)0, then S M(cid:2) = 0 for every M. Note that Q ⊆ R, then (cid:17)R = (Tα, (cid:17)W ) = (cid:17)0 guarantees that H Q = 0 holds. So,(cid:2) ∈ MI(K ) such that α /∈ M(cid:2)(MK |H, (cid:17)1) |= [Tα ← 0, (cid:17)W ← (cid:17)0](S M = 0)for all M ∈ MI(K ), and(MK |H, (cid:17)1) |= [Tα ← 0, (cid:17)W ← (cid:17)0](H Q = 0).On the other hand, P ∩ R = ∅ implies that(MK |H, (cid:17)1) |= [Tα ← 0, (cid:17)W ← (cid:17)0](H P = 0).70K. Mu / Artificial Intelligence 259 (2018) 52–90Theni.e.,(MK |H, (cid:17)1) |= [Tα ← 0, (cid:17)W ← (cid:17)0](I = 0),(MK |H, (cid:17)1) |= [Tα ← 0, (cid:17)W ← (cid:17)0]¬(I = 1).• AC2 (b). Consider (cid:17)Z = (cid:17)T − (cid:17)W . If Tα = 1 and (cid:17)Z(cid:2) = (cid:17)1 for all subsets (cid:17)Z(cid:2)Y |{α}∪Q -dominating set, there is at least one minimal inconsistent subset MThat is,of (cid:17)Z − (cid:17)Tα , then from the minimality of R as a and S M(cid:2) = 1 when (cid:17)W = (cid:17)0. s.t. α ∈ M(cid:2)(cid:2)(MK |H, (cid:17)1) |= [Tα ← 1, (cid:17)W ← (cid:17)0, (cid:17)Z(cid:2) = (cid:17)1](I = 1).So, Tα = 1 is a cause of I = 1.Necessity. If Tα = 1 is a cause of I = 1, then there exists a partition ( (cid:17)Z , (cid:17)W ) satisfying AC2. Let R W be the set of formulas corresponding to {Tα} ∪ (cid:17)W . Then R W ∩ P = ∅ and Q ⊆ R W , moreover, ∀M ∈ MI(K ), ∃β ∈ R W s.t. β ∈ M. Therefore, R Wis a Y -dominating set of G K |H, moreover, there exists a minimal Y |Q -dominating set R of G K |H such that R ⊆ R W . Suppose that any minimal Y |Q -dominating set R of G K |H such that R ⊆ R W does not contain α, then α /∈ Q and there exists a minimal Y |Q -dominating set R(MK |H, (cid:17)1) |= [Tα ← 1, (cid:17)W ← (cid:17)0, (cid:17)Zof G K |H such that R(cid:2) = (cid:17)1](I = 0).(cid:2) ⊆ R W \ {α}. This implies that(cid:2)This contradicts A2(b). So, there exists at least one minimal Y |Q -dominating set R of G K |H such that α ∈ R. Hence, there exists at least one minimal Y |{α}∪Q -dominating set of G K |H.2. From the proof for sufficiency above, we know that no subset of (cid:17)W satisfies AC2. Thendr((MK |H, (cid:17)1), (Tα = 1), (I = 1)) =11 + |R \ {α}|=1γY |Q ∪{α} (G K |H)if (Tα = 1) is a cause of I = 1. Otherwisedr((MK |H, (cid:17)1), (Tα = 1), (I = 1)) = 0.So,dr((MK |H, (cid:17)1), (Tα = 1), (I = 1)) = dr(K , α|H).(cid:2)The first item of this proposition shows that only formulas involved in a minimal Y |Q -dominating set of G K |H may be considered as causes of the inconsistency in a knowledge base in the presence of a hard constraint H. This accords with that only formulas involved in minimal Y |Q -dominating sets of G K |H have to bear nonzero responsibilities for the inconsistency of a knowledge base with the constraint in the context of the measure dr(K , α|H). The second item shows that the measure dr(K , α|H) exactly grasps the degree of responsibility of α for the inconsistency of K in the presence of H from the point of view of causality.6.2. A causal model for inconsistency with a soft constraintCompared to the hard constraint, the soft constraint is given in the form of pairs of formulas that are not allowed to be removed together. Given an inconsistent knowledge base K with a soft constraint C, besides the variables corresponding to formulas and minimal inconsistent subsets as above, we associate with each pair (α, β) ∈ C a binary variable L(α,β), whose value is 1 if and only if both α and β are removed from K . We use (cid:17)L to denote the vector of all variables corresponding to pairs of C.Let VK |C = {Tα|α ∈ K } ∪ {S M |M ∈ MI(K )} ∪ {I} ∪ {L(α,β)|(α, β) ∈ C}. Then RK |C(V ) = {0, 1} for each V ∈ VK |C .Further, we define the following functions:• F Tα ((cid:17)T − Tα, (cid:17)S, I, (cid:17)L, (cid:17)U ) = U α (Tα = U α for short) for every formula α ∈ K .• F S M ((cid:17)T , (cid:17)S − S M , I, (cid:17)L, (cid:17)U ) =Tα (S M =• F L(α,β) ((cid:17)S, (cid:17)T , I, (cid:17)L − L(α,β), (cid:17)U ) = (1 − Tα) × (1 − T β ) (L(α,β) = (1 − Tα) × (1 − T β ) for short) for every pair (α, β) ∈ C.(cid:7)• F I ((cid:17)S, (cid:17)T , (cid:17)L, (cid:17)U ) = (Tα for short) for every minimal inconsistent subset M ∈ MI(K ).L(α,β)) for short).L(α,β)) (I = (S M ) ⊕ (S M ) ⊕ (α∈Mα∈M(cid:7)(cid:7)(cid:7)(cid:6)(cid:6)M∈MI(K )(α,β)∈CM∈MI(K )(α,β)∈CThe function F L(α,β) aims to capture the constraint that α and β are not allowed to be removed together from K , while the function F I accords with the fact that we need to break all the minimal inconsistent subsets of K to restore consistency in K under the constraint C.Now we are ready to construct a causal model for inconsistency in the presence of a soft constraint. Let K be a knowl-edge base, then a causal model for the problem of inconsistency of K in the presence of constraint C, denoted MK |C , is K. Mu / Artificial Intelligence 259 (2018) 52–9071Fig. 8. The causal model MK |C .defined as MK |C = (cid:15)SK |C, FK |C(cid:16), whereSK |C = (cid:15)UK , VK |C, RK |C(cid:16)andFK |C = {F Tα|α ∈ K } ∪ {F S M|M ∈ MI(K )} ∪ {F L(α,β)|(α, β) ∈ C} ∪ {F I }.The number of endogenous variables in MK |C is |K | + |MI(K )| + |C| + 1, which is considered as the size of MK |C in computational complexity analysis.We use the following example to illustrate the notion of causal model for the inconsistency in the presence of a soft constraint.Example 6.2. Consider K = {a, ¬a, ¬a ∨ b, ¬b, c, d, ¬d} again. Suppose that C = {(a, d), (a, ¬d), (¬a, d), (¬a, ¬a ∨ b), (¬a ∨b, d)}, then we construct the causal model MK |C as follows:• Tα = U α for all α ∈ K .• S M1= Ta × T ¬a, S M2• L(a,d) = (1 − Ta) × (1 − Td), L(a,¬d) = (1 − Ta) × (1 − T ¬d), L(¬a,d) = (1 − T ¬a) × (1 − Td), = Ta × T ¬a∨b × T ¬b, S M3= T ¬d × Td.(1 − T ¬a∨b), L(¬a∨b,d) = (1 − T ¬a∨b) × (1 − Td).• I = S M1⊕ S M2⊕ S M3⊕ L(a,d) ⊕ L(a,¬d) ⊕ L(¬a,d) ⊕ L(¬a,¬a∨b) ⊕ L(¬a∨b,d).L(¬a,¬a∨b) = (1 − T ¬a) ×Given a context (cid:17)u = (cid:17)1 (i.e., U α = 1 for all α ∈ K ), then(MK |C, (cid:17)u) |= (L(α,β) = 0) for (α, β) ∈ C;(MK |C, (cid:17)u) |= (I = 1).This causal model for the inconsistency of K can be also represented by the causal network illustrated in Fig. 8.The following proposition provides an explanation for the measure dr(K , α|C) from the point of view of causality.Proposition 6.2. Let K be an inconsistent knowledge base with a soft constraint C and α a formula of K . Then1. Tα = 1 is a cause of I = 1 in (MK |C, (cid:17)1) if and only if there is at least one minimal Y |[C]2. dr((MK |C, (cid:17)1), (Tα = 1), (I = 1)) = dr(K , α|C).{α}-dominating set of G K .Proof. Let K be an inconsistent knowledge base with a soft constraint C and MK |C the causal model for the inconsistency of K in the presence of C.1. Sufficiency. If there is at least one minimal Y |[C]{α}-dominating set of G K , we only need to check AC2.Consider a smallest minimal Y |[C]{α}-dominating set R of G K . Let (cid:17)W = (cid:17)T R\{α}, where (cid:17)T R\{α} is the vector of variables corresponding to the formulas in R \ {α}.• AC2 (a). (cid:17)R = (Tα, (cid:17)W ) = (cid:17)0 guarantees that S M = 0 for all M ∈ MI(K ). Moreover, the compatibility of R with constraint C guarantees that L(β,γ ) = 0 holds for every pair (β, γ ) ∈ C. So, if Tα = 0 and (cid:17)W = (cid:17)0, then I = 0. That is,(MK |C, (cid:17)1) |= [Tα ← 0, (cid:17)W ← (cid:17)0]¬(I = 1).72K. Mu / Artificial Intelligence 259 (2018) 52–90• AC2 (b). Consider (cid:17)Z = (cid:17)T − (cid:17)W . If Tα = 1 and (cid:17)Zof (cid:17)Z − (cid:17)Tα , then from the minimality of R as a {α}-dominating set, there is at least one minimal inconsistent subset M s.t. α ∈ M and S M = 1 when (cid:17)W = (cid:17)0. That (cid:2) = (cid:17)1 for all subsets (cid:17)Z(cid:2)Y |[C]is,(MK |C, (cid:17)1) |= [Tα ← 1, (cid:17)W ← (cid:17)0, (cid:17)Z(cid:2) = (cid:17)1](I = 1).So, Tα = 1 is a cause of I = 1.Necessity. Suppose that Tα = 1 is a cause of I = 1, then there exists a partition ( (cid:17)Z , (cid:17)W ) satisfying AC2. Moreover, the set of formulas corresponding to {Tα } ∪ (cid:17)W is a Y |[C]{α}-dominating set of G K . Then there exists at least one minimal (cid:2). On the contrary, it is that α /∈ R-dominating set YR-dominating set Rsuch that R(cid:2) ⊆ R and α ∈ Rholds for all Ysuch that R[C][C](cid:2)(cid:2)(cid:2)(cid:2) ⊆ R. This implies that(MK |C, (cid:17)1) |= [Tα ← 1, (cid:17)W R(cid:2) ← (cid:17)0, (cid:17)Z(cid:2) = (cid:17)1](I = 0),where (cid:17)W R(cid:2) is the vector of variables corresponding to formulas in R(cid:2)2. From the proof for sufficiency above, we know that no subset of (cid:17)W satisfies AC2. Then. This contradicts A2(b).dr((MK |C, (cid:17)1), (Tα = 1), (I = 1)) =11 + |R \ {α}|=γ1(G K )Y |[C]{α}if (Tα = 1) is a cause of I = 1. Otherwisedr((MK |C, (cid:17)1), (Tα = 1), (I = 1)) = 0.So,dr((MK |C, (cid:17)1), (Tα = 1), (I = 1)) = dr(K , α|C).(cid:2)The first item of this proposition shows that only formulas involved in a minimal Y-dominating set of G K may be considered as causes of the inconsistency in a knowledge base in the presence of a soft constraint C. This accords with that only formulas involved in minimal Y-dominating sets of G K have to bear nonzero responsibilities for the inconsistency of a knowledge base with the constraint in the context of the measure dr(K , α|C). The second item shows that the measure dr(K , α|C) exactly grasps the degree of responsibility of α for the inconsistency of K in the presence of C from the point of view of causality.[C][C]6.3. A causal model for inconsistency with a mixed constraintGiven an inconsistent knowledge base K with a mixed constraint (H, C), the causal model for the inconsistency of K in the presence of (H, C), denoted MK |(H,C), can be constructed as follows:• the set VK |(H,C) of endogenous variables consists of all the variables involved in MK |H and MK |C , i.e.,(cid:3)VK |(H,C) = VK |H{Tα|α ∈ K } ∪ {S M |M ∈ MI(K )} ∪ {I} ∪ {H P , H Q } ∪ {L(α,β)|(α, β) ∈ C}VK |C =• RK |(H,C)(V ) = {0, 1} for each V ∈ VK |(H,C).• SK |(H,C) = (cid:15)UK , VK |(H,C), RK |(H,C)(cid:16).• The functions are given as follows:– F Tα ((cid:17)T − Tα, (cid:17)S, I, H P , H Q , (cid:17)L, (cid:17)U ) = U α (Tα = U α for short) for every formula α ∈ K .– F S M ((cid:17)T , (cid:17)S − S M , I, H P , H Q , (cid:17)L, (cid:17)U ) =Tα for short) for every minimal inconsistent subset M ∈ MI(K ).– F L(α,β) ((cid:17)S, (cid:17)T , I, H P , H Q , (cid:17)L − L(α,β), (cid:17)U ) = (1 − Tα) × (1 − T β ) (L(α,β) = (1 − Tα) × (1 − T β ) for short) for every pair – F H P ((cid:17)S, (cid:17)T , I, H Q , (cid:17)L, (cid:17)U ) =(1 − T β ) for short).(α, β) ∈ C.Tα (S M =α∈Mα∈M(cid:7)(cid:7)(cid:6)(cid:6)(1 − T β ) (H P =β∈P(cid:8)β∈P– F H Q ((cid:17)S, (cid:17)T , I, H P , (cid:17)U ) =Tγ ⊕(cid:7)γ ∈Q(cid:6)(cid:6)(1 −M∈MI(K ),γ ∈M(cid:9)Tα)( H Q =Tγ ⊕(cid:6)M∈MI(K ),γ ∈M(1 −(cid:6)(cid:9)Tα)α∈M,α(cid:22)=γ(cid:7)(α,β)∈C(cid:8)(cid:7)γ ∈Q(cid:7)M∈MI(K )α∈M,α(cid:22)=γ(cid:7)(α,β)∈CS M ) ⊕ H P ⊕ H Q ⊕ (L(α,β)) (I = (S M ) ⊕ H P ⊕ H Q ⊕ (L(α,β)) for for short).– F I ((cid:17)S, (cid:17)T , H P , H Q , (cid:17)L, (cid:17)U ) = ((cid:7)M∈MI(K )short).K. Mu / Artificial Intelligence 259 (2018) 52–9073Fig. 9. The causal model MK |(H,C).The function F I states that we need to break all the minimal inconsistent subsets of K to restore consistency in Kunder constraints H and C.Then the causal model can be given as MK |(H,C) = (cid:15)SK |(H,C), FK |(H,C)(cid:16), whereSK |(H,C) = (cid:15)UK , VK |(H,C), RK |(H,C)(cid:16)andFK |(H,C) = {F Tα|α ∈ K } ∪ {F S M|(α, β) ∈ C}.∪{F L(α,β)|M ∈ MI(K )} ∪ {F I } ∪ {F H P , F H Q}The number of endogenous variables in MK |C is |K | + |MI(K )| + |C| + 3, which is considered as the size of MK |(H,C) in computational complexity analysis.We use the following example to illustrate the notion of causal model for the inconsistency in the presence of a mixed constraint.Example 6.3. Consider K = {a, ¬a, ¬a ∨ b, ¬b, c, d, ¬d} again. Suppose that H = ({a}, {¬d}) and C = {(a, d), (a, ¬d), (¬a, d),(¬a, ¬a ∨ b), (¬a ∨ b, d)}, then we construct the causal model MK |(H,C) as follows:• Tα = U α for all α ∈ K .• S M1= Ta × T ¬a, S M2• H P = 1 − Ta, H Q = T ¬d ⊕ (1 − Td).• L(a,d) = (1 − Ta) × (1 − Td), L(a,¬d) = (1 − Ta) × (1 − T ¬d), L(¬a,d) = (1 − T ¬a) × (1 − Td), = Ta × T ¬a∨b × T ¬b, S M3= T ¬d × Td.(1 − T ¬a∨b), L(¬a∨b,d) = (1 − T ¬a∨b) × (1 − Td).• I = S M1⊕ S M2⊕ S M3⊕ L(a,d) ⊕ L(a,¬d) ⊕ L(¬a,d) ⊕ L(¬a,¬a∨b) ⊕ L(¬a∨b,d) ⊕ H P ⊕ H Q .L(¬a,¬a∨b) = (1 − T ¬a) ×Given a context (cid:17)u = (cid:17)1 (i.e., U α = 1 for all α ∈ K ), then(MK |(H,C), (cid:17)u) |= (I = 1).This causal model for the inconsistency of K can be also represented by the causal network illustrated in Fig. 9.The following proposition provides an explanation for the measure dr(K , α|H, C) from the point of view of causality.Proposition 6.3. Let K be an inconsistent knowledge base with a mixed constraint (H, C) and α a formula of K , where H = (P , Q ). Then1. Tα = 1 is a cause of I = 1 in (MK |(H,C), (cid:17)1) if and only if there is at least one minimal Y |[C]2. dr((MK |(H,C), (cid:17)1), (Tα = 1), (I = 1)) = dr(K , α|H, C).Q ∪{α}-dominating set of G K |H.Proof. Let K be an inconsistent knowledge base with a mixed constraint (H = (P , Q ), C) and MK |(H,C) the causal model for the inconsistency of K in the presence of the mixed constraint.1. Sufficiency. If there is at least one minimal Y |[C]Q ∪{α}-dominating set of G K |H, we only need to check AC2. Consider a smallest minimal Y |[C]Q ∪{α}-dominating set R of G K |H. Let (cid:17)W = (cid:17)T R\{α}.74K. Mu / Artificial Intelligence 259 (2018) 52–90• AC2 (a). From the proof of Proposition 6.1,(MK |(H,C), (cid:17)1) |= [Tα ← 0, (cid:17)W ← (cid:17)0](S M = 0)for all M ∈ MI(K ), and(MK |(H,C), (cid:17)1) |= [Tα ← 0, (cid:17)W ← (cid:17)0](H Q = 0),(MK |(H,C), (cid:17)1) |= [Tα ← 0, (cid:17)W ← (cid:17)0](H P = 0).From the proof of Proposition 6.2,(MK |(H,C), (cid:17)1) |= [Tα ← 0, (cid:17)W ← (cid:17)0](L(β,γ ) = 0)for every pair (β, γ ) ∈ C. Then(MK |(H,C), (cid:17)1) |= [Tα ← 0, (cid:17)W ← (cid:17)0](I = 0),i.e.,(MK |(H,C), (cid:17)1) |= [Tα ← 0, (cid:17)W ← (cid:17)0]¬(I = 1).• AC2 (b). Consider (cid:17)Z = (cid:17)T − (cid:17)W . If Tα = 1 and (cid:17)Z(cid:2) = (cid:17)1 for all subsets (cid:17)Z(cid:2)Q ∪{α}-dominating set, there is at least one minimal inconsistent subset Mof (cid:17)Z − (cid:17)Tα , then from the minimality of R as a and S M(cid:2) = 1 when (cid:17)W = (cid:17)0. s.t. α ∈ M(cid:2)(cid:2)Y |[C]That is,(MK |(H,C), (cid:17)1) |= [Tα ← 1, (cid:17)W ← (cid:17)0, (cid:17)Z(cid:2) = (cid:17)1](I = 1).So, Tα = 1 is a cause of I = 1.Necessity. If Tα = 1 is a cause of I = 1, then there exists a partition ( (cid:17)Z , (cid:17)W ) satisfying AC2. Let R W be the set of formulas corresponding to {Tα} ∪ (cid:17)W . Then R W is a Y |[C]Q ∪{α}-dominating set of G K |H, moreover, there exists a minimal Y |[C]Q -dominating set R of G K |H such that R ⊆ R W does not contain α, then α /∈ Q and there exists a minimal Y |[C]of G K |H such that (cid:2) ⊆ R W \ {α}. This implies thatRQ -dominating set R of G K |H such that R ⊆ R W . Suppose that any minimal Y |[C]Q -dominating set R(cid:2)(MK |(H,C), (cid:17)1) |= [Tα ← 1, (cid:17)W ← (cid:17)0, (cid:17)Z(cid:2) = (cid:17)1](I = 0).This contradicts A2(b). So, there exists at least one minimal Y |[C]there exists at least one minimal Y |[C]{α}∪Q -dominating set of G K |H.2. From the proof for sufficiency above, we know that no subset of (cid:17)W satisfies AC2. ThenQ -dominating set R of G K |H such that α ∈ R. Hence, dr((MK |(H,C), (cid:17)1), (Tα = 1), (I = 1)) =11 + |R \ {α}|=γif (Tα = 1) is a cause of I = 1. Otherwisedr((MK |(H,C), (cid:17)1), (Tα = 1), (I = 1)) = 0.So,1(G K |H)Y |[C]Q ∪{α}dr((MK |(H,C), (cid:17)1), (Tα = 1), (I = 1)) = dr(K , α|H, C).(cid:2)The first item of this proposition shows that only formulas involved in a minimal Y |[C]Q -dominating set of G K |H may be considered as causes of the inconsistency in a knowledge base in the presence of a mixed constraint (H, C). This accords with that only formulas involved in minimal Y |[C]Q -dominating sets of G K |H have to bear nonzero responsibilities for the inconsistency of a knowledge base with the constraint in the context of the measure dr(K , α|H, C). The second item shows that the measure dr(K , α|H, C) exactly grasps the degree of responsibility of α for the inconsistency of K in the presence of (H, C) from the point of view of causality.K. Mu / Artificial Intelligence 259 (2018) 52–90757. Logical properties and computational complexityIn this section, we discuss some interesting logical properties for the base-level measure and the formula-level measure, respectively.The following proposition shows that the base-level measure Idr (K |H) is a bounded function w.r.t. the constraint H.Proposition 7.1. Let K be a knowledge base with a hard constraint H. ThenγY (G K ) = Idr(K ) ≤ Idr(K |H) ≤ LY (G K ).Proof. Let K be a knowledge base with a hard constraint H = (P , Q ). Then any minimal Y |Q -dominating set of G K |H must be a minimal Y -dominating set of G K . So,γY (G K ) = Idr(K ) ≤ Idr(K |H) ≤ LY (G K ).(cid:2)Let H = (P , Q ) and H(cid:2) = (P(cid:2)following proposition shows that the base-level measure Idr (K |H) is a monotonic function w.r.t. the constraint H.(cid:2)) two hard constraints for K , we say that H ⊆ H(cid:2)and Q ⊆ Qif P ⊆ P(cid:2), Q(cid:2). Then the Proposition 7.2. Let K be a knowledge base and H and H(cid:2)two hard constraints for K such that H ⊆ H(cid:2). ThenIdr(K |H) ≤ Idr(K |H(cid:2)).(7.1)Proof. Let K be a knowledge base and H = (P , Q ) and H(cid:2) = (P. Then any minimal Y |Q (cid:2) -dominating set of G K |H(cid:2) must be a minimal Y |Q -dominating set of G K |H. Therefore the inequality (7.1)holds. (cid:2)(cid:2)) two hard constraints for K such that H ⊆ H(cid:2)(cid:2), QIn particular, we have the following result about the protected-formulas constraint.Corollary 7.1. Let K be a knowledge base. Then Idr(K |P N) ≤ Idr(K |PP ⊆ P.(cid:2)(cid:2)N) for any two protected-formulas constraints P and P(cid:2)such that Proof. This is a direct consequence of Proposition 7.2. (cid:2)The following proposition shows that there is a special relation between Idr (K |H) and the Y |Q ∩X(G i )-domination number for each component G i of G K |H.Proposition 7.3. Let K be a knowledge base with a hard constraint H. Let {G 1, G 2, · · · , Gm} be the set of components of the MIS-graph G K |H. ThenIdr(K |H) =m(cid:10)i=1γY |Q ∩ X(Gi ) (G i).Proof. Let R be a minimal Y |Q -dominating set of G K |H, then R ∩ X(G i) must be a minimal Y |Q ∩X(G i )-dominating set of G ifor all 1 ≤ i ≤ m. Therefore,Idr(K |H) = γY |Q (G K |H) =m(cid:10)i=1γY |Q ∩ X(Gi ) (G i).(cid:2)In particular, we have the following result about Idr .Corollary 7.2. Let K be a knowledge base and {G 1, G 2, · · · , Gm} the set of components of the MIS-graph G K . ThenIdr(K ) =m(cid:10)i=1γY (G i) =m(cid:10)i=1Idr(X(G i)).76K. Mu / Artificial Intelligence 259 (2018) 52–90Proof. This is a direct consequence of Proposition 7.3. (cid:2)This corollary states that the measure Idr (K ) is exactly the sum of the measures of MIS-components of K .Next we consider some properties of the formula-level measure. The following proposition shows that dr(K , α|H) is anti-monotonic with regard to H.Proposition 7.4. Let K be a knowledge base and α a formula of K . Thendr(K , α|H(cid:2)) ≤ dr(K , α|H)holds for any two hard constraints H and H(cid:2)such that H ⊆ H(cid:2).(7.2)Proof. Let K be a knowledge base and H and H(cid:2)Y |{α}∪Q (cid:2) -dominating set of G K |H(cid:2) must be a minimal Y |{α}∪Q -dominating set of G K |H.two hard constraints for K such that H ⊆ H(cid:2). Note that any minimal • If there exists at least one minimal Y |{α}∪Q (cid:2) -dominating set of G K |H(cid:2) , thendr(K , α|H(cid:2)) =1(cid:2) (G K |H(cid:2) )≤1γY |{α}∪Q (G K |H)γY |{α}∪Q= dr(K , α|H).• Otherwise,dr(K , α|H(cid:2)) = 0 ≤ dr(K , α|H).So, the inequality (7.2) holds for any two hard constraints H and H(cid:2)such that H ⊆ H(cid:2). (cid:2)Corollary 7.3. Let K be a knowledge base and α a formula of K . Then• dr(K , α|H) ≤ dr(K , α) for any hard constraint H.• dr(K , α|P(cid:2)N) ≤ dr(K , α|P N) for any two protected-formulas constraints P and P(cid:2)such that P ⊆ P(cid:2).Proof. This is a direct consequence of Proposition 7.4. (cid:2)The following proposition allows us to look inside the role of each component of the MIS-graph with a hard constraint in identifying the degree of responsibility of a given formula for the inconsistency.Proposition 7.5. Let K be a knowledge base with a hard constraint H = (P , Q ) and α a formula of K . Suppose that {G 1, G 2, · · · , Gm}is the set of components of the MIS-graph G K |H and α ∈ X(G 1). Then⎧⎨dr(K , α|H) =⎩γY |{α}∪ X10,1(G 1)+m(cid:14)i=2γY |Xi(G i ), if γY |{α}∪ X1(G 1) (cid:22)= 0,otherwise,(7.3)where Xi = Q ∩ X(G i) for i = 1, 2, · · · , m.Proof. If there is no minimal Y |{α}∪X1 -dominating set of G 1, then there is no minimal Y |{α}∪Q -dominating set of G K |H. On the other hand, if R is a smallest minimal Y |{α}∪Q -dominating set of G K |H, then R ∩ X(G 1) is a smallest minimal Y |{α}∪X1 -dominating set of G 1, and R ∩ X(G i) must be a smallest minimal Y |Q ∩X(G i )-dominating set of G i for all 2 ≤ i ≤ m. Therefore the equation (7.3) holds. (cid:2)Next we consider the cases that hard constraints have no impact on the two measures, respectively.Proposition 7.6. Let K be a knowledge base with a hard constraint H. ThenIdr(K ) = Idr(K |H)if and only if there exists at least one smallest minimal Y -dominating set R of G K such that R ∩ P = ∅ and Q ⊆ R.Proof. If R is a smallest minimal Y -dominating set of G K such that R ∩ P = ∅ and Q ⊆ R, then R is also a smallest minimal Y |Q -dominating set of G K |H. So,Idr(K ) = Idr(K |H).K. Mu / Artificial Intelligence 259 (2018) 52–9077On the other hand, if R is a smallest minimal Y |Q -dominating set of G K |H, then R must be a minimal Y -dominating set of G K such that R ∩ P = ∅ and Q ⊆ R i.e.,Idr(K ) ≤ Idr(K |H) = |R|.Further, ifIdr(K ) = Idr(K |H) = |R|,then R must be a smallest minimal Y -dominating set of G K . (cid:2)This proposition shows that a hard constraint (P , Q ) cannot affect the degree of inconsistency of K if there exists at least one smallest minimal Y -dominating set of G K compatible with the hard constraint. Similarly, given a formula α involved in the inconsistency, a hard constraint (P , Q ) cannot affect the degree of responsibility of α for the inconsistency if there exists at least one smallest minimal Y |{α}-dominating set of G K compatible with the hard constraint.Proposition 7.7. Let K be an inconsistent knowledge base with a hard constraint H = (P , Q ) and α a formula of (cid:2)MI(K ). Thendr(K , α) = dr(K , α|H)if and only if there exists at least one smallest minimal Y |{α}-dominating set R of G K such that R ∩ P = ∅ and Q ⊆ R.Proof. If R is a smallest minimal Y |{α}-dominating set of G K such that R ∩ P = ∅ and Q ⊆ R, then R is also a smallest minimal Y |{α}∪Q -dominating set of G K |H. So,dr(K , α) = dr(K , α|H).On the other hand, dr(K , α) = dr(K , α|H) implies that 0 < dr(K , α|H) = 1dominating set of G K |H. Then R must be a minimal Y |{α}-dominating set of G K such that R ∩ P = ∅ and Q ⊆ R. So,|R| , where R is a smallest minimal Y |{α}∪Q -dr(K , α) ≥ 1|R|= dr(K , α|H).Further, ifdr(K , α) = dr(K , α|H) = 1|R|then R must be a smallest minimal Y |{α}-dominating set of G K . (cid:2),The following proposition gives us the minimum nonzero responsibility that a formula involved in the inconsistency has to bear in the presence of a hard constraint.Proposition 7.8. Let K be an inconsistent knowledge base with a hard constraint H = (P , Q ) and α a formula of (cid:2)MI(K ). Then1|R0|≤ dr(K , α|H) ≤ dr(K , α)if dr(K , α|H) > 0, where R0 is the largest minimal Y |Q ∪{α}-dominating set of G K .Proof. If R is a minimal Y |Q ∪{α}-dominating set of G K |H, then R must be a minimal Y |Q ∪{α}-dominating set of G K . So, |R| ≤ |R0|. Therefore,1|R0|≤ 1|R|≤ dr(K , α|H) ≤ dr(K , α).(cid:2)Lastly, we consider the formulas that needn’t bear any responsibility for the inconsistency in the presence of a hard constraint.Proposition 7.9. Let K be an inconsistent knowledge base with a hard constraint H = (P , Q ) and α a formula of K . Then(1) dr(K , α|H) = dr(K , α) = 0 if and only if α is a free formula.(2) 0 = dr(K , α|H) < dr(K , α) if and only if α ∈ P ∪ N(K |H), where N(K |H) = {β ∈ X(G K |H)|∀R ∈ MC(K ) s.t. R ∩ P =∅ and Q ⊆ R, β /∈ R}.78K. Mu / Artificial Intelligence 259 (2018) 52–90Proof. It is a direct consequence of definition of dr(K , α|H). (cid:2)The following proposition shows that the base-level measure Idr (K |C) is a bounded function w.r.t. the constraint C.Proposition 7.10. Let K be a knowledge base with a soft constraint C. ThenγY (G K ) = Idr(K ) ≤ Idr(K |C) ≤ LY (G K ).Proof. Let K be a knowledge base with a soft constraint C. Then any minimal YY -dominating set of G K . So,[C]-dominating set of G K must be a minimal γY (G K ) = Idr(K ) ≤ Idr(K |C) ≤ LY (G K ).(cid:2)The following proposition shows that the base-level measure Idr (K |C) is a monotonic function w.r.t. the constraint C.Proposition 7.11. Let K be a knowledge base and C and C(cid:2)two soft constraints for K such that C ⊆ C(cid:2). ThenIdr(K |C) ≤ Idr(K |C(cid:2)).(7.4)Proof. Let K be a knowledge base and C and C(cid:2)-dominating set of G K must be a minimal YYtwo soft constraints for K such that C ⊆ C(cid:2)-dominating set of G K . So, the inequality (7.4) holds. (cid:2)[C(cid:2)][C]. Then any minimal The following proposition shows that dr(K , α|C) is anti-monotonic with regard to C.Proposition 7.12. Let K be a knowledge base and α a formula of K . Thendr(K , α|C(cid:2)) ≤ dr(K , α|C)holds for any two soft constraints C and C(cid:2)such that C ⊆ C(cid:2).Proof. Let K be a knowledge base and C and C(cid:2)Y |[C(cid:2)]{α} -dominating set of G K must be a minimal Y |[C]two soft constraints for K such that C ⊆ C(cid:2){α}-dominating set of G K . Then(7.5). Note that any minimal dr(K , α|C(cid:2)) =1(G K )Y |[C(cid:2)]{α}γ≤γ1(G K )Y |[C]{α}= dr(K , α|C)if there exists at least one minimal Y |[C(cid:2)](G K ) = 0, thenG K but γY |[C(cid:2)]{α}{α} -dominating set of G K . If there exists at least one minimal Y |[C]{α}-dominating set of dr(K , α|C(cid:2)) = 0 <= dr(K , α|C).1(G K )γY |[C]{α}(G K ) = 0, thenIf γY |[C(cid:2)]{α}(G K ) = γY |[C]{α}dr(K , α|C(cid:2)) = 0 = dr(K , α|C).So, the inequality (7.5) holds for any two soft constraints C and C(cid:2)such that C ⊆ C(cid:2). (cid:2)As a natural generalization of measures for the hard and soft constraints, the measures for the mixed constraint has the following properties.Proposition 7.13. Let K be a knowledge base. Then(1) max{Idr(K |H), Idr(K |C)} ≤ Idr(K |H, C).(2) Idr(K |H, C) ≤ Idr(K |H(cid:2), C(cid:2)) for any two mixed constraints (H, C) and (H(cid:2), C(cid:2)) such that H ⊆ H(cid:2)and C ⊆ C(cid:2).Proof. Let K be a knowledge base and (H, C) and (H(cid:2), C(cid:2)) two mixed constraints for K such that H ⊆ H(cid:2)Suppose that H = (P , Q ) and H(cid:2) = (P(cid:2), Q(cid:2)).and C ⊆ C(cid:2). K. Mu / Artificial Intelligence 259 (2018) 52–9079(1) Let R be a minimal Y |[C]Q -dominating set for G K |H, then R must be a minimal Y[C]-dominating set. So, Idr(K |C) ≤Idr(K |H, C). Also, R must be a minimal Y |Q -dominating set. Then Idr (K |H) ≤ Idr(K |H, C). Therefore,max{Idr(K |H), Idr(K |C)} ≤ Idr(K |H, C).(2) Let R be a minimal Y |[C(cid:2)]Q (cid:2) -dominating set for G K |H(cid:2) , then R must be a minimal Y |[C]Q -dominating set for G K |H. So,Idr(K |H, C) ≤ Idr(K |H(cid:2), C(cid:2)).(cid:2)Proposition 7.14. Let K be a knowledge base and α a formula of K . Then(1) dr(K , α|H, C) ≤ min{dr(K , α|H), dr(K , α|C)}.(2) dr(K , α|H, C) ≥ dr(K , α|H(cid:2), C(cid:2)) for any two mixed constraints (H, C) and (H(cid:2), C(cid:2)) such that H ⊆ H(cid:2)and C ⊆ C(cid:2).Proof. Let K be a knowledge base and (H, C) and (H(cid:2), C(cid:2)) two mixed constraints for K such that H ⊆ H(cid:2)Suppose that H = (P , Q ) and H(cid:2) = (P(cid:2), Q(cid:2)).and C ⊆ C(cid:2). (1) If either dr(K , α|H) = 0 or dr(K , α|C)} = 0, then dr(K , α|H, C) = 0. If dr(K , α|H, C) > 0, suppose that R be a min-imal Y |[C]{α}-dominating set of G K . So, dr(K , α|C) ≥dr(K , α|H, C). Also, R must be a minimal Y |Q ∪{α}-dominating set of G K |H. Then dr(K , α|H) ≥ dr(K , α|H, C). Therefore,Q ∪{α}-dominating set for G K |H, then R must be a minimal Y |[C]dr(K , α|H, C) ≤ min{dr(K , α|H), dr(K , α|C)}.(2) Let α be a formula of K .• If dr(K , α|H(cid:2), C(cid:2)) = 0, then dr(K , α|H, C) ≥ dr(K , α|H(cid:2), C(cid:2)).• If dr(K , α|H(cid:2), C(cid:2)) > 0, then there exists at least one minimal Y |[C(cid:2)]Q (cid:2)∪{α}-dominating set for G K |H(cid:2) , then R must be a minimal Y |[C]Y |[C(cid:2)]dr(K , α|H(cid:2), C(cid:2)).Q (cid:2)∪{α}-dominating set for G K |H(cid:2) . Let R be a minimal Q ∪{α}-dominating set for G K |H. So, dr(K , α|H, C) ≥Therefore,dr(K , α|H, C) ≥ dr(K , α|H(cid:2), C(cid:2)).(cid:2)Lastly, we consider the relation between the base-level and the formula-level inconsistency measures.Proposition 7.15. Let K be an inconsistent knowledge base.• Let H be a hard constraint. ThenIdr(K |H) =1dr(K , α|H)maxα∈K.• Let C be a soft constraint. ThenIdr(K |C) =1dr(K , α|C)maxα∈K.• Let (H, C) be a mixed constraint. ThenIdr(K |H, C) =1dr(K , α|H, C)maxα∈K.Proof. This is a direct consequence of definitions of Idr and dr. (cid:2)This proposition shows that the base-level measure can be derived from the corresponding formula-level measure. This is why we use the subscript dr in the base-level measure.Now we turn to the complexity issue. We assume that the reader is familiar with the basics of complexity, in particular the polynomial hierarchy.It has been shown that computing the degree of responsibility in binary models is F P N P [log n]case, it has been shown that computing the degree of responsibility is F P (cid:7)P2At first, we give the following proposition presented in [3].[log n]-complete [3]. In general -complete in general recursive models [2].80K. Mu / Artificial Intelligence 259 (2018) 52–90Proposition 7.16. Computing the degree of responsibility is F P N P [log n]-complete in binary causal models.Note that all the formula-level measures are based on the MIS-graph, which stems from the set of minimal inconsistent subsets of that base. Once the set of minimal inconsistent subsets of a knowledge base K is given, we can construct a binary causal model MK |H (resp. MK |C , and MK |(H,C)) for K with the constraint H (resp. C, and (H, C)) in polynomial time (with regard to |K | + |MI(K )|), by following the procedure mentioned in Section 6. Then we can get the following corollaries.Corollary 7.4. Computing the degree of responsibility of a formula in a knowledge base with a hard constraint for the inconsistency is F P N P [log n]-complete when the set of minimal inconsistent subsets of the knowledge base is given.Proof. It is a direct consequence of Proposition 7.16. (cid:2)Corollary 7.5. Computing the degree of responsibility of a formula in a knowledge base with a soft constraint for the inconsistency is F P N P [log n]-complete when the set of minimal inconsistent subsets of the knowledge base is given.Proof. It is a direct consequence of Proposition 7.16. (cid:2)Corollary 7.6. Computing the degree of responsibility of a formula in a knowledge base with a mixed constraint for the inconsistency is F P N P [log n]-complete when the set of minimal inconsistent subsets of the knowledge base is given.Proof. It is a direct consequence of Proposition 7.16. (cid:2)Compared to the complexity for computing responsibility of a formula in the case without constraint in [21], the three corollaries imply that introducing the constraints does not make the complexity of computing the formula-level measure harder in the case that the set of minimal inconsistent subsets in given.According to Proposition 7.15, Idr(K |H) (resp. Idr(K |C), and Idr(K |H, C)) can be computed by computing dr(K , α|H)(resp. dr(K , α|C), and dr(K , α|H, C)) for each formula α ∈ K . Recall that there are |K | + |MI(K )| + 3 (resp. |K | + |MI(K )| +|C| + 1, and |K | + |MI(K )| + |C| + 3) endogenous variables in MK |H (resp. MK |C , and MK |(H,C)) for K with the con-straint H (resp. C, and (H, C)). Then Idr(K |H), Idr(K |C), and Idr(K |H, C) can be computed with |K |(cid:26)log(|K | + |MI(K )| + 3)(cid:27), |K |(cid:26)log(|K | + |MI(K )| + |C| + 1)(cid:27), and |K |(cid:26)log(|K | + |MI(K )| + |C| + 3)(cid:27) queries to their own NP oracles, respectively, accord-ing to the three corollaries above. Then computing Idr (K |H), Idr(K |C), and Idr(K |H, C) are also in F P N P once the set of minimal inconsistent subsets is given.On the other hand, the correspondence between minimal correction subsets and minimal Y -dominating sets provides an alternative way to compute the measures when the set of minimal inconsistent subsets is not given. For the three base-level measures, we need to identify the smallest size of minimal correction subsets compatible with their own respective constraints. For the three formula-level measures, we need to identify the smallest size of compatible minimal correction subsets that contain the given formula. However, to the best of our knowledge, the complexity of identifying the smallest size of minimal correction subsets compatible with the given constraint is still open.8. Related workIn this section, we compare our measures for inconsistency with constraints with some closely related work.Measuring inconsistency has been increasingly recognized as one of the most important subprocesses for understanding and handling inconsistency for knowledge bases. Most of the inconsistency measures presented so far do not take into account constraints for resolving inconsistency explicitly. To the best of our knowledge, our approach presented in this paper is the first attempt to measure the inconsistency for knowledge bases in the presence of constraints.The MIS-graph plays a central role in our approaches to measuring inconsistency in the presence of constraints. The MUS-graph presented in [9] is very closely related to the MIS-graph. Roughly speaking, the MUS-graph of a knowledge base is a graph with vertices corresponding to minimal inconsistent subsets of that base such that two vertices are adjacent if and only if the corresponding minimal inconsistent subsets have common formulas. Given a knowledge base K , we use G MU S (K ) to denote the MUS-graph of K , then• V (G MU S (K )) = MI(K ) = Y (G K ), and• (M, M(cid:2)) ∈ E(G MU S (K )) if M ∩ M(cid:2) (cid:22)= ∅.Obviously, M and Mthat the MUS-graph G MU S (K ) can be derived from the MIS-graph G K . Moreover, the distance dMU S (M, Mare Y -adjacent in the MIS-graph G K . This means (cid:2)) between two are adjacent in G MU S (K ) if and only if M and M(cid:2)(cid:2)K. Mu / Artificial Intelligence 259 (2018) 52–9081connected minimal inconsistent subsets M and Mbetween M and M(cid:2)dMU S (M, M(cid:2)in the MIS-graph, i.e.,) = DistG K (M, M(cid:2))2(cid:2)in the MUS-graph defined in [9] can be represented by the distance if M and M(cid:2)are involved in the same component of G K .In addition, the distance dMU S (α, M) between a formula α and a minimal inconsistent subset M is defined as the containing α, i.e., dMU S (α, M) =(cid:2)} [9]. However, the MIS-graph G K allows us to define the distance between α and M directly (i.e., shortest distance in the MUS-graph between M and a minimal inconsistent subset Mmin{dMU S (M, Mthe length of the shortest path from α to M), moreover,(cid:2))|α ∈ M(cid:2)dMU S (α, M) = DistG K (α, M) − 12(cid:2)if α and M are involved in the same component of G K . This implies that the family of distance-based D I M measures presented in [9] can be also derived from the MIS-graph.The equivalence of the adjacency of M and Min the MIS-graph also implies that the MUS-graph and the MIS-graph have the same number of components. Then a special instance of the inconsistency measure of ICC , denoted I 0CC(K ) here, defined as the number of connected components of the MUS-graph [9], can also be given by the MIS-graph G K .in the MUS-graph and the Y -adjacency of M and MCompared the MUS-graph, the MIS-graph provides more information on associations between minimal inconsistent sub-sets. In each component of the MIS-graph of a knowledge base, the sequence of vertices in a path between two minimal inconsistent subsets is an alternating sequence of minimal inconsistent subsets and formulas instead of a sequence of minimal inconsistent subsets. This makes such a path allow us to look inside the association between the two minimal inconsistent subsets to explain how the two minimal inconsistent subsets are associated with each other. This is important to identify the role of each formula in causing the inconsistency in that base, especially in the case with constraints.(cid:2)This also implies that the MUS-graph is not a suitable framework for incorporating constraints on modifying inconsis-tency in representation of inconsistency. Then it is not easy to extend the D I M measures built upon the MUS-graph in [9]to the case with constraints directly.However, given an inconsistent knowledge base K , the MIS-graph G K provides a picture for the set of minimal incon-sistent subsets of that base from multiple perspectives. Besides the number of minimal inconsistent subsets (|Y (G K )|) and the set of formulas involved in the minimal inconsistent subsets (| X(G K )|), each subgraph of the MIS-graph induced by a minimal inconsistent subset and its neighboring formulas describes the inner structure of that minimal inconsistent subset, while each subgraph induced by a formula and its neighboring minimal inconsistent subsets describes all the membership of that formula in minimal inconsistent subsets. Then the inconsistency measures based on minimal inconsistent subsets (MIS-based inconsistency measures for short) can be expressed alternatively in terms of the MIS-graph. For example, con-sider the following representative MIS-based inconsistency measures proposed in [7,8]:• MI inconsistency measure (Base-level): I M I (K ) = |MI(K )|.• MinInc inconsistency values (Formula-level):(cid:4)(cid:2)– ∀α ∈ K , M I V D (K , α) =– ∀α ∈ K , M I V (cid:8)(K , α) = |{M ∈ MI(K )|α ∈ M}|.– ∀α ∈ K , M I V C (K , α) =1|M| .if α ∈1,0, otherwise.(cid:14)MI(K ),M∈MI(K ) s.t. α∈MEvidently, these inconsistency measures can be given alternatively as follows:• I M I (K ) = |Y (G K )|.• ∀α ∈ K , M I V D (K , α) =(cid:4)(cid:4)• ∀α ∈ K , M I V (cid:8)(K , α) =• ∀α ∈ K , M I V C (K , α)(cid:5)(cid:14)if α ∈ X(G K ),1,0, otherwise.degG K (α),0,if α ∈ X(G K ),otherwise.=M∈Y (G K ) s.t. (α,M)∈E(G K )0,1degG K (M) , if α ∈ X(G K ),otherwise.More importantly, each minimal Y -dominating set of the MIS-graph G K is exactly a minimal correction subset of K . This correspondence between minimal correction subsets and minimal Y -dominating sets provides a good starting point to incorporate constraints on modifying formulas in measuring inconsistency. Intuitively, the inconsistency in a knowledge 82K. Mu / Artificial Intelligence 259 (2018) 52–90base counterfactually depends on each minimal correction subset from the point of view of causality. Then the minimal correction subsets compatible to a given hard (or soft) constraint are of interest in explaining and measuring the inconsis-tency for a knowledge base with constraints from the context of causality. On the other hand, this correspondence allows us to understand intuitively and concisely the role of each formula in a minimal correction subset in breaking minimal inconsistent subsets by via of minimal Y -dominating set in the MIS-graph in the presence of constraints. This can help us better understand the formula-level inconsistency measure from the context of causality as well as from the perspective of syntax-based inconsistency handling.Our base-level inconsistency measure Idr (K |H) (resp. Idr(K |C), and Idr(K |H, C)) is exactly the minimum size of minimal correction subsets of K that are compatible with the hard constraint H (resp. soft constraint C, and mixed constraint (H, C)). From the point of view of causality, each kind of the base-level measures grasps the smallest sets of formulas which the inconsistency counterfactually depends on in the presence of the corresponding constraint, because the inconsistency in K would not have happened if each of formulas in such a set had not belonged to K . On the other hand, if we consider the size of each minimal correction subset compatible with the corresponding constraint as an evaluation of effort to restoring the consistency by removing the subset, then the base-level measure grasps the minimum cost of restoring the consistency by removing the formulas in the presence of the constraint. This means that the base-level inconsistency measure can also be explained from the point of view that an evaluation of inconsistency in a base should take into account the cost of actions needed to render the base consistent [13].Along this line, the minimum cost of restoring consistency by removing the formulas is not greater than the number of minimal inconsistent subsets, but not less than the number of clusters of minimal inconsistent subsets (according to Proposition 7.3), then it is not surprising thatCC(K ) ≤ Idr(K ) ≤ Idr(K |H), Idr(K |C), Idr(K |H, C) ≤ I M I (K )I 0holds for any knowledge base K and any constraints H and C compatible with K .To the best of our knowledge, there is no property designed for inconsistency measures in the presence of constraint. However, in last section we proposed several properties to characterize how the measures change as the constraints change. For example, we have shown that all the base-level inconsistency measures Idr(K |H), Idr(K |C), and Idr(K |H, C) are mono-tonic w.r.t. constraint and bounded, especially, Idr (K ) is the common lower bound of the measures under constraints. These properties signify that the base-level measures grasp the intuition that the cost of restoring consistency cannot decrease when constraints on modifying formulas are considered. We also characterized the invariant property of measures under some special constraints.If there is no constraint, all of the measures under constraints Idr (K |H), Idr(K |C), and Idr(K |H, C) are reduced to Idr(K ). In contrast to the case with constraints, several properties have been presented to characterize inconsistency measures for knowledge bases without constraints. For example, Hunter and Konieczny have presented the properties of Consistency, MinInc, Free Formula Independence, Monotony and Dominance in [6,8]. Let I be a nonnegative base-level inconsistency measure and K a knowledge base, then• Consistency: I(K ) = 0 if and only if K is consistent.• MinInc: I(K ) = 1 if K is a minimal inconsistent knowledge base.• Free Formula Independence: I(K ) = I(K \ {α}) if α is a free formula of K .(cid:2)) if K ⊆ K• Monotony: I(K ) ≤ I(K.• Dominance: if α (cid:2) ⊥ and α (cid:6) β, then I(K ∪ {α}) ≥ I(K(cid:2) ∪ {β}).(cid:2)The following proposition shows that Idr satisfies Hunter and Konieczny’s properties.Proposition 8.1. Idr satisfies the properties of Consistency, MinInc, Free Formula Independence, Monotony and Dominance.Proof. The satisfaction of Consistency, MinInc and Free Formula Independence is obvious since Idr is built upon the MIS-graph. We only need to provide proofs for Monotony and Dominance, respectively.• Monotony. Let K and K(cid:2)be two knowledge bases such that K ⊆ K(cid:2)and R(cid:2)a minimal correction subset of K(cid:2).(cid:2)(cid:2) ⊆ K , then R– if R– else RSo, there exists at least one minimal correction subset R such that R ⊆ R(cid:2) ∩ K is a correction subset of K .is also a correction subset of K .(cid:2). Therefore, Idr(K ) ≤ Idr(K(cid:2)).• Dominance. Let K be a knowledge base and α and β two formulas. Suppose that α (cid:2) ⊥ and α (cid:6) β, then ∀M ∈ MI(K ∪(cid:2) ∪ {α} ∈ MI(K ∪ {α}). So, for a minimal correction subset R of K ∪ {α},(cid:2) ⊆ (M \ {β}) s.t. M{β}), if β ∈ M, then ∃M– if α /∈ R, then R is a correction subset of K ∪ {β} (not necessarily minimal).– else (R ∪ {β}) \ {α} is a correction subset of K ∪ {β}.Therefore, I(K ∪ {α}) ≥ I(K(cid:2) ∪ {β}). (cid:2)P. Besnard argued against the last three properties, and then presented a more general system of postulates that consists of Consistency (also termed Consistency Null) and Subsumption Orientation [1]:K. Mu / Artificial Intelligence 259 (2018) 52–9083• Subsumption Orientation: If C(σ K ) ⊆ C(K(cid:2)) for some substitution σ then I(K ) ≤ I(K(cid:2)), where C(σ K ) is the set of primi-tive conflicts of σ K .Allowing for that our inconsistency measurements are built upon the minimal inconsistent subsets, here we consider a sim-plified case that the primitive conflicts C(K ) is exactly the set of minimal inconsistent subsets, i.e., C(K ) = MI(K ). However, if the substitutivity is ignored, then it has been shown that Subsumption Orientation is equivalent with Free Formula Indepen-dence and Monotony when primitive conflicts are essentially minimal inconsistent subsets [1]. Then in this sense, Idr also satisfies the postulate of Subsumption Orientation without substitutivity.More generally, we have the following result:Proposition 8.2. Idr satisfies Subsumption Orientation.Proof. Let K and Kformula of σ K arising from α ∈ K under substitution σ .be two knowledge bases and σ a substitution such that MI(σ K ) ⊆ MI(K(cid:2)(cid:2)). We use σ α to denote the (cid:2)) implies that for any minimal correction subset R of K(cid:2), R ∩ σ K must be a correction subset Note that MI(σ K ) ⊆ MI(K(cid:2)).of σ K , so, Idr(σ K ) ≤ Idr(KOn the other hand, suppose that σ R = {σ α1, σ α2, . . . , σ αn} is a minimal correction subset of σ K , then ∀M ∈ MI(K ), {αi|σ αi ∈ σ M ∩ σ R} is a correction subset of K . Then Idr (K ) ≤ Idr(σ K ). There-σ M (cid:6) ⊥ and σ M ∩ σ R (cid:22)= ∅. So, R(cid:2) =(cid:2)fore, Idr(K ) ≤ Idr(K(cid:2)). (cid:2)M∈MI(K )This proposition implies that Idr also satisfies all the postulates entailed by Subsumption Orientation introduced in [1].Recall that Corollary 7.2 states that the measure Idr (K ) is exactly the sum of the measures of MIS-components of K . (cid:2))) = ∅, then if MI(K ∪(cid:2)). This implies that Idr also satisfies the following property of Following this corollary, for two inconsistent knowledge bases K and K(cid:2)) = Idr(K ) + Idr(KKInd-decomposability for describing the additivity of inconsistency measures presented in [11,9]:(cid:2)), then Idr(K ∪ K(cid:2)) = MI(K ) ∪ MI(KMI(K )) ∩ (, if (MI(K(cid:2)(cid:2)(cid:2)• Ind-decomposability2: I(K1 ∪ · · · ∪ Kn) =(cid:2)(cid:2)i=1 I(K i) if MI(K1 ∪ · · · ∪ Kn) = MI(K1) union over sets, and (MI(K i)) ∩ (MI(K j)) = ∅ for 1 ≤ i (cid:22)= j ≤ n.(cid:14)n(cid:15)(cid:15)· · ·MI(Kn), where (cid:15)is the multi-set On the other hand, it is interesting to extend such properties to characterize inconsistency measures with constraints. However, the constraint introduced in this paper is specific to minimal inconsistent subsets of a given knowledge base. This implies that a given constraint may be less meaningful when the set of minimal inconsistent subsets is changed. In this sense, none of the properties of Monotony, Dominance, and Subsumption Orientation is considered as appropriate one to be extended. Here we adapt the properties of Consistency, MinInc, Free Formula Independence, and Ind-decomposability to characterize inconsistency measures with constraints, respectively:• Consistency*: I(K |H, C) = 0 if and only if K is consistent.• MinInc*: I(K |H, C) = 1 if K is a minimal inconsistent knowledge base.• Free Formula Independence*: I(K |H, C) = I(K \ {α}|H, C) if α is a free formula of K .• Constraint Decomposability: I(K1 ∪ K2|H1 ∪ H2, C1 ∪ C2) = I(K1|H1, C1) + I(K2|H2, C2) if MI(K1 ∪ K2) = MI(K1) ∪ MI(K2), and (MI(K1)) ∩ (MI(K2)) = ∅, where H1 ∪ H2 = (P 1 ∪ P 2, Q 1 ∪ Q 2) for H1 = (P 1, Q 1) and H2 = (P 2, Q 2).(cid:2)(cid:2)The following proposition shows that the inconsistency measure Idr with constraints satisfies these adaptations.Proposition 8.3. Idr satisfies the properties of Consistency*, MinInc*, Free Formula Independence*, and Constraint Decompos-ability.Proof. Let K be a knowledge base with a mixed constraint (H, C).• Consistency*. Sufficiency. If K is consistent, then H = (∅, ∅) and C = ∅. So, Idr(K |H, C) = Idr(K ) = 0.Necessity. If Idr(K |H, C) = 0, then K is consistent. Otherwise,Idr(K |H, C) ≥ Idr(K ) > 0.This contradicts Idr (K |H, C) = 0.singleton set. So, Idr(K |H, C) = 1.• MinInc*: If K is a minimal inconsistent knowledge base, then any compatible minimal correction subset of K is a 2 Note that (cid:2)MI(K ) is denoted by the notation unf ree(K ) in [11,9].84K. Mu / Artificial Intelligence 259 (2018) 52–90Fig. 10. G K ∪{a,b} and G K ∪{a∧b}.• Free Formula Independence*. If α is a free formula of K , then MI(K ) = MI(K \ {α}). Then K and K \ {α} have the same MIS-graph. So, Idr(K |H, C) = Idr(K \ {α}|H, C).Let K i be a knowledge base with a mixed constraint (Hi , Ci) for i = 1, 2.• Constraint Decomposability. Let R i be a compatible minimal correction subset of K i with (Hi, Ci) for i = 1, 2. If MI(K1 ∪K2) = MI(K1) ∪ MI(K2), and (MI(K2)) = ∅, then R1 ∩ R2 = ∅ and R1 ∪ R2 is a compatible minimal correction subset of K1 ∪ K2 compatible with (H1 ∪ H2, C1 ∪ C2). On other hand, if R is a compatible minimal correction subset of K1 ∪ K2 compatible with (H1 ∪ H2, C1 ∪ C2), then R ∩ K i is a compatible minimal correction subset of K i with (Hi, Ci) for i = 1, 2. Therefore,MI(K1)) ∩ ((cid:2)(cid:2)Idr(K1 ∪ K2|H1 ∪ H2, C1 ∪ C2) = Idr(K1|H1, C1) + Idr(K2|H2, C2).(cid:2)In addition, the expressivity of inconsistency measures has been proposed as an auxiliary criterion to evaluate an incon-sistency measure [32]. Roughly speaking, the expressivity of a given measure depends on the number of values the measure assigns to some knowledge bases. However, Idr is not less expressive than any inconsistency measure at least when we con-sider both the set of all the knowledge bases that are built upon at most n propositional atoms and the set of all knowledge bases that contain only formulas that are built upon at most n different propositional atoms each. To illustrate this, consider Idr(K i) = ∞. This implies that the number of values Idr assigns to K i = {a ∧ ¬a, · · · , ∧isuch knowledge bases is infinite.j=1a ∧ ¬a}, then Idr(K i) = i and limi→∞We must point that the minimal inconsistent subsets are syntax sensitive. Then replacing a subset of a knowledge base with a logically equivalent set of formulas may bring significant changes in the set of minimal inconsistent subsets of that base. To illustrate this, consider K = {¬a, ¬b}, then MI(K ∪ {a, b}) = {M1, M2} and MI(K ∪ {a ∧ b}) = {M3, M4}, whereM1 = {a, ¬a}, M2 = {b, ¬b}, M3 = {¬a, a ∧ b}, and M4 = {¬b, a ∧ b}.Moreover, as illustrated by Fig. 10, the MIS-graph of K ∪ {a, b} has two components, while the MIS-graph of K ∪ {a ∧ b}has only one component. So, their MIS-graphs have different structures, and they cannot be MIS-equivalent to each other. Actually, it is intuitive that 1 = Idr(K ∪ {a ∧ b}) < Idr(K ∪ {a, b}) = 2 holds, because we only need to remove a ∧ b to break M3 and M4 together, but we cannot break M1 and M2 together if only one formula is allowed to be removed.With respect to the base-level measures for knowledge bases without a constraint, I M I is one of the typical MIS-based inconsistency measures. It does not consider the interconnected structure of the set of minimal inconsistent subsets explic-itly. In contrast, the measures ICC [9,10], IW [11] and Ic f [11] presented by Jabbour et al. argued that taking into account the interconnection between minimal inconsistent subsets instead of just the number of minimal inconsistent subsets is more interesting to characterize the inconsistency in a knowledge base.All the three measures characterize the interconnection or correlation of minimal inconsistent subsets based on split-ting minimal inconsistent subsets into clusters by removing some formulas such that each cluster has only one minimal inconsistent subset. Also, we use p to denote the union of all the clusters (i.e., the set of remaining minimal incon-sistent subsets) obtained by such a split. Just for simplicity of discussion, we call p a split of minimal inconsistent subsets. For example, consider K0 = {a, ¬a, a → ¬b, b, ¬b}, then there is only one cluster of minimal inconsistent sub-sets {M1 = {a, ¬a}, M2 = {a, a → ¬b, b}, M3 = {b, ¬b}}. But if we remove the formula a → ¬b, then the remaining minimal inconsistent subsets can be split into two clusters {M1} and {M3}. Then {M1, M3} is a split of minimal inconsistent subsets.Given a knowledge base K , the measure ICC(K ) is the maximum number of clusters that remaining minimal incon-sistent subsets can be splitted into by removing some formulas from K , i.e., the maximum cardinality of all splits of minimal inconsistent subsets. Both the measures IW and Ic f considers the combination of some splits that can cover all the minimal inconsistent subsets. They call a set {p1, p2, · · · , pn} with |p1| ≥ |p2| · · · ≥ |pn| of splits a c-partition of K1≤i≤n pi . Moreover, they associate a c-partition {p1, p2, · · · , pn} with a numerical vector (|p1|, |p2|, · · · , |pn|). if MI(K ) =Then IW (K ) is defined as the maximum value of W({p1, p2, · · · , pn}) =i=1 w i|pi| under a decreasing positive weight se-} is a , where {p| +quence with w 1 = 1 for all c-partitions of K , while Ic f (K ) is defined as |p(cid:14)n(cid:15)1∗1, p∗2, · · · , p∗n∗111+|p∗2|+1+11. . .+ 1|p∗n|K. Mu / Artificial Intelligence 259 (2018) 52–9085maximal c-partition of K w.r.t. the lexicographic ordering relation over associated vectors for all c-partitions of K [11]. It has been shown that all the three measures are standard measures (i.e., the measures satisfying the properties of Consistency, Monotony, Free Formula Independence, MinInc, and Ind-decomposability) [9,11].However, our measure Idr is different from the three measures in their explanations as well as their characterizations for interconnections between minimal inconsistent subsets. We represent each cluster of minimal inconsistent subsets by a component of the MIS-graph, which allows us to look inside how these minimal inconsistent subsets are interconnected one another. Then we use the minimal Y -dominating set of each component of the MIS-graph to characterize the inter-connected structure of the corresponding cluster. Actually, the correspondence between minimal Y -dominating sets and minimal correction subsets makes such a characterization can be well explained from both the perspectives of syntax-based inconsistency resolving and causality. Moreover, as shown earlier, Idr satisfies the properties of Consistency, Monotony, Free Formula Independence, MinInc, and Ind-decomposability. Then it is also a standard measure. In addition, Idr also sat-isfies the property of Dominance. But the three measures do not satisfy the property of Dominance. To illustrate this, (cid:2)0 cannot be split into two clusters. So, consider K(cid:2)0) < ICC(K0), Ic f (KICC(K= (K0 \ {a}) ∪ {a ∧ (a → ¬b)}. Then the minimal inconsistent subsets of K(cid:2)0) < IW (K0) with w 1 > w 3.Our formula-level measure dr(K , α|H) (resp. dr(K , α|C), and dr(K , α|H, C)) is defined as 0 if none of minimal correction subsets compatible with the constraint H (resp. C, and (H, C)) contain α. Otherwise, dr(K , α|H) (resp. dr(K , α|C), and dr(K , α|H, C)) is defined as the reciprocal of the minimum size of minimal correction subsets compatible with H (resp. C, and (H, C)) that contain α.(cid:2)0) < Ic f (K0), and IW (K(cid:2)0From the point of view of Halpern and Pearl’s causal model [5], the other formulas of a compatible minimal correction subset containing α with the constraint H (resp. C, and (H, C)) compose a contingency where the inconsistency in K coun-terfactually depends on α in the presence of the constraint H (resp. C, and (H, C)). This means that all the three measures grasp the nature of α being a cause under contingency of the inconsistency presented in [5], moreover, each of them takes into account the impact of the corresponding constraint on the counterfactual dependence of the inconsistency in K on αby using the compatibility of minimal correction subsets with the constraint. Hence, all the three measures can be clearly explained in the context of Chockler and Halpern’s responsibility presented in [2]. Moreover, the property of anti-monotony w.r.t. constraints of dr captures the intuition that the degree of responsibility of a formula for the inconsistency cannot increase since more formulas may be involved in such a contingency when we extend the constraint.All the three measures under constraints are reduced to dr(K , α) presented in [21] when their own respective constraints are empty. All the four measures stem from the counterfactual dependence of the inconsistency on an individual formula under some contingency regardless if there are constraints. Then they all assign zero responsibility to free formulas of K . Moreover, adding a free formula to a knowledge base cannot affect the degree of responsibility of each formula for the in-consistency regardless if there are constraints. So, they all satisfy the property of Free Formula Independence for formula-level measure presented in [8]. On the other hand, recall that it holds that dr(K , α|H) ≤ dr(K , α) and dr(K , α|C) ≤ dr(K , α) for MI(K ) in the presence of H and C, respectively. This signifies that dr(K , α|H) (resp. dr(K , α|C)) captures all formulas α ∈the intuition that we may need to remove more formulas together with α to break all the minimal inconsistent subsets in the presence of H (resp. C). However, considering the impact of constraints on evaluating the responsibility of each formulas also brings the following differences between the case with constraints and that without constraints:(cid:2)• At first, it has been shown in [21] that dr(K , α) satisfies the property of Minimality presented in [8], i.e., dr(K , α) = 0if and only if α is a free formula. But neither dr(K , α|H) = 0 nor dr(K , α|C) = 0 implies that α must be a free formula when their own respective constraints are not empty. This signifies that neither dr(K , α|H) nor dr(K , α|C) satisfies the property of Minimality.• Second, when K is a minimal inconsistent knowledge base, it has been shown in [21] that dr(K , α) satisfies the property of Fairness presented in [25], i.e., ∀α, β ∈ K , dr(K , α) = dr(K , β) = 1 if K is a minimal inconsistent knowledge base. But dr(K , α|H) does not satisfy Fairness if H is not empty, since it holds that dr(K , α|H) = 0 for all α ∈ P .As far as the formula-level inconsistency measures are concerned, the Shapley inconsistency value presented by Hunter and Konieczny [6–8] is the first attempt to capture the contribution/responsibility of an individual formula for the in-consistency in a knowledge base, to the best of our knowledge. Given a base-level inconsistency measure, the Shapley inconsistency value of an individual formula of a knowledge base is the part of the base-level measure of that base dis-tributed to the formula by the Shapley value model [31], a well known cooperation game model. To be more precise, given a knowledge base K and a formula α ∈ K , the Shapley inconsistency value of α under the base-level inconsistency measure I , denoted S Iα(K ), is given asα(K ) =S I(cid:10)C⊆K(|C| − 1)!(|K | − |C|)!|K |!(I(C) − I(C \ {α}))86K. Mu / Artificial Intelligence 259 (2018) 52–90in [6–8]. In particular, when I(K ) = I M I (K ), the corresponding Shapley inconsistency value can be defined alternatively as follows [7,8]:α (K ) = M I V C (K , α) =S I M I(cid:10)M∈MI(K ) s.t. α∈M1|M|.Essentially, the Shapley inconsistency value S Iα(K ) is a weighted accumulation of I(C) − I(C \ {α}) for all C ⊆ K s.t. α ∈ C . It can be explained as the marginal utility of α in a coalitional game consisting of all the formulas of K when the collective payoff of each coalition C ⊆ K is given by I(C). The behavior of the Shapley inconsistency value S Iα(K ) depends on the characteristics of the base-level I . In particular, if the base-level inconsistency measure I used in the Shapley value model satisfies the property of Free Formula Independence, then the corresponding Shapley inconsistency value coincides with the formula-level measure dr in that all the free formulas are assigned to zero regardless if there are constraints. For example, Idrboth S I M Iα (K ) are such Shapley inconsistency values. However, we have compared the Shapley inconsistency value and our formula-level inconsistency measure dr in the case without constraints from the following aspects in [21]:α (K ) and S• Their starting points are different from each other. The Shapley inconsistency value stems from the Shapley value model, and then the inconsistency value of each formula can be explained as the Shapley value in a cooperation game consisting of all the formulas in a knowledge base. In contrast, the inconsistency measure dr is essentially based on the notion of counterfactual dependence under some contingency, and then the inconsistency value of each formula can be interpreted as the degree of responsibility for the inconsistency in causality.• The definition of Shapley inconsistency value depends on a given base-level inconsistency measure, moreover, the sum of the Shapley inconsistency values of all the formulas of a knowledge base is exactly the base-level inconsistency measure for the base. But the identification of dr is independent of any base-level inconsistency measure.• When the inconsistency of a knowledge base is characterized by minimal inconsistent subsets of the base, only the min-α(K ), while all the minimal inconsistent subsets imal inconsistent subsets that contain α are involved in identifying S Iare involved in identifying dr(K , α).Here we are more interested in the case with constraints. Given a knowledge base K with a satisfiable soft constraint C, (cid:2)let R be a minimal correction subset compatible with C, then R ∩ K(cid:2) ⊆ K . Then compatible with the restriction of C to Kwe may incorporate our base-level measure Idr in the Shapley inconsistency value to define a formula-level inconsistency measure in the presence of the soft constraint C. That is, we can define a Shapley inconsistency value with constraint C, denoted Sis a (not necessarily minimal) correction subset of K(cid:2)|C) is well defined for any K(cid:2) ⊆ K . This implies that Idr (Kfor all K(cid:2)(cid:2)Idrα (K |C), as follows:(cid:10)Idrα (K |C) =SC⊆K(|C| − 1)!(|K | − |C|)!|K |!(Idr(C|C) − Idr(C \ {α}|C)).This formula-level measure can be explained as the marginal utility of α in a coalitional game consisting of all the formulas of K when the collective payoff of each coalition C ⊆ K in the presence of the constraint C is given by the measure Idr(C|C). Idrα (K |C) is exactly the part of Idr(K |C) distributed to α by using the Shapley value As a special Shapley inconsistency value, Smodel. So,(cid:10)Idrα (K |C) = Idr(K |C).Sα∈KRecall that Idr(K |C) =from dr(K , α|C) in the starting point as well as the relationship to the base-level Idr (K |C).dr(K ,α|C) for an inconsistent knowledge base K with the constraint C. Then Smaxα∈K1Idrα (K |C) is different On the other hand, given a knowledge base K with a valid hard constraint H, the restriction of H to a subset C of K is not necessarily valid r.w.t. C . To illustrate this, consider K = {a, ¬a, a ∧ b, ¬b} and H = (P , Q ), where P = {¬b} and Q = {¬a, a ∧ b}). Evidently, H is valid w.r.t. K , but (P ∩ C, Q ∩ C) is not valid w.r.t. C = {a, ¬a, a ∧ b}. Then Idr(C|H)seems meaningless for some C ⊆ K . This implies that we cannot incorporate the base-level measure Idrin the Shapley inconsistency value for K directly in the presence of a hard constraint H.When there is no constraint, the drastic measure M I V D is too simple as compared with either M I V C or M I V (cid:8) to distinguish any two formulas involved in the inconsistency. However, the common ground of M I V C (K , α) and M I V (cid:8)(K , α)is that the formula-level inconsistency measure for α depends on the minimal inconsistent subsets containing α instead of all the minimal inconsistent subsets. This means that the counterfactual dependence of an individual minimal inconsistent subset on α underlies the two measures. It makes a distinction between the two measures and our measure dr(K , α|∅) from the perspective of causality, because dr(K , α|∅) stems from the counterfactual dependence of the set of minimal inconsistent subsets on α under some contingency. Moreover, we may extend the two measures M I V C or M I V (cid:8) along this line to the case with a hard or soft constraint by using the minimal inconsistent subsets that counterfactually depend on α in the presence of the constraint in their own respective definitions.K. Mu / Artificial Intelligence 259 (2018) 52–9087In addition, the measure IPm presented in [12] aims to capture the contribution made by the formula to the inconsistency in that base based on minimal proofs. Roughly speaking, given a knowledge base K and a formula α ∈ K , IPm (α) sums up the times of the formula α involved in both minimal proofs of x and that of ¬x for any variable x occurring in formulas of K . However, as argued in [21], for some inconsistent knowledge base, none of formulas of that base K bears responsibility for the inconsistency under the formula-level measure. Such a result is undesired in analyzing inconsistency in a knowledge base.The satisfaction of constraints is one of the obligatory postulates for characterizing scenarios under constraints such as belief merging under integrity constraints [14,15]. Then we focus on measuring the inconsistency in the presence of a valid hard or satisfiable soft constraint in this paper. However, given an inconsistent knowledge base, if the hard constraint H(resp. the soft constraint C, and the mixed constraint (H, C)) is not valid (resp. satisfiable), then we cannot find a mini-mal correction subset compatible with the constraint. So, we may consider +∞ as the designated value for the base-level measure Idr(K |H) (resp. Idr(K |C), and Idr(K |H, C)) for invalid hard constraint (resp. unsatisfiable soft constraint, and un-satisfiable mixed constraint). Correspondingly, we may use −1 as the designed value of the formula-level measure for all formulas involved in the minimal inconsistent subsets.With regard to the inconsistency handling, incorporating constraints on resolving inconsistency in measuring incon-sistency can facilitate the application of techniques for measuring inconsistency in practical inconsistency resolving. For example, our measures can be used to extend the measure-driven logical framework for managing non-canonical require-ments presented in [22] so as to allow some useful clues for resolving inconsistency to be considered in decision making.On the other hand, besides removing formulas, there are some other actions such as weakening formulas and splitting formulas [4] in order to restore the consistency in a knowledge base. It will be interesting to generalize our approach to constraints on such actions for restoring consistency.Lastly, our measures are given in terms of minimal correction subsets and minimal inconsistent subsets of a knowledge base. This implies that these measures can be generalized from the propositional logic to some more complex logics in which the notions of minimal correction subset and minimal inconsistent subset are exactly the same as those in proposi-tional logic.9. An application in requirements engineeringIn this section we use a small but explanatory example in requirements engineering to illustrate the application of our approach. We consider a scenario for eliciting requirements for updating an existing software, which is slightly adapted from the example used in [26,28,21].Example 9.1. Consider the following scenario for eliciting requirements for updating an existing software. There are three stakeholders involved in this scenario, including the seller of the new system, the user of the existing system (the user for short), and the domain expert in requirements engineering. Each of the three stakeholders may provide demands from her/his own perspective. When inconsistencies in their demands are identified, developers and the three stakeholders start to negotiate on resolving inconsistencies. Our measures may help developers and the stakeholders make a decision on revising the requirements.• The seller of the new system provides two demands:(a1) The user interface of the system-to-be should be in the modern idiom (i.e., fashionable).(a2) The system-to-be should be open, that is, the system-to-be could be extended easily.• The user of the existing system provides three demands:(b1) The system-to-be should be developed based on the techniques used in the existing system.(b2) The user interface of the system-to-be should maintain the style of the existing system.(b3) The system-to-be should be secure.• The domain expert in requirements engineering provides two demands about security:(c1) To guarantee the security of the system-to-be, openness (or ease of extension) should not be considered.(c2) To improve the security of the system-to-be, the newest development techniques should be adopted.The following predicates are used in [26] to formulate the requirements:• the predicate Fash(int_f) is used to denote that the interface is fashionable;• the predicate Open(sys) is used to denote that the system is open;• the predicate New(sys) is used to denote that the system will be developed based on the newest techniques;• the predicate Secu(sys) is used to denote that the system is secure.Then the requirements above can be represented by a knowledge base(cid:4)K R =Fash(int_f), Open(sys), ¬New(sys), ¬Fash(int_f), Secu(sys),Secu(sys) → New(sys), Secu(sys) → ¬Open(sys)(cid:16).88K. Mu / Artificial Intelligence 259 (2018) 52–90For simplicity of discussion, we abbreviate the knowledge base asK R = {a1, a2, b1, b2, b3, c1, c2}.Evidently, K R is inconsistent. Moreover,Idr(K R ) = 2.This implies that we need to change at least two requirements in order to get a consistent requirements set.The degree of responsibility of each requirement for the inconsistency is given as follows:dr(K R , a1) = dr(K R , b2) = dr(K R , b3) = 12dr(K R , a2) = dr(K R , b1) = dr(K R , c1) = dr(K R , c2) = 13Note that K R has 10 minimal correction subsets. Allowing for the practical costs for abandoning requirements, developers are more interested in suggesting the stakeholders to change the requirements with the highest degree of responsibility. That is, developers are interested in either {a1, b3} or {b2, b3} at the beginning of negotiation with stakeholders.,.Suppose that after the first round of negotiation, they reach an agreement to resolve the inconsistency as follows:(A1) b3 should be protected from being changed on the condition that b2 must be abandoned.(A2) c1 and c2 are not allowed to be changed together.Here we use H = ({b3}, {b2}) and C = {(c1, c2)} to represent the two constraints (A1) and (A2) on further inconsistency resolving, respectively. ThenIdr(K R |H, C) = 3.This implies that we need to change at least three requirements in order to get a consistent requirements set under the agreement.Now the degree of responsibility of each requirement for the inconsistency with the constraints is given as follows:dr(K R , a1|H, C) = dr(K R , b3|H, C) = 0,dr(K R , b2|H, C) = dr(K R , a2|H, C) = 13dr(K R , b1|H, C) = dr(K R , c1|H, C) = dr(K R , c2|H, C) = 13,.Besides b3, a1 is protected from being changed by the constraint. Note that dr(K R , b2|H, C) = 13 . This implies that stakeholders just have to abandon two other requirements with non-zero responsibility together with b2 in order to re-store the consistency of the set of requirements. Then in this case, developers are interested in recommending {b1, b2, a2}, {b1, b2, c2}, and {b2, c1, a2} to stakeholders.Suppose that the user of the existing system agrees to abandon requirement b1 after the second round of negotiation, while the seller agrees to withdraw requirement a2. Then requirements {b1, b2, a2} are chosen as the ones to be abandoned. The revised set of requirements is represented by the following knowledge baseK 1R= {a1, b3, c1, c2}.Now the set of requirements is consistent.10. ConclusionA growing number of inconsistency measures have been proposed so far. Most measures satisfy some properties that are considered intuitive and rational within their own contexts. In this sense, such measures have provided some char-acterizations of the inconsistency for a knowledge base from their own perspectives. However, we are more interested in incorporating inconsistency measures in the whole process of inconsistency resolving in many practical applications. To this purpose, establishing a meaningful linkage between inconsistency measures and actions needed to render a knowledge base consistent is more necessary.Causality can be considered as a promising starting point to establish such a linkage. Generally, from the point of view of inconsistency resolving, only formulas causing the inconsistency of a knowledge base should be involved in actions for restoring the consistency of that base. That is, only causes of the inconsistency are of interest when we choose formulas K. Mu / Artificial Intelligence 259 (2018) 52–9089that need to be changed in order to resolve the inconsistency. From the perspective of inconsistency measuring, inconsis-tency measures based on counterfactual dependence (under some contingency) allow us to better understand the nature of inconsistency at both base-level and formula-level from the perspective of causality. Then causality-based explanations of inconsistency measures make them more applicable in the practical application domains. Our previous measures presented in [21] have made the first attempt to introduce the causality in measuring inconsistency.On the other hand, constraints specify some conditions for acceptable actions for restoring the consistency of a knowl-edge base in practical applications. Then a useful linkage between inconsistency measures and inconsistency resolving should take into account the role of constraints in practical inconsistency resolving. We made an attempt to extend causality-based measures to the case with constraints so as to establish more practical linkage between inconsistency measures and inconsistency resolving in this paper. The graph-based approach to measuring the inconsistency for a knowledge base with one or both of the two typical kinds of constraints has been proposed. Given an inconsistent knowledge base with a constraint, the MIS-graph is constructed to represent the set of minimal inconsistent subsets of that base from multiple perspectives. In particular, the one-to-one correspondence between minimal correction subsets and minimal Y -dominating sets of the MIS-graph allows us to incorporate constraints on modifying formulas in such a graph-based characterization of inconsistency in a concise way.Based on this incorporation, then the degree of inconsistency of a knowledge base with the constraint is defined as the minimum cardinality of minimal Y -dominating sets compatible with the constraint, moreover, it is interpreted as the minimum size of sets of formulas which the inconsistency counterfactually depends on in the presence of the constraint from a perspective of causality.At the level of formulas, if a formula is subsumed in a minimal Y -dominating set of the MIS-graph that is compatible with the constraint, then the degree of responsibility of that formula for the inconsistency in the presence of the constraint is defined as the reciprocal of the minimum cardinality of compatible minimal Y -dominating sets with the constraint that contain the formula, otherwise, it is defined as 0. All these measures for inconsistency with constraints can be well explained in the framework of Halpern–Pearl’s causal model and Chockler and Halpern’s notion of responsibility. This causality-based interpretation makes the inconsistency measure more comprehensible and applicable to the practical application domains. Lastly, some interesting logical properties of these inconsistency measures, especially about monotony or antimonotony with regard to constraints, have been also studied.AcknowledgementsThe author is grateful to anonymous reviewers for their valuable comments. This work was partly supported by the National Natural Science Foundation of China under Grant Nos. 61572002 and 61170300.References[1] P. Besnard, Revisiting postulates for inconsistency measures, in: E. Fermé, J. Leite (Eds.), Proceedings of the 14th European Conference – Logics in Artificial Intelligence, JELIA 2014, Funchal, Madeira, Portugal, September 24–26, 2014, in: Lecture Notes in Computer Science, vol. 8761, Springer, 2014, pp. 383–396.[2] H. Chockler, J.Y. Halpern, Responsibility and blame: a structural-model approach, J. Artif. Intell. Res. 22 (2004) 93–115.[3] H. Chockler, J.Y. Halpern, O. Kupferman, What causes a system to satisfy a specification?, ACM Trans. Comput. Log. 9 (3) (2008) 20.[4] J. Grant, A. Hunter, Measuring consistency gain and information loss in stepwise inconsistency resolution, in: W. Liu (Ed.), Proceedings of 11th European Conference on Symbolic and Quantitative Approaches to Reasoning with Uncertainty, Belfast, UK, June 29–July 1, 2011, in: Lecture Notes in Artificial Intelligence, vol. 6717, Springer, 2011, pp. 362–373.[5] J.Y. Halpern, J. Pearl, Causes and explanations: a structural-model approach. Part I: causes, Br. J. Philos. Sci. 56 (4) (2005) 843–887.[6] A. Hunter, S. Konieczny, Shapley inconsistency values, in: P. Doherty, J. Mylopoulos, C. Welty (Eds.), Principles of Knowledge Representation and Reasoning: Proceedings of the 10th International Conference, KR06, AAAI Press, 2006, pp. 249–259.[7] A. Hunter, S. Konieczny, Measuring inconsistency through minimal inconsistent sets, in: G. Brewka, J. Lang (Eds.), Principles of Knowledge Representa-tion and Reasoning: Proceedings of the Eleventh International Conference, KR08, AAAI Press, 2008, pp. 358–366.[8] A. Hunter, S. Konieczny, On the measure of conflicts: Shapley inconsistency values, Artif. Intell. 174 (14) (2010) 1007–1026.[9] S. Jabbour, Y. Ma, B. Raddaoui, Inconsistency measurement thanks to mus decomposition, in: A.L.C. Bazzan, M.N. Huhns, A. Lomuscio, P. Scerri (Eds.), International Conference on Autonomous Agents and Multi-Agent Systems, AAMAS ’14, Paris, France, May 5–9, 2014, IFAAMAS/ACM, 2014, pp. 877–884.[10] S. Jabbour, Y. Ma, B. Raddaoui, L. Sais, Y. Salhi, On structure-based inconsistency measures and their computations via closed set packing, in: G. Weiss, P. Yolum, R.H. Bordini, E. Elkind (Eds.), Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems, AAMAS 2015, Istanbul, Turkey, May 4–8, 2015, ACM, 2015, pp. 1749–1750.[11] S. Jabbour, Y. Ma, B. Raddaoui, L. Sais, Y. Salhi, A MIS partition based framework for measuring inconsistency, in: C. Baral, J.P. Delgrande, F. Wolter (Eds.), Principles of Knowledge Representation and Reasoning: Proceedings of the Fifteenth International Conference, KR 2016, Cape Town, South Africa, April 25–29, 2016, AAAI Press, 2016, pp. 84–93.[12] S. Jabbour, B. Raddaoui, Measuring inconsistency through minimal proofs, in: L.C. van der Gaag (Ed.), Proceedings of the 12th European Conference – Symbolic and Quantitative Approaches to Reasoning with Uncertainty, ECSQARU 2013, Utrecht, The Netherlands, July 8–10, 2013, in: Lecture Notes in Computer Science, vol. 7958, Springer, 2013, pp. 290–301.[13] S. Konieczny, J. Lang, P. Marquis, Quantifying information and contradiction in propositional logic through epistemic actions, in: G. Gottlob, T. Walsh (Eds.), Proceedings of the 18th International Joint Conference on Artificial Intelligence, IJCAI2003, Morgan Kaufmann, 2003, pp. 106–111.[14] S. Konieczny, R.P. Pérez, Merging with integrity constraints, in: A. Hunter, S. Parsons (Eds.), Proceedings of the European Conference, Symbolic and Quantitative Approaches to Reasoning and Uncertainty, ECSQARU’99, London, UK, July 5–9, 1999, in: Lecture Notes in Computer Science, vol. 1638, Springer, 1999, pp. 233–244.[15] S. Konieczny, R.P. Pérez, Merging information under constraints: a logical framework, J. Log. Comput. 12 (5) (2002) 773–808.[16] M. Krzywkowski, Y.B. Venkatakrishnan, Bipartite theory of graphs: outer-independent domination, Nat. Acad. Sci. Lett. 38 (2) (2015) 169–172.90K. Mu / Artificial Intelligence 259 (2018) 52–90(2011) 281–322.55 (8) (2014) 1659–1693.54 (1) (2013) 109–131.[17] M.H. Liffiton, K.A. Sakallah, Algorithms for computing minimal unsatisfiable subsets of constraints, J. Autom. Reason. 40 (1) (2008) 1–33.[18] K. McAreavey, W. Liu, P. Miller, K. Mu, Measuring inconsistency in a network intrusion detection rule set based on snort, Int. J. Semant. Comput. 5 (3) [19] K. McAreavey, W. Liu, P.C. Miller, Computational approaches to finding and measuring inconsistency in arbitrary knowledge bases, Int. J. Approx. Reason. [20] A. Meliou, W. Gatterbauer, J.Y. Halpern, C. Koch, K.F. Moore, D. Suciu, Causality in databases, IEEE Data Eng. Bull. 33 (3) (2010) 59–67.[21] K. Mu, Responsibility for inconsistency, Int. J. Approx. Reason. 61 (2015) 43–60.[22] K. Mu, J. Hong, Z. Jin, W. Liu, From inconsistency handling to non-canonical requirements management: a logical perspective, Int. J. Approx. Reason. [23] K. Mu, Z. Jin, W. Liu, D. Zowghi, B. Wei, Measuring the significance of inconsistency in the viewpoints framework, Sci. Comput. Program. 78 (9) (2013) 1572–1599.[24] K. Mu, W. Liu, Z. Jin, A general framework for measuring inconsistency through minimal inconsistent sets, Knowledge Inf. Syst.: Int. J. 27 (1) (2011) 85–114.[25] K. Mu, W. Liu, Z. Jin, Measuring the blame of each formula for inconsistent prioritized knowledge bases, J. Log. Comput. 22 (3) (2012) 481–516.[26] K. Mu, W. Liu, Z. Jin, D. Bell, A syntax-based approach to measuring the degree of inconsistency for belief bases, Int. J. Approx. Reason. 52 (7) (2011) [27] K. Mu, W. Liu, Z. Jin, J. Hong, D. Bell, Managing software requirements changes based on negotiation-style revision, J. Comput. Sci. Technol. 26 (5) 978–999.(2011) 890–907.[28] K. Mu, K. Wang, L. Wen, Approaches to measuring inconsistency for stratified knowledge bases, Int. J. Approx. Reason. 55 (2) (2014) 529–556.[29] D.P. Muiño, Measuring and repairing inconsistency in probabilistic knowledge bases, Int. J. Approx. Reason. 52 (6) (2011) 828–840.[30] R. Reiter, A theory of diagnosis from first principles, Artif. Intell. 32 (1) (1987) 57–95.[31] L. Shapley, A value for n-person games, in: H.W. Kuhn, A.W. Tucker (Eds.), Contributions to the Theory of Games, in: Annals of Mathematical Studies, vol. 28, Princeton University Press, 1953, pp. 307–317.[32] M. Thimm, On the expressivity of inconsistency measures, Artif. Intell. 234 (2016) 120–151.