Artificial Intelligence 171 (2007) 754–775www.elsevier.com/locate/artintAn application of formal argumentation:Fusing Bayesian networks in multi-agent systemsSøren Holbech Nielsen a,∗, Simon Parsons ba Department of Computer Science, Aalborg University, Aalborg, Denmarkb Department of Computer and Information Science, Brooklyn College, City University of New York, Brooklyn, 11210 NY, USAReceived 19 October 2006; received in revised form 28 March 2007; accepted 16 April 2007Available online 29 April 2007AbstractWe consider a multi-agent system where each agent is equipped with a Bayesian network, and present an open framework forthe agents to agree on a possible consensus network. The framework builds on formal argumentation, and unlike previous solutionson graphical consensus belief, it is sufficiently general to allow for a wide range of possible agreements to be identified.© 2007 Elsevier B.V. All rights reserved.Keywords: Argument in agent systems; Argumentation frameworks; Application; Bayesian networks1. IntroductionLately research in distributed systems has intensified, spurred by increased availability of sophisticated electronicdevices and cheap networking equipment. Within this field, the crossover area of multi-agent systems (MAS), thatincorporates parts of artificial intelligence research, has been heavily researched, with each device being modeledas an autonomous agent capable of acting on its environment, reflecting on observations of its surroundings andcommunicating with other agents. To implement such reflective capabilities, a model-based agent architecture is oftenemployed, where the agent carries within it a formal model of its surroundings and acts on mathematical inferencesdrawn from this model. Hence, the more accurate the model is the more successful the agent will be in achieving itsobjectives. Therefore it is beneficial for the agent to (i) update its model when observations of the agent’s surroundingindicate that the model is inaccurate, and (ii) communicate with other agents about their models and alter its ownmodel to reflect model aspects common to the models of most other agents.In this text we investigate how Bayesian networks (BNs) can be used as internal models in a multi-agent set-ting, and more specifically how (ii) can be implemented with the help of argumentation theory. Previously the twomethodologies have mainly been studied together with a view to incorporating the efficiency and precision of BNsinto argumentation theory (e.g. [24]), or as an exercise in converting models of one theory into models of the other(e.g. [27] and [30]). Here, we instead try to exploit strong points of both reasoning methods: BNs constitute a com-* Corresponding author.E-mail addresses: soeren.holbech@gmail.com (S.H. Nielsen), parsons@sci.brooklyn.cuny.edu (S. Parsons).0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.04.005S.H. Nielsen, S. Parsons / Artificial Intelligence 171 (2007) 754–775755pact, elegant, and mathematically correct framework for drawing diagnostic or causal inferences from observations tohypothesis variables, even in face of noisy observations, and they can be constructed and altered automatically fromobservation data, and are thus good choices for internal models. Argumentation theory, on the other hand, provides amethodology for transparently extracting a consistent “truth” from a set of conflicting and/or overlapping views, andfurthermore has strong roots in dialectics, which makes distributed agent-oriented implementations natural.Playing along with these strengths, we envision a MAS of cooperating agents, where each agent has a BN as amodel of the domain it is situated in, and aim at providing a framework built on principles of formal argumentationtheory in which the agents, starting from their individual domain models, can end up agreeing on a single networkrepresenting their joint domain knowledge.The task of fusing several BNs into one compromise BN has previously been addressed with an a priori specifiedview to what constitutes a compromise [4,10,14,21,23], with no apparent consensus on the goal of network fusionamong the authors, and has mainly been considered a centralized operation. Matzkevich and Abramson [14] disregardthe strength of independency statements in the input networks, and seek to obtain a graph that contains all arcs fromthe input networks or their reverses. Sagrado and Moral [4] similarly disregard the quantitative parts of the inputnetworks, and gives rules for constructing graphs that imply either all independency statements implied by at leastone of the input BNs, or only those independency statements implied by all input BNs. Richardson and Domingos [23]also disregard the quantitative parts of the input networks, and construct a prior distribution over all graph structuresfrom the input BNs. This prior is then used as basis for a standard greedy search based on a separate database.Finally, Pennock and Wellman [21] derive a series of impossibility results for the general problem of combiningprobability distributions, and Il and Chajewska [10] uses some of the results from [21] to adapt standard greedy searchscore functions to use the input BNs, rather than a database, as their basis. The differing objectives of these papersstems from differences in interpretations of BNs: They are seen as either specifying flow of information, specifyingindependencies between variables, representing expert experience, or summarizing data. In this paper, we do notcommit ourselves to any specific compromise objective. Rather, we establish a general framework in which any kindof compromise can be reached, with the exact nature of this specified by a compromise score function and possiblya heuristic for walking search trees. The advantages of our approach include that a general purpose argumentationengine can be implemented, and reused in contexts with different definitions of compromise; efficient distributedimplementations are natural; in cases where agents almost agree a priori, little information need to be shared amongthe agents; and anytime compromises can be achieved.The text is structured as follows: In Section 2 we briefly cover the methodology that we need. In particular, weneed some concepts of graph theory, the main theory of BNs and their equivalence classes, and finally theory of anargumentation framework. Following this, in Section 3 we specify the problem that we wish to solve more formally,and present the strategy for doing so. The actual results then follow. First, Section 4 describes how we encode BNsin our framework. Then Section 5 presents a formal argumentation system whose preferred extensions correspond toproper BNs, and Section 6 contains the debating guide-lines that must be followed by agents. We end with a discussionof these results in Section 7.2. PreliminariesBefore we proceed with the theory needed for the results later in the paper, we briefly clarify the notation: asa general rule, sets are printed in boldface type (S, pa(V ), . . .), and individual entities are printed in plain letters(A, xi, . . .), except data structures, which are printed in calligraphic letters (G, A, . . .), and general classes, which areprinted in gothic type (C). By convention we use ≡ to mean “is defined to be” or “defined as”, and decline to use {and } when listing singleton sets. The material is necessarily heavy on definitions, and to help the reader refer back,each term is emphasized where it is defined.2.1. GraphsHere we briefly introduce the terms of graph theory and notation that are used in the remainder of the text. Formore elaboration on the concepts introduced, see e.g. [13].A graph is a pair G ≡ (X, E), where X is the finite set of nodes of the graph, and E ⊆ (X × X) \ {(X, X): X ∈ X}is a set of ordered pairs called edges of the graph. For any two nodes X and Y , if both (X, Y ) and (Y, X) is in E we756S.H. Nielsen, S. Parsons / Artificial Intelligence 171 (2007) 754–775Fig. 1. A simple graph.say that there is an undirected link (or just a link) between X and Y and that they are neighbors. If only (X, Y ) is inE, then we say that there is an arc from X to Y , that X is a parent of Y , and that Y is a child of X. The set of parentsof a node X is denoted pa(X). If X is a neighbor, parent, or child of Y , we say that X and Y are adjacent. A tripleof nodes (X, Y, Z) is said to constitute a v-structure, if Y is a child of both X and Z, and X and Z are not adjacent.When depicting a graph we use circles for nodes, lines for links, and arrows for arcs, as shown in Fig. 1. From thefigure it can be seen that pa(C) = G, that C is a neighbor of both B and D, that C has no children, and that (A, B, F )is the only v-structure in the graph.For two nodes X1 and Xk, we say that there is a path from X1 to Xk, if either (X1, Xk) is in E, or there are distinctnodes X2, . . . , Xk−1 different from X1 and Xk, such that (Xi−1, Xi) is in E for all 2 (cid:2) i (cid:2) k. We denote the path(X1, . . . , Xk) and say that its length is k − 1. If, for one of the edges (X, Y ) in a path, (Y, X) is not in E then we saythat the path is directed, if not it is undirected. A path (X, . . . , Y ), where X and Y are the same node, we call a cycle.Given a cycle (X1, . . . , Xk−1, X1) of length k (cid:3) 4, we say that the cycle has a chord if there is a pair of nodes Xiand Xj , where |i − j | (cid:3) 2 and Xi and Xj are not the pair X1 and Xk−1, such that Xi and Xj are adjacent. A cycleof length k (cid:3) 4 with no chord is called chordless. If there is a directed path from a node X to a node Y , then we saythat Y is a descendant of X. The set of descendants of X is denoted by desc(X). If, for any two nodes X and Y ina set Y , either X is the same node as Y , or there is an undirected path from X to Y , and this holds for no other setZ ⊃ Y , then we call Y a chain component. For examples, consider the graph in Fig. 1: There are no cycles in thegraph, desc(A) = {B, C, D, E, F, H }, and {B, C, D, H } is a chain component.Given a graph G ≡ (X, E), we introduce some auxiliary definitions. Let Y ⊆ X, then we say that GY ≡ (Y , E ∩(Y × Y )) is the subgraph induced by Y . If all the edges in G are arcs, we say that G is directed. If all the edges arelinks, we say that G is undirected. A graph, which is neither directed nor undirected, is a partially directed graph. Anundirected graph containing no chordless cycles is called decomposable. A graph with no directed cycles is called achain graph. A directed chain graph is also called an acyclic directed graph, traditionally abbreviated DAG. The graphGu ≡ (X, {(X, Y ): (X, Y ) ∈ E or (Y, X) ∈ E}), obtained by replacing each arc in G with a link, is called the skeletonof G.2.2. Bayesian networksA Bayesian network (BN), over a set of discrete1 domain variables V , is a pair (G, (cid:2)), where G ≡ (V , E) is aDAG, and (cid:2) is a set of conditional probability distributions:(cid:2)P(cid:4)(cid:3)V | pa(V )(cid:2) ≡: V ∈ V(cid:5).In the sequel we assume V to be fixed and implicitly constitute the basis for the nodes of all graphs. For moreinformation on BNs in general, see [11].A BN provides a probabilistic model P of the domain V , such that for any configuration v ≡ (v1, . . . , vn) over V ,P (v) ≡(cid:6)P(cid:2)(cid:3)Vi = vi| pa(Vi) = vpa(Vi )(cid:4),with vpa(Vi ) denoting the entries in the configuration v that corresponds to the variables in the set pa(Vi). For any BN,the limitations on P imposed by the structure of G are summarized as a set of independence constraints:(cid:2)V ⊥⊥ V \(cid:3)desc(V ) ∪ pa(V ) ∪ V(cid:4)| pa(V ): V ∈ V(cid:5),1 “Discrete” meaning that a variable can be in one of only a finite number of states. Other equivalent terms include “cardinal” and “ordinal”.S.H. Nielsen, S. Parsons / Artificial Intelligence 171 (2007) 754–775757where the notation X ⊥⊥ Y | Z, for three disjoint sets of variables X, Y , and Z, means that the variables in X areprobabilistically conditionally independent of those in Y given those in Z, i.e.P (X ∪ Y |Z) = P (X|Z) · P (Y |Z),whenever P (Z) > 0. In other words, the set of probability models that can be associated to some DAG to constitute aBN, all need to obey the independence constraints dictated by the structure [20].Two distinct DAGs may give rise to the same independence constraints as can be seen from the two graphs inFigs. 2(a) and 2(b): They imply the independence statements A ⊥⊥ C | B and C ⊥⊥ A | B, respectively, which by thecommutativity of standard multiplication are the same. We can thus define an equivalence relation over DAGs, suchthat G and H are equivalent iff the independence constraints implied by G are exactly those implied by H. This leadsto an important observation: when only the structure of BNs need to be determined (e.g. in situations where onlyindependencies among parts need consideration) several DAGs can be correct answers. Therefore, identifying a singleDAG, rather than the equivalence class containing it, can be a waste of effort and maybe even impossible, if onlyindependence information is available. Hence, it can be fruitful to consider equivalence classes rather than DAGs.Verma and Pearl [26] showed that any two DAGs imply the same independence constraints if and only if (iff) theycontain the same v-structures and have the same skeleton. Thanks to this result, we can represent the equivalence classof a DAG G as a graph having the same skeleton as G, the same v-structures, and all edges not participating in defininga v-structure being undirected links. Clearly this graph is uniquely determined, and following Verma and Pearl [26]we shall call it the pattern of the equivalence class. As an example, the pattern of the equivalence class of the DAG inFig. 3(a) is shown in Fig. 3(b).Once a pattern has been determined for a DAG all the members of its equivalence class can be constructed byexchanging links for arcs in all possible ways under the constraints that(1) the resulting graphs contains no directed cycles, and(2) no other v-structures than those of the pattern emerge.These two constraints sometimes cause one or more of the arcs replacing links in the pattern to have the sameorientation in the resulting DAGs, no matter in what order or direction other links are converted. For instance, thelink between C and E in the pattern in Fig. 3(b) cannot be exchanged with an arc going from E to C, as that wouldcreate a new v-structure (E, C, F ). Hence, it must be exchanged for an arc from C to E in all DAGs created from thatpattern. The arcs arising from replacing such links, and arcs participating in defining the v-structures in the pattern,we collectively call compelled arcs. The graph that results from replacing links for compelled arcs wherever possibleis called the completed pattern. Notice that by definition this graph must necessarily be unique for each equivalenceclass. The completed pattern of the DAG in Fig. 3(b) is shown in Fig. 4(a).Fig. 2. Two BNs with the same independence properties.Fig. 3. (a) A graph and (b) its pattern.Fig. 4. The completed pattern of the graph in Fig. 3 and a graph with no consistent extension.758S.H. Nielsen, S. Parsons / Artificial Intelligence 171 (2007) 754–775Now, consider the graph in Fig. 4(b). No matter how we try to exchange the links in the graph with arcs we end upeither creating a directed cycle or a v-structure not present in the original graph. Thus, this graph cannot be a patternfor any equivalence class of DAGs nor be a result of extending a pattern while respecting Constraints 1 and 2, and weare therefore dealing with two classes of graphs: Those graphs that can be turned into at least one DAG, by exchanginglinks for arcs while respecting Constraints 1 and 2, we say admit a consistent extension, whereas those that cannotdo not admit a consistent extension (terminology originally introduced by Chickering [3]). We denote the class ofgraphs admitting a consistent extension as C. As a DAG has itself as a consistent extension, it follows that any DAGG ≡ (V , E) is a member of C. Furthermore, the pattern Gp ≡ (V , Ep) of G must necessarily be a member of C, asmust any graph G(cid:10) ≡ (V , E(cid:10)), where E ⊆ E(cid:10) ⊆ Ep, including the completed pattern of G. We shall also distinguishcompleted patterns from other members of C, i.e. Ccp ⊂ C is the class of graphs that are completed patterns of at leastone DAG.Unfortunately, we are unaware of any simple characterization of members of C. That is, potentially trying out allpossible directions of undirected links in the hope of obtaining a consistent extension is not simple, but a computa-tionally intensive procedure calling for a lot of back tracking, and it requires global investigation of the graph ratherthan a series of local investigations. However, Andersson et al. [1] provide the following result on members of Ccp:Theorem 1. A graph G is a member of Ccp iff(1) G is a chain graph,(2) GC is decomposable for all chain components C of G,(3) if X is a parent of Y , and Z is a neighbor of Y , then X and Z are adjacent (i.e. the configuration in Fig. 5(a) doesnot exist as a subgraph of G), and(4) each arc in G is strongly protected (defined below).An arc from a node X to a node Y in a graph G is strongly protected if either• there is a node Z that is a parent of X and not adjacent to Y (see Fig. 5(b)),• there is a node Z that is a parent of Y and not adjacent to X (see Fig. 5(c)),• there is a node Z that is a parent of Y and a child of X (see Fig. 5(d)), or• there are non-adjacent nodes Z and W , such that both Z and W are parents of Y and neighbors to X (seeFig. 5(e)).The bullets of the theorem all have pretty intuitive justifications. In short, items 1, 2, and 3 ensure that all compelledarcs are arcs, whereas item 4 ensures that nothing but compelled arcs are arcs. In particular, item 1 calls for the graphto be a chain graph, which is reasonable, since any graph with a fully directed cycle cannot be extended to a DAG,and any graph with a directed cycle still containing undirected links cannot be extended to a DAG without creating anew v-structure, unless the cycle is of length 3, in which case the arc(s) participating in the cycle cannot be stronglyprotected, and hence would be forbidden by item 4.Item 2 is reasonable, since any graph with a chordless undirected cycle cannot be extended into a DAG withoutcreating a new v-structure.A graph failing to satisfy item 3 cannot be extended into a DAG without creating a new v-structure, unless theundirected link between Y and Z is directed away from Y . But then this arc is compelled, and it should have been anarc if the graph was to be a completed pattern.Fig. 5. Configurations described in Theorem 1.S.H. Nielsen, S. Parsons / Artificial Intelligence 171 (2007) 754–775759As for item 4, consider that for any arc in a completed pattern, it holds by definition that this arc cannot be reversedwithout changing the set of v-structures or introducing a directed cycle. Going through each case of the definition of“strongly protected”, it is easy to see that changing the direction of these arcs does result in a cycle, a new v-structure,or the destruction of a v-structure.Clearly, both items 3 and 4 are easily checked locally, and items 1 and 2 can be checked without any backtracking.Hence, Theorem 1 provides an efficient means for identifying members of Ccp and thus exactly those graphs that areof interest, when only the structure of a BN needs to be identified.2.3. Argumentation systemsArgumentation is a relatively new approach to extracting consistent knowledge from a possibly inconsistent knowl-edge base while possibly respecting some assumptions on the relative epistemological worth of statements in theknowledge base. The approach can be seen as an alternative to formal non-monotonic and defeasible logics. As theresearch area of argumentation systems is still fairly new, no single methodology has yet to stand out as the mainapproach, and a lot of problems are still not solved. However, the argumentation approach shows great potential as ageneral purpose reasoning mechanism, which is why we use it here.Due to the lack of an established framework for analysis of argument systems, it has been necessary to pick onefrom a large pool of these (e.g. [8,12,22,25,29]). The framework we have picked for our purpose is the frameworkof [19], which generalizes that of [7], as this is an abstract framework, which leaves the underlying language andreasoning unspecified.An argumentation system is a pair A ≡ (A, (cid:12)), where A is a set of arguments, and (cid:12) ⊆ (2A \ {∅}) × A is an attackrelation.2 The exact nature of an argument is left unspecified, but examples built on a language akin to propositionallogic could be:• “The sun is shining, so it is not raining”,• “I saw a pigeon yesterday, so it is not raining”, and• “It is not raining”.For two sets of arguments S ⊆ A and S(cid:10) ⊆ S and an argument A, if S(cid:10) (cid:12) A then S is said to attack A, and A is saidto be attacked by S. If no proper subset of S(cid:10) attacks A, then S(cid:10) is called a minimal attack on A. An example of anattack that would intuitively make sense is“The sun is shining”(cid:12)“It is raining”.A semantics of an argumentation framework is a definition of which arguments in the framework that should beaccepted by a rational individual. [7] and [19] work with a wide range of semantics, but we only introduce thosewe need here. First of all, we define a set of arguments S ⊆ A as being conflict-free, if there is no argument A in Ssuch that S attacks A. Intuitively, claiming a conflict-free set of arguments as your beliefs implies that you are notcontradicting yourself. We further define a single argument A as being acceptable with respect to a set of argumentsS, if for each set of arguments T ⊆ A, such that T (cid:12) A, there is an argument B in T , such that S attacks B. In thatcase we also say that S defends A. A conflict-free set S, where all arguments in S are acceptable with respect to S,is called admissible. Thus, claiming an admissible set of arguments as your beliefs means that you can defend yourbeliefs against all possible counter arguments.A very skeptical attitude towards arguments is captured by a semantics called the grounded extension. The groundedextension of an argumentation framework is the least fixpoint of the function F : 2A → 2A, defined asF (S) = {A ∈ A: A is acceptable wrt. S}.Thus the grounded extension consists of all the arguments that have no counter arguments, along with the argumentsthey defend, along with those defended by these arguments, and so on. A less skeptical semantics is that of a preferred2 Traditionally, attack relations have primarily been defined as subsets of A × A. The generalized notion that we use here renders the language,argumentation system, and proofs to follow more elegant, but there are other, more general, reasons for preferring the definition used here. See [19]and [17] for dialectical and computational reasons.760S.H. Nielsen, S. Parsons / Artificial Intelligence 171 (2007) 754–775extension, which is an admissible set that is maximal with respect to set inclusion. Finally, an admissible set S is saidto be a stable extension, if it attacks all arguments in A \ S. Clearly, a stable extension is a preferred extension as well.In general it is hard to compute a preferred extension [5], but Doutre and Mengin [6] present a method that enu-merates preferred extensions for an abstract argumentation system as presented in [7]. Furthermore, Vreeswijk andPrakken [28] and Cayrol et al. [2] present methods for answering whether a specific argument is in at least onepreferred extension, or if it is in all preferred extensions in the special case, where each preferred extension of theargumentation system is a stable one. In [18], we have adapted the technique of [6] to the problem of enumeratingpreferred extensions for argumentation systems, where sets of arguments attack other arguments. We present only theessentials of this technique here, and refer the interested reader to [18] for the details:Given an argumentation system A ≡ (A, (cid:12)), we define an A-candidate as a triple C ≡ (I , O, U ≡ A \ (I ∪ U ))where• I ∩ O = ∅,• every argument that is attacked by I is in O, and• every argument A, for which there exists S ⊆ I and B ∈ I , such that S ∪ A (cid:12) B, is in O.Given an A-candidate C ≡ (I , O, U ) and an argument A ∈ U the triples C − A ≡ (I −A, O−A, U −A ≡ A \ (I −A ∪O−A)) and C + A ≡ (I +A, O+A, U +A ≡ A \ (I +A ∪ O+A)) are given by:I −A ≡ I , O−A ≡ O ∪ A,I +A ≡ I ∪ A,and O+A ≡ O ∪ (cid:3)C+A,where(cid:3)C+A ≡(cid:2)B ∈ U : ∃S ⊆ I , C ∈ Is.t. S ∪ A (cid:12) B ∨ S ∪ B (cid:12) A(cid:5)∨ S ∪ {A, B} (cid:12) C ∨ S ∪ {A, B} (cid:12) A.If A does not participate in a minimal attack on itself (which is the case for all arguments of the argumentation systemwe construct in this paper), then both C − A and C + A are A-candidates themselves, and we can thus constructcandidate trees where each node is an A-candidate: Each A-candidate C has two children C − A and C + A, for somearbitrary chosen A in U , except those candidates where U = ∅, which act as leaves in the tree. A candidate tree havingcandidate C as root, is called a C-tree.It can be proven that if S∗ is a preferred extension of A, then there is a leaf C ≡ (I , O, ∅) of any (∅, ∅, A)-treesuch that I = S∗. Conversely, for any leaf in a (∅, ∅, A)-tree, where I defends itself, I is admissible. It follows that,by constructing an arbitrary (∅, ∅, A)-tree, all preferred extensions can be enumerated.Nielsen and Parsons [18] give a number of pruning rules for candidate trees. These can be used during constructionto cut off branches that cannot contain leaves with preferred extensions.3. Compromising on Bayesian networksThe problem we are addressing arises in a MAS containing a finite number of cooperating agents. We assume anordering over the agents exists, so that we can refer to them by integers. Each agent i has a BN Bi over a commonset of domain variables V , which we assume to be implicit in the remainder of the text. For ease of exposition, wefurthermore assume that an arbitrary but fixed total ordering (cid:2) over the variables is known by all agents a priori.At some point agents 1 to k decide to pool their knowledge, as represented by B1 to Bk, into a new BN B∗, thecompromise BN. Facilitating this task is the problem addressed here. We expect B1 to Bk to be large but somewhatsimilar (as each describe relationships among the same variables), and therefore that having each agent communicateits entire model to each other agent is inefficient.We shall focus solely on the graphical structure of B∗ (although we allow for non-structural aspects to act asguidelines in the construction of the structure). Therefore, the outcome of debate can be the full DAG of B∗, itspattern, or its completed pattern. These should all be equivalent. However, as the next example shows, this is notentirely true.S.H. Nielsen, S. Parsons / Artificial Intelligence 171 (2007) 754–775761Fig. 6. Three BNs and three different compromise graphs.Fig. 7. Three completed patterns and two partial compromises.Example 2 (Agreeing on a compromise BN). Consider three agents with BNs B1, B2, and B3 portrayed in Figs. 6(a)to 6(c). If the compromise is constructed by simple majority voting on the possible connections between each pair ofnodes, the result is the structure in Fig. 6(d). If the same is done for the patterns of B1 to B3 instead, the BN structurein Fig. 6(e) is obtained. For the completed patterns the result is the one in Fig. 6(f).As can be seen, evaluating each feature in isolation leads to vastly different results, even though the starting pointsare the same. This suggests that this simple approach is problematic, and should be ruled out, or that we should settlefor one representation only. We chose the latter route, as we see no simple characterization of those combinationmethodologies that guarantee that equivalent results are obtained.There seems to be little epistemological justification for choosing to compromise on a full graph, as most/alllearning algorithms are unable to differentiate between two graphs belonging to the same equivalence class, andcompromising on a DAG therefore seems to involve compromising on too much. Therefore, we choose to have agentscompromise on a pattern or completed pattern. Unfortunately, we are unaware of any simple characterization of graphsthat are patterns, so we choose completed patterns out of necessity. In summary, we shall aim for having the agentscompromise on the completed pattern G∗ ∈ Ccp of B∗.To establish whether a graph is a good compromise for the agents, we need a measure for how well such graphsmatch each of B1 to Bk. Furthermore, as we plan to build this compromise gradually, we wish for this measure to berelative to an already agreed partial compromise. The need for this should be clear from the following example.Example 3 (The need for partial compromises). Consider again the setting from Example 2, and refer to the completedpatterns of B1 to B3 in Figs. 7(a) to 7(c). It may be the case that agents have already agreed upon the connections in762S.H. Nielsen, S. Parsons / Artificial Intelligence 171 (2007) 754–775the graph in Fig. 7(d), and now Agent 2 is asked to evaluate the compromise where a link is added between A and C.Obviously, this addition is consistent with Agent 2’s beliefs, and thus must be valued highly. Consider then anothersituation, where the agents have agreed upon the connections in Fig. 7(e), and Agent 2 is again asked to evaluate theaddition of a link between A and C. Now the addition is not as important, since the connection between A and Cwould have to be directed into C (to avoid a directed cycle), and thus create a v-structure (A, C, E) not present in B2.Moreover, A and C are already connected (albeit through D and E) and the relationship between the two might besufficiently represented by this connection.In general, we cannot assume that a partially specified graph is suitable as representation of a partial compromise, asthis might include agreements on what should not be part of the final compromise. To address this need and otherwiseopting for an as general solution as possible, we shall take a partial compromise P ≡ (P +, P −) to be two sets ofsentences in some language, where P + describe aspects that should be true of the final compromise, and P − describeaspects that cannot be true.For any three partial compromises P, P a, and P b, where P + ⊆ P a−, weassume that each agent i can compute its compromise scores si(P, P a) and si(P, P b) such that si(P, P a) > si(P, P b)iff P a describes Bi better than P b, given that P has already been accepted as being descriptive of Bi . We will assumesi to be additive, i.e. for any three partial compromises P 0, P 1, and P 2, where P 0− ⊆ P 2−,it is the case that si(P 0, P 2) = si(P 0, P 1) + si(P 1, P 2).+ and P − ⊆ P b−, P + ⊆ P b+, P − ⊆ P a+ and P 0− ⊆ P 1+ ⊆ P 1+ ⊆ P 2+, P b− = ∅) where the sentences in P aExample 4 (Compromise scoring functions). Consider the partial compromises P a ≡ (P a(P bexample of s2(P a, P b) could be the number of features described in P bthose that are not. Specifically, s2(P a, P b) would equal −1.− = ∅) and P b ≡+ represent the graphs in Figs. 7(d) and 7(e), respectively. A simple+, which are consistent with B2, minus+ and P b+ \ P a+, P aA more complex score could weigh each of these described features according to the empirical evidence Agent 2has in favor of or against them: We may have that Agent 2 is employing a sensor for measuring the E variable, andthat this sensor is known to be of poor quality. Therefore, s2(P a, P b) would be equal to −0.3, as an indication thatthe addition of the arc is against Agent 2’s observations, but that those observations could easily be flawed.Yet another score could take into account the ramifications of the sentences in P b+. For instance, the additionof the arc from E to C might in itself not be much at odds with Agent 2’s observations, but the addition forces it toeither give up the idea of a link between A and C, or accept the existence of v-structure (A, C, E), both of which itmay have strong evidence for/against. Therefore, it has s2(P a, P b) = −10. Of course, the challenge is for Agent 2 toactually be able to survey the impact of the sentences in P b+ \ P a+ \ P a+.Had P a− not been empty, but rather included an agreement that there was not to be any connection between A andC, then the previous example of a compromise score would not have been so low, since the dreaded consequence ofthe addition of the arc from E to C would already be a consequence of P a. On the other hand, had this agreement−, then the first two examples of scores would have been lower: −2 for the first, and somethingbeen a part of P bless than −0.3, depending on Agent 2’s evidence, for the second.− \ P aNotice, that with this open definition, we do not attempt to define what it means to be a “better description”, sincewe believe that this issue can be dependent on the actual setting in which the framework is to be used, as stated inSection 1.In addition to the compromise score, we also assume that the agents know the combination function c : Rk → R,indicating how much trust should be put into the individual agents’ models. Differences in trust can be justified bydifferences in experiences and sensor accuracies. Formally, we define c as follows: Let P, P a, and P b be partialcompromises. c is the combination function for agents i to k, if(cid:3)(cid:4)s1(P, P a), . . . , sk(P, P a)c(cid:4)(cid:3)s1(P, P b), . . . , sk(P, P b),> cwhenever P a is a better compromise than P b for the group of agents 1 to k, given that they have already agreed on P.An obvious choice for c would be a linear combination of its inputs, and in fact we shall assume that this is the casein this text. We refer to c(s1(P, P a), . . . , sk(P, P a)) as the joint compromise score of P a given P.S.H. Nielsen, S. Parsons / Artificial Intelligence 171 (2007) 754–775763With this notation in place, we can restate the task more formally, as that of finding a partial compromise P, whichuniquely identifies some graph G∗ ∈ Ccp, such that(cid:3)s1(cid:3)(∅, ∅), P(cid:3)(∅, ∅), P (cid:10)for all other partial compromises P (cid:10), which uniquely identifies a graph G(cid:10) ∈ C.(cid:3)(∅, ∅), P (cid:10)(cid:3)(∅, ∅), P(cid:4), . . . , sk(cid:4), . . . , sk(cid:3)s1(cid:3) c(cid:4)(cid:4)c(cid:4)(cid:4),As presented here, it is clear that the problem is not of a simple binary nature, as we are not trying to establishwhether some proposition is true or not, and that we are furthermore dealing with a setting in which more than twoagents may interact. Consequently, we cannot utilize the vast literature on dialectic proof theories directly. Rather,the problem we are trying to solve is a distributed maximization over a super exponential hypothesis space (C).Furthermore, as the worth of (partial) compromises are specified in relation to already agreed upon compromises, theproblem is of a highly dynamic nature.Our solution to the problems is divided into three parts. First, we create a finite language with which graphs andsome essential properties of these can be expressed; second and most importantly, we construct an argumentationsystem with which the agents can reason about consequences of committing to partial compromises; and thirdly, wecreate an agora in which the agents can reach compromise graphs in an anytime fashion.4. Encoding graphsFor the agents to compromise on G∗, a formal language L for expressing graphs and properties of graphs must bedefined. For efficiency we aim to make this language as simple as possible, while ensuring that it is still sufficientlypowerful to describe any graph and its membership status of Ccp. By simple, we mean preferably finite and as smallas possible.First of all, we introduce a simple language Lg for encoding of graphs only:Definition 5 (Simple graph language). The language Lg is the set such that Arc(X,Y), Arc(Y,X), Link(X,Y),and NonAdjacent(X,Y) are members of Lg iff X and Y (X (cid:2) Y ) are distinct variables.A graph knowledge base we define to be a set (cid:4)g ⊆ Lg. Further:Definition 6 (Consistent and closed graph knowledgebases). Given a graph knowledge base (cid:4)g, if it holds that forall pairs of variables X and Y , where X (cid:2) Y , a maximum of one of Arc(X,Y), Arc(Y,X), Link(X,Y), andNonAdjacent(X,Y) is in (cid:4)g, then we call (cid:4)g a consistent graph knowledgebase (CGK).Furthermore, if it holds that for any two variables X and Y , where X (cid:2) Y , exactly one of Arc(X,Y), Arc(Y,X),Link(X,Y), and NonAdjacent(X,Y) is in (cid:4)g, then we call (cid:4)g a closed graph knowledgebase (CLGK).The graph encoded by a CGK (cid:4)g is the graph G[(cid:4)g] resulting from starting with the graph with no edges, andthen for any two nodes X and Y (X (cid:2) Y ) adding an arc from X to Y if Arc(X,Y) is in (cid:4)g, an arc from Y to X ifArc(Y,X) is in (cid:4)g, or an undirected edge if Link(X,Y) is in (cid:4)g. It is easy to see that graph encoded by a CGK iswell-defined. Furthermore, given a graph G ≡ (V , E) there exists a unique CLGK (cid:4)g[G], for which G is the encodedgraph. Clearly, (cid:4)g[G] can be constructed in time O(|V |2).Example 7 (Graph encoding). Consider the graph knowledgebase (cid:4)gArc(E,C). (cid:4)gE are not specified. Assuming that Lg is built from variables {A, B, C, D, E, F }, G[(cid:4)gFig. 7(e). If furthermore all ofe comprised of Arc(A,D), Arc(D,E), ande is a CGK, albeit not a closed one, as the connections among several pairs of variables, such as A ande ] corresponds to the graph inNonAdjacent(A,B), NonAdjacent(A,C), NonAdjacent(A,E),NonAdjacent(A,F), NonAdjacent(B,C), NonAdjacent(B,D),NonAdjacent(B,E), NonAdjacent(B,F), NonAdjacent(C,D),NonAdjacent(C,F), NonAdjacent(D,F),and NonAdjacent(E,F)were added to (cid:4)gfurther sentence was added to (cid:4)ge , (cid:4)ge , the set would cease to be a CGK.e would be the encoded version of the graph in Fig. 7(e), and would therefore be a CLGK. If any764S.H. Nielsen, S. Parsons / Artificial Intelligence 171 (2007) 754–775We thus have that any graph can be efficiently encoded by a unique CLGK, and Definition 6 allows us to distinguishthe graph knowledge bases, which can be interpreted as graphs, from those that cannot. Next, we extend Lg into alanguage powerful enough for building a reasoning engine about graphs and their membership status of Ccp on top:Definition 8 (Graph language). The graph language L is the set consisting of all sentences in Lg and• ArcNotAllowed(X,Y),• DirectedPath(X,Y),• UndirectedPath(X,Y),• UndirectedPath(X,Y)Excluding(Z,W),• ¬DirectedPath(X,Y),• ¬UndirectedPath(X,Y), and• ¬UndirectedPath(X,Y)Excluding(Z,W),for any choice of distinct variables X, Y , Z, and W 3 (Z (cid:2) W ). Sentences like DirectedPath(X,Y),UndirectedPath(X,Y), and UndirectedPath(X,Y)Excluding(Z,W) will be referred to as path sen-tences, and sentences like ¬DirectedPath(X,Y), ¬UndirectedPath(X,Y), and ¬UndirectedPath-(X,Y)Excluding(Z,W) will be referred to as negative path sentences.Intuitively, the sentences just introduced are supposed to be used as descriptors of attributes of the graphs encodedby CGKs: ArcNotAllowed(X,Y) states that an arc from X to Y would not be strongly protected; Directed-Path(X,Y) states that there is a directed path from X to Y ; UndirectedPath(X,Y) states that there is anundirected path between X and Y ; UndirectedPath(X,Y)Excluding(Z,W) states that there is an undi-rected path not comprising Z nor W between X and Y ; ¬DirectedPath(X,Y) states that there is no directedpath from X and Y ; ¬UndirectedPath(X,Y) states that there is no undirected path between X and Y ; and¬UndirectedPath(X,Y)Excluding(Z,W) states that there is no undirected path between X and Y , or thatany such path necessarily contains either Z or W .As Lg is a subset of L, it follows that a graph knowledge base is a set of sentences in L as well, and in particularthat Definition 6 still makes sense. Given a set (cid:4) of sentences of L, we denote by (cid:4)g the set (cid:4) ∩ Lg.5. Graph argumentation systemBuilding on the language L introduced above, we define an argumentation system for distinguishing completedpatterns that could be compromises for the agents. The system that we construct enjoys the properties that a graph isa member of C iff there is a preferred extension of the system, such that the extension encodes this graph.Definition 9 (Graph argumentation system). The graph argumentation system Ag is the tuple (L, (cid:12)g ⊆ (2L × L)),where (cid:12)g is defined as follows ([A,B] is short-hand for any one of (A,B) and (B,A)):(1) Arc(X,Y)(cid:12)g Arc(Y,X)(2) Arc(X,Y)(cid:12)g Link[X,Y](3) Arc(X,Y)(cid:12)g NonAdjacent[X,Y](4) Link(X,Y)(cid:12)g Arc[X,Y](5) Link(X,Y)(cid:12)g NonAdjacent[X,Y](6) NonAdjacent(X,Y)(cid:12)g Arc[X,Y](7) NonAdjacent(X,Y)(cid:12)g Link[X,Y](8) ¬DirectedPath(X,Y)(cid:12)g DirectedPath(X,Y)(9) ¬UndirectedPath(X,Y)(cid:12)g UndirectedPath(X,Y)3 Throughout the text we assume that the implicit set of variables has at least five members. This assumption can be lifted, albeit with a morecomplex notation to follow.S.H. Nielsen, S. Parsons / Artificial Intelligence 171 (2007) 754–775765(10) ¬UndirectedPath(X,Y)Excluding(Z,W)(cid:12)g UndirectedPath(X,Y)Excluding(Z,W)(11) Arc(X,Y)(cid:12)g ¬DirectedPath(X,Y)(12) Link(X,Y)(cid:12)g ¬UndirectedPath[X,Y](13) Link(X,Y)(cid:12)g ¬UndirectedPath[X,Y]Excluding(Z,W)(14) {DirectedPath(X,Y), DirectedPath(Y,Z)}(cid:12)g ¬DirectedPath(X,Z)(15) {DirectedPath(X,Y), UndirectedPath[Y,Z]}(cid:12)g ¬DirectedPath(X,Z)(16) {UndirectedPath[X,Y], DirectedPath(Y,Z)}(cid:12)g ¬DirectedPath(X,Z)(17) {UndirectedPath[X,Y], UndirectedPath[Y,Z]}(cid:12)g ¬UndirectedPath[X,Z](18) {UndirectedPath[X,Y]Excluding(Z,W), UndirectedPath[Y,U]Excluding(Z,W)}(cid:12)g ¬UndirectedPath[X,U]Excluding(Z,W)(19) DirectedPath(X,Y)(cid:12)g Arc(Y,X)(20) DirectedPath(X,Y)(cid:12)g Link[X,Y](21) UndirectedPath[X,Y](cid:12)g Arc(X,Y)(22) {UndirectedPath[X,Y]Excluding(W,Z), Link[X,W], Link[Y,Z], NonAdjacent[X,Z], Non-Adjacent[Y,W]}(cid:12)g Link[W,Z](23) {Arc(X,Y), NonAdjacent[X,Z]}(cid:12)g Link[Y,Z](24) ArcNotAllowed(X,Y)(cid:12)g Arc(X,Y)(25) {Arc(Z,X), NonAdjacent[Z,Y]}(cid:12)g ArcNotAllowed(X,Y)(26) {Arc(Z,Y), NonAdjacent[Z,X]}(cid:12)g ArcNotAllowed(X,Y)(27) {Arc(X,Z), Arc(Z,Y)}(cid:12)g ArcNotAllowed(X,Y)(28) {Link[X,Z], Arc(Z,Y), Link[X,W], Arc(W,Y), NonAdjacent[Z,W]}(cid:12)g ArcNotAllowed(X,Y)for all choices of distinct variables X, Y , Z, W , and U where the sentences obtained are in L.Loosely speaking, if (cid:4) is a conflict free set wrt. (cid:12)g, then items 1–7 ensure that (cid:4)g is a CGK; items 8–18 makesure that the path and negative path sentences in (cid:4) \ (cid:4)g are correct wrt. the graph that is encoded by (cid:4)g; items 19–21 ensure that (cid:4)g encodes a chain graph; item 22 ensures that the graph encoded by (cid:4)g has decomposable chaincomponents; item 23 ensures that graph also respects item 3 of Theorem 1; and items 24–28 guarantee that all arcs inthe graph are strongly protected.Example 10 (Argumentative reasoning about graphs). We return to the CGK (cid:4)ge presented in Example 7 joined withsentences DirectedPath(A,D), DirectedPath(D,E), DirectedPath(E,C), DirectedPath(D,C),and DirectedPath(A,C) to constitute the set of sentences (cid:4)e. Clearly, (cid:4)e is conflict-free. From item 19 wecan conclude that Arc(C,A) cannot be added to (cid:4)e without destroying its property of being conflict-free wrt. Ag.Item 20 yields the same result for Link(A,C), and the only options for putting a description of the connectionbetween A and C into (cid:4)e are thus NonAdjacent(A,C) and Arc(A,C). The argumentation system thus allowsfor reasoning about such consequences that were treated informally in Examples 3 and 4.In what follows we provide a formal treatment of the above outlined intuitions. More specifically we prove twoimportant results, namely that any preferred extension of Ag is a member of Ccp, and that any member of Ccp has acorresponding stable extension of Ag. These results are important since they guarantee that, if agents seek compro-mises under the restrictions specified by Ag, they can be sure that their result is a completed pattern and that they arenot restricted from agreeing on any model a priori by the relations of Ag.Lemma 11. Let (cid:4) be conflict free wrt. Ag. Then (cid:4)g is a CGK.Proof. Obvious, given items 1–7. (cid:3)Lemma 12. Let (cid:4) be a preferred extension of Ag. Then (cid:4)g is a CLGK.766S.H. Nielsen, S. Parsons / Artificial Intelligence 171 (2007) 754–775Proof. We need to prove that if X and Y (X (cid:2) Y ) are two nodes that are non-adjacent in G[(cid:4)g] then NonAdja-cent(X,Y) is in (cid:4). We prove this by contradiction: We assume that NonAdjacent(X,Y) is not in (cid:4) and thenprove that (cid:4)∗ = (cid:4)∪NonAdjacent(X,Y) is an admissible set, which contradicts that (cid:4) is a preferred extension.First we prove that (cid:4)∗ is conflict-free: Since X and Y are non-adjacent in G[(cid:4)g] it follows that none of Arc(X,Y),Arc(Y,X), and Link(X,Y) are in (cid:4), and therefore that (cid:4) cannot attack NonAdjacent(X,Y). Thus, if there isa set S ⊆ (cid:4)∗ and an argument A ∈ (cid:4)∗, such that S (cid:12)g A, then A cannot be NonAdjacent(X,Y) and hence mustbe in (cid:4). As (cid:4) is admissible, it follows that (cid:4) attacks at least one argument B in S, and as (cid:4) does not attack NonAd-jacent(X,Y), B must be a member of S\NonAdjacent(X,Y). But that means that (cid:4) attacks (cid:4), meaning thatit is not a conflict-free set, contradicting the assumption that (cid:4) is a preferred extension. So we conclude that (cid:4)∗ mustbe conflict-free.It is easy to see that (cid:4)∗ attacks all sets of arguments that attack (cid:4)∗: By assumption, (cid:4) attacks all sets of argumentsthat attack an argument in (cid:4), and by items 1–7, NonAdjacent(X,Y) attacks all sets of arguments that attack itself.Consequently, (cid:4)∗ = (cid:4)∪NonAdjacent(X,Y) attacks all arguments that attack some argument in itself, and thelemma follows. (cid:3)From [19] we have the following equivalent of the “Fundamental Lemma” of [7]:Lemma 13. Let (cid:4) be a preferred extension, and let A an argument defended by (cid:4). Then A is in (cid:4).Lemma 14. Let (cid:4) be a preferred extension of Ag and X, Y , Z, and W (Z (cid:2) W ) be variables. Then(1) if there is a directed path from X to Y in G[(cid:4)g], then DirectedPath(X,Y) is in (cid:4),(2) if there is an undirected path from X to Y in G[(cid:4)g], then UndirectedPath(X,Y) is in (cid:4), and(3) if there is an undirected path from X to Y in G[(cid:4)g] not comprising any of the variables Z and W , thenUndirectedPath(X,Y)Excluding(Z,W) is in (cid:4).Proof. Induction on the length l of the path between X and Y . We first consider the base case where l is 1. If thepath is a directed path, this means that there is an arc from X to Y and consequently that Arc(X,Y) is in (cid:4). Byitem 11 this means that (cid:4) attacks ¬DirectedPath(X,Y), which is the only argument that attacks Directed-Path(X,Y). Lemma 13 then guarantees that DirectedPath(X,Y) is in (cid:4). Similar arguments establish the basecases for 2 and 3.For the induction step, assume that the result is valid for all paths of length l (cid:2) n and consider a path π = (X =X1, U = X2, . . . , Xn+2 = Y ) of length n + 1. If π is an undirected path, then we know from the induction hypothesisthat both UndirectedPath(X,U) and UndirectedPath(U,Y) must be in (cid:4). The two sentences collectivelyattack ¬UndirectedPath(X,Y), which is the only argument attacking UndirectedPath(X,Y). Since (cid:4)is a preferred extension, Lemma 13 then gives that UndirectedPath(X,Y) is a member of (cid:4). The proof forUndirectedPath(X,Y)Excluding(Z,W) is the same.Assume next that π is a directed path. Then either there is an arc from X to U or a link between them. We considerthe two cases in turn.In the first case, an argument similar to the one used for the base case gives us that DirectedPath(X,U) mustbe in (cid:4). Next, if (U = X2, . . . , Xn+2 = Y ) is a directed path, then induction hypothesis gives us that Directed-Path(U,Y) is in (cid:4). If (U = X2, . . . , Xn+1 = Y ) is undirected, we get that UndirectedPath(U,Y) is in (cid:4).Either way, the two sentences obtained collectively attack ¬DirectedPath(X,Y), which is the only argumentattacking DirectedPath(X,Y). Since (cid:4) is a preferred extension, Lemma 13 then states that DirectedPath-(X,Y) must be a member of (cid:4).If there is a link between X and U , there must be a directed path from U to Y , for π to be a directed path. As beforethe presence of Link(X,U) or Link(U,X) yields that UndirectedPath(X,U) is in (cid:4), and the inductionhypothesis that DirectedPath(U,Y) is in (cid:4). Together the two attack ¬DirectedPath(X,Y), which is theonly argument that attacks DirectedPath(X,Y). Once again Lemma 13 guarantees that DirectedPath(X,Y)is in (cid:4). (cid:3)The converse of Lemma 14 is not true, which can be seen from the following example:S.H. Nielsen, S. Parsons / Artificial Intelligence 171 (2007) 754–775767Example 15. Let (cid:4)g consist of NonAdjacent(A,B), NonAdjacent(B,C), and NonAdjacent(A,C), thusencoding the empty graph over the set of variables V e = {A, B, C}. Furthermore, let (cid:4) \ (cid:4)g be(cid:5)(cid:2)ArcNotAllowed(X,Y): X, Y ∈ V e(cid:2)UndirectedPath(X,Y): X, Y ∈ V e(cid:2)DirectedPath(X,Y): X, Y ∈ V e.(cid:5)∪∪(cid:5)Then (cid:4) is conflict free and attacks all other sentences in L, meaning that it is stable and hence a preferred extension,yet clearly G[(cid:4)g] does not reflect the meaning of the path sentences in (cid:4).Theorem 16. Let (cid:4) be a preferred extension of Ag. Then G[(cid:4)g] is in Ccp.Proof. Assume not. This means that G[(cid:4)g] fails to satisfy one of the bullets of Theorem 1. We prove that this cannotbe the case, one bullet at the time:Assume G[(cid:4)g] does not satisfy item 1, namely that it is not a chain graph. Then there is a directed cycle(X, . . . , Y, X) in G[(cid:4)g] containing at least one arc. Without loss of generality, assume this arc to be going fromY to X, and consequently that Arc(Y,X) is in (cid:4). The rest of the cycle then constitutes either a directed path fromX to Y , or an undirected path between them. Either way, Lemma 14 allows us to conclude that one of Directed-Path(X,Y) and UndirectedPath[X,Y] must be in (cid:4). But that is impossible, since either one of them attacksArc(Y,X) and (cid:4) is conflict-free.Assume then that G[(cid:4)g] does not satisfy item 2, namely that it contains a chain component that is not decom-posable. This implies that the there is a chordless cycle in G[(cid:4)g]. Let this cycle be (X, Z, . . . , W, Y, X), whichimplies that Link[X,Z], Link[W,Y], and Link[Y,X] are in (cid:4). Furthermore, as the cycle is chordless, bothX and W and Y and Z must be pairs of non-adjacent nodes in G[(cid:4)g]. By Lemma 12 NonAdjacent[X,W] andNonAdjacent[Y,Z] must then be in (cid:4). Additionally, the path (Z, . . . , W ) and Lemma 14 collectively allow usto conclude that UndirectedPath[Z,W]Excluding(X,Y) must be in (cid:4) as well. However, Undirected-Path[Z,W]Excluding(X,Y) in conjunction with Link[Z,X], Link[W,Y], NonAdjacent[X,W], andNonAdjacent[Y,Z] attacks Link[X,Y], which is impossible since (cid:4) is conflict-free.Next, assume that G[(cid:4)g] does not satisfy item 3, which means that there are three variables X, Y , and Z, suchthat X is a parent of Y , X and Z are not adjacent, and Z is a neighbor of Y . According to Lemma 12, (cid:4) would thencontain all of Arc(X,Y), NonAdjacent[X,Z], and Link[Y,Z]. But the first two attack the last one, and since(cid:4) is conflict-free, this is impossible.Finally, assume that G[(cid:4)g] does not satisfy item 4, which means that there is some arc from a node X to a nodeY that is not strongly protected in G[(cid:4)g]. Thus Arc(X,Y) is in (cid:4), and as Arc(X,Y) is attacked by ArcNot-Allowed(X,Y) and (cid:4) is an admissible set, it follows that (cid:4) attacks ArcNotAllowed(X,Y). The only ways (cid:4)can attack ArcNotAllowed(X,Y) are by containing either• Arc(Z,X) and NonAdjacent[Z,Y] for some variable Z,• Arc(Z,Y) and NonAdjacent[Z,X] for some variable Z,• Arc(X,Z) and Arc(Z,Y) for some variable Z, or• Link[X,Z], Link[X,W], Arc(Z,Y), Arc(W,Y), and NonAdjacent(Z,W) for some variables Z and W .We deal only with the first case as the others are similar. As (cid:4) contains Arc(Z,X) and NonAdjacent[Z,Y]and (cid:4)g is a CGK, it follows that there is an arc from Z to X in G[(cid:4)g] and that Z and Y are not connected by a linknor an arc. But then the arc from X to Y is protected, which yields a contradiction with the assumption. As the otherthree cases yield similar contradictions, the assumption must be false, and the theorem follows. (cid:3)Theorem 17. If G is in Ccp, then there is a stable extension (cid:4) of Ag, such that G[(cid:4)g] = G.Proof. We prove this by construction of a stable extension (cid:4) such that G[(cid:4)g] = G. First let (cid:4)g be (cid:4)g[G], whichensures that G[(cid:4)g] = G, no matter what sentences are in (cid:4) \ (cid:4)g.Next, for any four variables X, Y , Z, and W , let (cid:4) \ (cid:4)g contain768S.H. Nielsen, S. Parsons / Artificial Intelligence 171 (2007) 754–775• ArcNotAllowed(X,Y) iff there is no arc between X and Y and such an arc would not be strongly protected,• DirectedPath(X,Y) iff there is a directed path from X to Y , and ¬DirectedPath(X,Y) otherwise,• UndirectedPath(X,Y) iff there is an undirected path between X and Y , and ¬UndirectedPath(X,Y)otherwise, and• UndirectedPath(X,Y)Excluding(Z,W) iff there is an undirected path not comprising Z nor W betweenX and Y , and ¬UndirectedPath(X,Y)Excluding(Z,W) otherwise.Then (cid:4) is the stable extension we are seeking. To prove it, we show (i) that (cid:4) is conflict-free and (ii) that (cid:4) attacksall sentences in L \ (cid:4).(i) We consider each bullet of the definition of (cid:12)g in Definition 9.Items 1 to 7: As (cid:4)g was defined to be (cid:4)g[G], which is a CLGK, there can be no two variables X and Y (X (cid:2) Y ),for which more than one of Arc(X,Y), Arc(Y,X), Link(X,Y), and Link(X,Y) are in (cid:4). Consequently, thesebullets do not give rise to any conflicts.Items 8 to 13: These bullets cannot give rise to any conflict. The first because by definition of (cid:4), for each pairof variables X and Y , only one of DirectedPath(X,Y) and ¬DirectedPath(X,Y) can be in (cid:4). The samereasoning prevents the next two bullets from giving rise to a conflict. Item 9 cannot give rise to a conflict as thepresence of Arc(X,Y) in (cid:4) means that there is an arc from X to Y in G and thus a directed path from X to Y , whichby definition of (cid:4) means that it does not contain ¬DirectedPath(X,Y). The same reasoning goes for the twonext bullets.Items 14 to 18 cannot give rise to conflicts. If item 14 was the reason for a conflict, then both DirectedPath-(X,Y) and DirectedPath(Y,Z) would have to be in (cid:4), which by definition of (cid:4) would mean that there isa directed path (X, . . . , Y ) from X to Y and a directed path (Y, . . . , Z) from Y to Z in G. But then there is alsoa directed path (X, . . . , Y, . . . , Z) from X to Z meaning that ¬DirectedPath(X,Z) by definition is not in (cid:4).Similar arguments show that the other bullets cannot give rise to conflicts.Item 19 cannot give rise to a conflict as that would mean that both DirectedPath(X,Y) and Arc(Y,X) wouldbe in (cid:4), and consequently that there would be a directed path from X to Y and an arc from Y to X in G, which wouldmean that G is not a chain graph, and by Theorem 1 not a completed pattern. The same goes for items 20 to 21, anda similar argument, substituting the chain graph requirement of Theorem 1 with the decomposability one, yields thatitem 22 cannot be cause of conflicts either.Item 23 cannot give rise to a conflict, as if it did that would mean that all of Arc(X,Y), NonAdjacent[X,Z],and Link[Y,Z] would be in (cid:4)g, which in turn would mean that X would be a parent of Y in G, that X and Zwould not be adjacent, and that Y and Z would be connected with an undirected link. This would violate item 3 ofTheorem 1, meaning that G is not a completed pattern, which is a contradiction.Item 24 can clearly not give rise to any conflicts, as ArcNotAllowed(X,Y) are only in (cid:4) for nodes not con-nected by an arc, ruling out that Arc(X,Y) is also in (cid:4), which would be needed for a conflict.The arguments as to why items 25 to 28 cannot give rise to conflicts are similar so only the argument relating toitem 25 is treated here. If this bullet caused a conflict, it means that Arc(Z,X), NonAdjacent[Z,Y], and Arc-NotAllowed(X,Y) are all in (cid:4), implying that Z is a parent of X and not adjacent to Y in G, and that there is noarc between X and Y , and had there been such an arc, it would not be strongly protected. But the definition of stronglyprotected clearly states that an arc from X to Y with Z being a parent of X and not adjacent to Y is strongly protected,yielding a contradiction.(ii) Next, we prove that (cid:4) attacks every sentence not in (cid:4), and thus that it is stable and therefore a preferredextension. We consider each argument A of L in turn, and show that it is either a member of (cid:4) or attacked by it.First, let A be Arc(X,Y) for some variables X and Y (X (cid:2) Y ). If Arc(X,Y) is not in (cid:4)g then, by definition ofa CLGK either Arc(Y,X), Link(X,Y), or NonAdjacent(X,Y) must be in (cid:4)g and (cid:4) thus attacks Arc(X,Y)by one of items 1 to 7. A similar argument applies if A is Arc(Y,X), Link(X,Y), or NonAdjacent(X,Y).Assume then that A is ArcNotAllowed(X,Y) for some pair of variables X and Y , and that (cid:4) does not attackArcNotAllowed(X,Y). That means that none of the left hand sides of items 25 to 28 are satisfied by members of(cid:4). This in turn means that the graph encoded by (cid:4)g, viz. G, does not give strong protection to an arc from X to Y . AsG is a completed pattern, it follows from Theorem 1 that there cannot be an arc from X to Y . However, by definitionof (cid:4) this means that ArcNotAllowed(X,Y) must be in (cid:4).S.H. Nielsen, S. Parsons / Artificial Intelligence 171 (2007) 754–775769Then assume that A is DirectedPath(X,Y) and that it is not attacked by (cid:4). This means that ¬Directed-Path(X,Y) is not in (cid:4), and by definition of (cid:4), DirectedPath(X,Y) must therefore be in (cid:4). Similar reasoningestablishes that both UndirectedPath(X,Y) and UndirectedPath(X,Y)Excluding(Z,W) are in (cid:4) iffthey are not attacked by (cid:4).Finally, assume that A is ¬UndirectedPath(X,Y), and that it is not in (cid:4). By definition of (cid:4) this meansthat there is an undirected path (X, . . . , Y ) between X and Y in G. If the length of (X, . . . , Y ) is 1, then there isan undirected link between the two variables X and Y , and consequently Link[X,Y] is in (cid:4)g and (cid:4) thereforeattacks ¬UndirectedPath(X,Y) by Item 12. If the length of (X, . . . , Y ) is more than 1, there must be at leastone variable Z on this path such that both (X, . . . , Z) and (Z, . . . , Y ) are undirected paths in G. It follows by thedefinition of (cid:4) that both UndirectedPath(X,Z) and UndirectedPath(Z,Y) are in (cid:4), and (cid:4) then attacks¬UndirectedPath(X,Y) by item 17. Similar (but more elaborate) arguments establish the result for argumentsA of the form ¬DirectedPath(X,Y) and ¬UndirectedPath(X,Y)Excluding(Z,W). (cid:3)Given these results it is thus clear that the result (cid:4) of a debate, if undertaken respecting Ag, is a completed patternif it is a preferred extension of Ag, and that (cid:4) can represent any completed pattern. However, checking whether a setof arguments constitute a preferred extension is complex. It involves checks for both admissibility and maximality. Wetherefore end this section with a result that yields a computationally efficient way of testing whether a set of argumentsof Ag is a preferred extension.Lemma 18. Let (cid:4) be a preferred extension of Ag, and A a path sentence not in (cid:4) and not attacked by it. Then thenegative path sentence corresponding to A is not in (cid:4) nor attacked by it.Proof. We show only the case where the path sentence is UndirectedPath(X,Y) for two variables X and Y ,as the others cases are similar. Since UndirectedPath(X,Y) is not in (cid:4) and not attacked by (cid:4), it follows fromitem 9, and the fact that this bullet represents the only attack on UndirectedPath(X,Y), that ¬Undirec-tedPath(X,Y) cannot be in (cid:4) either. Furthermore, as (cid:4) is a preferred extension and does not attack Undi-rectedPath(X,Y), it follows that (cid:4) cannot attack ¬UndirectedPath(X,Y) either, as that would imply thatUndirectedPath(X,Y) was defended by (cid:4), which according to Lemma 13 would mean that it should have beena member of (cid:4). (cid:3)Theorem 19. Let (cid:4) be a preferred extension of Ag. Then (cid:4) is a stable extension.Proof. We need to show that (cid:4) attacks each argument A in A \ (cid:4). We do so by considering each possible A:Assume first that A is one of Arc(X,Y), Arc(Y,X), Link(X,Y), or NonAdjacent(X,Y), for some vari-ables X and Y . As (cid:4) is a preferred extension, Lemma 12 guarantees that one of the other three arguments is in (cid:4), anditems 1 to 7 then ensures that (cid:4) attacks A.Assume then that A is ArcNotAllowed(X,Y), for some X and Y , and that it is not attacked by (cid:4). This meansthat for each of the left-hand sides of items 25 to 28 there is at least one element that is not in (cid:4). Furthermore, as (cid:4)does not defend ArcNotAllowed(X,Y), there is at least one of these bullets, whose left-hand side is not attackedby (cid:4). Assume that this bullet is item 25. That means that either Arc(Z,X) or NonAdjacent[Z,Y] or both areneither in (cid:4) nor attacked by it. But this is impossible, as was proved above. A similar contradiction arise for theremaining three bullets. It follows that ArcNotAllowed(X,Y) must be attacked by (cid:4).Now, assume that A is ¬UndirectedPath(X,Y), and that (cid:4) does not attack ¬UndirectedPath(X,Y).As (cid:4) does not attack ¬UndirectedPath(X,Y), it follows from item 17 that for all variables Z, one of Undi-rectedPath[X,Z] and UndirectedPath[Z,Y] cannot be in (cid:4) either. Furthermore, item 12 implies thatLink[X,Y] cannot be in (cid:4), and since it is a preferred extension, and by Lemma 12 thus a CLGK, it must at-tack Link[X,Y]. Since by Lemma 13 (cid:4) fails to defend ¬UndirectedPath(X,Y), then it must fail to attackboth of UndirectedPath[X,Z] and UndirectedPath[Z,Y] for some variable Z. Without loss of general-ity, assume that UndirectedPath[Z,Y] is the path sentence which is both outside of (cid:4) and not attacked by it.Lemma 18 then guarantees that ¬UndirectedPath[Z,Y] must also be outside of (cid:4) and not attacked by (cid:4). But¬UndirectedPath[Z,Y] has the exact same form as the A we started out exploring, and we can therefore applythe same argument again, obtaining yet another negative path sentence that must be outside (cid:4) and not be attacked770S.H. Nielsen, S. Parsons / Artificial Intelligence 171 (2007) 754–775by it. This process will never end, and since L is a finite language, it thus follows that there is a set N of nega-tive path sentences, which are all outside (cid:4) and not attacked by (cid:4) solely because of other negative path sentencesthat are in N . From the definition of N it is obvious that the set P of path sentences, corresponding to the negativeones in N , attacks each of the sentences in N , and furthermore that N contains all the sentences that attack P . As(cid:4) defends itself, it follows that the set (cid:4)∗ ≡ (cid:4) ∪ P defends itself against all attacks. If we can also show that (cid:4)∗is conflict-free, then it contradicts that (cid:4) is a preferred extension, and hence implies that the original claim, that¬UndirectedPath(X,Y) is not attacked by (cid:4), is false. To show that (cid:4)∗ is conflict-free, we assume otherwise,and let S ⊆ (cid:4)∗ attack some B in (cid:4)∗. Assume first that B is in (cid:4). As (cid:4) defends itself, it must attack some argumentin S. But this is impossible since (cid:4) is conflict-free and by construction P is not attacked by (cid:4). Thus, B must be inP . But this is also impossible, because the only arguments that attack P are the ones in N , which by definition is notpart of (cid:4)∗. It follows that (cid:4)∗ is conflict-free and thus that ¬UndirectedPath(X,Y) must be attacked by (cid:4).If A is UndirectedPath(X,Y) and is not attacked, then Lemma 18 guarantees that ¬UndirectedPath(X,Y) is also not in (cid:4) and not attacked by it, which as we just saw, is impossible. Thus UndirectedPath(X,Y) mustbe attacked by (cid:4).Proving that UndirectedPath(X,Y)Excluding(Z,W) and ¬UndirectedPath(X,Y)Excluding-(Z,W) must be attacked by (cid:4) if they are not in (cid:4) is proved in the same way as for UndirectedPath(X,Y)and ¬UndirectedPath(X,Y). The case of ¬DirectedPath(X,Y) can be proved in a similar manner to¬UndirectedPath(X,Y), except that instead of only item 17 to establish the existence of the set N , we need tosee that in any case at least one of items 14 to 16 implies the existence of another ¬DirectedPath(Z,W) not in(cid:4) and not attacked by (cid:4). That DirectedPath(X,Y) is attacked then once again follows from Lemma 18. (cid:3)Given this result we can thus efficiently identify a set (cid:4) as being a preferred extensions of Ag by simply checkingif it attacks all arguments in L \ (cid:4) and only those.6. Fusing agorasWe now address the problem of having agents agree on a preferred extension of Ag, given that each of them hasits own prior beliefs, as expressed by the compromise score function si , and that each know the combination functionc. There has not been a lot of work done in dialectics for more than two agents, where the simple proponent/opponentdualism does not suffice. The solution that we propose here is inspired by the Risk Agoras of [15] and [16] and thetraditional blackboard architecture of MAS of cooperating agents, without being an actual instantiation of any of them.We construct a fusing agora, which is a framework in which the agents can debate. The agora has the property that, ifagents are allowed to run the debate to conclusion, they end up with the best possible compromise according to theirjoint compromise score, and that throughout the debate they maintain a compromise, which improves as the debateprogresses.In the agora we shall take a Ag-candidate (I , O, U ) as a unique representative of a partial compromise (I , O).This is possible since I and O are subsets of L, and thus both contain sentences describing aspects of a compromisegraph as required, and since U is determined by I and O. Any leaf candidate representing a preferred extensionthen uniquely identifies a completed pattern, as guaranteed by Theorem 16. Agents can explore all compromises byexamining a (∅, ∅, L)-tree. Continually the agents take it upon themselves to explore sub-trees of this tree, and markother sub-trees as open for investigation by other agents. The heuristics guiding the agents’ choices for exploration, inaddition to s1, . . . , sk and c, then determine the outcome.The agora can work in a variety of ways, depending on the behavior of the individual agents (a vanilla algorithmfor an individual agent is provided later in Algorithm 1), but basically builds on two elements, which we assume eachagent can access in a synchronized fashion only: A pool of candidates C and a current best result (cid:17)I ∗, sI ∗(cid:18). C consistsof pairs (cid:17)C, s(cid:18), where C is an Ag-candidate and thus a sub-tree of a (∅, ∅, L)-tree, and s is a real value. I ∗ is either theempty set or a preferred extension of Ag, and sI ∗ is a real value. Initially, C contains only one element (cid:17)(∅, ∅, L), 0(cid:18),and (cid:17)I ∗, sI ∗(cid:18) is (cid:17)∅, −∞(cid:18).Each agent i can utter the following locutions:S.H. Nielsen, S. Parsons / Artificial Intelligence 171 (2007) 754–775771• ExploreFromPooli((cid:17)C, s(cid:18))—where (cid:17)C, s(cid:18) is a member of C. The meaning of the locution is that agent i takes uponitself the responsibility to investigate the preferred extensions in a C-tree, assuming that C has a joint compromisescore of s.• PutInPooli((cid:17)C, s(cid:18))—where C is an Ag-candidate, and s is a real value. The meaning of the locution is that agenti wants someone else to investigate the preferred extensions in a C-tree, and that C has a joint compromise scoreof s.• UpdateBesti((cid:17)I , s(cid:18))—where I is a subset of L, and s is a real value. The meaning of the locution is that agent ihas identified a preferred extension I with a joint compromise score s higher than sI ∗ .• AskOpinioni(C1, C2)—where C1 and C2 are Ag-candidates. The meaning of the locution is that agent i needs to• StateOpinioni(C1, C2, sδ)—where C1 and C2 are Ag-candidates, and sδ is a real value. The meaning of the locutionknow sj (C1, C2) for all other agents j .is that si(C1, C2) is sδ.The rules governing which locutions individual agents can utter, as well as their effects, we present as a set of pre andpost conditions:• ExploreFromPooli((cid:17)C, s(cid:18))– Pre: (cid:17)C, s(cid:18) is in C.– Post: (cid:17)C, s(cid:18) is removed from C• PutInPooli((cid:17)C, s(cid:18))• UpdateBesti((cid:17)I , s(cid:18))– Pre: s > sI ∗ .– Post: (cid:17)I ∗, sI ∗ (cid:18) is set to (cid:17)I , s(cid:18).– Pre: There is no (cid:17)C(cid:10), s(cid:10)(cid:18) in C such that C is a sub-tree of some C(cid:10)-tree.– Post: (cid:17)C, s(cid:18) is in C.Locutions AskOpinioni() and StateOpinioni() have no pre or post conditions attached.The basic algorithm in Algorithm 1 corresponds to an exhaustive search, if it is followed by all agents. The searchis gradual in two senses: One, the longer the search goes on, the more elements the average candidate in C will havein its I and O sets, and thus the closer it will be to describing a full compromise. Two, the current compromise heldin I ∗ will have an increasingly higher score.In order for the search to be a success, each agent i would of course need to keep an eye out for AskOpinionj (·)’suttered by other agents, and reply to these with StateOpinioni(·). It is relatively easy to verify that agents usingAlgorithm 1 are uttering locutions in accordance with the pre and post conditions of the fusing agora. Algorithm 1uses a series of helper functions, which are described below.Prune(C ≡ (I , O, U )) uses pruning rules to investigate whether there is an argument A in U such that eitherC + A or C − A contains no leaves with preferred extensions. If this is the case, the method invokes itself recursivelyon the sub-tree that did not get pruned away, until no further branches can be pruned. Some general pruning rules aregiven in [18], and more can be established for the specific case of Ag. For instance, it is known that any preferredextension of Ag is stable, so whenever I ∪ U does not attack an argument A ∈ U , then the branch corresponding toC − A cannot contain any preferred extensions.SelectCandidate(C) picks a promising candidate from C. A promising candidate could be one with a highscore annotated, since these encode good partial compromises, or candidates with small U sets, as these representpartial compromises that are nearly complete. If all agents use the same criteria for picking promising candidates, thisselection can be sped up by implementing the pool as a sorted list. SelectCandidate(·) is one of the areas whereheuristics limiting the search space can be implemented. For instance, it makes sense to allow agents to abstain fromexploring the sub-tree rooted at a candidate if it cannot contain compromises that are consistent with their own BN.This would mean that in cases where agents agree on all or most of the aspects of G∗ only few candidates would needto be explored.PreferredExtension(I ) is a Boolean valued function that returns true if the conflict-free set I is a preferredextension of Ag. The task of answering this is simplified by Theorem 19, as it states that I is a preferred extension iffI attacks each argument in L \ I .772S.H. Nielsen, S. Parsons / Artificial Intelligence 171 (2007) 754–775if PreferredExtension(I (cid:10)) thenAskOpinioni(C, C(cid:10))si ← si(C, C(cid:10))wait for StateOpinionj (C, C(cid:10), sj )∀j (cid:22)= is(cid:10) ← c(s1, . . . , sk) + selseend ifend ifgo to 1if U (cid:10) = ∅ thenif s(cid:10) > sI ∗ thenUpdateBesti((cid:17)C(cid:10), s(cid:10)(cid:18))(cid:17)C, s(cid:18) ← SelectCandidate(C)1:2: ExploreFromPooli((cid:17)C, s(cid:18))3: C(cid:10) (cid:4) (I (cid:10), O(cid:10), U (cid:10)) ← Prune(C)4:5:6:7:8:9:10:11:12:13:14:15:16:17:18:19:20:21:22:23:24:25:26:27:28:29:30:31:32:33:34:A ← SelectArgument(C(cid:10))AskOpinioni(C, C(cid:10) + A)AskOpinioni(C, C(cid:10) − A)+← si(C, C(cid:10) + A)si−← si(C, C(cid:10) − A)siwait for StateOpinionj (C, C(cid:10) + A, s+s+ ← c(sk )−s− ← c(sk )if s+ > s− thenPutInPooli((cid:17)C(cid:10) + A, s + s+(cid:18))C ← C(cid:10) − As ← s + s−PutInPooli((cid:17)C(cid:10) − A, s + s−(cid:18))C ← C(cid:10) + As ← s + s++1 , . . . , s−1 , . . . , send ifgo to 3end ifelse+j ) and StateOpinionj (C, C(cid:10) − A, s−j )∀j (cid:22)= iAlgorithm 1. Vanilla algorithm for agent i.SelectArgument(C ≡ (I , O, U )) simply selects an element A of U . This selection can be based on the agent’sown score increase going from C to C + A or C − A, or it might involve negotiations or argument with otheragents.We illustrate the basics of the fusing agora and Algorithm 1 with an example.Example 20. Refer back to Examples 2 and 3, and consider the simple case where the compromise scoring functionof the three agents is defined as the number of features that correspond to the completed pattern of their model minusthose that do not, as exemplified in Example 4. We shall follow the initial actions in the agora, where C consists ofonly one candidate, (cid:17)C ≡ (∅, ∅, L), 0(cid:18). We assume that Agent 1 is first to make a move.Agent 1’s first choice for exploration is simple, as C only contains one element, and the agent thus uttersExploreFromPool1((cid:17)C, 0(cid:18)). This candidate cannot be pruned, and since the third set in it is not empty, Agent 1 se-lects an argument to add to one of the other two sets, say, Arc(A, D). Agent 1 then constructs the two candidates (thethird set of the candidates are left out, as it is simply L minus the first two sets):S.H. Nielsen, S. Parsons / Artificial Intelligence 171 (2007) 754–775773C + Arc(A, D) =(cid:3)Arc(A, D),(cid:2)Arc(D, A), Link(A, D),NonAdjacent(A, D), ArcNotAllowed(A, D),¬DirectedPath(A, D), DirectedPath(D, A),UndirectedPath(A, D), UndirectedPath(D, A)(cid:5)(cid:4)andC − Arc(A, D) =(cid:3)∅,(cid:2)Arc(A, D)(cid:5)(cid:4).Agent 1 ask the other two agents their opinion by AskOpinion1(C, C + Arc(A,E)) and AskOpinion1(C, C −Arc(A, E)), and receives four answers −1, −1, 1, and 1 (as none of the other agents agree with Arc(A, D)). Added toits own perception, Agent 1 gets the scores s+ = −3 and s− = 3, and it thus utters PutInPooli((cid:17)C + Arc(A,E), −3),and continues exploring C − Arc(A,E).Let us switch to Agent 2, who at this point utters ExploreFromPool2((cid:17)C + Arc(A,E) ≡ (I +, O+, U +), −3(cid:18)), andtakes on the responsibility of examining the sub-tree rooted at C + Arc(A,E). First, Agent 2 prunes the candidate,by adding DirectedPath(A,D) to I +, and then chooses a new argument to investigate (seeing that U + is notempty). For sake of coherence with previous examples, assume this argument is Arc(D,E). Agent 2 creates thecandidates(cid:5)DirectedPath(A, D), Arc(D, E),(cid:2)C + Arc(A, D) + Arc(D, E) =(cid:3)I + ∪(cid:2)Arc(E, D), Link(D, E), NonAdjacent(D, E),O+ ∪ArcNotAllowed(D, E), ¬DirectedPath(D, E),DirectedPath(E, D), UndirectedPath(D, E),UndirectedPath(E, D), ArcNotAllowed(A, E)(cid:5)(cid:4)(cid:5)(cid:4)andC + Arc(A, D) − Arc(D, E) =Arc(D, E)and gets an evaluation from Agents 1 and 3 using AskOpinion2(·). These evaluations are +1, −1, −1, and +1,and taken together with +1 and −1 derived from Agent 2’s own beliefs, it gets s+ = 1 and s− = −1, so it putsC + Arc(A, D) − Arc(D, E) in C and continues exploring C + Arc(A, D) + Arc(D, E).(cid:3)I +, O+ ∪(cid:2)Of course, the debate in the agora can be stopped at any time, and G[I g∗] will then be the best compromise encoun-tered so far, as it is only ever replaced by compromises having a higher joint compromise score. More specifically wehave that:Proposition 21. Let agents 1 to k argue in a fusing agora. If• all agents have used Algorithm 1, and• each agent i have replied to all AskOpinionj (·)’s uttered by other agents, with a StateOpinioni(·) consistent withsi ,then all locutions uttered by agents are in accordance with the pre and post conditions of the fusing agora, and(I ∗, L \ I ∗, ∅) has a higher joint compromise score si than all other explored leaf candidates (I , L \ I , ∅), where Iis a preferred extension of Ag.If we furthermore have that• all agents have completed processing,• the pool of candidates has not been thinned along the way, and• the pool is empty now,then G[I g∗] = G∗.774S.H. Nielsen, S. Parsons / Artificial Intelligence 171 (2007) 754–775It is worth stressing that Algorithm 1 is a vanilla algorithm, and that the agora is open for more aggressive behavior.One such behavior could be to have agents skip the asking for opinions part in lines 14 to 22 for most additions ofarguments (and basing the decision only on the agents own beliefs), and only ask when the agent itself is indifferent.Another behavior could be to never perform lines 23 and 27, which would correspond to a myopic greedy constructionof the compromise. Alternatively, these two lines could be carried out only when the difference between s+ and s− isvery small. We could even have setups where the agents show different behaviors, or where individual agents changebehavior during debate depending on their available resources and utility of a good compromise. Moreover, the agoradoes not require that agents wait for a candidate to be in the pool, before somebody can start exploring this candidate;so even when one agent is pursuing an aggressive strategy and fails to leave candidates for others to explore, otheragents can still decide to explore these. The point is, that no matter what behavior is required, the basics of the agoraand the agents remains the same, and can be reused.7. DiscussionWe have introduced a problem which we believe is a challenging one for the argumentation community, due toits mix of complexity and conditional decomposability as well as its origin in conflicting knowledge bases. Our ownsolution enables agents to judge the possible compromises resulting from a partial compromise, by constructing acandidate tree rooted in this partial compromise, and the agora we have proposed ensures that such exploration cantake place in a distributed fashion. As an aside, we note that the method given here provides for a distributed solutionto the problem of enumerating all equivalence classes of BNs [9].One problem with the vanilla algorithm we have given, is that agents exploring a branch of a candidate-tree canend up putting a lot of candidates into the pool of annotated candidates. The space requirements for storing the pool ofannotated candidates can be prohibitive, so it might be required that the candidates in the pool are defined in relationto each other, which imposes restrictions on which candidates an agent can choose to explore, as these are removedfrom the pool. Furthermore, it might be necessary to construct heuristics for thinning the pool of annotated candidates.These issues, as well as finding good heuristics for selecting candidates to explore are challenging topics for futureresearch.AcknowledgementsThis work was partly supported by NSF REC-02-19347, NSF IIS-0329037, and EU PF6-IST 002307 (ASPIC).References[1] S.A. Andersson, D. Madigan, M.D. Perlman, A characterization of Markov equivalence classes for acyclic digraphs, Annals of Statistics 25 (2)(1997) 505–541.[2] C. Cayrol, S. Doutre, J. Mengin, On decision problems related to the preferred semantics for argumentation frameworks, Journal of Logic andComputation 13 (3) (2003) 377–403.[3] D.M. Chickering, Learning equivalence classes of Bayesian-network structures, Journal of Machine Learning Research 2 (2002) 445–498.[4] J. Del Sagrado, S. Moral, Qualitative combination of Bayesian networks, International Journal of Intelligent Systems 18 (2) (2003) 237–249.[5] Y. Dimopoulos, B. Nebel, F. Toni, On the computational complexity of assumption-based argumentation for default reasoning, ArtificialIntelligence 141 (1) (2002) 57–78.[6] S. Doutre, J. Mengin, Preferred extensions of argumentation frameworks: Query, answering and computation, in: R. Goré, A. Leitsch, T. Nip-kow (Eds.), Proceedings of the First International Joint Conference on Automated Reasoning, in: Lecture Notes in Computer Science,vol. 2083, Springer-Verlag, 2001.[7] P.M. Dung, On the acceptability of arguments and its fundamental role in nonmonotonic reasoning, logic programming and n-person games,Artificial Intelligence 77 (2) (1995) 321–358.[8] M. Elvang-Goransson, A. Hunter, Argumentative logics: Reasoning with classically inconsistent information, Data Knowledge Engineer-ing 16 (2) (1995) 125–145.[9] S. Gillispie, C. Lemieux, Enumerating Markov equivalence classes of acyclic digraph models, in: J. Breese, D. Koller (Eds.), Proceedings ofthe Seventeenth Conference on Uncertainty in Artificial Intelligence, Morgan Kaufmann Publishers, 2001.[10] P.M.-R. II, U. Chajewska, Aggregating learned probabilistic beliefs, in: J. Breese, D. Koller (Eds.), Proceedings of the Seventeenth Conferenceon Uncertainty in Artificial Intelligence, Morgan Kaufmann Publishers, 2001.[11] F.V. Jensen, Bayesian Networks and Decision Graphs, Springer-Verlag, 2001.[12] P. Krause, S. Ambler, M. Elvang-Gøransson, J. Fox, A logic of argumentation for reasoning under uncertainty, Computational Intelli-gence 11 (1) (1995) 113–131.S.H. Nielsen, S. Parsons / Artificial Intelligence 171 (2007) 754–775775[13] S.L. Lauritzen, Graphical Models, Oxford University Press, 1996.[14] I. Matzkevich, B. Abramson, The topological fusion of Bayes nets, in: D. Dubois, M.P. Wellman, B. D’Ambrosio, P. Smets (Eds.), Proceedingsof the Eighth Conference on Uncertainty in Artificial Intelligence, Morgan Kaufmann Publishers, 1992.[15] P. McBurney, S. Parsons, Risk agoras: Dialectical argumentation for scientific reasoning, in: C. Boutilier, M. Goldszmidt (Eds.), Proceedingsof the Sixteenth Conference on Uncertainty in Artificial Intelligence, Morgan Kaufmann Publishers, 2000.[16] P. McBurney, S. Parsons, Chance discovery using dialectical argumentation, in: T. Terano, T. Nishida, A. Namatame, S. Tsumoto, Y. Oh-sawa, T. Washio (Eds.), New Frontiers in Artificial Intelligence, in: Joint Japanese Society for Artificial Intelligence 2001 Workshop Post-Proceedings, vol. 2253, Springer-Verlag, 2001.[17] S.H. Nielsen, Reasoning and decision making with multiple autonomous agents, Ph.D. thesis, Aalborg University, 2007.[18] S.H. Nielsen, S. Parsons, Computing preferred extensions for argumentation systems with sets of attacking arguments, in: P.E. Dunne,T.J.M. Bench-Capon (Eds.), Proceedings of the First International Conference on Computational Models of Argument, in: Frontiers in Artifi-cial Intelligence and Applications, vol. 144, IOS Press, 2006.[19] S.H. Nielsen, S. Parsons, A generalization of Dung’s abstract framework for argumentation: AArguing with sets of attacking arguments, in:N. Maudet, S. Parsons, I. Rahwan (Eds.), Proceedings of the Third Workshop on Argumentation in Multi-agent Systems, Future University,Hakodate, Japan, 2006.[20] J. Pearl, Probabilistic Reasoning in Intelligent Systems, Representation & Reasoning, Morgan Kaufmann Publishers, 1988.[21] D.M. Pennock, M.P. Wellman, Graphical representations of consensus belief, in: K. Laskey, H. Prade (Eds.), Proceedings of the FifteenthConference on Uncertainty in Artificial Intelligence, Morgan Kaufmann Publishers, 1999.[22] J.L. Pollock, Cognitive Carpentry: A Blueprint for How to Build a Person, MIT Press, 1995.[23] M. Richardson, P. Domingos, Learning with knowledge from multiple experts, in: T. Fawcett, N. Mishra (Eds.), ICML 20, AAAI Press, 2003.[24] S. Saha, S. Sen, A Bayes net approach to argumentation based negotiation, in: ArgMAS 1, Springer-Verlag, 2004.[25] G.R. Simari, R.P. Loui, A mathematical treatment of defeasible reasoning and its implementation, Artificial Intelligence 53 (1992) 125–157.[26] T. Verma, J. Pearl, Equivalence and synthesis of causal models, in: L.K.J.L.P. Bonissone, M. Henrion (Eds.), Proceedings of the Sixth Confer-ence on Uncertainty in Artificial Intelligence, Elsevier Science Publishing, 1991.[27] G. Vreeswijk, Bayesian inference and defeasible reasoning: Suggestions for a unified framework, working paper, Department of ComputerScience, University of Utrecht, 1999.[28] G. Vreeswijk, H. Prakken, Credulous and skeptical argument games for preferred semantics, in: M. Ojeda-Aciego, I.P. de Guzmán, G. Brewka,L.M. Pereia (Eds.), Proceedings of the Seventh European Workshop on Logic in Artificial Intelligence, in: Lecture Notes in ComputersScience, vol. 1919, Springer-Verlag, 2000.[29] G.A.W. Vreeswijk, Abstract argumentation systems, Artificial Intelligence 90 (1) (1997) 225–279.[30] G.A.W. Vreeswijk, Argumentation in Bayesian belief networks, in: ArgMAS 1, in: Lecture Notes in Artificial Intelligence, Springer-Verlag,2004.