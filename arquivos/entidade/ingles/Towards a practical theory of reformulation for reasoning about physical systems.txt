Artificial Intelligence 162 (2005) 145–204www.elsevier.com/locate/artintTowards a practical theory of reformulationfor reasoning about physical systemsBerthe Y. Choueiry a,∗, Yumi Iwasaki b, Sheila McIlraith ca Constraint Systems Laboratory, Department of Computer Science and Engineering,University of Nebraska-Lincoln, Lincoln, NE 68588-0115, USAb Woodinville, WA, USAc Department of Computer Science, University of Toronto, Toronto, Ontario, Canada M55 3H5Received 20 November 2001; accepted 14 November 2002Available online 15 December 2004The authors would like to dedicate this article to the memory of Robert S. Engelmore. He was a long-time friendand senior colleague of the authors. He was also an important contributor to the initial discussion group at KSLthat eventually lead us to write this article. We dearly miss him and regret that he did not live to read this productof the many discussions we had with him.AbstractReformulation is ubiquitous in problem solving and is especially common in modeling physicalsystems. In this paper we examine reformulation techniques in the context of reasoning about phys-ical systems. This paper does not present a general theory of reformulation, but it studies a numberof known reformulation techniques to achieve a broad understanding of the space of available refor-mulations. In doing so, we present a practical framework for specifying, classifying, and evaluatingvarious reformulation techniques applicable to this class of problems. Our framework provides theterminology to specify the conditions under which a particular reformulation technique is applica-ble, the cost associated with performing the reformulation, and the effects of the reformulation withrespect to the problem encoding. 2004 Elsevier B.V. All rights reserved.Keywords: Abstraction; Reformulation; Approximation; Reasoning about physical systems* Corresponding author.E-mail addresses: choueiry@cse.unl.edu (B.Y. Choueiry), Yumi_iwasaki@hotmail.com (Y. Iwasaki),sheila@cs.toronto.edu (S. McIlraith).0004-3702/$ – see front matter  2004 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2004.01.004146B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–2041. IntroductionReformulation plays an important role in various intellectual activities and is ubiqui-tous in reasoning about physical systems. Reformulation improves the effectiveness of aproblem-solving process by recasting a problem into a new one that is tailored to a giventask. There are a number of reformulation techniques and the selection of reformulationtechniques must be carried out in the context of a problem-solving task.In this paper we examine the role of reformulation in reasoning about physical systems.To achieve a broad understanding of the space of available reformulations, we study anddiscuss a number of known reformulation techniques. All the methods discussed in thispaper have been presented in the literature, and some are in common use in science andengineering.Our investigations yield two important contributions. First, they provide the first prac-tical framework for a comprehensive description of reformulation techniques. This frame-work, based on our analysis of the field, allows us to characterize reformulation techniquesincluding their applicability conditions and effects along with the assumptions and implicitevaluation criteria underlying them. Such a framework is necessary for the future develop-ment of an automatic mechanism to select a reformulation technique that is appropriate fora task. Second, our study produces a survey of reformulation techniques in reasoning aboutphysical systems. Our framework was essential for undertaking this comparative analysis.Indeed, without a uniform framework from which to characterize reformulation techniquesas diverse as we have considered, a meaningful comparison would have been impossible.Informally, we define reformulation to be a transformation from one encoding of aproblem to another, given a particular problem-solving task. A problem-solving task isaccomplished by the application of a select sequence of reformulations to an initial problemencoding to produce a final encoding that directly addresses the task. We use the termreformulation to subsume the notions of abstraction and approximation, while avoidingthe implication that such a transformation necessarily generalizes or simplifies the domaintheory.Given a reasoning problem, one may choose to reformulate for any of the followingreasons:1. Engine-driven problem re-encoding: There may not be a method to solve the givenproblem as is. In such a case, one may choose to reformulate the original problemby approximating it by another problem (or a set of problems) for which a solutionmethod is known. For example, if the original problem requires one to solve a set ofnonlinear differential equations, engineers often substitute the original problem with aset of linear differential equations that approximate the nonlinear equations.2. Performance-driven problem re-encoding: The given problem may be too expensive tosolve by an available method, forcing one to reformulate into a similar problem that iseasier to solve. For example, if a given set of linear differential equation is too large tosolve with available computational resources, one may choose to aggregate to producea less detailed but smaller model.3. Supporting cognitive insight: One may choose to reformulate in order to gain cognitiveinsight into the problem or solution space. Mapping from Cartesian coordinates toB.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204147polar coordinates, mapping a time domain to a frequency domain, reformulating theequations of an electric circuit in terms of the voltage and current into ones in terms ofpower are all examples of reformulation that are sometimes performed to make certainaspects of the system behavior easier to detect and/or analyze.Note that a given reformulation can serve multiple purposes. A reformulation methodapplied to reduce the cost of solution may also improve one’s understanding of the overallbehavior of a complex problem.For the purposes of this paper, we have elected to focus on a specific class of prob-lems, in an effort to develop a framework for characterizing reformulation methods withsufficient detail to be useful to practitioners and researchers alike. In particular, we exam-ine reformulation techniques that can be exploited to reason about physical systems. Thelong-term goal of our research is to develop an automatic task-driven capability that se-lects and applies appropriate reformulation techniques in the course of problem solving.An essential tool towards this ultimate goal is a practical framework for characterizingand evaluating the merits and relevance of various reformulation techniques. This paperproposes such a framework with respect to the restricted class of problems we describedabove. The motivation for developing such a framework came from the observation thatmuch of the previous work on reformulation (including abstraction and approximation)was not sufficient for our purpose. It was either too specific to account for the large va-riety of reformulation methods commonly used in reasoning about physical systems, ortoo general for characterizing them in sufficient details to allow informed selection amongthem. The framework we present provides a significant step towards our long-term goalby defining general criteria for understanding the properties and assessing the merits ofvarious reformulation procedures. More specifically, the framework provides the means toidentify the conditions under which a reformulation is applicable, the cost associated withperforming the reformulation, and the effects of the reformulation both with respect to theproblem encoding and with respect to the accuracy and cost of reasoning.The paper is organized as follows. Section 2 discusses the motivations behind our en-deavor and its scope. Section 3 describes the processing stages of reasoning about physicalsystems to define the context for the types of reformulation we are interested in. The frame-work for characterizing reformulation techniques is introduced in Section 4, where weprovide a detailed description of the framework itself and present a set of evaluators forassessing the effects of reformulation. Section 5 uses the framework to actually analyzea number of known reformulation techniques. Section 6 discusses related work. Finally,Section 7 summarizes our contributions and outline directions for future research.2. Motivation and scopeIn this section, we first state the motivations of this paper, then we justify our reasons forusing the term reformulation in an effort to clear up the ambiguity of previous terminology.148B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–2042.1. MotivationReformulation is ubiquitous in reasoning about complex systems. Analyzing the be-havior of a complex electro-mechanical device in full detail, taking into account all itselectrical, mechanical, and thermal aspects is too costly and unnecessary for most purposes.Engineers and scientists are accustomed to reformulating repeatedly the mathematicalmodel of a complex physical system in order to reduce the complexity of analysis, tofacilitate the explanation of the problem or a solution to others, or often, even to be able toanalyze the system at all. There are numerous known techniques for reformulation that areused by engineers and scientists. AI literature also abounds with such techniques. A libraryof reformulation techniques and an ability to select from it the most appropriate techniquefor a given problem would greatly enhance the power of a program for reasoning aboutphysical systems.To compile such a library or to enable informed selection from it, we need a systematicway to compare and evaluate reformulation techniques, which the field currently lacks.This lack may be due to the fact that many commonly used reformulation techniquesare informally executed tools in engineers’ ‘bag of tricks’. A more significant problemin establishing a systematic classification of reformulation techniques is their inherent di-versity; they apply to different forms of models, at different stages of problem solving, andto achieve different goals. We need, as a first step, to articulate a vocabulary of attributesto describe various key aspects of reformulation techniques. This vocabulary needs to beinformative enough to enable selection of appropriate techniques for different goals at dif-ferent stages of problem solving.The understanding and classification of reformulations have been relatively well-addressed in the literature. While some researchers have focused on specific domains suchas theorem proving [25], planning [13,34], or model-based reasoning [33,39], others havetried to construct general theories in order to formalize the general properties of reformu-lations [4,10,22]. We discuss these contributions in Section 6. While these previous worksmentioned above explored new grounds and established key properties of certain types ofreformulation techniques, we have found them to be too general and insufficient to char-acterize many of the techniques common in reasoning about physical systems. They aretypically concerned with only one aspect of the reformulation: its effects on the solution,the models, the proof trees, the theorems, or the computational cost. They also do not applyto models in the form of mathematical equations, which limits their usefulness in reasoningabout physical systems.In surveying various abstraction and approximation techniques in kinematics theoryof rigid solid objects (KRSO), Davis also observes that abstraction and approximationin KRSO do not fit any one elegant metatheoretic structures such as those proposed byGiunchiglia and Walsh, Nayak and Levy, or Weld. He concludes by stating that he does notsee any “overarching metalogical structure that sheds useful light on the relation betweenthese approximation techniques” and conjectures that “none will be found in many domainsof physical reasoning” [5]. While we agree with Davis’s conclusion that there is no cleanmeta-theory of reformulation in reasoning about physical systems, we do believe that itis possible to provide a framework that enables a systematic description of many aspectsB.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204149of reformulation techniques that are critical in their selection. We also believe that such aframework is a pre-requisite for compiling a library of reformulation techniques.This paper is our attempt to formulate such a framework for systematic description ofreformulation techniques to enable their comparison and evaluation with respect to givenproblems. Such a framework will not take the shape of an overarching metatheory of re-formulation. Instead, the goal is to characterize reformulation techniques in such way thatone can select a technique that is appropriate for a given problem. We do not offer a formaltheory of reformulation with definitions and theorems. Instead, we discuss what aspects ofreformulation techniques and the context in which they are used must be made explicit ifwe were to be able to compare them and make an intelligent choice among them in thecourse of reasoning about physical systems. The goal is more modest than a constructionof a “grand-unified” theory of reformulation, but hopefully more realistic and, ultimately,more useful. This paper proposes a structure for presenting a reformulation technique witha view towards compilation of a library of a broad range of reformulation techniques andenabling intelligent selection. Furthermore, we identify the dimensions of a problem thatare relevant for the selection of the reformulation and provide the terminology to describethe effects of its application to the problem. In presenting this framework, we also hopeto shed new light on the confusion surrounding reformulation and to serve a pedagogicalpurpose by explicating a number of reformulation techniques from a unified perspective.2.2. ScopeThis paper focuses on reformulation techniques in the context of reasoning about thebehavior of physical systems. We restrict ourselves to problems where the behavior of thephysical system in question is expressible as a set of lumped-parameter continuous models,containing algebraic or differential equations, though reasoning need not be limited todirect manipulation of equations. We require that the task be motivated by a specific query,thus constraining the necessary computational machinery to solve the task. Finally, weconsider only reformulations of a specific problem instance as opposed to the constructionof gross properties of a population of instances.1In Section 1, we have informally defined reformulation as “transformation from one en-coding of a problem to another”. Review of the literature on reformulation reveals that inaddition to transformation, two other general approaches to reformulation exist, namely se-lection and formulating anew. When an existing encoding proves lacking in some respect,instead of transforming the original, one could formulate a new encoding from scratch orselect another formulation from a set of existing alternatives. In general, since there mustbe a way to use the knowledge of an encoding’s shortcomings to guide the process of cre-ating or selecting an alternative, these three approaches do not represent totally orthogonaldimensions in reformulation. Rather, they represent different points in the whole spectrumof formulation techniques and are likely to share many technical issues.1 The entire field of statistics is devoted to the problem of producing and using higher-level descriptions of alarge population of instances. Though Amador and Weld discuss this kind of an aggregation method as a type ofreformulation [2], we will not consider such methods in this paper.150B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204The apparent differences among transformation, selection, and new formulation tend tobe more a matter of focus of the work. Reformulation through selection presumes that thereexists a set of alternative formulations to begin with. The works that focus on selectiongenerally do not address the problem of generating the alternatives [1,36]. Techniques thatformulate anew focus on the problem of constructing a model in the first place. Whiletransformation presumes that there exists at least one formulation to start with, the processof altering an existing encoding can require much of the same type of knowledge needed forconstructing a new one. Both selection and transformation could be part of the process of anew formulation: In some approaches, the construction of a new model involves generationof possible candidates models followed by the selection among them [6]. In others, thegeneration of an initial model is followed by the transformation if the initial model isfound to be optimizable with respect to some criteria [20,21].While we recognize that selection and formulating anew are viable approaches to re-formulation, we focus, in this paper, on reformulation as a transformation. In practice,reformulation by transformation is an important, if not the most important, category ofreformulation techniques, as most of the abstraction and approximation techniques com-monly used in engineering fall in this category. Reformulation via transformation is fre-quently the only alternative in practice. In the real world, one often does not have theluxury of multiple existing models or the necessary resources to formulate a new modelfrom scratch.2.3. On the terminologyIn the previous attempts to capture the nature of reformulation and its effects, the words‘abstraction’ and ‘approximation’ have commonly been used to refer to various instancesof reformulation. Based on our observation that the words abstraction and approximationare not appropriate to designate all reformulation procedures that are of interest, we chooseto use the term ‘reformulation’ as a general term that subsumes abstraction and approxi-mation.Abstraction and approximation.It is rather difficult to clearly distinguish between ab-straction and approximation, and the notions of generalization and simplification that theyimply. Both ‘abstraction’ and ‘approximation’ imply some reduction in the complexityof the representation and of the reasoning process. In other words, they are supposed to‘simplify’ the problem in some way. ‘Abstraction’ is often used to indicate some structuralmodifications of a representation, whereas approximation refers to differences in numericalvalues or other mathematical quantities [5]. Abstraction is thought to ‘simplify’ a descrip-tion by dropping certain information, retaining only general characteristics, at the expenseof introducing some ambiguity. ‘Approximation’, in contrast, implies a replacement of adetailed, precise and accurate model2 with one that is less accurate but is easier to computewith. In both cases, the difficulty in producing a precise yet general definition of the term2 In logic, model is used to refer to an interpretation of a theory. This is not the meaning we intend in thisdocument. By model we mean a collection of statements that are a (possibly non-mathematical) representation ofa given physical situation useful for automated analysis.B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204151lies in defining the meaning of ‘simpler’. What is simpler almost always depends on whataspect one is focusing on. For example, consider the case of a periodic square function. Itis sometimes used to approximate a sine function of the same periodicity, since the formerranges over only two values instead of the continuum of values for the latter. However, thesquare wave is in fact much richer and more complex in terms of harmonics than the sinewave and, in this sense, the sine is an approximation of the square function.Simplification. Most work on abstraction and approximation techniques does not makeexplicit the precise measure of simplicity used. Even in those cases where the notion ofsimplicity is precisely defined, the definitions are too narrow to account for the variousways a reformulated problem differs from the original one. Rickel and Porter [28,29] definesimplicity in terms of the number of variables involved in the mathematical equations of amodel: the fewer variables a model has, the simpler it is. Nayak’s definition relies on twothings; subset relations among the causal relations implied by model fragments and theapproximation relations among model fragments [20]. Neither of these definitions allowsone, for example, to compare two mathematical models involving the same set of variables,one being a nonlinear model and the other a linearized approximation of the first.Generalization. Another important change in a model that is brought about by abstrac-tion or approximation, though it is often related to the notion of simplicity, is generality,which is the range of phenomena captured by a model. Comparing the classical dynamicsand relativistic dynamics will help illustrate the subtlety of the notion of simplicity and itsrelation to that of generality. The classical dynamics is a good approximation of the rela-tivistic dynamics but only when the speeds of objects do not approach the speed of light(i.e., when v/c (cid:2) 1). In other words, the classical dynamics is less general than the other.These difficulties in defining precisely what is abstraction or approximation have led usto use instead the term ‘reformulation’. Rather than classifying examples of reformulationas abstractions, generalizations, or approximations, we need to understand fully and artic-ulate clearly what happens when a model is transformed by making explicit the effects ofreformulation on specific aspects such as the representation, the computational efficiency,cognitive transparency and the result.3. Reasoning about physical systemsBefore discussing various reformulation procedures, we must set the stage by describingthe problem-solving context in which we wish to evaluate such procedures. As we statedearlier, we concentrate on the types of physical systems that can be described with lumped-parameter hybrid models containing algebraic and ordinary differential equations. In thissection, we describe the various processes that are executed in reasoning about physicalsystems, and we illustrate these processes in terms of several examples drawn from theliterature. The purpose of this section is to explicate the context in which we wish to employand evaluate reformulation techniques. Since one of the theses of this article is that suchan evaluation cannot be made in a vacuum, it is imperative that we make the context asexplicit as possible.152B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–2043.1. Stages of modeling physical systemsStarting with a description of the task of interest, we perceive the entire endeavor ofreasoning about physical systems as a progression through the three processing stagesillustrated in Fig. 1, namely: the model, the equation, and the solution processing stages.Task description. Reasoning about physical systems begins with a task description, whichdescribes the problem and establishes the problem solving goal. It consists ofthe following four elements: the domain theory, the scenario, the query, and themodeling assumptions.The domain theory is a corpus of knowledge about the physical world. It con-tains heterogeneous, possibly redundant, descriptions of the physical structureand phenomena of interest, including logical statements, symbolic equations, andnumerical parameters. In the work on compositional modeling [6], the domaintheory is represented in the form of a library of model fragments.In general, any profitable computational effort spent on reasoning about a domaintheory must be motivated by a specific task, where a task can vary from prediction,to explanation, to verification, under a wide spectrum of hypothetical situationsand conditions. We define a task by a combination of a scenario, a query, a domaintheory, and a set of modeling assumptions.Fig. 1. Reasoning about physical systems. Stages of reasoning and their corresponding processes.B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204153The scenario is a description of a particular problem instance (e.g., a set of systemcomponents and their physical structure, and the initial conditions of the system).The query is an explicit specification of the user’s interests in terms of the vari-ables, and their aspects of interest (e.g., the quantitative or qualitative values,direction of change at specific time points, temporal evolution).The modeling assumptions include assumptions that the problem solver makes inorder to broadly delimit the scope of the answer to the query (e.g., the temporaland physical extent of its coverage, granularity). See [15] for a more detaileddiscussion of modeling assumptions.Model processing. Given a task description, the model building process assembles the rel-evant aspects of the domain theory to produce a model, which is an instantiation ofa subset of the domain theory that is both consistent and sufficient to address thequery. A model at this point often consists of knowledge of the physical structure(components and their topology, for example) as well as knowledge of the rele-vant physical phenomena (including the conditions under which they are active),in contrast to the purely mathematical model of the following stage. Examples ofmodel building process include compositional modeling as in [6,15,20] and themodeling algorithm of TRIPEL [28].This process can be followed by a model reformulation process. Model reformu-lation may involve structural consolidation [40], simplification [21] or expansionof a model through aggregation, replacement, deletion or addition of a descriptionof components or phenomena. Specific examples of reformulation carried out atthis stage are presented in Section 5.1.Equation processing. Equation building produces an equation model either directly froma task description or by extracting mathematical equations from a model describ-ing the behavior of the system. For example, the Qualitative Physics Compiler [7]converts a model expressed in QP Theory [8] into a set of qualitative differentialequations. Once equations are obtained, an equation reformulation process maybe carried out. An equation reformulation is often motivated by a desire to trans-form the present equation model into a form that is easier to compute with or thatis amenable to a particular problem-solving engine.We distinguish between non-equational models and equational ones because thereis a large class of mathematical techniques that operate solely on equations.In fact, most well-known simplification techniques operate on equations. Theyinclude such techniques as dropping insignificant terms, linearizing non-linearequations, aggregating nearly decomposable systems, and reformulating ordinarydifferential equations as qualitative differential equations or qualitative differen-tial equations as causal orderings. Some of these techniques are discussed in detailin Section 5.2.Solutions processing. Equations are given to a solver to produce one or more solutions.Some examples of a solver are QSIM [14] and Matlab®. Once the equations aresolved, a solution reformulation process may subsequently be performed in or-der to make the solution easier to comprehend or to facilitate further reasoning.Examples of such reformulations include categorizing solutions, summarizing asingle solution, summarizing a set of solutions, and explanation generation [11].154B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204As the problem becomes larger and more complex, there is an increasing need tofacilitate understanding of a solution. In Section 5.3, we discuss two such tech-niques.An interesting use of solution reformulation for the purpose of speeding up theoverall problem-solving process is demonstrated by Clancy and Kuipers [3].Clancy and Kuipers interleave QSIM simulation with the aggregation of partialsolutions corresponding to chatter in a qualitative simulation. In so doing, theysignificantly improve the overall performance of QSIM on some problems.We note that reasoning need not necessarily proceed through every stage defined above.It is common for a problem solver to omit a stage or to loop over stages. For instance, onemay go from a task description directly to the Equation Processing stage, or from the ModelProcessing stage directly to the Solution Processing stage. QPE [9] is such an examplebecause it produces a solution directly from a model without explicitly generating a set ofequations. A problem solver may also loop through one or more of the stages. Ling andSteinberg in [16] describe a three-step procedure for automated modeling that encompassesmodel generation, simulation, and validation while looping over each of these steps (innerloop) and over the whole process (outer loop). In the example of solution reformulationmentioned above and discussed in Section 5.3.2, Clancy and Kuipers [3] loop over thesolution building and solution reformulation processes. Another example of such loops canbe found in the work on DME [17] for modeling device behavior. DME cycles through thestages of Equation Processing and Solution Processing during simulation as the operatingconditions change and the model used for simulation must be updated.Earlier, we have informally defined reformulation to be a transformation from one en-coding of a problem to another. Having described the stages of modeling physical systemsin which to study reformulation, we are now ready to define reformulation more narrowlyin this context. In the process of reasoning about physical systems as we have just outlined,what we regard as reformulation is a transformation of an encoding at one stage to anotherencoding at the same stage. Thus, such reformulation does not change the type of formal-ism of the encoding but does change the content in such a way that the change is not a mereconsequence of making explicit what is implicit in the original.3 Fig. 1 reflects this narrowdefinition of reformulation as each processing stage consists of a building step followed bya reformulation step. We believe that restricting the context and narrowing our field enablesus to lay out a more concrete and practical framework for informed comparison of refor-mulation techniques which are relevant in reasoning about physical systems than would bepossible otherwise if we adopt a more general definition of reformulation. In the remainderof this paper, we will refer to mechanisms that carry out a building step in any processingstage of Fig. 1 as “solution engines” to distinguish them from reformulation engines. We3 If we regard each encoding as a logical theory or as a model in the model theoretic sense, then the twoencodings would be two distinct and logically incompatible theories or models. It is open to discussion whethersuch “models” of physical systems as those we studied in this paper should be interpreted as theories or modelsin the model theoretic sense. However, such a distinction is not relevant to those of us actually trying to model aphysical system.B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204155use the term ‘engine’ broadly to include anything from an algorithm, to a special-purposesimulation program, to a general-purpose solution package such as Mathematica®.3.2. Characterizing reformulationThere are three general aspects in which we will characterize a reformulation technique.First, we must specify the types of problems to which the technique is applicable. Second,we must characterize the impact of the reformulation technique in terms of what aspectsof a problem it changes and how. Third, we must characterize the reformulation as a com-putational process. The first and second aspects are rather definitional as they describe theapplicability of the procedure and its raison d’être. The third aspect is more descriptive inthe sense that it represents a set of ways to evaluate the procedure as a computational tool.We now briefly introduce three examples of reformulation techniques that are discussedin more detail in Section 5. The three examples are model simplification by Nayak andJoskowicz, aggregation of nearly decomposable systems by Simon and Ando, and behaviorabstraction for explanation by Mallory. We will then highlight the key features of thesetechniques in order to motivate the framework presented in Section 4 for characterizingreformulation.• Nayak and Joskowicz propose a model reformulation technique that simplifies a com-positional model of a device [21]. Their reformulation technique simplifies a modelby replacing the model fragments in a given model by alternative simpler fragmentswhenever possible. The result is a model that has the same explanatory power as theoriginal but is provably most parsimonious.• Simon and Ando describe a technique for aggregating a system of linear ordinarydifferential equations to produce a smaller system [32]. The technique only applies toa system that consists of weakly interacting components such that interactions withineach component are much stronger than those among components. Their techniqueproduces a smaller system of equations that describes the mid- to long-term behaviorof the original system.• Mallory et al. propose to summarize the results of the qualitative simulation of a phys-ical system in order to help users recognize ‘basic patterns of behavior’ [19]. Theirreformulation procedure summarizes the behavior of the system by generating a be-havior graph that retains only those aspects of the behavior tree relevant to the query.The result is a smaller, more abstract tree that retains the essential features that arerelevant to the query.While all the three techniques aim to simplify a formulation, they differ from each otherwith respect to important aspects, such as the contexts to which they are applicable and theresults they produce. Below, we identify the dimensions for characterizing them that arecritical for the practical use of these techniques.3.2.1. What problem does the reformulation apply to?One of the fundamental assumptions of our analysis is that reformulation must be mo-tivated by a task, and furthermore, that the task itself must be driven by a specific query.156B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204Each of the three example techniques is motivated by a question about a quantity (or a setof quantities) associated with a system. Each however deals with a different formulationof such a query since each technique applies at different stages of reasoning about phys-ical systems of Fig. 1. Nayak and Joskowicz’s technique applies at the Model ProcessingStage to reformulate a conceptual model. Simon and Ando’s technique applies at the Equa-tion Processing Stage to produce a different set of equations. Mallory’s technique appliesat the Solution Processing Stage and produces a more concise description of a behavior.Thus, our framework requires that the definition of a problem include a specification of itsformulation as well as the query.3.2.2. What does the reformulation do?The objective of reformulation is to change some aspect of the formulation of the orig-inal problem. Thus, in order to characterize a reformulation technique, we must specifyprecisely the features of the problem that are affected and the ways in which they arechanged.While the three examples above all purport to affect the simplicity of a formulation,the precise definition of simplicity is different as the problem formulation is different ineach case. In Nayak and Joskowicz’s example, the notion of simplicity is based on thecausal-approximation relation. A model A is simpler than a model B if and only if the setof causal ordering relations implied by model A is a subset of those implied by model B.In Simon and Ando’s example, simplicity is defined in terms of the number of equationsand variables. In Mallory’s case, simplicity can be measured by the number of links andnodes, and the labels of those nodes in a behavior tree. Thus, our framework requires thedefinition of a set of evaluators to specify the features of a problem (i.e., formulation andquery) that are modified by the reformulation technique.Furthermore, in order to fully specify the effects of reformulation on problems, we mustalso specify how the affected features are to be compared. Comparators are specificationsof such means of comparison. Quite often, especially when the affected features are numer-ical values or sets, comparators are straightforward numerical (<, =, >) or set (⊃, =, ⊂)comparators. In the three examples above, the features affected by reformulation can becompared in this manner. In Nayak and Joskowicz’s case, the comparator is a subset re-lation over the sets of causal relations implied by models. In Simon and Ando’s example,the numerical comparator, <, is sufficient to compare the number of variables and equa-tions. In Mallory’s example, subset relations over the links, nodes, and labels are used tocompare the features. In other words, in all three cases, the notion of simplicity that eachreformulation technique aims to achieve can be precisely defined by specifying evaluatorsto measure some features of the problem and comparators to compare these measures.When a reformulation technique is defined as a mathematical function between twosets, the reformulation process can be characterized by the nature of the function suchas injective, surjective, one-to-one, etc., and two or more such processes compared forstrength or weakness, see [10].3.2.3. Characteristics of the reformulation technique itselfAside from describing a reformulation technique in terms of what it does, one needs tobe able to characterize it as a computational process using standard criteria. ComputationalB.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204157complexity is one such criterion that is almost always provided by the authors of suchtechniques. In all our three examples, the procedures are tractable with respect to the classof problems that satisfy the conditions specified by the procedures. In other cases, evalu-ation of the reformulation technique in terms of the computational complexity is given inslightly different forms, such as best/worst/average case with respect to a simulated/naturalpopulation of a certain size.Although the computational complexity is often provided when reformulation tech-niques are proposed, there can be a number of alternative ways to characterize thesetechniques. From the perspective of a person looking for a suitable tool for one’s problemat hand, the availability of the code for applying the technique is often an issue in practicalsettings. If the code for carrying out reformulation is available in several commercial pack-ages, their price or their ease of use could be points of evaluation. As there can be as manyangles from which to evaluate reformulation techniques as there are people who wish touse them to solve problems, this can only be a non-exhaustive set of evaluators.In summary. For practical purposes a reformulation technique must be described alongthree aspects:1. The class of problems to which it applies.2. What it does, in terms of what features of problems it targets and how it changesthem.3. Its characteristics and cost as a computational tool.Our framework provides the means to define a problem along with several types ofevaluators and comparators to characterize those aspects of the reformulation process. Thefollowing section formally introduces the components of our framework.4. Framework for characterizing reformulationIn this section we introduce a framework and a terminology for characterizing and eval-uating reformulation techniques. Section 4.1 introduces the components of the frameworkand reduces the selection of a sequence of reformulations to a planning task. Finally, Sec-tion 4.2 introduces the attributes necessary to characterize a reformulation technique, sothat selection can be performed.4.1. Components of the frameworkReformulation replaces an original problem by a new one, as shown in Fig. 2. We dis-tinguish two primary components, the problem and the reformulation, and two compositecomponents, the process and the strategy, obtained from composing the former two.4.1.1. ProblemWe define a problem Pi as a three-tuple:Pi = (cid:5)Queryi, Formi, Assmpti(cid:6).158B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204Fig. 2. Reformulation.• Queryi specifies the question of the user, the one we are trying to answer by manip-ulating the formulation. The query motivates the whole endeavor.• Formi denotes the formulation, i.e., the conceptualization of the domain of, for in-stance the studied physical artifact. This amounts to a list of objects, and their interre-lationships (e.g., functions and relations). Depending on the particular stage of Fig. 1 towhich the reformulation method is applied, the particular formulation can be a concep-tual model (Model Processing Stage), mathematical equations (Equations ProcessingStage), or even solutions (Solution Processing Stage).• Finally, Assmpti designates the conditions under which the formulation is valid, e.g.,the domain of applicability and the temporal granularity.According to this terminology, the task description defined in Section 3.1 and Fig. 1 isa problem Pi where:• Queryi is the query in the task description,• Formi is the domain theory and scenario, and• Assmpti is the set of modeling assumptions.4.1.2. Reformulation techniqueOur ultimate goal is to be able to automatically select a suitable reformulation techniquefrom among a collection of techniques. One step towards this goal is to articulate, for eachreformulation, its applicability conditions and algorithmic steps.A reformulation technique is applied to an original problem P1 to produce the reformu-lated problem, P2, as shown in Fig. 2. By examining a wide collection of reformulationtechniques, we have found that reformulation techniques typically modify the problemencoding only: the query and assumptions often remain unchanged before and after refor-mulation. Counterexamples do exist such as the ones discussed in Sections 5.2.1 and 5.2.3where assumptions are reformulated. We describe the reformulation technique as a tuple:R = (cid:5)Proc, Cond(cid:6),where:• Proc denotes an effectively computable procedure of which the input is P1 and theoutput is P2. For example, the approximation of the behavior of a nearly-decomposablesystem by aggregation, discussed in Section 5.2.1 is one instance of such a procedure.• Cond denotes the applicability conditions. For example, the aggregation of nearly-decomposable system of Section 5.2.1, requires that Form1 be a self-contained setB.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204159of nearly-decomposable linear ordinary differential equations and that the system bestable.It must be noted that Cond is a set of necessary conditions to be satisfied by P1 forthe reformulation to be technically applicable. However, whether or not R is an appropri-ate reformulation to perform depends on the goal of reformulation, which is discussed inSection 4.1.3. If, for example, the goal is to obtain more precise values for the variablesin the mid-term behavior of the system than can be produced from the aggregated sys-tem, aggregation of the nearly-decomposable system would not be an appropriate choiceof the reformulation method, though the procedure is technically applicable. In practice,sometimes it is not known whether Form1 satisfies Cond because some parameter valuesare unknown or even the precise form of the equations is unknown. Even in such cases,one sometimes applies the reformulation method. The validity of the results thus producedwill depend on the degree to which Cond is satisfied by Form1. In such cases, Condbecomes the assumptions Assmpt2 underlying Form2. Such conditional reformulationcan still be quite useful in providing insight into the shape of the problem space. The car-icatural reasoning discussed in Section 5.2.3 demonstrates the usefulness of conditionalreformulation.In Fig. 3 the reformulation R is illustrated as a transition between nodes representingtwo problems P1 and P2.As mentioned in the introduction, the decision to perform a reformulation could bemotivated by the availability of a suitable solution engine and its performance for solv-ing a problem.4 For example, if we have a slow but general-purpose solver for OrdinaryDifferential Equations (ODEs) and a high-performance implementation of a numericalsimulation algorithm that works only with systems of linear equations, we might re-formulate an original nonlinear system of equations, which would have to be solvedwith the general-purpose solver, into a linear one that can be solved by the fast integra-tor.A solution engine is applied to a problem to produce a result as an answer to the query.There could be multiple engines at one’s disposal to solve the original or reformulatedproblems. Alternately, there could be none, when the problem is too difficult. Further, wemay use the same means of solution before and after reformulation since the reformulationof a problem, for instance by decomposition, can result in an important improvement ofperformance for the same solution engine. Aggregation, discussed in Section 5.2.1, illus-trates this situation.Fig. 3. Reformulation process.4 In this paper, we do not address reformulations that apply to the engine itself, as proposed in [10], becausesuch reformulations do not seem to arise in the class of problems we address.160B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–2044.1.3. Process and strategyA problem, a reformulation technique and the problem resulting from applying the re-formulation technique to the problem compose a reformulation process. Fig. 3 illustratedsuch a process as a transition between two nodes.A single reformulation process can be understood as one step towards providing ananswer to the query. A sequence of reformulations, commencing with the initial problemand possibly including one or more engines, constitutes one strategy for addressing a task.The execution of a strategy constitutes problem solving.Thus, we define a strategy Si to be a sequence of reformulations, (cid:5)Ra, . . . , Rx (cid:6) thatis applied to an original problem P1. The path (cid:5)P1, Ra, P2, . . . , Rx , Pi (cid:6) in Fig. 4 is anexample of the execution of such a strategy. Any subsequence, Sk, of Si , starting at P1and stopping at any intermediary problem Pk , between P1 and Pi , is also a strategy, and iscalled a sub-strategy of Si .We perceive reasoning about physical systems to proceed according to processes iden-tified in Fig. 1. According to this figure, the content of the initial input, i.e., the taskdescription, is gradually modified by a combination of any number of processes culminat-ing in an answer to the query. Given our definition of reformulation, any of these processesis a reformulation. The stage of processing distinguishes whether the reformulation is ap-plied to a collection of model fragments, an equational model, or to one or more solutions.Reasoning about physical systems is thus a successive application of reformulation proce-dures that transforms an initial problem encoding.Problem solving as plan execution. Problem solving involves the successive applicationof reformulation procedures to an initial problem encoding to produce a final problem en-coding. Clearly there could be multiple sequences of reformulations that could be appliedto address the problem-solving task, as illustrated in Fig. 5. Identifying such sequences ofreformulation procedures can be viewed as a planning problem in which the states are prob-lem encodings, the transitions (or actions) are reformulations, and the plans are strategies.Fig. 4. Strategy.Fig. 5. Problem solving is plan execution.B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204161Hence, problem solving becomes an execution of the selected plan. In Fig. 5 we illustratea tree of four alternative strategies.In practice, as for planning, resources may be limited, and one may want to associatea utility or objective function to the problem-solving task. We expect the user to providethe goal of the problem-solving task in terms of a goal test and of an objective functionthat specifies the importance of some desired features of the problem and the resourcesavailable. In this context, selecting an optimal plan or strategy becomes a multi-criteriaoptimization problem.4.2. Evaluating and comparing componentsSection 4.1 defines the primary components (i.e., problem and reformulation technique)and the composite components (i.e., process and strategy) of our framework. To articulatethe goal driving the above-mentioned planning process, we identify the features of thesecomponents relevant for selecting reformulation techniques and characterizing their ef-fects. These features are divided into sets, relative to the components of our framework.The sets of features are meant to be incrementally augmented and refined as one explores,defines, and proposes new reformulation techniques. There are two main categories of sets:1. Evaluators, denoted Evals, evaluate some features of one component or a combina-tion of components of the framework.2. Comparators, denoted Compars, assess the change due to reformulation by compar-ing the values of the evaluators.The values returned by the evaluators and comparators are not necessarily quantitative;they could be qualitative or logical.4.2.1. EvaluatorsIn order to characterize a reformulation technique, we must first define measures orevaluators that capture relevant characteristics of the problem, the reformulation techniqueand their inter-relationships.Given a reformulation R = (cid:5)Proc, Cond(cid:6), and original problem Po, and the resultingreformulated problem Pr , we distinguish four such sets of evaluators as illustrated in Fig. 6.We distinguish four sets of such evaluators, Evalsprob, Evalsref, Evalsp+r, andEvalsp+r+p corresponding to evaluators that assess, respectively, aspects of a problem,a reformulation technique, and a combination of an original problem and a reformulationtechnique and finally a reformulation process. We introduce also a fifth set of evaluatorsFig. 6. Evaluators and the components to which they apply.162B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204Evalsstrat to be computed from the initial four. Below we explain and provide examplesfor each set of evaluators.1. Evalsprob(Pi) is a set of measures to evaluate some characteristic of a problem Pi .Pi could be the original problem Po or the reformulated one Pr . In the most generalcase, the elements in this sets can be defined with respect to any of the three elementsof the problem, i.e., the formulation, query and assumptions. An example of an eval-uator that assesses the problem as a whole (i.e., formulation, query and assumptions)is the complexity class of the problem (e.g., NP, PSPACE, and EXPSPACE). As wementioned in Section 4.1.2, we have found that in practice the query and assumptionsoften remain unchanged before and after reformulation, and that most evaluators arefunctions applied exclusively to the formulation of Po.The evaluators in the set Evalsprob can provide an assessment of some quantitativeaspects of the problem (e.g., size) or of its logical properties (e.g., compactness, com-pleteness, and decidability). They can also address qualitative aspects of the problem(e.g., complexity class, or how ‘close’ the formulation is from answering the query).For a system of equations, an example of a quantitative evaluator is the number ofequations or their degree, or the number of variables; an example of a qualitative eval-uator is adherence of the equations to some canonical form. Other evaluators of theformulation that appear in the literature include scope [38] (which is the range ofphenomena that it can describe), expressiveness, syntactic form, simplicity, general-ity, relevance, absence of irrelevant information, and language restriction to familiarterms [37].It is important to define an evaluator in sufficient detail. In the case of simplicity,for example, we must define the specifics of how it is measured (e.g., the number ofvariables/equations in a equation set, or the number of components in a model). Someof the evaluators in Evalsprob are dedicated to assessing the quality of the answer tothe query as it is made explicit in Formi. The result is often a numerical, quantitativevalue but it can also be a qualitative (e.g., an interval) or a logical one (e.g., truthor negation of a sentence). It can also be a description of a behavior over time, orsets of partials or global solutions. Examples of such evaluators are the soundness ofthe answer and its precision. These are typically the evaluators to use in the test thatdetermines whether the goal test of the planning process of Section 4.1.3 is achieved.2. Evalsref(R) is a set of measures to evaluate some characteristic of the reformulationtechnique Rt . Examples include but are not limited to:(a) the size of the code that implements the procedure,(b) the programming language it is written in,(c) the price of the commercial software,(d) its hardware and software requirements and interfacing capabilities, and(e) the type and value of human expertise required for exploiting it.3. Evalsp+r(R, Po) includes functions that assess the behavior of the reformulationtechnique relative to a given problem. A typical such evaluator is the computationalcomplexity of the procedure Proc when applied to the problem, and that of verifyingthe conditions of the reformulation, Cond.B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–2041634. Evalsp+r+p(R, Po, Pr ) is a set of measures that characterizes the reformulationprocess, typically, in terms of the properties of a function (e.g., partial/total, injective,surjective, bijective, or invertible).For example, Struss requires reformulation procedures, which he calls representa-tional transformations, to be surjective and not injective mappings [33]. Giunchigliaand Walsh study procedures that are surjective total functions between two formalsystems [10]. Other examples include the following: homomorphism, isomorphism,theorem increasing, decreasing, or constant [10], deducibility or negation preserv-ing [10], upward/downward solution [34], upward or downward-failure [39], orderedmonotonicity [13], and safety [4].5. In addition to these sets of evaluators, we introduce Evalsstrat(Si), a set of mea-sures for assessing a problem-solving strategy Si . An element in this set is obtainedby considering some combination of the values along Si of an element in the above-introduced evaluators (i.e., Evalsprob, Evalsref, Evalsp+r, and Evalsp+r+p).For instance, the financial cost of the strategy can be computed as the sum of theprices of the individual software packages; its computational complexity as the maxi-mum of their respective complexity; and, when the individual processes are functions,the strategy can be characterized in term of the their composition. Elements of this setis typically used in the objective function of the planning process discussed in Sec-tion 4.1.3 to express preferences and manage resources.4.2.2. ComparatorsComparators characterize the changes in the problem as the result of reformulation. Inorder to assess the effect of one or more successive reformulations within or across alter-native strategies, we define two sets of comparators, Comparsprob and Comparsstrat,which compare features of problems and strategies respectively. In order to capture somenotion of change or evolution, the elements of Comparsprob and Comparsstrat gen-erally reflect differences or ratios computed from the values returned by the evaluatorsEvalsprob and Evalsstrat. Below we discuss these two sets and provide illustratingexamples.1. Comparsprob(Pi , Pj ) denotes a set of effects that capture a change in some featureof the problem as expressed in Evalsprob(Pi ) and Evalsprob(Pj ).As for Evalsprob, some elements of Comparsprob(Pi , Pj ) assess the change thatone or more reformulations produce on some measure of the answer. Examples of suchcomparators are a 10% loss in the accuracy of the answer, whether the answer in PjFig. 7. Evaluating and comparing problems.164B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204Fig. 8. Evaluating and comparing strategies.is an overestimate (or an underestimate) of that in Pi , or whether or not the differencebetween them can be bounded within a threshold.When Pi and Pjare two problems situated along the same strategy Sk,Comparsprob(Pi , Pj ) captures the effect of applying a reformulation (or, a sequenceof reformulations) to Pi .When the reformulations are defined are functions, this outcome can sometimes bepredicted from considering the mathematical property of the reformulation itself (or,the composition of the consecutive reformulations). For instance, when the reformula-tion is an injective mapping, the size of Pj is bigger than or equal to that of Pi .One possible effect of reformulation on the problem is to improve cognitive insight;this is common at the Solution Reformulation Stage of Fig. 1. If the original formula-tion is too complex for a user to understand, reformulation can produce a descriptionbetter suited to human understanding.2. Comparsstrat(Si , Sj ) is a set that denotes the effects to two strategies Si and Sj .Examples of elements of this set are increase in cost, loss of time, and consumption ofavailable resources.When Si is a sub-strategy of Sj (or vice versa), Comparsstrat(Si , Sj ) indicates theeffects of extending a strategy by one or more reformulation steps. When Si and Sj aretwo distinct strategies applied to the same problem, Comparsstrat(Si , Sj ) assessestheir relative merits.Giunchiglia and Walsh in [10] introduce the operators “weaker than”, “stronger than”and “equivalent” (≡) to express an order relation determine an order two alternativemappings applied to the same problem.A reformulation is said to be cost-wise beneficial, when the cost of reformulating theproblem and then solving the reformulated problem does not exceed the cost of solvingthe original problem. This can be expressed by an element in Comparsstrat.Since one of the goals of reformulation is to improve overall problem-solving perfor-mance, the reformulation procedure itself should not significantly add to the computa-tional cost. However, sometimes there is no solution engine applicable to the originalproblem, and consequently any amount of effort to reformulate to make it solvable isjustifiable. A cost-intensive reformulation may also be justified when it is performedoff-line to improve runtime performance of a system.B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–2041654.2.3. SummaryTable 1 summarizes the vocabulary and criteria for evaluating and comparing refor-mulation introduced above. It also situates these terms with respect to the aspects ofreformulation that we discussed in Section 3.2.4.2.4. RemarksObserve that the evaluators for the problem, reformulation, and strategy are not nec-essarily independent. For example, the simplification of a set of equations often reducesthe size of the formulation (measured by Evalsprob) and the cost of applying the refor-mulation procedure (measured by Evalsp+r and consequently by Evalsstrat), at theexpense of also reducing the precision of the result (measured again by Evalsprob).In practice, the framework’s components seem often to be characterized and evaluatedwith respect to a set of non-orthogonal, and sometimes redundant, features. Weld in [38]suggests to assess a reformulation with respect to a set of independent features, whichhe calls model dimensions. He identifies scope, domain, resolution, and accuracy as foursuch orthogonal dimensions. Whether or not a set of canonical features exists remains anopen problem. Our study, however, indicates that a rich and expressive, although possiblyredundant, coverage of the features is desirable in practice.5. Illustrative examplesIn this section, we discuss a number of reformulation developed in the literature of rea-soning about physical systems. We review two or more techniques for each of the threestages of reasoning shown in Fig. 1: the Model Processing, Equation Processing and So-lution Processing stages. While all examples have been discussed in AI literature, theyoriginate from and are useful in a variety of science and engineering fields. For example,Aggregation (Section 5.2.1) is drawn from econometrics literature. Linearization (Sec-tion 5.2.2) is a common technique widely used in mathematics and engineering. Caricaturalreasoning (Section 5.2.3) is a formalization of the type of reasoning used in chemistry.In discussing the reformulation techniques, we conform to the following pattern: First,we briefly summarize a technique in general terms. Then, using the vocabulary introducedin the preceding section, we make explicit the components of the technique in the followingorder:1. The original and reformulated problems (Query, Form, and Assmpts).2. The reformulation technique (Proc and Cond).3. The evaluators and effects (Evals and Compars).For each example, the first part of the discussion explicates the types of problems thatthe technique applies to. The second part details the reformulation procedure itself alongwith its conditions. Finally, the third part describes the effects of the procedure in terms ofwhat aspects of the problems are changed and how. It also discusses the characteristics ofthe reformulation procedure as a computational process. Additionally, whenever we find itTable 1Summary of attributes and metricsNotationWhat does the reformulation do?Evalsprob(Pi )Evalsp+r+p(R, Po, Pr )EvaluatorsExamplesNotationComparatorsExamples166ProblemLogical:• Compactness, completeness, decidability• Result: truth/negation of a sentence, soundnessQuantitative:• Size, number of equations, degree of equations,number of variables, number of components in amodel,• Result: behavior over time, numerical or intervalvalue, precisionQualitative:• Complexity class, scope of model, expressivenessof model, syntactic form, simplicity, generality,relevance, restriction of language to familiar terms,adherence of equations to some canonical form,understandability• Result: sets of partial or global solutions, result:behavior over time, whether query is answeredReformulation process• Necessary, sufficient approximationFunctions: partial/total, injective, surjective,invertible, morphism, TI/TD/TC, upward/downwardsolution or failure property, ordered monotonicity,safety property, etc.BY..Comparsprob(Pi, Pj )• Set operators: ⊃, =, ⊂• Numerical operators: <, =, >Choueiryetal./ArtificialIntelligence162(2005)145–204(continued on next page)Table 1 (Continued)NotationExamplesCharacteristics of the reformulation itselfEvaluatorsNotationComparatorsExamplesEvalsref(R)Reformulation technique• Size of code• Programming language• Price of commercial software• Interfacing capabilities (hardware/software)• Human expertise requiredEvalsp+r(R, Po)• Computational complexity: Best, worst, averagecase; empiricalReformulation technique and problemEvalsstrat(Si)Combinations, to be defined, of the values along Siof an element of the above evaluators.• Financial cost.• Maximal/total computation cost in time/space.StrategyR: Reformulation technique.Pi : A problem. Original problem: Po; reformulated problem Pr .Si : A strategy, a sequence of problems are reformulations (cid:5)P1, Ra , P2, . . . , Rx , Pi (cid:6).Comparsstrat(Si , Sj )(Strategy)• Weaker, stronger, equivalentabstraction• Cost intensive, Cost-efficientBY..Choueiryetal./ArtificialIntelligence162(2005)145–204167168B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204is instructive to do so, we discuss the reformulation technique as part of a larger problem-solving strategy and compare it with other possible strategies.5.1. Reformulation at the model processing stageThe first step in reasoning about physical systems is to build a model. A model is theconceptual object we study and manipulate instead of studying the real physical device.There can be as many possible models of a given subject as there are reasons for studying it.While there is no one “correct” model, the usefulness of a model depends on the query onetries to answer by constructing and studying the model. For a model to be useful, it mustcontain enough information to answer the query with sufficient precision and accuracywhile avoiding unnecessary detail.The process of model construction sometimes amounts to model reformulation, whereone starts with some existing accepted model and modifies it to suit the task at hand. Itis said that in most engineering applications a significant part of the modeling effort isspent on iterative modification of the proposed model [26]. In AI, even works that focuson formulating new models can involve an explicit reformulation step where the modelinitially generated is modified to meet some optimality criteria.In this section, we discuss two model-reformulation techniques. The first one, ModelSimplification by Nayak and Joskowicz, is an example of a technique developed as partof a model-formulation method. In our discussion, we focus on the last step of the modelformulation process, in which the model initially generated is simplified to meet the au-thor’s simplicity criterion. Since this reformulation technique is embedded in a modelingapproach, called compositional modeling, we must introduce briefly the concept of com-positional modeling in order to put our discussion in proper light.Compositional modeling is an effective method for automatically formulating a behav-ior model represented by a system of ordinary differential equations for a physical system[6,15,21,29]. The basic idea in compositional modeling is to formulate a model of a givensituation by putting together pieces of descriptions, called model fragments, of physicalphenomena in the domain. Each model fragment describes one aspect of a component be-havior or a physical process. A system formulates a model of a given situation by selectingapplicable model fragments and composing them. The main advantages of compositionalmodeling are modularity and reusability of knowledge. It is, at least in principle, easier towrite and reuse model fragments than complete models. Since there can be multiple waysto describe a given situation, each with varying degrees of details or with different model-ing assumptions, it is possible to have several alternative model fragments describing thesame physical phenomenon. Nayak and Joskowicz’s reformulation technique involves re-placing the model fragments in the existing model by simpler alternatives that describe thesame phenomenon.The second example we discuss is Critical Abstraction by Williams [40]. As in Nayakand Joskowicz’s work, the goal of the reformulation in Critical Abstraction is to producea model that is the simplest yet sufficient to provide a causal explanation of the behaviorof interest. Critical Abstraction could very well be part of an overall model formulationmethod, even though Williams did not present it as such.B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204169Fig. 9. Model simplification.5.1.1. Model simplificationNayak and Joskowicz propose a model reformulation technique that simplifies a com-positional model of a device, while maintaining its ability to provide a causal explanationof the expected behavior of the device [21].The primary objective of their work is to perform efficient compositional modeling forgenerating parsimonious causal explanations of the functioning of a device. They providetools for model-fragment library indexing and selection to support the construction of de-vice models. The reformulation procedure is applied to the model thus built in order tosimplify it. The entire model formulation procedure is portrayed as a sequence of steps inFig. 9. While the compositional modeling contributions of this paper are particularly inter-esting, it is the reformulation procedure following the initial model formulation that is ofrelevance to us. Thus, we focus on this simplification process in our discussion.Given a device description, the expected behavior of a device, its structural and behav-ioral constraints, and a library of model fragments organized and indexed in a particularfashion, their model-building algorithm composes an initial coherent model of the device.This initial model is coherent in that it explains the expected behavior, it is internally con-sistent, and the set of equations implied by the model are not over-constrained. However,it may not be as parsimonious as it could be; that is, it may be possible to further simplifythe model while maintaining the structural and behavioral constraints of the device, andthe ability of the model to explain the expected behavior. Their reformulation procedureperforms this simplification by removing unnecessary model fragments from the modeland also by replacing model fragments by their approximations whenever it is possible todo so without compromising the coherence of the model.The organization of the library of model fragments makes explicit the causal approxi-mation relations among alternative descriptions of a given phenomenon. Thus, alternativesimpler descriptions can be found without search, which enables an efficient execution ofthe approximation.The metric for evaluating and comparing problems is parsimony of the formulation.A parsimonious model contains only those model fragments necessary to explain theexpected behavior while satisfying the structural and behavioral constraints. The refor-mulation algorithm guarantees that the resulting model is the most parsimonious in thesense that no model fragment in the model can be removed or replaced by any of its causalapproximations without violating the structural and behavioral constraints.The problems, P1 and P2The original problem, P1, and the reformulated problem, P2, consist of the three-tuples,(cid:5)Query1, Form1, Assmpt1(cid:6) and (cid:5)Query2, Form2, Assmpt2(cid:6).Query1 = Query2: Generate a causal explanation of the specified expected behavior.170B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204Form1 consists of:1. A library of model fragments, where• model fragments are grouped into assumption classes,• each assumption class has one best model fragment of which the rest are causalapproximations, and• the causal approximation relations are acyclic.2. The expected behavior of the device in terms of an expected causal relations among apair of variables, represented as causes(v1, v2).3. The structural and behavioral constraints.4. A coherent causal model of the device comprised of instances of model fragments.Form2: The same (1) through (3) as in Form1. As for (4), a simplest, coherent and causalmodel of the device.Assmpt1 = Assmpt2: The assumptions underlying the library of model fragments ifany.The reformulation techniqueProc:Input to the reformulation procedure is a compositional model that may containunnecessary model fragments and may not be as simple as possible. The reasonsfor this are that the model formulation algorithm initially selects the most accuratemodel fragment in each assumption class and also that it satisfies some constraintsby adding model fragments that may later prove unnecessary.The reformulation procedure exploits two operators:1. Replacement of a model fragment by one of its immediate causal approxima-tions, as defined in the model-fragment library; and2. Removal of an unnecessary model fragment.The first operator is applied repeatedly while ensuring that the resultant model canexplain the expected behavior. This is achieved by an order of magnitude reasoner.The second operator is then applied, again ensuring that the expected behavior canbe explained and that all the structural and behavioral coherence constraints aresatisfied. Note that the reformulation procedure generates one simplest adequatemodel. More than one may exist but the procedure stops after finding the first.Cond: The model-fragment library must be organized in a manner that makes the causalapproximation relations among alternative descriptions of the same phenom-ena explicit and alternative simpler model fragments readily available. This isachieved as follows: Model fragments that describe the same physical phenom-enon but are based on different assumptions are grouped into an assumption class.Each assumption class is a collection of mutually contradictory descriptions ofthe same phenomenon. For example, the behavior of a resistor can be describedas a constant resistance resistor or a temperature-dependent resistance. Each as-sumption class is organized in a tree with model fragments as nodes and causalapproximation relations as links. Each assumption class has a single most accu-B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204171rate description at the root, and all other descriptions are causal approximationsof it. Given two model fragments mi and mj , mi is a causal approximation ofmj if and only if mi is an approximation of mj and the causal ordering rela-tions among variables of mj is a superset of those of mi . Approximation relationsamong model fragments are given a priori in the library.Evaluators and effectsEvalsprob, Comparsprob: Nayak and Joskowicz evaluate a formulation—more specif-ically the model part of a formulation—in three ways, namely coherence, causal-ity, and parsimony of a model. Coherence refers to the consistency and complete-ness of a model with respect to the expected behavior and other given behavioraland structural constraints. Causality refers to the ability of a model to explain theexpected causal relations among variables. Parsimony refers to the simplicity of amodel.Coherence is in Evalsprob since it is a characteristics of a formulation—morespecifically, that of a model. Coherence of a model is defined in terms of consis-tency and completeness of a model. A model is coherent when it is both consistentand complete. A model is consistent when it does not contain model fragmentswith mutually contradictory assumptions. A model is complete when the set ofequations entailed by its model fragments are complete. A set of equations iscomplete if it contains the same number of equations as variables and no subsetis overconstrained.Causality is in Evalsprob as it is a characteristic of a formulation. More specifi-cally, it is a characteristic of the model as well as of the expected behavior, whichis expressed in terms of causal dependency relations between a pair of variables.A model is a causal model if and only if the causal ordering generated from theequations of the model entails the expected behavior.The most important characteristics of the reformulation procedure is that it pre-serves the coherence and causality properties of a model while making it mostparsimonious. Thus, the effect of the reformulation is expressed in terms of par-simony.Parsimony is in Compars(P1, P2) as it is defined in terms of a binary relation,simpler-than, between models instead of some measure of the degree of par-simony of an individual model. The simpler-than relation in turn is definedin terms of a binary relation, approximation(m1, m2), between model frag-ments. The approximation relations are given explicitly in the model-fragmentlibrary. A model M1 is simpler-than M2 if for each model fragment m1 in M1,either m1 is also in M2 or there is another model fragment m2 in M2 such that m1is an approximation of m2. A model M1 is said to be parsimonious if it is coher-ent and there is no other model strictly simpler than M1 that is also coherent. Thereformulation procedure is guaranteed to produce a parsimonious model. Thoughthere may be more than one, the procedure stops after producing one.Evalsp+r: The authors evaluate the reformulation procedure in terms of its computa-tional complexity, which is in Evalsp+r(R, P1). The complexity of the refor-172B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204mulation procedure relative to the problem encoding is polynomial provided theorder of magnitude reasoning used to verify that the simplified model still explainsthe expected behavior is polynomial. The tractability of the procedure is ensuredby the upward failure property regarding the need to explain the expected behav-ior. The upward failure property in this case means that, if a model fails to explainthe expected behavior, any of its approximation will also fail, thus allowing oneto prune large parts of the search tree. The upward failure property is ensured bythe requirements that: (1) the approximation relations among model fragments inthe library are causal approximations, (2) the causal approximation relations areacyclic, and (3) each assumption class has only one root, i.e., the most accuratemodel fragment.Discussion. The success of Nayak and Joskowicz’s elegant and efficient model formula-tion as well as simplification procedures hinges entirely on the strong restrictions placedon the organizations of the model-fragment library as well as on the types of constraintsit can handle. In other words, the model-fragment library (and to a large extent, the prob-lem itself) must be carefully crafted for the procedure to run efficiently. This criticism alsoapplies also to other model composition techniques that rely on an elaborately structuredmodel-fragment library such as the one used in [15]. Because of the restrictions placed onthe problems and model-fragment library, the practicality and generality of the simplifi-cation procedure described here remains questionable. For example, the requirement thatall approximation relations must be causal approximations seems to leave out many otheruseful types of approximations, such as linearization discussed in Section 5.2.2. Further,the requirement that the builder of a model-fragment library must specify approximationrelations a priori is also restrictive. As we have illustrated in Section 2.3 with the exampleof square and sine waves, given two different descriptions, the question of which is a usefulapproximation of the other may very well depend on the question being asked.As Pos points out [26], modeling is a naturally dynamic and iterative process, dur-ing which problems themselves, including the assumptions, constraints, and formulations,are likely to change. In light of this dynamic and iterative nature of the modeling en-deavor, reformulation approaches that involve selection from pre-specified set of modelfragments using hard-wired approximation relations among them could prove too limit-ing. Furthermore, the requirement for a large, carefully crafted model-fragment library tobe constructed makes the approaches that depend on such libraries less practical in mostcases. In the following section, we discuss a technique that does not require the use of amodel-fragment library, at least for the purpose of reformulation.5.1.2. Critical abstractionsWilliams proposes a reformulation technique, called Critical Abstraction, for simplify-ing a model of a physical device to the furthest extent possible while preserving its abilityto answer a given query [40]. The information retained in the model should be necessaryand sufficient to answer the query while supporting a causal explanation of the answer.There are two inputs to the procedure: a model of the physical behavior, and a query ona variable in the model. A model contains two types of information: physical componentsand their behavior equations. The behavior equations describe the interactions among theB.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204173Fig. 10. Critical abstraction.components as well as within the components. The output is a simplified version of themodel that is sufficient to answer the query. See Fig. 10.The reformulation is a three-step procedure that modifies the model according to thegiven query. First, superfluous interactions among mechanisms are eliminated. This isachieved by first building the causal ordering of the variables then eliminating the equa-tions that are not causally upstream of the query variable. Second, the behavior descriptionsof each mechanism are simplified by combining equations to eliminate the variables andinteractions that are only internal to each mechanism. Third, individual variables and equa-tions are modified to retain only those features that contribute to that determination of theanswer to the query.As in the case of Nayak and Joskowicz’s reformulation technique, the metric for eval-uating and comparing problems is parsimony of the formulation, though the definitions ofparsimony differ. While Williams’ concept of parsimony of a model is similar to that ofNayak and Joskowicz’s in that it requires the set of variables and causal relations entailedby a more parsimonious model to be a subset of those entailed by the original model, itdoes not involve approximation relations. As a result, his reformulated model produces theexact same answer to the query as the original model. Furthermore, Williams requires thatreformulation preserve the connection between equations and the mechanisms that producethem. This requirement ensures that the resulting model contain enough information to ex-plain the answer in terms, not only of the causal dependency relations among variables,but also of the actual physical mechanisms that are responsible for the relations. Williams’reformulation algorithm guarantees that the resulting model is the most parsimonious inthe sense that no model that is strictly more abstract can produce the same answer to thequery while maintaining the same causal and teleological explanatory power.The problems, P1 and P2The original problem, P1, and the reformulated problem, P2, consist of the three-tuples,(cid:5)Query1, Form1, Assmpt1(cid:6) and (cid:5)Query2, Form2, Assmpt2(cid:6).Query1 = Query2: Find, or verify, the value of a qualitative variable x.Form1 and Form2 consist of the following:1. A set of variables V .2. A set of independent variables I V ⊂ V .3. A set of equations I (called interactions) on the variables of V , such that• each member of V appears in at least one equation,• there is no simultaneity, and• the equations are not redundant.174B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–2044. A set of mechanisms M (such as components, connections, and processes).5. An onto function I M : I → M, which associates each interaction with the mechanismthat produces it.In addition, Form2 is an abstraction of Form1, and Form2 is the most abstract possiblein the sense that no formulation that is strictly more abstract than Form2 can produce thesame answer to the query while maintaining the same causal explanatory power. Williamsdefines abstraction as follows:Definition 1 (Abstraction). Form2 is an abstraction of Form1 if V2 ⊂ V1, I V2 ⊂ I V1,M2 ⊂ M1, and for every m in M1, its interactions in Form1 entail its interactions inForm2. In other words, for each i in I2 and its corresponding mechanism m, i is satis-fied whenever m’s interactions in Form1 are satisfied.Assmpt1 = Assmpt2: Whatever assumptions that underlie P1.The reformulation technique, RWilliams places the following restrictions, Cond, on the set of equations:• The equations describe static interactions.• The equations are non-redundant.• The equations do not contain simultaneity.The reformulation procedure, Proc, consists of the following steps:1. Determine the causal ordering among variables using the equations. The conditionsthat there is no simultaneity and that the equations are non-redundant guarantee that acausal ordering can be found efficiently and that it is unique. Remove all the variables,interactions, and mechanisms upon which the query variable does not causally depend.2. Simplify the remaining set of equations by eliminating the variables that are internal toone mechanism and do not participate in interactions with other mechanisms. Again,the lack of simultaneity in equations makes this step straightforward.3. Since the query asks for the qualitative value of a variable, the last step turns the re-maining equations into qualitative equations to the furthest extent possible withoutlosing the ability to answer the query. This step, which ultimately produces the finalset of equations in the mixed qualitative and quantitative algebra, is achieved roughlyas follows. With each equation on the causal ordering starting from the query variableand moving towards the independent variables on which the query variable causallydepends, the sign operator is pushed inwards as far as possible using the homomor-phism of the sign operator with respect to multiplication, division and negation.5 Thisprocess has the overall effect of pushing the sign operator from the query variable to5 The sign operator [] is homomorphic with respect to multiplication, division and negation but not with additionand subtraction. In other words, [a × b] = [a] × [b], [a/b] = [a]/[b], [−a] = −[a], but the same does not holdin general for + and binary −.B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204175causally upstream variables and expressions as far as possible. At the same time, thisprocess identifies the expressions whose qualitative values can only be determined byevaluating them quantitatively in order to answer the query.The requirement for static equations is essential for the claim that the procedure iden-tifies every landmark value for each variable necessary to answer the query and that thoseare the only ones needed. Since the equations are static, simulation is not necessary forsuch identification. If the equations were dynamic, one would have to perform simula-tion over time to identify relevant landmark values. The requirement that the equations benon-redundant ensures that the causal ordering can be found and is unique. Otherwise, onewould have to select a non-redundant subset of the equations to determine the causal order-ing. Finally, the requirement that the equations should not contain simultaneity ensures thatthe procedure can always associate a unique mechanism with an equation, which Williamsregards as important for a causal explanation.Evaluators and effectsEvalsprob, Comparsprob: Williams evaluates a formulation according to three as-pects, namely its ability to answer the query, causality, and parsimony. Theevaluators seem similar to those of Nayak and Joskowicz’s on the surface but,in fact, they are quite different in their actual definitions. The overriding con-cern in Critical Abstraction is that reformulation should not change the answerproduced by the formulation. The goal of reformulation here is to simplify theformulation to the furthest possible extent without altering any aspect of the an-swer to the query. This is a significant difference from reformulation in Nayakand Joskowicz’s work, where reformulation produces a more approximate model,which presumably will produce an answer that is different from the original. Like-wise, the concept of parsimony in Nayak and Joskowicz’s work relies on that ofapproximation while approximation plays no role in the concept of parsimony inCritical Abstraction. As for causality, an important difference between the two isthat Williams includes the connection between the interactions and mechanismsthat produce the interactions in the overall concept of causality in a formulationwhile Nayak and Joskowicz do not.The ability to answer the query is in Evalsprob(P ), and the means of compar-ison for this evaluator is that they must be exactly the same. The answer to thequery entailed by the two formulations must be exactly the same in all respects,including the accuracy, precision, and ambiguity.6Evalsp+r+p: The concept of causality Williams is concerned with includes the connec-tion between interactions and mechanisms in addition to the causal dependencyrelations among variables. This notion of causality is embodied in the last part ofthe definition of abstraction presented above, which says that the abstraction mustpreserve the connection between interactions and individual mechanisms that pro-6 If the initial formulation is qualitative, the reformulation must not change the ambiguity in the answer.176B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204duce them. We consider this evaluator to be in Evalsp+r+p(R, P1, P2) since itis defined as a relation between two formulations.Parsimony here is also in Evalsp+r+p(R, P1, P2) as Williams’ concept of parsi-mony is mainly that of abstraction as defined above. It also includes a measure ofsimplicity of the quantity space of variables. Informally, the less distinctions oneneeds to make in the quantity space of a variable, the simpler the quantity space.7In the mixed quantitative-qualitative algebra employed in Critical Abstraction,this means that for each variable, the fewer quantitative expressions involving thevariable there are in the equations, the simpler its quantity space is. However,Williams does not present a complete formal definition of parsimony.Evalsp+r: The computational complexity of the reformulation is in Evalsp+r(R, P1).Although Williams does not present an analysis of the computational complexity,all the steps in the procedure appear linear with respect to the number of equationsand variables.Discussion. The strength of Critical Abstraction is that it does not require a pre-enumerated set of pieces of alternative descriptions, as do the model formulation, orreformulation approaches that rely on model-fragment libraries. Based solely on the query,Williams simplifies the formulation by removing parts that are irrelevant to the query andidentifying the minimal set of quantitative distinctions that are necessary. Furthermore, thisreformulation is performed without compromising the causal explanatory power of the for-mulation or its ability to answer the query. Williams accomplishes this without incurring alarge computational cost.Also noteworthy is Williams’ attempt to abstract the quantity space of the variablesin accordance with the query. The last step in his reformulation procedure automaticallyidentifies the necessary quantitative distinctions that must be made to answer the query.This is in contrast to the more common practice in qualitative reasoning where landmarkvalues are, for most part, pre-enumerated.In both of the approaches discussed in this section for reformulating models, the pro-fessed goal of reformulation is a better explanation, where “better” means causally consis-tent and simpler, even though the end product in both cases is another formulation and notan explanation. A working assumption in both cases is that a simpler model will producea better explanation. It is also worth noting that their goal is not reduction of the com-putational effort required to answer the query though one might expect such a reduction,especially given both approaches produce simpler models in the sense of “more approxi-mate” or “requiring less quantitative distinctions”. This suggests that what one perceives asa satisfying causal explanation of a physical system involves more than just quantities andequations; it must somehow establish connections between quantities and equations on onehand and the components of the cognitive model of the physical system, may it be modelfragments (as in the Nayak and Joskowicz’s case) or mechanisms (as in Williams’). Exam-ples of reformulation whose primary goal is reduction of computational cost are found inthe next section on reformulation at the Equation Processing Stage.7 A quantitative variable can be considered to an infinite number of distinctions.B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–2041775.2. Reformulation at the equation processing stageWe now turn to examples of reformulation techniques at the Equation Processing Stage.Reformulation of a system of equations is a common practice when the system is too largeor complex to be solved or analyzed directly. Thus, most of the techniques employed at thisstage, including the first three discussed in this section, simplify the system through suchmeans as aggregating variables and equations (Section 5.2.1), substituting nonlinear equa-tions by linear ones (Section 5.2.2), and decomposing the problem space (Section 5.2.3).However, simplification is not the goal of the last technique discussed in this section: InExaggeration (Section 5.2.4), a system of qualitative equations based on standard num-bers is replaced by one based on nonstandard numbers, producing a more complex systemexhibiting more complex behavior.5.2.1. Aggregation of nearly decomposable systemsSimon and Ando provide a formal basis for a reformulation technique that aggregatesvariables in dynamic systems to reduce the size of the system [32]. The aggregation proce-dure they describe takes a set of linear differential equations that is nearly decomposableand produces a smaller aggregate. A nearly decomposable system is a system composedof subsystems such that the interactions among subsystems are much weaker than the in-teractions within each subsystem. If a given linear system is nearly decomposable, and ifthe system is stable, then their procedure defines an aggregate variable for each subsystemas a linear function of the original variables in the subsystem, and reformulates the entiresystem in terms of the aggregate variables and equations. The result is a smaller system setthat adequately describes the mid-to-long term behavior of the original set. The primarygoal of aggregation is reduction of the cost of solving the equations since the size of thesystem has a direct impact on the cost of finding the solution.The basis for the aggregation procedure is the observation that the behavior of a nearlydecomposable system can be characterized in the following four stages [32]:1. Short-run dynamics, where variables in each subsystem are moving towards their rel-ative equilibrium independently of other subsystems.2. Short-run equilibrium, where the most significant root of each subsystem dominatesthe behavior of the subsystem.3. Long-run dynamics, where the variables in each subsystem move together towardsoverall equilibrium.4. Long-run equilibrium, where the most significant root of the entire system dominates.Aggregation produces a system that ignores the first stage but models the remaining stageswith increasing accuracy as time goes on.Simon provides a good example of aggregation of variables in the case of heat flowwithin a building [31]. Consider a building divided into a large number of rooms that arein turn divided into a number of offices by partitions. The outside walls provide perfectthermal insulation from the environment. The walls between rooms are good but imper-fect insulators while the partitions within rooms are poor insulators. In this situation, thetemperature equilibrium among offices within one room will be reached very rapidly while178B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204Fig. 11. Solving linear ordinary differential equations by aggregation.equilibrium across rooms will be reached only slowly. Therefore, as long as we are not in-terested in modeling rapid temperature fluctuations within one room, a useful aggregationis to have one temperature variable for each room and to assume that equilibrium within aroom is reached instantaneously.Fig. 11 shows a strategy involving aggregation to solve linear differential equations. Itis depicted as a two-step strategy of aggregation (R1) followed by solution of the aggregatesystem (R2). It also shows an alternative strategy of directly solving the original system asthe path (cid:5)P1, R3, P4(cid:6).The problems, P1 and P2The original problem, P1, and the reformulated problem, P2, consist of the three-tuples,(cid:5)Query1, Form1, Assmpt1(cid:6) and (cid:5)Query2, Form2, Assmpt2(cid:6).Query1 = Query2: What is the value of the variable x at time t, where x is a variablein E.Form1 consists of the following:1. A set E of linear ordinary differential equations involving n variables and n equations.2. A small value ε, to be used as the threshold value for classifying coefficients in E intothose representing strong or weak interactions.Form2 consists of the following:1. A set E(cid:9) of linear ordinary differential equations involving m variables and m equa-tions, where m < n.2. n equations of the form xi = fi (yj ), one for each variable xi in E, where fi is a linearfunction of yj , and yj is a variable in E(cid:9).Assmpt1: None.Assmpt2: The values of x for a relatively small t are not important (i.e., the short-rundynamics is not of interest).B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204179The reformulation techniques, R1 and R2The aggregation technique R1 requires the following conditions to be satisfied by theoriginal system:Cond1:• The system is nearly decomposable with respect to the threshold value ε. This meansthat given ε, the matrix consisting of the coefficients in E can be put in a nearly block-diagonal form, where the elements outside the diagonal sub-matrices are all less thanε. This can be achieved by rearrangement of rows and columns if necessary. However,no other manipulations, such as Gaussian elimination, are allowed.• The behavior of the system represented by Form1 is stable.The reformulation procedure, Proc1, consists of the following steps:1. For each diagonal sub-matrix in Form1,• solve the sub-matrix by itself,• choose the most significant root,• define the aggregate variable as a linear function of the most significant root. Thedefinition of the aggregate variable and the eigenvector associated with the mostsignificant root determines the linear relation between the aggregate variable andeach of the variables in the subsystem.2. Rewrite the original matrix by substituting each variable with its expression in termsof the respective aggregate variable.The solution step R2 follows R1. R1 has no conditions. Its procedure, Proc2, consists ofthe following steps:1. Solve E(cid:9).2. Using the solutions for the variables yj ’s in E(cid:9) and the n equations of the form xi =fi (yj ) in Form2, compute the values of xi ’s.Iwasaki and Bhandari later generalized the original aggregation procedure to caseswhere there are multiple significant roots per system [12], but the intuition remains thesame.Evaluators and effectsEvalsprob, Comparsprob: The immediate effect of aggregation is to reduce the sizeof the system of differential equations that must be solved. Aggregation also hasan effect of making the solution less accurate. The size of a formulation is inEvalsprob(P ). It is measured in terms of the number of variables in the system.The size strictly decreases as a result of aggregation.Another effect of aggregation is on the accuracy of a solution, which is also inEvalsprob(P ). However, the comparator for this evaluator (Comparsprob(P1,180B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204P2)) is more complicated than the comparator for the size. The magnitude of thediscrepancy between the two solutions in general decreases as t grows.Evalsp+r: One can evaluate the reformulation procedure in terms of its computationalcomplexity. Solving the matrix analytically requires computing eigenvalues andeigenvectors of the non-singular square matrix whose elements are the linear co-efficients in the equations. Given ε, the complexity of all the steps in Proc1 isconstant or linear, except for the step 1, whose complexity is O(m3i ), where mi isthe size of the ith sub-matrix. Thus, the overall complexity of Proc1 is O(m3max)where mmax is the size of the largest sub-matrix.Evalsstrat: Likewise, strategies can be evaluated with respect to their computa-tional complexity. The complexity of the strategy represented by the path(cid:5)P1, R1, P2, R2, P3(cid:6) is the greater of O(m3max) and O(m3), where mmax is thesize of the largest sub-matrix and m is the size of the aggregate matrix. The com-plexity of the strategy represented by the path (cid:5)P1, R3, P4(cid:6) is O(n3), where n isobviously larger than m or mmax. The cost of computing the numerical solutiondecreases8 in general.Discussion. Aggregation reduces computational cost at the expense of some loss in ac-curacy, though the discrepancy diminishes as t increases. That is why this reformulationmethod is appropriate only when the short-run dynamics are not of interest. Of course,if the short-run dynamics are of primary interest, one can always solve the subsystemsindependently to obtain a reasonably accurate solution for a small t.Finally, aggregation can have an effect on the cognitive transparency of a formulation.Though in the work of Simon and Ando the issue of cognitive transparency of a modeldid not arise, it is often an important consideration as we have seen in Section 5.1 on re-formulation of models. Depending on the ways in which aggregate variables are defined,aggregation can make a formulation more compact and thus easier to understand or it canmake the physical meaning of a formulation more difficult to comprehend. If the originalvariables in a subsystem all have the same physical dimension, one could define the aggre-gate variable so that it has an easily discernable physical significance such as the sum orthe average. In this case, the resulting aggregate formulation will be easier to understandas a description of a physical behavior. However, in other situations, for example if theoriginal variables have different dimensions, the aggregate formulation may be difficult tointerpret physically even if it is useful computationally.5.2.2. Stability analysis of nonlinear systems through linearizationNonlinear systems can exhibit entirely new types of behavior compared to linear sys-tems, but rarely are there tools available to analyze these behaviors. Fortunately, it is oftenunnecessary to obtain detailed numerical or analytical solutions but is sufficient to charac-terize only some aspect of the system behavior. Existence of equilibrium points and theirstability are examples of aspects frequently studied about nonlinear systems [18].8 The cost will be proportional to m × t, where m is the size of the system and t is the number of time steps atwhich variables are evaluated.B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204181Fig. 12. Stability by linearization.Linearization is a strategy commonly used to evaluate the stability of a nonlinear systemnear equilibrium points. Linearization is justified because over a small time interval, theperformance of the system is approximately governed by the linear terms. Provided thatthe linear terms do not vanish near the equilibrium point, these terms dominate and thusdetermine stability around the point [18]. If the linear terms do vanish, a separate analysisis required.Once linearized, the stability of the system is determined by the location of the eigenval-ues of the system matrix in the complex plane. Thus, the problem-solving strategy consistsof the two sequential steps shown in Fig. 12—R1, which transforms a nonlinear systemto a linear system, followed by R2, which determines stability. This strategy is motivatedby the lack of a general method to directly determine the stability of a nonlinear system.For the purpose of stability analysis, there is actually an alternative to linearization. Thealternative involves a Liapunov function and is shown in Fig. 12 as a strategy representedby the path (cid:5)P1, R3, P4(cid:6). R3 requires no computation with the condition that a Liapunovfunction is known for the nonlinear system in P1, since the existence of such a functionimmediately implies that the system is stable and the region over which the function is de-fined is the region of stability. However, ways to construct a Liapunov function are knownonly for limited classes of nonlinear systems.The problems P1, P2, and P3Query1 = Query2 = Query3: Determine the stability of the system near an equilib-rium point.Form1 comprises:1. A set of nonlinear, time-invariant9 differential equations ˙x(t) = f (x(t)) of n vari-ables.2. An equilibrium point for the nonlinear system.Form2 is a set of time-invariant linear differential equations of n variables that approxi-mate Form1 at an equilibrium point. Form2 has the same set of variables and the same9 The dynamic behavior of a continuous system of n variables is described by a set of differential equations ofthe following general form: ˙x(t) = f (x(t), t). The system is said to be time-invariant when the functions f donot depend explicitly on time, i.e., ˙x(t) = f (x(t)).182B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204number of equations as Form1. The system matrix of Form2 is the Jacobian of Form1evaluated at the equilibrium point.Form3 is Form2, the positions of its eigenvalues in the complex plane, and the result (i.e.,one symbol of {stable, unstable, unknown}).Assmpt1: None.Assmpt2 = Assmpt3: Form2 is a valid approximation of Form1 near the equilibriumpoint, i.e., linear terms in Form1 do not vanish in its vicinity.The reformulation techniques R1 and R2R1 transforms a nonlinear system to a linear system. It has no conditions, and the pro-cedure is as follows:Proc1: Compute and evaluate the Jacobian of Form1 at the equilibrium point. Constructa linear system with the Jacobian as the system matrix.R2 determines the stability of Form2. It has no conditions, and the procedure is as follows:Proc2: Compute the eigenvalues, λi , of the system matrix of Form2. Then, the stabilityis inferred as follows:• If at least one eigenvalue is found to be in the right-hand side of the complexplane (∃i, Re(λi) > 0), the system is unstable.• If all eigenvalues are in the left-hand side of the complex plane (∀i, Re(λi ) <0), the system is stable.• If all eigenvalues are in the left-hand side of the complex plane, but at least onehas a zero real value (∃i, Re(λi ) = 0), then no conclusions can be drawn aboutthe stability, and one must analyze the higher-order terms of the function f .Evaluators and effectsEvalsprob: As linearization is motivated by the lack of general method for deter-mining stability of a nonlinear system, we can categorize it as an exampleof engine-driven reformulation. More specifically, an evaluator of a problem(Evalsprob(P ) for P1 and P2) is the existence of a general, computable pro-cedure for determining stability.Other aspects of the problem that are changed by linearization are accuracy andgenerality of a formulation as a description of a physical system. Accuracy andgenerality of a formulation with respect to the physical behavior that it describesare elements of Evalsprob(P ) for P = P1 and P2. Presumably, P1 is more ac-curate than P2, but the discrepancy between the two descriptions decreases asthe equilibrium point is approached. Accuracy is closely related to generality ifgenerality is defined as the subspace in the n-dimensional space in which a for-mulation is valid as a description of the system. P1 is a valid description in theB.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204183entire space in which the system is defined, while P2 is only valid in the vicinityof the equilibrium point.Evalsp+r: The two reformulation-steps, R1 and R2, in the linearization strategy can beevaluated with respect to the complexity of their procedure, Proc1 and Proc2,relative to the problem encoding, Form1 and Form2, respectively. The worst-case complexity of Proc1 is O(n3) where n is the number of variables in thesystem. For R2, which requires the computation of the eigenvalues of the systemmatrix, it is also O(n3) in general.Evalsstrat: The two strategies represented in Fig. 12 as the path (cid:5)P1, R1, P2, R2, P3(cid:6),involving linearization, and the path (cid:5)P1, R3, P4(cid:6), involving a Liapunov function,can be evaluated in terms of their computational cost, which is in Evalsstrat.The cost of the former is proportional to n3 as can be seen from the complexity ofits component procedures, while the cost of the latter is a constant. The two strate-gies can also be characterized in terms of their generality, also in Evalsstrat:Linearization is justified in cases where the linear terms do not vanish while Lia-punov function can be used only in cases where one is known.Discussion. Linearization is one of the most important approximation tools for modelingthe behavior of complex systems. Though basic equations of physics are nonlinear, lin-earization is a practical necessity since so little of general nature is known about nonlinearsystems. Also, there are many situations where linear approximation is adequate for mostpurposes. Linearization is particularly useful for stability analysis since one is interestedin the behavior of the system in a limited region where the linear terms tend to dominate.Since it is motivated by lack of other methods to analyze nonlinear systems, we can classifythis reformulation as engine-driven.Though linearization is performed only around an equilibrium point in the case dis-cussed in this section, linear approximation can be used more generally to reason aboutthe global characteristics of nonlinear dynamic systems. In piecewise linear approxima-tions of nonlinear ordinary differential equations, the entire space of behavior is dividedup into regions such that a different linear equation is used to approximate the behavior ineach region (e.g., [23,30]). The characteristics of the behavior of the original system can beinferred by analyzing each linear region separately and by piecing the inferred behaviorstogether. Sacks’ PLR system [30] analyzes nonlinear dynamic systems using piecewiselinear approximations. Given a nonlinear system, PLR semi-automatically breaks up thespace into regions and proposes a linear approximation for each region using informationabout the original function (such as local extrema) as well as user input. Then, it analyzesthe behavior within each region and pieces them together to draw a phase diagram of theentire space. In the process, PLR refines the initial linear approximations as necessary todetect all the qualitatively significant features of the behavior. Reasoning by PLR is ex-pensive; the computational complexity of the inequality reasoning employed by PLR isexponential in the length of its input. However, the expense is justifiable since nonlineardynamic systems can otherwise resist analysis altogether.Breaking up a complicated behavior into smaller pieces each of which can be approxi-mated by a simpler behavior is a common strategy employed by human experts analyzing184B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204Fig. 13. Caricatural modeling.a complex system. The reformulation technique discussed next also follows this strategyin solving high-order algebraic equations.5.2.3. Caricatural reasoningIn [41], Williams and Raiman study a reformulation technique used by analyticalchemists for analyzing a set of nonlinear, high-order algebraic equations such as thosedescribing the equilibrium behavior of a chemical reaction. High-order nonlinear equa-tions10 are hard to solve in general, and, furthermore, the complexity of such systems ofequations makes it difficult to gain clear insight into the space of possible solutions. Theyintroduce Caricatural reasoning as a technique for decomposing a problem space into aset of regimes, each of which is defined by a set of assumptions about the relative ordersof magnitude of certain terms. Such decomposition not only facilitates understanding ofthe general shape of the solution space but also gives rise to a set of simplified equationsfor each regime to approximate the solution in the regime. Since this reformulation oper-ates solely on equations and variables, we place it among reformulation techniques for theEquation Processing Stage.Fig. 13 depicts the entire problem-solving strategy as a two-step process of decomposi-tion (R1) followed by solution of a simplified set of equations (R2). Once the problem isdecomposed into regimes (as shown in P2), one can select a regime whose conditions aresatisfied by the set of givens and solve the simplified equations.The problems P1, P2, and P3Query1 = Query2 = Query3: Determine the values of the unknown variables.Form1: A set E of nonlinear algebraic equations involving a set G of given parametersand a set X of unknown variables.Assmpt1: None.Form2: A set of sets of simplified equations. Each set of equations is accompanied by aset of validity conditions about the relative orders of magnitudes of the parametervalues.Given values of the parameters in G.10 When the degree of the equations is equal to or higher than five, there exist no general closed form solutions(by Galois).B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204185Assmpt2: None.Form3: A set of simplified equations in a chosen regime.Computed values of the unknowns in X.Assmpt3: The given values of the parameters in G satisfy the validity conditions of thechosen regime.The reformulation techniques, R1 and R2The entire problem-solving strategy consists of a sequence of two reformulationprocesses, R1 and R2.R1 replaces the original equation model by a patchwork of sets of simplified equationsand determines their validity conditions. R1 has no conditions. The procedure of R1 reliesheavily on a process called qualitative resolution to simplify and solve equations usingorders of magnitude information. R1 employs the machinery of Minima [40] for mixedqualitative and quantitative algebraic reasoning and Estimates [27] for reasoning aboutorders of magnitude information.Proc1 consists of the following five steps:1. For each equation in E, a set of caricatural assumptions is generated. An assumptionis generated by extracting from the equation the relative strength of the terms and byexaggerating this feature. Each assumption is in the form of term1 (cid:2) term2, whereterm1 and term2 are terms appearing on the opposite sides of the equation.2. A set C of all consistent combinations of caricatural assumptions is generated. Eachsuch combination is called a dominance regime.3. For each dominance regime c ∈ C, a set E(cid:9) of simplified equations is generated fromc and E. Each set of simplified equations holds under the assumptions defining thedominance regime.4. For each dominance regime, a qualitative resolution mechanism is applied to the set ofsimplified equations to generate equations each containing only one unknown variable.5. The validity conditions for each dominance regime are computed. Validity conditionsare a set of relations involving only the parameters in G, and they are conditions thatcan be tested once the values of G are provided to select an appropriate dominanceregime. Validity conditions are derived from c and E(cid:9) using repeated qualitative reso-lution to eliminate all the appearances of unknown variables from c.Once a problem is simplified by R1, it is solved by R2 for a specific case. Given aspecific set of values for the parameters in G, Proc2 selects an appropriate dominanceregime and solves the simplified equations for the unknown variables using any availablemechanism for solving algebraic equations. R2 has no particular conditions.Evaluators and effectsEvalsprob, Comparsprob: The most immediate and obvious effect of caricatural rea-soning is on the compactness of the formulation, which is in Evalsprob. Caricat-186B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204ural reasoning makes a formulation less compact. While the original formulationdescribes the entire behavior with one set of equations, reformulation results in along conjunction of conditionalized sets of equations.A more important effect of caricatural reasoning is to simplify the equations. Sim-plicity of equations, which is also in Evalsprob, is measured in this case by thenumber of terms and the degrees of equations. Caricatural reasoning simplifiesequations in these aspects since the addition of assumptions often results in theremoval of terms after the qualitative resolution of equations, though in somecases an additional assumption results in no such simplification.Simplification also has obvious implication on the solvability of a set of equa-tions (also in Evalsprob). Simplicity in the above sense will generally makeequations easier to solve and even make hitherto unsolvable ones to have close-form solutions. Note, however, that there is no guarantee that simplification willin fact make the equations solvable.Another aspect of a formulation that Williams and Raiman emphasize is the cog-nitive transparency, which is also in Evalsprob. Cognitive transparency of aformulation refers to ease of deriving from the formulation insight into the behav-ior of the whole system. Though this aspect is clearly subjective and difficult todefine precisely, it is an important objective in many examples of reformulation.In the case of caricatural reasoning, Williams and Raiman argue that decomposi-tion of the problem space and simplification of equations lead to more cognitivetransparency—an argument that seems to be borne out by the chemistry examplethat they present.Since caricatural reasoning is an approximation technique, the answer to the querywill be less accurate as a result. Accuracy of an answer is in Evalsprob. Themagnitude of the error will depend on the actual parameter values and the regimeselected to compute the answer. Williams and Raiman note that they are unableto bind the error, and they recognize the importance of extending their method inthis direction.Evalsp+r+p: An aspect of caricatural reasoning thatis repeatedly mentioned byWilliams and Raiman is that it preserves nonlinearity of equations, which isin Evalsp+r+p. However, their own example shows that nonlinearity is notnecessarily preserved in all regimes. Stated more broadly, their objective is that“approximation should preserve essential characteristics of the behavior”. This isanother qualitative evaluator that is difficult to define precisely.Evalsp+r: Caricatural reasoning could be evaluated in terms of its computational cost,but the actual cost will depend on the types and size of the system of equations.The authors do not provide complexity analysis of the steps in the reformulationprocedure. Even if the decomposition step (R1) is expensive, it may be cost-effective if the cost can be amortized over a large number of actual problemssolved (R2).Discussion. The most significant contribution of caricatural reasoning is that it proposesan automatic method to identify a meaningful decomposition of the problem space wheresuch decomposition is not immediately obvious. In contrast, in both linear approximationB.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204187Fig. 14. Comparative analysis by exaggeration.of nonlinear systems (discussed in Section 5.2.2) and aggregation of nearly decomposablesystems (discussed in Section 5.2.1), a reasonable way to decompose is fairly obvious fromthe original system. Furthermore, despite the fact that decomposition does not necessarilyguarantee that the resulting equations will be solvable, the decomposition itself is of muchvalue in this case since it provides a person with insight into the space of solutions andhelps her identify interesting families of solutions.Caricatural reasoning achieves such decomposition through exaggeration of relativemagnitudes of terms in equations. Exaggeration is also the modus operandi of the reformu-lation technique we turn to in the next section. However, exaggeration in the next sectionhas the effect of complicating a model, while it is used here for the purpose of simplifica-tion.5.2.4. ExaggerationExaggeration is a technique proposed by Weld [36] for performing comparative analysis[35]. Comparative analysis predicts how the behavior of a system will change as a result ofthe perturbation, given a model of the system, its behavioral description and a perturbationto the model. Weld proposes two techniques for comparative analysis, namely Qualita-tive Differential Analysis and Exaggeration in [35]. Exaggeration is of particular interesthere since it involves a unique type of reformulation based on a change in the underlyingmathematics.Exaggeration answers a comparative analysis question by taking perturbation to thelimit and comparing the resulting behavior with that of the original. It proceeds in threesteps, which Weld calls transformation, simulation, and scaling. First, the transformationstep reformulates a given qualitative model into a qualitative model in the space of hyper-real numbers with some of the variables being given extreme values such as infinite orinfinitesimal according to the given perturbation. Second, the simulation step carries outa qualitative simulation using HR–QSIM, which is QSIM, a widely used qualitative sim-ulation program [14], extended with hyper-real numbers. Finally, the scaling step infersthe effects of the perturbation on the behavior by comparing the predicted behavior of thetransformed model to that of the original model obtained by QSIM.We focus on the transformation step in our discussion. Unlike any other reformula-tion techniques discussed in this paper, this reformulation involves very little syntacticchange since the essence of the transformation is a change in the model of numbers un-derlying the formulation from the standard model to the nonstandard one. Exaggeration isalso unique in that the reformulation results in a more complex formulation than the orig-inal one while most other reformulation techniques result in simplification. Complicationof the formulation serves the present goal of comparative analysis by enabling comparisonof the behaviors of the two formulations.188B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204The problemsQuery1 = Query2: What is the consequence of the given perturbation on the behaviorof the system?Form1 comprises:1. A mathematical model in the form of qualitative differential equations (QDEs),2. Initial state description, and3. The perturbation.Form2: QDEs in the hyper-real space, where some of the variable values are given ex-treme values. The choice of such variables and their values depends on the givenperturbation.Assmpt1 = Assmpt2: None.The reformulation techniqueProc1: Reformulation of a standard QDE to a non-standard QDE requires little syntacticchange in the formulation. An important change in the formulation takes place inthe semantic level since, in Form1, all the variables and operators, which usedto be defined over the reals, are now defined over the hyperreals. The difficultpart of the reformulation procedure is deciding how the perturbation is to be re-flected in a value of a variable in the nonstandard QDE. Weld does not provide adeterministic procedure for making this decision in general. His implementationworks correctly for cases where the decision of which and how parameters shouldbe perturbed is straightforward, and it will not work for cases where the decisionrequires more sophisticated reasoning. Weld describes the three parts of this asfollows:1. Choose a parameter to exaggerate. This choice is obvious when the pertur-bation is differential in nature (i.e., question of the type ‘what happens if thevalue of x is increased (or decreased)?’) However, when the perturbation is ofa different nature, such as a change in the physical configuration, there is noestablished procedure for the selection. Weld’s implementation handles onlydifferential perturbations.2. Choose the direction in which the parameter should be perturbed. There isno well-defined procedure for selecting the direction, but there are only twopossibilities, increase or decrease.3. Select the final value for the perturbed parameter. In some cases, this decisionis trivial, either infinity or infinitesimal depending on the direction of pertur-bation. However, there are cases for which this does not work. Weld states ‘theparameter should be transformed to the shortest distance that causes some pa-rameter to reach an infinite or infinitesimal value’ without providing a generalprocedure for doing so.Cond1: None.B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204189Evaluators and effectsEvalsprob: An immediate effect of Exaggeration on the formulation is on its complexity,which is in Evalsprob. Though there is little syntactic change in the qualitativedifferential equations themselves, the shift to a nonstandard model increases thenumber of landmark values in the quantity space of each qualitative variable. Foreach landmark value l that is not +inf or −inf in the original quantity space of avariable, the new quantity space include (HALO l−) and (HALO l+)11 in additionto l. Therefore, the complexity of the formulation measured in terms of the sizeof the quantity space of variables increases as a result of the reformulation.Evalsp+r: This increase in complexity of the quantity space results in a more complexpredicted behavior. The state tree produced by QSIM from Form1 and HR–QSIMfrom Form2 are in general not identical because the former is operating in thespace of standard numbers and the latter in the space of hyperreals, which resultsin a tree with a higher branching factor. Consequently, care must be taken to de-termine what differences in the predicted behavior are indicative of the effects ofthe perturbation and what are due to the difference between QSIM and HR–QSIM.The computational complexity of this scaling step is exponential in the depth ofthe behavior tree but Weld states that it does not in general constitute a problemsince the constant factor is very low compared to that of simulation.Evalsstrat: Exaggeration can be evaluated as a strategy for comparative analysis withrespect to its cost, its soundness, and the quality of explanations it provides(Evalsstrat). The overall cost of the Exaggeration can be computed as thecombination of the costs of the three steps. Although the reformulation step itselfis tractable, both QSIM12 and HR–QSIM13 have a worst-case exponential com-plexity. In his extensive analysis and comparison of Exaggeration and QualitativeDifferential Analysis [35], Weld points out that the inference made by the ex-aggeration method is unsound. This is not to say that HR–QSIM is unsound butthat the inference made to answer the comparative analysis question by compar-ing the two formulations is unsound since it assumes that the system respondsmonotonically to perturbations, an assumption that does not necessarily hold. Healso shows that while DQ analysis has many computational advantages over exag-geration, such as soundness and computational tractability, exaggeration producesmore intuitive and simpler explanations.11 (HALO l−) and (HALO l+) are the notations that Weld used to represent the qualitative values correspondingto the left and right half of the halo of l. They are the sets of all nonstandard numbers that are infinitely close to lbut that are less than or greater than l.12 Cost of the qualitative simulation by QSIM: In general, the time to produce the set of successor states for agiven state is linear with respect to the size of the model. However, since qualitative simulation can suffer fromintractable branching, the number of states produced for a given depth T of the tree can be exponential withrespect to T .13 The cost of the qualitative simulation by HR–QSIM is similar to that of QSIM except that the branching factorof the tree can be higher than that of QSIM. (However, Weld states that intractable branching occurred only in afew pathological cases out of 50 problems tried.)190B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204Discussion. One may question whether the transformation phase in Exaggeration shouldin fact be regarded as reformulation since nothing on the surface of the formulationchanges. We claim that it is a bona fide example of reformulation since a profound transfor-mation takes place in the semantics of the formulation.14 Another example of reformulationinvolving a change in the underlying model of numbers is switching between discrete andcontinuous domains in interpreting equations. Approximating a discrete model by a con-tinuous one (or vice versa) is a practice that is often useful but sometimes dangerous.Switching between standard and nonstandard models of numbers appears less dangerousby virtue of the transfer principle, which allows inferences made in the nonstandard uni-verse to be applied to the standard universe,15 but as the difficulties in the scaling phaseof Exaggeration discussed by Weld suggest, care must be taken in interpreting the resultsobtained using nonstandard models.5.3. Reformulation at the solution processing stageIn this section, we review two reformulation techniques that operate with QSIM to makeits results more understandable. Given a set of qualitative constraints called qualitative dif-ferential equations (QDE) governing the behavior of a system, QSIM predicts its possiblebehaviors by iteratively generating a node that describes its qualitative state then using thequalitative constraints to infer the set of next qualitative states that could follow the currentone [14]. The paths in the behavior tree correspond to possible behaviors of the dynamicsystem, and thus represent solutions to the qualitative differential equations. The biggestproblem that limits the usefulness of a qualitative simulator such as QSIM is the complexityof the results produced. While the ability to predict behavior from an imprecisely specifiedmodel is quite valuable, the imprecision also leads to a high degree of ambiguity in the re-sult. A typical QSIM output is a highly branching tree of states representing a large numberof possible courses of behavior. Complexity makes it difficult for a person to extract usefulpatterns of behavior from such output.The goal of the first example, discussed in Section 5.3.1, is to generate an explana-tion. The goal of the second one, discussed in Section 5.3.2, is to eliminate insignificantbranching in qualitative simulation. The former fits in a straightforward fashion into ourframework for reasoning about physical systems (Fig. 1): QSIM is used to solve the quali-tative differential equations (Equation Processing Stage), and the reformulation procedureis applied to the generated behaviors (Solution Processing Stage). The problem solvingprocess involving the second reformulation technique is more complex: the reformulationof the solution is interleaved with equation solving, producing a more compact behavior14 The surface similarity between the two formulations before and after transformation is a simple artifact of thepractice in nonstandard mathematics to use the same set of symbols for arithmetic operators as those in standardmathematics.15 A general form of transfer principle can be stated informally as follows (from “Standard and NonstandardAnalysis” by R.F. Hoskins, Ellis Hoswood Limited, 1990): “Every properly formulated proposition with boundedquantifiers about standard objects [. . .], will be true in the standard universe if and only if the corresponding propo-sition (suitably re-interpreted if necessary) about their nonstandard counterparts [. . .] is true in the nonstandarduniverse”.B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204191Fig. 15. Solution reformulation.tree and enabling the simulation engine to carry out simulation further than otherwise pos-sible.5.3.1. Behavior abstraction for explanationIn [19], Mallory et al. make the results produced by QSIM easier to understand bysummarizing along user-specified dimensions. Their goal is to support individual users ininterpreting QSIM results. Fig. 15 illustrates their approach. Given the aspects of behaviorthe user is interested in (such as a combination of variable values and their directionsof change), the reformulation procedure extracts a graph of abstract states from a QSIMstate tree. The procedure examines the states in the original tree, discards unnecessaryinformation from them, and aggregates adjacent nodes and arcs that are indistinguishablefrom the perspective specified by the user. The result is an abstract graph that reveals onlyinformation that the user wants to see. The result is also much smaller so that it can beeasily inspected visually to identify significant patterns of behavior such as oscillation.The problems, P1 and P2Query1 = Query2: Predict the qualitative behavior of the given system over time.Form1 comprises:1. A state tree produced by QSIM. Each node of the tree represents a qualitative state ofthe system and an arc a transition. Each path through the tree corresponds to a possiblebehavior over time.2. A method for labeling nodes. This method specifies the dimensions of the behavioralong which aggregation is to take place. A typical method may specify the values anddirections of change of a subset of the variables, but it could potentially be any methodfor labeling.Form2: A graph of abstract states. Each node corresponds either to a node or to an aggre-gate of nodes in Form1. Likewise, for the arcs. In addition, each node containsonly information specified by the labeling method.Assmptn1 = Assmptn2: The same assumptions underlying QSIM.The reformulation technique, RProc comprises the following steps:1. Label each node in the tree by the given labeling method.192B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–2042. Generate a graph by aggregating nodes that are adjacent and have the same labels. Arcsare also aggregated as necessitated by aggregation of the nodes. The exact conditionsfor merging nodes and arcs are specified in [19], but roughly speaking, two nodesare considered adjacent if “one is the successor of the other or if they share commonimmediate predecessors or successors”.Cond: None.Evaluators and effectsEvalsprob, Comparsprob: The primary objective of Mallory’s technique is to improvethe understandability of the generated behavior by projecting it over the dimen-sions specified by the user, which also reduces significantly its size. With respectto Size, which is be measured by the number of nodes and arcs in the graph, thesize of the abstracted behavior graph is guaranteed to be equal to or smaller thanthat of the original one. Understandability is more difficult to quantify, butone aspect of it is the ratio of the amount of information that is pertinent to theuser’s specified interest to the total amount of information in the formulation. Thismeasure is also in Evalsprob(P ), and its value for P2 is always 1 as the authorsprove that the abstracted behavior graph is guaranteed to keep only those statespertinent to the query, while the value for P1 is likely to be much smaller. Finally,as an observation with respect to understandability, the authors report that the userhas to experiment with different specifications of the labeling method in order toreach a satisfactory summary of the behavior of interest.Evalsp+r+p: The authors evaluate the reformulation process with respect to Sound-ness and Completeness. The authors define soundness to be that any path inthe abstract graph should correspond to at least one path in the original tree, andcompleteness to be that any path in the original tree should correspond to somepath in the abstract graph. They prove that an abstract graph produced by theirprocedure is always sound and complete with respect to the original tree.16Evalsp+r: The reformulation procedure is evaluated with respect to its complexity,which is polynomial in this case with respect to the size of the state tree, as-suming that the complexity of the labeling method is no more than polynomialwith respect to the number of variables.Discussion. Most solution reformulation techniques aim to facilitate the interpretation ofcomplex results produced by other programs through additional processing such as summa-rizing, graphing, generating natural language explanations, and extracting specific aspectsof the results [11]. The work discussed in this section is a clear example of such techniques,and though what is produced is another graph representing behaviors, it provides a goodbasis for generating high-level explanations. In fact, the authors state that their ultimategoal is to produce a natural language explanation of qualitative behavior.The technique is based on a simple idea but the approach is quite general and allows awide range of perspectives for summarizing since one can basically provide any piece of16 Thus, the procedure defines a surjective mapping between the original tree and the reformulated graph.B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204193code as a method for labeling the nodes. It places the burden of specifying the perspectivesquarely on the user’s shoulder, which may be inevitable since it is impossible to anticipateall the different perspectives from which users may wish to examine a given result.5.3.2. Chatter elimination in qualitative simulationIn [3], Clancy and Kuipers address the problem of chatter in qualitative simulation. Thephenomenon of chatter in qualitative simulation is one of the important factors that un-necessarily undermine the applicability qualitative simulation and complicate its results.Chatter happens when the direction of change in a variable is constrained only by con-tinuity. Since variables in such a situation are free to alternate among the three possibledirections of change, namely increasing (inc), steady (std), and decreasing (dec), thismay lead to intractable branching even though such branching reveals no significant infor-mation about the possible behaviors. The situation can be even worse since any number ofvariables may be unconstrained. Branching due to chatter may cause the size of the behav-ior tree to become infinite, limiting the range of behaviors that can be explored by QSIM[14]. Clancy and Kuipers propose two techniques, Chatter Box Abstraction and DynamicChatter Abstraction, each of which can be used to eliminate all occurrences of chatter inthe behavior tree. We focus on Chatter Box Abstraction in our discussion since it can bemore clearly viewed as reformulation than Dynamic Chatter Abstraction.To eliminate chatter during QSIM simulation, Chatter Box Abstraction is carried outevery time simulation enters a potentially chattering state. Simulation is first suspended,analysis is carried out to determine the chattering variables, and abstract states are insertedinto the behavior tree, before simulation is resumed. Fig. 16 illustrates the strategy of alter-nating simulation and reformulation as a path leading from P0 to Pn. As a result of ChatterBox Abstraction, regions of a behavior tree that can include a large number of chatteringstates and, thus, potentially represent an infinite number of distinct behaviors, are replacedby abstract nodes, extending the range of models that can be simulated by QSIM.The problems, P1 and P2Query1 = Query2: Predict the behaviors of the physical system.Form1 comprises:Fig. 16. Chatter elimination.194B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–2041. A set of Qualitative Differential Equations (QDEs).2. A partial behavior tree in which one of the states indicates the possibility of chattering.(The condition for detecting this possibility is given below as the condition of thereformulation procedure.)Form2 comprises:1. The same set of Qualitative Differential Equations (QDEs).2. A partial behavior tree that is the same as above except for new abstract states thatreplace the chattering states and their successors.Assmptn1 = Assmptn2: The same assumptions underlying QSIM.The reformulation technique, RBefore simulation starts, the constraints in the QDE are analyzed to identify the vari-ables that can potentially chatter and those that can never chatter throughout simulation.Variables that can chatter are further grouped into sets called chatter equivalency classes,such that if any one variable in a class starts to chatter, all the remaining variables in theclass will also chatter.Proc: The reformulation procedure consists of the following two steps. The first stepdetermines which variables are actually chattering, and the second step createsabstract states when chattering is detected.1. Determination of variables that exhibit a chattering behavior is accomplishedby a recursive call to QSIM to explore a limited region of the state space. Inthe recursive call, only the directions of change of the potentially chatteringvariables are allowed to change. The result is analyzed for existence of chatter.Chattering is detected if there are cycles in the graph of states that are onlydistinguished by the directions of change in some variables.2. Once chattering is detected, the states involved in the cycles are summarizedinto one abstract state, where the direction of change of each chattering vari-able is represented by a list of possible directions (inc, std, dec). Thesuccessor states (i.e., the states that are successors of the states included inthe cycles but are not themselves in any cycle) are also abstracted in the samemanner. In other words, if any successor states are different from each otheronly in the direction of change in the chattering variables, they are summarizedinto one abstract state. Abstract states are inserted into the original behaviorgraph and simulation resumes.Cond: The reformulation procedure is triggered when a potentially chattering variable ischanging within a time-interval state.Evaluators and effectsFor the purpose of assessing the benefits the reformulation, what should be evaluated inthe case of Chatter Box Abstraction is not the changes brought about by individual deploy-ment of the reformulation procedure but the cumulative effects of repeated deploymentB.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204195on the final result as well as on the computational effectiveness. Thus, we must comparePn and Pm as well as the strategies represented by the paths leading to them from P0 inFig. 16.Evalsprob, Comparsprob: The main effect of Chatter Box Abstraction is on the com-pactness of the state tree. Compactness can be measured in terms of the number ofdistinct behaviors (i.e., paths through a state tree). Clancy and Kuipers empiricallyevaluate the effect of the technique with respect to this measure and demonstrate1 to 3 orders of magnitude reduction in the number of behaviors predicted (Ta-ble 1 in [3]). Such reduction is significant in itself, but even more significant isthe fact that it makes the result of simulation by QSIM much easier for a personto comprehend. Cognitive transparency is also in Evalsprob, and even thoughit is difficult to quantify, it is an important aspect of a formulation that could de-termine the usefulness the overall problem solving effort. In addition, Clancy andKuipers evaluate the abstracted tree Pn by its correctness with respect to Pm. Theyguarantee that the set of trajectories in Pn is equal to the set in Pm with respect tothe non-chattering variables and that it is a super-set with respect to the chatteringvariables.Evalsp+r: The evaluator here is the computational complexity of Proc applied toForm. Each time Proc is invoked, the number of states explored in step 1 ofthe procedure is exponential in the worst case with respect to the number of chat-tering variables.Evalsstrat: By eliminating the behaviorally insignificant distinctions among states,Chatter Box Abstraction cuts down on the branching factor of the behavior treeand enables QSIM to explore a much larger portion of the state space than other-wise possible for given computational resources. Interestingly, the whole compu-tational process of simulation remains intractable with or without reformulation.However, Chatter Box Abstraction improves computational effectiveness by en-abling QSIM to avoid the futile effort of expanding infinite sequences of chatteringstates, thus using resources more efficiently. One way to measure computationaleffectiveness is would be to measure the ratio of the amount of time wasted onexpanding chattering states versus the overall processing time.Discussion. Unlike Chatter Box Abstraction, discussed above, Dynamic Chatter Abstrac-tion [3] does not make recursive calls to QSIM to determine the chattering variables.Instead, it relies on the current state and the constraints to determine if the current statecan lead to chattering. Dynamic Chatter Abstraction is more tightly integrated into thequalitative simulation process, and though the algorithm of Dynamic Chatter Abstractionis still exponential with respect to the number of chattering variables, the experimentalresults reported by the authors show that the it can outperform Chatter Box Abstractionby a factor of 4 to 10. Though it is devised to accomplish the same goal as Chatter BoxAbstraction, Dynamic Chatter Abstraction basically eliminates the need to reformulate byspending more resources analyzing the current state and the constraints to avoid generatingchattering states.196B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204Chatter Box Abstraction and Dynamic Chatter Abstraction along with the behavior ab-straction technique discussed in Section 5.3.1 present an interesting spectrum of techniquesfor reducing complexity. On one extreme, behavior abstraction tries to simplify after alarge complex result is produced. On the other extreme, Dynamic Chatter Abstraction triesto avoid producing unnecessarily complex results in the first place by doing more analy-sis during simulation. Chatter Box Abstraction is somewhere in between as it interleavessimulation and reformulation, trying to limit the area of behavior space that needs to bereformulated at any one time.5.4. DiscussionReformulation techniques vary widely with respect to their goals, the types of formula-tions they operate on, their actual effects on these formulations, their cost, etc. Having re-viewed a variety of reformulation techniques, we now summarize our findings and presentgeneral observations. Table 2 summarizes five key aspects of the reformulation techniquesexamined in this paper. The first column indicates the purpose of a technique, which isthe ultimate goal of the authors of the technique. The second column indicates the type offormulation to which each technique is applicable. The effect column describes the princi-ple change brought about by reformulation. The procedure column summarizes the majorsteps for realizing the change. The last column lists the key information, besides a repre-sentation of the system being modeled, that each technique relies on in order to carry outthe steps. In addition, the table indicates the reasoning stage at which each technique isapplied.5.4.1. Purpose of reformulationThe purposes listed in Table 2 for each technique are the ones stated by its authors. Ingeneral, the purpose of a reformulation falls in one of two categories; namely, facilitatinghuman understanding and facilitating problem solving. The former category encompassesthe techniques that seek better explanations and cognitive insight, and the latter includesthose aimed at reducing computational cost and making hitherto unsolvable problems intosolvable ones. The goals of these two categories are not mutually exclusive and somereformulation techniques actually achieve the objectives of both categories. For example,a technique that reduces the size of a formulation may decrease the cost of finding thesolution and make the formulation easier to understand at the same time. Exaggeration isan oddball among all the techniques. Its purpose, which is to compare the behavior of areformulated model with that of the original one, does not fall in either category. We arenot aware of other examples of this type although they may exist.We must point out that there is sometimes a leap of faith between the purpose of areformulation technique as stated by its authors and what it actually achieves. This is es-pecially true in cases where improvement of human understanding is the claimed purposeof reformulation. None of the works we surveyed actually demonstrates improved under-standability of the resulting formulation. Those that aim to generate better explanations donot actually generate explanations, but it is hoped that their reformulation improves thequality of the explanations to be generated.B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204197Table 2Summary of the reformulation techniqueTechniquePurposeFormulationtypeEffectsProcedureKey information StageModelSimplification(Section 6.1.1)CriticalAbstraction(Section 6.1.2)Aggregation(Section 6.2.1)Linearization(Section 6.2.2)BetterexplanationModelfragmentsMoreapproximatemodelReplace byapproximatemodel fragmentsBetterexplanationComponents,Behaviors,InteractionsCost reduction EquationsSolvabilityEquationsLess equations/variablesAggregate paths.Eliminate partsLess equations/variablesLinear equations Focus.Decompose.AggregateCaricaturalReasoning(Section 6.2.3)Exaggeration(Section 6.2.4)Solvability &cognitiveinsightComparativeanalysisBehaviorAbstraction(Section 6.3.1)ChatterElimination(Section 6.3.2)Betterexplanation &cognitiveinsightCost reduction& cognitiveinsightEquationsLower degree forequationsEquationsState graphNonstandardmodel that allowsexaggeration ofvalues to extremeSmaller behaviorgraphState graphSmaller behaviorgraphReplace bysimpler modelDecompose.ExaggerateReplace theunderlyingsemanticsProject.Aggregate (aftersimulation)Aggregate(duringsimulation)ModelCausal relationof interest.Assumptionclasses.Causal relationof interestThresholdvalue εEquilibriumpointGivenvariablesDisturbedvariable andvariable ofinterestLabelingmethodEquationSolution5.4.2. Effects of reformulationThe effects of reformulation are the actual changes a particular technique brings aboutin a formulation, distinct from the stated purpose discussed above. In the discussion of eachtechnique, we have identified what and how aspects of formulations are changed in termsof a set of evaluators and comparators. The most common effect in all techniques, exceptExaggeration, is what one might generally call ‘simplification’. However, as we argued inSection 2.3, this labeling is insufficient since the exact metrics of simplicity varies in everycase. We list below factors of simplicity used in different techniques. The precise definitionof simplicity sometimes involves multiple factors. For example, the definition of simplicityin Model Simplification relies both on the knowledge of approximation relations as wellas that of subset relations of causal orderings among variables.• Simplicity based on the size of the formulation:– Fewer variables, equations, and/or causal orderings.Examples: Critical abstraction, Aggregation, Model simplification.– Fewer states and transitions.Behavior abstraction, Chatter elimination.198B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204• Simplicity based on the form of equations:– Linear vs. nonlinear.Example: Linearization.– Degree of equations.Example: Caricatural reasoning.• Simplicity based on the concept of approximation:– Example: Model simplification.175.4.3. Reformulation procedureWhile reformulation procedures are varied, some general types of manipulation emergefrom the examples, which we will call here generic methods. The generic methods wehave observed in our examples are replacement, decomposition, aggregation, and focus-ing. A reformulation procedure often consists of the application of one or more genericmethods:Replacement: Examples are Model simplification, Linearization, Exaggeration. The re-formulation consists in replacing a part or the entire formulation by anotherformulation. The alternative used must have a well-defined relationship to theoriginal but may not have been generated by the reformulation technique itself(e.g., model simplification).Decomposition: Division of the entire problem space into smaller ones. Examples areAggregation and Caricatural reasoning.Aggregation: Parts that are “adjacent” according to some criterion are merged. Examplesare Aggregation, Critical abstraction, Behavior abstraction, and Chatter elimina-tion.Focusing: Removing parts of the formulation from consideration to emphasize the remain-ing parts. Examples are Critical abstraction, Behavior abstraction, and Lineariza-tion. The labeling method of Behavior abstraction provides the projection mecha-nism to filter out uninteresting information about each component. Linearizationfocuses on the area around the equilibrium points, while ignoring everything else.5.4.4. Key informationEvery reformulation is guided by a specific query. All the techniques discussed, ex-cept Chatter elimination, require some additional information, beyond the representationof the system modeled, to address only the aspect of the formulation that is relevant tothe query. Three techniques (i.e., Model simplification, Critical abstraction, and Exaggera-tion) require the specification of the variables of interest. Model simplification and Criticalabstraction require also the specification of causal relations among these variables. Lin-earization requires the selection of an equilibrium point. The labeling method of Behaviorabstraction is a procedural way to specify one’s interest. Aggregation requires the specifi-cation of a threshold value (ε), which allows one to focus on mid- to long-term behavior.17 The approximation relations among model fragments are stated a priori by the builder of the knowledge base.B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204199In Chatter elimination, it is implicit that the chattering behavior is uninteresting and needsto be eliminated.5.4.5. Processing stageSince reformulation is simply one step in the larger endeavor of reasoning about phys-ical systems, it is important to localize where a particular reformulation technique fits inthe entire problem-solving process. Doing so enables one to discover other reformulationopportunities for achieving the same purpose and to explore the trade-offs of reformulatingat different stages.On the one hand, reformulating at an early stage has the advantage of having one model-equations-solution sequence where the relations between the formulations at consecutivesteps are clear. Indeed, if one chooses to reformulate at a later stage, the causal relations be-tween the original model and the end result of the physical system becomes more complex,less direct, and can be harder to explain.On the other hand, if the primary goal of applying a reformulation is to affect the per-formance of a particular reasoning stage, it may be preferable to reformulate the encodingclosest to the targeted reasoning stage. Reformulating at an earlier stage may prevent usfrom controlling the effects of reformulation we are seeking as precisely as we would wish.For example, Model Simplification (Section 5.1.1), which reformulates a model, resultsin a consistent model-equations-solution sequence that will be easy to trace and explain.However, if the primary goal were to produce equations that are easier to solve or solu-tions that are less complex to interpret, the benefits of Model Simplification could be lesspredictable.6. Related workVarious general theories of reformulation, including abstraction and approximation,have been proposed in the literature. Some of these theories provide an encompassinghigh-level characterization. Others restrict their scope to some specific aspect (e.g., costor faithfulness of results). These theories proved to be essential to our understanding ofreformulation, but we found them to be of limited practical use in automating the selectionof reformulation techniques.Giunchiglia and Walsh [10] introduced a general theory of abstraction applicable totheorem proving in formal systems, and illustrated their theory in planning and common-sense reasoning problems. They introduced a formal classification of reformulation and itsproperties, as well as highlighting their use for both provability and refutation. Importantly,their theory also encompasses those techniques that may yield inconsistencies. Giunchigliaand Walsh acknowledged that their terminology does not capture all desirable properties ofabstraction, such as the upward and downward-solution properties proposed by Tenenberg[34] based on the structure of the proof tree in theorem proving. Plaisted [25], Cremoniniet al. [4], and Nayak and Levy [22] also explored abstraction theories that are restricted tological systems and to techniques that preserve consistency and correctness of proofs.Each of these general theories of abstraction deals with only one, mainly logical, aspectof reformulation and addresses only a few aspects of change that can be cleanly character-200B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204ized formally. We find that those logical theories are often not sufficient, and sometimes notuseful, for characterizing the types of reformulation used by engineers or those proposedin the literature about model-based reasoning. Another serious problem with those logicaltheories is that they ignore the relevance of problem-solving goals of reformulation, whichwe believe is crucial in understanding why and how aspects of a formulation are affectedby reformulation.The goal-directed nature of reformulation is addressed by Weld and Addanki in [37,39].Weld and Addanki [39] take a task-driven approach to reformulation and adopt Tenenberg’svocabulary [34] for describing the effects of the reformulation on the formulation. In hispaper on approximation reformulations [37], Weld discusses the idea of switching betweentwo models18 in order to find the model whose predictions best match some observations.In this work, models are organized as nodes in a graph, called a graph of models (GoM),whose edges represent the approximation relations among models obtained by the elimina-tion of one assumption. These works are more relevant to reasoning about physical systemsthan the general, logical theories of abstraction, since many, but not all, reformulations usedby engineers can be seen as approximations. However, they only deal with only one typeof reformulation, namely approximation. In addition, the goal of approximation reformu-lations is not to dynamically reformulate, but rather to exploit a fixed set of models andidentify the one best that satisfies given criteria.None of the theories discussed so far makes extensive analysis of complexity issues, nordo they provide the terminology for quantitatively evaluating the effects of reformulation.In contrast, the body of research on approximations in the computational complexity com-munity [24], provides rigorous evaluation criteria with respect to cost. More specifically,the reformulation procedure is constrained to logarithmic space mappings, and the goalpursued is strictly the improvement of the computational cost, while providing a guaran-teed bound on the quality of the result.19 While focusing on the computational aspects,these approaches are not concerned with the important aspects of representation and ex-pressiveness.Our work comes closest in spirit to [5], where Davis studies approximation and ab-straction and focuses on the practical application of reformulation techniques applied toreasoning about solid object kinematics. Davis also stresses that the selection of the re-formulation technique must be task-driven, in order to satisfy some well-defined criteria.Our work goes further in providing a practical framework for characterizing and compar-ing many different aspects of reformulation techniques in the context of a specific type ofreasoning about physical systems.7. ConclusionsIn this paper we have provided a practical framework for characterizing, evaluating,and selecting reformulation techniques in the context of reasoning about physical systems.18 In his paper, a model is a set of equations.19 In our terminology, this bound can be represented as a comparator the output of two strategies, the one thatcomputes the exact result and the one that approximates it.B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204201Our framework allows one to express the relevant quantitative and qualitative aspects ofa reformulation process, whereas previous theories addressed either logical properties orcomputational aspects. Another important feature of our framework is that it requires oneto explicitly state the effects of reformulation in terms of what and how aspects of theformulation are changed, which is essential in the selection and evaluation of reformulationtechniques with respect to a given goal.Using our framework, we have presented an analysis of eight examples of reformulationtechniques applicable at various stages of reasoning. Though we have limited ourselves tothese eight examples in this paper, we are aware of the vastness of the space of refor-mulation techniques in reasoning about physical systems. In mathematics, one transformsgeometry problems into algebra and vice versa, real analysis into non-standard analysis,number theory into set theory, and so forth. In engineering, one transforms a time do-main into a frequency domain, continuous problems into discrete problems, and so forth.While all the examples in this paper have been discussed in the AI literature, their choicedoes not reflect our belief that they are somehow the most common or the most important.Rather, they were chosen because the set represents breadth in terms of the stages of ap-plication, and also because descriptions of their goals, algorithms, along with examples oftheir execution were readily available to us. This is central to this work since our goal isto characterize reformulation techniques as a specific computational procedure with well-defined scope and effects. Furthermore these examples demonstrate the generality of ourframework since they originate from and are useful in a variety of science and engineeringfields. Both our framework and our narrow focus on the process of reasoning as set out inSection 3 were essential in undertaking this study since a meaningful comparison of sucha diverse set of techniques would have been impossible without a uniform platform.From our investigations, we have learned that characterizing a reformulation techniquein terms of what aspects of a formulation are affected and how these aspects are modi-fied reveals the hidden assumptions underlying the technique. It is essential to uncover andclearly articulate these hidden assumptions since they determine which aspects of the orig-inal formulation are targeted by reformulation, which is a prerequisite for automation. Wehave learned that it is important to place the reformulation step in the context of the overallprocess of reasoning about physical systems in order to precisely predict to what extent thereformulation step contributes to realizing the goal of the problem-solving task. Indeed, wehave noticed that there is often a leap of faith between the stated goal of a reformulationtechnique as presented in a technical paper and how well it achieves the goal. We have alsoobserved that, despite the diversity of the reformulation procedures that we have studied,four distinct types of manipulation emerged as generic methods of reformulation.Our analysis of the eight examples has also shed light on the question of how to select areformulation method in a specific context and for a specific goal. The selection and designof a reformulation method requires the consideration of the following issues:1. What is the goal of the reformulation?2. What effect should the reformulation have on a formulation of the problem in orderto achieve the goal? In other words, which aspect of the original formulation makes itdifficult to achieve the desired goal? Which components and what aspects need to bechanged and how?202B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–2043. At what stage of the problem-solving process is it most effective to reformulate inorder to achieve the goal?4. What information, beyond the representation of the system being manipulated, is avail-able to help focus the reformulation?5. What cost are we willing to pay for reformulation?Reformulation is ubiquitous and techniques for reformulation are varied. Given a broadinterpretation of reformulation as any change in the formulation of a problem, everyproblem-solving step can be conceived as a reformulation. Nevertheless, in the practiceof reasoning about physical systems, it is useful to distinguish reformulation from otherproblem solving steps that make explicit the implications of an existing formulation. Thus,in the work presented here, we have made the distinction. We were able to do so by restrict-ing the context of reformulation to a particular type of reasoning about physical systemswith three distinct stages. We believe that restricting the context and narrowing our fieldhas enabled us to lay out a concrete and practical framework for informed comparison ofreformulation techniques that are relevant in reasoning about physical systems.While our work is still one step away from a formal specification of a language forrepresenting attributes of reformulation to enable automatic selection, we believe that theanalysis of techniques we present here identifies and articulates the features essential tosuch automatic selection. There are several directions in which this work can be extended:• Develop a method for automatically selecting and composing reformulation tech-niques, relative to a given goal.• Identify a reasoning task for which a multitude of reformulation techniques exists.Design and implement a system that consists of a formal representation of the taskand an encoding of these techniques together with an extended set of evaluators. Usethis system to validate our framework and to test its robustness under a variety ofconditions to be selected.• Extend our framework to encompass engine reformulation. We have deliberately ig-nored in our research all reformulations that apply to the engine20 itself (be it aheuristic reasoner, or formal inference rules), because such reformulations do not seemto arise in the class of problems we address. However, this may not hold for the mostgeneral case, and one may have to examine this issue more closely and decide whethermore attributes are indeed required.AcknowledgementsThis work emerged from the discussions of a reading group on reformulation at theKnowledge Systems Laboratory of Stanford University. The group also included WilliamBuchanan, Robert S. Engelmore, Richard Fikes, Tony Loeser, and Todd Neller. We would20 In [10], Giunchiglia and Walsh consider the deductive machinery, denoted ∆, to be part of the formal system towhich the reformulation is applied. They distinguish between ∆-variant and ∆-invariant reformulation dependingon whether or not the same inference engine is used to solve both the original and reformulated problems.B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204203like to thank Ernest Davis, Alon Y. Halevy, and the anonymous reviewers for their con-structive comments. Berthe Y. Choueiry was supported by a fellowship for advancedresearchers from the Swiss National Science Foundation. Yumi Iwasaki was supportedin part by DARPA and the National Institute for Standards and Technology, Rapid Devel-opment, Exploration and Optimization (RaDEO) program, under cooperative agreement70NANBH0075. Sheila McIlraith was supported by the Natural Sciences and EngineeringResearch Council of Canada (NSERC) and by Xerox Palo Alto Research Center.References[1] S. Addanki, R. Cremonini, J. Penberthy (Eds.), Reasoning about Assumptions in Graphs of Models. Read-ings in Qualitative Reasoning about Physical Systems, Morgan Kaufmann, San Mateo, CA, 1990.[2] F.G. Amador, D.S. Weld, Multi-level modeling of populations, in: 4th International Workshop on QualitativePhysics, Lugano, Switzerland, 1990.[3] D.J. Clancy, B. Kuipers, Static and dynamic abstraction solves the problem of chatter in qualitative simula-tion, in: Proc. of AAAI-97, Providence, RI, 1997, pp. 118–125.[4] R. Cremonini, K. Marriott, H. Søndergaard, A general theory of abstraction, in: Proc. of the 4th AustralianJoint Conference on Artificial Intelligence, Australia, 1990, pp. 121–134.[5] E. Davis, Approximation and abstraction in solid object kinematics, TR706, 1995.[6] B. Falkenhainer, K.D. Forbus, Compositional modeling: finding the right model for the job, Artificial Intel-ligence 51 (1991) 95–143.[7] A. Farquhar, A qualitative physics compiler, in: Proc. of AAAI-94, Seattle, WA, 1994, pp. 1168–1174.[8] K.D. Forbus, Qualitative process theory, Artificial Intelligence 24 (1984) 85–168.[9] K.D. Forbus, The qualitative process engine, in: D.S. Weld, J. de Kleer (Eds.), Readings in QualitativeReasoning about Physical Systems, Morgan Kaufmann, San Mateo, CA, 1990, pp. 220–235.[10] F. Giunchiglia, T. Walsh, A theory of abstraction, Artificial Intelligence 57 (1992) 323–389.[11] T.R. Gruber, P.O. Gautier, Machine-generated explanations of engineering models: a compositional model-ing approach, in: Proc. of IJCAI-93, Chambéry, France, 1993, pp. 1502–1508.[12] Y. Iwasaki, I. Bhandari, Formal basis for commonsense abstraction of dynamic systems, in: Proc. of theNational Conference on Artificial Intelligence (AAAI-88), Saint Paul, MN, Morgan Kaufmann, San Mateo,CA, 1988.[13] C.A. Knoblock, J.D. Tenenberg, Q. Yang, Characterizing abstraction hierarchies for planning, in: Proc. ofAAAI-91, Anaheim, CA, 1991, pp. 692–697.[14] B. Kuipers, Qualitative simulation, Artificial Intelligence 29 (1986) 289–338.[15] A.Y. Levy, Y. Iwasaki, R. Fikes, Automated model selection for simulation based on relevance reasoning,Artificial Intelligence 96 (1997) 351–394.[16] R. Ling, L. Steinberg, Automated modeling in computational heat transfer, in: Proc. of the AAAI Fall Sym-posium on Scientific Modelling and AI, Cambridge, MA, 1992.[17] C.M. Low, Y. Iwasaki, Model generation and simulation of device behavior with continuous and discretechanges, Intelligent Systems Engineering 1 (2) (1992) 115–145.[18] D.G. Luenberger, Introduction to Dynamic Systems: Theory, Models, and Applications, 1979.[19] R.S. Mallory, B.W. Porter, B.J. Kuipers, Comprehending complex behavior graphs through abstractions,in: Tenth International Workshop on Qualitative Physics, Fallen Leaf Lake, CA, 1996, pp. 137–146. AAAITechnical Report WS-96-01.[20] P.P. Nayak, Causal approximations, Artificial Intelligence 70 (1994) 277–334.[21] P.P. Nayak, L. Joskowicz, Efficient compositional modeling for generating causal explanations, ArtificialIntelligence 83 (1996) 193–227.[22] P.P. Nayak, A.Y. Levy, A semantic theory of abstractions, in: Proc. of IJCAI-95, Montréal, Québec, 1995,pp. 196–203.[23] T. Nishida, K. Mizutani, S. Doshita, Automated analysis of qualitative behaviors of piecewise linear differ-ential equations, New Gen. Comput. 11 (2) (1993) 159–177.204B.Y. Choueiry et al. / Artificial Intelligence 162 (2005) 145–204[24] C.H. Papadimitriou, Computational complexity (1994) 299–328.[25] D.A. Plaisted, Theorem proving with abstraction, Artificial Intelligence 16 (1981) 47–108.[26] A. Pos, Automated Redesign of Engineering Models, The Dutch Graduate School for Information andKnowledge Systems, 1997.[27] O. Raiman, Order of magnitude reasoning, Artificial Intelligence 51 (1991) 11–38.[28] J. Rickel, B. Porter, Automated modeling for answering prediction questions: selecting the time scale andsystem boundary, in: Proc. of AAAI-94, Seattle, WA, 1994, pp. 1191–1198.[29] J. Rickel, B. Porter, Automated modeling of complex systems to answer prediction questions, ArtificialIntelligence 93 (1997) 201–216.[30] E.P. Sacks, Automatic qualitative analysis of dynamic systems using piecewise linear approximations, Arti-ficial Intelligence 41 (1990) 313–364.[31] H.A. Simon, The architecture of complexity, nearly decomposable systems, in: The Sciences of the Artificial,Cambridge, MA, 1969, pp. 99–101.[32] H.A. Simon, A. Ando, Aggregation of variables in dynamic systems, Econometrica 29 (1961).[33] P. Struss, On temporal abstraction in qualitative reasoning (a preliminary report), in: Proceedings of theSeventh International Workshop on Qualitative Reasoning about Physical Systems, Orcas Island, WA, 1993,pp. 219–227.[34] J.D. Tenenberg, Inheritance in automated planning, in: First International Conference on Knowledge Repre-sentation and Reasoning, Toronto, Ontario, 1989, pp. 475–485.[35] D.S. Weld, Comparative analysis, Artificial Intelligence 36 (1988) 333–373.[36] D.S. Weld, Approximation reformulations, in: Proc. of AAAI-90, Boston, MA, 1990, pp. 407–412.[37] D.S. Weld, Exaggeration, Artificial Intelligence 43 (1990) 311–368.[38] D.S. Weld, Reasoning about model accuracy, Artificial Intelligence 56 (1992) 255–300.[39] D.S. Weld, S. Addanki, Task-driven model abstraction, in: 4th International Workshop on QualitativePhysics, Lugano, Switzerland, 1990, pp. 16–30.[40] B.C. Williams, Critical abstraction: generating simplest models for causal explanation, in: Proceedings of theFifth International Workshop on Qualitative Reasoning about Physical Systems, Austin, TX, 1991, pp. 77–92.[41] B.C. Williams, O. Raiman, Decompositional modeling through caricatural reasoning, in: Proc. of AAAI-94,Seattle, WA, 1994, pp. 1199–1204.