Adversarial dictionary learning for a robust analysis and modelling of spontaneousneuronal activityEirini Troullinoua,b, Grigorios Tsagkatakisb, Ganna Palaginac,d, Maria Papadopoulia,b, Stelios Manolis Smirnakisc,d,Panagiotis Tsakalidesa,baDepartment of Computer Science, University of Crete, Heraklion, 70013, GreecebInstitute of Computer Science, Foundation for Research and Technology Hellas, Heraklion, 70013, GreececDepartment of Neurology, Brigham and Women’s Hospital, Harvard Medical School,Boston MA 02115dBoston VA Research Institute, Jamaica Plain Veterans Administration Hospital,Harvard Medical School, Boston, United States9102ceD42]CN.oib-q[2v12710.1191:viXraAbstractThe field of neuroscience is experiencing rapid growth in the complexity and quantity of the recorded neural activityallowing us unprecedented access to its dynamics in different brain areas. The objective of this work is to discoverdirectly from the experimental data rich and comprehensible models for brain function that will be concurrently robustto noise. Considering this task from the perspective of dimensionality reduction, we develop an innovative, robust to noisedictionary learning framework based on adversarial training methods for the identification of patterns of synchronousfiring activity as well as within a time lag. We employ real-world binary datasets describing the spontaneous neuronalactivity of laboratory mice over time, and we aim to their efficient low-dimensional representation. The results on theclassification accuracy for the discrimination between the clean and the adversarial-noisy activation patterns obtainedby an SVM classifier highlight the efficacy of the proposed scheme compared to other methods, and the visualization ofthe dictionary’s distribution demonstrates the multifarious information that we obtain from it.Keywords: Dictionary Learning, Supervised Machine Learning, biological neural networks.1. IntroductionThe advances of imaging and monitoring technologies,such as in vivo 2-photon calcium imaging at the meso-scopic regime as well as the massive increases in compu-tational power and algorithmic development have enabledadvanced multivariate analyses of neural population activ-ity, recorded either sequentially or simultaneously.More specifically, high resolution optical imaging meth-ods have recently revealed the dynamic patterns of neuralactivity across the layers of the primary visual cortex (V1)leading to this important question: Neuronal groups thatfire in synchrony may be more efficient at relaying sharedinformation and are more likely to belong to networks ofneurons subserving the same function. By using 2-photonimaging, we monitored the spontaneous population burstsof activity in pyramidal cells and interneurons of mouse inL2/3 V1. We found that the sizes of spontaneous popula-tion bursts and the degree of connectivity of the neuronsin specific fields of view (FOVs) formed scale-free distri-butions, suggestive of a hierarchical small-world net ar-chitecture [1]. The existence of such groups of ”linked”units inevitably shapes the profile of spontaneous events(cid:73)Fully documented templates are available in the elsarticle pack-age on CTAN.observed in V1 networks [2, 3, 4]. Thus, the analysis of thespontaneous activity patterns provides an opportunity foridentifying groups of neurons that fire with increased lev-els of synchrony (have significant ”functional connectivity”between each other).In order to analyze these populations and to find fea-tures that are not apparent at the level of individual neu-rons, we adopt dictionary learning (DL) methods, whichprovide a parsimonious description of statistical features ofinterest via the output dictionary, discarding at the sametime some aspects of the data as noise. Moreover, dictio-naries are a natural approach for performing exploratorydata analysis as well as visualization. Given the fact thatthe dictionary is the new space of reduced dimensionality,the computational complexity of its management is muchsmaller compared to the initial raw data and thus, for allthese advantages, DL has been applied in various domains.In brain signaling specifically, the K-SVD algorithm[5], has been used for capturing the behavior of neuronalresponses into a dictionary, which was evaluated with real-world data for its generalization capacity as well as for itssensitivity with respect to noise [6]. DL has been alsosuggested for the EEG (electroencephalography) inverseproblem. Specifically, Liu et al. [7] proposed a supervisedformulation of source reconstruction and supervised sourceclassification to address the estimation of brain sourcesPreprint submitted to Journal of LATEX TemplatesDecember 25, 2019   and to distinguish the various sources associated with dif-ferent status of the brain. Moreover, accurate EEG signalclassification plays an important role in the performanceof BCI (Brain Computer Interface) applications. Ameri[8] adapted the projective dictionary pair learninget al.method (DPL) for EEG signal classification. They learneda synthetic as well as an analysis dictionary, which wereused in the classification step to increase the speed and[9] proposed aaccuracy of the classifier. Morioka et al.dictionary learning, sparse coding method to address theissue of the inherent variability existing in brain signalscaused by different physical and mental conditions amongmultiple subjects and sessions. Such variability compli-cates the analysis of data from multiple subjects and ses-sions in a consistent way, and degrades the performance ofneural decoding in BCI applications.In this work, we propose the Adversarial DictionaryLearning (ADL) algorithm, which captures the synchronic-ity patterns among neurons, and its extended version, theRelaxed Adversarial Dictionary Learning (RADL) for cofir-ing patterns within a time lag. Adversarial training is theprocess of explicitly training a model on adversarial ex-amples, in order to increase its robustness to noisy inputs.Thus, we create an adversarial learning environment byusing clean and adversarial-noisy activation patterns. Themain objectives are the construction of a dictionary thatwill be robust to the measurement noise (i.e. calcium fluc-tuations) as well as to the identification of firing eventsemerging by chance. Both ADL and RADL construct theoutput dictionary by selecting only those patterns of theinput data that contribute to a better reconstructed rep-resentation of the clean input signal than the adversarial-noisy one. After obtaining our trained dictionary, we quan-tify its quality and robustness by training a supervisedclassifier with the reconstructed clean and noisy signals aswell as with the raw ones, and examine when the classifierexhibits the smallest testing error. To assess whether thetrained dictionary has captured the underlying statisticsof the input data, we employ the classification accuracy(i.e. the extent to which the classifier can discriminate theclean from the noisy signal).To validate the proposed algorithms, we employed tworeal-world binary datasets that depict the neuronal activ-ity of a 9-day old and a 36-day old C57BL/6 laboratorymouse. Data was collected using 2-photon calcium imag-ing in the V1, L2/3 area of the neocortex of the animals.Fig. 1 illustrates the format of our data, where each col-umn represents an example-activation pattern that con-sists of 0s for the non-firing events, while 1s represent thefiring events.While DL has delivered impressive results in variousdomains (such as pattern recognition, and data mining),the construction of the appropriate dictionary dependingon the application still remains challenging. A commondrawback in DL algorithms is the generation of real-numbereddictionaries, which in our domain have no physical mean-ing, and thus they cannot be directly used for extracting2useful information from the data nor for visualizations.Thus, an innovative aspect of our work is shaped by therequirement of constructing binary dictionaries (given thebinary activation patterns). Additionally, while the major-ity of the algorithms require a dictionary size parameter,often there is no prior-knowledge on the number of pat-terns that should be used. To overcome these limitations,ADL constructs a dictionary, using the most representativeand robust patterns of the input data and automaticallyestimates the dictionary size, as the algorithm does thisitself during the dictionary construction. RADL offers thesame benefits and is extended to discover temporal pat-terns within a lag (i.e. temporal patterns in larger timewindows). The contributions of this work are summarizedas follows:• Adversarial DL outputs robust to noise dictionar-ies by excluding those patterns from the input data,which could be a result of noise, caused mainly fromcalcium fluctuations or other sources of imaging noise.• Acquisition of an interpretable dictionary, as the dic-tionary elements are selected from the input dataand thus, the dictionary construction is not a re-sult of a mathematical transformation, as opposedto other methods, such as K-SVD [5] or PCA [10].• In contrast to other methods that require a choice ofdimensionality K (dictionary size), here this is not aparameter that has to be determined by the user, orbe estimated (e.g. based on the choice of arbitrarycutoff values or cross-validation methods [11]).• Detection of statistically significant synchronous andwithin a lag temporal patterns of activity, whichcan be distinguished from shuffled data (adversarial-noisy examples), whose temporal correlations are de-stroyed.InThe remainder of the paper is organized as follows:Section II, we describe the proposed approaches. Evalua-tion methodology and experimental results are presentedin Section III. Related work is reported in Section IV, whileconclusions are drawn in Section V.2. Proposed Dictionary Learning FrameworkIn this section we present the proposed DL methods:• Adversarial Dictionary Learning Algorithm (ADL)identifies the synchronicity patterns, i.e. patternswhere the neurons fire within the same time bin(W = 1). For example, in Fig. 1 Neurons 2, 4 and 6(yellow boxes) fire simultaneously.• Relaxed Adversarial Dictionary Learning Algorithm(RADL) is the extension of ADL, which gives thepotential to detect firing activity within a temporalwindow of length that is determined by the user. Forexample, in Fig. 1 Neurons 4 and 5 (green boxes)are not activated simultaneously but within a timewindow interval W = 2.Figure 1: Temporal patterns: Synchronous (W = 1) and withinlarger time windows (W > 1).We also employ a supervised machine learning frameworkto quantify the learning capacity of the dictionaries thatare produced by the two methods as well as their robust-ness to adversarial noise.2.1. Adversarial Dictionary Learning AlgorithmADL aims to identify synchronous activation patternsexisting in the input data and outputs them to a dictio-nary. It is an iterative algorithm, which in every iterationselects randomly an example-activation pattern from thedata and examines if it will be included in the dictionaryor not. Every iteration consists of two stages. In the firststage, the algorithm examines the contribution of the se-lected example in the representation of the input data viatwo representation errors. In the second stage it examinesthe contribution of the example in the representation of thenoisy data (i.e. data that we have artificially added noise)based also on two other representation errors. When thesetwo stages are completed, they are combined in order todetermine if the selected example will be included in thedictionary or not.Given a training set Yclean ∈ BM ×N , where B is thebinary set consisting of 0 and 1, M is the number of neu-rons, N the number of clean examples (yj)Nj=1, where eachone represents an activation pattern (i.e. the activity ofall neurons within one time bin as shown in Fig. 1), weaim to construct a dictionary D ∈ BM ×K, which at theend of the algorithm will have K dictionary elements thatcapture the activity among those neurons. Zero columnsand those with only one 1-entry (firing of only one neuronwithin one time bin) have been removed from the trainingset Yclean, as we are interested only in synchronicity pat-terns (i.e. when two or more neurons fire simultaneouslywithin the same time bin).ADL constructs the dictionary D incrementally, as inevery iteration of the algorithm one example yi of the setYclean is examined as to whether it will be included inthe dictionary or not. The algorithm iterates N times (i.e.for each one of the examples yj that are in the set Ycleanand stops when all of them are examined. Apart from theoutput dictionary D the algorithm also uses an auxiliary3dictionary D(cid:48), which in every iteration of the algorithmhas all the elements of D as well as an extra exampleyi, which at the current iteration is the example that isexamined whether it will be included in the dictionary Dor not. Namely, if at the iteration i, D ∈ BM ×k then D(cid:48) ∈BM ×(k+1). D is initialized randomly with an example yjof the set Yclean and at the first iteration of the algorithmwhen the first yi is to be examined, dictionaries D and D(cid:48)have the following form:D = yj and D(cid:48) = [D, yi] = [yj, yi](1)At the first stage of the algorithm, in order to vali-date and decide if the example yi should be included inthe dictionary or not, we also use a set of clean valida-tion examples Vclean ∈ BM ×(N −1), which consists of allthe examples of set Yclean, except the current example yiunder consideration, namely Vclean = (cid:8)(yj)N −1j=1 , j (cid:54)= i(cid:9).According to the sparse representation framework, giventhe dictionaries D and D(cid:48), we search respectively for thecoefficient matrices X ∈ Rk×N and X(cid:48) ∈ R(k+1)×N . Anapproach to this problem is the minimization of the fol-lowing l0 norm problems:||Vclean − DX||22,minX||Vclean − D(cid:48)X(cid:48)||22,minX(cid:48)subject to ||xj||0 ≤ T0subject to ||x(cid:48)j||0 ≤ T0(2)(3)where ||xj||0 and ||x(cid:48)j||0 are the l0 pseudo-norms, whichcorrespond to the number of non-zero elements for ev-ery column j of the sparse coefficient matrices X and X(cid:48),respectively. The sparsity level T0 denotes the maximalnumber of non-zero elements for every column j of X andX(cid:48). Namely each column can have at most T0 elements.These minimization problems are solved using the OMPAlgorithm [12].Based on eqs. (2) and (3), we examine whether DXor D(cid:48)X(cid:48), which represent the sets Vclean reconstructed andV(cid:48)clean reconstructed respectively, better approach the val-idation set of examples Vclean. Thus, the question underdiscussion is if the example yi, which is included in D(cid:48),contributes to a better representation of the set Vclean.The metric we used to answer this question is:Eclean = {RMSE(Vclean, Vclean reconstructed)}clean = {RMSE(Vclean, V(cid:48)E(cid:48)clean reconstructed)}(4)(5)where RMSE is the root mean squared error. In case ofE(cid:48)clean < Eclean(6)this means that the example yi, which was only includedin D(cid:48) had indeed an effective result in the representationof the validation set Vclean.We will keep up with the description of the second stageof our algorithm, which is partially inspired from adversar-ial learning methods [13, 14], justifying the characterismadversarial that we have given to it. The combination ofthe first and second stage will determine if the exampleyi will be ultimately added in dictionary D. More specif-ically, in order to include the example yi in dictionary D,besides its good contribution to the representation of thevalidation set Vclean, it should be simultaneously a non-helpful factor for the representation of an adversarial noisysignal. This aims to the creation of a dictionary that willIn order to achieve this, we createbe robust to noise.a set of adversarial-noisy examples Ynoisy ∈ BM ×N bycircularly shuffling the spike train of each neuron of theinitial set Yclean by a random number, different for eachneuron. Fig. 2 depicts a simple example with five neuronsspiking at various time bins showing how the adversarial-noisy signal is created. In order to create the noisy signal,we perform circular shifting to each neuron of the initialsignal independently. For example, the spike train of thefirst neuron is circularly shifted by 2 positions-time units.Accordingly, the spike train of the second neuron is circu-larly shifted by 5 positions-time units etc. From both theinitial and the noisy signal, zero columns and those withone single active neuron are removed (filtering). This typeof noise is much more realistic compared to other types,such as random flipping of events, gaussian noise etc., asit preserves the spike distribution of each neuron (firingrate), while it destroys the synchronicity patterns betweenindividual neurons. We also create a validation set of noisyexamples Vnoisy ∈ BM ×(N −1), which consists of all the ex-amples included in set Ynoisy except from a random onethat is removed so that Vclean and Vnoisy have the samenumber of examples.Figure 2: Creation of noisy dataset with circular shift and removalof zero columns and those where only one neuron is active from theinitial and the noisy signal (filtering).In order to evaluate the contribution of the exampleyi to the representation of the set Vnoisy, the followingminimization problems are solved using again the OMP4algorithm:minXnoisy||Vnoisy − DXnoisy||22,s.t.||xj,noisy||0 ≤ T0(7)minnoisyX(cid:48)||Vnoisy − D(cid:48)X(cid:48)noisy||22,s.t.||x(cid:48)j,noisy||0 ≤ T0(8)Using the same metric as that in eqs. (4) and (5), we getthe following representation errors:Enoisy = {RMSE(Vnoisy, Vnoisy reconstructed)}noisy = {RMSE(Vnoisy, V(cid:48)E(cid:48)noisy reconstructed)}(9)(10)This time we should haveE(cid:48)noisy > Enoisy(11)A bigger error in E(cid:48)noisy suggests that the presence ofthe example yi in dictionary D(cid:48) does not contribute to thegood representation of the noisy set of examples Vnoisy.That would be exactly the prerequisite for the inclusionof the example yi in D, if we took into account only thesecond part of our algorithm. Note that the dictionaryD consists only of examples from the set Yclean. The setVnoisy, which results from the set Ynoisy is used by thealgorithm during the training procedure only in order todetermine the appropriateness of the example yi in thedictionary D.Eventually, to determine whether or not to include yiin dictionary D, (6) and (11) are combined in the followingway:E(cid:48)cleannoisy + (cid:15)E(cid:48)<EcleanEnoisy + (cid:15)(12)where (cid:15) is a very small positive quantity, so as zero de-nominators are avoided.If (12) holds, then yi will be also added in dictionary D.Dictionaries D and D(cid:48) would then temporarily be exactlythe same, until the next iteration, where another exampleyi would be added in dictionary D(cid:48), in order to be exam-ined as to whether it should be eventually included in Dor not. Otherwise, ifE(cid:48)cleannoisy + (cid:15)E(cid:48)≥EcleanEnoisy + (cid:15)(13)then yi is removed from dictionary D(cid:48) and it is obviouslynever included in D. The algorithm keeps up with select-ing randomly the next example yi and iterates until all ofthe examples are examined and a desirable dictionary Dis formed. The procedure that we have described so far isdepicted in steps 1-6 of Fig. 3. In step 1 a random exampleyi is selected and the representation errors Eclean, E(cid:48)clean,Enoisy and E(cid:48)noisy of stages one and two of the algorithmare computed. Fig. 3 is a snapshot of our algorithm atFigure 3: Proposed approach: ADL selects all the appropriate examples of set Yclean (steps 1-5) and obtains a dictionary D. Steps 1-5 arerepeated 4 times-epochs and in every epoch dictionaries D and D(cid:48) are initialized with the dictionary obtained from the previous epoch (step6). After the 4 epochs we report the final D.some iteration j, as D and D(cid:48) are initialized with the ex-ample y4, and the example y2 was already examined andincluded in dictionary D, while some other examples mayhave also been examined but were not included in D. So,at the jth iteration another example yi (in blue color) isexamined as to whether it will be included in D or not.Step 2 of Fig. 3 is the combination of stages one and twoit is the step, where the inclusionof our algorithm, i.e.of the example yi in dictionary D is determined. In step3, after we have finished with the example yi, we keep upby selecting randomly the next example yi+1 and steps 1-2are repeated again for this example too. Step 3 is repeatedfor all the examples y(cid:48)js. In step 4 we obtain the dictionaryD, and in step 5 we move on to the next epoch, where Dwill be used to initialize D and D(cid:48) (step 6).In order to report the final dictionary D, the steps1-6 of Fig. 3 are repeated 4 times-epochs in exactly thesame mode that was described previously (we use 4 epochsbecause as shown and discussed later in Fig. 14, after thethird epoch the performance of the algorithm is stabilized).In every epoch of the algorithm the examples in set Ycleanare randomly selected and examined as to whether theywill be included in the dictionary or not. Moreover, fromthe second epoch onward the dictionaries D and D(cid:48) are notinitialized with one random example as in the first epoch.Instead, the algorithm initializes both dictionaries D andD(cid:48) with the dictionary D that was formed in step 5 of theprevious epoch, which is essentially used as a baseline forthe construction of the next dictionaries.The reason for introducing the idea of epochs in our al-gorithm is that in every epoch new examples can be added,which in previous epochs were kept out of the dictionary,because at the time they were selected and examined someother examples with which they could make a good com-bination were not examined yet, and as a result at thatepoch they remained out of the dictionary. After the com-pletion of these 4 epochs the algorithm terminates and asshown in Fig. 3 we report our final dictionary D. We em-phasize once more that the dictionary size does not have tobe predefined by the user, as the algorithm decides itselffor the number of the dictionary elements-patterns thatare sufficient for the effective representation of the data.2.2. Relaxed Adversarial Dictionary Learning AlgorithmIn this section we describe the RADL algorithm, whichis the extension of the ADL algorithm that was describedin the previous part. In addition to the synchronous activ-ity (i.e. firing activity within the same time bin), RADLcan identify temporal patterns within bigger time windowintervals and outputs them to a dictionary.We define a time-window parameter W , which deter-mines the number of time bins that will be used, in order tosearch for patterns with some temporal correlation withinthat interval. Thus, by defining the length of the time-window to be W time bins, we add the content of everyW columns-time bins in an overlapping mode. Namely, wesum the columns y1 + y2 + ... + yW , y2 + y3 + ... + yW +1,y3 + y4 + ... + yW +2 etc. We also normalize all the valuesthat come out from this summation by dividing with thelength of the time-window (i.e. by W ), so that the valuesare normalized in the scale {0 1}. The procedure and the5idea behind this approach, i.e. the reason why the sum-ming of the columns gives us the possibility to identifytemporal patterns within bigger time window intervals isexplained with the following example, which is depicted inFig. 4. If we define the time window for example to beW = 2 time bins, we add the content of every 2 columns-time bins in an overlapping mode as shown in Fig. 4.Namely, we sum up the columns y1 + y2, y2 + y3, y3 + y4etc. and the values that come out from this summationare 0, 1 and 2 (highlighted in blue). The first column ofthe matrix after the summations indicates that neurons 1,2 and 3 have some temporal correlation, which is indeedtrue, as neurons 1, 2 and 3 in the initial signal are acti-vated in consecutive time bins. More specifically, neuron1 is activated exactly one time bin before neurons 2 and3, while 2 and 3 are synchronous in the same time bin.In this mode we check temporal correlations among otherneurons too. Then, at the normalization step, all valuesare normalized in the scale {0 1} by dividing with W sothat the and thus, values 0, 0.5, and 1 for W = 2 time binsrepresent:• 0: Neuron did not fire at all within W = 2 time bins• 0.5: Neuron fired in one of the two time bins• 1: Neuron fired consecutively at each time binThen, at the filtering step, zero columns and those withonly one non-zero entry are removed. The same procedureas it is depicted in Fig. 4 is obviously repeated for thenoisy signal too. The summing of the columns in the ini-tial signal results to a signal that has less zero columns andcolumns where only one neuron is active. We can also ob-serve this in Fig. 4, where the initial signal included threezero columns and one column where only the first neuronwas active, while after the summing of the columns thesignal remained with only one zero column. Thus, dur-ing the filtering procedure the amount of columns thatare removed is much smaller than before (i.e. when weapplied the ADL algorithm and there was no column sum-ming), which results to a training set Yclean with moreexamples. Thus, as we increase the time window, thenumber of columns that have to be removed during thefiltering is much smaller, which results to an increase inthe number of the examples of each set as shown in Ta-ble 1. The increase in the number of the training examplesbrought also an increase in the size of the dictionary, whichRADL outputs and in order to compress it, apart fromthe sets Yclean, Vclean and the corresponding noisy setsYnoisy and Vnoisy, we also introduce during the train-ing procedure a testing set T1 ∈ F M ×S of S clean andadversarial-noisy examples, where F is the set of normal-ized values in scale {0 1}. T1 is independent from thetesting set T2 ∈ F M ×Q, where Q is the number of cleanand adversarial-noisy examples that will be used in thefinal step of the algorithm, in order to obtain the finalperformance of our model.Figure 4: Searching for patterns with temporal correlation withina time window W = 2. We sum the signal every 2 columns in anoverlapping mode (step 1), we normalize the values (step 2) and weremove zero columns and those where only one neuron is active (step3), for both initial and noisy signal.For the compression of the dictionaries that are pro-duced in every epoch, we use only the clean examples ofthe set T1 (the noisy examples of set T1 are used onlyafter the compression to evaluate the performance of ouralgorithm in every single epoch). More specifically, in or-der to compress the dictionary formed in each epoch weremove all the dictionary elements that are not used signif-icantly in the representation of the clean testing examplesof the set T1. So, after the formation of each dictionaryD (step 4 in Fig. 3), and before we use it in the nextepoch, we examine how much each dictionary element isused for the representation of the clean examples of setT1. The contribution of each dictionary element is mea-sured in the following way: Given the dictionary D thatis formed in the current epoch, we obtain the CoefficientMatrix X, whose columns refer to the clean testing ex-amples of set T1 described above. For every row-vectori of the Coefficient Matrix X, namely for every xi thatrefers to the specific column-vector dictionary element di,we calculate its l2-norm. Then, we sum all the elements ofthe row-vector xi and if the summation is smaller or equalwith the l2-norm, then we remove the element di from thedictionary. The intuition behind this technique is that weremove all dictionary elements that are used negatively forthe representation of most of the examples (i.e. when row-6vector xi has many negative values). Eventually, in thelast epoch of the algorithm (i.e. the 4th epoch) we obtainthe final dictionary D, which is used with the testing setT2 that we have available for the testing procedure, inorder to evaluate the performance of our algorithm.So, what essentially changes from ADL is the inputdata that we give to the system, where every column-timebin in the new data represents patterns that have a tempo-ral correlation within W time bins. Obviously, this infor-mation but in a compressed format is also encoded in thedictionary, providing an insight into temporal correlations.Additionally, during the training procedure of the RADLalgorithm, we compress the dictionary of each epoch byremoving the dictionary elements that have small contri-bution in the representation of the clean examples in T1.2.3. Evaluation of the dictionary qualityIn order to evaluate the quality of the output dictionariesin terms of learning capacity and robustness to noise, weemploy a supervised machine learning framework by train-ing an SVM-classifier with the clean and noisy raw dataas well as with the reconstructed ones (i.e. the output ofDX). We aim to examine the extent to which the clas-sifier can discriminate the clean from the noisy activationpatterns, and whether its training with the reconstructeddata results to a better classification performance, ratherthan when we use the raw data. Thus, the classificationperformance is the quantitative metric offering an insightabout the extent to which the output dictionary has cap-tured the underlying statistics of the data.3. Performance Analysis3.1. Dataset CollectionTo evalute the merits of the proposed modeling approach,we employed two real-world datasets that were collectedusing two-photon calcium imaging in the neocortex of a9-day old mouse and a 36-day old one (C57BL/6). Thefirst dataset of the 9-day old mouse includes 183 neuronsof the layer 2/3 of the V1, and neurons were imaged us-ing calcium indicator OGB-1 (imaging depth 130 micronsfrom pia). The dataset of the 36-day old mouse includes126 neurons of the layer 2/3 of the V1 area. Addition-aly, for the 9-day old mouse 29 minutes of spontaneousactivity were recorded, comprised of 11970 frames, each of0.1451 seconds duration, while for the older one the totalmovie length was 30 minutes comprised of 11972 frames,each of 0.15 seconds duration. The raw fluorescence moviewas motion-corrected to remove slow xy-plane drift. Aftermotion correction, we used ImageJ software [15] to drawthe ROIs of cells around cell body centers, staying 1-2 pix-els from the margin of a cell in the case of the 9-day oldmouse, in order to avoid contamination with neuropil sig-nals and 1-2 pixels for the 36-day old mouse. We then av-eraged the signals of cell ROI pixels and converted them todF/F [16]. To determine the onsets of spontaneous calciumresponses, the dF/F timecourse for each cell was thresh-olded, using the noise portion of the data, to 3 standarddeviations above noise. To make a binary eventogram ofthe responses, for each cell the frames containing the on-sets for this particular cell were assigned the value 1, andall other frames were assigned the value 0. The result-ing binary eventogram of all cells was used in subsequentanalysis.3.2. Adversarial Dictionary Learning (ADL)In this section, we illustrate the performance of our pro-posed algorithm ADL for the case of one time bin windowinterval (W = 1), with respect to other methods, such asK-SVD [5], Analysis K-SVD [17], LC-KSVD [18] and ODL[19]. More specifically, we examine which of the traineddictionaries produced from these methods are more robustto adversarial noise. In order to quantify this information,we examine the extent to which each trained dictionarycan discriminate the clean from the adversarial-noisy acti-vation patterns. Through this analysis the impact of thefollowing parameters is also explored:• Dictionary size (DS), which is the number of ele-ments considered in the dictionary. While in all ex-amined methods, DS must be defined by the user,in our method, it is automatically inferred.• Sparsity level (SL), i.e., the maximal number of dic-tionary elements that are used for representation ofthe examples.We also present some more qualitative results of the dic-tionary that are produced from our proposed method.3.2.1. Parameter SetupAfter the completion of the filtering that is described inFig. 2, we select 50% of the examples of the clean filteredsignal, namely 1138 examples to train K-SVD. Regardingour proposed method, in order to train the dictionary weselect the same 50% examples from the clean filtered sig-nal, as well as 50% of the examples from the noisy filteredsignal. Subsequently, the other half of the clean and noisyfiltered signal sets will serve as the testing set for eachone of the two methods. Namely, they will be used forthe training and testing of an SVM-classifier with gaus-sian kernel and scale σ = 0.01. The classifier is trainedand tested with the:(i) Raw clean and noisy data(ii) Reconstructed clean and noisy data, which are bi-narized by considering all values greater than 0.5 asactivations (1s), while the rest as zeros.The number of the testing examples in set T2 as well asthe number of the training examples in set Y, where Yconsists of the clean examples Yclean and the adversarial-noisy examples Ynoisy for the case of one time bin windowinterval (W = 1) are depicted in Table 1. Note that all sets7SizeTraining Set (Y )Testing Set (T1)Testing Set (T2)W = 1 W = 2 W = 3 W = 4415622762578-37702324364822703336296418662744Table 1: Sizes of the Sets Y , T1 and T2 for all W sdescribed in Table 1 (Y, T1 and T2) include the numberof both the clean and the adversarial-noisy examples (i.e.half of the size of each set described in Table 1 refers to theclean examples and the other half refers to the adversarial-noisy examples).Fig. 5 shows the distribution of the original clean (5(a)) and of the noisy signal (5 (b)), as it results from thecircular shifting procedure. The distributions refer to theactivity of the 9-day old mouse before the process of thefiltering. Namely, in both figures axis x indicates the sizeof co-firing neurons (i.e. the number of neurons that co-activate within one time bin) and the log-scaled axis yindicates the number of these patterns that exist in thedata. We observe that for the noisy signal, circular shift-ing has caused a reduction in zero columns-patterns anda simultaneous increase in doublets (i.e. patterns where 2neurons co-activate within a time bin) as well as in pat-terns where only one neuron is active within a time bin.Finally, more complex patterns with more than seven neu-rons firing simultaneously are completely destroyed.runs are executed in order to examine the sensitivity ofour algorithm with respect to the different sequence thatthe examples are selected. Thus, the K-SVD algorithm isinitialized with a different dictionary in every run, as thecolumns are presented with a different sequence. Regard-ing our algorithm, the different sequence in the columns ofthe training set in every run, results to the selection andas a consequence to the examination of the examples witha different sequence as to whether they will be includedin the dictionary D or not. The testing set remains thesame in all runs. The vertical error bar demonstrates thestandard deviation of these four runs (i.e. how much theaccuracy of each run differs from the mean accuracy of thefour runs). More specifically, as it is illustrated in each sub-figure of Fig. 7, we give as input to the K-SVD algorithm adifferent dictionary size, and we evaluate the performanceof the algorithm compared to our proposed method. Fig.6 depicts the corresponding dictionary sizes that are pro-duced from our method for the case of W = 1. Morespecifically, for every sparsity level (SL), Fig. 6 demon-strates the size of the final dictionary D that is obtainedfrom the 4th epoch for each one of the 4 runs.Figure 6: Size of the final dictionary D for every run and SparsityLevel (SL).We observe in Fig. 7 that when the classifier is trainedand tested with the raw data, the accuracy that it achievesis almost 51%. This percentage is quite low and indicatesthe difficulty of the problem that we are supposed to solve.By using the reconstructed data that are produced by theK-SVD algorithm we observe that the classifier achieves abetter performance with an accuracy of 56% for DS=150elements and for SL=2.In all of the subfigures we ob-serve that as the SL increases, the accuracy of the clas-sifier decreases, which can be attributed to overfitting ofthe system. Moreover, the three different dictionary sizes,which were tried as input to the K-SVD algorithm do notaffect significantly the performance of the classifier. Whenwe use the reconstructed data that are produced from ourmethod and as depicted in Fig. 7, the classifier achievesbetter performance results compared to the performanceof the K-SVD algorithm. More specifically, we obtain anaccuracy of 62% for SL=3 and mean dictionary size (of the4 runs) equal to 418. We observe that for values of spar-sity level greater than 3 the performance deteriorates dueto overfitting. Nevertheless, our proposed method givesbetter performance results for every value of sparsity level.(a)(b)Figure 5: (a) Clean signal distribution (b) Noisy signal distribution3.2.2. Evaluation ResultsFig. 7 illustrates the performance of the SVM-classifierregarding the discrimination between the clean and thenoisy signals for the 9-day old mouse, as a function of thesparsity level when the classifier is trained and tested withthe raw data, the reconstructed data produced by our pro-posed method ADL and the reconstructed data producedby the K-SVD algorithm. Each point in the errorbar plotscorresponds to the mean accuracy of 4 runs and in everyrun the examples in the training set are given with a dif-ferent sequence in terms of the columns (i.e the secondcolumn of the training set in the first run may be the fifthcolumn of the training set in the second run). These 48(a) DS=150(b) DS=200(c) DS=300Figure 7: Mean accuracy classification performance when the classifier is trained with the raw data, the reconstructed data produced by ourmethod ADL and the reconstructed data produced by the K-SVD.In Table 2, we report the mean accuracy performanceof 4 runs for several DL methods and for various values ofDS and SL. The parameters that we used for each methodwere selected after exhaustive search, so that they givethe best possible accuracy performance. Regarding ODLand Analysis K-SVD, the SL parameter is only used withthe OMP algorithm to obtain the coefficient matrix corre-sponding to the testing data (for their reconstruction) andnot during the training procedure (i.e to obtain the out-put dictionary). We observe that Analysis K-SVD outper-forms all the other methods for all the examined param-eters, but still gives a worse accuracy performance com-pared to ADL. The corresponding DSs of ADL for eachSL are reported in Fig. 12.We also applied the PCA method, which is a dimen-sionality reduction algorithm, not dictionary learning based,on both the clean and the noisy test data. We obtainedthe corresponding coefficients and used them in order totrain and test the classifier, which gave an accuracy per-formance of 51.55%As it is already stated, our algorithm executes 4 runs,where in every run the examples of the training set are se-lected and examined with a different sequence as to whetherthey will be included in the dictionary or not. Thus, wewant to ensure that neurons’ firing activity captured bythe dictionaries of each run will be similar and not withintense variations. To that end, we demonstrate Fig. 8,which depicts the variation in the number of firing eventsthat neurons have across the 4 dictionaries formed in eachrun, under the consideration of W = 1 and SL = 2. Weobserve that for most of the neurons (almost 50 neurons)the maximum variation across the 4 dictionaries is only 2firing events, while only one neuron has a variation of 8 fir-ing events. Thus, we end up with 4 dictionaries that havealmost the same number of firing events for each neuron,indicating the robustness of our algorithm with respect tothe different sequence in the selection of the examples.Unlike all the methods that we compared, which pro-9MethodsDSSL=2SL=3SL=4SL=5ODLLC-KSVD1LC-KSVD2Analysis K-SVDADL150200300150200300150200300150200300-0.5080.51610.51570.51550.51050.50770.50620.50560.50650.50650.5060.5060.50770.49760.50630.49960.50410.50690.50110.50320.50060.50250.50180.50370.52670.50770.51880.510.52840.52970.5420.53880.52670.53740.51380.52110.55530.55770.56390.56780.56880.56580.57490.56170.57470.58180.5590.56630.60590.61850.54360.5436Table 2: Mean accuracy performance when the classifier is trainedwith the reconstructed data produced by ODL, LC-KSVD1, LC-KSVD2, Analysis K-SVD and ADL.Figure 8: Neurons grouped in the same bin have the same variationin the number of firing events across the 4 dictionaries formed inevery run (W = 1, Sparsity Level=2).duce real-numbered dictionaries with no physical meaning2345Sparsity Level0.450.50.550.60.650.7AccuracyRaw DataReconstructed Data-KSVDReconstructed Data-Proposed Method2345Sparsity Level0.450.50.550.60.650.7AccuracyRaw DataReconstructed Data-KSVDReconstructed Data-Proposed Method2345Sparsity Level0.450.50.550.60.650.7AccuracyRaw DataReconstructed Data-KSVDReconstructed Data-Proposed Methodfor our application, our proposed method ADL producesdictionaries that provides us with quantitative as well aswith qualitative information, giving us an insight aboutthe synchronicity patterns existing in the data. So, Fig. 9Figure 9: Distribution of the two dictionaries (W =1, SparsityLevel=3).demonstrates the distribution of two dictionaries (we usedthe dictionaries that were produced from the 4th run ofour algorithm, for SL = 3) that refer to the spontaneousneuronal activity of a 9-day old and a 36-day old mouse.Namely, axis x indicates the size of the co-firing neuronsthat exist in the dictionary, i.e. the number of neurons thatco-activate within one time bin, such as doublets (when 2neurons co-activate within one time bin) or triplets (when3 neurons co-activate within one time bin), etc and axisy indicates the number of these patterns (doublets etc.)that exist in the dictionary. The dataset that refers tothe 9-day old mouse, firing events occupy the 0.487% ofthe data, while for the 36-day old mouse firing activityoccupies only the 0.364% of the dataset. These percent-ages show the sparseness of our datasets and by extensionindicate the low frequency of the neurons’ firing activityfor both laboratory animals. Moreover, these percentagesreveal that the 9-day old mouse has a more intense firingactivity, which can be attributed to its young age. Allthis information is depicted in the distribution of the twotrained dictionaries Fig. 9, as we observe that the num-ber of the various synchronicity patterns for the 9-day oldmouse is greater than the number of patterns for the 36-day old mouse. Additionally, the dictionary that refers tothe activity of the 9-day old mouse includes more complexpatterns with more than six neurons firing simultaneously,while for the 36-day old mouse such patterns tend to bezero. Eventually, the size of each dictionary also revealsinformation about the data that we summarize. Namely,the dictionary that refers to the activity of the 9-day oldmouse has a size of 411 elements as depicted in Fig. 6,while the dictionary that refers to the older mouse has asize of 51 dictionary elements, which correctly verifies thatit fires less.103.3. Relaxed Adversarial Dictionary Learning (RADL)This section demonstrates the analysis for temporalcorrelation patterns within larger time window intervals(W > 1). The analysis assesses the impact of the follow-ing parameters:• Time window interval (W ), from which we can ex-tract information about temporal correlations.• Sparsity level (SL), i.e., the maximal number of dic-tionary elements that are used for representation.3.3.1. Parameter SetupAfter the completion of the procedure that is describedin Fig. 4 we select 40% of the examples of the clean filteredsignal, as well as 40% of the examples of the noisy filteredsignal for the set Y, which will be used for the trainingof the dictionary. Then, we select 25% of the examples ofthe clean filtered signal for the set T1, which will be usedfor the compression of the dictionaries that are producedin every epoch as well as 25% of the examples of the noisyfiltered signal in order to evaluate the performance of ouralgorithm at every epoch of each run. Eventually, theother 35% of the clean and noisy filtered examples will beused by the set T2 and will serve as the testing set, whosehalf of the examples will be used for the training of anSVM-classifier with gaussian kernel and scale σ = 0.01 andthe other half will be used for the testing of the classifier.The number of the training examples in set Y, as well asthe number of the testing examples in sets T1 and T2 forall the time window intervals are depicted in Table 1. Asit was also stated in the parameter setup section of ADL,all sets described in Table 1 (Y, T1 and T2) include thenumber of the clean and the adversarial-noisy examples.The classifier is trained and tested with the:(i) Raw clean and noisy data(ii) Reconstructed clean and noisy data whose values areprocessed as we describe in the following exampleAs it was described in section II, for the cases of timewindow intervals, where W > 1, activation patterns arenot represented by the values 0 and 1 due to the summingof the columns and the normalization step. For examplein the case of W = 3, if one neuron has not fired at allwithin 3 consecutive time bins, we get a 0-event. If it hasfired once, we obtain the normalized value of 13 , which arethe most prevalent values with the 0 value. Additionally,if the neuron has fired twice, we obtain the value 23 andif it has fired consecutively in all of the 3 time bins, weobtain a 1-event, which is not very common due to therefractory period. Because of the fact that we deal witha reconstruction problem, reconstructed values other thanthose described before may appear. Thus, without loss ofgenerality we make the simplification, which is depicted inFig. 10. Namely, for W = 3 all values which are smaller(cid:1) are6 are turned into zero. Values in space (cid:2) 1than 16 , 123 and values in space (cid:2) 1(cid:1) are turned intoturned into 123 . Any other value is turned into 1. Accordingly, we workfor any time window W .2 , 56Figure 10: Processing the values of the reconstructed events.3.3.2. Evaluation ResultsFig. 11 illustrates the performance of the SVM-classifierregarding the discrimination between the clean and thenoisy signals for the 9-day old mouse, as a function ofthe SL when the classifier is trained and tested with theraw data and the reconstructed data produced by theRADL algorithm. Each point in the errorbar plots cor-responds to the mean performance of the 4 runs of the al-gorithm, where in every run the examples in the trainingset are selected and examined with a different sequenceas to whether they will be included in the dictionary Dor not. The vertical error bar demonstrates the standarddeviation of these 4 runs. More specifically, as it is illus-trated in Fig. 11, each subfigure refers to the performanceof the classifier for different time window intervals. Whenthe classifier is trained and tested with the raw data, thehighest accuracy that it achieves, taking into account allthe time windows is 51%, which is a quite low percentage.When we use the reconstructed data that are producedfrom our proposed method, we observe that as we increasethe time window interval, we obtain a better classificationperformance. More specifically, for SL = 5 and W = 3as well as W = 4, we obtain the highest accuracy perfor-mance equal to 65%. Moreover, we notice that for timewindow intervals W > 1, when the SL is increased, theclassification performance is increased too. This happensbecause the patterns for time windows W > 1 are greaterin number (Table 1) and more complex (more firing eventsper signal) compared to the patterns of W = 1. Thus, byincreasing the SL, the algorithm obtains greater flexibil-ity, as it can use more dictionary elements to representthe data. Consequently, the algorithm can better general-ize and does not overfit as in the case of W = 1.Fig. 14 illustrates the classification performance thatis obtained in every epoch of the algorithm for all the runsand for SL=3. We observe that for all the cases of timewindows the classification performance is either improvedor it remains the same in every epoch of the algorithm.Thus, as it is depicted in Fig. 14 the dictionary that isobtained in the 4th epoch of each run, ensures the bestpossible accuracy performance for the specific run com-pared to the dictionaries that are formed in the previousepochs.(a) W=1,W=2(b) W=3,W=4Figure 11: Classification performance when the classifier is trainedwith the raw data and the reconstructed data produced by RADLwith respect to different time window intervals.Figure 12: Size of the final dictionary D for every run and SparsityLevel (SL)Fig. 13 demonstrates the distribution of two dictio-naries (we used the dictionaries that were produced fromthe 4th run of our algorithm) that refer to the sponta-neous neuronal activity of the 9-day old and the 36-dayold mouse under the consideration of W = 3 and SL = 3.The figure demonstrates the number of various patterns(doublets, triplets etc.) co-activating within a temporalwindow of 3 time bins. As in the case of W = 1, we112345Sparsity Level0.50.60.70.8AccuracyRaw Data-W=1Raw Data-W=2Reconstructed Data-W=1Reconstructed Data-W=22345Sparsity Level0.50.60.70.8AccuracyRaw Data-W=3Raw Data-W=4Reconstructed Data-W=3Reconstructed Data-W=4in the case of the RADL algorithm, it has a larger set oftraining examples (N2 > N1), which results to more iter-ations, and thus to a higher time complexity.Concerning the convergence nature of the algorithms,we report in Fig. 15 the objective function values of ADLas well as of RADL (W=2) with respect to the number ofiterations of the algorithms, when they execute 8 epochs.We observe that the objective function values of both algo-rithms are non-increasing during the iterations, and theyboth converge to a small value. Compared to ADL, RADLconverges faster and to a lower value than ADL. It alsoneeds only one epoch for that, while ADL reaches its low-est value in the 4th epoch.Figure 13: Distribution of the two dictionaries (W =3, SparsityLevel=3).4. Related Workobserve that the number of the various synchronicity pat-terns for the 9-day old mouse is greater than the numberof the patterns for the 36-day old mouse. Additionally,the dictionary that refers to the activity of the 9-day oldmouse includes more complex patterns with more than 20neurons having a temporal correlation within 3 time bins,while such patterns appear in much smaller numbers forthe 36-day old mouse. Finally, the size of each dictionaryalso reveals information about the data that we summa-rize. The dictionary that refers to the activity of the 9-dayold mouse has greater size than the dictionary that refersto the activity of the 36-day old mouse, which correctlyindicates and verifies that it fires less.3.4. Time Complexity and Convergence Analysisclean reconstructed, Vnoisy reconstructed and V(cid:48)The main computational burden of ADL lies in thecalculations of the coefficient matrices. ADL performs 4epochs, and each epoch executes a number of iterationsequal to the number of training examples (Section II, Fig.3). To compute the reconstructed signals Vclean reconstructed,V(cid:48)at each iteration, so that they are used in the calculationof the representation errors Eclean, E(cid:48)clean, Enoisy andE(cid:48)noisy respectively, our algorithm calculates 4 coefficientmatrices using the OMP method. The time complexity of2)OMP at a given iteration T0 is O(kM 2 + k + T0M + T0[20], where k is the number of dictionary atoms, M is thedimension of the signal and T0 indicates the number ofatoms that have been selected (i.e.the sparsity level).Thus, given the fact that in every iteration of our algo-rithm, OMP is calculated 4 times and our algorithm exe-cutes 4 epochs, the cost of our method is O(16N1(kM 2 +2)), where N1 is the number of iterations ofk + T0M + T0ADL. Regarding the time complexity of the RADL algo-rithm, after we obtain the dictionary D and before the be-ginning of a new epoch, RADL uses the set T1 to keep onlythose dictionary elements, which are mostly used for therepresentation of this set (Section II). Thus, the time com-2)+4k),plexity of the RADL is O(16N2(kM 2+k+T0M +T0where N2 is the number of iterations of RADL. Notice thatThe past several years have witnessed the rapid de-velopment of the theory and algorithms of DL methods.DL has been successfully applied in various domains, suchas image classification and denoising, remote sensing, facerecognition, digit and texture classification etc. The suc-cess of these methods lie in the fact that high-dimensionaldata can be represented or coded by a few representativesamples in a low-dimensional manifold.In remote sensing, Li et al.[21] addressed the prob-lem of cloud cover and accompanying shadows, which aretwo of the most common noise sources for the majorityof remote sensing data in the range of the visible and in-frared spectra. For the recovery of surficial information,which is very important for target recognition, classifica-tion, segmentation etc, they proposed two multitemporalDL algorithms, expanding on their K-SVD and Bayesiancounterparts. Li et al. [22] also addressed the problem thatremote sensing images are easily subjected to informationloss, due to sensor failure and poor observation conditions.Thus, they proposed an analysis model for reconstructingthe missing information in remote sensing images, so thatmore effective analysis of the earth can be accomplished.In image and video processing, where it is common tolearn dictionaries adapted to small patches, with trainingdata that may include several millions of these patches,[19] proposed an online dictionary learn-Mairal et al.ing (ODL) algorithm based on stochastic approximations,which scales up to large datasets with millions of train-ing samples handling also dynamic training data changingover time, such as video sequences. In the same contextof image processing, Iqbal et al.[23] proposed a DL al-gorithm, which minimizes the assumption on the noise byusing a function derived from the α-divergence, which isused in the data fidelity term of the objective function in-stead of the quadratic loss or the Frobenius norm. Thealgorithm is applied on various image processing applica-tions, such as digit recognition, background removal, andgrayscale image denoising.For the task of face as well as object recognition, Li[24] proposed a discriminative Fisher embeddinget al.noisy reconstructed12(a) W=1(b) W=2(c) W=3(d) W=4Figure 14: Classification performance with respect to the epochs of the algorithm for each run (Sparsity Level=3).5. Conclusions and Future WorkIn this work we proposed the Adversarial DictionaryLearning algorithm (ADL) that was applied on real-worlddata that refer to the spontaneous neuronal activity of a9-day old and a 36-day old mouse over time. In order toexamine the extent to which the trained dictionary hadcaptured the underlying statistics of the data, we trainedand tested an SVM-classifier with the reconstructed cleanand noisy signals that were produced from our methodas well as with the reconstructed signals produced fromother dictionary learning methods. The results on theclassification accuracy showed that our method can betterdiscriminate the true from the noisy activation patterns,indicating the robustness of our method. Moreover, in con-trast to other dictionary learning methods, our frameworkalso produces an interpretable dictionary, consisting onlywith the most robust activation patterns of the input dataand not with real-numbered values, which have no physi-cal meaning. We also extended the idea of ADL to a morerelaxed approach, proposing thus the RADL algorithm,which produces a dictionary that captures patterns withinbigger time window intervals and is not restricted to thesynchronous activity of neurons within the same time bin.Experimental results demonstrate that increasing the ac-tivation patterns time window, has a positive effect on theclassification performance.Future work will focus on the extension of our algo-rithm with graph signal processing methods, which couldprovide insights related to the temporal dynamics of thenetwork as well as its functional network activities. Wealso plan to explore the potential of the proposed methodin characterizing normal brain organizations as well as al-terations due to various brain-disorders, such as schizophre-nia, autism, and Alzheimer’s disease.AcknowledgmentThis research is co-financed by Greece and the EuropeanUnion (European Social Fund-ESF) through the Opera-tional Programme Human Resources Development, Edu-13(a) W=1(b) W=2Figure 15: Convergence curves of the objective function values versusiterations for (a) ADL (W=1) and (b) RADL (W=2)DL algorithm to concurrently preserve both interclass vari-ances and intraclass similarities of the learned dictionaryand coding coefficients in the embedding space. One ofthe first successful attempts in discriminative DL was theDiscriminative K-SVD (D-KSVD) algorithm [25] for facerecognition. They extended K-SVD by incorporating theclassification error into the objective function, thus allow-ing the performance of a linear classifier and the represen-tational power of the dictionary to be considered at thesame time in the same optimization procedure, while inour work these are considered two seperate steps (i.e. clas-sification error is not incorporated in the objective func-In several variants of discriminative DL methodstion).are proposed to improve the data representation and clas-sification abilities by encoding the locality and reconstruc-tion error into the DL procedures, while some of them aimto concurrently improve the scalability of the algorithmsby getting rid of costly norms [26, 27, 28]. Recently, DLhas also been extended to deep learning frameworks [29],which seek multiple dictionaries at different image scalescapturing also complementary coherent characteristics.1234Epochs0.50.550.60.650.70.75Accuracy1st Run2nd Run3rd Run4th Run1234Epochs0.50.550.60.650.70.75Accuracy1st Run2nd Run3rd Run4th Run1234Epochs0.50.550.60.650.70.75Accuracy1st Run2nd Run3rd Run4th Run1234Epochs0.50.550.60.650.70.75Accuracy1st Run2nd Run3rd Run4th Run05001000Iterations468101214Objective function valuesEpoch 1Epoch 2Epoch 3Epoch 4Epoch 5Epoch 6Epoch 7Epoch 80500100015002000Iterations0246810Objective function valuesEpoch 1Epoch 2Epoch 3Epoch 4Epoch 5Epoch 6Epoch 7Epoch 8[17] R. Rubinstein, T. Peleg, M. Elad, Analysis k-svd: A dictionary-learning algorithm for the analysis sparse model, IEEE Trans.on Signal Processing 61 (3) (2012) 661–677.[18] Z. Jiang, Z. Lin, L. S. Davis, Label consistent k-svd: Learn-ing a discriminative dictionary for recognition, IEEE Trans. onpattern analysis and machine intelligence 35 (11) (2013) 2651–2664.[19] J. Mairal, F. Bach, J. Ponce, G. Sapiro, Online dictionary learn-ing for sparse coding, in: Proc. of the 26th annual internationalconf. on machine learning, ACM, 2009, pp. 689–696.[20] B. Mailh´e, R. Gribonval, F. Bimbot, P. Vandergheynst, A lowcomplexity orthogonal matching pursuit for sparse signal ap-proximation with shift-invariant dictionaries, in: IEEE Interna-tional Conf. on Acoustics, Speech and Signal Processing, IEEE,2009, pp. 3445–3448.[21] X. Li, H. Shen, L. Zhang, H. Zhang, Q. Yuan, G. Yang, Re-covering quantitative remote sensing products contaminated bythick clouds and shadows using multitemporal dictionary learn-ing, IEEE Trans. on Geoscience and Remote Sensing 52 (11)(2014) 7086–7098.[22] X. Li, H. Shen, L. Zhang, H. Li, Sparse-based reconstructionof missing information in remote sensing images from spec-tral/temporal complementary information, ISPRS journal ofphotogrammetry and remote sensing 106 (2015) 1–15.[23] A. Iqbal, A.-K. Seghouane, An α-divergence-based approach forrobust dictionary learning, IEEE Trans. on Image Processing28 (11) (2019) 5729–5739.[24] Z. Li, Z. Zhang, J. Qin, Z. Zhang, L. Shao, Discriminative fisherembedding dictionary learning algorithm for object recognition,IEEE Trans. on neural networks and learning systems.[25] Q. Zhang, B. Li, Discriminative k-svd for dictionary learningin face recognition, in: IEEE Computer Society Conf. on Com-puter Vision and Pattern Recognition, IEEE, 2010, pp. 2691–2698.[26] Z. Zhang, J. Ren, W. Jiang, Z. Zhang, R. Hong, S. Yan,M. Wang, Joint subspace recovery and enhanced localitydriven robust flexible discriminative dictionary learning, arXivpreprint arXiv:1906.04598.[27] Z. Zhang, W. Jiang, J. Qin, L. Zhang, F. Li, M. Zhang, S. Yan,Jointly learning structured analysis discriminative dictionaryand analysis multiclass classifier, IEEE Trans. on neural net-works and learning systems 29 (8) (2017) 3798–3814.[28] Z. Zhang, W. Jiang, Z. Zhang, S. Li, G. Liu, J. Qin, Scalableblock-diagonal locality-constrained projective dictionary learn-ing, arXiv preprint arXiv:1905.10568.[29] S. Mahdizadehaghdam, A. Panahi, H. Krim, L. Dai, Deep dic-tionary learning: A parametric network approach, IEEE Trans.on Image Processing.cation and Lifelong Learning in the context of the projectStrengthening Human Resources Research Potential viaDoctorate Research (MIS-5000432), implemented by theState Scholarships Foundation (IKY). S.M.S. received sup-port from the Simons Foundation SFARI Research AwardNo.402047, NEI Grant RO1-EY-109272, and NINDSR21 NS096640. This work is also supported from theHellenic Foundation for Research and Innovation (HFRI)and the General Secretariat for Research and Technol-ogy under grant agreement No. 2285, Erasmus+ Inter-national Mobility between University of Crete and Har-vard Medical School 2017-1-EL01-KA107-035639, and theMarie Curie RISE NHQWAVE project under grant agree-ment No. 4500.References[1] G. Palagina, J. F. Meyer, S. M. Smirnakis, Inhibitory units: Anorganizing nidus for feature-selective sub-networks in area v1,Journal of Neuroscience (2019) 2275–18.[2] J.-e. K. Miller, I. Ayzenshtat, L. Carrillo-Reid, R. Yuste, Visualstimuli recruit intrinsically generated cortical ensembles, Proc.of the National Academy of Sciences 111 (38) (2014) 4053–4061.[3] T. Kenet, D. Bibitchkov, M. Tsodyks, A. Grinvald, A. Arieli,Spontaneously emerging cortical representations of visual at-tributes, Nature 425 (6961) (2003) 954.[4] A. Luczak, P. Barth´o, K. D. Harris, Spontaneous events outlinethe realm of possible sensory responses in neocortical popula-tions, Neuron 62 (3) (2009) 413–425.[5] M. Aharon, M. Elad, A. Bruckstein, K-svd: An algorithm fordesigning overcomplete dictionaries for sparse representation,IEEE Trans. on signal processing 54 (11) (2006) 4311–4322.[6] E. Troullinou, G. Tsagkatakis, G. Palagina, M. Papadopouli,S. M. Smirnakis, P. Tsakalides, Dictionary learning for sponta-neous neural activity modeling, in: 25th European Signal Pro-cessing Conf. (EUSIPCO), IEEE, 2017, pp. 1579–1583.[7] F. Liu, S. Wang, J. Rosenberger, J. Su, H. Liu, A sparse dictio-nary learning framework to discover discriminative source acti-vations in eeg brain mapping, in: Thirty-First AAAI Conferenceon Artificial Intelligence, 2017.[8] T. Zhou, F. Liu, H. Bhaskar, J. Yang, H. Zhang, P. Cai, Onlinediscriminative dictionary learning for robust object tracking,Neurocomputing 275 (2018) 1801–1812.[9] H. Morioka, A. Kanemura, J.-i. Hirayama, M. Shikauchi,T. Ogawa, S. Ikeda, M. Kawanabe, S. Ishii, Learning a com-mon dictionary for subject-transfer decoding with resting cali-bration, NeuroImage 111 (2015) 167–178.[10] I. T. Jolliffe, Principal component analysis and factor analysis,in: Principal component analysis, Springer, 1986, pp. 115–128.[11] J. P. Cunningham, M. Y. Byron, Dimensionality reductionfor large-scale neural recordings, Nature neuroscience 17 (11)(2014) 1500.[12] J. A. Tropp, A. C. Gilbert, Signal recovery from random mea-surements via orthogonal matching pursuit, IEEE Trans. oninformation theory 53 (12) (2007) 4655–4666.[13] L. Huang, A. D. Joseph, B. Nelson, B. I. Rubinstein, J. Ty-gar, Adversarial machine learning, in: Proc. of the 4th ACMworkshop on Security and artificial intelligence, ACM, 2011,pp. 43–58.[14] P. Stone, M. Veloso, Towards collaborative and adversariallearning: A case study in robotic soccer, International Journalof Human-Computer Studies 48 (1) (1998) 83–104.[15] M. Abramoff, P. Magalhaes, S. Ram, Image processing withimagej. biophotonics int. 11: 36–42, Google Scholar.[16] C. Stosiek, O. Garaschuk, K. Holthoff, A. Konnerth, In vivotwo-photon calcium imaging of neuronal networks, Proc. of theNational Academy of Sciences 100 (12) (2003) 7319–7324.14