Artificial Intelligence 72 ( 1995) 139- 171 Artificial Intelligence Learning dynamics: system identification for perceptually challenged agents Kenneth Basye ‘,*, Thomas Dean b*i, Leslie Pack Kaelbling b*2 a Department of Mathematics and Computer Science, Clark Universiiy 950 Main Street, Worcester, MA 01610, USA ’ Department of Computer Science. Box 1910, Brown University, Providence, RI 02912-1910, USA Received September 1992; revised March 1993 Abstract From the perspective of an agent, the input/output behavior of the environment in which it is embedded can be described as a dynamical system. Inputs correspond to the actions executable by the agent in making transitions between states of the environment. Outputs correspond to the perceptual information available to the agent in particular states of the environment. We view dynamical system identification as inference of deterministic finite-state automata from sequences of input/output pairs. The agent can influence the sequence of input/output pairs it is presented by pursuing a strategy for exploring the environment. We identify two sorts of perceptual errors: errors in perceiving the output of a state and errors in perceiving the inputs actually carried out learning in making a transition from one state to another. We present efficient, high-probability algorithms for a number of system identification problems involving such errors. We also present the results of empirical investigations applying these algorithms to learning spatial representations. 1. Introduction System identification refers to inferring a model of the dynamics governing an agent’s For instance, we might wish to infer a model of how interaction with its environment. * Corresponding author. E-mail: kbasye@gamma.clarku.edu. ’ This work was supported in part by a National Science Foundation Presidential Young Investigator Award IRI-8957601, by the Air Force and the Advanced Research Projects Agency of the Department of Defense under Contract No. E30602-91-C-0041, and by the National Science foundation in conjunction with the Advanced Research Projects Agency of the Department of Defense under Contract No. IRI-8905436. 2 This work was supported in part by a National Science Foundation National Young Investigator Award. 0004-3702/95/$09.50 @ 1995 Elsevier Science B.V. All rights reserved SSDl0004-3702(94)00023-T 140 K. Btrsy YI d./Arrijkkr/ Inrrllipxce 72 (1995) 139-I 71 fluctuations assembly in the output of a parts supplier affect production for a factory or how an robot interacts with the other devices in its work cell. rules, or a set of states and transition probabilities to a system of differential a set of for a stochastic process. the agent to predict consequences of performing spatial inference, equations, Such predictions might be used in planning, The inferred model might correspond production The model is useful insofar as it enables actions or diagnostic System reasoning. identification in its environment. has been studied in a variety of disciplines theory. We focus on learning theory, neural networks, and automata environments that can be characterized a large literature even on this restricted problem, a portion of which is summarized this paper. Our results address Our objective probability outputs complexity. that infer accurate models with high inputs and the effects of uncertainty algorithms interaction with its environment. learning time when faced with noise on computational as deterministic that determine in polynomial is to produce in observing the agent’s finite-state the including representations automata. There control of is in We are interested in how agents interact with their environments such interactions. We have chosen and, in particular, how to focus on identification in observation complicates as it appears to be critical that system system uncertainty system identification It is clear that studying which such identification in observation is annoying it is not that hard to cope with. However, any structure. Useful structure sequences of distinctive plays a supporting identification in facilitating a wide range of interactions. is a means and not an end; however, we believe in into many problems in isolation provides insight role. Our basic findings are that uncertainty and requires somewhat more bookkeeping but asymptotically lacking is hopeless landmarks or short in the form of reasonably distributed in environments learning features makes to function learning adequately relatively easy. the use of a in which having some sort of a model can is in learning space to support path planning. A dynamical model can also speed the clearest example of the utility of a model even optimally without however, [ 221 by allowing an agent to simulate there are tradeoffs involved in learning dynamical models; exactly what learning will depend on the tasks of the agent. Again, we avoid addressing in how (but see [9] ) in order to focus on basic in this paper issues its actions and the environment’s It is certainly possible model. There are environments, help enormously. Perhaps, maps of large-scale up learning plans reactions. Clearly is worth those uncertainty in observation tradeoffs affects learning. 2. Modeling dynamical systems with automata We model dynamical finite-state automata systems as deterministic graph for a DFA shows the state-transition agent’s actions and the outputs in learning interested is defined in terms of the agent’s perceptual capabilities. Discernability that, from the information in a state, the agent can uniquely but rather that there exists some sequence of actions and observations structure of real environments, where discernible does not require that state, that can be used from the DFA are the agent’s perceptual the discernible the inputs in which available identify (DFAs). Fig. 1 to the DFA are the inputs. We are K. Basye et al./Art$cial intelligence 72 (1995) 139-171 141 0 1 :I:i. x CJ interacting with its environment. Fig. 1. An agent Y Y 0 1 X X x by the agent to distinguish any two states. For instance, the states of an automaton might correspond to the agent being in one locations in which in an office building, of many where hallways meet. In this case, the observed outputs might correspond of hallways hallways. As another example, consider Here the states might correspond by the user, and outputs to the announcements made at each state. to various menus and services, actions for traversing the structure of a voice-mail to junctions to the number incident system. to keys pressed on a junction, correspond the inputs to actions locations learning incident and The DFA need not represent the whole of the agent’s interaction with its environment; separate models could be used for different aspects of the interaction. We assume size by careful choice of perception state space has been reduced to limit action primitives. Actions agent’s options small through equivalence abstract behaviors in a given state. The set of possible observations for response the use of perceptual apparatus experiences. relations on perceptual that act as filters, are encapsulated to a manageable that serve thereby the and the is kept introducing of a relatively that determining states. We admit requires a great deal of insight specifying only a set need not correspond the set of states of the to the cross product of the sets of values for all the state of state variables and, even if this is desirable, Historically, AI researchers have kept the state space implicit, In our view, the agent’s observations of state variables or fluents. to observations automaton need not correspond variables. We see the world as consisting distinguishable and action primitives general advice on how to obtain such primitives. We claim, however, primitives, Even in a state do not uniquely in stochastic results tions available particularly in the agent observing process output at a state or realizing one action while attempting Fig. 2 illustrates for quite extreme arises due to the fact that the observa- that state. In this paper, we are sources of uncertainty. We allow there to be a noise something other than the true to execute some other action. results apply in relatively both sorts of errors. Our polynomial-time forms of uncertainty, into the problem, and we offer no that without such small number of perceptually perception interested that occasionally but predict fairly poor performance learning will be very difficult. such state-space-reducing in the deterministic case, uncertainty performance determine 142 K. Basye et al. /Artificial Intelligence 72 (1995) 139-171 Fig. 2. Noisy observations of inputs and outputs. benign environments. Our empirical perform much better than our current of the sort we expect robots to encounter in the real world. investigations, that our algorithms theoretical bounds predict for benign environments however, indicate 3. Formal model In order automaton; as inferring identification to model system the structure of finite-state that there are two varieties of finite-state au- tomata, we now introduce an extension of the familiar definition of finite-state automata. in both versions, output Recall follows some action, and the state reached by the action depends on the action taken and the previous state. In the Moore model, output depends only on the state reached by in the Mealy model, output depends on both the previous state and the action, whereas, the action taken. Alternatively, that depend on the current state and the previous action. In terms of system which model is appropriate depends on the nature of the agent’s sensing in particular on whether sensations depend Moore automata the same regardless of how we got to that state. systems and in some way on the previous action. We use for a given state are one may think of the Mealy model as having outputs for our model, which implies that our sensations identification, between In this model, we explicitly distinguish the actual states and actions of the automaton and the agent’s possibly erroneous view of them. Thus, in any given true state the agent observes a label, which may or may not be an accurate of the environment, to the environment; reflection of the state.’ Similarly, these commands to real actions, but the corresponding action have a nominal correspondence an agent generates is not always commands taken. s It would be more technically correct to define an output alphabet then describe how the outputs generate observable states to outputs, simplicity of how states give rise directly in the following treatment, we have chosen to possibly erroneous to collapse labels. for the automaton, give a function mapping labels that are sometimes not correct. For into one, giving an account these processes K. Basye et al./Art$cial Intelligence 72 (1995) 139-l 71 143 In order to make use of probabilistic functions as a means of modelling uncertainly, we introduce the following notation: for any finite set S, let flf:s+ [OJl,~f(s)=l s the set of probability density functions (PDFs) over S. The structure of the agent’s environment and its interaction with that environment is specified by the tuple E = (Q, B, L, C, 6, q5, +k), where l Q is a finite nonempty l B is a finite nonempty l L is a finite nonempty l C is a finite nonempty l 6 : Q x B -+ Q, is the state transition function, l 4 is the probabilistic set of states, set of basic actions, set of observable set of executable commands, observation labels, function, 4 : Q --f FL, mapping each state into a distribution over possible observed labels, and $ l @ is the probabilistic action function, : C --+ FB, mapping each executable command into a distribution over possible actions. We write from B. We extend IZ for /Ql. We write A = B* for the set of all finite sequences of basic actions in the usual way by defining 6(q, A) = q, and S( q, ab) = 6( 6(q, a), 6) for all q E Q, a E A, and b E B, where A is the empty sequence. We write qa as shorthand for 6(q, a), the state resulting function 6 to such sequences the state transition from execution of sequence a from state q. that every action may be executed We assume in every state, so the function 6 induces a set E of labelled edges (41, b, q2) for every 41, q2 E Q and b E B. An automaton strongly connected that qla = q2. is if for any two states 41, q2 E Q, there is some sequence a E A such We write q(a) to denote executing example, the sequence a starting if a = bobI b2 . . . b,, then q(a) = (~(q),~(qbo),~(qbobl),. . .,$(qa)). the sequence of outputs of length from in state q, beginning with the output at state q. For /al + 1 resulting Q, B, and 6 specify is deterministic; we are concerned with worlds or systems represent function structure. The remaining environment. When the distribution d(q) c, it performs an action drawn from the distribution the system itself apart from any agent. Note that the state transition that have a fixed to observe and act in its the agent’s ability the agent reaches some state q E Q, it observes a label drawn from to perform command . Similarly, when it is in state q and attempts elements $(c). We assume that there is some “correct” observation function action (command) action for each command. or observation a deterministic each state our inference procedures will have wider applicability about the stochastic cannot expect we exclude at each state, and some “correct” It is therefore useful to distinguish between a “correct” action for function, which may be thought of as mapping 1. Clearly, few assumptions and action. However, we certainly to be able to learn in the presence of arbitrarily malicious noise. Instead, functions behave and a “noisy” version of that function. We write d* (+*) (observation) to a PDF in which some element has probability functions governing observation such situations by assuming that observation if they require and action 144 K. Busye et ul./ArtiJicinl intelligence 72 (1995) 139-I 71 When sidering outputs are understood function vation states by con- sequences of that is, from the obser- if When each state has a different output under the correct observation correctly with probability the errors made in the remaining the lifetime of the agent). restrictions on the error distribution; In some cases, cases are stationary above some threshold value and that the distributions governing (that is, they do not change during to impose additional these will be made explicit where they are required. function, we say present agents with functions provide additional is unique. While not all environments it is also necessary function to infer automata that allows agents that the observation unique observations, we shall see that unique observation structure in environments without unique observation uncertainty. Even case that some states have unique outputs. We refer to such states as landmarks. to make use of landmarks it must also be capable of determining capable of recognizing that the observation made is unique, in the presence of stochastic landmarks there are no landmarks, the outputs of sequences of states. In the following discussion, as landmarks. it becomes necessary to distinguish functions, forms of it may be the In order that is, be the agent must not only be able to make a unique observation, to arise from deterministic observations, assume that would to automata indistinguishable does not mean there is one sequence automaton M has a unique them. The class of automata that the environments we are attempting there would be no experiment we could perform c$*. A sequence u E A is said to distinguish q1 and q2 if and only Th e notion of distinguishability if there is a single sequence a E A that distinguishes is extended if there is a state q of Mt in the following qt(a) + 92(a). way: Mt and M2 are distinguishable (or MT) and some action sequence a such that for all states q’ of M2 (or Ml), q(a) # q’(u). An automa- if, for all pairs of states q1 # q2 E Q, there exists an action ton is said to be reduced sequence from a given that distinguishes strongly-connected reduced member (up to isomorphism) [ 161; this automaton has the minimum number of states. that is also strongly connected to learn are reduced, We consistently tell us otherwise. since all Note that this requirement pairs of states. However, all non- identical pairs of states, then a is called a distinguishing sequence for M. More precisely, a E A is a distinguishing The outputs signature can only be determined you were when you began executing that provides a unique signature precisely, a sequence a E A is a homing sequence ql (u) = q2 (a) + qla = qza. Every distinguishing because knowing where you were when you started executing quence the sequence) is the result of having executed know where you are at the end of the sequence. Both distinguishing quences may be either preset or adaptive the next action a tree of actions whose branches correspond fixed, and is executed “blindly,” without regard for the outputs along the way. sequence provide a unique for a given state a way of knowing where is a sequence for the state reached at the end of its execution. More for M if and only if for all 41, q2 E Q, is also a homing sequence, sequence se- the distinguishing that you also implies and homing se- is one in which thus it is really is from the execution of a distinguishing for each state in an automaton, but note that the signature [ 111. An adaptive sequence is determined by the previous outputs, if, for all q1 ,q2 E Q, ql(a) = 92(a) H q1 = q2. to possible outputs. A preset sequence the sequence. A homing sequence the state, thus providing that distinguishes in the sequence by leaving sequence resulting (which The usual definition for finite-state automata includes a start state, where the machine K. Basye et al./Art@cial Intelligence 72 (1995) 139-171 145 to be prior is assumed agent has the ability environments, however, to any actions. Some systems may have this feature, and if the to this state at will, we say that it has a reset. For many to return the assumption of a reset is not realistic. 4. Theoretical results for the purely deterministic case results of this paper are methods input and observation The main of stochastic in this section we review some automata in the purely deterministic functions. important previous case. for learning automata In order to put those results results concerning in the presence in context, the inference of data, there inferring sequences automaton automaton, are allowed, an automaton an automaton this construction to the observed pairs are assumed between and inferring Some writers have made a distinction automaton. For any sequence of input/output (in terms of ]Ql > that agrees with a given set of data. Moore that behaves that is isomorphic is a trivial that agrees with the data that is constructed by building a chain of states as can build a tree the [ 161 to have come from a reduced, strongly then inference of the smallest consistent automaton yields a result correct identically to the observed automaton long as the data. If multiple with the start state as the root. For this reason, research has concentrated smallest automaton showed that if the input/output connected that is isomorphic inference their in- Gold inputs and by generating put/output produces a description of the automa- recording produced by the ton. Inference algorithm eventu- ally, but in this case there is no way to detect that this has happened. Gold’s algorithm relies on the learner having to the initial state at any time. that the sequence of descriptions to converge on the description of the correct automaton automaton. Thus, are the same. for inferring samples to the original inference a method the resulting outputs and periodically and isomorphic [ 121 provides automata the automaton in this case, behaviorally behavior. The algorithm to reset the automaton in the limit means is guaranteed in the limit the ability on finding from The general problem of inferring the smallest [ 1,131. automaton consistent with a given Indeed, even finding an automaton is intractable is NP-complete assuming P # NP [ 171. [ 21, building on the work of Gold, provides a polynomial-time pairs close to the smallest set of input/output polynomially Angluin for inferring the smallest source of counterexamples. an automaton it is not, provides a sequence of inputs on which the hypothesized generate different outputs. Rivest and Schapire the ability given In this model, at any point, and the source of counterexamples indicates whether automaton algorithm to reset the automaton the algorithm can hypothesize and a it is correct and, if and actual automata [ 191 show how to make use of a homing sequence as a substitute for a reset and how to dispense with both the reset and the source of counterexamples sequence in the case in which a distinguishing polynomial time [ 18,201. Several is either provided or can be learned have approached researchers finite-state in learning et al. [ 211 used a recurrent network systems using neural net- to learn works. For example, Servan-Schreiber 146 K. Busye et trl. /Artijkiul Intelligence 72 (I 995) 139-I 71 grammars, finite-state Rivest and Schapire algorithms mentioned mance and Bachrach [ 31 used a neural net to implement one of the above. This work has not stressed perfor- issues, nor has the issue of noise in inputs or outputs been considered. 5. Theoretical results for the stochastic case In this section we provide polynomial-time settings. stochastic three different agent’s actions, but allow error in its observations that observations the action function. of the agent, but impose the restriction of special landmark In the first, we assume algorithms identification for automata in that there is no error in the In the second, we assume states are unique and perfect, but allow error in and actions of outputs. In the final case, we allow error in both the observations that every state’s nominal label be unique. 5.1. Deterministic actions and stochastic observations In this section, we consider a situation labelled states. We show that by relying on a correct action function and knowledge of a distin- guishing functions can be learned even when the output function sequence, automata with non-unique there may be no uniquely observation is noisy.4 in which X1.1. Structural and interaction properties Structurally, the automaton the agent becomes other parts. We also assume states in the environment. the requirements to be learned be strongly connected. We thus avoid the possibility for this algorithm are quite weak: we require only that that from which it cannot reach that the agent knows some upper bound on the number of in some part of the environment trapped With regard to interactions, we assume that the agent moves deterministically, is perfect. Observations, however, are assumed that the correct observation is made with probability greater than are independent sequence events. Finally, we assume for the environment. to determine it is straightforward a distinguishing that the learner For many man-made that execution of actions the restrictions that observations with a preset distinguishing natural environments example, all junctions in most office environments, in the environment. a short sequence of turns will serve to distinguish that is, to be noisy, with i and is provided and sequence. For 5.1.2. Algorithms The algorithm we present here uses as a subroutine that moves the agent statistics on the labels it observes. The procedure provides a procedure collecting in the environment, as output a signature homing sequence at the end of the sequence for the state reached at the end of the movement. Recall is one for which and a distinguishing the output uniquely determines sequence is one for which that a the state reached the output ‘The work described in this section was carried out jointly with Dana Angluin and Sean Engelson, and is described in more detail in [ 7 I K. Basye et al./Artificial Intelligence 72 (199.5) 139-I 71 147 the state from which homing sequences cannot be used because the sequence was begun. In an environment their signatures correctly. This algorithm makes use of a procedure, the effect of having in a the automaton is achieves is, it terminates with that is probably correct. The procedure sequence, sequence. That for that state that, given a distinguishing in such a way that it can be run longer in order to guarantee correctness in general, be observed uniquely determines with stochastic observations, will not, called LOCALIZE, a probably state and returns a signature parameterized with a higher probability. We begin by explaining correct homing the LOCAL= procedure, and then show how it can be used to learn environments with the properties discussed above. The localization procedure works by exploiting the fact that movement is deterministic. sequence the period of the cycle of locations, we can separate the given distinguishing then execute the agent The basic idea is to execute it some number of times after that and collect to be in a cycle, is certain the output. By finding the observed outputs and use them as statistics on the outputs observed at each state. These statistics the correct outputs at each state can then be used to determine that would be in the cycle, and hence the signature returned by the distinguishing case for the state the agent is in. the agent by supplying in the deterministic (with high probability) repeatedly until to localize sequence In order to determine keep statistics these statistics are analyzed for alternative For an environment bound on IQ/. The set of outputs of observing on all the Tii for i # j. symbol Zj given hypotheses to determine with high probability for the period of the cycle. After the period of repetition of the walk with high probability, we the walk, the period of the cycle. E with states Q = (41, q2, . . . , qn}, let m be the given upper the probability that the agent is in state qi. Let P denote a lower bound is L = {Eo, II,. . . , Zk}. Let Pji denote Let s = blb2. . . blsl be a preset distinguishing more actions. For any integer Let q(i) be the state reached after executing are sufficient that the agent to guarantee i > 0, let si represent sequence the sequence for & consisting of one or i times. the sequence Pfi. The first m repetitions the sequence of states this is the the least period of the cycle; s repeated is in a cycle. Thus, 4(O),q(l),qC9,. value we wish to find. . . is periodic. Let p denote As we execute in the sequence, and keep statistics separately position e=o,..., of s, that is, q(i)bl b2. . . be. For each e, the sequence &,d, period p. the second part of the walk (after the 3”’ prefix), we keep track of our for each position. For each offset the first e actions q$, . . . is also periodic of IsI - 1, let d(i) be the state reached from q(i) by executing For each C, consider the sequence of (correct) outputs from the states d(i): & = d*(q’(i)). The output sequence 4&&P”, ,.... is also periodic, of some unique, we may have p > pt. However, because s is a distinguishing least period me dividing p. Since outputs are not necessarily sequence, p will 148 K. Basye et al./Amjzcial Intelligence 72 (1995) 139-I 71 Table I Sequences of visited states for QT = 4 Step # States visited (LCM) of all the pc’s. Thus, it would suffice to find each be the least common multiple of the values PJJ, and take their LCM. In fact, what we will do is to find (with high probability) values qe such that p& divides qt and qe divides p, so that the LCM of the q& is also p. We describe for the others. for the sequence qo, qi, 42,. . ; it is analogous the procedure Consider any candidate period rr 6 m, and let g = gcd(p, z-). For each 0 < i < T- 1, of s, starting with m + i the sequence of states visited every rr repetitions consider repetitions of s. This will be the sequence of states Since q(i) k = O,l,...,p/g- states. is periodic of period p, this sequence visits each state of the set {q(i + kg) : I} in some order, and then continues to repeat this cycle of p/g Table 1 shows an example with p = 6, rr = 4,g = 2. In this case, row r gives indices of the states visited by repeating s is qo, 91,. of states visited by repeating s, starting , qs. from q(r), assuming In the special case 7r = p, shown in Table 2, each row r will consist exclusively of visits to state q,.. It is this case that we wish to distinguish from the others. We cannot observe the states themselves, but we can observe the agent visits. The algorithm will repeat times, with N chosen close to the probabilities we form a table with r rows, numbered 0 to r- label ri. During each time we observe sequence the distinguishing that, with high probability, our observed the labels at each state s a total of JV are frequencies of the sampled distribution. For each candidate period r 6 m, 1, and k columns, one for each possible j the second part of the walk, we increment the table in row r, column to ensure label l,,. After relative the frequency of each entry in the same row. Let p = (P - i), the second part of the walk, we compute to the other entries (label) the separation between i + $p as a threshold. the lower bound on correct observation the the threshold, When every row in the table for some r has a value table, we take the sequence of rr outputs table is said to be plausible. For each plausible determined by the largest value in each of the r rows and find the minimum period r’ of the sequence. We find the LCM of all IT’; this is our candidate and 4. We use the value that is above for p. We now present the procedure in a precise manner. Procedure Localize. ( 1) For simplicity, we assume to the integers 1,. that all the possible outputs are known and correspond , k. Build a table T( r, t, Y, j) of size m x 1st x m x k. Initialize the that the cycle K. Basye et al./Art@cial Intelligence 72 (1995) 139-I7I 149 Table 2 Sequences of visited states for * = 6 Step # States visited 0 1 2 3 4 5 0 I 2 3 4 5 0 1 2 3 4 5 0 I 2 3 4 s 0 1 2 3 4 5 0 1 2 3 4 5 0 1 .., 2 3 4 5 (2) (3) (4) to zero. 5 s“’ to ensure the sequence traverse all the table entries Execute continually Initialize Execute s at least N times, incrementing individual (a) Let C = c mod IsI, and j be the label observed for as long as it continues step, do the following: that the agent is in a closed walk that it will to execute S. 6 the sequence counter R c 0 and the step counter c c 0. R after each time. After executing each immediately following exe- cution. (b) Foreachn.=1,2,... , m - 1, increment j) the table entry T(G-, e, R mod 7rTT, by 1. Increment (c) Let (5) the step counter: c t- c + 1. (6) (7) (8) than list C c the period i + isep, build {-}. For each 7r and each f!, consider to the large elements, at-g maxj F( q, f?, r, j) the outputs corresponding , n- - 1. Find the two- table F( T, e, ., .). If, for each r < 7r, row r in this table contains the sequence of outputs of length n- by larger for Initialize dimensional an element taking r=O,l,... Let ZS7 be the LCM of all 7r’ E L. Conclude R mod 17 in the three-dimensional table F(I7, esis for the correct outputs of the distinguishing sequence of outputs argmaxj F(nJ, after the single output arg maxj F( IZ, 1 SI - 1, (r - 1) mod ZI, j) . row r = ., ., .), and return, as the hypoth- s from this state, the the period of this sequence and add it to L. for e = 0, 1, . . . , IsI - 1 concatenated located at the last state before is currently the agent sequence that r, j) Table 3 shows the tables that resulted from a run of LOCALIZE in the environment in Fig. 3. The distinguishing shown that T is the conjectured the sequence S, r is an index into the cycle of length r, and j is the observed can see that the tables to the procedure was (bb). Recall into label. We r = 2 and C = 0, for r = 2 and 7~ = 4 are all plausible. When (number of executions of s), I is an index sequence given period length 5 If the labels are not known, then the table can be constructed incrementally, adding new labels as they are observed. 6 Following Step 2, the next action should be the first action in s. IS0 K. Btrsye rf (11. /Rrtijkicil lnrellijiencr 72 (I 99.5) 139-I 71 alb Fig. 3. A simple environment with I short distinguishing sequence Table 3 Tables built by LOCALIZE for the environment of Fig. 3 7r= I 7r=2 ??=3 ?r=4 j = 0 j=l j=O j=l j=O j= I j=O j=l I = 0 26(0.52) 0 0 0 24(0.48) 0 0 0 I = I 44(0.8X) 6(0.12) 0 0 0 0 0 0 21(0.84) 4( 0.16) 20(0.8) S(O.2) 0 0 0 0 21(0.84) 4(0.16) 23(0.92) 2(0.08) 0 0 0 0 10(0.588) 7(0.412) 10(0.588) 7(0.412) 7(0.438) 9(0..562) 0 0 2(0.118) lS(0.882) 16(0.942) l(O.0588) 13(0.812) 3(0.188) 0 0 ll(O.846) 2(0.154) 2(0.514) ll(O.846) lO(O.833) 2(O.I67) 3(0.25) 13(l) 12(0.923) S(O.667) 4(0.333) ll(O.917) 9(0.75) 0 l(O.0769) l(O.0833) we have the sequence 01, which has period 2; for r = 2 and ! = 1, the period r = 4 and e = 0 the period this set of periods either returned by the algorithm is (010). is 1; for is 1. The LCM of the agent starts in qo, and so finishes In the first case r = 0 and the signature is that of qo: (000). In the other case I = 1 and the signature is 2; and for n- = 4 and e = 1, the period in qo (R is even) or in q2 (R is odd). is 2, so Ilr = 2. In the example, 5.1.3. Analysis A formal proof of the correctness of the algorithm and a proof of the complexity in in a paper by Dean et al. [ 81. We cite the final this complexity, and refer the reader to the paper for a complete proof. terms of the number of steps appears result concerning Theorem 1. In order to provide a correct signature with probability must execute sequence s at least the distinguishing 1 - E, LOCALIZE 8m2 2/sJkm3 m+ (2P- l)@ & times. The number of steps taken is thus K. Basye et al./Artifcial Intelligence 72 (1995) 139-171 151 Mm2 (P - $2 In that IsI is the length of the distinguishing Recall number of states correct output the probability in the automaton, P > i is a lower bound on the probability sequence, m is an upper bound on the of the from a state, k is the number of possible outputs, and E is a bound on that the procedure will fail. returns sequence the agent for a moment The complete a distinguishing of the underlying is in [ 81. Suppose and proof of correctness procedure which employs straightforward is relatively s and learning LOCALIZE as subroutine and hence only sketched here. that The detailed algorithm LOCALIZE always to the same state and that the agent can always determine when it is in a state that it has visited before. In this case, the agent can learn to a depth- the connectivity state transition graph. The agent does not actually first search it cannot manage a depth-first traverse it executes sequences of actions search since, from the root of the corresponding depth-first in the course of the search, a state is recognized arc is added to the inferred automaton has not been completely as having been visited before, an appropriate to the next path that Instead, the state transition graph starting to the root each time using LOCALIZE. When, automaton by performing what amounts and the search “backtracks” in general, to paths search tree by returning it cannot backtrack. the state-transition the automaton’s in depth-first explored. fashion; through through graph The actual inference algorithm the states we encounter during does not necessarily able to immediately first problem state (root) knows (with high probability) what state it has landed depth-first using a number of executions of the distinguishing to identify is more complicated because our localization procedure always put the agent in the same final state and because we are not search. The identify in parallel, one for each possible the agent is executed in and can take a step of the is solved by from a given starting state is solved by performing many searches that LOCALIZE ends up in. Whenever LOCALIZE search that has that state as the root node. The second problem the depth-first sequence that state with high probability. that it is possible It can easily be shown to learn an automaton with high probability number of visits to a fixed starting state. LOCALIZE may not return number of times time, but in a polynomial to some state the required number of times. to the same state, but the state every the agent will return sure that it has returned to the same starting given a polynomial the agent executing LOCALIZE Of course, agent can achieve any required probability in the reciprocal of the probability the agent is never absolutely of success in a number of steps polynomial and the other measures of problem size. The requirement in general. that a distinguishing In particular, Dean et al. [8] show that learning sequence be provided in polynomial avoided as general as those we are considering not possible that even computing here. Further, they provide sequences preset distinguishing an efficient way to compute adaptive distinguishing it is clear that an adaptive sequence will not work in place of a preset one in the LOCALIZE procedure. [23] for general environments indicate is hard, although the results of Yannakakis time for environments sequences. However, such a sequence and Lee seems unlikely to be is I.52 K. Bmye et al. /Artijiiciul Intelligence 72 (I 995) 139-I 71 The procedure is certain With an adaptive action relies on the ability to follow the sequence deterministically, to be in the right states, even if it perceives incorrect outputs along sequence, correct movement would no longer be assured, to perform at any point would depend on the previous, possibly so that it the way. the since incorrect, output. 5.2. Stochastic actions and deterministic observations that allows A landmark environment this seems to be a fairly strong condition, is one in which certain states have unique it to determine whether or not an observed labels that can be detected as such. That is, not only are the labels unique, but one can think of the agent as label is unique. having a detector Although that people are quite good at. Indeed, people select landmarks precisely because they are sure that they present a unique aspect, and this surety comes without having examined all other in San locations. For example, almost anyone would identify that Francisco assures learned what that agents have is unusual enough this ability. The problem of how this ability is an interesting the scope of this work. ’ one, but is outside as a good landmark, based on background knowledge of building in this section we assume is learned or programmed in appearance. This ability amounts the Transamerica pyramid to count as a landmark; it is certainly something them that it is unique to having styles 5.2.1. Structural and interaction properties In addition to the landmark property, we assume that the environment to be learned it is possible that reverses the agent’s observation to movement, we assume the effect of the first. While that for every action that does not result in a self-transition, reversible. This means is another action perfect, no restriction property. Thus, With regard probability we assume action, call the latter requirement the ability obviously many of these there are; we will sometimes is made on the structure of the labelling other than the landmark that all states that are not landmarks have the same label. the intended action with takes 13 > f , but allow any static distribution over actions that are in error. Finally, that the agent has perfect knowledge of the action that would reverse its last location. We that the agent has This that the agent will also know which actions will succeed, and how that will fail, that is, that will cause self-transitions. reverse movement certainty. We assume to detect actions implies from which way it arrived at its current refer to this as the degree of the state. that is, it knows perfectly that the agent is there is For convenience, we define D to be the subset of Q consisting of the landmark states. We define the from any state in I to (if r = 0, then Z is empty and all states are landmarks). We say the local connectivity within radius r of some 4 E D if it can the shortest path between 9 and any landmark within a radius r of 4. We say the global connectivity of an environment E within a constant if, for any two states q1 and q2 in D, it can provide a path between q1 and q2 states and I to be the subset of Q consisting of the non-landmark landmark distribution parameter, r, to be the maximum distance landmark the nearest that a procedure provide that a procedure factor learns learns ’ The work described in this section was carried out jointly with Jeff Vitter and is described in more detail in 141. K. Basye et al. /Art@icial Intelligence 72 (1995) 139-171 153 Fig. 4. A path found between landmarks A and D. length is within a constant whose and q2 in &. The path will be constructed landmarks (see Fig. 4). factor of the length of the shortest path between q1 from paths found between locally connected Thus, we may summarize the agent’s capabilities is not perfect, but serves function than half the time. At each state, last action taken, even whether the state is a landmark, the agent to move the agent knows what action as follows. The agent’s action in the intended direction more the the agent knows to take to reverse In addition, if it was not the intended action. and if so, what its unique name is. 5.2.2. Algorithms We begin by presenting that learns error the local connectivity incurred a procedure that the multiplicative of an environ- ment. We then show to answer global path queries can be kept low if the local error can be kept low and that the transition from a local uncertainty measure complexity by more than a polynomial procedure that directs exploration that are accurate and within a small constant for learning the to build a so as to answer global path queries to a global uncertainty measure does not increase begins with a search of the environment factor of optimal with high probability. factor. We conclude and map building that it is possible local connectivity The procedure in trying they have been found, than cr, where c > 2 is an integer) paths between to locate all the landmarks. Once (less in the first, candidate paths are located, and in the second, two phases: are verified. The need for this two-stage process arises from the possibility combination landmarks, can statistically traversals, occurring paths in 1. the algorithm looks for short landmarks. This process has these paths that some to connect two reverse certainty we enough frequently but that, in fact, did not. We show that by exploiting the true paths and errors. By attempting can ensure with high probability sets of directions corresponding traversals actually correspond the procedure that appeared of movement errors could to perceived distinguish the most in paths between result that to The learning algorithm can be broken down into three steps: a landmark identification selection and filtering step in which the agent determines which of those candidate paths the agent the agent finds a set of candidate paths in E connecting step in which step in which a candidate a set of landmarks, finds and identifies a candidate landmarks, correspond We now present to actual paths in 1. the procedure for learning local connectivity. Procedure Connect. ( I ) (Landmark location) A uniform random walk is made in the environment and landmarks encountered arc added to a list. (2) For each landmark A in the list from step ( I ): (a) For each sequence of directions of length cr, make multiple from A, recording the path defined by the sequence, direction and reverse direction at each step. After each traversal, A with a random walk. Add any path which reaches some other landmark to the list of candidate paths. traversals of the intended return starting to (3) For each candidate path in the list from step at the head of the list and comparing at the landmark times, beginning directions observed with those recorded these comparisons the traversal landmark with a random walk. For each path, maintain traversals. is a failed traversal. If the landmark if the landmark is successful. (2), execute for the path in step (2). Any failure the path multiple reverse in is reached without failure, is not reached, return to the beginning a count of successful (4) Return all paths from the list whose count from step (3) is above a threshold. 5.2.3. Analysis We now state without proof ( the detailed proof can be found leading up to the result that this algorithm lemmas complexity. is correct and has polynomial in 161) a series of sample Lemma 2. For any FI > 0, the CONNECI‘ procedure within cr qf each state polynomial in 1 /cl, 1 / ( I - 28)) and the sire qf E, and exponential in any lundmark environment with probability learns the in cr. local connectivity I - EI in time Lemma 3. Let E be a landmark environment with distribution parameter r, and let c be any integei; c > 2. Given a procedure within cr of any landmark possible time polynomial result will be at most c/ ( c - 2) times the length of the optimal path. I - ~1, it is I - cR for any F~ > 0 in in I /F,~ and the size of the environment. Any global path returned as a that, ,for any ~1 > 0, learns the local connectivity in l/r, with probability to learn the global connectivity of & with probability in & in time polJnomia1 Theorem 4. It is possible with probability exponenfial in r. I - F in time polynomial to learn the global connectivity of any landmark environment I - 20), and the size of E, and in I/c, l/( Theorem 4 is a simple consequence to the problem of learning are landmarks. length I in order to establish of Lemmas 2 and 3. It has an immediate application of an environment where all the states r = 0, and we need only explore paths of of the environment. Because each the global connectivity In this case, the parameter the global connectivity K. Basye ef al./Art$cial Intelligence 72 (1995) 139-I 71 155 candidate path has length one, this process works even if there is no reverse certainty. 5. It is possible Corollary distinguishable and the size of G, even if there is reverse uncertainty. locations with probability the connectivity to learn 1 - E in time polynomial of an environment E with only - 28, in 1 /E, l/l defined above does not require that the environment The notion of global connectivity learned (i.e., necessary to recover the structure of the entire environment). that the indistinguishable states are of interest only situations where instance, be completely assumed directions to imagine are of interest. For into equivalence equivalence just across above approach and try to completely local neighborhoods to traverse a direct path between the indistinguishable the indistinguishable classes so that one could uniquely designate class and some radius from a particular global landmark the street from the Chrysler building). It is in so far as they provide it is easy them further its (e.g., the bookstore the learning two landmarks. But states and the paths between states might be partitioned In [ 5 J , we show how to modify learn the environment a state by specifying by first completely of each landmark. 5.3. Stochastic actions and observations In this section, we consider and observations. we are required then give the algorithm the case in which there is error in both the agent’s actions sample complexity, those restrictions, In order to provide an algorithm with polynomial to make restrictions on the environment. We present and sketch a proof of its correctness and complexity. 5.3.1. Structural and interaction properties is reversible if, whenever is also a corresponding have this property. Even one-way there is an action a leading action from from q2 to 91. Virtually streets normally have Recall that an environment 41 to q2 and q1 Z q2, there all navigational corresponding undirected assumption environments parallel streets running in the opposite direction, providing an essentially environment. Here, we assume the action that the agent knows the environment that would reverse a given action. is reversible, but make no The conductance of an environment is, informally, are to get from one part of the environment is harder to learn the environment here will work on environments the longer more bottlenecks), We assume it will take. to another. If there are a lot of bottlenecks, a measure of how many ways there it through random exploration. The algorithm presented (the but the lower the conductance of any conductance, that the labelling of the environment that IQ1 < IL/ (the number of states is less than or equal to the number of labels) and for simplicity of correct presentation we will assume label for state qi. Let Pi = q3( qi) (li) be the probability li when it is in state qi. For i # j, let Pji = +( qi) (lj) be the probability that the agent let P be a lower bound mistakenly that the higher apparent on all probabilities it is in state qi. Finally, of correct observation, Pi. It is intuitively that IQ] = IL1 and that for all i, label Ii is nominally that the agent correctly observes is unique, so know observes lj when label 1% K. Basw et 01. /ArtiJicicd Intelligenc~e 72 (1995) 139-I 71 of correct observation is, the sooner the agent will be able to correctly the probability identify its underlying environment. between commands that and actions The relationship labels and states. We assume that the agent correctly performs action a, when it executes command c;. Let 0 be a lower bound fi is such that the agent on all the 8;. In addition, we assume can choose commands the agent to generate a random walk in the environment. that the action function in such a way as to choose actions uniformly, allowing IAl = ICI. Let 19; = +(c;) (a;) be the probability to that between is analogous With regard to observation, we assume that is, for all i, j, P;i = P,. The agent is just as likely it is to mistake state 4; for state q;. As will be seen later, the point of this requirement is to limit the frequency with which a given label can be seen in those states where the observation is incorrect. that the observation probabilities are rejlexive; to mistake state qr for state q.i as 5.3.2. Algorithms Given the restrictions structure of the envi- ronment can be learned by a very simple algorithm. The result of the algorithm will be, with high probability, to the original environment. from the previous section, that is isomorphic an environment the underlying The algorithm uses a random strategy to explore the graph and records, for each pair (l;, la). and each command, <Ji, the number of times that an observation of li a label that there is an edge of labels, followed by performing graph can be extracted after doing command ci when observing for action ai from state q, to state qk in the underlying graph. in an observation of lk. After enough exploration, c,~ resulted from these statistics. If lk is the most frequently observed label 1,, then we assume More formally, the state-transition graph can be learned in the following way: Algorithm CMFO ( 1) For each command (Choose Most Frequent Observation) c E C, construct a two-dimensional table T, indexed in each dimension Initialize by the labels in L. all of the entries of all tables to 0. (2) (3) Begin executing a uniform tion is made from a state in which label 1; is observed I,, is observed by using command c, increment the value of T,( 1,) I, ) . random walk in the environment. Whenever a transi- label to a state in which (4) After n action steps, stop and return edge set E’ containing edge ( qr, ah, qi) only if T,,, (I;, li) > Tc,, ( lj, lk) for all k not equal to j. Fig. 5 shows the results of a sample run of this algorithm on a very simple graph. The at each vertex; the large tables indicate, label pairs. The underlying graph is encoded the frequency of sequential the perception probabilities small tables specify for each action, by the largest element in each row of each table, which is in bold-face type. 5.3.3. Analysis In this section we state specific conditions ceeds and provide a bound on the number of observations to have a given confidence of identifying the entire graph correctly. under which algorithm CMFO above suc- the agent must make in order K. Basye et ul./Art@cial Intelligence 72 (1995) 139-171 157 Fig. 5. Results of running the graph-identification algorithm in the simple environment shown for I ,000 (19 = 0.8). In the following, we abuse notation vertex qi, Zi for the event of perceiving for the event of visiting qi as a result of executing event of perceiving constructing c, given that the label Zi was seen just prior; this probability The observation by the agent. This will be addressed estimates of the probabilities li as a result of executing later in the proof. probabilities slightly and let qi stand for the event of visiting label Zi, and so on; in addition, we let oqi stand some action and oli stand for the some action. The algorithm can be seen as that a label Zj is seen after executing command is notated as Pr(oZj 1 Zi AC). depend on the details of the random walk being executed An important quantity for bounding the necessary number of trials is the separation (that label incorrect successor c, 6(qi,a) i, j, and k, the separation is, Zk is the label not equal i, si = si(j, k) where Zj is the “correct” successor to command of the probabilities Pr( 0Z.j 1 Zi) and Pr( OZk 1 Zi), given that command c was executed. For is defined as si(j, k) = Pr( oZj / Zi) - h$ oZk 1 Zi) ; 8 a particular Iabel to label Z; (that for a given label = qj) and Zk is the most is, that for action a corresponding likely to Z,i that maximizes Pr( OZk 1 Zi) ) ; a lower bound on all the si is written as s. If the value of s is high, than to see “incorrect” ones. then we are much more likely is For the CMFO algorithm than the always positive, be reflexive corresponding a particular derives from to construct observation situations impossible of several possible one set of noise models this is as high as IQ1 ( 1 - P), and in which positive separation high values of P. The reflexivity is requirement is one In Section 6 we discuss to be observed probabilities of making it is possible correct one. The requirement this need. Consider in which for all but unrealistically in error: Ci+k Pki. Without any other restriction, to work correctly, we must guarantee the sum of the probabilities so that no incorrect that the separation this requirement. to see “correct” that observation such situations. that eliminate requirements that satisfy transitions transition is more likely s Because the separation is always with respect to a particular command, we suppress the parameter throughout. 158 K. Basye et al. /Art&id intelligence 72 (1995) 139-171 We can characterize the number of observations of the separation. The proof Hoeffding’s likely that the observation with the largest sample frequency the largest is omitted, but can be found elsewhere to show that after a large enough number of samples, required by the algorithm as a function It uses it is very is also the observation with true frequency. inequality [ 6,141. Lemma 6. lf the separation than 0, then the output of algorithm CMFO is correct with probability at least 1 - E after each vertex has been visited at least N times, where N is polynomial l/.e, IQ/, and JAI. s is greater in l/s, We will use a random walk to explore so we must turn our attention to the question of how long a walk is needed. Not only must we guarantee with high times, we must also be able to charac- probability terize the distribution it affects the transition probabilities, and, hence, that the states are all visited enough of state visitations, because the environment, the separation. that allows random walk in the environment by our earlier assumption, this. We can describe is one in which actions are also chosen the agent knows some distribution over com- the walk by a Markov process with transition A uniform equiprobably; mands matrix R, defined by r,; = g//Al, where g is the number of edges in E from qi to q,t. there are as many edges from qi to qj as there are from In a reversible q,j to qi, so R is symmetric; as well as the rows, sum this implies that is doubly stochastic has a to 1, making uniform stationary probability [ IO] ; that is, in the limit each state is visited with probability the matrix doubly stochastic. Any matrix distribution that the columns, environment, l/jQl. The next lemma concerns the rate at which the distribution the uniform stationary distribution. Let _?i( t) be the probability t and let ri be the stationary probability to be the L2 norm of the difference between of state visitations ap- that the process of state qi. Define the rr and X(t). This result is proaches is in state qi at time discrepancy, a direct consequence l,, of Mihail’s result [ 151 on the convergence of Markov chains. Lemma 7. Let t be the number of time steps needed to guarantee between the state distribution at time t and its stationary distribution executing above by that the discrepancy is less than 5, when the process determined by the transition matrix R. Then t can be bounded where @ is the merging conductance of the process. It is defined by @= min @(S), ScQ:~q;~,~td~/= where K. Basye et al./Artijicial Intelligence 72 (1995) 139-171 159 Fig. 6. A plot of 1/(2OP* - 1) in the area of positive separation. Now, we give a bound on the separation, assuming a bound on the discrepancy. /( 1 - IQ 1 fl), Lemma 8. Let & be an upper bound on the discrepancy after t steps, let z = ( 1 + IQ/ fl> let P be a lower bound on the probability of making a correct observation, Pi, and let 8 be a lower bound on the probability of taking a cor- rect action, et. If the probabilities of making incorrect observations are reflexive, that is, if tlx, y, PxY = PYx, then for all actions and all initial labels li, after a random walk of length t, (1) si>OifP>(l-~+J~~+88~-2~+1)/48,and (2) St > P(28P - 1)/Z + P - 1. Note that for a long enough walk it is reasonable to approximate requirement that P > l/m, this has the intuitively the simple than that 8, the lower bound on correct execution of commands, must be greater complexity this case, the separation of algorithm CMFO contains a factor of l/( 20P2 - 1) . Fig. 6 shows a plot of this factor for values of P and B from is positive. The “plateau” area in the figure represents the portions of (P, 0) -space for which the bound on the separation is bounded below by 2t?P2 - 1, so the exploration i to one in the area where the separation is negative. i. In z by 1, which yields pleasing consequence Theorem 9. The output of the CMFO algorithm is correct with probability at least ( 1 - s) ( 1 - ~2) after a uniform random walk of length polynomial in P(2eP - i)iz + P - 1, l/&2, I/@, IQl, and 1 Al, where P is the lowest probability of correct obser- 1/e, vation, 8 is the lowest probability of correct action, Cp is the conductance, z = 160 K. Bmyr et trl. /Artificicd Intulli~ence 72 (199.5) 139-I 71 (1 + IQldm tribution, whene\Ber 1 - IQlLm. ad ( is an upper bound on discrepancy of the state dis- (I) P>(l-z+Jz2+88z-2z+1)/48, (2) a uniform distribution on C induces a uniform distribution on A, (3) Vx, y, C,, = PYX, and the environment (4) is reversible. 6. Empirical results sections we develop a particular simulations of our algorithms In the following results of empirical cases, the results demonstrate ments, results. that in automata the actual number of samples needed class of noise mode1 and present from Sections 5.1 and 5.3. In both real-world environ- representing plausible is far less that predicted by the theoretical 6.1. Noise models that the probability of correct action be Two of the results of Section 5 require require threshold. Two others that the probability In addition, algorithm CMFO requires above some be above some threshold. of error be reflexive for observation. A large number of possible noise models satisfy these constraints, of the algorithm. several different noise models for observations. and the choice of noise model will certainly affect the actual performance In our experiments, we have used one noise mode1 for actions, and of correct observation that the probability at random for actions is constructed Our error model it is chosen uniformly is a simple uniform model. When an incorrect action is taken, from all incorrect actions. For observations, we have developed a general class of noise models called similarity partition noise models. into subsets Such a model Ql, Q2, . . , Qk. Intuitively, that represent look alike. Each state in a given partition, Q;, has an observation that gives the correct answer with probability P, and gives the label of some other state in the partition with probability ( 1 - P)//Q,/. Th e uniform error mode1 is one special case of this scheme; it occurs when the partition has only one element as follows. The set Q of states is partitioned sets of states function the elements of the partition that covers all of Q. 6.2. Deterministic actions and stochastic observations The polynomial in Section 5.1 are pessimistic. We now describe functions we have shown to bound the performance of the algorithms the results of experiments results for the complete that this is so. There are similar described with LOCALIZE that indicate inference automaton algorithm provided in [ 8 1. Our result requires environments with distinguishing and hallway environments many natural environments, tinguishing environments and determined sequences. To test this hypothesis, we constructed the length of the shortest distinguishing that sequences. We hypothesize in particular, possess short dis- a variety of hallway sequence, assum- K. Basye et al./Art$icial Intelligence 72 (199.5) 139-I 71 161 il. iv 111. Fig. 7. Graphs for hallway environments. sequence are shown for Fig. 7(i) in Figs. 7(ii) the state-transition II pairs of adjacent in each of the four directions a graph of n edges by selecting is four. The lengths of the shortest distinguishing graph for the fifth ing that such a sequence existed. Fig. 7(i) depicts floor of the Brown CS Department. Three other graphs typical of the ones that we used in our experiments through 7(iv). The length of the shortest distinguishing sequences for Figs. 7( ii), 7( iii), and 7( iv) are two, three, and two respectively. We generated a large number of graphs by starting with a d x d grid of locations and constructing to a uniform distribution without replacement. The actions available at a location consisted of (i.e., N, E, W, S) along axes of the grid; if there movement was not an edge in a particular direction, The labels orientation degenerate model was used, so the probability the probability fixed d with n in the range of d to d2, the length of the shortest distinguishing was nearly constant. For the graphs distinguishing sequence states. Fig. 8 shows the number of states in the environment, and the to a location with no adjacent corridors. A uniform error label was P and that it observed a label other than the correct one was k ( 1 - P) . For sequence that we have looked at, the length of the shortest roughly as the square root of the number of sequence as a function of type (e.g., L-shaped or T-shaped) including for locations (e.g., label corresponding facing N, E, W, or S) for a total of sixteen the length of the shortest distinguishing averaging over sets of environments. the action corresponded that the agent observed locations according to a self-transition. the junction the correct to increase encoded seemed labels, 162 K. Btuye et al. /Arti$ciul Intelligence 72 (I 995) 139-I 71 10 20 30 40 50 60 Fig. 8. Length of the shortest distinguishing sequence as a function of the number of states in the environment. 80 - 20 40 60 80 Fig. 9. Percentage of correct state identifications sequence. the distinguishing for LOCALIZE as a function of the number of repetitions of The theoretical results indicate that for a DFA consisting needs as many as 76206 steps for P = 0.8. In our simulations, is successful 100% of the time with no more sequence of length three. We also observed insensitive with P as low as 0.5. We believe uniformly that the performance of LOCALIZE is largely to perform with 100% accuracy having executed 50 steps this is largely due to the fact that errors are distributed error than 50 steps using a distinguishing it is straightforward to P, continuing over the incorrect to construct alternative labels; of 21 states LOCALIZE however, LOCALIZE K. Busye et d./Artijicial Intelligence 72 (1995) 139-171 163 Fig. 10. An abstract environment used to test the CMFO algorithm. distributions graph of the percentage environment sequence. This graph graphs that we considered that require a lot more work on the part of LOCALIZE. Fig. 9 shows a for LOCALIZE running on the of correct state identifications of Fig. 7(i) as a function of the number of repetitions of the distinguishing typifies the performance in our experiments. of LOCALIZE running on the range of 6.3. Stochastic actions and observations In this section, we consider the performance of the CMFO algorithm in simulation. used by the simulation These environments The environments hallway environments. North, South, East, and West. As before, actions location our experiments; University for the parameters P and 8. as abstract models of to moving for a given called CZT 4, used in at Brown and has 21 states. The experiments were performed using a range of values are also constructed have four actions, corresponding that are not applicable it models one floor of the Computer Science Department Fig. 10 shows the environment, in self-transitions. result With regard to the CMFO algorithm, the uniform error model the size of the problem actually helps over a large number of states virtually guarantees is quite benign. This is because uniform distribution that the most frequent observation will be correct. the uniform noise model, the increased increasing size also requires a longer walk to gather enough data. By using smaller partitions, more noise models may be created. For example, by partitioning Q into pairs, a pernicious is assured. It is easy significant competitor stated to see that all similarity partition noise models satisfy in the proof. in this regard, although to the correct answer, in terms of frequency, Indeed, under the reflexivity requirement three different the second and the uniform model, based on the hallway structure of the environment. In these experiments, first error model was cated partitions locations were partitioned world. For example, UT 4 has corner junctions, T-junctions agent to a noise model be partitioned junction with South and West hallways might be distinguished and East hallways. similarity partition error models were used. The third were more compli- In these models, in the they represented and hall junctions. If the its sensors will conform types may further a corner from one with North re- In the CZT 4 environment, to the type of junction the type of a junction locations by junction of the junction. by considering the orientation type. Junction that partitions For example, the oriented junction-type according to detect partition reliably, is able then 164 K. B~JZ et (11. /ArtiJiciol Intelligence 72 (1995) 139-I 71 in a number of singleton sults triples. elements, but also results in a number of pairs and h.3. I. Results each time the algorithm The experiments than 8, an random consisted of multiple of correct action, 0, probability runs of algorithm CMFO on the CIT 4 envi- the algorithm was run in simulation with of correct observa- issued a a random value from 0 to 1 was generated and compared against 0. If the ronment. For each of the three error models, different values for the probability tion, P, and number of steps. In these simulations, command, value generated was greater and executed, otherwise number was generated than P, a random ment of the current state. Otherwise, Values of 0 and P from 0.5 to I in 0.1 increments were used; varied from 1000 to 10,000. The walk length which combination map (50 tries per combination were used for the uniform error model). incorrect action was chosen uniformly the correct action was executed. After each execution, a second and compared against P. If the number generated was greater from the similarity partition ele- label of the current state was returned. the walk length was in to give a range the algorithm’s overall performance went from bad to nearly perfect. For each of walk length, 8, and P, the algorithm was given 20 tries to construct a incorrect observation was returned interval was chosen the correct Figs. 11-13 show the performance of algorithm CMFO on the UT 4 environment junction-type error models, at i. improves is obtained junction-type the performance for combinations Each figure shows in action and in observation of the algorithm only when P > l/m, In the oriented partition model, performance success by the theorem. This and unoriented that the algorithm’s performance re- with the uniform, oriented steadily as spectively. the uncertainty decrease and as the number of steps in- creases. The figures also provide a comparison of the different error models. Although data the theorem guarantees In the case of the uniform was collected with values of P and 0 beginning error model, of these parame- even complete is a result of the benign nature of the ters that are disallowed is very poor un- uniform noise model. are met (in particular until P reaches til the requirements this model comes much closer used in the theorem. The unoriented to the pessimistic to model performs much more closely than size 6. In addi- the fact that the partitions tion, than those suggested by the theorem, by roughly 2 orders of magnitude. The success of the algorithm on and to the looseness of a re- shorter walks in sult concerning the data gathered a different needed by the algorithm is shown for different values of P and to infer a correct map in each of twenty failed 8. The “plateau” of these fig- to get twenty perfect answers with that these failures are ures with Fig. 6, reproduced not unexpected; separa- tion. are large in this model, none smaller the walk lengths used in the simulation were much shorter to the factors just mentioned random walks used in our proof. Fig. 14 shows assumptions to the uniform model, and this is attributable less than 10,000 steps. Comparison right plot, shows the number of steps (in areas of these plots that may have very trials represent low or negative in the bottom the algorithm form. Here, is due both in a region they occur thousands) in which because areas l/a) K. Basye et al./Art#cial Intelligence 72 (1995) 139-171 165 1 e = 0.6 e = 0.7 e = 0.8 e = 0.9 e = 1.0 Fig. 11. Number of successes plotted as a function of p and the walk length for different values of 0 for algorithm CMFO on the CIT 4 environment with uniform error model. 9 = 05 9 = 0.6 P 1 P .5 20 15 0 9 = 0.7 9 = 0.8 e = 0.9 e= 1.0 Fig. 12. Number of successes plotted as a funcuon of /> and the walk length for different values of 0 for algorithm CMFO on the CfT 4 environment with the oriented junction-type similarity partition error model. K. Busye et d/Artificial Intelligence 72 (1995) 139-171 167 6 = 0.5 t' = 0.6 e = 0.7 0 = 0.8 steps e = 0.9 e = 1.0 Fig. 13. Number of successes plotted as a function of p and the walk algorithm CMFO on the CIT 4 environment with unoriented junction-type length for different values of 0 for similarity partition error model. 168 K. Basye et crl./Art~$cicd Intelligence 72 (1995) 139-I 71 CIT4 Unoriented CIT4 Oriented CIT4 Uniform l/s Fig. 14. Number of steps for first 100% success (N = 20) plotted as function of P and the walk length for different values of ~9 for algorithm CMFO on the CIT 4 environment with three similarity partition error models; the bottom right plot is the 1 /s factor from Theorem 2. 6.4. Application to a real mapping system were made In the earlier analyses, simplifications we assume for observation the sake of mathematical and movement errors assumptions, we be- these simplifying independent For example, error. Despite that our models are relevant to a variety of interesting faced by mobile tractability. and ignore sources of systematic lieve Our simulations were based on the problem their spatial environment. map building based on the CMFO algorithm elsewhere Recall nominally some threshold. This requirement was satisfied by combining tation, that the CMFO algorithm in addition junction required, features, a unique output at each state which whose observation probability was above about orien- type and position at each location. The robot used was equipped with to several structural information about In this section we briefly describe a real system for robotic is available from Section 5.3; more detail tasks and environments. in learning robots [ 61. K. Basye et al./Art$cial Intelligence 72 (1995) 139-171 169 and an odometer which were used to generate these procedures were used as the algorithm’s strategies; transducers eight sonar Robust high-level movement procedures were implemented traversal sensing and movement ronment algorithm was modified allowed more efficient exploration to fail. to operate to the CIT 4 simulation from the version presented such as that corresponding procedures were designed and avoided slightly as combinations this information. of simpler actions. The robot’s in common hallway envi- environment. The CMFO these modifications taking actions which could be predicted above; The goal of the modifications identification and development strategies using a number of steps well required by the analysis of Section 5.3, on the order of a small This goal was achieved; The of sensing and movement in the environment. of the environment the number of states was to allow correct below constant robot successfully the number times built models using 3]Q] steps. 7. Discussion and open problems The system identification problems discussed here can be thought of as points in each with a large space of such problems, properties. Our goal in this work has been to provide solutions problems interest problems These in this part of the space derives directly from our interest in the real world, where such noise is unavoidable. results provide indications from a portion of this space characterized by noisy inputs and/or outputs. Our in solving identification its own set of structural interaction and to several representative robotic systems. For example, proached with current direct comparisons ical and empirical advantage. The robotic mind. With regard to problems tions that can be made which allow even better results. of the complexity results suggest system described that having nominally involving about which problems might be realistically ap- although we have not provided of the problems explored here, both our theoret- is an enormous unique labels earlier was designed with this knowledge in there may be other assump- spatial exploration, The solutions to problems involving non-unique sequences. Gill [ 111 provides outputs generally involve sequences, a way to construct preset in the sequences when they exist, but these may have length exponential distinguishing in particular distinguishing number of states and the algorithm Yannakakis has a preset distinguishing constructive guishing questions algorithm and Lee sequence. As regards uncertainty to be resolved. remain requires a complete description of the automaton. [ 231 show that the problem of determining whether an automaton but also give an efficient, has an adaptive distin- two important for determining whether an automaton is PSPACE-complete, in perception, the following sequence l Suppose distinguishing sequences exist and observation and movement are uncer- tain? Are adaptive sequences still easy to find? l Suppose the agent is given an adaptive distinguishing the underlying automaton with observation sequence. and movement uncertainty? Is it easy to identify I70 8. Conclusions that algorithms for agents investigates as a deterministic system corresponding linite automaton with a relatively the input/output In our model, to identify to their environment. to any high degree of predictive accuracy, expediency the means of simplifying This paper of the dynamical is represented states and actions. While we admit automata provided Biological that serve believe does not require an agent interaction with the environment; modeled with different automata. We claim action automata. behavior the system small number of the real world cannot be modeled by such requires and nature has to our senses. routines of the real world. We is impossibly hard. In addition, our approach the full range of its rather, different aspects of that interaction would be then that, given appropriate perceptual and in terms of inferring systems appear to abstract and considerably to be equipped with robust perceptual the huge amounts of data available that, lacking such routines, to learn one automaton to model system it makes sense the complexity identification to represent and motor routines, learning reduce errors In this paper, we address the problem of dealing with the inevitable and movement without any means of establishing and movement, Given our model, we show that errors approximation. A genera1 method of dealing with errors that oc- in perception are rather easy to contend with if the goal is polynomial- cur in perception that do not affect movement in both time, high-probability observation truth as a basis for filtering hypotheses has so far eluded us. We have, however, provided algorithms that work for the case the envi- throughout how it got somewhere without ronment and the agent has some means of determining for the necessarily from. We have also provided it came are case in which all states have unique signatures but both observation noisy. algorithms and movement there are landmarks distributed knowing where in which ground that indicate In additional to our theoretical results. we have performed extensive that, for a class of relatively benign but nevertheless experimental realistic en- our bounds are quite conservative. Ultimately, we are seeking algorithms environmental studies vironments, that can learn a high-probability model the presence of occasional errors. In our work on real mobile robots, we are approaching that goal. factor of the size of the underlying mode1 even in in time some small constant to the correct, underlying approximation Acknowledgments Dana Angluin and Sean Engelson provided and proof of Section 5.1. Oded Maron and Evangelos Kokkevis also participated discussions participated pointers provided helpful suggestions. to the algorithm in results. Jeffrey Vitter and provided helpful simulation of the landmark algorithm. Philip Klein provided useful reviewers also to the literature of random walks in graphs. Several anonymous of these algorithms in the development insights and corrections K. Basye et al./Art@cial Intelligence 72 (1995) 139-l 71 171 References [ 1 I D. Angluin, On the complexity of minimum ]2] D. Angluin, Learning 131 J.R. Bachrach, Department MA (1992). Connectionist modeling of Computer regular sets from queries and counterexamples, inference of regular sets, Inf: Control 39 (1978) 337-350. I$ Comput. 75 ( 1987) 87-106. Tech. Report 92-6, at Amherst, Amherst, and control of finite state environments, and Information Science, University of Massachusetts 141 K. Basye, T. Dean and J.S. Vitter, Coping with uncertainty in map learning, in: Proceedings IJCAI-89, Detroit, MI (1989). 151 K. Basye, T. Dean and J.S. Vitter, Coping with uncertainty in map learning, Tech. Report CS-89-27, Department of Computer Science, Brown University, Providence, RI ( 1989). I61 K.J. Basye, Aframework$tr map construction, Ph.D. Thesis, Department of Computer Science, Brown University, Providence, RI ( 1992). [ 71 T. Dean, D. Angluin, K. Basye, S. Engelson, L. Kaelbling, E. Kokkevis and 0. Maron, finite in: Proceedings AAAI-92, Inferring automata with stochastic output functions and an application San Jose, CA ( 1992). to map learning, 181 T. Dean, D. Angluin, K. Basye, S. Engelson, L. Kaelbling, E. Kokkevis and 0. Maron, finite to map learning, Tech. Report CS-92-27, Inferring automata with stochastic output Department of Computer Science, Brown University, Providence, RI ( 1992). functions and an application 19 ] T. Dean, K. Basye, R. Chekaluk, S. Hyun, M. Lejter and M. Randazza, Coping with uncertainty in a control system for navigation and exploration, in: Proceedings AAAI-90, Boston, MA ( 1990). I 10 I W. Feller, An Introduction to Probability Theory and its Applications (Wiley, New York, 3d ed., 1970). revised printing. I II] A. Gill, State-identification I 121 E.M. Gold, System I 131 E.M. Gold, Complexity I 141 L. Kaelbling, K. Basye and T. Dean, Learning of automaton identification experiments in finite automata, Inf Comput. 4 ( 1961) 132-154. via state characterization, Automatica 8 ( 1972) 621-636. identification from given sets, IY$ Control 37 ( 1978) 302-320. labelled graphs from noisy data, in: Proceedings Seventh Yale Workshop on Adaptive and Learning Systems ( 1992) I 151 M. Mihail, Conductance and convergence of Markov chains: a combinatorial treatment of expanders, in: Proceedings 31st ACM Symposium on Foundations of Computer Science ( 1989). I 161 E.E Moore, Gedanken-experiments on sequential machines, in: Automata Studies (Princeton University Press, Princeton, NJ, 1956) 129-153. I 171 L. Pitt and M.K. Warmuth, The minimum consistent DFA problem cannot be approximated within any polynomial, in: Proceedings 21st Annual ACM Symposium on Theoretical Computing ( 1989). I 181 R.L. Rivest and R.E. Schapire, Diversity-based inference of finite automata, in: Proceedings 29th ACM Symposium on Foundations of Computer Science ( 1987). [ 191 R.L. Rivest and R.E. Schapire, Inference of finite automata using homing sequences, in: Proceedings 2lst Annual ACM Symposium on Theoretical Computing ( 1989). 1201 R.E. Schapire, The design and analysis of efficient learning algorithms, Tech. Report MIT/LCS/TR-493, ( 199 I ) and J.L. McClelland, A. Cleeremans in simple in: D. Touretzky, ed., Advances in Neural Information Processing Vol. 1 (Morgan sequential Learning structure for learning, planning, and reacting based on approximating dynamic in: Proceedings Seventh International Conference on Machine Learning ( 1990). and D. Lee, Testing finite state machines, in: Proceedings 23rd ACM Symposium on for Computer Science MIT Laboratory I21 ] D. Servan-Schreiber, recurrent networks, Kaufmann, San Mateo, CA, 1989). Integrated architectures [ 221 R.S. Sutton, programming, I23 1 M. Yannakakis Theoretical Computing ( 199 1). 