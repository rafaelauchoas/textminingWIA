ELSEVIER Artificial Intelligence 79 ( 1995) 241-292 Artificial Intelligence Performance of linear-space search algorithms * Weixiong Zhang *, Richard E. Korf Computer Science Department, Universiry of California at Los Angeles, Los Angeles, CA 90024, USA Received December 1992: revised June 1994 Abstract space linear Search that use algorithms (DFBnB), iterative-deepening tree T( b, d) that has mean branching in the search depth are widely employed such as planning and scheduling. search algorithms, that are the sum of the costs of the edges from the root to the nodes. We prove in practice In this paper, we study to solve difficult problems optimally, including depth-first branch-and- the average-case performance of linear-space (ID), and recursive best-first search (RBFS). To facilitate bound factor b, depth d, and node our analyses, we use a random that the costs expected number of nodes expanded by DFBnB on a random tree is no more than bd times the expected number of nodes expanded by best-first search (BFS) on the same tree, which usually in depth d. We also show that DFBnB is asymptotically optimal requires space that is exponential time, and ID and RBFS are asymptotically optimal when the edge when BFS runs in exponential If bpo is the expected number of children of a node whose costs costs of T( b,d) are integers. are the same as that of their parent, three then the expected number of nodes expanded by these is exponential when bpo < 1, at most 0( d4) when bpo = 1, and at most linear-space algorithms factor of T( b, d) and the quadratic when bpo > 1. In addition, we study the heuristic branching factor of BFS, DFBnB, ID, and RBFS on T( b, d). Furthermore, we use our effective branching analytic and to in the performance predict in the Asymmetric Traveling Salesman Problem. to explain a surprising anomaly the existence of a complexity of these algorithms, transition results 1. Introduction and overview Search is a fundamental problem-solving technique. In this paper, we study search algorithms that are widely used in practice for problem solving. In particular, we are *This research was supported by NSF Grant, #IRI-9 119825, and a grant from Rockwell second author, and partially by a GTE Graduate Fellowship Year Fellowship * Corresponding 1001. Marina de1 Rey, CA 90292, USA. Telephone: author. Current address: USC/Information to the first author. (310)822-1511. ( 1993-94) Sciences E-mail: zhang@isi.edu. ( 1992-93) and a UCLA Chancellor’s Dissertation International to the Institute, 4676 Admiralty Way, Suite 0004-3702/95/$X)9.50 @ 1995 Elsevier Science B.V. All rights reserved SSDlOOO4-3702(94)00047-6 242 initial state goal state pI#FlJ (a) initial and goal states (b) Searching for the goal state Pig. I. An Eight Puzzle example. in those algorithms linear-space interested we call are the algorithms problems and-bound, paper is to understand when they are employed [ II]. The known iterative-deepening, of choice algorithms. Linear-space for algorithms that use space that is linear in the search depth, which they are important because such as the NP-hard include depth-first branch- and recursive best-first search. The primary goal of this algorithms large and difficult problems, search algorithms time complexity of these linear-space linear-space the average-case to solve difficult problems optimally. 1.1. Search problems We start by discussing two search problems, the sliding-tile puzzles, which have been intelligence, used extensively as example problems in operations Traveling Salesman Problem, which problems and model we will use and the search algorithms we will analyze. in artificial is ubiquitous are used as benchmarks for our experiments, and the (Asymmetric) research. These two the analytic to introduce We first present the problems themselves, can be solved. Operators are used to decompose if the original one cannot be solved directly. The lower-bound cost functions, their most effective operators, and the most and then briefly describe into cost functions a problem lower-bound used or most efficient commonly how these problems subproblems are used to guide a search algorithm. 1.1. I. Sliding-tile puules A square sliding-tile puzzle consists of a k x k frame holding k2 - 1 distinct movable tiles, and a blank space (see Fig. 1). Any tiles that are horizontally or vertically adjacent to the blank may move is any such legal move. into the blank position. An operator Given an initial and goal state of a sliding-tile puzzle, we are asked to find a minimum number of moves that transform the initial state into the goal state, which is NP-complete [ 431. for arbitrary-size A commonly used cost function, or heuristic evaluation, puzzles ;e( n) is the number of moves from the initial state to state rr, and h(n) is f(n) = g(n) + h( n), where is the Manhattan W Zhang, R.E. Kmf/Artifcial Intelligence 79 (1995) 241-292 243 for the number of moves along the grid it is away from its is computed by counting, from n to the goal state. The Manhattan distance distance each tile not in its goal position, these values over all tiles, excluding goal location, and summing is an underestimate distance number of moves of the minimum since every tile must move at least its Manhattan distance problem, and only one tile can move at a time. the blank. Manhattan required the to its goal location, to solve adjacent at the initial A given sliding-tile state. The cost function puzzle can be solved as follows. Starting state is expanded by individually moving each tile that is horizontally state, or to the blank. Each such possible move produces a new state, a child to all new states. A state that is then selected as the next current state, and the current vertically of the current has been generated but not yet expanded this state-selection than or equal to the cost of the best states, or all unexpanded goal node found so far. How a new state is selected depends on the search algorithms employed, which process continues until there are no unexpanded states have costs greater and state-expansion in Section 1.3. is then applied is discussed in detail 1.1.2. The Asymmetric Traveling Salesman Problem Given n cities, { 1,2,3,. . . , n}, and a matrix the Traveling Salesman Problem tour that visits each city exactly once and returns (ci,j) of intercity costs that defines a (TSP) is to find a to the starting city. problems can be formulated as TSPs, such as computer wiring, etc. [ 291. When the cost matrix equal to the cost from each pair of cities, cost between minimum-cost Many NP-hard combinatorial vehicle routing, workshop scheduling, is asymmetric, city j to city i, then the problem optimization i.e. the cost from city i to city j is not necessarily is the asymmetric TSP (ATSP) . lower-bound cost function The most effective [ 1,361. The assignment problem for the ATSP is to assign to the is the solution to each city i another such that the total cost of all assignments is a relaxation of the ATSP since the assignments tour, allowing collections of disjoint subtours, and thus provides of each city to its assignment problem city j, with ci,j as the cost of this assignment, is minimized. The assignment problem need not form a single a lower bound on the cost of the ATSP tour, which is an assignment successor tour, it is the solution time [36]. in the tour. If the assignment problem solution happens to be a single complete in O(n3) to the ATSP as well. The assignment problem is solvable for the given six cities. Assume that the assignment illustrated in Fig. 2, to introduce the operators [ 1 I. We first contains problem problem two subtours We use an example, the assignment solution solve problem assignment If subtour 2 + 3 ---$ 2 is chosen either exclude edge (2,3) or edge (3,2), additional subproblems, still not a single complete solution contains constraint, tour. shown subtours, we try to eliminate in the root node of the tree. Since the them, one at a time. two choices. We may each of which leads to a subproblem with an the excluded edge. We then solve the assignment problems of the is if its assignment problem solution to be eliminated, we have and further decompose a subproblem In order to keep the total number of subproblems should avoid generating duplicate subproblems. generated as small as possible, we in This can be realized by including I=( (2,3) t 6) t t 2) Fig 2. An exarnplc OF solving the ATSP. that were excluded suppose any edges that we generate the current subproblem example, The second subproblem B excludes edge (3.2), fore. no subproblems under B will have edge disjoint. generated under A can have edge guaranteeing in previous subproblems. edge In our (2,3). the edge (2,3). There- but all subproblems that the subproblems will be mutually but includes the first subproblem A by excluding (2,3), (2.3), In general, let E denote the set of excluded edges, and I the set of included edges of a tour. We choose problem , x,}, that into t children, with the kth one having subproblem whose assignment problem solution one subtour, solution are not in 1. We then decompose excluded arc set Ek and included arc set II, such that the assignment that there are t edges in the subtour, {xt , x2,. is not a single complete from the one with minimum to eliminate Assume number of edges, the problem Ek =Eu(Xk} fI,=IU{x I,...,. XL-,} , k=l,? ,__., t (1) Since _KL is an excluded edge of the kth subproblem, edge of the (k + I )st subproblem, XL E 1~. 1, any subproblems kth subproblem I )st subproblem must generated, and the state space is a tree of unique nodes. Briefly, a given ATSP can be solved by taking cannot contain edge _~i. but all subproblems .rk. Therefore, no duplicate include edge xk E Ek, and it is an included from the the (k + subproblems will be generated from obtained problem and repeating the assignment the following: First, solve subproblem current subproblem. If the assignment then select a subtour, and generate all child subproblems subtour. Next, select as the current subproblem a new subproblem but not yet expanded. This process continues until there are no unexpanded or all unexpanded complete Section 1.3. tour found so far. How to select the next current subproblem have costs greater than or equal subproblems solution the original problem is not a single complete edges by eliminating problem as the root for the tour, in the that has been generated subproblems, to the cost of the best in is described W! Zhang, R.E. Kmf/Art$cial Intelligence 79 (1995) 241-292 245 E (a) ECBEDCE UN Fig. 3. A simple graph and part of its depth-first search tree 1.2. State-space tree model 1.2.1. A state space As described of the problem in the previous examples, solving a problem can be formulated as search in a state space. A state space consists of a set of states and a collection of operators. that The states are configurations map one state to another. In general, a state space is a graph, in which nodes represent states, and edges represent operators or state transitions. is a systematic that have specified properties, or a path from the initial state to a goal state. In this paper, we in focus on state-space tree is a state-space graph without cycles, which leaf nodes are goal nodes, but of varying cost. The number of children of a node is referred of the space in order to find one or more goal nodes to as the branching factor of the node. to be solved. The operators are actions trees. A state-space in a state space exploration Search We adopt the tree model in practice. As discussed into disjoint subproblems for two reasons. The first is that a tree is a realistic model in the ATSP example, a problem can often in/from to most such that one entity then we have a partition of some entities that can be applied by including/excluding from its siblings, If the problem is decomposed is excluded to the subproblems. This is a general principle optimization problems. in one subproblem for problem solving be decomposed the solutions combinatorial included the state space, which reason The second is a tree without any duplicate nodes. is that a tree is an appropriate model for linear-space is the most general model of a state space, algorithms. linear-space While a graph with cycles algorithms restriction, graph. For example, a brute-force depth-first at node A, is shown in Fig. 3(b), explore a tree, at the cost of generating duplicate nodes. Due to their space in a linear-space search of the graph in Fig. 3 (a), starting in general detect all duplicate algorithms cannot nodes in which duplicate nodes appear. tree have associated costs, which are used by a search to explore next. The estimated cost of a node, f(n), the this node, or an estimate of the total cost of the best goal node in is the cost of solving which The nodes in a state-space to decide which node algorithm is an estimate of the actual cost of the node, f’(n), problem the tree underneath A cost function < f*(n), the given node. is a lower-bound that includes i.e. f(n) be obtained by relaxing for all nodes n in the state space. A lower-bound [ 391. One such example the original problem the actual cost of a node, cost function can is the assignment if it never overestimates 246 W Zhm~. K.E. Ko~~f/A~rijiciul lnrelli~ence 79 (1995) 241-292 the property, and the former a monotonic can be cost of all nodes on the path function implies is monotonic if the cost of a child node rr’, f( n’), than or equal to the cost of its parent node n, i.e. f(n’) > f(n). The represents a more than its parent, and hence costs at least as much. The monotonic from the fact that a child node typically problem for the ATSP. A cost function problem is always greater monotonic property comes constrained property latter, but not vise versa. Given a lower-bound constructed from the root to the node, guaranteeing additive cost function, [ 161. g(n) is slighter stronger intelligence by taking than the lower-bound function, the cost of a node as the maximum that ,f(n’) > f(n), where n is the parent of 11’. f(n) has been widely used = g(n) + h(n), A particular is the estimated cost, or the heuristic estimate, in is the sum of the cost of the path from the initial state artificial from n to to the current node II, and h(n) [ 391 if for any a goal node, for example is the cost of child node II’ and its parent II, h(rr’) + k(rt.rz’) 3 h(n), where k(n,fz’) [ 231. This the edge from n to 11’. Monotonicity can be simply shown as follows. Given f( n’) 3 f‘(n), or g( n’) + h( n’) 3 g(n) + h( n), using g(n’) = g(n) + k(n,n’), we then have g(n) + k(n,n’) -I- h(n), or k(tt,n’) + h(n’) > A(H). of ,f and consistency of h are equivalent the Manhattan distance. /I is called consistent + h(n’) > g(n) A state-space tree with node costs can also be treated as if it has edge costs instead. the cost of the the sum of the edge The cost of an edge that connects child node and costs on its path to the root. Edge costs are nonnegative non-decreasing with their depths. An edge cost can also be viewed as the cost of an operator that of the parent. The cost of a node if node costs are monotonically is the difference between that maps the parent to the child node. two nodes is then 1.2.2. A random An additional tree model reason tractable. To facilitate our average-case that we use a state-space tree model analyses, we introduce is that a tree is analytically the following model. random incremental 1.1. An tree, or random Definition random branching identically depth d. root cost 0, and factors with mean b. Edge costs are finite, nonnegative, drawn from a common probability distribution. The cost of a node is the sum of the edge costs from cost at depth d. the root to that node. An optimal distributed and independently is a leaf node of minimum is a tree with independent tree T( b, d), goal node and Fig. 4 shows an example of an incremental random tree, with the numbers on the edges and in the nodes being the edge costs and the resulting node costs, respectively. Two important features of this model are worth mentioning. The first is that multiple in which only one optimal goal optimal goal nodes may exist, that the is allowed costs of all nodes are independent the costs of two nodes are correlated if they share common edges on their paths to the root, with the degree of dependence based on the number of edges they have in common. is that, unlike [ 12,39,41], [ 12,39,41]. The second the conventional in contrast assumption to models In this random cally distributed, which is called to the branching the edge costs are assumed to be independent the i.i.d. assumption. The i.i.d. assumption factors of different nodes. These assumptions, unfortunately, tree model, and identi- also applies rarely hold W Bang, R. E. Kotf/Artijicial Intelligence 79 (1995) 241-292 247 optimh goal Fig. 4. A simple incremental random tree. t optimal goal Fig. 5. A binary tree with depth three and edge costs from {0,1,2,3,4} in practice. Nevertheless, average-case assumptions Examples analyses. often characterize are presented in Section 4. they are usually introduced to facilitate analyses, In many cases, however, analytic results obtained under real-world problems where the assumptions especially i.i.d. do not hold. Since the branching factor of a node is a nonnegative for a random length. Thus, it is possible in the tree has finite nodes with nonzero probability, factor be greater mention a random is that most of our results are asymptotic hence we must rule out finite depth trees. than one, tree T( b, d) , we assume tree to be finite, meaning In order for a random random variable, it may be zero. that every path from the root tree to have an infinite number of it is necessary and sufficient that the mean branching i.e. b > 1 [ 151. In the rest of this paper, whenever we that b > 1. The reason for this assumption results as the tree depth goes to infinity, and 1.3. Search algorithms random A search algorithm is a strategy used to decide which node to explore next. We use in Fig. 5, it is a uniform tree with depth three, edge costs chosen from (0, 1,2,3,4}, and an optimal goal in a simple binary node of cost four (4). The numbers on the edges are edge costs, and the numbers the nodes are the resulting node costs. tree to illustrate our algorithms. As shown 0: expanded 0:generated Fig. 6. The order of node expanwns of best-first search 1.3.1. Be.+first search state-space for expansion. To maintain The first algorithm we consider is best-first search (BFS). BFS maintains tree, and at each cycle expands a node of minimum a partially cost, among expanded all nodes that have been generated but not yet expanded, until an optimal goal node is chosen requires space that is exponential for most applications. is in Appendix A. Fig. 6 illustrates how BFS works on Pseudo-code the tree of Fig. 5, with the numbers beside the nodes being the order in which the nodes are expanded. in the search depth, making the partially expanded tree, BFS typically for the algorithm it impractical is the A* algorithm A special case of BFS the cost function ,f( n) = g(n) + Iz( II), where <q(n) is the sum of the cost of the path from the initial state is an estimated cost from node II to a goal node. An to the current node II, and h(n) important the minimum number of nodes among all algorithms guaranteed to find an optimal goal, up to tie-breaking feature of A* is that for a given consistent heuristic estimate h, it expands among nodes whose cost equal to the optima1 goal cost [ 71. 1 161, which uses 1.3.2. Depthjirst branch-and-hound (DFBnB) uses space that is only Depth-first branch-and-bound in the search depth. Starting at the root node, and with a global upper bound u on the cost of an optimal goal, DFBnB always selects a most recently generated node, or a deepest node a new leaf node is reached whose cost is less than u, u is to expand next. Whenever revised for expansion whose cost is greater along a path from the root, and all descendents great as that of their ancestors. a node is selected to U, it is pruned, because node costs are non-decreasing of a node must have costs at least as to the cost of this new leaf. Whenever than or equal linear In order to find an optimal goal node quickly, in an increasing order of their costs. This child nodes is called node-ordering. this paper, when we refer to DFBnB, we mean DFBnB with node ordering. in Appendix A. Fig. 7 shows how in should be searched Throughout A recursive version of the algorithm DFBnB works on the tree of Fig. 5. The numbers beside which they are expanded. the nodes are the order the newly generated is included for DFBnB The penalty that are not explored by BFS, or some nodes whose costs are greater than the optima1 goal cost. four (4) in Fig. 7 is not expanded by BFS For example, to run in linear space is that it expands some nodes the node with sequence number W Zhang, R.E. Korf/Arti$cial Intelligence 79 (1995) 241-292 249 0: expanded 0:generated Fig. 7. The order of node expansions of depth-first branch-and-bound. its cost (5) in Fig. 6, because DFBnB does not work on a graph with cycles, since it may keep to expand on a cycle. In this case, DFBnB to guarantee In addition, the nodes requires either a finite tree, or a cutoff depth in order than the optimal goal cost (4). termination. is greater 1.3.3. Iterative-deepening In order to use space linear in the search depth, and never expand a node whose cost is greater than the optimal goal cost, we turn to iterative-deepening (ID) [ 221. initially Using a global variable called the cutoff threshold, performs a series of depth-first search iterations. then it terminates iterative-deepening expands all nodes with costs less than or equal to the threshold. for expansion, the minimum and a new iteration iterative-deepening the order thresholds of 0, 1, 2, 3, and 4. cost of all nodes that were generated but not expanded on the last iteration, is begun. The algorithm is listed in Appendix A. Fig. 8 shows how works on the tree of Fig. 5, with the numbers beside the nodes being iterations have cost they are expanded. successfully. Otherwise, In this example, the threshold In each iteration, set to the cost of the root, it If a goal node is chosen to is increased successive in which uses depth as cost and expands all nodes at a given depth before expanding is a general Iterative-deepening search algorithm, includes cial cases, depending on the cost function. For example, depth-first (DFlD) any nodes at a greater depth. Uniform-cost Dijkstra’s path from the root to a node as the node cost. Iterative-deepening-A* the A* cost function f(n) = g(n) + h(n). iterative-deepening, single-source shortest-path algorithm and an iterative version of [8], uses the sum of the costs on the (IDA*) employs a number of spe- iterative-deepening 0 :expanded 0: generated Fig. 8. The order of node expansions of iterative-deepening 0: expanded 0: generated Fig. 9. The order of node expansions of recursive best-first search Although iterative-deepening than the cost of the optimal goal node, it may expand some nodes more than once, as shown in Fig. 8. will not expand a node whose cost is greater 1.3.3. Kecursive best-jrst Another problem with srurch iterative-deepening It is also somewhat is that it does not expand new nodes with a monotonic best-first order when node costs are nonmonotonic. with a monotonic cost function. Recursive best-first search (RBFS) unexplored nodes in best-first order, regardless of the cost function, iterative-deepening cost function, and still runs key difference between maintains local cutoff describe formal description of the algorithm to [ 241. iterative-deepening a single global cutoff threshold and RBFS threshold for the whole tree, RBFS computes a separate for each subtree of the current search path. For simplicity, we the behavior of the algorithm on the tree in Fig. 5 (see Fig. 9). and leave a to Appendix A, and a full treatment of the algorithm in inefficient even [ 241 always expands is more efficient than in linear space. The iterative-deepening is that while to return the memory After expanding the upper bound of 2. causing RBFS for the children of the left child of the root node. First, however, is called recursively on the left child the root (see Fig. 9), RBFS with an upper bound of 2, the value of the right child. The reason is that the best frontier node will be in the left subtree as long as its value is less than or equal to 2, the the left child, both its children’s best frontier node in the right subtree. After expanding to the root and values, 3 and 5, exceed release it child value of 3 and stores that as the new value of the left child backs up the minimum is called recursively on the right child of the root. After returning with a upper bound of 3, the value of the best frontier node in the left subtree. After expanding the upper bound of 3. so RBFS backs up the minimum of these values, 4, stores it as the new value of to the root. It then calls itself recursively on the left child the right child. and returns with an upper bound of 4, the value of the best frontier node in the right child. After expanding the left child and its left child, all frontier nodes in the left child are greater than or equal to 5, 5 is stored as the new value of the left child of the root, and RBFS is called on the right child with an upper bound of 5. It then proceeds down the right subtree until the right child, both its children’s values, 4 and 6, exceed the goal node of cost 4, and terminates. to the root, RBFS it chooses At any point with all immediate search path, along siblings of nodes on the current path, together with the cost of the the current in memory to expand in time, RBFS maintains bi! Zhang, R.E. Korf/Art$cial Intelligence 79 (1995) 241-292 251 best frontier nodes below each of those siblings. Thus, its space complexity the search depth. An important generates fewer nodes only expands expands however, RBFS also suffers from node re-expansion seven nodes on the tree in Fig. 5 (see Fig. 9)) but iterative-deepening to iterative-deepening, in is linear is that with monotonic node costs, it up to tie-breaking. For example, RBFS fifteen nodes on the same tree (see Fig. 8). Similarly than iterative-deepening, feature of RBFS overhead. 1.4. A surprising anomaly In spite of the fact that these search algorithms performance explained by existing original motivations is still not fully understood. For example, results. Understanding this work. behind are widely used their the following anomaly cannot be the cause of this anomaly was one of the in practice, and independently scale. The straight dotted lines of DFBnB on trees with different uniform branching Fig. 10 shows the performance factors b, and edge costs uniformly The horizontal axis is the tree depth d, and the vertical axis is the number of nodes generated, to the left show the numbers of nodes on a logarithmic in the trees, which the lines tree depth, and to the right to find a factor and search minimum-cost depth. branching the average number of nodes generated by DFBnB leaf node, averaged over 1000 trials for each branching - 1) = O(bd), growing exponentially with is (b”+’ - increasing with factor. The curved chosen from (0, 1,2,3,4}. increasing represent solid l)/(b counter-intuitive the following the trees with larger branching anomaly. For a fixed search depth, Fig. 10 displays if the faster. For example, factors DFBnB can search is fixed at 50, then DFBnB generates 1,846,801 nodes on average on a search depth factor random factor six, and only 1,276 nodes on a tree with four, 9,076 nodes on a tree with branching branching for a given amount of computation or total number of node generations, DFBnB can search deeper in the trees with greater branching factors. two, 110,894 nodes on a tree with branching factor ten. Alternatively, tree with branching factor chosen from (0,1,2,3,4) ----. total txe.nodes DFBnB - 0 1 I 50 100 search depth d I 150 I I 200 Fig. 10. Anomaly of depth-first branch-and-bound edge costs uniformly chosen from (0,1,2,3,4) LL- 0 --I__ ~_i 50 100 search depth d 150 ~_ii 200 --I’( II 0 edge costs uniformly chosen from (0.1,2,?,4) _-.._ 50 A~____ 100 search depth d A 150 200 (a) Anomaly in ID (b) Anomaly in RBFS Fig. I I. Anomaly of iterative-deepening and recursive best-first search if the total computation For example, can reach depth 37 on a binary on a tree with b = 6, and depth more than 200 on a tree with b = IO. Furthermore, and RBFS as well, as illustrated by Fig. 11. anomaly exists in iterative-deepening then DFBnB tree, depth 50 on a tree with b = 4, depth 160 this is tixed at 100,000 node generations, random All the algorithms mentioned the worst case. As the worst case is usually pathological, is its average-case a search algorithm search algorithms is still unknown. are used most of the time in practice, above have to examine every node in a state space in a more realistic measure of the fact that linear-space complexity performance. Despite their average-case In this paper, we analyze the average-case complexity of linear-space search algo- tree T( b, d) that has mean branching show that on a random time. We further show that iterative-deepening rithms. To facilitate our analyses, we use a random factor 17. depth d, and a node cost computed as the sum of the edge costs on its path to tree T( b, d), DFBnB expands at most the root. We analytically is the expected number of nodes ex- O( tl N( 0. d) ) nodes on average, where N( b, d) optima1 when BFS runs in panded by BFS. We also prove that DFBnB and RBFS are asymptotically exponential tree with integer edge costs. If pu is the probability of a zero-cost optimal on a random then the expected number of children of a node whose costs are the edge in T( 0, d), is bpo. Overall, we prove that the average number of nodes same as that of their parent expanded by these linear-space is exponential when bpo < 1, at most O(d4) when bpo = 1, and at most quadratic when bpo > 1. In addition, we study the heuristic branching factor of BFS and linear-space algorithms. These results are presented factor of T( b, d), and the effective branching is asymptotically in Section 2. algorithms The results in Section 2 indicate exponential children bpo increases to polynomial that there is an abrupt complexity from in the search depth, when the average number of same-cost than or equal to one. We examine from less than one to greater transition, S! Zhang. R.E. Korj’/Artijicial Intelligence 79 (199.5) 241-292 253 transition on the ATSP We further consider how to select a search algorithm linear-space transition in Section 3. In Section 4, we apply this complexity explain a previously observed anomaly of DFBnB on sliding-tile complexity for a given problem algorithms space and running Section 7. Previous in Section 5. Our experimental the algorithms from this research were presented time. We discuss are usually of choice in [ 57,581. results results show for large problems, that both in terms of in to the analytic puzzles, and predict a results related work in Section 6. Finally, we conclude 2. Complexity of linear-space search In this section, we analyze trees. The difficulty rithms and their effective branching factor of random linear-space be carried over characterize and that of best-first search. the relationship algorithms between the expected complexity factors on random search algo- of the linear-space trees, and the heuristic branching is that the mathematical to these algorithms. To circumvent to directly obtain tools used for best-first the expected complexity of the search cannot is to this difficulty, our approach the expected complexity of linear-space algorithms 2.1. Problem complexity and optimal goal cost To analyze the expected complexity of these algorithms, we first consider the problem in terms of the total number of node complexity expansions. of finding an optimal goal node, tree with monotonic node costs, the total number of Lemma 2.1. On a state-space nodes whose costs are strictly less than the optimal goal cost is a lower bound on the complexity of finding an optimal goal node, and the total number of nodes whose costs are less than or equal to the optimal goal cost is an upper bound on the complexity finding an optimal goal node. of Proof. See Appendix B. Cl This lemma indicates that the problem complexity is directly related goal cost. The optimal goal cost and other properties of the random studied using the tools of an area of mathematics particular, 211. [ 151 and first-percolation branching processes age-dependent called branching processes to the optimal tree have been [ 151, and in [ 14, processes Let po be the probability that an edge cost is zero. Since b is the mean branching leaving a node, or the expected factor, bpo is the expected number of zero-cost branches that have the same cost as their parent. We call these number of children of a node nodes same-cost children. It turns out that the expected number of same-cost children of the expected cost of optimal goal nodes. Intuitively, when bpo > 1, a node determines child, so that the optimal goal a node should expect to have at least one same-cost cost should not increase with depth. On the other hand, when boo < should not have a same-cost child, which causes depth. I, most nodes the optimal goal cost to increase with Lemma 2.2 ( [ 32,331) tree T(b,d) with b > 1. As d - X, . Let C* be the expected cost of optimal goal nodes of a random ( I ) C’ld + cy almost surely ’ when bpo < I. where a is a constant independent IIJ~ tl, (2) C*/( log log d) + 1 almost surely rvhen bpo = I. ( 3 ) C’ almost surely remains bounded when bpo > I. Lemma 2.2 means that when bpo < I. cd is the dominant term in the optimal goal cost C*. Similarly, when bpo = I, log log d is the dominant term in C*. We can further show the following monotonic property of the optimal goal cost. Lemma 2.3. On a random tree T( b, d) with bpo > I, as d ---t 00, the expected cost of optimal goal nodes decreases when bpo increases ,for a given 6, or a given po > 0. In particular; zero when po + 1 for a given b, or when b --f x the expected goal cost approaches for a given po > 0. Proof. See Appendix B. U 2.2. Best-first search To characterke the expected complexity of the linear-space algorithms, we first con- sider the expected complexity of BFS. Lemma 2.4. On LI state-space optimal among all algorithms that use the same node costs, and are guaranteed an optimal goal node, up to tie-breaking among nodes whose costs are equal optimal goal co.st. tree with monotonic node costs, best-first search is to find to the Proof. See Appendix B. U Lemma 2.4 implies that BFS is optimal, up to tie-breaking, on a random tree as well, since it has monotonic node costs. that is guaranteed It has been shown in [ 32,331 algorithm d when bbo < 1, and the expected number of nodes expanded by BFS on T(b, d) quadratic algorithm that the expected number of nodes expanded by any in is in d when bpo > 1. Since BFS is an optimal in d when bpo = I, and linear for this problem, up to tie-breaking, to find an optimal goal node of 7’( b, d) then we have the following. is exponential ’ A sequence X,, of random variables is said to converge ulmost surely (with probability one) to X if P (lim,,,, X,, =X) = I 1441. W. Zhang. R.E. Korf/Artificial Intelligence 79 (1995) 241-292 255 Lemma 2.5. The expected number of nodes expanded by best-first search for$nding an optimal goal node of a random tree T( b,d) is (I) 6(pd) 2 when bpo < 1, where /3 is a constant, 1 < p < b, (2) 0(d2) when bpo = I, and (3) B(d) when bpo > I, as d + 00, where po is the probability of a zero-cost edge. BFS expands those nodes whose costs are less than or equal to the cost C’ of an the average number of nodes whose costs are less than optimal goal node. Intuitively, C* is exponential when bpo < 1, since C* grows linearly with depth when bpo < 1. The extreme case is when no two edges or nodes have the same cost, thus po = 0 and bpo = 0. On the other hand, when bpo > 1, there are a large number of nodes that have the same cost, and there are many optimal goal nodes as well. The extreme case is when all edges or nodes have cost zero, i.e. po = 1, and hence every leaf of the tree is an optimal goal node, and to find one and verify that it is optimal is easy. 2.3. Depth-Jirst branch-and-bound runs linear in space To reiterate, in the search depth. The other difference there are two major differences between DFBnB and BFS. One is that space in the search depth, whereas BFS usually DFBnB is that DFBnR may expand nodes exponential than the optimal goal cost, whereas BFS does not. The second whose costs are greater difference makes tool of branching processes used for BFS cannot be carried over to DFBnB directly. To circum- the complexity vent this difficulty, our approach of DFBnB and that of BFS. More specifically, we try to answer the question: how many more nodes does DFBnB generate the analysis of DFBnB more difficult, as the mathematical the relationship between is to determine than BFS? requires Theorem 2.6. Let NB (b, d) be the expected number of nodes expanded by best-jrst branch- search, and ND( 6, d) and-bound, on a random the expected number of nodes expanded by depth-jrst tree T(b, d). As d ---f co, d-l ND(b,d) < (b- l)xNs(b,i) +d. i=l Proof. See Appendix B. 0 Theorem 2.6 is one of the two most important analytic results of this paper. It shows the expected complexity of DFBnB and that of BFS. Most of between the relationship the following results on DFBnB are based on this theorem. 2 0(x(x)) denotes the set of all functions w(n) such for all x > x,1. In words, 8(x(x)) that there exist positive constants CI, c-2, and .ro functions of the same represents such that clx(x) asymptotic order as x(x). < w(x) < czx(x) 256 W Zhun,q. K.E. Korf/Arti$cicd Intelligence 79 (1995) 241-292 2.7. On a random l)), where Corollary Na (0, d) and ND( 0, d) are the expected numbers of nodes expanded by best-jirst search und depth-first branch-and-bound, < O(d. Ns(b,d respectivel?: tree T(b,d), N~(h,d) - Proof. See Appendix B. E Theorem 2.6, combined with Lemma 2.5. also leads to the following Theorem for ,$nding an optimal goal node of cl random tree T( b, d), as d + CQ, is 2.8. The expected number of nodes expanded by depth-$rst branch-and-bound ( I 1 O( p”) when bpo < 1, meaning that depth-first branch-and-bound is asymptoti- cally optimul, where p is the same constant as in Lemma 2.5, (2) O(d”) when bpo = 1, and (3) 0(d2) when bpo > I, where p() is the probability qfa zero-cost edge. Proof. See Appendix B. C to Lemma 2.5, showing Theorem 2.8 is analogous that p in Theorem 2.8 is the same p as in Lemma 2.5. This means the expected number of nodes ex- panded by DFBnB under different values of the expected number of same-cost children. Note that when bpo < I and d --t CC, DFBnB expands asymptotically the same number of nodes as BFS. Since BFS in this case. is optimal by Lemma 2.4. DFBnB is asymptotically optimal We are also interested same-cost children grows. in the behavior of DFBnB when the expected number of 2.9. On a random Corollary number of nodes expanded by depth-first branch-and-bound po + 1 for a given b, or when b + x for u given po > 0. tree T(l), d) with bpo > 1, as d + 3c, the expected approaches O(d) when Proof. See Appendix B. KY This corollary means that when bpo > I and bpo increases for a given po or a given b, it becomes easier to find an optimal goal node, and verify that it is optimal. 2.4. Iterative-deepening Iterative-deepening (ID) it those nodes whose costs are less than or equal to the current cost bound, and them in depth-first order. is a cost-bounded depth-first iteration, In each search. iterative-deepening, each node cost that is less than the cost of the optimal expands expands For the behavior of iterative-deepening iteration. Thus, goal node will generate a different critically depends on the distribution of edge costs. The following edge-cost distribution plays an important is a lattice distribution role. A distribution if it takes values from W Zhang, R.E. Korf/Arti&ial Intelligence 79 (199.5) 241-292 257 for nonnegative a finite set {sod, al A,. . . , a,A} constant A that is chosen so that the integers Q, a~, . . . , a, are relatively prime Any distribution distribution, A = r. integers aa, a~, . . . , a,,,, and positive [ 151. is a lattice such as on a finite set of integers or a finite set of rational numbers A may also be an irrational number, for example. Furthermore, tree T( b, d) with edge costs chosen from a continuous Theorem 2.10. On a random distribution, expands O( ( NB (b, d) > *) expected number of nodes, iterative-deepening where NB (b, d) is the expected number of nodes expanded by best-first search. On a ran- dom tree T( 6, d) with edge costs chosen from a lattice distribution, expands 0( Ns( b, d)) optimal. expected number of nodes as d ---f 00, which iterative-deepening is asymptotically Proof. See Appendix B. 0 that This there indicates overhead is a significant node-regeneration from a continuous when edge costs are chosen theorem iterative-deepening case, node costs are unique with probability node that has not been expanded an upper bound on the expected complexity of iterative-deepening chosen zero so that the probability implies of nodes when bpo < 1, bpo = 1, and bpo > 1, respectively, where p is defined Lemma 2.5. in In this one, and each iteration expands only one iteration. Theorem 2.10 also provides when edge costs are nonzero values, but an impulse at of a zero-cost edge is not zero. In this case, theorem 2.10 expected number in from a hybrid distribution with continuous expands O(/32d), 0(d4), that iterative-deepening in the previous distribution. and O(d*) On only lead to a constant multiplicative the other hand, when edge costs are chosen node is that many of edge costs have the same in the search depth when edge in the proof of Theorem 2.10, that the number of distinct node costs that are less than the optimal goal cost is regenerations nodes whose paths to the root have different combinations cost. The fact that the total number of iterations is linear as shown costs are chosen means also linear from a lattice distribution, from a lattice distribution, overhead. The reason in the search depth. Continuous and lattice distributions distribution. Consider discrete edge costs that are rationally are two extreme cases for edge costs. Unfortu- optimal when edge costs are chosen inde- if there exists no independent iterative-deepening is not asymptotically nately, from any non-lattice pendent. Two different numbers x and y are rationally rational number When tions, ci . 1 + c2 . TT for instance, will have a total cost that is different is no longer asymptotically combinations. r such that x. r = y. For example, 1 and 7~ are rationally independent, some edge costs are rationally In this case, iterative-deepening any different independent. combina- from all other edge-cost optimal. 2.5. Recursive best-jirst search With a monotonic cost function, nodes than iterative-deepening, up to tie-breaking recursive best-first search fewer [24]. Thus, for a state space with generates (RBFS) 758 Table I Expected complexity of BFS and DFBnB Algorithm BFS DFBnB Table 2 hp,, c I H( pd) optimal H(d2) optimal H(d) optimal /i( p”) asym. optimal O(tP) O(t12) Expected complexity of’ ID and RBFS hp,, c’ I Lattice edge costs H(p”) asym. optimal H(rP) asym. optimal H(d) asym. optimal Non-lattice edge costs o(p?d, O(d4) O(G) monotonic the complexity iterative-deepening RBFS. Thus, RBFS lattice distribution. node costs, the complexity of recursive best-lirst on a random is also asymptotically of iterative-deepening search. Consequently, is an upper bound on the expected complexity of tree is an upper bound on the expected complexity of from a optimal when edge costs are chosen 2.6. Summary of tree search complexit) Tables I and 2 summarize the results of this section, expanded by best-first search (BFS), depth-first branch-and-bound deepening asymptotically and recursive best-first as d ----i X. (RBFS) search (ID), i.e. the average number of nodes iterative- (DFBnB), tree T( b, d), on a random 2.7. Bratiching factors Before we close this section, we discuss one is the average brute-force branching of children of a node in the tree. b captures from one depth to the next. three different branching factors. The first factor b of a tree, which is the average number the rate of growth of the number of nodes The second is the asymptotic heuristic branching factor, or heuristic branching factor B, of a tree [Sl]. B is the ratio of the average number of nodes with a given cost X, to the average number of nodes with the largest cost less than X, in the limit as x + c. iterations. to capture over BFS. Iterative-deepening The heuristic branching factor B was introduced is asymptotically increases the average number of node expansions deepening cause sive In this case, panded by iterative-deepening (B/C B ~ I ) )* as d + x arc unique, which leads constant as d - K, so that B does not exist because large node costs. When edge costs are chosen the average value of B is greater than one, because the overhead of iterative- optimal when B > 1, be- exponentially with succes- the overhead of the total average number of nodes ex- constant over those expanded by BFS is a multiplicative variables, node costs a it is defined only in the limit of and bpo < 1, to B = I. When bpo > I, the optimal goal cost remains from a lattice distribution iterative-deepening [ 221. When edge costs are continuous is asymptotically W Zhang, R.E. Korf/Artijicial Intelligence 79 (199.5) 241-292 optimal this case. (Theorem 2.10). As we will see in Theorem 2.11, B approaches a constant 259 in Theorem 2.11. Let B be the asymptotic heuristic branching T( b, d) with b > 1. B = 1 when edge costs are chosen from a continuous distribution. When bpo < 1, and edge costs are chosen from a lattice distribution al A, a2A,. chosen such that the nonnegative approaches a constant as d -+ 00, which is a solution greater on (a0 = 0, . . , a,,,A} with probabilities PO, p1 ,p2, . . . , p,,,, respectively, where A > 0 is integers al < a2 < ’ . . < a,,, are relatively prime, B than one to the equation factor of a random tree Proof. See Appendix B. q is the asymptotic The third branching factor factor ,& of a search algorithm branching of the average number of nodes expanded, as d -+ 03. In other words, p measures relative level. j? in Lemma 2.5 and Theorem 2.8, for example, of BFS and DFBnB. factor, or effective [40]. p of a search to depth d is the dth root the the search depth by one extra factor in average complexity due to extending is the effective branching effective branching increase It is evident factor p of a search algorithm on a state- factor b of the tree. However, factor B of a tree can be either greater or less than b, and can that the effective branching space tree cannot be greater than the brute-force branching the heuristic branching be either greater or less among p, B, and the optimal goal cost C* when edge costs are chosen distribution. j? of an algorithm. We have the following relationship from a lattice than tree T(b, d) with b > 1, when bpo < 1 and edge costs Theorem 2.12. On a random are chosen from a lattice distribution, iterative-deepening, factor p = B” as d -+ 00, where po is the probability that an edge has cost zero, B is the asymptotic heuristic branching factor of T( b, d), LY is the limit of C*/d as d ---f m, and C* is the optimal goal cost. and recursive best-first search all have the same efSective branching best-first search, depth-first branch-and-bound, Proof. See Appendix B. q 3. Complexity transition of tree search 3. I. Average-case complexity transition The results of Section 2 show that the average-case complexity of a tree search algo- rithm on random This phenomenon trees experiences a dramatic transition, from exponential to polynomial. is similar to a phase transition, which is a dramatic change to some 260 W Zkrn~, K.E. Kor_f/Artijbcd Intelligence 79 (I 995) 241-292 , I I baa 1 polynomial region transition boundary g 1.0 5 3 Oi3 6 g 0.6 - + 0 g 3 -E L II a” 0.4 - - 0.2 o.oo 5 10 mean branching factor b 15 20 Fig. IL. llit’licult and easy regms for tree search problem property as some order parameter changes across a critical point. The simplest from a solid phase to a liquid phase example of a phase transition when the temperature is lhat water changes rises from below the freezing point the complexity that determines The order parameter is the that an edge takes cost zero factor is b. then bpo is the expected number of same-cost algorithms expand an number of nodes on average. On the other hand, when bpo 3 1, BFS and their average- as the expected number of from less than one to greater than or equal to one. Fig. 12 expected number of same-cost children. If the probability is ~‘0 and the mean branching children of a node. When bpo < I, both BFS and the linear-space exponential the linear-space case complexity same-cost children illustrates regions and the transition boundary between average to polynomial algorithms changes these two complexity from exponential time. Therefore, in polynomial increases them. run to above that point. transition of tree search The condition of bpo > I, Dpo = I or b,~o < 1 can be estimated by random sampling of the nodes the edge costs are independent results provide a means nately, the independence the independence Scction 4. in a state space, counting the average numbers of same-cost children. of each other, this random sampling to estimate of edge costs often does not hold the performance If and our analytic of a search algorithm. Unfortu- in practice. Nevertheless, assumption may be a reasonable one for some cases, as discussed in 3.2. Finding all optimal goal rwdrs exists transition however, is difficult The complexity all solutions, different Consequently, the goal depth. Therefore, number of optimal goal nodes expected number of nodes However. is desired. To find if only one optimal goal node in both regions of bpo 2 1 and bpo < 1, but for reasons. When bpo > I, a node has at least one same-cost child on average. increases exponentially with the expected is exponential. On the other hand, when bpo < 1, the is small. the optimal goal that have the minimum the expected number of nodes whose costs are less than to find all optimal goal nodes is difficult because the expected number of optimal goal nodes cost at a particular depth cc! Zhang, R.E. Kmf/Art$cial Intelligence 79 (1995) 241-292 261 1 I , I- q 10 It+=6 by5’ edge costs from (0.1.2, with po= l/5 . ( 2’6-1) L 6( b’ 0 I 20 I search %?pth I I 60 fi 20 search depth I 40 (a) # of optimal goals (b) # of nodes generated by DFBnB Fig. 13. Finding all solutions is always difficult. cost increases exponentially with the tree depth. Hence, is difficult because number of nodes with lower costs. to find all optimal goal nodes there exist only a few optimal goal nodes among an exponential the remaining Fig. 13 shows an example of finding all optimal goal nodes on random factor b and pc = l/5 using DFBnB. To emphasize nonzero edge costs uniformly trees with the impact of uniform branching . . , 216 - 1). ~0, we choose The results of Fig. 13 are averaged over 1000 trials. Fig. 13(a) shows that the average increases exponentially when bpo > 1. Fig. 13(b) gives number of optimal goal nodes the corresponding that it is exponential average number of nodes generated by DFBnB, for all values of bpo. from { 1,2,. indicating 3.3. Meaning of po ties PO,PI,P~~...,P,~,~ transition results indicate The previous number of edges whose costs are zero. What for example, that the complexity to the if there are no zero-cost edges? Assume, the edges have costs {S,6 + 1,6 + 2,. . . ,6 + m} with probabili- respectively, where 6 is a positive number. Does a complexity is closely transition related that exist in this case? Consider an example of a random from { 1,2,3,4,5}. chosen uniformly of Section 1 by shifting performance Fig. 14 is our experimental that there is no complexity of any algorithm, the edge costs by one. At first glance, This is only different tree with uniform branching factor b and edge costs in Fig. 5 this should not affect the the same value is added to every edge in the tree. results of DFBnB, averaged over 1000 runs. Fig. 14 shows transition when edge costs cannot from the example since take value zero! When edge costs in a tree change, node costs change accordingly. However, the costs of nodes located at different depths are not adjusted by the same amount, even if the the cost of a node is the sum of edge costs same value is added to every edge, because on the path from the root to the node. Thus, a larger value is added to a node at a deeper depth than a node at a shallower depth, and the costs of the nodes at depth d, where the 262 W Zlung. K.E. Ko).//Arfiji~~ul Irzrell~<~enr~e 79 (I 995) 241-292 -3 IO6 F 22 e IO’ 2 B 104 M a s IO3 2 i 102- 2 10 - 0 5 edge costs uniformly chosen from (1,2,3,4,5) I I , 10 20 15 search depth d I 25 I 30 Fig. 14. There is no search anomaly without zero-cost edges amount. goal node is located. In consequence, more increase by the maximum optimal nodes will have new costs that are less than the new optimal goal cost, so that searching for an optimal goal node becomes harder. Furthermore, when there is no zero-cost edge, node costs strictly the cost of a node at depth d is at least 6d, which is a lower bound on the optimal goal cost. that have costs less than or equal to 6d on a tree with a larger There are more nodes factor. This is why there is no factor than on a tree with a smaller branching branching search anomaly when edge costs are nonzero, as shown in Fig. 14. increase with depth. If the minimum edge cost is 6, then is the cost of node 11. d is the goal depth, and II is the current upper bound. edge cost to increase search efficiency, a node n at depth j. The is generating 6 > II, We can use the information of the minimum however. Consider the scenario when DFBnB node II and the whole subtree below it do not need to be explored where ,f(n) This is because In summary, the cost of a leaf node below II is at least .f( n) + (d - j) 6. the intrinsic meaning of po is the probability cost, and this cost is known a priori. In other words, a known minimum zero edge cost are equivalent. Given an edge-cost distribution with a known minimum value, we can convert minimum that edges take the minimum edge cost and into one with zero edge costs by subtracting cost from every edge. this distribution if f(n) + (cl-j) the The obstacle we have to overcome edges in the state-space is generally unknown, This learned minimum by a search algorithm is to obtain in practice tree of a real-world problem. Although it can be learned or estimated by sampling edge cost can then be subtracted its efficiency. to improve the minimum this minimum cost of all edge cost tree. the state-space from every edge encountered po can also be considered as a rough measure of the accuracy of a cost function. The accuracy of a cost function on a given problem can be measured by the difference the optimal goal cost and the cost of the initial node in a state space. If this between is zero, then the cost function difference tree, this is represented by the optimal goal cost, as the root has cost zero. In a random difference tree, a larger po gives rise to more same-cost children, and thus reduces the optimal goal the larger po is, the closer the estimated cost cost, according is exact on the root node. In a random to Lemma 2.2. Therefore, W Bang, R.E. Kqf/Art$cial Intelligence 79 (1995) 241-292 263 the cost function will be. However, of a node is to its actual cost, and the more accurate the edge costs in the state space of a real problem are generally dependent upon each other. It is not clear how the dependence of edge costs will impact our results. 4. Applications in Section 2 explain the search anomaly presented pe of a zero-cost edge is a constant the edge costs in the trees are uniformly Our analyses Section 1.4. Since the probability less than 5 (bpo < 1)) the average-case in search depth d; it is at most 0(d4) when b = 5 (bpo = 1); and it is quadratic when b > 5 (bpo > 1) . Thus, when the branching complexity l/5. When complexity of a search algorithm factor b increases, the branching decreases. chosen from (0, 1,2,3,4}, factor b is is exponential in Figs. 10 and 11 in the average-case in d This section presents applications of our analytic results to our benchmark problems, sliding-tile puzzles and the Asymmetric Traveling Salesman Problem. 4.1. Anomaly of DFBnB on sliding-tile puzzles Given an initial and a goal state of a sliding-tile that map the initial state into the goal state. In a real-time to find a setting, sequence of moves we may have to make a move with limited computation. One approach to this problem, called fixed-depth lookahead search [ 231, is to search from the current state to a fixed depth, then move to the child of the current state that contains frontier node in its subtree, and take that child as the next current state. puzzle, we are asked the minimum-cost from the initial Fig. 15 shows experimental state to node n, and h(n) results of lookahead searches on sliding-tile puzzles using is the total number DFBnB. The cost function used is f(n) = g(n) + h(n), where g(n) distance of moves made the total numbers from n to the goal state. The straight dotted lines to the left represent puzzles. of nodes in the search tree, for the Eight, Fifteen, Twenty-four, the total numbers of nodes expanded by The curved solid [ 231. For a DFBnB. The results reported given search depth, DFBnB can search the trees of larger puzzles faster. Alternatively, for a given amount of computation, DFBnB can search deeper in the trees of larger puzzles. For example, at one million node expansions, DFBnB can reach depth 35 on the Eight Puzzle, depth 42 on the Fifteen Puzzle, depth 49 on Twenty-four Puzzle, and depth 79 on the Ninety-nine to the right represent the following if we fix the total computation anomaly, originally is the Manhattan and Ninety-nine respectively. Puzzle, show lines in An explanation for this anomaly Manhattan distance h by one, or decreases value by one, the cost function each move. Thus, edge costs zero or two, if dependence that the h value either initially, independent the same cost as its parent of the problem is the following. Moving a tile either increases its the g f = g+ h either increases by two or stays the same with tree with it by one. Since every move increases this problem can be approximately modeled by a random among edge costs increases or decreases by moving size. Thus, the probability is approximately one half, is ignored. The probability a tile is roughly one half that a child node has the i.e. p,-, x 0.5. In addition, 1 _+I i -L-L 60 I 20 lib lookahead depth d 80 Rg. 15. Anomaly of lookahead hearch on sliding-tile puzzles average blanching arc approximately pu/.zlc siLc. Thus, h~a increases with the puzzle size as well, and lookahead easier on larger puzzles factors 0 of the Eight, Fifteen, Twenty-four, 1.732. 2.130, 2.368, and 2.790, respectively, in Section 2. the analyses and Ninety-nine following i.e. b grows with puzzles the is search This explanation. however, does not imply that solving a larger puzzle length for a larger puzzle the larger puzzle more difficult a unique board configuration is easier than than is longer solving a smaller one. First of all, the solution for to solve. Secondly, that of a smaller one, making a particular problem is specified instance, as the goal stale. Although multiple nodes with the same board configuration may be the search, the number of copies of the goal state is relatively small encountered compared the edge costs is not valid. A most important the sequence of moves that decrease initial states of distance more likely. Specifically, the Eight Puzzle, po is 0.501 initially, and steadily decreases with search depth, making the problem more difficult as the search depth increases. to the number of nodes with minimal cost at a fixed search depth. Finally, the Manhattan distance makes a move that increases from our experiments on 1000 random is that the assumption of independent of the puzzle reason during 4.2. Complexity trunsitiotr on the Asymmetric TSP between (Section from R = (0, 1,2. 1.1.2), with intercity the number of distinct Consider the node costs in the state-space assigmnent problems . r}. for some positive costs of the corresponding chosen uniformly the relationship state-space K have the same total sum is smaller of II edges total cost decreases as r increases. When Y is small compared the probability tree is equal tree of the ATSP, which are solution costs integer r. Let us examine in the that two sets of tz values from that two sets the same have to the number of cities, in the search the tree which have cost zero. The probability problem cost of a child subproblem intercity costs r, and the edges problem cost of its parent is large. In other words, if r is larger. Thus, to two subproblems that the assignment in the assignment to the assignment the probability solutions problem N! ifhang, R.E. Korf/Art@cial Intelligence 79 (1995) 241-292 265 uniform intercity cost distribution 6 4 2 0 1 10 102 lo6 number of distinct edge costs r lo3 lo4 16 10’ 1 lo2 10 number of clistiqcct edge costs r lo3 lo6 lo4 lo5 IO’ (a) average #of same-cost children (b) average # of node generations Fig. 16. Complexity transition on loo-city Asymmetric TSP, uniform distribution. larger, as is the probability po of zero-cost edges in the search tree is larger when Y is smaller, so that than one, if b does not children bpo may be greater the problem may be easy to solve that the assignment problem cost of a child probability the average number of same-cost significantly decrease when when Y is small. Conversely, is equal to that of its parent po of zero-cost edges in the search tree. Consequently, solve when r is large. The above argument r increases. Therefore, the probability is smaller when r is relatively the complexity tested this prediction by experiments on the ATSP as r changes, shown ATSPs. In our experiment, we randomly generated 1000 problem assignment DFBnB, between tree of the ATSP and the average number of nodes generated by DFBnB. Fig. 16 shows intercity costs, on a axes are the number the results, where the horizontal scale. logarithmic problem and averaged the average number of same-cost of BnB search on loo-city instances whose initial the problems using the relationship from these instances. We examined that there may exist a complexity solutions are not single complete the problem may be difficult to in Fig. 12. We experimentally transition of random-tree children bpo of a node in the search tours, solved r of distinct the results following transition suggests Fig. 16(a) shows that bpo > 1 when that the problem by point A. Following indicated Fig. 12, this means difficult when r > 130. Fig. 16(b) by DFBnB under different values transition. When r 6 20 the problem has also been complexity ATSPs. transition the complexity is easy transition to solve when r < 130, and bpo < 1 when of random-tree r > 130, in search r < 130, but becomes the average numbers of nodes expanded costs, showing a complexity is easy and it is difficult when r > 1000. A similar random found on 200-, 300-, 400- and 500-city illustrates r of distinct intercity However, the transition from easy problem instances as we expected. This is most likely due to the following to difficult ones is not as dramatic factors. First, bpo decreases 266 !N Zhun,y. R.E. Korj/Artijiciul Intelligence 79 (1995) 241-292 gradually when Secondly, of random and more importantly, nor are the branching random trees are violated. r increases the search trees have relatively tree search are asymptotic the complexity for Y < 1000, making slowly. transitions infinity. Finally results as tree depth approaches edge costs in the search tree are not independent from each other, factors of different nodes, so that the i.i.d. assumptions made for small depths, while the complexity increase As suggested by Section 2, if we take the particular value of r such that bps = 1 as determine then this transition point the transition point, point A in Fig. 16 for instance, with the problem size, or the number of cities. It remains an open problem, however, analytically random ATSP. In short, increases to the value of the cost range r at which the transition occurs for a is primarily determined by the of the ATSP space of the ATSP. Our results in the problem that difficult ATSP instances can be easily generated by using a large number to test the average-case average number of same-cost children showed of distinct a search algorithm. intercity costs, which is useful when we need difficult ATSP instances complexity 5. Algorithm selection The complexity measure of search algorithms used in Section 2 is the total number of time are two more practical to find an optimal solution of the space for algorithm nodes expanded or generated. However, space and running and important measures a given problem. We continue our investigation and running selection. for choosing a search algorithm time complexity. The purpose is to provide some guidelines below by taking into account First consider space complexity. in the search depth. Given In order to select one node of minimum cost among that have been generated but not yet expanded, which we call active nodes, is usually speed on in a matter of minutes, in one millisecond all nodes BFS has to maintain all the active nodes in memory, so that its space required exponential to processing current computers, BFS typically exhausts halting the algorithm. For example, on a computer with ten megabyte memory, twenty minutes. Therefore, BFS is not applicable algorithms use space that is only linear size, they are the only algorithms of choice for large problems to large problems. Since linear-space in problem in the search depth, which is linear if a new active node is generated then BFS will fill the memory the available memory the ratio of memory in less than Assuming that memory is not a constraint, given it is still not clear which algorithm, BFS, DFRnB, should use for a given problem. Although BFS expands algorithms, results which ditions. The remaining algorithms on random Problem. in Section 2, or RBFS, we the other than in practice‘? It is also not clear from the analytic con- runs time of these trees, sliding-tile puzzles and the Asymmetric Traveling Salesman the others under different running compares the analytic iterative-deepening does it really linear-space of this section experimentally run faster algorithm fewer nodes faster than in practice. results W! Zhang, R.E. Korf/Art@ial Intelligence 79 (1995) 241-292 267 5. I. Comparison on the analytic model We first compare the average number of nodes expanded by BFS, DFBnB, iterative- time of these algorithms on random deepening, trees. and RBFS, and then consider the running 5.1. I. Node expansions We use random trees with uniform branching factors, and two different edge-cost In the first case, edge costs are uniformly distributed among (0, 1,2,3,4}. po = l/5, and nonzero edge costs are uniformly of discrete edge costs. In the second case, edge costs chosen this hybrid edge-cost distribution the impact of po on the complexity of the this as a representative . . , 216 - 1). The purpose of choosing distributions. We choose are set to zero with probability from {1,2,3,. is twofold. We set po = l/5 search algorithms. We take nonzero costs from a large range distribution. Note shallow distribution. We choose complexity polynomial case (bpo < 1 ), b = 5 for the transition case (bpo > 1) . complexity only approximates large, this distribution trees. When d is relatively three different branching that this simulation to study to simulate a continuous a continuous for should be treated as a discrete factors: b = 2 for an exponential distribution case (bpo = 1 ), and b = 10 for a The algorithms are run to different depths, each with 1000 trials. The average in Fig. 17. These results are consistent with the analytic is superior re- results: BFS to iterative- optimal when bpo < 1 (Figs. 17(a) and 17(d)), is asymptotically and RBFS the fewest nodes among all algorithms, and RBFS are asymptotically optimal when edge costs are dis- and 17(c)). However, when bpo < 1 and edge costs are (Fig. 17(d) ) , the slope of the iterative-deepening is result expands O( N*) nodes on average when edge costs are chosen distribution, where N is the expected number of nodes expanded by is consistent with the analytic curve the slope of the BFS curve. This (Figs. 17(a), sults are shown expands deepening. DFBnB and iterative-deepening 17(b) crete from a large range chosen nearly twice that iterative-deepening from a continuous BFS. Fig. 17 also provides additional information not provided by the analytic results. When and RBFS are asymptotically and 17(f) ), iterative-deepening (Figs. 17(b) In these cases, regardless of the number of distinct nonzero edge costs. Moreover, when bpo 3 than both the number of than the and RBFS. When bpo < 1 and edge costs and from a bpo > 1 (Figs. 17(c) optimal, 1 and edge costs are discrete iterative-deepening and RBFS. nodes expanded whose costs are greater re-expansion are discrete RBFS. Fig. 17(d) also shows large set of values, RBFS has the same unfavorable deepening. overheads of iterative-deepening (Fig. 17(a) ), however, DFBnB outperforms the overhead of DFBnB, than the optimal goal cost, is larger that when bpo < 1 and edge costs are chosen asymptotic complexity as iterative- both iterative-deepening and 17(c)), DFBnB is worse In summary, for large problems that can be formulated depth, and require exponential for easy problems ed. computation (bpo > 1) or those with unbounded (bpo < l), DFBnB as a tree with a bounded should be used, and depth, RBFS should be adopt- 268 W Z/:/lung, K.E. Korf/Art&xr/ hrelhpwce 79 (1995) 241-292 edge-costs=(0,1,2,3,4), uniformly, PO =t/5 edge-costs=(O,lZ, ,.. ,216-1); pO =1/S ’ 0 10 20 30 search dcprh (a) b=2, bp, 4 _..~~ .I~~~ _~ r~ 40 50 0 10 40 20 30 search depth (d) b=2, bpO<l 50 60 7- -r----r --7‘ L.-m-~_ 0 50 L_ m_,_mmm MU 200 150 100 search depth L-L. 0 50 100 search depth 150 200 (e) b=S, bp, =l search depth (c) b=lO, bpo >l .l-oi---“- 50 - search depth 150 200 (f) b=lO, bp, >l Fig. 17. Average number of nodes expanded on random trees. We now consider how BFS compares the main performance measure, assuming is optimal faster than the linear-space in terms of the number of node expansions, algorithms. to linear-space algorithms when running time is that space is not a constraint. Although BFS that it runs that does not mean W. Z./tang, R.E. Korj’/Artl@cial Intelligence 79 (1995) 241-292 269 branching factor = 2 edge costs chosen from (OA2, . . . ,216-l) 20 30 40 search depth 50 (a) running time 60 20 30 40 search depth (b) time per node expansion 50 60 Fig. 18. Running time and time per node expansion on a binary tree. To expand nodes in best-first order, BFS has to maintain a priority queue to store all the nodes that are generated but not yet expanded. The time to access the priority queue, selecting a node from the queue and inserting new nodes into the queue, depends on the total number of nodes stored, and increases as more nodes are added. If a heap is used, in the which is an optimal total number of nodes in the heap. For a difficult problem exponential becomes to expand a node for difficult problems. All linear-space can be implemented time. takes constant for some constant p > 1, the heap access time in the search depth that BFS takes time linear algorithms, on the other hand, is executed on the top of the stack, and in the search depth, O(pd) = O(d). This means of a priority queue, access time is logarithmic that requires node generations on a stack; each operation implementation log(pd) Fig. 18 (a) shows one example on a binary random tree where the running time of BFS faster than that of DFBnB. The zero edge costs were chosen with probability increases po = l/5, and nonzero edge costs were uniformly Fig. 18(b) and DFBnB in this case, which confirms our analysis. the corresponding illustrates average chosen from { 1,2,3,. time per node expansion . . , 216 - 1). for both BFS Overall, whether or not BFS runs faster than a linear-space problem complexity the time for expanding and its size, which determine a node and generating all its children. algorithm depends on the the number of nodes generated, and 5.2. Comparison on actual problems 5.2.1. Lookahead search on sliding-tile pu&es Consider lookahead fixed-depth from the current state to a fixed depth, and returns a node at the given depth whose cost is a minimum and RBFS on lookahead g(n) + h(n), where g(n) among all nodes at that depth. We compared DFBnB, search. In our experiments, the cost function used is f(n) from is the total number of moves made puzzle, which searches search on a sliding-tile iterative-deepening = state the initial 270 W. Zhang, RX. Korf/Artijicial Intelligence 79 (199s) 241-292 I 0 20 40 search depth 60 80 Fig. 19. Lookahead search on sliding-tile puzzles. distance expands slightly more nodes is the Manhattan show that iterative-deepening from node n to the goal state. Our than RBFS for to node n, and h(n) experiments lookahead search, as expected. Fig. 19 compares DFBnB and RBFS. The horizontal axis is the lookahead depth, and the vertical axis is the number of nodes expanded. The labeled by 8, 15, 24 and 99 results were averaged over 200 initial states. The curves are the results on Eight, Fifteen, Twenty-four respectively. The results show that DFBnB performs than RBFS on small puzzles, while RBFS and Ninety-nine slightly better is superior puzzles, puzzles In addition, Unfortunately, a shortest complete solution path in such a graph cycles. advance. Thus, DFBnB cannot be applied the nodes on a cycle, and does not terminate. Furthermore, insignificantly on running algorithm of choice for finding an optimal solution path to the problem. fewer nodes than iterative-deepening, is not a tree, but a graph with in it may keep to expand although RBFS generates RBFS has slightly higher overhead is still the time than iterative-deepening. in that setting, since iterative-deepening Consequently, is unknown to DFBnB on large ones. the state space of sliding-tile 5.2.2. The Asymmetric TSP intercity and RBFS on the ATSP with from (0, 1,2,3, We ran DFBnB, iterative-deepening axes are the number of distinct costs . , r}, where r is an integer. Figs. 20(a) and 20(b) and 300-city ATSPs, averaged over 500 trials each. The intercity costs r, and the vertical axes are the number of distinct costs r is small or large, the cannot compete with RBFS and DFBnB, than DFBnB on easy that the overhead of RBFS is larger than that of DFBnB. RBFS does to DFBnB on difficult ATSPs as well, since in this case the node costs uniformly chosen show our results on loo-city horizontal the numbers of nodes generated. When relative discussion especially ATSPs, indicating poorly relative in the search tree are unique, which causes significant node regeneration overhead. in Section 4.2. Iterative-deepening for difficult ATSPs when r is large. RBFS to the number of cities n, the ATSP is easy or difficult, respectively, following is worse W Bang, R.E. Korf/Artificial Intelligence 79 (I 995) 241-292 271 I I / I I I , I intercity costs unifoImly chosen from 10.1.2, . . . I rl number of distinct intercity costs r (a) loo-city ATSP 0 ld Id 10 number of distinct intercity costs r lo” 10’ 10’ ld (b) JOO-city ATSP Fig. 20. Performance of Iinear-space algorithms on the ATSI? 5.3. Summary Even though linear-space that are not generated by BFS, or re-generating ing nodes linear-space problem tion, algorithms linear-space methods are often the algorithms of choice. search algorithms expand more nodes than BFS, by explor- the the In addi- is relatively less space than BFS. For large problems, algorithms may run faster than BFS. This is typically times, the case when small. is large, and the time for node expansion space the linear-space a node multiple take much Among the linear-space algorithms, DFBnB is inapplicable spaces are graphs with cycles, since no cutoff bounds are known is preferable exponential by bounded-depth computation. RBFS should be applied to problems on problems whose search spaces are bounded-depth that can be solved in polynomial trees, or problems to problems whose state in advance. DFBnB trees and require that cannot be represented time. 6. Related work 6.1. Analytic models Most existing models tree models three different factor, with one or more solutions satisfaction problems can also be formulated by this model for analyzing search algorithms are trees. There are at least in the literature. The first model assumes a uniform branching that lie exactly at depth d [ 13,27,49]. Constraint- [42]. The second model is a uniform [ 6,12,18,39,41]. node cost function the first one. Node costs are assumed random variables. The most important complexity exponential of the A* algorithm in most cases [ 18,391. This cost function distinguishes tree with a unique goal node at a given depth, and a from distributed is that the expected is [ 161, a best-first search with f(n) = g(n) + h(n), result on this model to be independent this model identically analytic and 272 W Zhuq. R.E. Korf/Artlficiul htelli~ence 79 (1995) 241-292 The third model is a random tree with independent edge costs, the cost of a node as the sum of the edge costs on its path to the root, and an optimal goal node being a minimum- cost leaf node at a fixed depth [ 20,32,33,53,57,58], or at variant depths [48]. The idea of assigning costs to edges can be traced back to the work of Fuller et al. [ lo] on game- tree search. Two variations of this model are used in the literature, one with a uniform [ 32,33,48, branching factor 581, This model the Traveling Salesman Problem We adopt this model with random branching an incremental and the other with a random branching optimization suitable function factor problems, is to be minimized. for combinatorial [ 291, in which an objective factor but fixed goal depth, which we call [ 20,53,57], is typically random tree. such as 6.2. Analyses of brunch-and-bound BFS and DFBnB can be considered as special cases of branch-and-bound for problem [ 19, solving. Kumar et al. [ 261 showed that many as BnB. can be formulated intelligence (BnB) in artificial 25,301, a general graph-search For example, Smith technique algorithms developed the A* algorithm an average-case [48] performed used is a random equations were obtained, however, and thus no direct conclusion complexity of BnB. analysis of BnB. The model he tree with leaf nodes at different depths as goal nodes, and he derived to these equations is drawn on the average-case complexity. No closed-form for the average-case complexity solutions [ 161 is a BFS algorithm. analysis was conducted by Wah and Yu [53], using a random factor. The process of BFS is modeled as the behavior of two toward each other, with one wall as the minimum cost of the currently the other as the current upper bound. A stochastic process is Another average-case tree with uniform branching walls moving generated nodes, and employed Empirical the edge costs have the gamma distribution compared DFBnB with BFS, arguing the lower-bound to derive approximate results verified formulas that the average-case for the average number of nodes expanded. complexity of BFS is exponential when and the binomial distribution. They also to the latter when is comparable that the former cost function used is very accurate or very inaccurate. Karp and Pearl [ 201 delineated polynomial and exponential average-case complexities tools used are branching processes tree with edge costs of 1 or 0 with probabilities p or I - p. of BFS on a random binary [ 151. They elegantly showed The basic mathematical to remain bounded when p < 0.5, that the cost of an optimal goal is almost certain to d when very likely p > 0.5. They further proved is linear when p < 0.5, quadratic when p = 0.5, and exponential when p > 0.5. These results were also suggested earlier by Hammersley to be near loglogd when p = 0.5, and almost surely proportional that the average number of nodes expanded by BFS [ 141. [ 32,331 McDiarmid significantly and Provan to factors. They trees with arbitrary edge-cost distributions, in depth d when bpo < 1, the goal cost almost surely grows that loglogd when bpo = 1, and remains bounded when bpo > 1. They showed average time when bpo < 1, runs in in linear average time when bpo > 1. random proved approaches that BFS finds an optimal goal node in exponential time when bpo = I, and finishes quadratic average extended Karp and Pearl’s work and random branching linearly W Zhang, R.E. KorflArtifcial Intelligence 79 (1995) 241-292 273 The results of Karp and Pearl, and of McDiarmid form the basis of this In fact, the properties of the optimal goal cost (Lemma 2.2) and the average- and Provan’s of BFS (Lemma 2.5) of this paper are from McDiarmid and Provan, research. case complexities results. 6.3. Analyses of iterative-deepening that first showed the worst-case Patrick et al. using [38] the A* cost function is iterative- in = g(n) + h(n), occurs when all nodes (N* + N) /2 nodes, where N is the number the worst-case of IDA* on trees and graphs. Vempaty et al. [ 511 compared DFBnB with is high, whereas is preferable when the solution density f(n) deepening the search tree have unique costs, expanding of nodes performance IDA*. They argued that DFBnB IDA* should be used when the heuristic branching that are surely expanded by A*. Mahanti et al. [ 3 1 ] discussed of IDA*, which factor is high. the average-case Patrick [37] also considered tree with uniform branching expected number of nodes with a particular the dependence among nodes Chapter 6, page 631. In other words, the dependent model was treated as an independent one. complexity of IDA* using a random the cost k, Patrick did not take into account [ 37, that share common edges on their paths to the root factor and integer edge costs. However, in computing 6.4. Algorithms using limited space BFS and the linear-space algorithms is on the exponential-space BFS between on a machine, but no more. these two extreme cases are algorithms A general method to make use of more end, and the others are on the linear-space stand on opposite ends of the space spectrum. end. In that use as much space as is available algorithm. Pearl presented requirement [ 31 are combinations run slower than iterative-deepening overhead, while generating a linear-space meet a limited memory algorithm algorithms maintenance algorithm iterative expansion not monotonic. that is close to RBFS of BFS and iterative-deepening. than combinations linear space three possible BFS-DFBnB [ 391. Both the MREC algorithm is to combine BFS and to [ 471 and the MA* these two on the Fifteen Puzzle because of memory [ 241. One [ 451. Unlike RBFS, however, in best-first order when node costs are Unfortunately, fewer nodes than iterative-deepening is iterative expansion does not expand new nodes Several algorithms of iterative-deepening, all try to reduce thresholds In order to guarantee revert to DFBnB have been developed to reduce including DFS* [51], IDA*-CR the node regeneration [46] and MIDA* the number of iterations in iterative-deepening to values larger than the minimum value that exceeded finding an optimal goal node, once a goal is found, to complete the final iteration. overhead [ 521. They by setting successive threshold. the previous the algorithms On problems whose state spaces are not trees, the most serious problem with al- gorithms that use less than exponential space is how to detect or prevent generating 274 W Zhung, R.E. Korf/Artificiul Intelligence 79 (1995) 241-292 duplicate nodes. Taylor and Korf [ 501 proposed one scheme of duplicate node pruning limited memory. The idea is to first learn some of the structure of the state space using of a given problem using a small exploratory that structure in a finite automata, which is used during search to avoid duplicate node expansions. search, and then to encode the problem-solving 6.5. Complexity transitions The earliest evidence of complexity of BFS [ 201. Huberman systems. Cheeseman complexity in some intelligent transitions satisfaction problems, graph coloring, and Symmetric Traveling Salesman Problem. The complexity the attention of many researchers transitions was Karp and Pearl’s average-case transitions that complexity circuit, constraint- exist in many NP-hard problems, [ 171 discussed complexity problems have attracted in constraint-satisfaction including Hamiltonian et al. [4] empirically [ 5,28,34,54]. and Hogg transitions showed Most recently, Zhang and Pemberton [56,59,60] proposed a method of exploiting transitions to find approximate problems. Their method allows BFS or DFBnB solutions quickly, or to obtain better solutions op- to combinatorial complexity to find either high quality timization than truncated DF- sooner approximate BnB is effective on a problem whose state space has a large number of distinct edge costs. On the Asymmetric Traveling Salesman Problem, DPBnB using this method runs faster and finds better solutions than a local search method. and optimal solutions [ 551. This method 7. Conclusions We studied search algorithms (DFBnB), depth-first branch-and-bound first search (RBFS). Due to their linear-space more nodes in the search depth. Using a random than best-first search (BFS) that use space linear in the search depth, including (ID) and recursive best- all these algorithms expand , which typically uses space that is exponential iterative-deepening requirement, proved in exponential is asymptotically optimal on a random that iterative-deepening time. We also proved tree model, we analytically that DPBnB expands at most 0( d. N) nodes on average, where d is the goal depth and N is the expected number of optimal when nodes expanded by BFS. We further showed that DFBnB and RBFS are BFS runs the average asymptotically in the tree number of nodes expanded by these linear-space is less than one, and is at most depth when O(d4) when to one. Our analytic in the transition of search performance the algorithms on the Asymmetric Traveling Salesman Problem. heuristic branching factor of BFS, factor of a random DFBnB, tree with integer edge costs. Overall, is exponential algorithms the average number of same-cost successfully the average number of same-cost children tree, and the effective branching the existence of a complexity of DFBnB, and predict In addition, we studied and RBFS on a tree. explain a previously iterative-deepening, than or equal is greater observed anomaly children results WI Zhang, R.E. Korf/ArtQkial Intelligence 79 (1995) 241-292 275 algorithms on large problems, because of its It may even run slower algorithm. than a linear-space the only algorithms of choice for optimally is that cannot be formulated as a tree with a bounded depth, or a algorithms, DFBnB the linear-space linear-space BFS cannot compete with linear-space space requirement. algorithms are usually large and difficult problems. Among exponential Therefore, solving inapplicable state-space graph with known cutoff depth. DFBnB that requires exponential bounded-depth by a bounded-depth tree, or a problem computation, to problems is the best, however, on a problem and whose state space can be represented by a tree. RBFS should be adopted on a problem that cannot be represented that can be solved in polynomial time. Acknowledgements like We would to thank Mark Cassorla, Peter Cheeseman, Sheila Greibach, Lars Hagen, Tad Hogg, Judea Pearl, Joe Pemberton, Curt Powley, Greg Provan, Roberto to this Schonmann, greatly research. We also want improved reviewers of our previous papers [ 57,581, on which this paper is based. Sek-Wah Tan, and Colin Williams to thank related reviewers whose comments the clarity of this paper, and the anonymous for helpful discussions two anonymous Appendix A. Search algorithms This appendix contains pseudo-code descriptions of best-first search (BFS) , iterative-deepening and recursive best-first (DFBnB) , depth-first search (ID), branch-and-bound (RBFS). In the following descriptions, root represents the root node or initial state of a state- space tree, and cost(n) is the cost of a node n. A.1. Best-$rst search The BFS algorithm for tree search is given in Fig. A.l, where the list open is used to maintain current frontier nodes. The algorithm starts with BFS( root). BFShot) open +- 0; n t WHILE (n root is not a goal EXPAND n, generating INSERT all DELETE n from open n t a minimum-cost its children node) and evaluating open into all its children node in open Fig. A.l. Best-first search algorithm. 276 W .Zhung. R.E. Korf/Arftjicial Intelligence 79 (199.51 241-292 DFBnB(n) GENERATE all k children of n: rz1,r@,...,nk EVALUATE them, and SORT them in increasing order of cost FOR (i from I to k) IF (cost(n;) < 1~) IF (ni is a goal node) u + ELSE DFBnB(ni) COSt(ni) ELSE RETURN RETURN Fig. A.2. Depth-first branch-and-bound algorithm. ID(r.oot) threshold + cost( root) next-threshold +- CK REPEAT DFS (root> threshold + next-threshold nex_threshold + oc DFS(rl) FOR (each child II, of n) IF (n, is a goal node and cost(ni) < threshold) EXIT with optimal goal node IZ; IF (cost( n;) < threshold) DFS (q) ELSE IF (cost(n,) < next-threshold) next-threshold +- cost(ni) RETURN Fig. A.3. Iterative-deepening algorithm A.2. Depth-jirst branch-and-bound Fig. A.2 is a recursive version of DFBnB using node ordering. The top-level call is made on the root node, DFBnB( root), with initial upper bound u = co. A.3. Iterative-deepening The iterative-deepening (ID) algorithm repeatedly calls a depth-first search procedure for each iteration with increasing thresholds. The global variables olds for the current and next iterations, does not use node ordering and is implemented It cost threshold and next-threshold are the node cutoff thresh- search, DFS( n), is in Fig. A.3, and starts with ID( root). respectively. The depth-first recursively. N? Hang, R.E. Korf/Ar@cial Inrelligence 79 (1995) 241-292 217 > u) RETURN cost(n) RBFS(n,F[nl,u) (cost(n) (n a goal) is (n has no children) child (cost(n) < F[n]) IF IF IF FOR (each IF ELSE F[i] + Cost(ni) ni of n) F[i] EXIT with optimal RETURN 00 + MAX(F[n],cost(ni)) goal node n SORT ni and F[i] (only IF WHILE (F[l] in one child) <U and F[l] <co) increasing F[2] + co order of F[i] + RHFS(nl,F[l], F[l] INSERT nl and F[l] MIN(u,F[21)) order sorted in RETURN F[l] Fig. A.4. Recursive best-first search algorithm. A.4. Recursive best-first search The RBFS algorithm is given in Fig. A.4, where F(n) is the stored value of node n, and u is a local upper bound. The initial call is RBFS( root, cost( root) ,oo) . Appendix B. Proofs This appendix contains proofs to the lemmas and theorems in Section 2. tree with monotonic node costs, the total number of Lemma 2.1. On a state-space less than the optimal goal cost is a lower bound on the nodes whose costs are strictly complexity ofjinding an optimal goal node, and the total number of nodes whose costs are less than or equal to the optimal goal cost is an upper bound on the complexity of fmding an optimal goal node. that is guaranteed that any algorithm and is based on [ 71. Assume that there is an algorithm A that is guaranteed Proof. We prove the lower bound by showing to find an optimal goal node must expand at least those nodes whose costs are less than the optimal goal cost. This is done by contradiction, the converse, namely, to find an optimal goal node on a tree with monotonic node costs, and that skips a node that has cost less than that when A the optimal goal cost. Let T be a tree with monotonic node costs. Suppose less than the that is strictly is applied optimal goal cost. We now create another tree T’ that is the same as T except that node n in T’ has only one child that is also the only optimal goal node of T’ with cost f(n). Note that the node costs are monotonic it is applied Consequently, the optimality it is applied find the only optimal goal node of T’, contradicting in T’. Since algorithm A skips node n when to the new tree T’. to T, it does not expand a node n of cost f(n) algorithm A cannot assumption to T, A must skip node n as well when for algorithm A. 278 W Zlzung, R.E. Kotf/Artijiciul Intelligence 79 (1995) 241-292 c (d) Fig. B. 1. Structure of a random tree for proving Lemma 2.3 that there is an algorithm We prove the upper bound by showing that finds an optimal to the goal node and expands at most those nodes whose costs are less than or equal of node optimal goal cost. Best-first search costs, and the best-first node-selection strategy it uses, BFS always expands a node with cost x before any node with cost greater than x is chosen for expansion. Thus, BFS will not expand any node whose cost is greater than the optimal goal cost. Cl is such an algorithm. By the monotonicity Lemma 2.3. On a random tree T( b, d) with bpo > 1, as d -+ co, the expected cost oj optimal goal nodes decreases when bpo increases for a given b, or a given po > 0. In zero when po -+ I for a given 6, or when particular; b + 32 for a given p0 > 0. the expected goal cost approaches Proof. Let c(d) be the expected optimal goal cost of a random in Fig. B. 1. We prove the lemma by induction on the depth d. Consider a random of depth one, as in Fig. B.l (a). c( 1) is the expected cost of the minimum costs, where k is a random variable with mean b, i.e. tree T( b, d), as shown tree of k edge c( 1) = E[min{et , e2,. , ek} I. (B.1) that c( 1) decreases It is evident more independent increase. Notice approaches zero, since each ei has a nonzero probability of being zero. that bpo > 1 implies po > 0. Thus, when b increases and identically distributed random variables. as k increases, the minimum is taken over Increasing b causes k to to infinity, c( 1) since As the inductive step, we assume that c(d - 1) decreases and approaches zero as b increases with a fixed po > 0. Let c, (d - 1) be the optimal goal cost of the subtree rooted at the ith child node of the root node of a random tree T( b, d), as shown in Fig. is computed as B.1 (b). Then c(d) c(d) =E[min(et +cl(d-- l),e;!+c2(d- l),...,ek+q(d- I)}]. (B.2) the random variable When b increases, the inductive assumption. Thus, when b increases, b + cc for i = 1,2, c(d) decreases, of more random variables, and each of them decreases as b increases. Similarly, variable e, + ci(d - 1) has a nonzero probability of . , k, following it is the minimum e; + c;( d - 1) decreases and reaches e; as since W Zhang, R.E. Korf/Art#cial Intelligence 79 (1995) 241-292 279 T(b,d,c) Fig. B.2. Structure of a random tree for proving Theorem 2.6. being zero when b + oc, because po > 0 and ci( d - 1) -+ 0 in this case. Consequently, c(d) + 0 when b -+ 00, which concludes our claim for the case when b --t 00. The fact that the optimal goal cost decreases and reaches zero when po + 1 with a given b can be proved similarly. (cid:144)i tree with monotonic node costs, best-first search is optimal Lemma 2.4. On a state-space to find an optimal among all algorithms goal node, up to tie-breaking among nodes whose costs are equal to the optimal goal cost. that use the same node costs ana’ are guaranteed Proof. This than the optimal goal cost. Because of its best-first node-selection expands a node with cost greater is a corollary of Lemma 2.1. BFS must expand all nodes with costs less strategy, BFS never than the optimal goal cost. q Theorem 2.6. Let NB( b, d) be the expected number of nodes expanded by best-first the expected number of nodes expanded by depth-$rst branch- search, and ND( b,d) and-bound, on a random tree T( b, d). As d -+ W, d-l N&b,d) < (b- l)xNB(b,i) +d. i=l of discussion, Proof. For convenience T(b, d, c). By this notation, For the same reason, DFBnB on T( b, d, c) with initial upper bound U. denote a random tree with root node cost c as tree T(b, d) with root cost zero is T(b, d, 0). let ND (b, d, c, u) be the expected number of nodes expanded by a random As shown in Fig. B.2, the root of T(b, d, c) has k children, nr, n2,. . . , Ilk, where k is a random variable with mean b. Let ei be the edge cost from the root of T( b, d, c) The to its ithchild, children of the root are generated all at once and sorted in nondecreasing order of their costs. Thus er < e2 < . . . 6 ek, arranged from left to right in Fig. B.2. We first make the following the root of its ith subtree z(b,d- two observations. for i= 1,2,...,k. l,c+ei), First, subtracting the root cost from all nodes and the upper bound has no affect on the number of nodes expanded by DFBnB on T(b, d, c) with the search. Therefore, initial upper bound u is equal to those expanded on T( b, d, 0) with initial upper bound u - c. That is 280 W. Zlzar~~, R.E. Korf~Artijiciul Intelligence 79 (1995) 241-292 ND(b,d,C,U) =ND(b,d,O,u-c). N,,(b,d,c,x,) =ND(b,d,O.x). I (B.3) Secondly, because expanded T(b,d,c) upper bound u’ < U. That is a larger to be the number of nodes expanded by DFBnB on as a smaller upper bound, with initial upper bound u is no less than the number expanded with initial initial upper bound causes at least as many nodes N,)(O,d,c,u’) 6 ND(b,d,c,u), for U’ < U. (B.4) It first searches the subtree Tl(b,d Now consider DFBnB on T( b,d,O). - 1, el) (see Fig. B.2), expanding No (b, d - 1, el, cx;) expected number of nodes. Let p be the goal cost of Tl (b, d - I, 0). Then the minimum goal cost of Tl (b, d - 1, el ) minimum is the upper bound after searching Tt (b, d - 1, el ) After the subtree is p + ei , which TI (6, d - I, el ) is searched, subtree Tz( b, d - 1, e2) will be explored if its root cost e2 is less than the current upper bound p + el , and the expected number of nodes expanded is No(b,d-l,ez,p+et). in T;( b, d - 1, ei), for i = 3,4,. the number of nodes expanded upper bound can only decrease after searching T2 (6, d - I, e2) and the edge cost ei can only increase as i increases, both of which cause fewer nodes to be expanded. Since the root of T( b, d, 0) has b expected children, each of which we write isalsoanupperboundontheexpected is independently ND(b,d-l,ez,p+el) is because generated, , k. This Nt,(b,d,O,oc) <No(b,d-l,c1,x)+(b-l)ND(b,d-l,e2,p+el)+l, (B.5) where the I is for the expansion of the root of T( b, d, 0). By (B.3) and (BS), we have No(b,d,O.cx:) ~NNo(b,d-l,O.~c)+(b~-I)N~(b,d-l,O,p+e~-e;,)+I. (B.6) Since p + e I - e2 < p for el < e2, by (B.4), we rewrite (B.6) as < ND(b,d - 1,0x) + (0 -- l)ND(b.d - l,O,p) f 1. (B.7) Now consider ND (0, d - 1 , 0, p), the expected number of nodes expanded by DFBnB on T( 0, d - 1,O) with initial upper bound p. If T( b, d - 1,O) is searched by BFS, it the optimal goal node and its expected cost p, and expand Nn( b, d - 1) will return is searched by DFBnB with upper bound p, nodes on average. When T( b, d - 1,O) only those nodes whose costs are strictly less than p will be expanded, and these nodes must also be expanded by BFS. We thus have No(b,d - l,O,p) < Ne(b,d - 1). 03.8) Substituting (B.8) into (B.7 ), we then write W Zhang, R.E. Kmf/Art$cial Intelligence 79 (1995) 241-292 281 ND(b,dO,m:,) <ND(b,d-l,O,ca)+(b-l)Ng(b,d-I)+1 <ND(b,d-2,0,m)+(b--l)(Ng(b,d-l)+Ng(b,d-2))+2 < . . . <h(b,o,o,m) +(b- d-l l)x%(b,i) i=l +d. (B.9) This proves the lemma since ND( b,O,O, co) = 0. 0 Corollary 2.7. On a random tree T(b,d), N~(b,d) - 1)). where NB( b, d) and ND( b, d) are the expected numbers of nodes expanded by best-$rst search and depth-jG-st branch-and-bound, respectively. < O(d. N~(b,d Proof. It directly follows Theorem 2.6 and the fact that d-l c Ns(b,i) < (d - l)NB(b,d - I), i=l since NB(b,i) < NB(b,d - 1) for all i <d - 1. 0 (B.lO) Theorem 2.8. The expected number of nodes expanded by depth-first branch-and-bound forfinding an optimal goal node of a random tree T( b, d), as d -+ 00, is ( 1) 6(pd) when bpo < 1, meaning that depth-$rst branch-and-bound is asymptoti- cally optimal, where p is the same constant as in Lemma 2.5, (2) O(d3) when bpo = 1, and (3) O(d*) when bpo > 1, where po is the probability of a zero-cost edge. Proof. It is evident totic expected complexity that Na( b, i) < NB(~, Ld/2] + i). This allows us to use the asymp- of BFS as d -+ 00. By Lemma 2.5 and Theorem 2.6, when bpo < 1, ND(b,d)c:(b-l)xNB(b,i)+d d-l d-l <2(b- 1) c NB(b,i)+d i= Ld/2J d-l =2(b- 1) c O(p’)+d i=[d/2] = e(pd>. The other two cases directly follow from Lemma 2.5 and Theorem 2.6. 0 282 W. Zhang, R.E. Korf/Arfijiciul Intelligence 79 (I 995) 241-292 Corollary 2.9. On a random number of nodes expanded by depth-first branch-and-bound po + 1 for a given b, or when b --) cx) for a given po > 0. tree T( b, d) with bpo > 1, as d --f W, the expected approaches O(d) when for a given edge-cost distribution, I for a given Proof. When b --$ x b, the optimal goal cost C* approaches zero, according the upper bound after searching TI (b, d - 1, el ) approaches ei (see Fig. B.2). Since the root of subtree T;( b, d - 1, e;) has cost e,, which is no less than the current upper bound ei, no = willbeexpanded,fori=2,3,...,k.Then,No(b,d-l,e2,el) nodesinT,(b,d-l,ei) 0, and (B.7) becomes to Lemma 2.3. Thus, or when po + ND(b,d,O,m) =ND(b,d - l,O,cx,) + 1. (B.11) where the 1 is for the expansion of the root of T( b, d, 0)) which leads to ND(b,d,O,oc;)=ND(b,d-2,0,oc)+2 =ND(b,d - 3,0,cc) + 3 =. =d. 0 Theorem 2.10. On a random iterative-deepening distribution, tree T( b, d) with edge costs chosen from a continuous expands 0( ( Ns (b, d) )*) expected number of nodes, where NB (b, d) is the expected number of nodes expanded by best-first search. On a ran- dom tree T( 6, d) with edge costs chosen from a lattice distribution, expands 0( Ns (b, d) ) expected number of nodes as d -+ co, which is asymptotically iterative-deepening optimal. Proof. When edge costs are chosen unique with probability and the ith iteration expands of iterations deepening is Na (b, d) . Hence is one. Thus, each successive from a continuous all node costs are iteration expands one new node, the expected number the expected number of nodes expanded by iterative- i nodes on average. Consequently, distribution, NB(~A) Nm(b,d) = c i=O((Ng(b,d))‘). ,=I Now consider lattice edge costs chosen from the set {sod, al A, a2A, . . . , a,,A}, where and a0 < al < a2 < il > 0 is a constant relatively prime integers. To include the situation where edges may have zero cost, we set a0 = 0. It is clear that all node costs are multiples of A, and so is the difference of two distinct node costs. This means is a constant independent increases by at least A, which that the cost threshold < a,,, are nonnegative of d, from one iteration to the next. The last iteration has a cost threshold equal to the optimal goal cost C* of T( 6, d), and expands all nodes whose costs are less than C” and some nodes whose costs are H! Zhang, R.E. Kmf/Artijicial Intelligence 79 (1995) 241-292 283 equal to C*. In other words, the expected number of nodes expanded by the last iteration is of the same order as the expected complexity of best-first search. In addition, each iteration before fewer nodes than the last iteration. the last one expands thus the maximum the total number of iterations When bpc > 1, the optimal goal cost almost surely remains bounded by a constant that constant, the cost threshold to the next. A constant num- to the total num- in this by Lemma 2.2, and Therefore, increases by at least a constant ber of iterations only contributes ber of nodes expanded. Hence case. d from one a constant multiplicative iterative-deepening is also a constant, iteration overhead is asymptotically cost threshold will not exceed optimal since The number of iterations is not a constant when bpo < 1, since the optimal goal cost the case when bps < 1. The optimal goal cost of T(b, d) grows linearly with d, and the expected number of nodes with costs the expected number of in d in this case. Intuitively, in that cost, the following increases with the depth d. First consider C*(d) less than C*(d) nodes whose costs are less than a particular cost seems to be exponential so that the optimality should follow. This suggests proof. of iterative-deepening is exponential increases has to execute that iterative-deepening - 1) + amA, where a,A the optimal goal cost C*(d < C*(d of d. This means that there are a constant number of iterations is at most a,. The last iteration of Z(d) the iterations of T(b, d) after obtaining to find the optimal goal - 1) of a shallower , which than C*( d - 1) and less than or equal to the cost threshold by at least d. It is evident is the largest edge cost and a constant in Z(d), Consider cost C*(d) tree T( b, d - 1) of T( b, d) . For simplicity, name the set of these iterations Z(d) explore new nodes whose costs are greater C*(d). Each iteration of Z(d) that C*(d) independent which nodes as d --+ 00, where p > 1 is a constant, last iteration expands more nodes than any other iterations of Z( d) . Therefore, expected number of nodes expanded by all iterations of Z(d) iterative-deepening Notice number of nodes expanded by the iterations the asymptotic expected number of nodes expanded by BFS as d -+ cm. By definition, 0( p’) < K . p’ for some K > 0 and large i. Thus, the total expected number of nodes expanded , for i = 0, 1,2, . . . , d. in Z(i) the is less than in Z( [d/2J + i). This allows US to use expected number of the the total that the number of nodes expanded by the iterations executes a sequence of sets of iterations 2(i) to find an optimal goal node of T( b, d) following Lemma 2.5. In addition, is c9(pd). Furthermore, expands O(pd) is NID(b,d) <2 2 0(p’> < 2K k p’ i= Ld/SJ i=Ld/2J d+l _ 1 P-1 <2K&?=2KP i=O <2Kp_ 1 Ppd, which is O(pd). Hence iterative-deepening is asymptotically optimal when bpo < 1. The above proof also executes deepening the fact that the total number of iterations in the search depth d when bpe < 1. This directly that the algorithm has to execute is linear indicates that the total number of iterations that iterative- follows to find C*(d) after obtained C*(d ~ I) is a constant. When bpo = 1, best-first search expands H( d2 ) expected number of nodes in a random tree T( 0, d) by Lemma 2.5, which is also the asymptotic order of the expected number The optimal goal cost of nodes expanded by the last iteration of iterative-deepening. C*(d) is equivalent = 1 by Lemma 2.2, which C*(d)/loglogd of T( h, d) satisfies lim,l,, to C*(d) = loglogd +&loglogd), (B.12) xc, for some function q5( log logd) as d - 2 log log d, because 4( log log d) < log log d, as d + m. Therefore, iterations of iterative-deepening where the constant A is the minimum to the next. for searching T( 0, d) increment of the cost threshold t o( loglogd) ‘. Notice that C*(d) < the total number of is I < C* (d)/A = O(loglogd), from one iteration Consider a shallower tree T( b. irrdl ) ol‘ T( 0, d), for some constant 0 < g < I. For the same reason as above, the optimal goal cost C* ( [ad1 ) of T( b, ludl ) satisfies C*( [vdl) = loglog[cTdl + &logloglrrdl). (B.13) since T(b, is the same function 4 in (B.12), is as d - 3~. Function 4 in (B.13) the same. In the following, we show within T( 0. d) and these problems are structurally are chosen that the first time that nodes with costs in the interval that the penultimate for expansion, it is during this result and Lemma 2.5, the last iteration, iteration cannot reach depth [cTdl. Following iteration, iteration expected number of nodes. For the same iteration reason, expected number of nodes, etc. By definition. 0( d’) < K d’ for some K > 0 as d --f x), and 1.~1 < x + 1. Thus, the total expected number of nodes expanded I, expands O(d’) I ~ 1, expands expected number of nodes, and iteration, which also implies iteration 1 ~ 2 expands [C*( [cTdl), C*(d)] less than 0( [a’dj*) less than 19( [udl’) the penultimate the same [ad]) is which is O(d’), since c is a constant. ’ O( y( .\ ) ) denotes the set of all that WC.\-) < <x(-r) for all x > xt,. or equivalently functions W(.I ) such linlr_r that for all positive constants L’ there is an 10 such o(x)/~(x) = 0. W Zhang* R.E. KorfIArtificial Intelligence 79 (1995) 241-292 285 We now show that it is during the same iteration that nodes with costs in the interval to prove for the first time as d ---) 00. It is sufficient = 0. By (B.12) and (B.13), [C*([4)>C*(41 that limd,, (C*(d) are expanded - C*( [ad])) C*(d) - c*( [cdl) =loglogd - loglog[o-dl + &loglogd) - $(loglog[c+d]), (B.14) as d + cc. We first prove [cdl 2 crd and log x is an increasing Therefore, that loglogd - loglog[ad] that function of X. Thus, log log[c+dl 3 log log( gd) . = 0 as d + co. Notice lim d+oo (loglogd - loglograd]) </ima (loglogd - loglog( = log lim d-co ( = log 1 = 0. log d log d + log (+ > (B.15) In the above calculation, we used [ 21. On the other hand, continuous (B.15) mean that lim log( Y(n) ) = log(lim Y(x)) is log log d - log logrc+d] > 0, since c < 1. This and because log(y) lim d-03 (loglogd - loglogrrrdl) = 0. (B.16) We now prove @(loglogd) the function +(loglogd) Consider depths d and d - 1 in T( b, d) . Following - &log introduced logrod]) in (B.12) that = 0 as d -+ co. We first show is nondecreasing with d as d + 0~). (B.12)) we write C*(d) - C*(d - 1) =loglogd - loglog(d - 1) + +(loglogd) - 4(loglog(d - 1)). (B.17) Using a similar calculation as in (B.15), we can simply prove lim d-m (loglogd - loglog(d - 1)) = 0. Because C*(d) - C*(d - 1) > 0, by (B.17) we then write ~~~~~t4tloglogd) - ~tloglogtd - 1))) 2 0, meaning that +(log log d) does not decrease with d, as d -+ co. Therefore, ,limm(+(loglogd) - +(loglog[c+dl)) > 0, (B.18) where c < 1. If &loglogd) does not increase with d either, then 286 W Zhung, R.E. Kmj/Artijicial Intelligence 79 (1995) 241-292 d’iinl_ (&loglogd) - 4(loglog[adl)) =o. (B.19) If 4( log log d) than that of the function we have increases with d, on the other hand, loglogd, since $(loglogd) its growth rate cannot be greater Thus, by (B.16), E o(loglogd). ,/iim_ (~(loglogd) - 44oglogbdl)) < fim, (loglogd - loglog[cdl) = 0. (B.20) Inequations (B.18) and (B.20) also lead to (B.19). Thus, jimw (C*(d) - C*( rod])) = 0. combining optimal in the case when bpo = 1. 0 (B. 14)) (B. 16) and (B. 19). Therefore, iterative-deepening is asymptotically Theorem 2.11. Let B be the asymptotic heuristic branching T( 6, d) with b > 1. B = 1 when edge costs are chosen from a continuous distribution. When bpo < 1, and edge costs are chosen from a lattice distribution on (a0 = 0, al A, a2A,. . . , a,,A} with probabilities . ,p,,, respectively, where A > 0 is po,p~, ~2,. . < a,,, are relatively prime, B integers al < a2 < chosen such that the nonnegative approaches a constant as d 4 x, which is a solution greater than one to the equation factor of a random tree ,I, c Pi jg i=O 1 = jj’ (B.21) factor. from a lattice Proof. When edge costs are chosen from a continuous distribution, node costs are unique with probability the ratio of the number of nodes of a given cost to the number of nodes of any other cost is one, and so is the heuristic branching one. Consequently, The heuristic branching factor of T(b, d) with edge costs chosen lifetime of random [ 151. In an age-dependent tree T( b, d) can be mapped length. At the end of its life, the object distribution on (a0 = 0, al A, a2A,. . , anrA} is a corollary of the results of age-dependent branching process, an object born at time branching processes is replaced 0 has a finite by a random number of similar objects of age 0, which independently the same as their parent. This process of generating new objects continues as long as objects are branching process present. A random in the process. as follows. The root node of the tree corresponds to the lifetime of the object represented by the node at the An edge cost corresponds end of the edge. The cost of a tree node corresponds the the children of the object are born. One minor corresponding the lifetime of the discrepancy original object may not be zero. However, in our analysis, since to be a nonzero number, and this number is that the root node has cost zero, as defined, whereas the cost of the root node can also be defined is then added to all internal nodes of the tree. this will not cause a problem object dies, or when to the original object to an age-dependent to the absolute time when behave W Zhang, R.E. Korf/Art$icial Intelligence 79 (1995) 241-292 287 Edge costs are multiples loss of generality, we divide all edge and node costs by A, and thus treat edge and node costs as integers. A node cost K is a linear combination of A, and hence, so are the node costs. Without of nonzero edge costs, K=klal +kzaz+...+k,,a,,,, (B.22) for some nonnegative that requires integer (B.22) has a solution costs may include every with cost k is exponential dependent branching processes. integers { kl , k2, . . . , k,}. solutions in nonnegative (B.22) [ 351. In fact, for all integer K > 2a,_l {kl , k2, . . . , km} [ 91, indicating integers integer K as K -+ 00. Indeed, [am/ml is a linear Diophantine equation - a,,, that node the expected number of nodes from age- the results in K, which we prove below using Let D(K) be the expected number of nodes with cost K, which corresponds to the expected number of objects process. Furthermore, duced) exactly at time K, and A(K) at time K in the branching process. Thus, we write let P(K) be the expected number of objects be the expected number of objects that die exactly at time K in the corresponding branching that are born (pro- that are alive A(K) = A(K - 1) + P(K) -D(K), (B.23) that the total expected number of currently alive objects A(K) which means the total expected number of objects alive at the previous the expected number of new borns at time K ( P(K) ) , and minus of the objects died at time K (D(K)). is equal to (A( K - 1) ) plus the expected number time point It has been shown in [ 151 that A(K) grows exponentially in K, i.e. as K -+ CQ A(K) = qepK + C#JI (e““K), (B.24) where cl > 0 is a constant, ~$1 (epK) E o(epK), root to the equation and ,U is a constant and the positive ,,l x5=;. i=O Eq. (B.25) has a unique positive root if b > 1 [ 151. (B.25) Further notice that P(K) > 0, because increases with K by (B.24). This gives D(K) > 0 since child objects are born when their parents die. Therefore, by (B.23) the expected number of alive objects and (B.24), we have P(K) =A(K)-A(K-l)+D(K) >A(K) -A(K- 1) = cte PK _ ctePL(K-l) + f$t (ePK) - f$t (eficK-‘)) =ci(l -e-*)ePK++t(ePK) -#i(ePCK-‘)). (B.26) It is evident that P(K) < A(K) . This, combining (B.24) and (B.26)) gives 28X II! Zhcm,$. K.E. Kor-f/ArtiJiciul Intellqrnce 79 (1995) 241-292 P(K) =czeP”“+&(ePLh’). (B.27) where (‘I( I - e-p’) < c? < cl, and $1 (e F”K) ~ 41(efi(K-‘)) Therefore, hy (B.23), (B.24) and (B.27), we have < &(e@) < +l(epK). D(K) =P(K) - A(K) + A(K - I) = cy.2 PK _ C,ePK + C,ePL(K-l 1 + 42(eF”“) - q5I (epK) + $1 (epL(Kp’)) = qe +’ + qb3(epK). (B.28) wherec~=c~-cI(I-cCfi) Using (B.28) and by the definition, we finally obtain the heuristic branching factor >0,and(63(e~LK)=~2(eyK)-~l(e/lK)+~l(e~(K-’)). B= D(K) lim ~- K-wD(K-~) Because p is a positive solution Eq. (B.21). q to Eq. (B.25), B = e/* is a solution greater than one to 2.12. On u rundom tree T( b, d) with h > I, when bpo < I and edge costs Theorem are chosen from a lattice distribution, best-first search, depth-jirst branch-and-bound, and recursive hest;jirst search all have the same effective branching iterative-deepening, ,factor p = B” as d 4 W, w,here p() is the probability that an edge has cost zero, B is the asymptotic heuristic branching factor of T( b, cl), Q is the limit of C”/d as d + cx), arrd C* is the optimal goal cost. is superior and RBFS are all asymptotically they all have the same asymptotic effective branching Proof. When bpo < I and edge costs are chosen iterative-deepening to Theorems 2.8, 2.10 and the fact that RBFS Therefore. effective branching from a lattice distribution, DFBnB, optima1 as d + co, according [24]. factor as the asymptotic factor p of BFS. We now only need to show that /3 = B” as d ---f cc. the notations used in the proof of Theorem 2. I 1. Let lattice edge costs be chosen from the set {CIQ = O,alA,a~A,. ,a,,!A}. Again, we divide all edge and node costs by A, and loss of generality. By Lemmas 2.1 and 2.4, BFS expands treat them as integers without all nodes with costs less than the optima1 goal cost C”, plus some nodes with cost C*, but no nodes with cost greater We again use the results to iterative-deepening from age-dependent than C*. That is, and adopt processes, branching Z(C” - 1) < &(b,d) < Z(C*), (B.30) where Z(K) corresponds is the expected number of nodes with costs less than or equal to K. Z(K) that died up to time K. The number to the expected number of all objects W Bang, R.E. Kwf/Art$cial Intelligence 79 (1995) 241-292 289 of all dead objects up to time K is greater died at time K, but is less than or equal time points up to K, where a living object which it is alive. That is. than or equal to the number of objects that to the total number of all living objects at all in time at is counted again for each point D(K) < Z(K) <CA(i), i=O (B.31) where D(K) time K. Following as d 4 co. Thus, and A(K) are the expected number of died objects and living objects at (epK) < 2clepK, since c5t (ekK) < cte@ (B.24), A(K) = clekK+$l CA(i) i=O <2cl eepi i=O eP(K+l) _ 1 = 2ct efi - 1 ep < 2ct -e ep--1 PK ’ By (B.28) in the proof to Theorem 2.11, D(K - 1) = csePL(K-‘) +&(ePCK-‘)) = (cs/e)epK + &(efiCK-‘)). From (B.30), (B.31) and (B.32), we then have ?epc* +q&(e pcc*-1’> e < &(b,d) < kl&&*. (B.32) (B.33) This means c* = ad + o(d) finally have that epc’ is the dominant (Lemma 2.2) and by the definition of effective branching function of Nn (b, d) as d -+ co. Therefore, using factor, we P=d’i”, QXZGG = /im, J ’ ep(ad+ofd)) = /im, Eva . ePo(d)ld =ep*. (B.34) Because B = efi by Theorem 2.10, (B.34) is equivalent to p = B” as d -+ CXI. 0 References 1 I 1 E. Balas and P. Toth, Branch and bound methods, in: E.L. Lawler et al., ed., The Traveling Salesman Problem (John Wiley and Sons, Essex, 1985) 361-401. 12 1 K.G. Binmore, Mafhematical Analysis (Cambridge University Press, New York, 1982). 290 W Zhung, R.E. Korf/Ar@ciul Intelligence 79 (1995) 241-292 131 141 151 161 171 181 I91 1101 IIll 112 I13 I14 I IS II6 are, 197-221. in: Proceedings in restricted memory, Arrif: in satisfiability problems, the really hard problems results on the crossover point search, Tech. Report UCLA-ENG-81-39, and Applied Science, University of California, Los S. Ghose, A. Acharya and SC. de Sarkar, Heuristic search and W.M. Taylor, Where (1991) 331-337. and L.D. Auton, Experimental P.P. Chakrabarti, Intel/. 41 (1989) P. Cheeseman, B. Kanefsky IJCAI-91, Sydney, Australia J.M. Crawford in: Proceedings AAAI-93, Washington, DC ( 1993) 21-27. A. Dechter, A probabilistic analysis of branch-and-bound Cognitive Systems Lab, School of Engineering Angeles, CA ( 198 I ). R. Dechter and J. Pearl, Generalized ( 1985) 505-536. E.W. Dijkstra, A note on two problems P. ErdBs and R.L. Graham, On a linear diophantine problem of frobenius, Actu Arithmarica 399-408 S.H. Fuller, J.G. Gaschnig and J.J. Gillogly, Analysis of the alpha-beta pruning algorithm, Tech. Report, Carnegie-Mellon University, Computer Science Department Pittsburgh, PA ( 1973). M.R. Garey and D.S. Johnson, Compurers und Intractability: A Guide to the Theory ofNP-Completeness (Freeman, New York, 1979). J.G. Gaschnig, Performance measurement Report CMU-CS-79-124, (1979). M.L. Ginsberg and W.D. Harvey, J.M. Hammersley, Postulates and analysis of certain search algorithms, Ph.D. Thesis, Tech. Computer Science Department, Carnegie-Mellon University, Pittsburgh, PA lterative broadening, Artif: Infell. 55 (1992) 367-383. for subadditive processes, Ann. Probability 2 ( 1974) 652-680. in connexion with graphs, Numer. Math. 1 ( 1971) 269-271. search strategies and the optimality of A*, J. ACM 32 21 (1972) best-first I T. Harris, The Theory of Branching Processes (Springer, Berlin, 1963). T.!? Hart, N.J. Nilsson and B. Raphael, A formal basis for the heuristic determination paths. lEEE Trans. Syst. Sci. Cybern. 4 ( 1968) of minimum cost lOO- 107. in artificial intelligence systems, Art$ fntell. 33 (1987) I I7 I B.A. Huberman and T. Hogg, Phase transitions 15%171. I I8 I N. Huyn, R. Dechter and J. Pearl. Probabilistic analysis of the complexity of A*, Artif Infell. 15 ( 1980) 241-2.54. I I9 I T. lbaraki, Enumerafive Approaches to Combinatorial Opfimizalion-fart I, Annals of Operations Research 10 (Scientific, Basel, Switzerland, 1987). 1201 R.M. Karp and J. Pearl, Searching for an optimal path in a tree with random costs, Artif Intell. 21 ( 1983) 99-l 17. 12 I I J.F.C. Kingman, The first birth problem for an age-dependent branching process, Ann. Probability 3 (1975) 790-801. I22 I R.E. Korf, Depth-first 97-109. iterative-deepening: An optimal admissible tree search, Artif Intell. 27 ( 1985) I23 I R.E. Korf, Real-time heuristic search, Artif. Intell. 42 ( 1990) 189-2 I I. best-first search, Artif Intel/. 62 (1993) 41-78. 1241 R.E. Korf, Linear-space [ 25 I V. Kumar, Search branch-and-bound, in: S.C. Shapiro, ed., Encyclopedia ofArtificial Intelligence (Wiley- lnterscience, New York, 2nd ed., 1992) 1468-1472. I26 I V. Kumar, D.S. Nau and L. Kanal, A general branch-and-bound formulation for and/or graph and game tree search, York, 1988) 91-130. in: L. Kanal and V. Kumar, eds., Seurch in Artijicial Inrelligence (Springer-Verlag, New I27 I P. Langley, Systematic and nonsystematic search strategies, in: Proceedingsfirst Internafional Conference on AI Plunning Sysrems, College Park, MD (1992) 145-152. I28 I T. Larrabee and Y. Tsuji, Evidence for a satisfiability threshold for random 3CNF formulas, in: Working Nores of AAAI I993 Spring Symposium: AI und NP-Hard Problems, Stanford, CA ( 1993) 112-l 18. 1291 E.L. Lawler, J.K. Lenstra, A.H.G.R. Kan and D.B. Shmoys, The Traveling Salesman Problem (John Wiley and Sons, Essex, 1985). [ 30 I E.L. Lawler and D.E. Wood, Branch-and-bound methods: a survey, Operations Research 14 (1966) 699-719. W Bang, R.E. Korf/Artifcial Intelligence 79 (1995) 241-292 291 13 11 A. Mahanti, S. Ghosh, D.S. Nau, A.K. Pal and L.N. Kanal, Performance of IDA* on trees and graphs, in: Proceedings AAAI-92, San Jose, CA ( 1992) 539-544. 1321 C.J.H. McDiarmid, Probabilistic analysis of tree search, in: G.R. Gummett and D.J.A. Welsh, eds., Disorder in Physical Systems (Oxford Science, 1990) 249-260. I33 I C.J.H. McDiarmid and G.M.A. Provan, An expected-cost analysis of backtracking and non-backtracking algorithms, in: Proceedings IJCAI-91, Sydney, Australia ( 199 1) 172-177. [ 341 D. Mitchell, B. Selman and H. Levesque, Hard and easy distributions of SAT problems, in: Proceedings AAAI-92, San Jose, CA (1992) 459-465. 1351 I. Niven and H.S. Zuckerman, An Introduction to the Theory of Numbers (John Wiley and Sons, New York, 4th ed., 1980). [ 36 1 C.H. Papadimitriou and K. Steiglitz, Combinatorial Optimization: Algorithms and Complexity (Prentice- Hall, Englewood Cliffs, NJ, 1982). I 371 B.G. Patrick, An analysis of iterative-deepening-A*, Ph.D. Thesis, Computer Science Department, McGill University, Montreal, Que. ( 1991). 138 I B.G. Patrick, M. Almulla and M.M. Newborn, An upper bound on the complexity of iterative-deepening- A*, Ann. Math. Art$ Intell. 5 (1992) 265-278. [ 391 J. Pearl, Heuristics (Addison-Wesley, Reading, MA, 1984). I40 I J. Pearl, Branching factor, in: S.C. Shapiro, ed., Encyclopedia of Artificial Intelligence (Wiley- Interscience, New York, 2nd ed., 1992) 127-128. 141 1 I. Pohl, Practical and theoretical considerations in heuristic search algorithms, in: E.W. Elcock and D. Michie, eds., Machine Intelligence 8 (Wiley, New York, 1977) 55-72. I42 I PW. Purdom, Search rearrangement backtracking and polynomial average time, Art$ Intell. 21 ( 1983) 117-133. I43 1 D. Ratner and M. Warmuth, Finding a shortest solution for the n x n extension of the 15-puzzle is intractable, in: Proceedings AAAI-86, Philadelphia, PA (1986) 168-172. [ 44 1 A. Rtnyi, Probability Theory (North-Holland, Amsterdam, 1970). [ 45 ] S. Russell, Efficient memory-bounded search methods, in: Proceedings ECAI-92, Vienna, Austria ( 1992). 1461 U.K. Sarkar, PP. Chakrabarti, S. Ghose and S.C. DeSarkar, Reducing teexpansions in iterative-deepening search by controlling cutoff bounds, Artt$ Intell. 50 (1991) 207-221. [ 47 I A.K. Sen and A. Bagchi, Fast recursive formulations for best-first search that allow controlled use of memory, in: Proceedings IJCAI-89, Detroit, MI ( 1989) 297-302. [ 481 D.R. Smith, Random trees and the analysis of branch and bound procedures, J. ACM 31 ( 1984) 163-188. 1491 H.S. Stone and P. Sipala, The average complexity of depth-first search with backtracking and cutoff, IBM J. Research Development 30 ( 1986) 242-258. [SOI L.A. Taylor and R.E. Korf, Pruning duplicate nodes in depth-first search, in: Proceedings AAAI-93, Washington, DC ( 1993) 756-761. 15 1 1 N.R. Vempaty, V. Kumar and R.E. Korf, Depth-first vs best-first search, in: Proceedings AAAI-91, Anaheim, CA ( 1991) 434-440. 1521 B.W. Wah, MIDA’, an IDA* search with dynamic control, Tech. Report UILU-ENG-91-2216 CRHC- 91-9, Center for Reliable and High-Performance Computing Coordinated Science Lab, College of Engineering, University of Illinois at Urbana Champaign-Urbana, IL ( 1991) [ 53 I B.W. Wah and CF. Yu, Stochastic modeling of branch-and-bound algorithms with best-first search, IEEE Trans. Sofrware Engineering 11 (1985) 922-934. [ 54 ] C.P. Williams and T. Hogg, Extending deep structure, in: Proceedings AAAI-93, Washington, DC ( 1993) 152-157. [ 551 W. Zhang, Truncated branch-and-bound: a case study on the asymmetric TSP, in: Working Notes of AAAI I993 Spring Symposium: AI and NP-Hard Problems, Stanford, CA (1993) 160-166. 1561 W. Zhang, Analyses of linear-space search algorithms and applications, Ph.D. Thesis, Computer Science Department, University of California at Los Angeles, Los Angeles, CA (1994). [ 57 1 W. Zhang and R.E. Korf, An average-case analysis of branch-and-bound with applications: summary of results, in: Proceedings AAAI-92, San Jose, CA (1992) 545-550. [ 581 W. Zhang and R.E. Korf, Depth-first vs. best-first search: New results, in: Proceedings AAAI-93, Washington, DC (1993) 769-775. 192 W .Zhan,q, K.E. Ko~f/Arr@cial Inrelli~encr 79 (1995) 241-292 1591 W. Zhang and J.C. Pemberton. Epsilon-transformation: Exploiting combinatorial University of California, Los Angeles. CA ( 1994). 160 I W. Zhang and J.C. Pemberton, Epsilon-transformation: optimization problems, Tech. Report UCLA-CSD-940003, phase solve transitions Computer Science Department, to exploiting phase transitions to solve combinatorial optimization problems-initial results, in: Pmceedings AAAI-94, Seattle, WA ( 1994). 