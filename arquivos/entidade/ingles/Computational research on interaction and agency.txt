ELSEVIER Artificial Intelligence 72 (1995) 1-52 Artificial Intelligence Computational research on interaction and agency Philip E. Agre * Department of Communication, University of California, San Diego, Lo Jolla, CA 92093-0503, USA Abstract research intelligence in artificial theories of agents’ has developed computational in their environments. Although inspired by a great diversity of formalisms Recent volvements architectures, terizations of agents’ interactions with their environments design of artificial ones. This article offers a conceptual several other fields of research that hold the potential projects, and summarizes It also briefly describes a case study in these ideas-a a short-order breakfast cook. Because it inhabits, Toast can employ an extremely in- and these research projects are unified by a common concern: using principled charac- to guide analysis of living agents and surveys framework for dialogue with these new computational the principal contributions of the articles in this special double volume. computer program called Toast that acts as in the world its designers have discovered useful structures to decide what to do next. simple mechanism for such theories, 1. Introduction The papers in this special double volume illustrate an emerging way of doing research in artificial intelligence, which might be stated compactly as follows: Using principled ronments to guide explanation and design. characterizations of interactions between agents and their envi- The purpose of this introduction explore is to explain this emerging in AI and elsewhere. its relationship to other research Let us begin with a familiar example. Consider a device style of research and to (a “controller”) that must an oil the operations of an oil refinery. So far as control direct refinery that can be adjusted (the settings of various valves and burners) number of “output variables” whose values at any given moment can be determined is an enormous machine (the “plant”) with a number of “control variables” from the outside is concerned, and a from theory * E-mail: pagre@ucsd.edu. Telephone: (619) 534-6328. Fax: (619) 534-7315 0004-3702/95/$09.50 SSDfOOO4-3702(94)00054-9 @ 1995 Elsevier Science B.V. All rights reserved 2 PE. Agre/Artijicial Intelligence 72 (1995) 1-52 the outside let us say, maintaining must adjust the valves and burners (the readings on various sensors and gauges). The task of the “controller”, around certain values while is to stabilize terms, the controller other variables within certain fixed ranges. In concrete to sustain a fixed flow of oil without the plant blowing some of the output variables up. Given a proposed design to answer the plant in isolation. for this controller, how do we know whether simply by analyzing this question It is impossible obviously, does it suffice to analyze how the controller will interact with the plant. Given any particular and supposing of plant plus controller will follow a determinate ensure way to characterize relates changes rates of change, or past values, or both) of the output variables. it will work? itself. Nor, to analyze set of initial values, system trajectory. The designer’s goal is to trajectories has certain properties. One that equation the ongoing that the entire family of these interaction is in terms of a differential this family of trajectories in the control variables to the current values that the interaction is not stochastic, (and perhaps the combined for simplicity the controller it is crucial Instead, in this example might be regarded as an agent interacting with its envi- the plant, and differential equations provide one way of characterizing theory, of course, provides only one way of thinking It is tied to a particular model of interaction has been profoundly its historical development The controller ronment, namely such interactions. Control interactions. variables), safety and conservatism matical. A principled qualities of natural ones. Indeed, we have deliberately opposed of theories of interaction. The important should allow us to address questions to, say, “formal”) characterization like these: in relatively well-behaved of interaction, to provide a useful guide to the design of artificial agents and the explanation in order to include an unforeseeable range of possible chosen the vague word “principled” thing is that our characterization (as types of interaction about (through output and control influenced by the need for systems, and it is thoroughly mathe- though, need not have any of these l What will our agent do in a given environment? l Under what conditions will it achieve its goals or maintain desired relationships with other things? l In what kinds of environments will it work? aspects of an environment, l How do particular the workings of artifacts, affect particular that have particular properties? interactions such as topography or mutability or in types of agents’ abilities to engage l What forms of interaction require an agent to employ particular elements of internal architecture, such as memory? to make any a prioti of our agents. To the contrary, l What forms of interaction permit an agent to learn particular knowledge or skills? the about in as general a and theory can in this special double volume, some is and no single To ask these questions, we do not need architecture way as possible, forms of interaction give a complete though, each provide detailed particular thus explicitly is to understand, the properties of agents, environments, examples of the analysis of interactions within in approach, advocating no single architecture among them. Of course, account of this vast topic. The papers the relationships between This special double volume domain of architectures and environments. that any single it is doubtful assumptions ecumenical the point PE. Agre/Art$cial Intelligence 72 (I 995) l-52 3 the shared formalism. Through of interactions, we hope that each project can benefit can benefit from the three-dimensional can offer. themes that arise within picture of research the principled characterization from the others, and that readers in this area that this approach This introduction cannot attempt a complete synthesis of research in this area, nor is it reported representing the research a definite group or movement. together with examples and conceptual discussion. as follows. Section 2 outlines research on interaction Instead, in this special double volume and technical world. It is organized that arise when doing computational it offers one perspective in the larger is situated a series between agents In so doing, the territory of research covered by this special double reported for further the individual papers in this and their to one another. Section 5 presents a case study in the ideas of the special a manifesto on how intellectual of themes and their environments, it also specifies more precisely volume. Section 3 describes here and research computational special double volume, offering comments relationships double volume. Section 6 concludes with a prophesy research. between in other fields. These connections may provide research on interaction. Section 4 summarizes and plea for interdisciplinary the research inspiration on their distinctive the conceptual contributions connections 2. Studying interaction It is far too early to assemble through and agency. of interaction have been developing computational which offered here should be understood things to formulate research reported here and through the existing it builds. Putting words to these intuitions It is possible, the progress of research though, a rulebook for research into computational to convey some of the intuitions in this area, both theories that the traditions of research upon is a hazardous matter, and the words as heuristic devices, as first passes, and as invitations through in different ways, through different metaphors. 2.1. Mapping the territory to define carefully the scope of research reported here. Let us to the number of agents involved it is necessary research on agents interacting with the world to be arrayed in a two-dimensional First imagine and field, with one axis corresponding the other axis corresponding to the degree of realism with which the world is modeled. (See Fig. 1.) A single agent interacting with a very simple world would lie toward the in to model human origin of this diagram. Any project a realistic way would lie in the upper-right the in three areas: future simple environ- in enough detail life, or the lives of most animals, corner of the diagram, and that is surely research clusters interacting with relatively are analyzed ideal of much of the field. As it is, most current in the interaction ( 1) Research single agents that explores ments, where particular aspects of the environment to bring out larger points. (2) Research on relatively complex extremely simple environments, where forms of interaction the interaction among is largely several agents symbolic in and FE. Agre/Arti’cial lnfelligence 72 (1995) 1-52 many Number of agents Area 3 a few Area 2 one I Area 1 IOW high Complexity of environment Fig. I. Current Al research falls mostly into three clusters. which can be contrasted according to the degree of complexity of the environments they deal with and the number of interacting agents they employ. depends the interaction. little on the agents’ bodies. The emphasis is on the logical structure of agents in slightly in some way on (3) Research on relatively simple interaction among numerous in this special double volume more complex environments, where the interaction does depend the agents being embodied. The agents may be physical and the emphasis robots or simulations, is on the emergence of order from simple forms of interaction. The papers three clusters, with the exception of the paper by Shoham and Tennenholtz, which lies in the symbolic third. As a result, numerous to an forms of interaction an important goal for the exploration of the middle regions of the diagram, future, and we hope that the analyses developed here will contribute their part to that project. issues go unaddressed here, including of the three approaches, in the first of these among agents. lie exclusively is obviously Integration important leading 2.2. Planning and reaction Computational research on interaction historically been structured by two sets of ideas: a dominant ning” and a subordinate tradition ideas will make the distinctive position of the research reported here much clearer. focused on “reaction”. Careful consideration has focused on “plan- of these their environments agents and tradition between Although the term “planning” is not always used with great precision, to the notion of organizing program-like wards through these is Karl Lashley’s 1951 lecture “The problem of serial order in behavior” let it refer here and execution of computer- [ 73 > . This idea can be traced back- the most important of [ 493. As the history of AI to a number of sources. Perhaps structures called plans the construction symbolic through action (cf. FE. Agre/Artificial Intelligence 72 (1995) I-52 5 a neurophysiologist vitally concerned with the workings of human brains, Lashley urged an understanding of cognitive processes whose prototype was the phonetic structure of language. Utterances of language have a formal structure of great intricacy whose basic elements, the phonemes, follow upon one another so rapidly that the structure simply could not emerge through the chaining together of behavioristic stimuli and responses. It follows, Lashley argued, that the brain must be capable of generating these structures on its own internal resources. Moreover, Lashley proposed understanding all human action on the model of language. The job of the brain was to string together the “‘expressive elements” (by analogy to words or lexical units) by means of “the syntax of the act” (the grammar of action) in accord with the “determining tendency” that the action is intended to express. Al- though the theoretical vocabulary has changed, the general shape of this proposal was enormously influential [ 31. In a more familiar AI vocabulary, Lashley is suggesting that the brain generates sequences of primitive actions by applying stored habitual schemata. The vague idea of “determining tendency”, which Lashley abstracted by analogy to the semantic content being expressed by a linguistic utterance, has been replaced by the simpler notion of the goal to be achieved at the end of an action sequence. Another influential early proposal, better known in the AI world because it was ac- companied by computer models, was Allen Newell and Herbert Simon’s computational model of problem solving based on search [ 591. Although linguistic metaphors were not central to their exposition, their proposal was similar to Lashley’s. Thought was held to consist in a process of search through a space of possible sequences of “operators”, some of which correspond to desirable situations which might be understood as problem solutions or goals. The term “planning” entered the AI lexicon as one of the heuristic devices that could abbreviate these searches. According to Newell and Simon’s concep- tion, planning takes place when a coarser search space is used to guide the exploration of a finer (and thus combinatorially much larger) search space. This notion of nested search spaces aligned neatly with the formal concept of the hierarchical decomposi- tion of action that was already found in research on linguistics. Each utterance has a grammatical structure that can be drawn as a hierarchical parse tree, with each lexical item itself having a hierarchical structure of syllables and phonemes. To researchers such as Newell and Simon, hierarchical decomposition held the promise of a universal structuring principle for human cognition. The ideas proposed by Lashley and by Newell and Simon were combined in the first synthesis of the computational theory of planning, Plans and the Structure of Behavior by George Miller, Eugene Galanter, and Karl Pribram [57]. There one encounters the first recognizable definition of “Plans”: A Plan is any hierarchical process in the organism that can control the order in which a sequence of operations is to be performed. 157, p. 161 Note that a Plan here is not necessarily a symbolic mental structure. It is less specific than that: a “hierarchical process” specified in terms of its ability to structure (in Lashley’s terms) the serial order of the organism’s behavior. Miller, Galanter, and Pribram’s conception of a Plan shaped later AI research in numerous ways. But the most important of these for present purposes is a persistent ambiguity throughout the whole of their 6 PE. Agre/Arti’cial Intelligence 72 (1995) l-52 book between two conceptions of Plans and their use: ( 1) A notion of “Plans”, a relatively fixed repertoire of commonly tures of action. Miller, Galanter, come from. The Plans are hierarchical bled into larger structures by treating In more recent AI work, this would be called a “plan and Pribram give no account, however, of where employed struc- library”. these Plans in their structure, and they can be assem- them as elements in a larger hierarchy. structure or process which provides a (2) A notion of “the Plan”, a hierarchical transcription (in linguistic sort of running behavior. No commitment arises, and it could perfectly well be improvised the sole constraint hierarchical that it be possible in nature. to the process terms, a parse tree) of the organism’s this Plan to moment, with in retrospect as having been from moment by which is made here to the mechanisms These two concepts correspond are commonly though, book, it clear why. A computational makes known as “planning” they are conflated conceptually and “reaction”. to two strands of research in AI, which In Miller, Galanter, and Pribram’s in a wide variety of ways. Brief reflection on them theory of action has at least two central goals: l to explain how action has the structure l to explain how actions are chosen it does, and that are appropriate to the circumstances in which they are taken. through it arises action has the structure the question of structure: it The notion of “Plans” addresses the execution of things called Plans does, says this theory, because account which have that same structure. Yet this theory does not provide a convincing if the organism of how these actions are adapted about action can be then rational decisions is wholly made a priori, before the execution of one of these Plans. And this may indeed be true for short stretches, as when uttering a single word or phrase. But Miller, Galanter, and Pribram wished life, in which a wide variety of contingencies to their circumstances. Of course, the whole structure of everyday in control of the circumstances to explain arise. including It allows this need. can be added since elements at the very moment when The notion of “the Plan” addresses for a greater degree of structure of the Plan improvisation, to be at any time, it does. executed. But it offers no account of the reason why action has the structure Action is wholly in nature, but the particular unspecified. Miller, Galanter, and Pribram do not seem aware of the problem, most likely because frequently back and forth between them as the details of their argument demand. they do not clearly distinguish between those Plan elements are about shape of the hierarchy their two proposals, to the hierarchical is still hierarchical shifting in Miller, Galanter, tradition of research [ 221, a long and Pribram’s and Pribram’s book foreshadowed the outlines This ambiguity decades of research. Starting with Fikes and Nilsson’s STRIPS of three subsequent its attention on the first of Miller, program and executed Galanter, as packages, to provide an organism or robot with a repertoire of habitual patterns of action for future occasions. STRIPS did in the address focused execution process simple upon [23,24]. But for the next decade or so, research generally in a simple way through certain flexibilities that of Plans which are constructed process, assuming plan execution and which might be stored the question of improvisation the plan-construction to be a relatively concepts, libraries focused in Plan l?E. Agre/Arti$cial Intelligence 72 (1995) 1-52 7 line of research matter. This 1980s as researchers began more formal problems gave rise original story was missing. terms, and to explore into plan-construction to a new phase to cast the classical problems of plan-construction in the late in much to which these formalized [ 14,31,42,55]. Yet all along, half of Miller, Galanter, and Pribram’s the mathematical questions shifted [4,26,28,68,70]. These “reactive” This situation was remedied action” or (somewhat unfortunately, in the mid 1980s with the rise of what has come to be in my own view) “reactive plan- systems should be understood not as a radical in a hole in the existing the other half of Miller, Galanter, the environment interaction with called “situated ning” departure, but as filling as reinventing phasis was on perception-action of moment-to-moment how the organism or robot’s actions could be guaranteed nal, and so on. Conflict between each school has been able to point at substantial weaknesses of the other’s mechanisms without always possessing own. system of ideas around planning- and Pribram’s theory. Here the em- and on the role of tightly coupled activity. Just as planning offered no robust account interaction with the world, reaction offered no robust account of to “work”, understood as ratio- the two schools of research has often been heated, as the weaknesses of its loops in organizing the necessary to appreciate concepts Observing this impasse, a substantial literature immediately grew up attempting (e.g., theories realizing recapitulate the planning and reaction and reaction (probably without and Pribram attempted through “hybrid architectures” it) this same attempt at reconciliation. through rhetorical ambiguity and logical thesize Just as Miller, Galanter, oncile planning (again, probably designers of hybrid architectures In each case, the implicit project without realizing views is to fashion a whole theory out of two half-theories theory might work out, and prob- of action. Although such research able that the resulting architectures may have some practical applications, will most likely be frustrated concep- tual framework. These things are easy to see with the benefit of hindsight, of course, but it is important for computational in its forward progress by its lack of a consistent because of their substantial theories of action. them nonetheless that the resulting in computational it is conceivable that presuppose improvisation, to recognize incompatible implications terms to syn- [ 25,621. it) to rec- the It is the central purpose of this special double volume to overcome though research is not necessarily that will reconcile and reaction. The point the structure of behavior informed by new ideas will presumably split between planning and and reaction by providing the dynamics impasse between planning and newer architecture, that direction, but to identify some concepts and methods of research the unhappy both environment. are not ruled out a priori. To reconcile planning accounts of its Symbolic plans might play a role in this story or they might not, but they thing is to focus upon the structures the important of interaction between agents and their environments. Every agent that undertakes actions it is symbolic in some world has a structure of interaction with its environment, whether or connectionist, whether it has internal state or not, and so forth. To focus on interactions is not to legislate impose a stiff constraint a focus on interactions does interacting with an on the research process. Given an agent these things ahead of time. Nonetheless, interactions with of an agent’s and reaction, interesting the conceptual to offer a better lead in 8 FT. Agre/Artificial Intelligence 72 (1995) l-52 and different has no single definition, one must ask this question: “why do we think it should work?“. Of course, research programs can legitimacy. The proposal of to of the agent’s interactions with its environment. As to cast a wide theories, environment, the notion of “working” pursue a wide range of notions of “working” with equal this special double volume formulate principled characterizations noted at the outset, net, including explanatory Whatever symbolic theories, biological and social theories, and so forth. the phrase “principled informal characterizations” theories, to this question will require researchers is designed and quantitative research on planning is that approaches both formal and and prescriptive its faults, the agent’s actions ought the designer can be assured then stable, it, and in ways proceeds that the agent search process of its interaction with to work. The environment in the sense interaction some kind of search process. The agent its environment why basically tion within through acterizations for an adequate plan halts ally work-the will work. (In the case of probabilistic will be probabilistic provably be imposed upon that malism within which a proof of correctness Of course, historically most such “proofs” have been has been at all. in nature.) The problem, of course, systems that produce correct plans correct plan-construction is effectively proving the world-roughly, to construct planning systems [45], assumed is the only significant is usually that can be anticipated does at least offer a clear account of to be source of disrup- in advance all of the char- if its search that that plan will actu- that some such plan the proposition being “proved” is that the design of such formulates it needs, and itself that the theorem requires that highly the world be representable can be performed restrictive conditions using a for- as a practical matter. though, if they halt with any plan informal. The point, The accomplishments of this research should certainly not be underestimated. that AI research has investigated. Research on principled It is not a simple matter to obtain any kind of correctness proof in domains as formally complex as those of interaction will surely build upon this existing work in a wide variety agent-environment of ways. At the same time, it will also incorporate a wide variety of other influences. The remainder of this section sketches results from this still emerging the outlines of the approach characterization to AI research synthesis. that 2.3. Correspondence and convergence How does one argue that a particular internal between representations agent-environment in AI research has been to formulate arguments interaction will work? By in terms and the outside world. In a simple that the agent has correct that correctness far the most common approach of correspondence form, such arguments work by induction: knowledge of the world at some initial that the of knowledge is preserved If the agent’s knowledge of the world will remain correct for as long as it takes actions. the correctness of an agent’s actions agent can then be shown this correspondence method of argument with a broader convergence method that is employed by many of the papers in this special double volume. is guaranteed by the correctness of its reasoning, to “work”. This section contrasts time, and if we can demonstrate to the next, then it follows from one unitary action if it is assumed l?E. Agre/Arr$cial Intelligence 72 (1995) l-52 9 The correspondence method may seem unfamiliar when stated in the abstract form provided in the previous paragraph. Nonetheless, it is precisely what is at stake in attempts to solve the frame problem. Understood in its broadest terms, the frame problem is a lemma that must be proven in the midst of any attempt to design a plan-construction program. It asks, given that the agent correctly anticipates what the world will be like up to a certain point, how can it infer what the world will be like after a particular action is taken? In particular, which of the agent’s beliefs can be assumed to stay in correspondence with the world after the action is taken? Answering these questions is a difficult matter, since it can take real work to infer all of the consequences of a given action. These consequences might be hard to catalog, yet we would not wish an agent to become disabled worrying that opening a door might have consequences far beyond its reasonable surmises, for example causing the sun to fall from the sky. Technical and philosophical research into the frame problem has determined that it can be usefully decomposed into a variety of separate problems [65], but this decomposition does not matter for the purposes of the present argument. The point is simply that the frame problem arises as part of any attempt to argue for an agent’s correctness in a given environment by means of the correspondence method. Some authors have made strong claims about the theoretical implications of the frame problem. Toth [73], for example, argues that the frame problem is fatal for a certain conception of AI research, whose unit of analysis is the individual’s cognitive process. Likewise, the difficulty of bounding the necessary inferences from a given action is reminiscent of Dreyfus’ [20] argument that real-life reasoning takes place against a large enough unarticulated background that attempts at logical formalization necessarily encounter an infinite regress of rules-about-how-to-apply-rules. These arguments should not be interpreted as grounds for the categorical rejection of a tradition of research, but rather as roughly indicating the contours of a complex phenomenon. Indeed, the paradoxes of the frame problem may simply be, at least in part, an inherent condition of life that is “solved” piecemeal by real agents through learning in particular cases. Although it is not possible to resolve the question here, we can explore how the question arises through the concepts that have historically guided AI research. The correspondence method makes fairly specific assumptions about the process through which agents choose actions. These assumptions are not necessarily architectural in nature: the reasoning processes that encounter a version of the frame problem might operate on symbolic structures in an agent’s memory, but they might also potentially be encoded in hardwired circuitry, simulated through neural networks, or subserved implicitly in the operation of other types of machinery. The point, though, is that the designer is approaching the design process in a certain way, maintaining a sense of the representational content of various machine states and making sure at all points that the correspondence method of argument constrains the design process. This procedure might be contrasted with the convergence method. Here the design process is also constrained by an argument about correctness, whether formal or informal. The difference is that the method of argument focuses upon the agent’s behavior and not on its internal states. Put another way, the method focuses upon particular relationships between the agent and its environment, characterizing these relationships in principled ways and making arguments about their invariants and their evolution. This approach is IO PE. Aqe/Arti/icial htelli~encr 72 (1995) I-52 from the correspondence method; not wholly distinct the correspondence method as a particular case-the of semantic correspondence. that the agent is necessarily many other kinds of evaluation is that principled are possible as well. arguments The point it is a larger category relationship is a little misleading that includes in that case being one in suggesting The term “convergence” evaluated by its eventual arrival at some kind of goal, but about correctness can be formulated in a than referred an exhaustive for the agent’s to find what it is looking states. To take a trivial example, to this sort of thing as “external memory” search of a finite physical homing an agent territory, placing breadcrumbs in on spots without breadcrumbs, Some of the most important in the physical world, without that on in terms of correspondence. identified by these arguments might be located internal variety of ways other invariants any regard performs each spot already searched and continually for within a certain amount of can be easily demonstrated and did time. Early AI theorists than not regard it as significantly internal memory too simple once we take account this view is surely of the geography of the physical world and the capacities of our organisms’ physical from bodies, note that the proof of correctness proofs of program correctness (the a progress total of spots searched and unsearched), (the number of spots still unsearched), (no more spots unsearched). Other arguments condition for correctness might employ considerably argument will depend on some kind of principled not necessarily an adequate argument familiar in computer science. The proof involves an invariant function of every detail of the interaction, for this simple agent is entirely just enough of its properties for cognitive architecture In each case, though, different methods. of the interaction- and a convergence in its implications to be formulated. [ 1,2]. Although characterization to allow different the achieve between “beliefs” the agent that employs to demonstrate is a finite being in a complicated world, to decide what actions seem indicated for research on agents an agent with a traditional Another example may help to illustrate one of the correspondence method’s in environments with much qualitative set of symbolic inher- structure. ent limitations logical Consider in particular reasoning, based on these beliefs, it will probably situations. Since that the have mistaken beliefs occasionally. Yet it may still be possible agent will necessarily its goals anyway. Such a demonstration might proceed in several different ways, but in each case it will take into account specific properties For example, different paths of the relationship the agent and its environment. certain properties of may be easily distinguishable the its environment, routes. Likewise, situa- environment may be provided with signs that disambiguate tions that the agent might encounter. As with any other theory of erroneous beliefs (for in a principled example in way requires an error model-a that mistaken belief might take place that mistaken actions will necessarily provoke safe beliefs will necessarily get corrected, of the difficulty, or that uncorrected mistaken beliefs will lead at worst to indications alternative In each solution paths case, the argument proceeds on the convergence model, even though symbolic beliefs arguments might rest on the correspondence model. are present and other, is registering so long as the agent against ending up on unintended research), theory of the circumstances [77] ). One might be able to demonstrate in computer perception through which errors all of the ambiguous that are quantifiably than the optimum. thus guarding less desirable demonstrating such things interrelated (cf. PE. Agre/Art$cial Intelligence 72 (1995) 1-52 11 A simple example might be provided by the control-theoretic uncertainty certain known bounds. A controller desired behavior that is robust under for all the possible plants consistent with these constraints. notion of robust control: that plant parameters are within the is characterized by assuming these conditions about the plant produces These examples of this introductory in this special double volume interactions simple and abstract, meant are obviously article will explain some of the concepts to develop more sophisticated for illustration. The rest that have led the authors about forms of argument between agents and their environments. 2.4. Aerial and ground views agents and agency in research on interaction Another helpful distinction aerial and ground views of an agent’s activities. When designing abstract territories in any real sense, about a situation not crucial when the design process since environment supposed it suffices but the whole point of the correspondence method which permit is that between in that operate such as search spaces, and that do not have bodies (simulated or not) between what the agent knows it can be easy to lose the distinction is and what the designer knows about is being constrained by the correspondence method, about its it is that proof, since in a generalized way off-line, those facts to do. The agent need not be capable of actually performing for the designer to permit a proof to be constructed that the agent will do the things that situation. This distinction it to get along successfully. in that case it is important for the agent to maintain is that the agent knows enough knowledge to have conducted the proof This that a large number of conditions is not true with the convergence method. An agent designed using the conver- (or it might not), but this support a proof of convergence. The designer might be gence method might be spoken of as having knowledge knowledge need not necessarily able to demonstrate together with the agent’s achieve around will have great trouble knows one particular world prove that the agent will get where it is going, regardless of whether be sure of this. about that the agent will be able to to find its way in a world where such signs are sparse, but if the designer to the agent itself can its goals. For example, an agent to have been adequately posted that relies upon posted signs the agent’s environment, then it will be possible states, afford a proof internal straightforward This too is obviously a trivial example, and it is also a conceptually that the agent is spoken of as having knowledge-the and in the sense is understood the relationship the designer-for example tion concerns Things become more from of knowledge to its surroundings-or reference maintain the particularities relief-and having a body, being so forth. between interesting when the agent’s knowledge-set the agent only ques- the designer’s. to have different kinds indexical knowledge of its relationship terms, without to important so that can come out in full so that new theories about knowledge can arise that are rooted in the agent’s interacting with artifacts, and In such cases, it becomes particularly is spoken of in wholly different to notions of knowledge. a rigorous conceptual the agent and the designer, in a physical environment, separation between to its environment when the agent of the agent’s relationship example, located 12 PE. Agre/Arfijicial Intelligence 72 (1995) 1-52 for computational The general point ies, and embodiment and learning. knowledge, perception, bodies, embedded in physical environments, the world. These limited regions are not accidental or arbitrary structure hills and roads and walls and tools, and the causal interconnection partialness of the agent’s access to these things already has significant consequences complete world models. theories of action is that agents who are interacting with physical worlds have bod- theories of action, has pervasive consequences agents with only have direct access to limited regions of in their shape, but have a like of things. The simple for that is made from the geometry of the space, the shapes of physical objects In large part this is due to locality: to have substantially that require agents indexicality: or McDonald’s is involved with But more subtly, is, nor which particular it might be dealing with at any given the local structure of an agent’s involvements with the world brings a pervasive this place, the agent to those involvements interacts now with these artifacts. The agent does not necessarily faces in this direction, stone know where it is, nor what time it is, nor what its heading this or can-opener forms, would suggest ensuring fact, the correspondence method, at least in its traditional to all these questions. The agent might possess that the agent always know the answers and so a compass and a clock and a map, objects might be labeled with their identities, on. Another approach, compatible with the looser demands of the convergence method, is to explore (“this bike here now”) the relationships (“Karen’s bike in Miami on Christmas”). and the more objective kinds of knowledge indexical Perception register “red” at a specific hand does not close world is to do things with your body, and your body is a physical in the same locality and the same concrete particularity in character: your retinas do not latitude and longitude, but rather “red here”. Likewise, your the door to room 317, but rather “this door”. To interact with the and action, after all, are inherently thing that participates indexical knowledge as any other. time. Given between It is this materiality of embodied action that makes the distinction between taking a metaphorical the aerial position view and the ground view so compelling. The designer, above the territory, can know a wide variety of things that an agent resting in a particular spot on the ground, with a particular heading, may not know. The agent’s knowledge those and ignorance are structured phenomena, structures. An agent might be going around it, but the designer might be in a position the conditions under which the agent can and cannot avoid such a fate. An agent might be at risk of running out of stove burners it is too late, but the designer might be able to demonstrate without that stove burners will necessarily be plentiful unless certain supplies run low. An agent may continually lose track of its tools, but the designer might be able to demonstrate that the tools will remain accessible back where they belong. so long as the agent makes a habit of putting in circles without ever knowing and it is the designer’s job to understand to characterize realizing it until them 2.5. Structure in the agent and the world the outlines of this emerging Having established things can be learned from in which agents are adapted perhaps most familiar from biology, the most it? Perhaps important to their environments. Although notions of adaptation lessons concern the most style of research, what kinds of the ways are in the ideas about adaptation important f?E. Ape/Artificial Intelligence 72 (1995) 1-52 13 In his pre-AI book Administrative Behavior [ 7 11, history of AI are actually sociological. Simon outlined many ways rationality” organization, Likewise, compensates formation precise tasks, compensate usefully bureaucracies and goals. formats of that organization, the organization for individuals’ compensates for their through in which social organizations of their members. The orchestration Simon argued, compensates for the individual’s the division of labor and the assignment limited abilities to learn new compensate for the “limited of numerous workers within a larger for work. limited capacity tasks to individuals of specialized tasks. The flow of structured and limited knowledge, in- the for their compensates in making decisions. Finally, Simon believed together with the precise definition of individual limited abilities to absorb information that the hierarchical to adopt it and apply structure of their own values for individuals’ limited abilities imagined cognition in this analysis, cognitive environment to studies of individual from studies of organizations influence on AI. This influence, in AI research has generally been Whatever the value system implicit the general though, has been except in the matter of goals, which in practice have almost form of argument indirect. When in the did not survive isolated and invariably been logic the general form of argument outlined has had an important Simon moved 1950’s, most of these ideas about the individual’s the transition. The individual self-reliant, assigned of the enterprise, AI researchers have rediscovered for the weaknesses in Administrative Behavior: cognitive architectures. Some of these weaknesses might be imposed by the designers, example when the goal is to explain human processing from the weaknesses of all known architectures, or they might be inherent computational limitations Despite of for or they might derive from the outside by the system’s designer. Yet almost through the inherent in the world compensates problems and the like. the most significant from undecidable shortcoming limitations, structure It is quite plausible [ 33,401). Unfortunately, deriving this insight, perhaps tive” systems and “hybrid” planning-reaction for discussing the useful and constrained microworlds sized environments which are “uncertain”, the like (e.g., general about environments and not-that. fact wholly untenable, forth that no organism (Of course, and other profoundly military discourse.) But given intractable become ronment increases more of that complexity), world-and tenable. or undecidable (or, more precisely, it becomes interaction with of the agent’s these negative adversarial activities, architectures is a relative structures of the world. When breaking of classical planning research, “unpredictable”, “complex”, that are characterized it is next to impossible in these negative in the sense above a certain primitive that, by some measure, most environments unpredictable, survive that they are so uncertain, level could possibly characteristics may be viewed as constitutive and they are certainly that the classical problems of plan-construction of research on “reac- lack of concepts free from the safe these new schools empha- and ‘changing”, to say anything very terms, as not-this are in and so in them. of warfare part of American rapidly of the agent’s envi- registers more and the features of a given in that world make life as the qualitative complexity as the planning imperative to discover formalism the world-that To be sure, AI research has employed a variety of concepts of “structure”. Marr [ 521, each that posits a set of modules, a method of vision for example, outlined research 14 7: Hogg et al./Arti$cial Inrelligence 81 (1996) I-1.5 I 2 1 I T. Hogg and B.A. Huberman, Artificial intelligence and large scale computation: A physics perspective, Phys. Reports 156 ( 1987) 227-310. I22 I T. Hogg and J.O. Kephart, Phase transitions in high-dimensional pattern classification, comput, sysr, Sci. Eng. 5 (4) ( 1990) 223-232. I 23 I T. Hogg and C.P. Williams, Solving the really hard problems with cooperative search, in: Proceedings AAAI-93, Washington, DC (1993) 231-236. I24 I T. Hogg and C.P. Williams, Expected gains from parallelizing constraint solving for hard problems, in: Proceedings AAAI-94, Seattle, WA ( 1994) 33 l-336. I25 1 T. Hogg and C.P. Williams, The hardest constraint problems: a double phase transition, Artif: Intell. 69 ( 1994) 359-377. 126 1 J.H. Holland, Adaptation in Natural and Arhjicial Systems (University of Michigan Press, Ann Arbor, Ml, 1975). I27 I B.A. Huberman and T. Hogg, Phase transitions in artificial intelligence systems, Artif Intell. 33 ( 1987) 155-171. I 28 I M.T. Jones and FE. Plassmann, A parallel graph coloring heuristic, SIAM J. Sci. Compuk 14 (3) ( 1993) 654-669. I29 I A. Kamath, R. Motwani, K. Palem and P. Spirakis, Tail bounds for occupancy and the satisfiability threshold conjecture, in: S. Goldwasser, ed., Proceedings 35th Symposium on Foundations of Computer Science (1994) 592-603. [ 30 I I? Kanerva, Self-propagating search: A unified theory of memory, Technical Report CSLI-84-7, Stanford University, CA ( 1984). 131 1 R.M. Karp and J. Pearl, Searching for an optimal path in a tree with random costs, Arri$ Well. 21 (1983) 99-116. 132 I S. Kirkpatrick, C.D. Gelatt and M.P. Vecchi, Optimization by simulated annealing, Science 220 ( 1983) 67 l-680. { 33 1 S. Kirkpatrick and B. Selman, Critical behavior in the satisfiability of random boolean expressions, Science 264 (1994) 1297-1301. 134 1 J.R. Koza, Generic Programming: On Programming Computers by Means of Natural Selection and Genetics (MIT Press, Cambridge, MA, 1992). I 35 I T. Larrabee and Y. Tsuji, Evidence for a satisfiability threshold for random 3CNF formulas, in: H. Hirsh et al., eds., AAAI Spring Symposium on AI and NP-Hard Problems (AAAI, Menlo Park, CA, 1993). I361 M. Lau and T. Okagaki, Applications of the phase transition theory in visual recognition and classifications, J. Visual Commun. Image Representation 5 (1) (1994) 88-94. 137 1 G. Lewandowski and A. Condon, Experiments with parallel graph coloring heuristics, in: Proceedings 2nd DIMACS Challenge ( 1993). I 38 1 A.K. Mackworth, Constraint satisfaction, in: S. Shapiro and D. Eckroth, eds., Encyctopedia ofAI (Wiley, New York, 1987) 205-211. I39 1 C.J.H. McDiarmid and G.M.A. Provan, An expected-cost analysis of backtracking and non-backtracking algorithms, in: J. Mylopoulos and R. Reiter, eds., Proceedings IJCAI-91. Sydney, Australia (1991) 172-177. I40 I S. Minton, M.D. Johnston, A.B. Philips and P. Laird, Minimizing conflicts: a heuristic repair method for constraint satisfaction and scheduling problems, Artif: Intell. 58 ( 1992) 161-205. I41 ] S. Minton and I. Underwood, Small is beautiful: a brute-force approach to learning first-order formulas, in: Proceedings AAAI-94, Seattle, WA ( 1994) 168-174. I42 1 D. Mitchell, B. Selman and H. Levesque, Hard and easy distributions of SAT problems, in: Proceedings AAAI-92, San Jose, CA (1992) 459-465. I43 1 A. Nijenhuis and H.S. Wilf, Combinatorial Algorithms for Computers and Calculators (Academic Press, New York, 2nd ed., 1978). I44 I J. Pearl, Heuristics: Intelligent Search Strategies for Computer Problem Solving (Addison-Wesley, Reading, MA, 1984). [ 45 1 J. Pearl, Probabilisric Reasoning in ln~elligen~ Systems: Networks of Plausible Inference (Morgan Kaufmann, San Mateo, CA, 1988). [ 46 I F? Presser, An empirical study of phase transitions in binary constraint satisfaction problems, Technical Report AISL-49-93, Department of Computer Science, University of Strathclyde, Glasgow, Scotland ( 1993); also: Artif: Intell. 81 (1996) 81-109 (this volume). FE. Agre/Artificial Intelligence 72 (1995) 1-52 15 include what AI has historically called “the domain” ? The various papers in this special double volume, which are summarized in a later section of this introduction, make numerous suggestions. By way of general orientation, though, here are some general categories that might aid the search for structure: l Artifacts. How do the properties of tools simplify the reasoning that decisions that agents must undertake in choosing actions? How about buildings and streets? How about clothing and furniture? l Signs. Where are signs placed in the particular world being studied? What do they say, and what assumptions about knowledge do they make? What other sorts of symbolic labels are placed on things? What kinds of instructions are provided? Does the language in those instructions have any reliable properties? l Physical dynamics. What rhythms are established in a particular category of phys- ical interactions with an environment? What properties of those interactions are conserved or remain invariant? Under what conditions do they converge to attrac- tors or remain bounded by certain envelopes? Why? l Customs. What conventions do the agents in this world maintain? If the agents can rely upon one another to maintain these customs, how can this simplify their reasoning? What invariants do these customs maintain in the physical world? l Practical constraints. What orderings upon actions are dictated by plain physical practicality? A cupboard must normally be open before objects can be retrieved from it. Although often possible, it is usually impractical to put on your pants after putting on your shoes. You cannot normally pick something up without being near it. You cannot bake bread every day without periodically obtaining fresh supplies of flour. The sheer mass of such constraints will tend to channel activity in particular ways. l Learning situations. In what situations are agents called upon to do something new? Do those situations have any reliable properties? Does anyone or anything ensure that agents need only perform reasoning that is incrementally more complex than they have performed in the past? When and how can the agent get help? l Mutual adaptation. Does some pressure operate to incrementally adapt various en- tities to one another? Examples might include biological coevolution, accumulation of shared knowledge in joint activity, and moving parts wearing together. Each of these cases obviously has its own particular logic and its own way of conceiving adaptation. l Inertia. Are there limits to the possible rates of change of important things in the world? Does this inertia provide agents in that world with a margin of safety in uncertain situations? Does it guarantee that dangerous situations will be detectable before they cause permanent damage? l Locality. Are the effects of actions confined to relatively limited parts of the world? Such locality effects can arise either through physical distance or more subtle routes of causal connection. Do these effects simplify reasoning or perception? In particular, do they guarantee that particular important circumstances will be perceptible when the agent needs them to be? Do they provide provable bounds on the possible harm that mistakes can cause? l Stabilization. (The term derives from the article by Hammond, Converse, and 16 P.E. A,yre/Arrijiciul lntclli~enc~r 72 (1995) I-52 Grass.) What actions do agents in this world take to ensure that the world maintains its computationally useful properties? l Geometry. What properties of the physical environment bound the complexity of the reasoning “bottleneck”, required “critical path”, “hillclimbing”, and so forth? to act or learn in it‘? Are there useful notions of “diameter”, and “perception” These are elementary terms such as “reasoning” In hinting at their computational examples of the kinds of structure ramifications that one might seek in the here, it has been necessary tend to presuppose are not neces- in this special double volume will illustrate, analysis of the environment. to employ particular architectures or philosophies of activity. But such commitments sary a priori. As the articles and structures of the world can be conducted relationship the point on a wide range of agents to the world of structure will be shaped by the needs of the architecture. What is the architecture good and bad at? When has the necessary computations been impossible or intractable? And so forth. the questions one might address in a wide range of worlds. of scaling up? When have between agent architectures is to simplify computations, In each case, since fragile or incapable that might it been between to prove in explicit knowledge the designer and methods of argument in the world, corresponding inspire the designer In particular, one should distinguish these structures might that enable two uses that a designer might make to the aerial view or the ground view. of these structures about structures of As part of the aerial view of the agent’s activities, that the agent’s activities will neces- the world might enable the devel- sarily have certain properties. For example, to demon- opment of formalisms strate convergence in to set goals. As a separate matter, knowledge the world might also be part of the agent’s ground view of its situation. The agent might engage it might commu- these structures with other agents, or it might even use its ideas about nicate about them as the need arises. the structures to set about creating, maintaining, to the designer’s The agent’s understandings understandings. understanding the world, or it might have a simplified or comparatively signer’s understanding, increments views of the world will help designers tions world. of shallow version of the de- itself by for the aerial and ground keep track of the wide range of design op- of the agent’s need not correspond The agent might have a subset of the designer’s or it might slowly discover Clearly distinguishing that are compatible with any particular designer’s understanding and approximations. of its environment that understanding these structures, about structures or restoring reasoning symbolic between about A focus on structures in the world and upon principled has a further benefit. When research is focused upon architectures intellectual little lines of research. Discoveries room exists for interchange between about structures the other hand, might be useful on architectures. Different but each project can research projects may employ learn valuable interactions, different vocabularies, the others have moved back and forth between the design of agent and the exploration of structures of the world and properties characterizations of in- and researchers pursu- in the world and prop- employ- to researchers incom- the ways archi- interac- lessons from of teractions mechanisms, ing different erties of ing radically mensurable that tectures tions. PE. Agre/Artificial Intelligence 72 (1995) I-52 17 2.6. Units of analysis within engaged ideas were influential and values of AI is a powerful battles. One factor contributing occurring between “cognition” The earliest internal cognition, sense of an embodied All of this attention to activities in the world can be misleading when it is viewed from the context of the history of AI. Founders of AI such as Newell and Simon were as were other authors such as Lashley whose in the concepts born of the field’s founding in the development allergy in a fight against behaviorism, of AI. As such, embedded to behaviorism Perhaps as a result, research on agents’ texts of AI were mostly framed with terms like “thinking” perhaps with occasional perceptions agent’s continual and structured to this allergy inside agents and “the world’ that pointed is a powerful distinction made within AI located outside of them. to and actions but with no strong in an outside world. can sound that would ideas in his article on the for computational interactions with their environments for research it is easy enough involvement like covert advocacy of behaviorism. ideas rebel against AI’s conventional such as the stimulus-response chains structure of serially ordered behavior. The central conceptual challenge research on interaction which does not fall into either extreme. Indeed, to slip into a reliance on behaviorist-type that Lashley argued against is to formulate AI problems and methods and agency in a way Borrowing a term from sociology, the conceptual issue here concerns the “units of that human a certain degree of that occur research the things that occur within them and the things between agents and their environments is conducted. There can be little doubt focus of research, between that interactions though, inside and outside. analysis” within which beings and other creatures have skins and skulls which provide causal isolation between outside of them. To the extent provide a useful cross the boundaries to develop units of analysis a world considered people science, can be spoken of as causing effects caused elsewhere. Yet to speak of interactions studying defined that refer to interactions as two separate entities. This proposition inasmuch to happen, or else as being in terms of interactions that In other words, AI research will have to an agent plus to can sound forbidding is not a “thing” that the object of effects than simply concepts be that at least some of one’s fundamental and their properties. What does this mean? it will be necessary as units of analysis to define concepts as an interaction and not simply in computer interactions: is stronger it requires trained To reconstruct this introduction to a refinery through in computational to the control-theory terms the idea of the interaction example with which (or, for that matter, to a walking let us return troller attached series of inputs Long-term observation of these numbers may reveal that they converge or that they enter controller from more precisely. That does not make structure of the behavior interaction as a unit of analysis, began. A con- robot) will receive a long its sensors, and it will produce a long series of outputs as well. to certain values, and frequency. Does the results for it cannot be pinned down any that the in the “located” and plant, and not in either of them separately. cause this behavior? Does the plant cause it? Of course, is (to employ one more term from sociology) into an oscillation with a certain amplitude of the two, and responsibility the behavior mysterious; it only means the interaction the behavior between the controller The notion of units of analysis becomes more important when the agent and its IX P.E. Agre/ArtiJcial Intelligence 72 (1995) l-52 their original each other, so that each one changes and environment states, have had a chance then influencing If we watch the interaction proceed for a moderately are continually environment through the course of the interaction. long period of time, so that both organism to change in large and complex ways from to even are. Of course, one might make a list specify what the agent and its surroundings of every molecule or variable setting or memory address or synaptic weight, but such In such a an enumeration would probably not be a useful or parsimonious case, the very identity of the agent, as well as the identities of the various in its things through which they environment, for arrived at their current states. Again, nothing research to be made about the rationale behind the agent’s architecture about this. The challenge is to develop principled ways of talking about it that allow useful arguments the properties of the interaction, can only be conceptualized in terms of the interaction it can be a challenge and thence about is mysterious and design. description. between subsection. The point in the world” described that certain likely ideas allow us to reformulate in a more sophisticated way the insights about These “structure is not exactly in the previous that the world has structure all by itself, but rather that the world has the kind of structure to the workings of that particular agent. This is a property of the that makes a difference the agent and the world, not of the world alone. For example, we relationship might discover in such a way that human them as they are customarily used. Such hands are minimally to use tools are well adapted It is only in a very narrow sense, then, that the by other species or for other purposes. tool’s adaptation it as a (tool, hand, materials being property of the relationship that only makes sense in the context of worked on, etc.), and specifically in this case, a particular then, is not the tool but rather the customary way of using the tool to interact with the world. tools have come to be designed to slip when using to their customary use, but they might be poorly adapted those entities. The unit of analysis simply of the tool. It is better among a number of entities form of interaction to conceptualize is a property as something among This is progress, but much remains issues is almost wholly to be done. The account of “interaction” individualistic in terms of a single agent’s in this in nature. Its units of analysis, interactions with a struc- from the designer’s aerial To make full sense of these interactions for research on embodied to merge with interaction interactions. Tools and the customary ways of using activities but of a not properties of an individual’s it will be important research on social are generally forms of embodied interaction that offer us considerable in adapting ourselves to a complex world, and computational for analysis of these settings as it does for the more particular research holds types frame research special double volume likewise, tured environment. view, though, computational them, for example, culture’s. Cultures provide guidance as much promise of interaction treated here. 2.7. Representation The revised theoretical orientation suggested here clears some new space for compu- research on representation. tational method and the maintenance So long as research is guided by the correspondence of objective world models, representations have very spe- PE. Agre/Art@cial Intelligence 72 (1995) l-52 19 to do and the respective in consequence are highly constrained the broader perspective suggested here, though, new possibilities cific jobs Within of these have already been sketched. Perhaps most fundamentally, understand couple of feet straight ahead” versus “latitude 41, longitude 13”). Indexical tions are more closely tied, in causal and epistemological circumstances, knowledge Reacting but they are not as well suited for other purposes, about spaces and times to agents at distant or unknown against conventional in their forms and uses. open up. Some to (“a representa- terms, to the agent’s immediate such as distributing locations. to import an encumbering forms of representations roles of indexical designers need and objective computational research on sit- the concept of representation. Authors to say that their agents employ no visual (inner monologues, exist that have seemed assumptions, about obviously this raises [ IO] and Beer [9] have been willing at all. Since representations tactile maps, etc.), serve. Brooks and Beer concentrate that representations theories system of philosophical and architectural uated action has been deeply ambivalent such as Brooks representations imagery, actually mon to suppose Chapman resentation” in which but stable interactional functional “representations” binary argument explore alternatives take another approach, describing the representational relationships roles in the agents’ activities. Whether to the correspondence model. is a valid question. The important in terms of “representations framed concepts which might do similar interactional [4] are late evolutionary elements are not internal between agents and the objects developments a notion of “indexical-functional their attention on insects, and it is com- [ 431. Agre and rep- symbolic structures that serve particular to be called is not to provoke a but to thing, versus no representations”, theoretical work while providing these things really deserve though, the question of what purposes representations reasoning assumptions it is possible it will be valuable in this special double volume demonstrate, to representation. to the question, For present purposes, in AI was tied to architectural for example, explored mechanisms that resembled to take a The perspective advocated here does not dictate and the reality of the matter might be complex to review some of the about theorizing As the papers variety of approaches any single approach and heterogeneous. history of the AI notion of representation. Most of the earliest explicit representation Quillian [66], like structures of a small set of basic units joined by connections with the difficulty of building network clear (e.g., Woods by most of the AI community logic with the whole of AI work [ 271. Concern with the physical has lately crucial Complexity of particular possibilities and processing mechanisms. in network- for automated the structure of the brain, at least in the sense of consisting that can transmit simple signals. Faced these semantic their semantics [ 791)) with the result that the structures were eventually understood first-order been concerned foundations realization of logical reasoning analyses of the problems of making [ 121. has primarily semantics, which has widely been viewed as providing analysis, architecture of a particular class of architectures, [ 381. Subsequent AI research on representation logical research, due to its strong focus on the the type of close analysis has resumed though, does not yield detailed choices. Connectionist of complex invested great effort the form of complexity-theoretic things within into making types of inferences within structures, AI researchers about the consequences logics with particular as merely notational sets of expressive representations for modified information schemes features taken for 20 t?E. A,qre/Art~ficud /ntelligenc~e 72 (1995) I-52 of distributed inference mechanisms that Quillian began [41]. in AI, then, has had two interacting research involvements representations realization, whose constraints in tits and starts. Computational is deeply concerned with the physical in their environments. A basic observation interaction with an environment. The research is the inherent efficiency virtues of indexical The story of representational and physical the vocabulary of “reasoning” account of the meaning of representations, semantics plored have these two aspects as well, but now each aspect will be placed agents’ remarked upon, tied to direct sensorimotor double volume (if, indeed, interactional and in particular between what AI has historically understood as “internal” and “external” aspects, upon one another have been ex- research on agency and interaction will surely in the context of in this regard, already that are in this special reasoning but it has no fully developed the relationship representations. to provide a sub- stantial amount of useful structure like signs things and instructions. What do people do with representational materials, how do these activ- ities complement play interactions representational gated in a variety of other fields directions some possible connections concretely. and what properties do internal investi- I 16,17,29,37,50,80], so rather than speculating on the in this area could take, let us simply survey to these other fields that future research could develop more internal uses of representations, what role do representation-mediated in the rise of internal reasoning have as a result? These representational materials are likely including topics have been thoroughly that future computational in the everyday world, realization of agents’ remarked, external representations, is employed), As already research 3. Connecting to other fields As the articles in this special double volume demonstrate, research on from contact with a wide variety of other fields of of these contacts number of other strands interaction and agency can benefit research. The common denominator an extraordinary although well. This section offers a very brief outline of some of these fields and their potential connections theory has been discussed briefly above, and several other fields might be mentioned decision is the abstract notion of interaction, run theory, and several varieties of psychology. as well, including philosophical to AI research. Control logic, sociolinguistics, computational the various fields as through 3.1. Dynamical systems theop in numerous In recent years, researchers systems, which are defined generally as any systems fields have developed mathematical models of dynamical that can be described in terms of the changes over time of a set of interacting variables. Many such “systems”, linear systems whose of course, have no very useful properties. And others are simple fall within properties for which robust solution or analysis methods are categories of differential for which useful known. Dynamical the development analyses can be made. The most the categories of systems cases are those in which can be analyzed with traditional mathematical theory extends important tools. Yet others equations systems l?E. Agre/Artijicial Intelligence 72 (1995) 1-52 21 is driven by the repeated application of the same principle, the laws of mechanics or natural selection or economic choice. Since AI understandings at all levels, from the neurological the full range of these cases should ultimately be relevant of organisms to the social, for the relationship between AI and dynamical and qualitative aspects of the various systems equations describe systems variables, but symbolic systems is general enough systems. But it does not follow theory systems that can be characterized require other types of analysis. is to theory that AI research in In to provide definitions of even results exist that that general they will most likely in the of structure light upon those systems. As the various fields develop, in their approaches, particularly as the conceptions in this special double volume also continue to influence time of a system over for example pursues computational and mechanical to AI research. A challenge the quantitative reconcile seeks to understand. Differential terms of numerical its broadest definition, very complex cast useful begin world that inform research in other fields. the research to overlap symbolic systems 3.2. Robotics and vision Inasmuch as roboticists construct actual embodied agents, research on robotics has led the theories of kinematics to several forms of principled analysis of interactions between agents and environments. The most innovative of these have been on the lower levels where the main analytical tools are built upon [67], found in animals’ gaits and demon- for example, analyzes strates how these might be represented mathematically and used to simplify analysis and synthesis of walking and running machines. The designer of a running machine cannot to impose any arbitrary pattern of leg movements mind. Only certain cycles of movement this space of possibilities allows are physically possible, and principled the various types of symmetry in physics. Raibert to be characterized. and foot landings that might come and dynamics analysis is defined in terms of dynamic a sequence of physical the theory of force control of a robot effector by specifying [ 781. Whereas a position control system directs Or consider that the movements the it should occupy, force control such as a specific force vector that should describe robot and its physical environment, in the robot’s pressure upon a picked-up part regardless of any changes or variations it in nature, the parts’ shapes. Because are indexical or relational can be easier like absolute than for objective quantities the robot and the workpiece are made of rigid elements and position fixed to the floor). The point is useless, but that the space of is structured possible designs discussed is not that position control in large part by the kinds of epistemological in this special double volume. locations between (unless, of course, to build a sensor force relationships considerations relationships for them Robot design must also be informed by dynamical in the world that the robot’s actions will set in motion. Mason analysis of the interactions among [ 531, for example, objects that arise when a robot must push presents a mathematical an object across a surface. A part might move in a variety of ways due to the vagaries of friction, and anticipation to that move the part into a desired configuration without wasted motion and be fashioned analysis of the interactions of the space of possible allows motor plans trajectories 22 PE. A~re/Artijiciul Intelligence 72 (1995) l-52 such a system might visually the part’s progress and update the dynamic analysis and motor strategy as new even without sensors. In situations with greater uncertainty, observe information becomes available. assuming reference to confront to demonstrate the depth of rethinking to its purpose. But recent in vision has not always been forced Because computer vision programs can be presented with digital snapshots taken at the distant places and times, research embodied nature of visual activity. The theories of Marr, for example, do not envision in any complex way with its environment, an agent that is interacting instead is to construct a three-dimensional model of the world with that the purpose of vision for robots has research on visual systems little of embodied agents begun in “animate vision”, demands. Ballard in which in tight and principled ways with the architecture of motor control. A paradigm of this kind of interconnection might be vergence (eye orientation, is dynamically particular object at some determinate distance. And the architectural boundaries reasoning, the active choices agents make about what to perceive based on what information need (cf. [15]). of the visual system to permit stereo focus upon a among start to disappear altogether once one starts modeling they that the construction [ 81, for example, presents a series of experiments the physical configuration adjusted the architecture of visual processing control, for example) learning, and perception is interconnected in which 3.3. Biology Ecology and evolutionary the central to be adapted between organisms is adaptation. For an organism the organism nor the environment biology offer several powerful concepts and their environments. for thinking about such Perhaps to an environment is not a simple are likely to be simple themselves. from this in terms of the mechanics of flying or swimming. The life has many is that every organism’s finding and eating food and water, its the relationship concept thing, since neither Some aspects of adaptation, of course, can be explained full complexity, challenge aspects-locomotion, regulating body temperature, own adaptational Biologists in sum up these demands by speaking of a particular for a full explanation respiration, of adaptation avoiding predation, its local ecosystem. Each component of the ecosystem and so forth-each of which brings for example interaction, in relative demands. isolation social context for the others, and to coevolve and to become adapted “niche” the adaptational elements ecosystem changes various components, dynamic notion of an agent’s environment conceptions through exogenous the adaptational historically employed by computational species as filling a provides part of for all of the in intricate ways. As the of its interactions the internal demands of the niche will change as well. This than the the result to one another and is much more complex and subtle is a tendency influences At the same scribe organisms’ other, and Research ing and analyzing it is here on “artificial time, biology activities has historically in their environments that computational life” [46,74] artificial and simulated research. had fairly and their ideas may make simple to de- concepts interactions with one an- significant contributions. has commenced this project. Build- creatures may help clarify many biologi- precisely l?E. Agre/Artificial Intelligence 72 (1995) I-52 23 cal concepts by forcing unarticulated face. assumptions and unasked questions to the sur- 3.4. Activity theory Activity theory is a school of sociologically arise processes is profoundly that cognitive and education oriented psychology that human cognition from the writings of the Russian psychologist Lev Vygotsky through among people. Vygotsky believed search that developed Vygotsky believed ticular interaction deal of structure. Specifically, takes place he believed calls the “zone of proximal development”. Watching caretakers and children the context of shared activities endeavored ensuring current capabilities. Thus spared from overly simple and overly difficult could focus on incremental learning of thinking rise to them. re- [ 761. shaped by culture, and in par- of patterns of social the internalization that the process of learning has a great in what he in that the caretakers the two, with the aim of lay near the outer edge of the child’s tasks, the child that these complex structures of so that the child’s processes that gave that the child’s portion of the activity like games and chores, he observed shift the division of labor between could be viewed as internalizing the patterns of social interaction learning. Vygotsky argued in the child’s developing to dynamically are reflected that most cognition, learning interact event, to its affordances A strong believer in the cultural dimensions the result of a beneficial process of thinking as it effectively encodes and experimenting. of cognition, Vygotsky also emphasized the role of cultural artifacts such as tools in shaping cognition. The invention or refine- in a physical ment of a tool is an important inasmuch In learning material its use, future to use the tool according it. Moreover, generations will be spared the tedious and haphazard burden of reinventing in order to use a tool it is usually not necessary the reasoning behind for the tool that had been tried out and discarded. less the alternative designs it, much The environment tools of daily provide a tremendous and other artifacts their activities. These amount of support artifacts like cars and computers, clothing, and much else. include kitchen utensils, buildings and streets, machines to which Vygotsky’s to individuals a rich collection of cultural artifacts-the and groups who are organizing and the customs surrounding to fully understand life includes arguments apply-that in numerous larger “activity systems” beyond research has developed Vygotsky’s theory” was coined by Vygotsky’s for analyzing shares with much AI research an interest directions. The ideas follower Leontiev, who proposed a the simple parent- through structuring world by a Subsequent term “activity conceptual framework child dyad. Leontiev which activities become habitual or automatic, no longer requiring conscious theory has been brought and guidance. Activity and educationalists who are looking for ways to place children’s number of psychologists [ 601. Engestrom and learning cognition [21] has considerably to provide a principled means of intervening the activity broadened in the local activity system in complex organizational through awareness of its actual the development dynamics. in larger social contexts framework theory its members of an “expanded” to bring about changes to the English-speaking in the process settings among 24 P E. Azre/Arl@cial Intelligence 72 (1995) I-52 3.5. Genetic epistemology Another relevant school of developmental on Instead, proceeds the object psychology of thought. the “permanence” that it encounters the child will come to understand to the same object a few moments an extensive program of computational through a series of discrete and identifiable later, after it has been momentarily of objects of a world that exists that employs “sensorimotor schemata” in Drescher’s usage, does not represent it states (roughly) things out through a process figuring to scientific experimentation. He argued that the child’s relationship [ 191 has conducted theories. Building on some suggestions of Piaget’s, he has implemented is that founded by Jean Piaget traces the ways in which the child grasps In contrast to Vygotsky, that to “stages”, each of research based a to learn and represent knowl- the world through correspon- “when the perceivable world is like this, then the world is likely to turn out like this”. Such schemata can trying numerous [ 631, whose work on “genetic epistemology” the nature of reality through its interactions with its environment. Piaget focuses upon the child as an individual has been likened its environment which is defined by a different form of epistemology. A child in a very early sensorimotor stage, for example, might have difficulty connecting one occasion obscured. Later, though, across time, and this is the beginning of the child’s understanding independently Drescher on Piaget’s computer system edge. A schema, dence or mirroring. and you take this action, be learned simple actions built up by “chaining” plans through AI planning i terns”, which function the much more abstract proposition the ongoing situation. Drescher presents some extremely detailed scenarios how the creation of these complex cognitive structures schemata explains various features of the developmental work, including the period allow Drescher Piaget’s amount of innate cognitive in constructing reconstructs to be integrated with one another more effectively design. that Piaget traced in his through which the child passes during of object permanence. These scenarios that is consistent with the in the infant. Specifically, he argues that the infant, effectively them than is possible on a simple modular structures can then be in form to the assembly of new in traditional is the creation of “synthetic that they represent in to be applicable that describe the simpler sensorimotor theories, as well as with recent empirical claims structure in the process of development, faculties, together of existing plans and primitive actions through a relatively in numerous research. Another, more advanced mechanism simple process of induction by simply leading up to the full establishment situations. More complex cognitive the detailed sequence of substages these schemata, a process similar input except is likely of many innate peripheral that Piaget underestimated that a certain schema to “items” of sensory a theory of cognitive its own cognitive thereby allowing the functionality the stringing to construct architecture apparatus similarly through process For present purposes, arguments infant numerous the human environment on a table and cover When you put something is precisely that depend upon on the structure of the environment the great strength of Drescher’s work is that its scenarios include in which this the existence of permanent objects. When you rest something the most fundamental fact about theory, lives. Within Piagetian it with a cloth, in the refrigerator, it stays there until you take the cloth back off. takes it back it stays there until someone t! E. Ape/Artificial Intelligence 72 (1995) 1-52 25 out again. As you move around a stationary object, the views of that object that become available to your eyes possess some stable, reliable, and predictable relationships to one another. And so forth. This observation about the environment of human activity gives substance to the scenarios, which follow the child through the discovery of a wide variety of simple but fundamental interactional regularities. 3.6. European phenomenology Phenomenology is a branch of philosophy whose goal is to develop good vocabu- laries for describing the experience of ordinary activities. Put in plain language, phe- nomenology provides words for answering the question, “what is it like?‘. Although Merleau-Ponty’s [ 561 phenomenological analysis of human embodiment has a straight- is forward relevance to the analyses in this special double volume, phenomenology chiefly known in AI through the influence of Martin Heidegger, whose book Being and Time [39] provides a phenomenology of ordinary routine activities such as carpentry. Heidegger’s work is notorious for its obscurity, and those who have been inspired by his writing to criticize various central tenets of AI routinely find themselves in the impos- sible situation of translating between intellectual languages and communities that could hardly be more different. In particular, attempts to read Heidegger as directly specifying alternative algorithms or architectures of cognition are doomed to especially intractable confusion, inasmuch as it was very much Heidegger’s goal to avoid expressing himself in such terms. Nonetheless, Heidegger’s writing can, if handled with care, provide useful guidance theories of interaction. Heidegger places great for the development of computational emphasis on the customary forms of activity that structure much of everyday life, and in particular upon the customary uses of tools that give a conventional structure to actions, space, and materials. This “structure”, for Heidegger, is not a cognitive symbolic structure, but a structure of experience within which things take on particular interrelated meanings. He emphasizes, for example, that we do not normally relate to a pencil as this particular pencil, but rather as a pencil that is used in a certain habitual way. We can choose to withdraw the pencil from this ordinary, routine kind of relationship to our activities, staring at it as an object of curiosity or levity or scientific inquiry, but that is a very different experience from simply using it to write. This idea suggests, in a loose sort of way, investigating how a computational theory of interaction might give a different status to routine interactions with generic things (writing with a pencil) than to exceptional interactions with specific things (examining or measuring this particular pencil). But research like Heidegger’s can have its most productive influence upon AI when AI itself recovers a sense of its own historical development. Despite the efforts of Dreyfus, Heidegger’s work is not directly addressed to AI as it exists today, but rather to a larger tradition of which AI is one part. If Heidegger’s analysis of the history of philosophical therefore, alternative ways in ideas can be viewed as indicating paths not taken-and, which AI research might be conceptualized-then it need not be taken as posing an all-or-nothing challenge to AI’s foundations, but rather one critical perspective to assist in the field’s self-examination and evolution. 26 PI<. A,gre/Art(ficict/ /nrrlligenw 72 (1995) IL.52 3.7. Buddhist phenomenology Whereas the European phenomenological recent literature is relatively and Buddhist as communities that provide guidance developed phenomenological by using systematic meditation system. The whole point of Buddhism scholars have developed extensive descriptive (while, of tradition), Buddhism has an ancient and is to to pursue mindful awareness of one’s accounts of course, building upon much older philosophical continuously seek enlightenment own cognition, cognitive processes have evolved historically inadequate is the idea of illusion, which holds that any particular conceptualization be understood any definitive or exhaustive cognition proceeds upon that result. Mindfulness the individual compels action. for this process. These systems of description of meditators have found previous formulations system of reality must perhaps possessing heuristic value but not providing representation. Prior to the cultivation of mindful awareness, interpretations illusions thought or paralyze action, but it does liberate grasps reality or inevitably the world and contracting desires and drives based on the unrecognized in a ceaseless cycle of imposing specific, prestructured their own experiences. Central does not eliminate as an imposition, to this evolving that thought transparently the illusion to describe intellectual from that traditions and Rosch These ideas may seem distant from the concerns of computational [75] have argued the connections of inquiry, after all, are concerned with the mind and Thompson, and deep. Both relationships with reality. The pivot through which these authors develop the connections between Structural coupling species are adapted in interactional is Maturana and Varela’s notion of “structural coupling” is a biological to their environments, and this adaptation ought to be conceptualized research. Yet Varela, are actually numerous in the theory of evolution. Evolved the two traditions rooted terms: notion its [ 54 1. l the organism l this interaction both sustains interacts of effects upon the environment in complex ways with its environment; the organism’s internal functioning and has some range as well; and time through mutual adaptation of species and the structures of its external environment internal l the organism’s structures have both changed over historical ecosystem; l the changes and in these structures have accumulated to such a degree that it is difficult if not impossible to understand them except in the context of their interaction. are, in this sense, “coupled” and Rosch point out that this coupling The structures of the organism and its environment another. Varela, Thompson, ways to the Buddhist notion of “codependent of cognition: one does not experience cognition as rising up, searching reality, and then settling upon it; nor does one experience bringing a previously dormant cognition back to life. Instead, and the structures of reality arise together, each proposing validation. Although it is certainly which perception and action guide one another further research will need to Resh out this analogy arising”, which describes and leads to innovative in embodied activity. in reality as invading oneself and the processes of cognition the other as its own illusory in more detail, through to one in certain the experience investigations of the processes for something is analogous stimulating, This type of research has many skeptics among technical people. And indeed, phe- FE. Agre/Ar@cial Intelligence 72 (1995) 1-52 27 research are not straightforwardly the other requires drawing out the most promising the suggestions the phenomenological for research that method strikes many people commensurable. Al- analogies these analogies might in the cog- and empirical and German psychologists tradition as akin to introspection, which was once pursued systematically ran afoul of its lack of concep- though, makes no claim and detailed particu- having to provide compelling phenomenological methodology, than introspectionism, internal mental mechanisms of experience. More far more rigorous Phenomenology, reproducibility. but ultimately importantly, but only is simply in extensive communities of investigators. and computational them and pursuing nomenology lowing each to influence between generate. Unfortunately, nitive science by Russian tual precision to identify descriptions larly in the Buddhist version, developed over a long period 3.8. Sociology Sociology has numerous though, to research on interaction connections ical research, to have a relatively of this question research within tionism has been distinguished how, in fact, people actually enact another. stable structure? in a short space, much sociological schools and subdisciplines, many of which have potential in AI. Perhaps the central question of all sociolog- is the question of social order: in virtue of what does society seem It is impossible to survey less the available schools such as ethnomethodology by a commitment to detailed empirical the structures of society answers the many formulations to it. Nonetheless, interac- of in their dealings with one and symbolic investigation in Plans to use theories, a plan a in her critique of AI planning [ 721. Suchman observed some people attempting influence upon thinking research that had been equipped with a device that, based on AI planning its users through complex copying operations by constructing the successive steps of the plan to the users. The users experienced and they interpreted The sociological that has had the greatest research program that of Lucy Suchman in AI is arguably and the Structure of Behavior a photocopier attempted to guide and then presenting wide range of difficulties using these instructions, ways based on the situation as it presented executing the instructions to take next. Both through Suchman’s what actions a number of AI research projects have investigated might actually be made of plans many subtle and improvised ways in which people structure the demands of moment-to-moment future computational to the improvisatory research nature of human action. its basic concepts as resources-and the instructions meaningful to rethink itself in the moment. in the manner of a computer program, [5,30,64]. The deeper point, and other developments, influence the complex and varied uses that the in accord with interaction. These phenomena may lead in ways that can do justice though, concerns their actions them in complex In particular, far from the people employed figuring out as one set of resources among many-in 3.9. Anthropology Historically, anthropology differs from sociology in that it studies “them” rather than “us”. Remarkably, even as this distinction has become untenable, anthropology 28 PE. Agre/ArtiJiciul Intelligence 72 (1995) 1-52 in a large variety of settings has led anthropologists through from one another its focus upon culture-and specifically in profound ways. Exploring features of life that are normally is the role of habitual a social order. Pierre Bourdieu that locates social order tradition numerous the notion its distinctive character that cultures differ has retained upon the question of social order investigate these attention. Among defining and maintaining ing with a long laws and ceremonies best be found the habitual ing, pathways, anthropology” day cultural practices. While perhaps exaggerated as opposed erally salutary and quotidian research. choice, as anthropologists aspects of life as important to conscious influence and conflicts, activities too familiar and customary to the contrary in loud and visible to to attract much in artifacts [ 111, for example, disagree- things such as that the social order can in and particularly tools, cloth- refer to this kind of theory as “practice in every- in its emphasis on structured habit and gen- to view ever more ordinary topics of like houses, hearths, and as legitimate and so forth. Anthropologists [ 6 11 because of its emphasis on the hidden order to be found suggested in the most ordinary details of everyday activities, this style of research has had a massive structuring of everyday uses of artifacts have chosen and meaningful, is the differing research on interaction anthropology with computational scales of research. Computational and agency, a In connecting significant obstacle researchers must get things working, and that requires analyzing very small and specific actions. Whereas in several schools of sociology, has mostly been concerned with microscopic studies of human larger speaks of the fine details of like a worked-out grammar of those activities habitual activities, to be provided. The focus, that that allow things on very different scales allow apt descriptions to be fitted together, so that economic for example, can be related to the ways in which people those previously mentioned, anthropology things. Even when an author such as Bourdieu including interaction, teach and learn skills. to be given-descriptions it is rare for anything a set of analytical is on articulating have engaged structures, categories instead, scales research people’s interleaving of different in cognitive from the moment-to-moment details of moment-to-moment In this regard, a particularly promising analytical interactions with their worlds on several different science and AI, she rejects that can be abstracted structuring of an arena of activity such as a kitchen or supermarket. framework can be found in the work of Jean Lave. In her book Cognition in Practice [ 5 11, she provides a set of categories (more for analyzing tasks to the accurately, “levels”), In con- historical that people trast to much the notion decide what to do by solving “problems” from the complex and activity. The people she observes do not interconnected things just so much solve problems in terms of enough research interactions to be as it has historically between con- worked out and rethought research on ceptual systems such as Lave’s and the concepts interaction. An emphasis upon formulating though, will ensure commensurable. resolving focus upon units of analysis defined to keep moving. Her resolute leads her to theories that are hard to reconcile with computational in the two research projects are at least in order to strike up a productive as work through complicated ideas in terms of interactions, that the units of analysis that guide computational been practiced. And details will have indeed, numerous computational relationship dilemmas, P: E. Ape/Artificial Intelligence 72 (I 995) l-52 29 4. Papers in this double volume The papers collected here are a diverse group, deriving and technical backgrounds the agenda and vocabulary of disciplinary within they each represent a distinctive voices them. Despite into topical groups, approach in a conversation, with numerous they are arranged the temptation literatures. Although article, of this introductory to the issues. They should be understood and subtle points of interconnection from a remarkable variety they are described here that it bears repeating as among them to impose an artificial structure upon them by sorting in alphabetical order by the first author. 4.1. Arbib and Liaw Arbib and Liaw present an evolutionary scenario for explaining the complex func- the visual system of the frog, than directly specifying “schemata” of neurons, they frame the evidence that motivates their model. Rather their theory at an abstract system. Taking as their model tionality of the nervous they summarize the operation interacting abstract units of computational hardware substrates. brains and computer Liaw and their colleagues have developed general precise accounts of particular ways. in terms of the that give rise to the observed patterns of behavior. Schemata are on a variety of that allows in a common vocabulary. Arbib and that allow formal models of schemata to be formulated and reasoned about in principled schemata provide a level of abstraction In particular, hardware that can be implemented to be discussed functionality systems level, Beginning with the life and ways of the frog, Arbib and Liaw develop an approach to interactions with its environment. Having done so, they discuss it squarely within the context of an embodied that the issues from sensorimotor behavior to symbolic reasoning. through which novel schemata might arise in to the demands of novel situations. They emphasize, however, that cognition is not controlled by a centralized transition that places the difficult they sketch some processes the study of the visual system agent’s arise in making In particular, response within cooperation any single representation schemata of partial each of which captures interactions within a particular mode of processing. do not employ representations, among a distributed the schema model and competition set of schemata. Furthermore, device but is a matter of these scheme, but rather a patchwork aspect of the agent’s a particular Arbib and Liaw’s argument illustrates if one believes research on interaction functions less attention computational with “higher” cognitive arbitrary goals, with enough studied by itself, without and routine activity against which thought to a considerably interactions with the world, and upon the functional, developmental, this means reference an inversion of priorities and agency. AI has traditionally such as the construction to evolutionarily prior phenomena. This that is common in of innovative plans been concerned to solve is natural that can be defined and of “low-level” processing this point of view leads that, in fact, “thought” is a phenomenon to the whole background takes place. Rejecting different approach: an emphasis on routine activities, on sensorimotor functions provide In practice postpone- the ways in which “low-level” and evolutionary basis for the higher functions. suffer the same methodological that the higher functions generally 30 f? E. Agre /Art@ficia/ Intelligence 72 (I 995) I-52 the higher functions to be more important is not to declare one set of functions ment that older Al research had visited upon the lower ones. The ultimate challenge, of course, than the other, but accounts of their interrelationship. Arbib and Liaw suggest rather to provide substantive some ways of seeing as continuous with the lower ones. Although the higher and lower functions are made of the same stuff, so to speak, they do differ in the sense that the higher functions in require schemata a way that the lower functions do not. As Arbib and Liaw point out, this evolutionary to as the “Great shift is congruent with the theoretical movement to a focus Move” upon the interconnectable a focus upon hardware, with its static interconnections, to be replicated and synthesized structures of higher thought. that Newell referred [ 581 -from symbolic 4.2. Barto, Bradtke, and Singh applying repeated review and synthesize their unified understanding trials of actual or simulated the agent draws on its accumulating Barto, Bradtke, and Singh programming, a great deal of research on the of this class of to real-time control. Each of these algorithms enables an agent to learn how in achieving goals when interacting with dynamic, and possibly its efficiency control of a given systems. Through improved control in that their way function their search strategy. Unlike the algorithms described by Barto, Bradtke, states. As the algorithm converges, those states which must actually be visited by an to prove fairly strong results about the conditions under use of dynamic algorithms to improve stochastic, system, strategies. These methods differ from AI’s heuristic state-space search techniques they must repetitively through an explosive number of states. By improving using principles classical dynamic programming and Singh do not need is focused effort optimal controller. which these learning methods will converge systems, to visit all of the possible visit a large number of states, as opposed from dynamic programming, their heuristic evaluation to optimal controllers. they improve It is possible to threading increasingly experiences to produce upon results and control it greatly strengthens This research unifies is a nearly exhaustive from a number of fields. In particular, by pointing out to research on learning dynamic programming methods the relevance of asynchronous between AI research in stochastic environments, theory research on adaptive control methods. The on search and learning result that can be applied to a wide range of problems. On the other hand, as with any weak method of any the results guarantee convergence without making any strong promises about generality, how long convergence will research will be to understand how the learning methods might be specialized structure to take advantage of particular kinds of of a set of weak methods in the environment. take. A project the connections investigation for future 4.3. Basye, Dean, and Kaelbling Basye, Dean, and Kaelbling develop a series of algorithms for probabilistically the problem of “system problem of reconstructing output behavior. That identification”. On an abstract level, system identification the structure of a state-transition its input- is presented with a series of discrete options graph by sampling is, the algorithm solving is the P: E. Agre/Artifcial Intelligence 72 (199.5) I-52 31 left or right) and, upon choosing one of those options, problems have been investigated is to the problem of discovering is told what (red or green; hot, warm, or cold; etc.). Although their by in a wide variety of settings, the structure of an environment to some strategy. And since Basye, Dean, and Kaelbling in mind, the environment they have extended that the agent receives the problem to assume that is only probabilistically in the operation of its sensors. As a result, can now be “seen” (such as turning information identification system relevance here traveling around have real robotic applications the information correct, perhaps because of noise algorithms correctness. in it according about do not guarantee perfect correctness but a certain specifiable likelihood their of The problem cannot be solved in its most general form, since insufficient information location the difficulty to sort through is that the agent never knows where to where it came from, and has no perfectly may be available Intuitively, that it can return if its present moreover, must begin wherever to an arbitrary which can be exploited by particular It transpires that the world has certain properties such as reliable structures which can be mapped with greater certainty interconnected the fog and actually pin down which states are which. it is, has no guarantees reliable way of knowing time. Its exploration, in other words, jump in the environment reduce uncertainty. time, provided landmarks or tightly constrained fields of densely than wide-open is the same as its location at any previous it cannot, the structures to provably the authors explore search strategies that the problem can be solved location. Therefore, in probabilistic to be located; polynomial it happens vertices. study in relation and follows terms. Despite the environment in the interaction is a sophisticated trajectories it is possible it is, may have wildly mistaken Although clearly simplified paper action strategies, and environment to many real environments, Basye, Dean, and learning, partial between structures. Their agent is not omniscient, ideas about the structure can only characterize interactions Kaelbling’s knowledge, does not reliably know where of the environment, in abstract with the environment will converge algorithm using results will apply of changes, will be to understand what structures of particular categories of environments, these not-literally-spatial Basye, Dean, and Kaelbling that the resulting models of the the represent other kinds such as the workings of artifacts. An important project for future research especially to the formal properties of graphs that permit that to characterize the spatial metaphors of travel through a graph-structured to explain space, to accuracy. Although to prove their results. in sufficient detail the state-transitions ones, correspond it is convenient to environments to demonstrate the designer the agent’s in which this, 4.4. Beer Beer applies the mathematical machinery of dynamical ization of agent-environment environment be viewed as the trajectory of one large system whose variables are simply of both agent and environment of the general notion of making theory to the formal- interactions. Specifically, he proposes viewing agent and them can systems, so that the interaction between the variables reading the together. This proposal provides a straightforward not the internal cognitive processing, as two coupled dynamical interaction, systems 32 PE. Ape/Artificial Intelligence 72 (1995) 1-52 for AI research. Having defined unit of analysis theory provides an extensive vocabulary which a given agent-environment ample, might settle into a stable, periodic “limit set”. The interaction might be defined as adaptive relation systems through travels. A given region of the space, for ex- initial configurations in this way, dynamical the space of possibilities to an arbitrary condition upon its trajectory. form a basin within which all possible for discussing eventually system things in interaction as a trajectory can be understood Beer’s particular domain One benefit of this general is in analysis. Research on approach if it becomes possible interaction to inspect particular performances, and agency will only progress and to characterize general categories of them, so as to understand what the agent is really doing and why. Since any given through to analysis using a variety of tools. Particular a space, this trajectory can be submitted though presumably can be visualized by being plotted, trajectories in a reduced subset system. Beer provides several examples of the full coupled dynamical of the dimensions that can be drawn from it. of this kind of analysis, and of the conclusions insect whose leg parameters are driven in turn, are set by a ge- in cer- insect’s performances. Analysis of these perfor- that the neural network has settled upon patterns of interaction (the by a simple neural network. The weights of this network, netic algorithm through tain measurements mances demonstrates with the environment gaits used by insects. Moreover, when sect’s legs are unreliable, the demands. to the the positions of the in- that permit gaits as the situation the sensors measuring the genetic algorithm settles upon a set of weights evolutionary of the simulated to switch among different dynamics settings of the weights and homes that simulates many different insect walks on a horizontal on a set of weights that correspond that maximizes for generating is a walking incremental, refinements robotic insect floor) to this particular Beer emphasizes, that his principal commitment framework. He presents is not though, but to the dynamical-systems of an emerging role. Once style of AI research this is done, he argues, all of the traditional architecture prototypes accorded a central of AI research must be rethought. His robotic but do not have anything traditional course, one might vindicate the notion of representation to include all possible uses of internal content, Beer argues, his insects robotic agent’s insects are grounded interactions with its environment. these discoveries in which an agent’s embodiment as is categories states for example, have internal symbolic notions of representations. Of it widely enough retains any real in the to, the state. But so long as the notion in, and take their functional fall outside of it. Instead, states in relation the internal by defining “meanings” resembling insects, Dynamical theory provides a highly general framework definitions in more general categories of agent-environment that capture the principal challenge systems interactions. Perhaps systems-theoretic environment work will be to formulate of structure encountered The structures of tool use, for example, presumably of enormous compact and comprehensible will presumably ment of this theory will require systems. But can formulas the elucidation dynamical correspond these constraints for characterizing for formalizing for research within agent- this frame- the particular kinds interaction. to particular properties be captured by relatively those properties? This question shows, develop- conceptions not have a single, simple answer. As Beer’s analysis of new, more appropriate PE. Agre/ArtiJicial Intelligence 72 (1995) 1-52 33 as basic as “representation”. in terms of interactions will take unpredictable AI having been decades forms as well. in the making, its of categories reconstruction 4.5. Donald Donald presents a formalism for reasoning two sensor systems arranged about the computational properties of in the world, one would complexity: sensor systems. Given system detect every condition distributed like to ask a series of questions modeled on the theory of computational Can one sensor the two sensor systems equal what would need to be added to the “stronger” power information which example, a design flashing computations is “conserved” that involves lights versus a single relatively that the other can? Are If not, can we define precisely in in to the other (for via all of the necessary it equivalent sensor system one? And most generally, does there exist a formal sense in their sensory powers? to the “weaker” simple mobile agents communicating complex agent performing from one design in the movement two relatively in the world on its own)? to make it may amounts it possible Formalizing that usually this information into the calibration to, and how it compares a great deal of information of a design process. For example, of sensors, and the formalism makes these questions brings forth a large number of points in the background encoded precisely what another sensor or the addition of extra capabilities example, of considerable seemingly because that transformation would require a particular computation problems, of course, are frequently much harder to solve than the problems remain is to explain to the addition of to an existing one. To take another into another, effort inverse they invert. in Donald’s paper would be extremely useful agents. An informal model the capacities as an agent’s machinery turn out that one sensor system cannot be transformed to other aspects of the design of autonomous The form of analysis made concrete computational to be inverted; similar one, without [ 131 speculations in Braitenberg’s the expenditure Intuitively about it ought if extended in this regard might be found of various kinds of agent machinery. to be able sophisticated, grows nore interactions with a given environment. Different into a hierarchy, participating being considered, would provide a valuable varieties of agent machinery kinds of understandings would qualitatively agents and to understand according in them. Of course, the rearrangements and explain possess and to which categories of agent machinery this hierarchy depends on the particular in a growing forms of interaction would range of thus fall are capable of environment in different environments of the hierarchy indication of the degrees and kinds of adaptation that different to environments with particular properties. These to design novel situated improve our abilities speaking, to participate the ones that already exist. 4.6. Hammond, Converse, and Grass Hammond, Converse, call “long-term pursuing Hammond a goal (and et al. wish activity”. Whereas classical planning was defined and Grass wish to develop computational models of what they in terms of an agent for a new goal), in the strategies by which an agent can engage then, presumably, to understand to sleep or asking going 34 PE. Agre/Art$cial lntellipwe 72 (1995) 1-52 to program. argument in Hammond that contribute the environment so as to maintain et al. is important over long periods. In their contribution in a given environment long periods. They refer they explore a category of action policies theories of interaction and agency. An omnipotent to these policies as “stabilization”- in effect the properties that the rely upon. A simple example would be putting away your tools when taxonomy of the types et al. provide a helpful in a and they embody some of these examples activity productive this special double volume, to orderly action over actively changing agent’s actions you are finished with them. Hammond of stabilization, with many examples, simple demonstration The underlying making computational agent would not need to put its tools away, since it would bave no trouble them the next time it needs them. Agents with more realistic capacities, by contrast, need the world in the context of the case-based architectures that Hammond et al. employ. Their emphasis is not upon unique, complex, creative “cases” from situations be able to act in a sophisticated computation. But a collection of cases is only useful future. If the tools are always much more frequently sense, other things being equal, tend to arise over and over. if those casts actually arise in the left in different places then new cases might be required left in the same place. It therefore makes the world so that the same cases by precedents to be usefully that have gone before. An agent with a large collection of casts will stable properties. This observation forms of reasoning but upon fashion without necessarily for the general project of that permit newly arising takes on a specific form than if they are always to actively manipulate to have relatively in sophisticatcd the stockpiling and omniscient assimilated situations engaging finding of Note the form of this argument: the architecture they sought structures architecture, Hammond Instead, general. interactions with the world-that, “fit” between in Administrative Behavior largely Hammond but the similarities environments, pensatory structures were found, back to the architecture. But generalization of defense, not the first. in terms of compensating et al. did not immediately decide in the world-and, lack of generality faced with a seeming in their to make the architecture more in agents’ once properly articulated, actually revealed an adaptive to Simon’s approach of organizations employees. more specifically, for the limited the functioning of individual rationality and its environment. This is similar [71], where he explained et al. are, of course, dealing with individual agents remain. It could have transpired in which case suspicion might have been of the architecture in a wider variety of that no viable com- transferred should be the second line The approach of Hammond et al. ought to find application their own have in a wider variety of forms of stabilization, activities and organizational of stabilization settings. Social techniques and facts such as toolboxes here”. Analysis of new in turn provoke a search for further world. (seeming, are supported by cultures to linguistic to teaching methods of the limits of stabilization, moreover, might apparent) weaknesses in the case-based types of structure in agents’ from arti- in many ways, phrases such as “this goes lead to the discovery architecture, which might interactions with the I?E. Agre/Art@cial Intelligence 72 (1995) I-52 35 4.7. Hayes- Roth of actions; other environments, to be improvised based on relatively complex moment-to-moment Hayes-Roth approach: perceptual introduces categories of agent architectures. While Hayes-Roth defines a niche according architectural methods, and meta-control their high reliability on strict actions evolving circumstances. than looking sequencing Rather linear and their high demands the concept of the “niches” inspired by the biological that can be occupied by particular concept of a niche, each calling for a particular strategies, control mode, reasoning choices, reasoning to several dimensions, strategies. For example, some environments, perhaps due to for efficiency, call for control modes based by contrast, may call for to adaptation responsive to the that is capable of that to for a single super-architecture that is equally has developed an architecture itself adapting response long-term the agent to change conditions, synthesizing to changing the patient’s is necessary complex territory of niches, Hayes-Roth that is capable of rapid responses control policies repertoire according entire dynamically select and combine certain elements of the system’s architectural its analysis of the demands of the situation. This kind of dynamic adaptation target domain of intensive-care monitoring, in Hayes-Roth’s environment whose demands can qualitatively patient has a sudden medical crisis, for example, give way to a much more urgent form of processing shifting states. Likewise, pattern, requiring policy of probing and diagnosing in turn, might shift between more qualitative quantitative forms based on simulation, symbolic knowledge might be available. is still evolving. system experience of empirical to treatment may drift into an unfamiliar into a much more active to determine what might be going on. This reasoning, and more forms based on past precedents and an extraordinarily shift among extreme positions. When a tracking and reasoning must to accumulation care monitoring. As a strategic matter, the architecture can be deemed promising able to shift gracefully require of it. Detailed of its many modes will be required is equipped with the mass of detailed knowledge accurate provide promising the system behaves optimally within each later on, of course, once each facet of the system that it will require. But qualitatively among analysis of whether insists upon such as intensive within a relatively parsimonious the various modes of operation on what kinds of information signs for future development. that changing conditions its processing mode real-life domains framework will it, Hayes-Roth responsiveness In evaluating Hayes-Roth’s architectural in complex depending if it is the 4.8. Horswill Horswill presents a methodology for the construction that AI has long pursued to arbitrary circumstances, Horswill considers tures. Observing can be adapted search for architectures gests a process of incremental so to speak, “folded versions of the architecture that are maximally refinement in” to the agent’s computations that require simpler of specialized the goal of wholly general architectures agent architec- that the contrary project, a to particular environments. He sug- are, simpler in adapted in which structures of the environment as assumptions, forms of computation yielding and perhaps, 36 P E. Aqe /Artificial Intelligence 72 (1995) I-52 to lead de- to fill out a space of possible designs, a kind of lattice structure within which and extreme cases, no computation signers a designer can move downward upward as those regularities prove false or unstable. at all. Experience with this method ought as new environmental are discovered regularities of variables to a particularly His examples are chosen tours of an office space. Suitable constraints from the construction to robot designed of an autonomous are discovered in the level floor, in search spaces afforded by this in a of course, might lead to the discovery of different regularities and that is largely retrospective. The point of the design from which optimal designs can be simple agent design. The same design process to the agent architecture. Horswill emphasizes provide reliable visual properties, and independence environment, leading different environment, the making of different simplifications his analysis of his robot’s architecture methodology cranked out, but to provide a framework and specialization for thinking within which the generalization is not to provide a simple algorithm in a conscious and deliberate way. of designs can be undertaken the desirability in terms of interactions, Horswill’s paper expresses in a particularly of parsimony clear way a theme in architectures. When the mutual the most important source of guidance that runs throughout the units of analysis these papers: fit between an for design and analysis are defined agent and its environment for the design becomes process. A highly genera1 architecture may be able to function well in a wide variety of circumstances, but this very generality will produce a great deal of “slack” to the environment. By aiming planatory burden to interactions are forced to pay ever more detailed attention within for simple machinery, and not to the architecture, designers the primary ex- such as Horswill and the agent’s place in the architecture’s and by shifting that its computations are not impossibly to the environment cumbersome, relationship assuming it. 4.9. Kirsh Kirsh explores to complement their cognition. the resources around highlight opportunities, to encode useful information, complexity of the world to a manageable If we watch people as they work we note happen on all scales, from a slight repositioning the wide variety of ways in which people employ the space around that them, not just to get things done, but for and to keep the level. These cognitively oriented them they constantly manage cognitive ends-to task-relevant of the environment manipulations single workpiece to a long-term range of cases, he distinguishes and materials that simplify that permit calculations internal cognition. As we observe an individual physical in a familiar “external” it is simple enough causal events going on with hands and artifacts and a second going on within brains, but the fact is that these two categories of events are continually through perception, in a way that fits better with the capacities of array of in a familiar activity and the “internal” to make one list of the list of the causal events that simplify an agent’s choices among alternatives, the gathering of information to be formulated interacting with a complicated when participating to draw lines between structuring of a whole workplace. Considering among spatial arrangements and spatial arrangements aspects of cognition. Of course, in an environment-particularly a striking of tools can become difficult spatial arrangements three phenomena: setting-it things of a P. E. Agre/Artijicial Intelligence 72 (1995) l-52 31 triggering one another, so that it is difficult of a closely coupled system. to make sense of them except as a members traditional unit of analysis It is here that the case for an interactional research on situated agency starts to become compelling. This is not to say that analyses based theories of cognition must be abandoned. To the contrary, Kirsh uses upon theories of cognition-as-search of why certain spatial internal cognition. The resulting picture arrangements in new directions, placing of interaction, them in a highly structured environment. in the larger context of an agent’s to provide an intuitive explanation the burden upon lessen takes those traditional of things though, in computational involvement concepts Kirsh’s analysis brings out some of the enormous to explain adaptation complexity of the phenomenon structural: are frequently of the used architecture is well-adapted The metaphors “adaptation”. agent is spoken of as “well-fitted” cognitive sense in the context of a potentially manipulates its surroundings these practices are cultural artifacts, and so forth. Furthermore, workplaces are inseparable in those settings. With this realization, becomes complicated, sharply distinguished from moment to a given environment, to its surroundings. Yet if we ask whether a particular the question only makes elaborate set of practices by which the agent actively that “fit”. Many of to achieve in nature, must be learned by the agent, are supported by their from the means by which they actually get useful work done and “action” the means by which agents actively manage the boundary between “perception” to moment and it becomes necessary by many conventional AI architectures-are to take care about what these terms-so to mean. 4. IO. Lespe’rance and Levesque routinely that agents in objective terms things is the observation terms. For example, in indexical to know and Levesque adapt methods things it is common place name or a latitude and longitude) red just went by here” without having any objective name for “here” Lesperance of the distinction departure they do not know “something as a conventional the current or recent outside observer might have this knowledge the ground, to represent epistemological of objective of what county one inhabits or what month cumbersome ways, quantifying terms. logic to give an account from philosophical between objective knowledge and indexical knowledge. Their point of that know like (such or any objective knowledge of the designer or another from an aerial point of view. But down on an agent impose a wholly unnecessary independent the right way to core an apple, which operates regardless in unnecessarily over the possible places and times rather than in indexical is immediately terms, in objective burden, as well as requiring time (such as a clock reading). Of course, then, would that knowledge it is) must be formulated the world the world forms. Requiring that is actually in indexical information tangible (like accurately, Formalizing to various “thens”, indexical knowledge to time. Events can have a range of complex relationships challenges. to “now” Many of these pertain and Levesque develop a fairly sophisticated and logic of time that permits a wide variety of types of partial knowledge to be expressed accurately. They are also able to express a wide variety of “knowledge preconditions” is that you cannot call me on the phone without knowing for action. A simple example though, presents and Lesperance significant 38 PE. Agre/Artificial Intelligence 72 (1995) 1-52 my number. A more complex example mailbox The is that you cannot if you are only aware of being “here”, as opposed that Lesperance solely as an account of the “knowledge formalism logical and Levesque have developed is meant, as level” of indexical and objective is, they do not provide any account of how these forms of reasoning that an agent would to those in Lesperance in hardware. a mass of symbolic It would be a mistake formulae corresponding to assume reliably place a letter in my to being on my front step. they explain, reasoning. That might be realized have to manipulate and Levesque’s paper. Instead, the designer as a tool for analyzing reasoning. Before this possibility the computational particular will of course be possible programs. This approach kinds of physical ways. Research computational in this area it is possible that their formalism (and, of course, designing) properties of the formalism can be realized, though, it will be necessary and the ways classes of machinery. Simple and straightforward through is most realization will probably the use of general-purpose impractical, likely require the logic is bound to produce an expanded understanding properties of various forms of situated reasoning. is best employed by an agent’s patterns of to explore to of their theory that it can be fitted realizations logical theorem-proving though, and more sophisticated in various of the to be adjusted 4.11, Lyons and Hendriks framework incremental that participate for the characterization automata. Each automaton is founded upon a formal Lyons and Hendriks present an architecture in complex, structured for the automatic synthesis of interactions with their environments. Their and analysis of interactions. The basic idea is to model the agent and environment from a vocabulary elements, and the behavior and interaction of agent and environment agents research agent-environment as interacting mathematical of basic computing can be modeled according long list of important questions about interaction, most particularly whether tion will eventually as powerful stands as one of the most thoroughly worked out frameworks complex followed by these automata as they evolve rules. This approach allows one to make precise a the interac- is only it, it to a specific desired state. Although in terms of the trajectories for analyzing qualitatively such conclusions within to a fixed set of formal for demonstrating as the proof is assembled the method interactions. techniques converge their automata-theoretic for controlling industrial tasks. Their architecture has two components, the robot’s moment-to-moment that is capable of incrementally employ to control and a “planner” In their paper, Lyons and Hendriks the design of a system motivate complex assembly a fixed circuit-structure environment, structure provides Lyons and Hendriks with a principled programmer one of these dynamics particular will evolve just in them, in a particular way. so as to extend its behavioral actions in case it can sense particular kinds of situations, that the joint agent-environment that will guarantee a “reactor” formalism robots as they engage to in that employs interaction with its to the reactor’s formalism adding repertoire. The automata-theoretic basis for designing a language can use to represent “dynamics” of interaction. A robot can “participate” that a in and take system PE. Agre/Artificial Intelligence 72 (1995) 1-52 39 This is a different and more complex concept than the traditional notion of “executing a plan to achieve a goal”. First of all, Lyons and Hendriks take for granted that only a certain proportion of the action in the world will be controllable by the agent (for example, through the movement of its limbs). Secondly, the “planner” does not envision a definite sequence of actions and world-states through which the “execution” will travel. Instead, it specifies a potentially large and complex space of possible trajectories whose destinations can be sufficiently influenced through the adoption of particular action policies that can be physically realized by the reactor, through the particular kind of machinery of which the reactor is made. 4.12. Rosenschein and Kaelbling Rosenschein and Kaelbling present a view of representation and control based on the theory of situated automata. They observe that AI ideas about representation have frequently been based on mathematical logic, or upon notations that can be formalized in logical terms. Unfortunately, these ideas have traditionally been accompanied by specific architectural commitments, according to which knowledge is formulated through structures modeled on the techniques of symbolic programming. Thought, in this view, is a matter of the explicit computational manipulation of these symbolic structures by mechanisms such as theorem-proving programs. The extreme inefficiency of most such schemes has cast shadows on formal logic as a research tool in AI. Rosenschein and Kaelbling point out, however, that the basic point of logic is not architectural but semantic: it is a formal means of sorting out the meanings of representational elements, with no inherent commitments about the manner in which these elements are physically realized. Pursuing this observation, Rosenschein and Kaelbling present an agent synthesis methodology in which the machinery being generated is unusually simple and straight- forward. They present a logical formalism that allows them to represent the workings of a specific, wholly traditional class of digital machinery. The representational elements here are not symbolic structures but values in registers and on wires. Logical formal- ization permits the designer to give a precise account of the meanings of individual elements in terms of their correspondence to the world, and logical notation provides the basis for a set of languages for specifying the machinery for newly designed agents. The resulting circuitry need not be specified in complete detail. To the contrary, the com- pilers for these languages can perform a wide variety of manipulations on the logical forms and circuitry representation, and these manipulations can be proven to preserve the intended meanings of the computations because of the clear formal semantics of the underlying logical formalism. The devices that are synthesized through Rosenschein and Kaelbling’s methods are embodied agents whose activities take place across time. The authors point out that this is quite a different picture from the traditional notion of “solving a problem” by mapping a single, isolated input onto a single, isolated output. Instead, the picture is more like that of control theory, with a continual stream of inputs and a continual stream of outputs-in this case, tied to a discrete digital clock. The logic includes operators that can represent the relationships between values on adjacent ticks of this 40 P.E. Agrr/ArtrjtcYtr/ Intrllipwe 72 (1995) I-52 it possible thereby making clock, of computational processes step would be to employ in particular kinds of environments, regarding time-extended processes occurring the correspondences to reason in a principled way about the meanings that unfold over a series of time units. A further valuable of activity these methods in which strong guarantees might become possibfe inside the agent and the time-structures computations to formalize between time-extended in its surroundings. 4. I.?. Schoppers a modal symbolic that combines in complex decision Schoppers presents an architecture philosophy of an agent’s relationship tree that interacts with a variety of asynchronously logic of time and belief to its environment. Rather reasoning on-line, Schoppers’ program compiles operating the information from the various sensors and maintains a consistent set of beliefs. This approach to its are in the agent’s with a control-theoretic than engaging a sensorimotor subsystem available permits environment, not headed for desired states. It also affords a high degree of parallelism execution. intervening with specific corrective actions only when these dynamics controllers within a robot. One of these subsystems monitors to take advantage of complex dynamics within in the face of unexpected perturbations. as well as considerable its relationship the agent resilience A reformulation of traditional AI ideas within a control-theoretic to guarantee any sort of iron-clad coupling between vocabulary to lresh perspectives on a variety of AI issues. His point of departure that it is impossible Schoppers observation agent’s internal states and the world outside. Instead, factors to ensure that it remains adequately coupled inertia, which ensures perceptions corrected. They also include locality effects, so that the agent will necessarily it is in a position on managing predetermined leads is the the the agent can rely upon a variety of to the world. These include physical that incorrect actions undertaken based on transiently mistaken they are the world cannot do too much harm before the agent, with its strong that that focuses a is a distinctive to its environment the structure of the space around to affect. The result than upon dictating look at any object system modularity or deductions get a better relationship rather about the agent’s sequence of actions. Schoppers applies his architecture to the control of a rescue robot operating types of interactional It would be valuable different artifacts and real-time cooperative characterize recognized by Schoppers’ approach. in more detail to apply Schoppers’ framework regularities, such as those interaction with other agents. Future the loose coupling between in space. to environments with more and interaction with research could that is robot and environment involving 4.14. Shoham ad Tennenholtz Shoham and Tennenholtz explore in mathematical large numbers oi‘ simple agents can bc programmed that strategies other. They observe a continuum, from one extreme at which each individual to another extreme li)r programming ;II which agent, the programmers terms the conditions under which to avoid colliding with one an- such agents can be arrayed along specify detailed paths for of the agents engage in negotiations P. E. Agre/Arrifciul Intelligence 72 (I 995) l-52 41 complexity. unbounded of possible “social might develop Shoham and Tennenholtz laws. In the middle region between laws” that might guide agents’ actions. While these social laws through systematic these extremes are a wide variety themselves the agents evolution, reasoning or incremental these for designing focus on the problem of off-line methods in which case study, they consider in two stages. the first stage, is to define a social Their paper develops In the agents attempt at length a traveling to prove that the agents will reach their goals without colliding. This is difficult of the agents sketch a the laws in the particular in a grid. The challenge mathematically when upon general complexity computational for large numbers of agents. Although general case, they specific various conditions the designers the grid. In the second part of their paper, Shoham and Tennenholtz things about social to avoid colliding while the designers limited knowledge of the precise arrangement correct social intractable synthesis of provably laws. In particular, of the automatic law that permits is unsurprisingly this problem they explore for proving formalism have under which a distinctive it can be made tractable. place among specify to provide the papers for the agents them to characterize the use of customs Shoham and Tennenholtz’s traveling on the grid require paper occupies It is the only paper reliable in agents’ their paper fits comfortably with the others in to deal with large numbers of agents, interactions with structure that in the sense to the this special double volume. and with the world. Nonetheless, their agents are embodied. Their bodies are surely primitive, but it does matter definition of the problem, and to the proofs of correctness, occupy space, and have limited perceptual Shoham and Tennenholtz to use the space in specific ways by moving about in relatively conventional particular, their proofs require in enough detail to demonstrate of the ways need not be able those laws. Future these emergent patterns of movement that they converge. Their paper is thus a simple example structure. The agents they need only follow that the agents have locations, and motor capabilities. The social laws that the agents In vise their interactions with one another. It would probably be impractical which another; customs, kinds of impossibly open-ended with time, and agents do improvise mental optimizations of agents who deal with one another in a great deal of this sort of thing, computational simple cases and work upward. the ways in which agents can impro- to posit agents time they encounter one these benefit of making reasoning processes unnecessary. Yet customs do evolve in a variety of ways, from incre- among small numbers regularly. Although human beings clearly engage research should probably begin with to private deals (both formal and informal) innovative ways of interacting after all, have the important these lines might explore customs can provide laws are adequate; invent completely that their social their interactions research along computational interactional in which to prove patterns. reliable every 4.15. Webber et al. Webber and her colleagues describe a project to build an system that can animate the movements of a human Webber et al. point out, differ figure as it follows instructions written in English. Instructions, in numerous ways from computer programs, as well as 42 PE. Agre/Artificiul Intelligence 72 (1995) IL.52 appears structures to be conditioned from the symbolic of instructions are given. This context dependence forms commonly found Webber et al. adduce numerous examples they have studied. in instructions, that AI has long referred by the situation in which to as “plans”. The interpretation the instructions is reflected as well in the linguistic for machines, and in users’ manuals that instructions from the naturally occurring of instructions for instance These insights have numerous implications for research on computational and agency. They illustrate one sense in which the “higher-level” interact with the “lower-level” reasoning must theories of functions functions that the conventional modularity from motor skills might have to role of pragmatics-features interpretation the situated of language of instructions. they suggest of linguistic meaning the significant interaction of language use and symbolic interaction. of sensorimotor that separates the interpretation be rethought. They also suggest that relate to the situation of language-use-in Finally, are central theories of action. In particular, to cognitive As this ambitious and project develops, that relate it will no doubt encounter other to agents ’ interactions with their environments. are cultural, their concepts about action and interaction instructions thought language expectations upon which people rely in interpreting that different cultures organize ways. Interactions shared background are members of the same profession, experience possess a shared background difficult challenge in embodied between people can presuppose understandings, of references the senses activities. for example when the participants in an interaction and thus possess a shared vocabulary and a shared of training, or members of the same family or circle of friends, and thus in the past. A are grounded that have happened in which these phenomena is to understand to things a wide and very subtle features of The in the sense in different range of they force clear thinking about notions such as intentions and expectations that 4.16. Whitehead and Lin Whitehead and Lin explore a number of algorithms for learning in serially to engage learning. Historically, intelligence the technical framework of reinforcement learning has a close association with the behaviorist the main stream of AI research but their work is clearly part of an alternative focused on complex to agents, other work retained a focus upon agents’ school of sought to overcome. Whitehead and tradition cognitive interactions with that it was pointless that the founders of artificial ordered behavior within of course, reinforcement psychology Lin are not nearly behaviorists, within AI. Whereas processes their environments. Behaviorists or meaningless explaining learning process by positive and negative principles based wholly on internal processing. to posit internal internal took this focus to extremes, arguing cognitive processing. But their search behavior based on sequences of stimuli and responses, guided for means of the through explanatory reinforcement, counterbalances The architectures that Whitehead and Lin explore do not maintain models. To the contrary, are grounded architectures in sensorimotor to actively interpret they maintain very simple representations experience. As a result, sensory their available it becomes necessary input in functional of the world complete world that for their terms. The P: E. Agre/Artificial Intelligence 72 (1995) 1-52 43 is likely stimuli the agent its actions will receive. A stimulus to, and it must learn the degree of in a is most likely capable of being generated by things in the world with to accurately predict that has low predictive value to pay attention significance% with the result that it does not provide information to choose correctly among possible actions. A stimulus situation functional agent must actively decide which available which of these stimuli to permit “payoff’ which particular differing that allows high predictive value, on the other hand, world whose states are relevant indexicality limited information. the agent is probably generated by those things to the agent’s decisions. This deep idea connects and active nature of perception with the practicalities of learning that has in the the from The most immediate difficulty with this proposal to be functions of its immediately to architectures to architectures available that can maintain that assume the authors explore much simpler schemes state elements which assist representation tied to the meaningful limited inputs. Whitehead is that it requires the agent’s ac- and Lin therefore types of internal state. In is kept itself is a notion aspects of the agent’s interactions with internal model the architecture that a complex in which it in predicting payoffs. The result tions their analysis extend contrast once again up to date, synthesizes of internal the world. the algorithms tied to functionally This model obviously in the world that permit requires much further development before it can undertake more tasks. One aspect of this development might be a more extensive analysis of the to work well or poorly. The synthesis significant properties of the agent’s sensorimotor idea, and it might work best when dealing with artifacts whose or in environments which have forms of activity. complex structures of internal interactions functional been heavily marked with indications of their normal roles in customary In such settings, ways, corresponding structure of the agent’s states is a powerful states are meant to the objective in it. to be readily distinguishable, structure of the environment states might be channeled the synthesis of internal in comprehensible involvements not simply but to the 5. Case study artifacts An informal in which cultural that I conducted with Ian Horswill review of research case study tasks that would otherwise be extremely complex. [6] will provide in the themes of this special double volume. This research an instructive support activity by simplifying explores one of the ways computational Its ideas are embodied in a computer program called Toast that acts as a short-order cook, cooking a continual the various actions. It does so without having stream of breakfast dishes by interleaving to construct any symbolic plans, perform any search, or engage in any explicit reasoning It can do so because certain properties of the artifacts of cooking about tend to reduce at that needs doing and do it” to least to permit simple strategies such as “find something provably converge is like this, either inside or outside the kitchen, but to indicate some of the ways in which structures in the world can simplify computational to certain kinds of goals. The point is not that all activity complexity of decisions about what to do next-or the computational the future. problems. 44 /?E. Agre/Arti$iciul Intelligence 72 (1995) 1-52 5.1. Model of action increments the consequences (for example, by introducing One place to begin the story is with the assumptions of the classical planning literature. takes a definite stand on the nature of action. Although some authors have of relaxing or complicating one or more of these assumptions This literature explored by certain underlying model of action continues default assumptions “situations” terms of the transition course, the possible whose arcs are labeled with the actions which can lead from one situation this a set of for new projects. The model begins with the idea of “actions” and in to another. The result, of in terms of to situations and to the next. is that the agent’s actual and potential activities can be represented routes through a directed graph whose vertices correspond so that the effects of an action can be represented the literature by providing from one clearly defined as discrete entities, or concurrency), probabilities to anchor situation is going implicitly the possible is concerned, scheme employed is affected by many A great deal of planning the representation situations to take actions or explicitly, with things, most prominently to identify research structure of this graph. This structure agent’s repertoire of actions, actions and dissect itself. If an agent must be guaranteed arrives at a desired end-point any beginning-point beginning-point. Whether, and how efficiently, a plan will depend on the structure of the state graph branching graph can be exploited the the the possible in the world, and the structure of the world that plan in the world by executing that from the agent has about the to discover such (large or small, high or low etc.) and on the ways in which the structure of the that is consistent with whatever knowledge from a given beginning-point-or, (at least probabilistically) to trace a path through factor, clear landmarks, it should be possible more precisely, the graph a plan, in designing Investigation of the computational to search it. algorithms properties of the state-space graph structure, of the idea of a plan or the idea of activity as plan-execution. is that the world includes structures though, through simple forms of improvisation without It is sometimes necessary to engage the future, of course, and to make representations of action that these more complex to a substantial (cf. in the [ 32,471) because like to suggest and controlled forms of moment-to-moment is that of cooking breakfast in choosing I wish to make clear our intentions domain defined properties but regularly admits of uncertainty organized [4,8,48] ). We do not claim [ 341) . Rather, we formalize cooking, of course for purposes of our analysis using the formal methods of the classical planning In employing them, but rather to demonstrate our goal extent by the structures action choice. restaurant, and in a short-order is an attractive this domain. Cooking it is fairly complicated but still routine, has fairly well- and surprise, and has plainly been (cf. in large part by vision of actual breakfast- the activities of cooking breakfast literature. that underlie them. Finally, for making breakfast, but the assumptions how the research process points beyond in customary ways to allow action is not to invent a sophisticated these methods our purpose all of the complexities is not to endorse new architecture to be driven to analyze (cf. to be conducted is conceptually independent The upshot of our research of action of explicit plan-construction. about activities. But we would about action are delimited world that support simpler Our domain, once again, that permit a great deal the necessity reasoning to help guide future forms of reasoning in symbolic PE. Agre/Artificial Intelligence 72 (1995) I-52 45 rather to discover structures within the domain that make the invention of sophisticated architectures unnecessary. The real work, in other words, is taking place at the designer’s level, in the “aerial view”, discovering regularities that can permit an agent operating at the “ground level” to get along with relatively simple policies. To explore the structure of cooking world, we elaborate the traditional formal frame- work by using an object-centered representation of action. The objects in question are those found in cooking tasks, such as pots and pans, tools and utensils, and materials such as food ingredients. The agent’s actions all pertain in some way to these objects: moving them, transforming them, mixing them, cleaning them, and so forth. The state of the world can be decomposed into the states of these objects and a small number of possible relationships among them. The states of an egg, for example, can include being intact, being broken, being beaten, and being cooked. A bowl can be filled, empty-and-dirty, and empty-and-clean. These descriptions of states obviously fail to capture all of the properties that the objects could possibly have. The formalization of these actions is analogous to the model of actions employed by a classical planning program: each possible action has a set of preconditions and a set of effects. The difference is that these preconditions and effects must be expressed in terms of the properties and relationships of objects. The action of cleaning a given spoon, for example, has no preconditions at all, since it makes sense to clean a spoon regardless of what state it is in; the effect of this action is to move the spoon into the “clean” state. The action of beating an egg with a fork in a bowl has the preconditions that the fork be clean (if the set of states is more elaborate, of course, the fork can be in the state of being dirty-with-beaten-egg, so that the egg-stirring fork need not be cleaned after each episode of stirring), that the egg be broken, and that the broken egg be located in the bowl; its effects are that the egg moves into the “beaten” state, the fork moves into the “dirty” state, and the beaten egg remains in the bowl. Much of the formalism, then, concerns the states of objects. In particular, the state of the world at any given moment will consist in large part of the states of all objects. As with any conventional formalism, it would be possible to generate a graph structure that contains all of the possible world-states and the actions that can be taken to move from one world-state to the next. If the kitchen contains a large number of objects, of course, this graph will be enormous because of the large number of actions that can be taken at any moment and the huge number of possible combinations of individual object-states. The enormity of this graph obviously conceals a great deal of structure within it. This becomes evident if we represent the state-space graph in another, object-centered way. If we neglect for the moment the relationships among objects, we can view each object as having its own state graph. The structure of this graph will depend on what type of object it is, so that the graph for eggs has one structure, which might include states to “intact”, “broken ” “beaten”, and “cooked”; and the graph for forks corresponding will have another structure, which might have the states “clean” and “dirty”. Given such graphs for each type of object, the state space of the whole world can be understood as the cross-product of the state-space graphs for each individual object. In fact, the whole world’s state-space graph is a subset of this much larger cross-product graph, since it only includes actions that can actually be taken with the objects that are present. A , 46 P.E. A,qre/Art~fi~icrl I~~tltrllipnce 72 (1995) l-52 world without beaten. forks, for example, will include no state-transitions in which eggs are representing This idea of decomposing state graphs by interpreting for these graphs as statecharts. Simply a correct plan within a given graph is unsolvable or intractable them as the products of graphs for individual objects has already been introduced by Hare1 [ 34,351, who refers to his planning problems within notation If the problem of such a notation, of course, does not change identifying in the search to the product graph then it is equally unsolvable or intractable when space corresponding state-graph in a different way. The purpose of the object-centered is drawn the graph formalism, like making structure of domains the implicit then, to provide a language within which breakfast them. Such additional to express additional difficult domain structure might into a much more straightforward as they are already defined, but also that might be discovered within their inherent complexity. from a computationally is not simply structures transform to reveal can found structure arc primarily Additional tools and materials. state raw states. and items of food like eggs. cups of water, and pats of butter. Tools include in the domain by categorizing in kitchens. Let us consider Informally the state- two major graphs for the types of objects actually speaking, materials categories, which might be called things include tool like forks and spatulas which tend to has a distinguished to pass through a series of further states as have original, time, furthermore, to them with tools. Tools, things are done the necessity of invoking other objects that regardless of what state they arc in, without If a sponge or brush is used to clean a tool, might be in inconvenient then it will always tools and materials. cover a large proportion of the objects found in kitchens, and their properties arc much more specific than tho worst, most complex state graphs and actions that might be imagined used to do things is clean, dry, and ready to materials. Every to use. Materials und in a suitable state. These two categories, can be cleaned at any it they tend states themselves. in the abstract. be available in which cooking breakfast one. indeed be found 5.2. Fornmlisn~ these Given intuitions, let us outline a simple concrete object.) Each object for domains that involve formalism objects and actions. Such a domain will have a set of object types. (The term “object” can be used instead when the context makes clear that one is speaking of an object type and not a particular state graph, is a finite directed graph whose vertices are called states and whose arcs are which is the arc itself, not a label on the arc. Each called operations. Note that the “operation” types. The domain will operation also have a set of action types, each of which has an associated set of operations drawn type from the graphs associated with the domain’s object types. For example, of beating an egg might have two operations, corresponding from from “clean” “broken” is thus unique and is not shared by different object to the egg’s transition to “dirty”. to “beaten” and the fork’s transition type has an associated the action Let us say that an action is focused involves a single object). A state in a given object be reached from any other state if it consists of a single operation is, if it if it can in that graph using only focused operations. A tool, type’s state graph is free (that PE. Agre/Artijcial Intelligence 72 (1995) I-52 41 then, distinguished is an object with at least one free state in its state graph. Each tool will have a free state, its normal state. An example of a normal state is “clean”. Given a set of tool types, it becomes possible to define a material. The basic idea is (most commonly tools to do things is not a tool. A normal to materials. A tool action is an action involving that one uses clean also one object some finite number of tools the actions class which in their normal states. A material is an involving tools require object with an acyclic state, the raw state, from which any other state in the graph can be reached purely by means of normal in its state graph besides the ones included tool actions. The material might have other operations tool actions. that those tools originate state graph which includes a particular, distinguished tool action is a tool action one tool), and possibly in normal in which A cooking task is a task which has these four properties: l all of the objects are tools and materials, l enough l every instance of material starts out in its raw state, and l the goal is to move some of the materials, states. types, into other particular material tools exist to perform each of the actions required by each type of material, all of which are instances of different Informally, policy: it is possible to solve a cooking problem by repeatedly applying a simple l Choose a material l Determine in order action l Inspect to reach that has a goal state but is not yet in it. its current state, look up in a table which state it must pass through next tool table a normal its goal state, and then look up in another state change. this necessary that is capable of affecting the list of tool types required by this action. If the world contains a tool in these tools to execute their its normal state for every one of these tool types then employ the action, states. the material and all of the tools to potentially thus causing change l If there exists a tool type in the required action to any in its normal state, then choose one of these that does not correspond tool in the world which problematic tool types. q Choose a tool of this type. Determine is currently its current slate, look up in a table which state it must pass through next in order to reach its goal state, and then look up in another state change. Then take that action. that can effect this necessary table a focused action to see why (if not before), it becomes possible type’s state graph is finite, it is possible this simple policy works. Each action either moves a material its goal state or moves a tool toward state It is easy toward normal state. Since every material number of state transitions Likewise, tool an upper bound on the number of state transitions through reduces one of these quantities, necessarily action ever increases its normal state. When every tool is in its its goal toward the total to calculate in the goal must go through. to place that the tools in the world must go to become possible. Since every action from their goals decreases whenever all of the tools are in their normal states, and since no that that the materials mentioned type’s state graph in order for an action upon a material since the total distance of the materials the total distance of the materials from their goals, it follows to move a material is finite as well, it is possible since every 48 l?E. Ape/Artificial Intelligence 72 (1995) 1-52 the materials with goal states will eventually reach them. for which assumptions. holds are “containers” thus temporarily making such as cups, plates, bowls, to a purpose over a long period, relies on a large number of simplifying This argument obviously relations together or split into pieces. As well, it has been assumed example, be mixed be committed being used for any other purpose. The major category of objects condition burners. This category also includes clamps and vises, implements. The major pitfall associated with containers the key to avoiding of them are not available scheduling. Potentially world’s structure can isolate (The intuition here is similar presented by Dechter and Pearl by a judicious to the architecture. My purpose here, though, detail to accommodate Instead, I wish to present Referring back to the discussions For among objects have not been taken into account and objects cannot that no object can it incapable of this latter frying pans, and stove though very few other kitchen is running out of them, and to have enough of them at hand. If enough type of to engage thus has its place, but analysis of the small corner of the total activity. satisfaction for efficient constraint can likewise be remedied in the world and limited extentions in enough the formalism its usefulness. them as an instance of the ideas in this special double volume. is not to develop even to thoroughly vindicate is simply it will become necessary this place to a relatively to that of the algorithms in Section 2, let us consider [ 18 ] .) Other simplifications this pitfall then complex plan-construction these possibilities-or these in turn. combination to structure of appeals in some l Aerial and ground views. The whole formalism of states, actions, tools, materials, and so forth is part of the designer’s aerial view, not the agent’s ground view. The that involves agent can employ a simple policy in information tables, and the designer lead to a correct that this policy will always outcome, l Structure if not necessarily in the world. The domain of cooking breakfast was discovered looking up certain an optimal one. can prove that could assist an agent some useful kinds of structure a simple way. This structure can be viewed as an abstraction actions on tools forming another abstraction layer. The model can obviously be generalized layer of abstraction forming one [ 441. and in choosing to have in hierarchy, with the the actions on materials actions to several layers of in the world” was not l Located in the practices. The “structure (the tools and materials) together with a customary all by themselves. set of practices objects objects that another culture might employ eggs and forks and spatulas activities with different computational these objects being used in the ways that are familiar American kitchens. them. It is conceivable in wholly different properties. The proofs here depended on in located it was located from the simplest in the in the for using Instead, recipes l Looking for structure. The search complexity of unconstrained computational ticular by the enormous domains. This structure compensates ensuring that the necessary are so constrained search spaces that planning methods plan-construction for this structure was motivated by the great problems, and in par- face in most realistic for the difficulty of searching huge spaces by spaces are small, and indeed that subgoal interactions l Convergence. The proof of correctness that search becomes unnecessary. is precisely, in computer science terms, a P: E. Agre/Artificial Intelligence 72 (1995) 1-52 49 proof of convergence. It proceeds along the lines of classical program correctness proofs using progress functions that can be demonstrated to move continually toward the goal state of zero. l Cultural support. The structure in the world is not a simple matter of physics but is located largely in artifacts such as tools. As Vygotsky suggested (see the account of Vygotsky’s the people who invented the artifacts of cooking effectively rendered concrete a type of knowledge for simplifying tasks without requiring everyone in future to understand this knowledge in any explicit way. ideas above), 6. Conclusion This introduction has sketched an emerging method of computational research on interaction and agency. It has placed this method in the context of a variety of other fields and it has illustrated them through summaries of the articles and a case study. The shape of future research in this area cannot be predicted in detail, this being the nature of research. The precedents offered by the papers in this double volume, though, do make clear that research on computational theories of interaction and agency provides a fertile territory for the cross-pollination of a wide variety of different fields, each with its own conception of interaction and its own models of agency. Changing the metaphor, perhaps the continuation of the trend will help to transform artificial intelligence from a self-contained discipline to a kind of interdisciplinary switchboard for the construction of principled characterizations of interaction between agents and their environments. Acknowledgements The electronic mail archive for this project contains over 4000 messages totaling nearly five megabytes (not including manuscripts). Clearly the editors ought to acknowledge the contributions of numerous individuals and organizations, and they are happy to do so. Danny Bobrow and Mike Brady supported the project over a long period. Approximately sixty referees wrote well over 300 pages of exceptionally useful comments on the manuscripts. The American Association for Artificial Intelligence and Philips Research Laboratories New York provided grants to support the Workshop on Computational Theories of Interaction and Agency at the University of Chicago in February 1993, in which the authors assembled to discuss early drafts of their papers. We wish to thank the University of Chicago Computer Science Department’s AI Group for acting as our hosts for this workshop, and Tim Converse for coordinating the local arrangements. Finally, the authors themselves gracefully acceded to numerous requests for revisions and considerable delays in the mechanics of the editorial process. We hope that they and the reader will benefit from the result. References I I] RE. Agre, The symbolic worldview: Reply to Vera and Simon, Cogn. Sci. 17 ( 1) (1993) 61-69. SO PE. Agre/Artifcial Intelligence 72 (1995) 1-52 121 P.E. Agre, Interview with Allen Newell, Artif. lntell. 59 (1-2) [ 31 P.E. Agre, The soul gained and lost: Artificial (1993) 415-449. intelligence as a philosophical project, Stanford Humanities Review, to appear. [ 4 I PE. Agre and D. Chapman, Pengi: An implementation 196-201. Seattle, WA (1987) of a theory of activity, in: Proceedings AAAI-87, 15 1 PE. Agre and D. Chapman, What are plans for?, in: P Maes, ed., Designing Autonomous Agents: Theory and Practice from Biology to Engineering and Back (MIT Press, Cambridge, MA, 1991). 161 PE. Agre and 1. Horswill, Cultural support for improvisation, in: Proceedings AAAI-92, &n Jose, CA (1992). [ 7 1 J. Allen, J. Hendler and A. Tate, eds., Readings in Planning (Morgan Kaufmann, San Mateo, CA, 1990). 181 D.H. Ballard, Animate vision, Artif: fntell. 48 ( 1) ( 1991) 57-86. as Adaptive Behavior: An Experiment 191 R.D. Beer, Intelligence (Academic Press, Boston, MA, 1990). in Computational Neuroetholagy 1 IO) R.A. Brooks, I 1 1 I P. Bourdieu, Outline af a Theory af Practice, Intelligence without representation, Art% Intell. 47 ( 1-3) ( 1991) 139-160. translated by Richard Nice (Cambridge University Press, Cambridge, England, 1977) Originally published in French in 1972. [ 12 1 R.J. Brachman and H.J. Levesque, The tractability of subsumption in frame-based description languages, in: Proceedings AAAI-84, Austin, TX ( 1984) 34-37. [ 13 j V. Braitenberg, Vehicles: Eqeriment.s I 141 D. Chapman, Planning for conjunctive goals, Art@ Intell. 32 (3) ( 1987) 333-377. [ 15 1 D. Chapman, Vision, Instruction. and Action (MIT Press, Cambridge, MA, 1991 ). [ 16 1 H.H. Clark and D. Wilkes-Gibbs, Referring as a collaborative [ 17 1 J.L. Comaroff and S. Roberts, Rules and Proresses: The Cultural Lqtc afDispute in Synthetic Psychology process, Cngnitia,t 22 ( 1) ( 1986) I-39. in an African Context (MIT Press, Cambridge, MA, 1984). (University of Chicago Press, Chicago, 198 I). I181 R. Dechter and J. Pearl, The anatomy of easy problems: a constraint-satisfaction formulation. in: Proceedings IJCAI-85, Los Angeles, CA ( 1985) 1066- IO72. [ 19 1 G.L. Drescher. Made-Up Minds: A Canstructivist Approach ro Arrijnial Inte//igence (MIT Press, Cambridge, MA, 199 I ) 1201 H.L. Dreyfus, What Computers Can’t Do: A Critrque ofArtificial Reason (Harper and Row, New York, 1972). I21 1 Y. Engestrom. Learning by Expanding 122 1 R-E. Fikes and N.J. Nilsson, STRIPS: a new approach ( Orienta-Konsultit Oy, Helsinki, 1987). to the application of theorem proving to problem solving, Arttf Intell. 2 (3) ( 197 1) 189-208. I23 I R-E. Fikes, PE. Hart and N.J. Nilsson, Learning and executing generalized robot plans, Artif Intell. 3 (4) (1972) 2.51-288. I24 I R.E. Fikes, PE. Hart and N.J. Nilsson, Some new directions in robot problem solving, in: B. Meltzer and D. Michie, eds., Machine Intelligence 7 (Wiley, New York, 1972). [25 I R.J. Firby, An investigation WA (1987) 202-206. into reactive planning in complex domains, in: Praceedings AAAI-87, Seattle, 1261 M.S. Fox and S. Smith, ISIS: A knowledge-based system for factory scheduling, Expert Syst. 1 ( 1) ( 1984) 25-49. 1271 M.R. Genesereth and N.J. Nilsson, Logical Foundations af Artificial Intelligence (Morgan Kaufmann, Los Altos, CA, 1987). 128 I M.P. Cieorgeff and A.L. Lansky, Reactive reasoning and planning, in: Pmceedings AAAI-87, Seattle, WA ( 1987) 677-682. 129 1 J. Goody, The Logic of Writing and the Organization of Society (Cambridge University Press, Cambridge, England, 1986). I30 I B.J. Grosz and C.L. Sidner, Plans for discourse, in: P.R. Cohen, J. Morgan and M.E. Pollack, intentions in Cammunicution (MIT Press, Cambridge, MA, 1988). I 3 1 J N. Gupta and D. Nau, On the complexity of blocks-world I32 ] K.J. Hammond, T. Converse and C. Martin, Integrating planning and acting planning, Art8 Intell. 56 (2) ( 1992) 223-254. framework, in a case-based in: Pmceedings AAAI-90, Boston, MA (1990. FE. Agre/Artificial Inielligence 72 (1995) I-52 51 reasoning 1341 C. Hardyment, 1331 S. Hanks and D. McDermott, Modeling a dynamic and uncertain world about change, Artif: Intell. 66 ( I ) ( 1994) l-55. I: Symbolic and probabilistic From Mangle lo Microwave: The Mechanization of Household Work (Polity Press, Oxford, England, 1988). 135 J D. Harel, Statecharts: A visual formalism for complex systems, Sci. Cornput. Program. 8 (3) (1987) 23 l-274. [ 36 j D. Harel, On visual formalisms, Commun. ACM 31 (5) (37 J H. Haste, Growing ( 1988) 514-530. into rules, in: J. Bruner and H. Haste, eds., Making Sense: The Child’s Construction of the World (Methuen, London, 1987). 1381 PJ. Hayes, [ 391 M. Heidegger, Being and Time, translated by J. Macquanie In defense of logic, in: Proceedings IJCAI-77, Cambridge, MA (1977) 559-565. and E. Robinson (Harper and Row, New York, 1961). Originally published in German in 1927. 140) J. Hendler, ed., Planning in uncertain, of the or changing at Stanford, University of Maryland Systems Research Center Repott SRC TR 90-45 environments, unpredictable, proceedings AAAl symposium (1990). ] 4l] G.E. Hinton and D.S. Touretzky, Symbols among the neurons: details of a connectionist inference architecture, in: Proceedings IJCAI-85, Los Angeles, CA ( 1985) 238-243. I42 1 H.A. Kautz and E.P.D. Pednault, Planning and plan recognition, AT & T Tech. J. 67 ( I ) ( 1988) 25-4 I. [43] D. Kirsh, Today the earwig, [ 441 C.A. Knoblock, Automatically [45] N. Kushmerick, S. Hanks and D.S. Weld, An algorithm for planning, Artif Intell. 68 (2) ( 1994) 243-302. in: tomorrow man?, Artif. fntell. 47 (l-3) generating abstractions least-commitment for probabilistic planning, 161-184. (1991) Proceedings AAAI-94, Seattle, WA ( 1994). [ 46 ] C.G. Langton, ed., Artificial Life II: Proceedings of the Workshop on the Arnficial L$e, Santa Fe, NM (1990). I47 1 AL. Lansky and D.S. Fogelsong, Localized representations and planning methods for parallel domains. in: Proceedings AAAI-87, Seattle, WA ( 1987) 240-245. ] 48 ] J.H. Larkin, Display-based problem solving, in: D. Klahr and K. Kotovsky, eds., Corrz@~ Infinmation Processing: The lmpacr of Herbert A. Simon (Erlbaum, Hillsdale, NJ, 1989). [ 491 K.S. Lashley, The problem of serial order in behavior, in: L.A. Jeffress, ed., Cerebral Mec~harrisrrr in Behavior: The Hixon Symposium (Wiley, New York, 195 1). [SO] B. Latour, Visualization and cognition: Thinking with eyes and hands, Know/edge and Sociery: Studies in the Sociology of Culture Pasr and Present 6 ( 1986) I-40. [ 5 I 1 J. Lave, Cognirion in Practice: Mind, Mathematics, and Culture in Everyday Lge (Cambridge University Press, Cambridge, England, 1988). 1521 D. Man; &ion 1531 M.T. Mason, Mechanics and planning of manipulator pushing operations, (Freeman, San Francisco, CA, 1982). Inr. J. Rob. Res. 5 (3) ( 1986) 53-71. [ 541 H.R. Maturana and F.J. Varela, The Tree of Knowledge: The Biological Roots of Human Understanding (New Science Library. Boston, MA, 1987). and D. Rosenblitt, Systematic 1551 D. McAllester nonlinear planning, in: Proceedings AAAI-9I, Anaheim, 1561 I571 I581 1591 1601 161 I I621 translated from the French by Colin Smith (Humanities and K.H. Pribmm, Plans and the Sfructure of Behavior (Holt, New York, CA (1991) 634-639. M. Merleau-Ponty, PhenomenologyofPerceprion. Press, New York, 1962). G.A. Miller, E. Galanter 1960). A. Newell, Unified Theories of Cognition (Harvard University Press, Cambridge, MA, 1990). A. Newell and H.A. Simon, GPS: A program J. Feldman, eds., Computers and Thought (McGraw-Hill, New York, 1963) 279-296. D. Newman, P Griffin and M. Cole, The Construction Zone: Working for Cognitive Change in School (Cambridge University Press, Cambridge, England, 1989). S.B. Ortner, Theory (1) D.W. Payton, J.K. Rosenblatt 20 (6) in anthropology since the sixties, Comparative Studies in Society and History 26 IEEE Trans. Syst. Man Cybern. and D.M. Keirsey, Plan guided that simulates human in: E.A. Feigenbaum (1990) 1370-1382. 126-166. reaction, thought, (1984) and 52 PE. Agre/ArfiJcial Intelligence 72 (1995) I-52 [ 63 ] .I. Piaget, The Construcrion of Reality in the Child, translated by Margaret Cook (Basic Books, New York, 1954). [64] M.E. Pollack, The uses of plans, Arfif. Intell. 57 ( 1) ( 1992) 43-68. 165 1 Z.W. Pylyshyn, ed., The Robot’s Dilemma The Frame Problem in Artificial InieBigence (Ablex, Norwood, NJ, 1987). [ 661 M.R. Quillian, Semantic memory, in: M. Minsky, ed., Semantic Information Processing (MIT Press, Cambridge, MA, 1968). 1671 M.H. Raibert. Running with symmetry, [ 68 1 S.J. Rosenschein properties, Knowledge, Monterey, CA ( 1986). in: J. Halpem, Inr. J. Rob. Rex 5 (4) (1986) 3-19. and Leslie Pack Kaelbling, The synthesis of digital machines with provable epistemic ed., Proceedings Conference on Theoretical Aspects of Reasoning About 169 1 E.D. Sacerdoti, Planning 1701 M. &hoppers, Universal plans for reactive robots in a hierarchy of abstraction spaces, Art$ Infell. 5 (2) in unpredictable environments, ( 1974) 115-135. in: Proceedings IJCAI- 87, Milan, Italy (1987) 1039-1046. [ 7 1 1 H.A. Simon, Administrative Behavior: A Study of Decision-Making Processes in Administrative Organization (Macmillan, New York, 2nd ed., 1957). [ 721 L.A. Suchman, Plans and Situated Actions: The Problem of Human-Machine Communication (Cambridge University Press, Cambridge, England, 1987). 1731 J.A. Toth, Review of Kenneth Ford and Patrick Hayes, eds., Reasoning Agents in a Dynamic World: The Frame Problem Artif Intel/.. 73 ( 1995), to appear. [ 741 F.J. Varela and P. Bourgine, eds., Toward a Practice of Autonomous Systems: Proceedings of the First European Conference on Artificial Life (MIT Press, Cambridge, MA, 1992). 175) F.J. Varela, E. Thompson and E. Rosch, The Embodied Mind: Cognifive Science and Human Experience (MIT Press, Cambridge, MA, 1991). 1761 L.S. Vygotsky, Mind in Sociefy: The Development of Higher Psychological Processes, M. Cole, V. John- (Harvard University Press, Cambridge, MA, 1978). eds. Steiner, S. Scribner published Originally and E. Souberman, in 1934. in Russian 1771 D.S. Weld, Reasoning [ 781 D.E. Whitney, Historical perspective and state of the art in robot force control, about model accuracy, Artif In/ell. 56 (2) ( 1992) 255-300. Inf. J. Rob. Res. 6 ( 1) (1987) 3-14. [ 791 W.A. Woods, What’s in a link?, in: D.G. Bobrow and A. Collins, eds., Represenfation and CInderstanding: Studies in Cognirive Science (New York, Academic Press, 1975). [ 80 1 J. Yates, Confrol through Communication: The Rise of System in American Management (Johns Hopkins University Press, Baltimore, MD, 1989). 