Artificial Intelligence 103 (I 998) 2099235 Artificial Intelligence A gentle introduction to NUMERICA Pascal Van Hentenryck ’ Brown lJniver.sity, Box 1910. Providence, RI 02912, USA Abstract NUMERICA is a modeling to express these problems it possible textbooks or scientific papers. In addition, combines about correctness, convergence, and completeness. techniques language for stating and solving global optimization problems. It makes in a notation close to the way these problems are stated in algorithm of NUMERICA, which intelligence, provides many guarantees the constraint-solving from numerical analysis and artificial This paper is a gentle introduction to NUMERICA. It highlights global optimization methods. high-level, way. 0 1998 Elsevier Science B.V. All rights reserved. the essence of the constraint-solving It also presents and illustrates the functionality of NUMERIC A by contrasting some of the main difficulties of it to traditional algorithm of NUMERICA in a novel, 1. Introduction Many science and engineering applications require the user to find solutions to function includes problems, and of electrical robot kinematics, such as the modeling applications circuits, (e.g., nuclear to find all solutions of chemical reactor design). The field of constraints over real numbers or to optimize a nonlinear constraints. This processes and design problems is the study of methods systems of nonlinear to nonlinear subject chemical engineering equilibrium global optimization to systems of nonlinear constraints and all global optima to optimization problems. Nonlinear problems raise many issues from a computation if a set of polynomial constraints has a solution the problem programming problems up to, say, 20 variables. On the other hand, computing over real numbers numerical problems because of the finite nature of computers. lies in NP. Nonlinear to solve raises is NP-hard. In fact, Canny [4] and Renegar [36] have shown that can be so hard that some methods are designed only is in PSPACE and it is not known whether the problem standpoint. On the one hand, deciding problems ’ E-mail: pvh@cs.brown.edu OOO4-3702/98/$ - see front matter 0 1998 Elsevier Science B.V. All rights reserved. PII: SOOO4-3702(98)00053-8 210 F1 Vun Hrnrrniyk /Arrijicial Intvlligence 103 (1998) 209-235 NUMERICA 1391 is a modeling to solve nonlinear problems written in a form close to the statements textbooks and scientific papers. In addition, and contrary tools, NUMERICA provides many guarantees on its results (modulo implementation traditionally to most nonlinear programming errors): language for global optimization which makes it possible found in l Correctness: NUMERICA never produces any wrong solution; l Completeness: Under reasonable assumptions, NUMERICA is guaranteed to nonlinear equation systems and all global optima to unconstrained to isolate and all solutions constrained optimization problems; l Finiteness: NUMERICA is guaranteed l Certainty: NUMERICA can prove to converge; the existence of solutions and the absence of solutions. These functionalities should be contrasted with traditional numerical methods (e.g., quasi- local: they converge quickly when Newton methods). Traditional methods are inherently they are close to a solution or to a local optimum but it is outside the scope of these methods to find all solutions (or global optima) or to prove the existence or absence of solutions. Traditional methods may also fail to converge on hard problems. The limitations of local methods come from their inability to obtain global information functions. There on nonlinear is no way to collect global probing finitely many points. In contrast, NUMERICA has the ability to evaluate nonlinear functions over intervals, which provides global on the value of the function on any point in the intervals. The global nature of this information makes it possible bound numerical errors automatically a consequence, for nonlinear programming. to and to prune away entire regions of search space. As the use of intervals makes it possible to implement global search algorithms on a function by information information relaxation techniques intelligence Of course, computations in numerical the use of intervals is hardly new, since it from Moore’s thesis in 1966 [28] and is a very active research area (e.g., [ 12-15, algorithm of NUMERICA is the constraint-solving to obtain level, NUMERICA into discrete problems, which is exactly [lo]). Once (e.g., in integer programming to apply it is natural (e.g., [25-271) which have been originated 18,20-23,28,32,37]). What distinguishes of techniques the combination techniques effective pruning can be viewed as mapping continuous problems the opposite of traditional nonlinear programming techniques consistency applied in many areas [40]. successfully its constraint-solving problems are viewed as discrete problems, such as arc- and path-consistency from numerical analysis and artificial (for many problems). At a very abstract local the thousands of of the the robustness of the approach true for small-scale highly nonlinear problems as in chemical and electrical engineering where traditional methods are likely (a that progress methods. Local methods are extremely effective tools when they apply and are probably only way to approach large-scale nonlinear programming problems variables. However, NUMERICA are needed, either because of the nature of the application, problem simplifies those found to diverge, are unable requirement in chemical engineering there are many applications where the additional is too hard for local methods, or simply because in these problems). Gehrke and Marquardt to locate all solutions or to prove the need for these functionalities. functionalities or because does not aim at replacing the task. This is especially the absence of solutions [ 111 in fact indicate NUMERICA, and algorithm, involving increases I? Van Hentenryck / ArtiJcial Intelligence 103 (I 998) 209-235 211 The as follows. Section 2 discusses rest of this paper programming is organized of nonlinear problems, difficulties. Section 3 is a short tour of NUMERICA, which depicts variety of problems and contrasts level, presentation of the main constraint-solving concludes NUMERICA can be found in [38,39]. on a it to traditional methods. Section 4 is a novel, very high- algorithm used in NUMERICA. Section 5 about for further research. More information the paper and suggests directions the nature and practical its functionality theoretical limitations including 2. The nature of nonlinear programming This section discusses some of the properties of nonlinear systems and some of the limitations of traditional methods. 2.1. What is possible and what is not? Today’s computers can manipulate the solution of a nonlinear problem may be a real number that cannot be represented finite space or displayed on a screen in finite time, the best we can hope for in general point close to a solution or an interval enclosing a solution. and store only a finite amount of information. Since in is a (preferably with some guarantee on its proximity to the solution) Computer methods for solving nonlinear problems typically use floating-point real numbers. Since there are only finitely many floating-point numbers to approximate numbers, these methods are bound to make numerical errors. These errors, although probably small for in isolation, may have fundamental considered instance, Wilkinson’s problem, which consists on the results. Consider, in finding all solutions to the equation implications 20 I-I i=l (x + i) + px’” = 0 [-20.4, it has no solution. Wilkinson’s in the interval When p = 2-23, numerical have fundamental require users of numerical With this in mind, consider positive values for x; (1 < i < 10) satisfying -9.41. When p = 0, the equation obviously has 11 solutions. that a small can issues software to exercise great care when interpreting their results. the following combustion problem, which consists of finding for the results of an application. These numerical error (e.g., assume implications that p is the output of some numerical problem clearly the equations computation) indicates x~+~X~+X~+~XIO= 10P5, X3+Xs=3.10-5, xt+X3+2X5+2Xs+X9+Xto=5~10-5, x4 + 2x7 = 10P5, 0.5140437 lo-7 X5 =x;, 0.1006932 1O-6 X6 =2x;, 212 I? Van Hentenryck /Artijicial Intelligence IO3 (19%‘) 209-235 0.7816278 0.1496236 lo-l5 x7 =x2 4> lo@ x8 =x1x3, 0.6194411 1O-7 x9 = x1x2, 0.2089296 lo-l4 xl0 =x,x;. Using (0.5, . . ,0.5) as starting point and the default setting of the system, a well-known commercial to obtain point, say b, and prints a warning desired accuracy. It is not obvious way. system produces a point, say a. In the same conditions but with the defaults set system produces another to achieve the that the machine precision in this case how to interpret the highest numerical precision, these results in a meaningful the same commercial is not sufficient It is also interesting uniqueness of solutions and Schnabel the existence or to mention is outside the scope of computer algorithms. For instance, Dennis the common belief that proving in their excellent text [8] present the three functions fl (x) =x4 -12xX+47x2-60x, f*(x) =x4 - 12x” + 47x2 - 60x + 24, .f3(x) =x4 - 12x3 + 47x* - 60x + 24.1 and state: computer routine that would tell and 5; the real roots of f*(x) are x = 1 and f3 (x) has no real roots.” that there will ever be such a routine. It would be wonder@1 if we had a general-purpose us: “The roots of fl (x) are x = 0,3,4, x 2 0.888; It is unlikely existence and uniqueness-does beyond the capabilities one can expect of algorithms In fact, we must readily admit that for any computer algorithm ,functions (injinitely continuously differentiable, the algorithm. Therefore, ull a user can be guaranteed u nonlinear problem is the answer “An approximate “No approximate solution to the problem was found solution in the allocated if you wish) perverse enough that solve nonlinear problems. there exist nonlinear to defeat to .‘I or from any algorithm applied to the problem is a problem have a solution and is it unique?-ure In general, the questions oj time.” is not correct This statement wonderful procedures the limits computers) and one of them is used in NUMERICA. in fact exist (within in general and applies mainly to local methods. Such imposed by the finite nature of 2.2. Local versus global optimum Traditional globally to a local optimum converge to isolate all local optima and minimization of the function convergent methods when applied problem from almost all starting points. They are unable however is well illustrated by the the global optima. This limitation to a minimization 5 xi i=l cos((i + 1)x + i) P: Van Hentenryck /Artijicial Intelligence 103 (1998) 209-235 213 (1 - ~1~2)~3[exp(k5klk - g3,C~x710-~ -g5kxgle-33))-ll-_gjk+g4kx2=O(l~k~4) (1 - xl~2)~3[exp(.vJm - ~2k - ~3~710-3 +,~4~.~~10-3))-11-~~~.~,+g4~=0(1~k44) X,X3 -X2X4=0 Fig. 1. The transistor modeling problem and the maximization of the function - c5i i=l ( cos(G - 1)X1 + i) CScos((i + 1)X2 + i) i( i=l 1 as well as by the minimization of the function f(xl , . . . , x,) defined as 10sin(nyl)2 + (yn - 1)2 + C(yi - 1)2(1 + 10Sin(nyi+l)2). n-1 i=l local minima. For instance, local These functions have many that a local minima when FZ = 10 but only a single global minimum. method will converge towards a global minimum without external knowledge about these problems. 2 Also, a local method will never be able to prove that the global minimum has been found. the last function has 10” It is unlikely is much harder than finding to the size of problems which can be solved globally Of course, finding global optima whole search space must be explored limits NUMERICA also offers the possibility of finding local optima, sacrificing of the search but preserving local optima. local optima, since the there are in practice. For this reason, the completeness the numerical correctness and the ability to prove existence of (at least implicitly). As a consequence, 2.3. Convergence limitations, implemented to the above theoretical In addition problems when convergence. An interesting example Ebers and Moll [9]. The problem to the system of nonlinear equations depicted in Fig. 1 where the variables xi must take their values in [0, lo] and the constants are given by local methods also suffer from practical is of course in this context is the transistor modeling example of on a computer. One of the main problems is to find a solution 0.485 0.369 0.752 1.254 0.869 0.703 0.982 1.455 5.2095 10.0677 22.9274 20.2153 23.3037 101.779 111.461 191.267 28.5132 111.8467 134.3884 211.4823 * Of course, there always exists a starting point that will converge towards the global optimum 214 F( Van Hententyck /Art@d Intelligence 103 (1998) 209-235 Ratschek and Rokne [35] summarize various attempts using local methods and states to tind a solution to this problem [7] combined local damped Newton-Raphson In 1974, Cutteridge the method with eigenvalue conjugate gradient method and a second-order gradient-descent determination where the two latter methods were applied to the least squares problem [. . .] Cutteridge emphasized that only the sophisticated combination of the three methods to only use the first two approaches had led to a positive result, i.e., it did not sufice mentioned above [. . .]. steps with constraints some external is convergence algorithms are guaranteed important practical problem that fails Another solution to satisfy statement. Globally convergent or some local minimum given solution. For instance, a traditional quasi-Newton method applied to the transistor in which some variables have modeling problem almost always converges system on the combustion negative values. Solution a produced by problem has some negative components. Morgan that these undesired convergences solution, in the problem to some solution to an undesired not included to converge from almost any starting point, but they may fail to produce a [3 I] also mentions systems: to a solution the commercial are typical of chemical equilibrium i.e., a The other day an electrochemistfriend came by my office with a problem. He was trying to work out part of a battery-plate manufacturing process. He had set up a math model to in the plating determine equations bath at various in 10 unknowns. His problem was that Newton’s method kept converging to nonphysical solutions. [. . .] This incident has been repeated in various guises many times. that would be present times. He had ended up with a system of 10 polynomial the amounts of various metal compounds 2.4. Practicality The functionalities precludes any guarantee on the computation that, for a rich collection of nonlinear problems, of NUMERICA of course come at a price. The intractable nature of nonlinear programming times of interval methods. Conventional wisdom claims that interval methods are too slow to be of practical use and that their guarantees and ease of use come at too high a price. The performance of NUMERICA indicates is reasonable. Moreover, even when the full functionality NUMERICA avoids the tedious work necessary starting points. As a consequence, compensate solution. linear time in the number of variables a traditional benchmark is as large as or larger than, say, [ - 1 O*, lo’]. that NUMERICA takes essentially to isolate the zeros of the Broyden banded function, from numerical analysis, even when the initial range of the variable the price to pay is not needed, to tune local methods and find suitable frequently time and may even reduce to mention NUMERICA'S ease of use and robustness for a longer running of global methods it may be useful In this context, the actual time to obtain a In addition, NUMERICA compares well and methods on their benchmarks. This good performance of interval analysis methods (e.g., Hansen-Sengupta’s techniques. The combination of these orthogonal frequently outperforms continuation comes from a novel combination operator) and constraint satisfaction techniques gives surprisingly good results I? Van Hentenryck /Art$cial Intelligence 103 (1998) 200-235 215 Input: real p: "p: "; Variable: x in [-20.4,-9.41; Body: solve system all prod(i in [1..201) (x + i) + p * xA19 = 0; Fig.2. The Wilkinsonproblemin NUMERICA. on many problems, requires further research. although understanding its strengths and limitations more formally Of course, at this point because there are also classes of problems interval methods are not interval evaluations may lose too much precision. For appropriate instance, nonlinear to effective solution with the interval methods of which we are aware. Interval methods converge, of course, on these applications but they do not compare well in efficiency with local methods. least-squares problems are not amenable for which 3. Atourof NUMERICA We now illustrate NUMERICA on a number of applications to highlight the language and its functionality. is depicted The Wilkinson problem. for this problem statement p of type real and a variable x which ranges statement prod which makes it possible p = 0, NUMERICA returns eleven solutions, These exact solutions are of the form Let us start with the Wilkinson’s problem. The NUMERICA in Fig. 2. The statement declares an input constant [ -2 0 .4, - 9 .4 I . The body of the in function. Note the aggregation operator to have a statement close to a LaTeX description. When exactly. requests all zeros to the Wilkinson’s ten of which being represented Solution: 1 [SAFE] x = -20 The approximate solution Solution: 5 [SAFE] x= -16.0 + [-0.356e-14 , +O.l78e-141 intervals that NUMERICA returns that NUMERICA has proven that there exists a solution illustrates indicates inside the interval. When the keyword is not present, it simply means that NUMERICA was not able to obtain a proof of existence. As a consequence, is greater than 1) not marked with SAFE may or may not contain a solution. When p = 2-23, NUMERICA simply returns that there is no solution an interval (or a box when the dimension solutions. The keyword SAFE to the problem. enclosing 216 P Vun Hrntrwyck /Art$cial lnttdligencr 103 (1998) 209-235 Pragma: precision = le-12; Variable: x:array[l..lOl in IO. .ll; Body: solve system all + x[3] + 2*x[5] + 2*x[8] + XL91 + x[lOl = 5e-5; x[2] + 2 * x[6] + x[9] + 2*x[101 = 1e-5; ~[3] + xL81 = 3e-5 ; x[l] x[4] + 2 * x[7] 0.5140437e-7 O.l006932e-6 0,7816278e-15 * x[5] = x[11^2; * xL61 = 2 * x[2]^2; * XL71 = ~~41~2; = le-5; 0,1496236e-6 0,6194411e-7 0,2089296e-14 * x[81 = x[ll*x[31; * x[9] = x[ll*x[21; * x[lOl = x[ll*x[21^2; Fig. 3. The combustion problem in NUMERICA The combustion problem. Reconsider statement NUMERICA of variables and a pragma to specify the desired accuracy. NUMERICA positive solution for this problem the combustion problem discussed earlier. The is shown in Fig. 3. The statement uses an array returns the unique Solution: 1 [SAFE] x[l] = 0.00000014709 x[2] = 0.00000022619636102 x[3] = 0.000015128076338 x14] = 0.000000000062 + [-0.3151616090976e-12 + [0.31239815e-17 ,+0.5348538119178e-121 , 0.67358889e-171 + [0.28151603e-15 , 0.38648037e-151 + [0,39268906099084274e-12 , 0.51871986419385418e-121 x[5] = 0.0000004208884800 x[6] = 0.000001016251221 x[73 = 0.000004999968 x[8] = 0.000014871923661 x[9] = 0.0000005371172945 x[lO] = 0.000003602091950 + [0.670113679e-16 , 0.922409855e-161 + [0.301906781e-15 + [0,740640067315e-12 + [0,60945464e-15 , 0.402067581e-151 , 0.803655470521e-121 , 0.7225471e-151 + [O.l42273089e-16 + [0.808352357e-15 , 0.563773625e-161 , 0,927440531e-151 and proves its existence commercial in about 0.1 second on a Sun Spare- 10. Solution b produced by the system mentioned previously is close to being contained in this output box. Dennis and Schnabel’s functions functions. Let us now revisit the Dennis and Schnabel’s fl(X) =x4 - 1 2x3 + 47x* - 60x f*(x) =x4 - 12x3+47x2-60x+24 .f3(x) = x4 - 12x3 + 47x2 - 60x + 24.1. returns NUMERICA solution in each of them for f2; it shows the absence of solutions the existence of a in each of them for fl ; it returns two boxes and proves the existence of a solution times for for ,f3. The computation four boxes enclosing the solutions and proves F! Van Hentenryck /Artificial Intelligence 103 (1998) 209-235 211 these examples are negligible. More precisely, the NUMERICA statement I I Variable : x in [O..le81; Body: solve system all xA4 - 12 * x^3 + 47 * x”2 - 60 * x + 24 = 0; produces the following output boxes: Solution: [SAFE] x = 0.8883057790717 1 + [0.4e-13 , 0.6e-131 solution: 2 + x = 1.0 [SAFEI [-O.le-13 , +O.le-131 This example methods. illustrates well the functionalities of NUMERICA compared to traditional The Broyden banded numerical analysis: traditional collections of problems aspects of NUMERICA. The problem amounts function. We now consider from the Broyden Banded function. This is a benchmark which is found in to illustrate several (e.g., [ 191) and which is interesting to finding the zeros of n functions a traditional benchmark fi (Xl > . . ., X,)=Xi(2+53L12)+1_CXk(l+Xk)(l~i~n) kEJi where Ji = {j 1 max( 1, i - 5) < j 6 min(n, n sets that share the same basic definition. i + 1) , j # i }. Note that this statement uses Fig. 4 depicts the NUMERICA statement and it contains several interesting features. First, it illustrates the use of generic sets in the instructions Set: J[i in idx] = { j in [max(l,i-5). .min(n,i+l) 1 ( j <> i I; to obtain a close similarity with the mathematical use of generic constraints statement. Second, it also illustrates the [i in idx]: 0 = x[i] * (2 + 5 * x[il^2) + 1 - Sum(k in J[i]) x[k] * (1 +x[k]); to state a system of equations. Both of these features simplify is the performance interesting Also behavior of NUMERICA as shown in Table 1. the statement significantly. Experimentally, it was observed that NUMERICA essentially encloses the unique solution 218 I? Vun Hentenryck /Artijiciul Intelligence 103 (I 998) 209-235 Input: int n : "Number of variables: q Constant: range idx = [l..n]; set: J[i in idxl = { j in [max(l,i-5 ..min(n,i+l)l 1 j <> i 1; Variable: x Body: : array[idx] in [-lOe8..10e8] solve system all [i in idx]: 0 = x[i] * (2 + 5 * x[i]^2 + 1 - Sum(k in J[il) x[kl * (1 +x[kl); Fig. 4. The Broyden banded function. Table 1 Performance results on Broyden’s function n Solving time (ms) Growth factor 5 IO 20 40 80 100 500 1600 4200 9800 160 30700 5.00 3.20 2.65 2.33 3.13 large range. ’ This is not an isolated in linear time in the number of variables for extremely case and there are many benchmarks which exhibit a similar behavior. Understanding why and isolating is an interesting and open theoretical problem. this class of problems statement (i.e., splitting the level of constraint first): The transistor modeling problem. the transistor problem. The NUMERICA pragmas which specifies strategy section. NUMERICA box [O.. . lOI and proves 40 minutes. Traditional commercial The previous workstations. is shown propagation these will be explained As our last example of equation solving, reconsider in Statement 5. Note the the search in the next in the in less than to this problem. [35] required more than 14 months on a network of Sun-l tools are unable to locate the solution to the transistor modeling problem its existence and the absence of other solutions finds the unique solution interval solution (i.e., 2) and the largest interval Unconstrained minimization. the unconstrained minimization the use of functions and of real constants such as pi. On optimization problems, NUMERICA Statement 6 depicts the NUMERICA statement problems discussed previously. The statement (as abbreviations of complex expressions), of trigonometric for one of illustrates functions, is guaranteed to 3 There is a cubic step at the end of the search to prove the existence of a solution. P Van Hentenryck /Artificial Intelligence 103 (1998) 209-235 219 Pragma : variable-choice consistency = 2; = If; constant: [1..51; range range real g: array[xr,yrl xr = yr = [1..41; = 1 [ 0.485, 0.752, 0.869, 0.982 1, [ 0.369, 1.254, 0.703, 1.455 1, [ 5.2095, 10.0677, 22.9274, 20.2153 [ 23.3037, [ 28.5132, 111.8467. 134.3884, 211.4823 II; 101.779, 111.461, 191.267 I, I, Variable: x: array[l..91 y: arraylO.. in [O.O..lO.Ol; in I-1000..10001; Body: solve system all ylO1 = 1 - XI11 * xL21; Y[ll = YLOI * xL31; Y[21 = YFOI * xL41; [k in yrl: Y[ll * (exp(xl51 * (g[l,kl - gt3,kl*x[7l*le-3-g[5,kl*x[8l*le-3)) - g[S,kl + g[4,kl*x[21 = 0; - 1) [k in yrl: YC21 * (exp(x[6l*(g[l,kl-g[2,kl-g[3,kl*x[7l*le-3 +g[4,kl*x[9l*le-3)) -1) - g[S,kl*x[ll + g[4,kl = 0; x[ll*x[31 - x[2l*x[41 = 0; Fig. 5. The transistor modeling problem in NUMERICA bound and isolates all global optima. Table 2 gives the performance As can be seen, NUMERICA seems to be essentially quadratic on this problem. results on this problem. in the number of variables Constrained optimization. a constrained optimization problem from a standard collection of benchmarks isolate global optima in constrained optimization problems. this section by showing a statement for solving in NUMERICA. Statement 7 in fact depicts problem 95 to [ 171. Once again, NUMERICA is guaranteed We conclude 4. The essence of NUMERICA The purpose of this section is to present the main ideas behind NUMERICA'S the algorithm. implementation. behind and describes The main algorithm Throughout The presentation here is novel and aims at crystallizing the main intuitions It starts with a review of the main concepts of interval analysis techniques. assumptions. this section, only equation solving is considered, since it is also the cornerstone to be solved, the main algorithm, and the pruning to remove some of the simplifying is then reconsidered the problem 220 F! Van Hentenryck /Arti$ciul Intelligence 103 (1998) 209-23.5 Input: int n : "Number of variables"; Constant: range idx = [l..nl; Variable: x Function: : array[idxl in [-lO..lOl; y(i in idx) = 1 + 0.25 * (x[il-1); Body: minimize 10 * sin(pi*y(l))^2 + Sum(i in [l..n-11) + (y(n) - 1)^2 (y(i) -1)^2 * (1 + 10 * sin(pi*y(i+l))^2); Fig. 6. Unconstrained optimization: Levy 8’ Table 2 Performance results on Levy 8’ n Solving time (s) Growth factor 5 10 20 40 80 0.40 1.20 4.30 27.10 136.60 3.00 3.58 6.30 5.04 Indeed, optimality conditions for optimization problems (e.g., can be expressed as a system of equations. for optimization problems. the Kuhn-Tucker conditions) 4.1. Preliminaries Here we review some basic concepts of interval analysis on interval arithmetic can be found information 341). Our definitions are slightly non-standard. to needed for this paper. More in many places (e.g., [I ,14,15,28,29,32, 4.1.1. Interval arithmetic We consider RBco = R U (-co, co), the set of real numbers extended with the two infinity symbols, and the extension of the relation < to this set. We also consider a finite subset numbers F of Iwo3 containing used in the implementation. -co, 00, 0. In practice, to the floating-point .F corresponds Definition 1 (Interval). An interval [I, U] with 1, u E _F is the set of real numbers {r E R Il< r 6 u}. The set of intervals is denoted by 1 and is ordered by set inclusion. 4 4 These intervals are usually called floating-point intervals in the literature. P. Van Henterqck/Arti$cialIntelligence 103(1998) 209-235 221 Constant: real Bl = 4.97: real B2 = -1.88; real B3 = -29.08; real B4 = -78.02; Variable: x: array[l..6]; Body : minimize 4.3 * x[l] + 31.8 * x[2] + 63.3 * xL31 + 15.8 * x141 + 68.5 * x[5] + 4.7 * XL61 subject to [i in [1..6]1: x[i] >= 0; x[l] <= 0.31; x[2] <= 0.046; x[3] c= 0.068; x[4] <= 0.042; x[5] <= 0.028; x[6] <= 0.0134; 17.1 * x[l] + 38.2 * x[2] + 204.2 * x[3] + 212.3 * xc41 + 623.4 * xL51 + 1495.5 * x[6] - 169 * x[ll * xi31 - 3580 * x[31 * xl51 - 3810 * x[4] * x[5] - 18500 * x[41 * xL61 - 24300 * x151 * xL61 >= Bl; 17.9 * x[l] + 36.8 * x12] + 113.9 * x[3] + 169.7 * x[4] + 337.8 * x[5] + 1385.2 * x[6] - 139 * x11] * xL31 - 2450 * x141 * x151 - 16600 * x[4] * x[6] - 17200 * x[5] * x[6] >= B2; -273 * x[2] - 70 * x[4] - 819 * x[5] + 26000 * x[4] * x[5] >= B3; 159.9 * x[l] - 311 * x[2] + 587 * x[4] + 391 * x[5] + 2198 * x[6] - 14000 * x[ll * x161 >= B4; Fig. 7. A constrained optimization problem in Numerica Definition 2 (Enclosure). Let S be a subset of R. The enclosure of S, denoted by 3 or OS, is the smallest I such that S C I. We often write F instead of (T] for r E IR. interval - 1-) (respectively of signature Z + 1) by the letters F, G, all possibly We denote real numbers by the letters r, v, a, b, c, d, F-numbers by the letters 1, m, u, (e.g., functions subscripted. We use strictly rounding, we greater largest) F-number r. We also use I’ to denote a box . . , I,) and F to denote a tuple (~1, . . , rn). Q is the set of rational numbers and N intervals by the letter I, real functions by the letters functions I+ greater use [rl (respectively (It, is the set of natural numbers. We also use the following notations: the smallest than the F-number to denote smaller) [rj) (respectively (respectively 1. To capture outward to return the smallest to the real number smaller) or equal largest) F-number f, g and interval (respectively (respectively kft(U, ul) = 1 right([l, u]) = u center([a, b]) = l(a + b)/2]. 222 P Van Hententyck /Artijcial Intelligence 103 (IY98) 20%235 Definition 3 (Canonical [Z, I+], where 1 is a floating-point number. interval). A canonical interval is an interval of the form [Z, I] or The fundamental concept of interval arithmetic is the notion of interval extension. Definition 4 (Set extensions). Consider a set S 2 IP and a function extension of f is defined as f : Rn + IR. The set f(S) = { .fF) I r’ E s}. Definition 5 (Interval extension of f : IR” + R in I;, if extensions). An Vr’c &: f(f) & F(f). interval function F :T’ -+ Z is an interval Example 6. The interval function @ defined as ~~l~~ll~~~2,b21=[la~+a2~,~bl+b2l] is an interval extension of addition of real numbers. In this paper, we restrict attention to monotonic fundamental properties and because satisfy these requirements naturally. traditional interval extensions because of their interval extensions of primitive operations Definition 7 (Monotonic tonic in I;, if interval extensions). An interval function F : 1” + Z is mono- _.+ + VII, 12 C lo : Ii 5 Z2 =+ F(ZI) C F(Z2). -3 + It is important to stress that a real function can be extended in many ways. For instance, the interval function @ is the most precise interval extension of addition (i.e., it returns the smallest possible [--co, co] would be the least accurate. interval extensions the interval extension of + is defined by @). In addition, we overload the real symbols and use them for their interval extensions. all real results), while a function always returning fixed monotonic In the following, we assume for the primitive operators interval containing (for instance, 4.1.2. Constraint representations It is well known that different computer representations of a real function produce on a computer. As a numbers the way in which constraints are written may have an impact on the behavior to in this paper is considered floating-point results when evaluated with different consequence, on the algorithm. For this reason, a constraint or a function be an expression written functions remaining (but arbitrarily constraints. (respectively sections, we assume . . , x,). Similar conventions and their representations in some language. that real variables large) set (XI, constraints) Interval variables are taken from a finite (but arbitrarily by the same symbol. In addition, we abuse notation by denoting In the are taken from a finite apply to interval functions and large) set {X 1, . . . 1 X, ]. in constraints I? Van Hentenryck /Artijicial Intelligence 103 (1998) 209-235 223 3.2. Problem description The problem considered in this section is finding all solutions to a system of equations s= I o=fl(Xl,...,&~) . . 1 o=fn(xl>...,.%) . , I,“). Of course, on a computer, in a box T’ = (Zp, these solutions exactly and interval methods aim at returning solutions. Preferably, each such box is safe, meaning purposes of this section, problem: assuming that fi canonical 5 boxes (It, . . , In) in I -0 satisfying to find all that it contains a solution. For the the following interval extension of fi (1 6 i 6 n), find all interval methods can thus be viewed as solving small boxes containing is a monotonic it is generally impossible OEFl(ZI,...,Z,) s= . . . 1 OEFn(Zl~~..~Zn). This is of course a simplification, tensions. However, restricting attention intuition underlying our novel pruning methods. Section 4.7 reconsiders since interval methods generally use various interval ex- the to this problem has the benefits of crystallizing this simplification. Notation. Let S be a system of constraints of the form s= . . . I OE Fl(XI,...,Xn) oEFn(Xl,...,Xn) andletfbeabox(Zt,... the system of interval constraints S or, in symbols, , Z,). We denote by S(i) and S(Zt , . . . In) the fact that r’ satisfies 0 E Fl (It, . . , zn)A~~~AOEF~(zn,...,z,). Note also that we use S to denote systems of constraints and S to denote systems of interval constraints. 4.3. The generic branch-and-prune algorithm The above problem description highlights are only finitely many floating-point the finite nature of the problem, since there intervals. Most interval methods are thus best viewed 5 In practice, one may be interested in boxes of a certain width or one may want to stop as soon as a safe box is obtained. It is easy to generalize our results to these requirements. 224 F! Van Hententyck /Artificial Intelligence 103 (1998) 209-23.5 function Search (S , 10 ) begin := Prune(S,&); 7 if Empty(f) then return fl else if Canonical (I) return [f} else then (!;,I;) := Split(f); return Search(S,fj) U Search(S,i*); end Fig. 8. The branch-and-pnme algorithm. as global search algorithms schema underlying iterating these algorithms, two main steps: pruning and branching. The basic in Fig. 8. schema, the branch-and-prune is depicted The function Search receives a system of interval constraints S and an initial box fu: the set of canonical boxes I’ in I -0 satisfying S(l’). The function Search first the initial box. This pruning step is the main topic of to the problem. If the box I’ into it returns applies a pruning step that reduces this section. If the resulting box r’is empty, there is no solution is canonical, it is returned as a result. Otherwise, two subboxes, ?t and &,, which are then explored recursively using the same algorithm. the box is split along one dimension A specific interval algorithm can be obtained by specifying techniques. Our algorithms use a strategy the splitting strategy and that consists of splitting the intervals strategy. 6 The main novelty of our three pruning operators, last two three distinct algorithms. These and we will define in a round-robin techniques that produce pruning associated with algorithms Pruneu, algorithms are used in NUMERICA. the variables lies in the pruning and Prune2, Prunet, 4.4. Box(O)-consistency It is traditional in branch-and-prune algorithms to the easier problem, to use a relaxation of the problem at it follows that there are no solutions hand. If there is no solution is a weak, but very simple, relaxation used in to the original problem. Box(O)-consistency most interval systems. Given the problem of finding canonical boxes in a bo_x I satisfying a system of interval constraints S, box(O)-consistency consists of testing S(Z). If S(Z) does to the original problem, because of the definition not hold, there are obviously no solutions can thus of interval extensions. The pruning operator associated with box(O)-consistency be defined as follows: Pruneu(S, f) = VI if -S(7) r’ otherwise. 6 This default can be overwritten with pragmas: for instance, the transistor modeling statement specifies that the variable with the largest interval should be split first. f! Van Hententyk/Art$cial Intelligence 103 (1998) 209-235 22s Box(O)-consistency could be stated as an existence question can in fact be viewed as a form of projection. The original problem 3x1 c II,. . , 3x, EZ,:S(X,,....X,) and box(O)-consistency to obtain the test approximates it by replacing each interval variable by its interval which reduces to testing each constraint in S independently. 4.5. Box( 1 )-consistency This section presents discussion, the first pruning operator used in our algorithm. then specifies the pruning operator, and presents It starts with a simple an informal implementation. 7 4.5.1. Informal presentation The first fundamental but one or, more precisely, a stronger pruning existence problem idea underlying box( 1)-consistency [2] is to project all variables to replace all variables but one by their intervals. This produces but, of course, at a higher cost. The original than box(O)-consistency 3X] c It, . .) 3x, E z, : S(Xl, . .) X,) is thus approximated by 3X] c II : S(X1) 12, . . , In) A 3x2 c z2 : S(Z1) x2, . . . ) In) A . 3x, & In : S( II, . . . ) In_1 ) X,). relaxation This independent. In addition, a condition of the form can be tested relatively easily. Notice first that the conditions are 3x1 2 I] : S(Xl,Z2, . . , In) can be tested by considering all the canonical intervals I in It and testing S(Z, 12, . . . . I,?>. Our implementation method. tries to be more effective by using adaptations of the interval Newton ‘Separating the specification has the advantage of distinguishing what the implementation from it. There are many ways to implement computed and our goal here is to focus on the concepts, not on the technical details (which can be found elsewhere the concepts described from how to compute [38]). is being in this section, 226 f? Van Hententyck /Artificial Intelligence 103 (1998) 209-235 The second fundamental associated with the variables. Consider idea underlying box( I)-consistency the relaxation is to reduce the intervals 3x1 c II :S(X1, I?_. . . ) f,) and let 1i be the leftmost interval in It satisfying S(Il, 12, . . .1 1,) and I, the rightmost interval in It satisfying S(I,, 12,. . . > InI. It should be clear that X 1 must range in the interval I’ I’ = [kft(I~), right(Z,)] since any interval on the left or on the right of I’ violates one of the conditions of the relaxation. The interval associated with Xt can thus be reduced to I’. This reduction is applied for each of the variables until no more reduction The resulting box is said to be box( I)-consistent. to detect that no solution the variables become smaller. Note also that a variable can be considered this reduction process. takes place. In the course of this process, it is possible to the original problem exists, since the intervals associated with several times in 4.5.2. The pruning operator We now formalize the informal discussion the pruning operator associated with box( 1)-consistency. Recall that all definitions assume that S is defined over is box( 1)-consistency, which expresses the set of variables Xt , . . , X, . The main concept that a system cannot be narrowed further by the reduction process described in the previous subsection. above and present informally Definition 8 (Box( 1)-consistency). Let S be a system of interval constraints, C,rt , . . , I,), and let li = left(Zi) and Ui = right(Zi) I with respect to i if (1 < i 6 n). S is box(l)-consistent let I’be a box in S(Zt, . . .Z;-l,[li,1+],Ii+I,..., In) A S(Il, . . Ii-l. [Ui, Ui], Zi+l, . . , In) when li # ui and S(Z1,. . , Ii-l, [li, li], li+l, . . , In) when li = ui. S is box-consistent in I’ if it is box(l)-consistent in I’ with respect to all i in 1 . . n. The pruning operator associated with box( 1)-consistency in the initial interval that is box( l)-consistent (or, more informally, simply returns the largest box the largest box in the I? Van Hentenryk /Artificial Intelligence IO3 ( 1998) 209-235 227 function Prune, begin (S, I) repeat I;, I = n I mrrowl(S,f,i) := i; until return i = Ji ; I; end function Narrowj (S, begin (II,. , I,), i ) / I<i<n I; := ( I, & I, 1 I,. C if C = kl then return 69; is canonical and S(f, ._._. [;_I, I,., !,+I. 1 ‘If) 1; else end return [ minI,c I@(l) , rnaxltC right(l) 1; Fig. 9. Implementing box(l)-consistency. interval initial monotonicity that cannot be narrowed further). This box always exists because of the of interval extensions and is unique. Of course, it can be empty. Definition 9 (Box( 1)-consistency pruning). Let S be a system of interval constraints let I’ be a box. The pruning operator associated with box( 1 )-consistency and can be defined as Prunel(S,i)= I; where T’ is the largest box in r’ such that S is box( I)-consistent in ?. 4.5.3. A simple implementation The pruning operator can be computed for this purpose; see [38] for a more efficient in many ways. Fig. 9 presents a simple iterative is algorithm a, simple fixpoint algorithm (i.e., I = I,,). The body of the loop applies a narrowing operation on each of the variables and function produces a new-box that is the intersection of?11 the_se narrowings. The narrowing Narrow1 (S , I, i ) returns in ? with respect to i. that terminates when no further pruning can be obtained the largest box I’ in I such that S is box( 1)-consistent implementation. The algorithm 4.6. Box(2)-consistency Box consistency has been shown [38]. For some of the more difficult applications applications problem and chemical engineering obtained by using a stronger Box(2)-consistency some consistency notions presented applications local consistency is in fact an approximation in [24]. to be effective for solving a variety of nonlinear (e.g., the transistor modeling [ 1 l]), however, better performance can be condition of path consistency that we call box(2)-consistency. [27] and is related to 228 P Van Hententyk /Art$cial Intelligence 103 (1998) 209-235 4.6.1. Informal presentation Box(2)-consistency generalizes box( I)-consistency by projecting all but two variables. The original existence problem 3x1 s II,. . ,3x, c I, :s(xJ, . . . , X,) is thus approximated by 3x1 5 Zl, x2 E 12 :S(X,, x2,13, . . . . In) A 3x1 czl,X3Cz3:S~X1,z2,X3,14 ,...‘rn)A 3X2Cz2JX3Cz3:S(z1,X2,X3,14 ,..., In)r\ 3X,-l EI,-1,X,~I,:S~zl,...,zn-2,Xn~l,Xn) Once again, it is possible The conditions are independent and a condition of the form to test this relaxation easily, at least from a conceptual standpoint. can be tested by considering all pairs of canonical intervals in II and 12 for Xt and X2. As was the case for box( I)-consistency, box(2)-consistency makes use of this relaxation to prune the intervals associated with each variable. Consider a condition 3x1 EzI,X2Cz?:S(XI,X2,z3,....zn) and a canonical interval I; 2 It. If there is no box f’ s (I;, 12, . . . , I,) such that S is box( I)-consistent It by using further pruning is available. in fi, then obviously x q! Ii. It is thus possible to narrow the bounds of rule, and this process can be iterated for all variables until no this pruning 4.6.2. The pruning operator The notion of box(2)-consistency is defined precisely, consistent in terms of whether a system of interval constraints in a box. in terms of box(l)-consistency or, more can be made box(l)- A 2ystem of Definition 10 _(Box(l)-satisjability). satisfiable in IO, denoted by BoxSat (S, IO), if there exists a box I C lo such that S is box( 1)-consistent is box(l)- cons?ai@ interval in I’. S Informally speaking, box(2)-consistency that they cannot be reduced further using the pruning says that the bounds of each variable are box- rule described satisfiable, above. implying Definition 11 (Box(2)-consistency). box (II, . . , I,,) with I,i = [l.j, uj 1. S is box(2)-consistent Let S be a system of interval constraints and I’ be a in I with respect to i if P Van Hentenryck /Artificial Intelligence 103 (1998) 209-235 229 BoxSat (S, (I1 , . . , Ii-l, [li, /+I, li+l, . .9 In)) A BOXSUtl (S, (It,. . , Zip], [Ui, Ui], Zi+], . . . Iti)) when li # ui and if BoxSutl (S, 7) otherwise. The system S is box(2)-consistent (1 6i <n). in r’ if it is box(2)-consistent in I’ with respect to all i It can be shown that box(2)-consistency implies box( 1)-consistency. Proposition consistent in I, then S is box( I)-consistent in I. l_2, Let S be a system of monosmic interval constraints. If S is box(2)- Proof. Assume for simplicity is similar otherwise. Since S is box(2)-consistent respect to all i (1 < i ,< n). Thus, that I’ = (Zr , . . , I,*) with Ii = [li , ui] and li # Ui. The proof in I’ with in f, S is box(2)-consistent Bo~~~tl(S,(~~,...,~i-l,[~i,~+l,~i+~,...,~~)) or, more explicitly, 3I; 5 (Zl 3 . .3 Ii-13 [li, lttlt li+l, . . , In) : S is box( 1)-consistent in ?. It follows that 0 E Fi(f’ ) (l<i<lz) and, by monotonicity of Fi, that 0 E Fi (II, . . . Ii-1, [li, 1+]3 Ii+1 9 . . .t 1,). The proof that OE Fi(Zl,. . .t Ii-1 1 [ui, Uilt li+l, . . . , In> is similar. The result follows from the definition of box( I)-consistency. q The pruning operator associated with box(2)-consistency simply returns the largest box in the initial interval which is box(2)-consistent. Decnition 13 (Box(2)-consistencypruning). let I be a box. The pruning operator associated with box(2)-consistency Let S be a system of interval constraints and can be defined as Prunez(S,i)= I; where ? is the largest box in r’ such that S is box(2)-consistent in ?. 230 P Van Hen&vyck /Artijicial lnrelligence IO.? (IY9H) 209-235 function Prune2 begin (S , 7) repeat I = f- { Narrow~(S,~,i) 1 l<i<n I; until i = 1; ; return I; end (S, (11. , In), i 1 function Narrow2 begin C if C =M then return M; := (Ic 2 li / fc is canonical and - Empty(Prunel (S, (II . . . . . li_1. IC,Ii+l ,..., I,)))); else end return [ minrcc left(Z) , max~,~ right(l) ] ; Fig. IO. Implementing box(2)-consistency, 4.6.3. A simple implementation Once again, implementation. the pruning operator can be computed iterative algorithm close to our actual in many ways. Fig. 10 presents a is again a simple simple fixpoint algorithm that terminates when no further pruning can be obtained. The body of the loop applies a narrowing operation on each of the variables and produces function a new box in Narrow2 ? with respect to i. The pruning operator of box( 1)-consistency this at this narrowing operator. Note that it would be easy to define any level of box-consistency point, since box(k - I)-consistency in a generic way. the largest box ?’ in I’ such that S is box(2)-consistent is used to compute of all these narrowings. The narrowing can be used to define box(k)-consistency is the intersection The algorithm i, i ) returns that (S, 4.6.4. Related work to earlier work in constraint satisfaction. It is useful to relate these pruning operators and approximations in problems community of projections, (under the name consistency are weaker than box( l)-consistency, (e.g., [25,27]). They have been adapted have been used extensively techniques) the to solve discrete to continuous problems [3,33] and CLP(BNR) and like BNR-PROLOG into since they decompose all constraints Projections, artificial intelligence combinatorial (e.g., [6,24]) and used inside systems such as BNR-PROLOG and many systems since then. The techniques used in systems CLP(BNR) ternary constraints on distinct variables before applying in They do not scale well on difficult problems. Box(l)-consistency [2]. It is related idea for the splitting process. The consistency notions of [24] are a weaker, and less effective, form of box(k)-consistency: over distinct variables constraints. into ternary constraints on the resulting in [18], which uses a similar a form of box( 1 )-consistency. it is obtained by decomposing a form of box(k)-consistency to the techniques presented and by applying was introduced all constraints P Van Hentenryck/Artijcial Intelligence 103 (1998) 209-235 231 4.7. The brunch-and-prune algorithm revisited We now reconsider the assumptions algorithm uses two interval extensions, interval extension, particular, the natural the mean value interval extension reviews both extensions and reconsiders interval extension since distinct interval extensions may produce different prunings. of Section 4.2. As mentioned the natural in that section, our interval extension and the mean value In is generally better when far from a solution, while is more precise when close to a solution. This section the overall branch-and-prune algorithm. 4.7.1. The natural interval extension The simplest interval extension of a function is its natural interval extension. Informally it consists speaking, it, each real variable by an interval variable and each real operation by its fixed interval extension. In the following, in replacing each number by the smallest f^is its natural extension. if f is a real function, interval enclosing Example 14 (Natural xi (x:! + x3) is the interval function Xi (X2 + X3). interval extension). The natural interval extension of the function The advantage of this extension users of the system can choose constraint problem at hand. It is useful constraints. to generalize is that it preserves how constraints are written and hence for the to a system of particularly interval extension representations the natural appropriate Definition 15 (Natural interval extension of a system). Let S be a system of constraints The natural extension of S, denoted by $, is the set of the interval constraints s= . . . O=fn(xt,...,.%). I O=fl(xl,...,~n) I O=~(X,,...,Xn) 0=X(X ,,..., X,). s;= . . . The following result is easy to prove by induction. Proposition 16. The natural interval extension of a function, a constraint, or a system qf constraints is monotonic. 4.7.2. The mean value interval extension The second around a point. This extension introduced by Moore [28] and have been studied by many authors, since they have important properties. interval extension is an example of centered is based on the Taylor expansion that are interval extensions forms 232 I? Van Hentenryck/Art(ficial Intelligence 103 (1998) 209-235 in the function. interval extension of a function for The mean value partial the variables derivatives. Given these assumptions, is to apply a Taylor expansion of the function around the center of the box and to bound the rest of the series using the box. that the function has continuous the key idea behind the extension by the intervals It also assumes is parametrized Definition 17 (Mean value interval extension). Let I’ be a box (II, . . , In) and rni be the f in I’, denoted by r (f, I’>, is center of Zi. The mean value interval extension of a function the interval function Let S be a system of constraints s= . . . I o=flt~1,...,&z) o=.fntx1,...,xn>. The mean value interval extension of S in i, denoted by t(s, constraints i), is the system of interval I o=wlAxl,...m r(S, i, = ( . . I o=t(fnAxl ,..., m. Note that the mean value interval extensions is defined in terms of natural interval extensions. The proof of the following proposition can be found in [.5]. Proposition 18. The mean value interval extension of a function extension. is a monotonic interval related is closely It is interesting to note that box consistency over Krawczyk’s operator a system of constraints is an improvement these operators are more effective when the interval Jacobian of the system is diagonally the system S. For the purpose of this section, dominant we simply assume operator cond(S, Z) and use the notation r,(S, I) to denote t(cond(S, that we have a conditioning 4 + I), I). See [20,21] for extensive coverage of conditioners. [23]. Hansen and Smith also argue [ 161 and they suggest conditioning on the mean value interval extension of [15], which that to the Hansen-Sengupta operator .+ 4.7.3. The branch-and-prune We are now in position algorithm to reconsider our branch-and-prune given in Fig. 11, differs in two ways from the algorithm presented one hand, the algorithm receives as input a system of constraints algorithm. The new version, in Section 4.3. On the (instead of a system of J? Van Hentenryck /Artificial Intelligence 103 (1998) 209-235 233 function Search ( S, & ) begin r’ := Prune(TUs,(S,Q,IO); if Empty(j) then return 0) else if Canonical return {f, else (i) then := Split(l); (f~,l;) return Search(S,ff) U Search(S,&; end Fig. 11. The branch-and-prune algorithm revisited. interval constraints). On the other hand, the operation Prune constraints interval extensions of the original system. consisting of the natural interval extension receives a system of interval and the conditioned mean value 4.7.4. Existence proof We now describe how the algorithm proves the existence of a solution in a box. Let (fl = 0,...,f,=O]beasystemofequationsovervariables(x~,...,x,),letZ=(Z~,...,Z,)be a box and define the intervals I( (1 6 i 6 n) as follows where rni = center( Zi ). If Z,‘CZi (l<i<n) then there exists a zero in (Z; , . . . , IL). A proof of this result can be found in [30]. 5. Conclusion, challenges, and opportunities language some of them without to NUMERICA, a modeling This paper gave a gentle introduction for solving of NUMERICA have been illustrated and algorithm of global optimization problems. The functionalities contrasted with traditional methods. The essence of the constraint-solving NUMERICA was presented at a very-high to be exhaustive. A particularly level. There are many possible ways to improve global methods for nonlinear programming interesting and we mention research avenue (studied by F. Benhamou and D. Kapur for instance) symbolic and numerical methods. New pruning problem Similarly, satisfaction intervals. Finally, constraint development of NUMERICA but only a tiny fraction of the existing in NUMERICA. It is an exciting years. is the combination of techniques with a more global view of the to improve the pruning when far from a solution. information beyond the force behind is exploited in the coming field and it is likely to evolve substantially to study ways of collecting global techniques have been a driving it would be interesting is also of paramount importance research trying 234 t! Van Hentenryk / Art@d Intelligencr I03 ( 1998) 209-235 Acknowledgement NUMERICA was developed jointly with Laurent Michel and Yves Deville. NUMERICA is also based on previous work on Newton with FrCdCric Benhamou, Deepak Kapur, and David McAllester. Thanks to all of them for their invaluable contributions. This work was supported by an NSF National Young Investigator Award. References I I I G. Alefeld, J. Herzberger, 121 F. Benhamou, D. McAllester, P. Van Hentenryck, CLP(intervals) Introduction to Interval Computations, Academic Press, New York, 1983. revisited, in: Proc. International Sympo- sium on Logic Programming (ILPS-94). Ithaca, NY, November 1994, pp. 1244138. 131 E Benhamou, W. Older, Applying 32 (1) (1997) Logic Programming interval arithmetic l-24. to real, integer and Boolean constraints, Journal of 141 J. Canny, Some algebraic and geometric computations in PSPACE, in: Proc. 20th ACM Symposium on the Theory of Computing, 1988, pp. 460-467. [S] 0. Caprani, K. Madsen, Mean value forms in interval analysis, Computing 25 (1980) 147-154. [6] J.G. Cleary, Logical arithmetic, Future Generation Computing Systems 2 (2) (1987) 125-149. 171 O.P.D. Cutteridge, Powerful 2-part program for solution of nonlinear simultaneous equations, Electronics Letters 10 (1971). [S] J.E. Dennis, R.B. Schnabel, Numerical Methods for Unconstrained Optimization and Nonlinear Equations, Prentice Hall, Englewood Cliffs, NJ, 1983. [9] J.J. Ebers, J.L. Mall, Large-scale behaviour of junction Integer Programming, transistors. John Wiley. New York, 1972. IEE Proc. 42 (1954) 1761-1772. [IO] R.S. Garfinkel, G.L. Nemhauser, 1 I I ] V. Gehrke, W. Marquardt, Direct computation of all singular points of chemical engineering models using in: International Conference on Interval Methods and Computer Aided Proofs in Science interval methods, and Engineering, Wtirzburg, Germany, 1996. [ 121 R. Hammer, M. Hocks, M. Kulisch, D. Ratz, Numerical Toolbox for Verified Computing I-Basic Numerical Problems, Theory, Algorithms, and PASCAL-XSC Programs, Springer, Heidelberg, 1993. [ 131 E. Hansen, Global Optimization Using Interval Analysis, Marcel Dekker, New York, 1992. [ 141 E.R. Hansen, RI. Greenberg, An interval Newton method, Appl. Math. Comput. 12 (1983) 89-98. LlS] E.R. Hansen, S. Sengupta, Bounding solutions of systems of equations using interval analysis, BIT 21 (1981) 203-2 1 I. 1161 E.R. Hansen, R.R. Smith, Interval arithmetic in matrix computation: part II. SIAM Journal on Numerical Analysis 4 (1967) 1-9. [ 171 W. Hock, K. Schittkowski. Test examples for nonlinear programming codes, Lecture Notes in Economics and Mathematical Systems, Springer, 1981. 1181 H. Hong, V. Stahl, Safe starting regions by fixed points and tightening, Computing 53 (34) [19J J. More. B. Garbow, K. Hillstrom, Testing unconstrained optimization software, ACM Transactions on (1994) 323-335. Mathematical Software 7 ( I ) ( 198 I ) 174 I. [20] R.B. Kearfott, Preconditioners for the interval Gauss-Seidel method, SIAM Journal of Numerical Analysis 27 (1990) 804822. [21] R.B. Kearfott, A review of preconditioners for the interval Gauss-Seidel method, Interval Computations I 1 (1991) 59-85. [22] R.B. Kearfott, A review of techniques in the verified solution of constrained global optimization problems, to appear. [23] R. Krawczyk, Newton-algorithmen zur Bestimmung von Nullstellen mit Fehlerschranken, Computing 4 ( 1969) 187-201. 1241 0. Lhomme, Consistency for numerical techniques Joint Conference on Artificial Intelligence constraint (IJCAI-93) Chambery, France, August 1993. satisfaction problems, in: Proc. 1993 International [ 251 A.K. Mackworth. Consistency in networks of relations, Artificial Intelligence 8 ( I ) (I 977) 99-l 18. I? Van Hentenryck /Artificial Intelligence 103 (1998) 209-235 235 1261 A.K. Mackworth, E.C. Freuder, The complexity of some polynomial network consistency algorithms for constraint satisfaction problems, Artificial Intelligence 25 (1985) 65-74. [27] U. Montanari. Networks of constraints: Information Science 7 (2) (1974) 95-132. fundamental properties and applications to picture processing, [28] RF. Moore, Interval Analysis, Prentice-Hall, Englewood Cliffs, NJ, 1966. [29] R.E. Moore, Methods and Applications of Interval Analysis, SIAM, Philadelphia, PA, 1979. [30] R.E. Moore, S.T. Jones, Safe starting regions for iterative methods, SIAM Journal on Numerical Analysis 14(1977) 1051-1065. [31] A.P. Morgan, Solving Polynomial Systems Using Continuation for Scientific and Engineering Problems, Prentice-Hall, Englewood Cliffs, NJ, 1987. 1321 A. Neumaier, Interval Methods for Systems of Equations, PHI Series in Computer Science. Cambridge University Press, Cambridge. 1990. [33] W. Older, A. Vellino, Constraint arithmetic on real intervals, in: Constraint Logic Programming: Selected Research, MIT Press, Cambridge. MA, 1993. [34] H. Ratschek. J. Rokne. New Computer Methods for Global Optimization, Ellis Horwood Limited, Chichester, 1988. 1351 H. Ratschek, J. Rokne, Experiments using interval analysis for solving a circuit design problem, Journal of Global Optimization 3 (1993) 50 l-5 18. [36] J. Renegar, A faster PSPACE algorithm for the existential theory of the reals, in: Proc. 29th IEEE Symp. Foundations of Computer Science, 1988, pp. 291-295. 1371 S.M. Rump. Verification methods for dense and sparse systems of equations, in: J. Herzberger (Ed.). Topics in Validated Computations, Elsevier, Amsterdam, 1988, pp. 2 17-23 1. [3X] 1’. Van Hentenryck, D. McAllister, D. Kapur, Solving polynomial systems using a branch and prune approach, SIAM Journal on Numerical Analysis 34 (2) (1997) 797-827. [39] P. Van Hentenryck, L. Michel, Y. Deville, Numerica: a Modeling Language for Global Optimization, MIT Press, Cambridge. MA, 1997. 1401 P. Van Hentenryck, V. Saraswat, Strategic directions in constraint programming, ACM Computing Surveys 28 (4) (I 996). 