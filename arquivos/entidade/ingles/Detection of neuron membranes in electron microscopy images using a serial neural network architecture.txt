NIH Public AccessAuthor ManuscriptMed Image Anal. Author manuscript; available in PMC 2011 December 1.Published in final edited form as:Med Image Anal. 2010 December ; 14(6): 770–783. doi:10.1016/j.media.2010.06.002.Detection of Neuron Membranes in Electron Microscopy Imagesusing a Serial Neural Network ArchitectureElizabeth Jurrusa,b, Antonio R. C. Paivaa, Shigeki Watanabec, James R. Andersone, BryanW. Jonese, Ross T. Whitakera,b, Erik M. Jorgensenc, Robert E. Marce, and TolgaTasdizena,daScientific Computing and Imaging InstitutebSchool of Computing, University of UtahcDepartment of Biology, University of UtahdDepartment of Electrical Engineering, University of UtaheMoran Eye Center, University of Utah School of MedicineAbstractStudy of nervous systems via the connectome, the map of connectivities of all neurons in that system,is a challenging problem in neuroscience. Towards this goal, neurobiologists are acquiring largeelectron microscopy datasets. However, the shear volume of these datasets renders manual analysisinfeasible. Hence, automated image analysis methods are required for reconstructing the connectomefrom these very large image collections. Segmentation of neurons in these images, an essential stepof the reconstruction pipeline, is challenging because of noise, anisotropic shapes and brightness,and the presence of confounding structures. The method described in this paper uses a series ofartificial neural networks (ANNs) in a framework combined with a feature vector that is composedof image intensities sampled over a stencil neighborhood. Several ANNs are applied in seriesallowing each ANN to use the classification context provided by the previous network to improvedetection accuracy. We develop the method of serial ANNs and show that the learned context doesimprove detection over traditional ANNs. We also demonstrate advantages over previous membranedetection methods. The results are a significant step towards an automated system for thereconstruction of the connectome.KeywordsMachine Learning; Membrane Detection; Auto-Context; Artificial Neural Networks; Filter Bank;Contour Completion; Neural Circuit ReconstructionI-NHPAAuthorManuscriptI-NHPAAuthorManuscriptI-NHPAAuthorManuscript1. IntroductionNeural circuit reconstruction, i.e. the connectome [1], is currently one of the grand challengesfacing neuroscientists. Similarly, the National Academy of Engineering has listed reverse-engineering the brain as one its grand challenges 1. While neural circuits are central to the study© 2010 Elsevier B.V. All rights reserved.Publisher's Disclaimer: This is a PDF file of an unedited manuscript that has been accepted for publication. As a service to our customerswe are providing this early version of the manuscript. The manuscript will undergo copyediting, typesetting, and review of the resultingproof before it is published in its final citable form. Please note that during the production process errors may be discovered which couldaffect the content, and all legal disclaimers that apply to the journal pertain.   I-NHPAAuthorManuscriptI-NHPAAuthorManuscriptI-NHPAAuthorManuscriptJurrus et al.Page 2of the nervous system, relatively little is known about differences in existing neuronal classes,patterns, and connections. Electron microscopy (EM) is an unique modality for scientistsattempting to map the anatomy of individual neurons and their connectivity because it has aresolution that is high enough to identify synaptic contacts and gap junctions. These areimportant indicators for types of neuron topology and are required for neural circuitreconstruction. Several researchers have undertaken extensive EM imaging projects in orderto create detailed maps of neuronal structure and connectivity [2, 3]. Early work in this area,by White et al. [4], includes the complete mapping of the nematode C. elegans nervous system.This is a simple organism, containing just over 300 neurons and 6000 synapses, yet it tooknearly a decade to identify all the relevant structures and reconstruct the connectivity 2. Incomparison, newer imaging techniques are producing much larger volumes of very complexorganisms, with thousands of neurons and millions of synapses [5,6]. Thus, automating thereconstruction process is of paramount importance.The ability to reconstruct neural circuitry at ultrastructural resolution is of substantial clinicalimportance. Retinal degenerative diseases, including pigmentosa and macular degeneration,result from a loss of photoreceptors. Photoreceptor cell stress and death induces subsequentchanges in the neural circuitry of the retina resulting in corruption of the surviving retinal cellclass circuitry. Ultrastructural examination of the cell identity and circuitry reveal substantialchanges to retinal circuitry with implications for vision rescue strategies [7,8,9,10,11,12,13].These findings in retinal degenerative disease mirror findings in epilepsy where neural circuitsalso undergo remodeling in presumed response to abnormal electrical activity clinicallymanifested as seizures. Scientists are interested in examining normal and pathological synapticconnectivities and how neuronal remodeling contributes to neuronal pathophysiology [14,15,16]. Examination of synaptic and dendritic spine formation during development provide insightinto the adaptivity of neural circuits [17,18]. Ultrastructural evaluation of multiple canonicalvolumes of neural tissue are critical to evaluate differences in connectivity between wild typeand mutants. The complexity and size of the these datasets, often approaching 17 terabytes,makes human segmentation of the complex textural information of electron microscopicimagery a difficult task. Moreover, population or screening studies become unfeasible sincefully manual segmentation and analysis would require multiple years of manual effort perspecimen. As a result, better image processing techniques are needed to help with automatedsegmentation of EM data including identification of neurons and the connections.1.1. Serial-section transmission electron microscopyThe modality we have chosen for reconstructing the connectome at the individual cell level isserial-section transmission electron microscopy (TEM). It provides scientists with images thatcapture the relevant structures; however, it poses some interesting challenges for imageprocessing. Most importantly, serial-section TEM offers a relatively wide field of view toidentify large sets of cells that may wander significantly as they progress through the sections.It also has an in-plane resolution that is high enough for identifying synapses. In collectingimages through TEM, sections are cut from a specimen and suspended so that an electron beamcan pass through it creating a projection. The projection can be captured on a piece of film andscanned or captured directly as a digital image. An important trade-off occurs with respect tothe section thickness. Thinner sections are preferable from an image analysis point of viewbecause structures are more easily identifiable due to less averaging. However, from anacquisition point of view, thinner sections are harder to handle and impose a limit on the areaof the section that can be cut. For instance, in the rabbit retina, scientists need to study sections1William Perry, Farouk El-Baz, Wesley Harris, Calestous Juma, Raymond Kurzweil, and Robert Langer, The unveiling of the grandchallenges for engineering, in AAAS Meeting, Feb 2008.2Emily Singer, A wiring diagram of the brain, Technology Review, Nov 2007.Med Image Anal. Author manuscript; available in PMC 2011 December 1.   I-NHPAAuthorManuscriptI-NHPAAuthorManuscriptI-NHPAAuthorManuscriptJurrus et al.Page 3with areas as large as 250µm in diameter to gain a sufficient understanding of neuralconnectivity patterns. Sections of this size can be reliably cut at 50 – 90nm thickness with thecurrent serial section TEM technology. This leads to an extremely anisotropic resolution, 2 –5nm in-plane compared to 50 – 90nm out-of-plane, and poses two image processing challenges.First, the cell membranes can range from solid dark curves for neurons that run approximatelyperpendicular to the cutting-plane, to grazed grey swaths for others which run more obliquelyand suffer more from the averaging effect. Consequently, segmentations of neurons in these2-D images, are difficult given the change in membrane contrast and thickness. Second, dueto the large physical separation between sections, shapes and positions of neurons can changesignificantly between adjacent sections.There are alternative specimen preparation and EM imaging techniques that can be used forneural circuit reconstruction such as Serial-Block Face Scanning Electron Microscopy.Briggman and Denk proposed a specimen preparation which only highlights extracellularspaces removing almost all contrast from intracellular structures [5]. However, it is not possibleto identify synapses with that approach. Identification of synapses is an important part of neuralcircuit reconstruction because it determines which cells are communicating, and where in thecircuitry they connect. To highlight synapses in TEM, scientists must use a stain that alsohighlights intracellular structures, such as vesicles and mitochondria, as well as neuronmembranes. Therefore, image segmentation techniques must account for these datacharacteristics in order to identify and successfully track neurons across hundreds of sections.1.2. Neuron segmentationThere are two general approaches for neuron segmentation. One approach focuses first on thedetection of neuron membranes in each 2-D section [19,20,21]. These boundaries can be usedto identify individual neurons, which are then linked across sections to form a complete neuron.Unfortunately, accurate detection of neuron membranes in EM is a difficult problem given thepresence of intracellular structures. This makes simple thresholding, edge detection (i.e.,Canny), and region growing methods ineffective for the detection of neuron membranes. Someexample images and results with traditional image processing methods are shown in Figure 1.The other approach to neuron segmentation is to directly use the 3-D characteristics of the data[22,23]. However, full 3-D approaches are difficult due to the anisotropic nature of the data.As mentioned earlier, in serial-section EM, there is a trade-off between section thickness andsection loss rate. The datasets used in this paper to demonstrate membrane detection are fromthe C. elegans ventral nerve cord and from the rabbit retina. For these datasets, the nerve cordhas a resolution of 6nm × 6nm × 33nm and the retina has a resolution of 2nm × 2nm × 80nm.This large section thickness often causes features to shift significantly between sequentialimages, decreasing the potential advantages of a direct 3-D approach. For these reasons, wefollow the first approach which is to first perform a 2-D segmentation followed by a linkingof the segmented regions in 3-D. This approach is particularly suitable for datasets in which amajority of the neurons run in a general direction which is roughly orthogonal to the sectioningplane such as the datasets considered in this paper. The main focus of this paper is to improvethe 2-D neuron segmentation in each section. This information can then be used to link thesegmentation in each section to obtain the full 3-D reconstruction.Recent related work indicates that machine learning methods are an effective approach fordetection of neuron membranes. These methods all use different representations for learningmembrane pixels, most of which include training a single instance of a classifier on imagederived features, such as Hessian eigenspaces [21,24] and local statistical features [22].Inspired by Tu’s auto-context shape classification approach [25], the method described in thispaper uses a series of classifiers to more accurately detect membranes in EM images, which isa necessary step for improved 3-D neuron segmentation as discussed above. However, unlikeMed Image Anal. Author manuscript; available in PMC 2011 December 1.   I-NHPAAuthorManuscriptI-NHPAAuthorManuscriptI-NHPAAuthorManuscriptJurrus et al.Page 4Tu’s auto-context [25] which uses boosting to select features from a large pool of candidatessuch as Haar wavelet responses, we use a series of artificial neural networks (ANNs) thatoperate on a fixed set of features. The first ANN uses as input the intensity values sampleddirectly from the image. The input to the subsequent ANNs in the series is comprised of thesame set of image values, in addition to the output of the previous ANN sampled on a stencilof nearby pixels (as depicted in Figure 4). The ANNs in the series, therefore, have differentinputs even though they have a common desired output. The advantages of this method aretwofold. First, the classifier uses raw data, that is, the image intensities, rather than a constrainedversion of the image as given by responses to a large filter bank or statistical features that willnot scale well for large datasets. Second, the use of the serial ANNs provides context, whichis information from nearby pixels that contributes to the learning, providing increasing amountsof relative information at each stage of the network. As a result, the series of ANNs learns toremove vesicles and mitochondria from the membrane detection and close gaps in places wherethe membrane is weak. In this paper, we demonstrate the improvement from the combined useof stencils and the series of ANNs for two datasets with distinctly different characteristics.2. Related WorkThere are several methods that attempt to segment EM images of neural tissue. Active contours,in both parametric and level set forms [26,20,27], can provide smooth, accurate segmentationsof cells. However, they are very sensitive to initialization, which must be close to the neuronmembrane, and often confuse internal structures for neuron membranes. If given an edge termthat suppresses internal structures, such as one that is derived from the output of the classifierproposed in this paper, these methods may be more promising. Also, recent work using graph-cut segmentations on EM images produces promising neuron segmentations starting from amanual initialization [28]. All of these methods require an initialization and are moreappropriate for segmenting only a few cells. Our goal is the automatic segmentation ofthousands of cells which renders manual initialization impractical.Another set of approaches focus on segmenting the neurons by first performing membranedetection. Simple thresholding methods can be applied after anisotropic directional smoothingto improve membrane continuity [29,19]. This method does not remove internal cellularstructures and simultaneously fails to detect a sufficiently high percentage of the truemembranes to make accurate segmentations.Supervised machine learning methods have proved to be useful for detecting membranes inEM images. For example, Jain et al. utilizes a multilayer convolutional ANN to classify pixelsas membrane or non-membrane in specimens prepared with an extracellular stain [23]. Theconvolutional ANN has two important characteristics: it learns the filters for classificationdirectly from data, and the multiple convolutions throughout the layers of the network accountfor an increasing (indirect) filter support region. On the other hand, the proposed ANN containsmore than 30,000 parameters and, therefore, is computationally intensive and requires verylarge training sets. For these reasons, this approach has limited practical usefulness. Andres etal. proposes a multi-part segmentation process that uses statistical learning and watersheds tosegment neural tissue [22]. Both of these methods produce clear segmentations of themembranes, however, they are aimed at datasets in which the stain used on the specimensuppresses the contrast of intracellular structures leaving only the cell membranes visible [5].This preparation technique simplifies the segmentation task but, on the other hand, it preventsa full neural circuit reconstruction since this requires the detection of synapses, which arecharacterized by certain intracellular structures.In other work based on supervised learning, simple classifiers such as a single perceptronapplied to a carefully chosen set of features has been shown to provide promising results inMed Image Anal. Author manuscript; available in PMC 2011 December 1.   Jurrus et al.Page 5identifying membranes in EM images [24]. Nevertheless, this method still needs significantpost processing to connect membranes and remove internal cellular structures. Similarly,Venkataraju et al. proposes using local context features computed from the Hessian matrix totrain a boosted classifier to detect membranes, which highlights the importance of context formembrane detection [21]. The results obtained with these methods demonstrate not only thecomplexity of the problem, but also the potential of supervised machine learning for neuronsegmentation.Conceptually, of particular relevance to this work is Tu’s auto-context framework [25], whichuses a series of classifiers with contextual inputs to classify pixels in images. In Tu’s method,the “continuous” output of a classifier, considered as a probability map, and the original set offeatures are used as inputs to the next classifier. The probability map values from the previousclassifiers provide context for the current classifier, by using a feature set that consists ofsamples of the probability map at a large neighborhood around each pixel. This means that aclassifier can utilize information relayed by previous classifiers from pixel values beyond thescope of its neighborhood, much like a convolutional network. This works well for thestructures being detected in this paper. For example, when detecting smooth and elongatedfeatures, context helps identify pixels as belonging to membranes instead of other localstructures, such as vesicles, by using information from a broader area. Hence, each subsequentclassifier extends the support of the probability map, improving the decision boundary, andthus the system can learn the context, or shapes, associated with a pixel classification problem.Theoretically, the series of classifiers improves an approximation of a posteriori distribution[25]. One of the main contributions of our work is the formulation of a series of ANNs in anarchitecture similar to auto-context. The particular implementation demonstrated by Tu uses8,000 nonspecific, spatially dispersed, image features, and a sampling of probability maps invery large neighborhoods. This is appropriate for methods that use a boosting classifier strategy[30] and are being performed on smaller scale machine learning problems. However, in theproposed method, a much smaller set of features allows for flexibility and training of largedatasets, such as the full rabbit retina dataset [6], which in total is 16TB, and is more suitablefor an ANN classifier.More generally, the detection of complete membranes, even when portions of the membraneare low in contrast, is closely related to the contour completion and salient contour extractionproblems which have been studied extensively in the computer vision literature. A detailedreview of the literature on contour completion is beyond the scope of this paper. Variousapproaches have been proposed including spectral clustering and, graph analysis [31,32,33,34], tensor voting [35], probabilistic models [36] and conditional random fields [37]. Somerelated work in this area also uses supervised classification that combines features acrossdifferent scales to detect edges and close contours [38,39]. This paper applies similartechniques in the use of auto-context, which uses incremental learning to gather informationabout features at different levels. Each stage of the network learns more information aboutnearby pixels, closing structures that would otherwise be difficult to identify without anincremental approach.3. MethodI-NHPAAuthorManuscriptI-NHPAAuthorManuscriptI-NHPAAuthorManuscriptThe method developed here for neuron membrane detection combines ANN classifiers andimage stencil neighborhood feature vectors. The following sections provide details on each ofthese components.3.1. Artificial Neural NetworkGiven the success of ANNs for membrane detection [24,23] and because auto-context is notspecifically tied to any classifier, we implement a multilayer perceptron (MLP) ANN as ourMed Image Anal. Author manuscript; available in PMC 2011 December 1.   I-NHPAAuthorManuscriptI-NHPAAuthorManuscriptI-NHPAAuthorManuscriptJurrus et al.Page 6classifier. An MLP is a feed-forward neural network which approximates a classificationboundary with the use of nonlinearly weighted inputs. The architecture of the network isdepicted schematically in Figure 2. The output of each processing element (PE) (each of nodeof the ANN) is given as [40,41](1)where f is, in our case, the tanh nonlinearity, w is the weight vector, and b is the bias. The inputvector x to PEs in the hidden layer is the input feature vector discussed in more detail in thenext section. For the output PEs, x contains the outputs of the PEs in the hidden layer.ANNs are a method for learning general functions from examples. They are well suited forproblems without prior knowledge of the function to be approximated (a.k.a., ”black boxmodels”). They have been successfully applied to robotics [42,43] and face and speechrecognition [44,45], and are robust to noise. Training uses gradient descent to solve for asolution which is guaranteed to find a minimum. However, several trade-offs occur in trainingANNs regarding the size of the network and the number of inputs. An ANN with too manyhidden nodes can lead to overfitting of the network [40], resulting in a set of weights that fitswell to the training data, but may not generalize well to test data. At the other extreme, if thenumber of hidden nodes is insufficient the ANN does not have enough degrees of freedom toaccurately approximate the decision boundary. The number of inputs should also be keep smallto mitigate the problem high-dimensional spaces, known as the “curse of dimensionality.”Generally speaking, as the dimensionality of the input space increases, the data becomesincreasingly sparse which makes it difficult to accurately learn a decision boundary.Additionally, the training time tends to scale with the amount of training data and size of thenetwork, and therefore training smaller networks is generally preferable. Hence, the numberof inputs to each ANN should be large enough to describe the data, while keeping this numberto a minimal.3.2. Image Stencil NeighborhoodChoosing the best set of features to use in training an ANN is crucial for obtaining goodsegmentations. The field of machine learning has made available several possible strategies.A possible approach uses large sets of statistical features as the input to a learning algorithm.These features can include simple local and non-local properties, including the pixel values,mean, gradient magnitude, standard deviation, and Hessian eigenvalues [22,25,21]. Theseattempt to present the learning algorithm with a large variety of mathematical descriptors totrain on, and are designed to work on a variety of data types. To achieve this generality,however, large numbers of these features are required to train a classifier. Training a classifier,and ANNs in particular, with a large number of features is challenging due to the “curse ofdimensionality” which, if not done carefully, can complicate the decision space and make itdifficult to find an optimal solution. Another approach is to design a set of match filters andapply them to an image to approximate a pixel’s similarity to a membrane. This works well ifthe membranes in the image are uniform and respond well using cross-correlation [46,47].Moreover, the design of the filter bank requires significant a priori knowledge of the problem.Yet, the fixed design may not be optimal for the dataset. Most importantly, the match filtershave to be redesigned for datasets with different characteristics. On the other hand, learningthese filters from training data, as in the case of convolutional networks [23], has the advantagethat no a priori knowledge is required. A similar idea was been used in texture classificationwhere is was shown that direct sampling of the image with a patch is actually a simpler andbetter approach for training a classifier compared to the use of filter banks [48]. Image patcheshave also been used successfully for texture segmentation [49] and image filtering [50,51,Med Image Anal. Author manuscript; available in PMC 2011 December 1.   I-NHPAAuthorManuscriptI-NHPAAuthorManuscriptI-NHPAAuthorManuscriptJurrus et al.Page 752]. Similarly, using image neighborhoods in our case allows the ANNs to learn directly onthe input data, giving the classifier more flexibility in finding the correct decision boundary.We define a square image neighborhood as an image patch, shown in Figure 3(a), centered atpixel k, l,R is the width of the square image patch. Unfortunately, the size of the image patches requiredto capture sufficient context can be quite large. For this reason, we propose using as input tothe ANNs the values from the image and probability map of the previous classifier sampledthrough a stencil neighborhood, shown in Figure 3(b). A stencil is also centered at pixel k, land defined as,(2)where(3)(4)and n is the number of rows the stencil spans in the image. The stencil can cover large areasrepresenting the desired feature space, but samples it with a spatially adaptive resolutionstrategy. In this way, an ANN can be trained using a small number of samples from image data,without having to use the whole image patch. Since the number of weights to be computed inan ANN are dominated by the connection between the input and the hidden layers, reducingthe number of inputs reduces the number of weights and helps regularize the learned network.Moreover, using less inputs generally allows for faster training. With this, one aims to providethe classifier with sparse, but sufficient context information and achieve faster training, whileobtaining a larger context which can lead to improve membrane detection. This strategy,combined with the serial use of ANNs (described in section 3.3), grows the region of interestfor classification within a smaller number of stages and without long training times.3.3. Serial Artificial Neural NetworksUsing principles from auto-context, we implemented a series of classifiers that leverage theoutput of the previous network to gain knowledge of a large neighborhood. For the firstclassifier, the input is the image intensities around a pixel sampled using a stencil. For theANNs in the remaining series, the input vector contains the samples from the original image,used as input to the first ANN, appended with the values from the output of the previousclassifier sampled through the stencil neighborhood, yielding a larger feature vector. While thedesired output labels remain the same, each ANN is dependent on the information from theprevious network and therefore must be trained sequentially, rather than in parallel. Figure 4demonstrates this flow of data between classifiers. I denotes the image, S the image valuessampled from the image using the stencil, C the output from the ANN, and T the thresholdapplied to C at zero, yielding the final membrane detection.The serial structure allows the classifiers to gather with each step context information from aprogressively larger image neighborhood to the pixel being classified, as occurs with aconvolutional ANN. Indirectly, the classification from the previous ANN contains informationabout features in surrounding pixels, that is not represented in the original feature set. ThisMed Image Anal. Author manuscript; available in PMC 2011 December 1.   Jurrus et al.Page 8allows the subsequent networks in the series (Figure 4) to make decisions about the membraneclassification utilizing nonlocal information. Put differently, each stage in the series accountsfor larger structures in the data, taking advantage of results from all the previous networks.This results in membrane detection that improve after each network in the series. Figure 5visually demonstrates the classification improving between ANNs in the series as gaps in weakmembranes are closed and intracellular structures are removed with each iteration in the series.The receiver operating characteristic (ROC) curves in Figures 6 also demonstrate the increasein detection accuracy after each ANN in the series.Combining the original image features with features sampled from the output of the previousclassifier is important because, in this way, the membrane structure relevant for detection isenforced locally and then again at a higher level with each step in the series of classifiers. Oneof the advantages of this approach is that it provides better control of the training, allowing thenetwork to learn in steps, refining the classification at each step as the context information itneeds to correctly segment the image increases. Again, note that the membrane structure islearned directly from the data. Compared to a single large network with many hidden layersand nodes, such as the convolutional ANN of Jain et al. [23] which requires 34,000 parameters,the proposed classifier is easier to train. This is mainly because each of the ANNs have arelatively small number of parameters. For example, given a single ANN used to compute theresults in Section 4, the number of parameters needed is approximately 500 for the first ANNand 1100 for the remaining ANNs in the series. The number of weights in an ANN with asingle-hidden layer is given by (n + 1)h + (h + 1), where n is the number of inputs and h is thenumber of nodes in the hidden layer. For the first ANN in the series, n = s, where s is the numberof points in the stencil. For the remaining ANNs in the series, n = 2s, since we sample theoriginal image and the output from the previous classifier once. The total number of parametersacross the whole series totals to approximately 5000. In contrast, a convolutional ANN needs(n + 1)h for the first layer,and (nh + 1)h for the remaining layers, an h2 dependence [23]. Hence,much less training data is needed, which is hard to obtain, since the ground truth must be handlabeled3. Furthermore, the training is simpler since backpropagation is less likely to get stuckon local minima of the performance surface [40,41], and the network will train much faster.Two TEM datasets are used as test cases for the proposed method. The first dataset is a stackof 50 sections from the ventral nerve cord of the C. elegans. The second dataset is a singlesection from the 16TB rabbit retina dataset. These datasets contain very different types of neuralcells. The C. elegans data has a resolution of 6nm×6nm×33nm and each 2-D section is 662×697pixels. Neuron membranes in the C. elegans data appear as intensity valleys; however, not allvalleys in the data are neuron membranes, i.e. membranes of intracellular structures may alsoappear locally as valleys. The proposed method successfully learns the appropriate subset ofridges that need to be identified as neuron membranes as will be described in Section 4.2. Therabbit retina data has a resolution of 2nm×2nm×80nm and each 2-D section is 7629×7351pixels. Unlike the C. elegans dataset, neuron membranes in the retina data generally appear asintensity edges. Owing to the flexibility offered by the use of stencils rather than a predefinedfilter bank, the proposed method is also successful in learning to detect neuron membranes inthis dataset as will be discussed in Section 4.3.I-NHPAAuthorManuscriptI-NHPAAuthorManuscript4. ResultsI-NHPAAuthorManuscript3According to the “rule-of-thumb” in [41], one needs at least 10× training samples pf the total number of parameters. Thus, comparedto Jain et al. [23] convolutional ANN, our approach needs about 27× less training samples, for the values given.Med Image Anal. Author manuscript; available in PMC 2011 December 1.   I-NHPAAuthorManuscriptI-NHPAAuthorManuscriptI-NHPAAuthorManuscriptJurrus et al.4.1. Experimental SetupPage 9Before discussing detailed results of experiments on the two dataset, we will outline thecommon experimental details. First, our setup for these data sets used 5 ANNs in series.Additional networks could be included; however, for these datasets, the performance convergesto a limit (Figure 6) and improvement in membrane detection is minimal. Each ANN used inthe experiments contained one hidden layer with 20 nodes. We experimented with more layersand different numbers of nodes but did not find significant advantages. It is important that thenumber of nodes be large enough to approximate a non linear boundary and small enough thatthe ANN does not overfit to the training data [53,54]. Results using 10, 20, and 30 nodes turnedout to be somewhat similar. Given the time versus performance trade-off, we chose 20 nodes.The networks were trained using backpropagation with a step size of 0.0001 and momentumterm of 0.5. We used early stopping as the criterion to determine when to terminate training[40,41]. This means that a small portion of the training data (20% in our case), called thevalidation set, is used only to test the classifier generalization performance. The trainingterminates when the lowest error on the validation set is attained. To mitigate problems withlocal minima, each network is trained for 5 Monte Carlo simulations using randomly initializedweights.Preprocessing is performed for each image using a contrast limited adaptive histogramequalization (CLAHE) [55] filter. This enhances the contrast of the membranes. Window sizesof 64×64 and 256×256 were used for the C. elegans and retina datasets, respectively.Each image used in the experiments was annotated by an expert who carefully marked neuronmembranes with a one-pixel-wide contour. This contour was dilated using a disk shaped kernelwith a radius of 2 pixels, ensuring that the positive training examples cover all of the actualmembrane pixels. The negative training examples were selected as the remaining pixels in theimage, after erosion to remove training pixels that are very close to the membranes. Thisstrategy leaves a thin layer of pixels between the positive and negative training example pixelsthat are not used for training purposes. This ensures that the network learns on pixels that areeither membrane or non-membrane, excluding those that are more prone to labeling errors.Finally, to optimize network performance, the total number of training examples from eachimage includes all of the positive examples and a random selection of negative examples suchthat there are twice the number of negative examples, than positive. Choosing the optimalnumber of training examples was difficult given there were many more negative than positiveexamples in this dataset. If all the negative training examples are used then the ANNS arebiased towards classifying pixels as non-membrane. After conducting a series of experimentsfor considering the results from different ratios of positive and negative examples and thetraining times, we found the 2:1 ratio resulted in the best segmentation while achieving areduced training time. Using all the training data (and other increased ratios, such as 4:1)produced a similar ROC curve but results were biased towards false negatives. Clearly, wecould have adjusted the threshold in the final stage.Alternatively, one possible solution for thisproblem would be the use of a weighting factor chosen to obtain unbiased training. However,either approach would have much slower training than the previous described strategy withoutimproving the overall segmentation. For each pixel in our training data, a stencil with a radiusof 5 (or n = 11 in Equation 3) is used to sample the image data and form the feature vector.4.2. Results on the C. elegans Ventral Nerve CordThe nematode C. elegans is an important dataset for neural circuit reconstruction. Despite beinga well studied organism [4], there are still numerous open questions such as how genes regulatewiring [56] or how connectivity is altered to mediate different behaviors, for example betweenmales and females [57]. Reconstructions of the full nervous system reveals topologicalMed Image Anal. Author manuscript; available in PMC 2011 December 1.   I-NHPAAuthorManuscriptI-NHPAAuthorManuscriptI-NHPAAuthorManuscriptJurrus et al.Page 10characteristics important for researchers studying neuron wiring. The particular dataset usedin this paper is from the ventral nerve cord of the C. elegans and is important for studying thetopological structure resulting from neurons making connections to local targets.To validate the robustness of the method, five-fold cross-validation was used on a set of 50annotated images, separated into 5 groups of 10 images in each. The network was trained oneach fold according to the procedure described in Section 4.1, and tested on the remaining four.The improvement in the classification after each ANN in the series is visible in the classificationof the training data after each stage, shown in Figure 5, and in the receiver operatingcharacteristic (ROC) curves in Figure 6. The output from the network improves quantitativelyand qualitatively with each network in the series. Directly sampling the image using a stenciland repeated uses of the network enables the method to accurately estimate the appearance ofmembrane pixels and pixels in surrounding neighborhoods.Figure 7(a) shows four sections from the C. elegans dataset chosen at random. The finalmembrane detection with the proposed method is shown in Figure 7(e). Note that these aretesting results; that is, these four sections were not used as training data. To demonstrate theadvantages of the proposed method, two other methods are presented. The first method, shownin Figure 7(b), performs thresholding after enhancing the membranes with anisotropicdirectional smoothing [19]. Figure 7(c) shows results from an approach similar to the approachin Mishchenko [24], which learns boundary confidences using Hessian eigenvalues as inputto a single layer neural network. It can be seen that the proposed method removes a substantiallylarger percentage of the intracellular structures from the detection results as well as providingbetter membrane continuity. It is important to note that in Mishchenko [24] further post-processing is performed to interpolate between broken boundaries and complete contours,resulting in an improved result compared to the one shown here. However, we compare againstonly the single layer network part of that method since our goal is to demonstrate theimprovement achieved by the use of ANNs and auto-context. Of course, the samepreprocessing methods could be applied to the results of the proposed method as well. Figure8 shows enlarged regions demonstrating the removal of large intracellular structures andclosing of weak membranes.To demonstrate the advantages of directly sampling the image with a stencil, we also testedthe proposed auto-context ANN strategy but with inputs to the ANNs that are derived from aline detection filter bank rather than sampling the image. We used a filter bank that consists ofa set of 32 line detection filters oriented at different angles and 5 circle detection filters withdifferent radii. The circle detection filters were included to help the auto-context ANN to learnto remove vesicles from the membrane detection results. Figure 7(d) is the output obtainedwith the filter bank/series of ANN approach. While these results are better than the results inFigure 7(b) and (c), they contain more false positives than the results of the full stencil/auto-context ANN approach shown in Figure 7(e). The advantages of using the stencil becomesclearer in a quantitative comparison as discussed in the next paragraph. Furthermore, animportant practical advantage of using the stencil is that it does not require any a prioriknowledge. Therefore, it can be trained to detect different structures as will be shown for theretina dataset in Section 4.3. In comparison, a filter bank designed to capture the relevantstructures for the C. elegans dataset is not expected to capture the relevant structures in adifferent dataset which necessitates the design of a new filter bank.Figure 9 compares the ROC curves for each method from Figure 7. For this particular data, asingle layer ANN using Hessian eigenvalues as inputs (labeled “Hessian”) demonstrates noquantitative differences from thresholding after directional anisotropic diffusion (labeled“Jurrus et al.”). These ROC curves correspond to the qualitative results in Figure 7(b) and (c),respectively. The other three curves all show a large improvement in performance. The use ofMed Image Anal. Author manuscript; available in PMC 2011 December 1.   I-NHPAAuthorManuscriptI-NHPAAuthorManuscriptI-NHPAAuthorManuscriptJurrus et al.Page 11membrane detection filters (labeled “Filters”) demonstrates how a carefully chosen set offeatures can be used for learning to detect membranes. Image patches (labeled “Patches”) arejust as successful in training to detect membranes as filters. However, in testing, the patchesoutperform the filters. We argue that this is due to the fact that patches sample the image directlyand give more flexibility to the classifier than a filter bank. Using a stencil (labeled “Stencil”)results in the best performance. The stencil provides the classifier with two important features.First, similar to patches, it trains the classifier on image sample directly, as opposed to a fixedrepresentation as obtained from the filters. Second, it samples a larger area than the patches,while maintaining the same number of features (as seen in Figure 3). The latter feature is veryhelpful in practice since it ensures improved performance without sacrificing the networktraining time (actually, in our experiments, using the stencil improved the training reliabilityand time).Figure 10 demonstrates the final neuron segmentation, after a very simple region flood fill isapplied to the image of detected membranes with the proposed method. This depicts how closethe final segmentation is to the true segmentation. Figure 11 is a full 3-D neuron segmentationfor four key neurons and nearby muscles from this dataset. Neurons are segmented in eachsection using a region flood fill and linked across sections using a minimum path findingalgorithm similar to Jurrus et al. [19]. Hand edits were required to correct some mistakes inthe automatic segmentation. This 3-D model shows the motor neurons in the ventral nerve cordand their processes interdigitating along the lateral edge of the nerve bundle (Figure 11(a)) tomake contact with the muscles (Figure 11(b)). Multiple muscles, in turn, must send processesto these motor neurons to receive input. Areas where this communication is occurring aremarked in red. There are three motor neuron inputs into these muscles: the VA neurons releaseacetylcholine during backwards movement, the VB neurons release acetylcholine duringforward movement, and the VD motor neurons release GABA to relax the muscle to allowsinusoidal movement. These data demonstrate that axons do not precisely interweave. GABAneurons run alongside a group of muscle arms and form multiple synapses to differing subsetsof muscles before giving way to acetylcholine motor neurons. By contrast, the two types ofacetylcholine neurons usually form contacts to the muscles simultaneously. Again, they form2 to 3 contacts to the muscles for a segment of axon before giving way to the GABA motorneuron. This demonstrates the importance and diagnostic capabilities of full connectivitydiagrams and renderings.4.3. Results on the Rabbit RetinaThe retina is a complex structure containing several layers of neurons. Processing light sets offa series of chemical events and connections among these neurons that scientists would like tomodel. Most importantly, scientists would like to characterize neural circuitry that is damagedand in a diseased state. However, unraveling the connective patterns in this complex tissue isan enormous task.To demonstrate the robustness of our method on a very different dataset, an expert handsegmented all of the bipolar, amacrine, and horizontal cells in a single 2-D section through theretina. This section is 7629×7351 pixels and contains approximately 500 neurons. The imagewas divided into four equal sections and a four-fold cross validation technique is used to assessthe performance of the algorithm.Figure 12 shows the output on the test data. Figure 12(a) shows portions of the TEM image,cropped to show the cellular details. Figure 12(b) is a simple baseline membrane detectionobtained by thresholding the intensity gradient after smoothing the input image with a Gaussiankernel (standard deviation 3 pixels). Thresholding the gradient results in some obviousproblems. Differences in contrast and the presence of intracellular features make isolation ofthe neuron edges difficult. Figure 12(c) shows the results of applying the series of ANN methodMed Image Anal. Author manuscript; available in PMC 2011 December 1.   I-NHPAAuthorManuscriptI-NHPAAuthorManuscriptI-NHPAAuthorManuscriptJurrus et al.Page 12with a filter bank as input. For this data, 25 Leung-Malik edge filters [46] were used. TheLeung-Malik filter banks consists of first derivatives of a Gaussian kernel (standard deviation3 pixels) at various orientations. The results in Figure 12(d) are from the stencil/serial ANNapproach identical in architecture to the one used for the C. elegans dataset. From a qualitativeperspective, the stencil removes more intracellular structures and is more robust to changes incontrast. When the weights from the final network, which was trained with a filter bank, areapplied to the testing images, the edge detection performs poorly. However, sampling the imageusing a stencil is a more robust way to detect membrane edges and provides more consistentresults across images. Figure 13 gives clear examples of how this method removes nonmembrane structures and closes complex gaps resulting from inconsistent membrane data.Most importantly, the results from this dataset demonstrate the flexibility of our method ondifferent feature types. The feature vectors for both dataset are the same, that is, they are simplyram image values sampled from the input data.Figure 14 shows the quantitative comparison for the methods demonstrated in Figure 12. Thegradient magnitude provides a baseline for how well a simple edge detection method can beexpected to perform. While it detects many of the neuron boundaries, it also has a lot of falsepositive responses for internal structures and fails to close gaps in weak parts of the membranes.The serial networks provide a very large improvement over this simple method when a filterbank is in place. However, the proposed stencil/auto-context ANN method is demonstrated todo still a significantly better job at detecting boundaries than the filters.5. Conclusion and Future WorkIn this paper a new approach for neuron membrane detection is proposed. Inspired by Tu’sauto-context framework [25], our approach introduces two major contributions. The firstcontribution is the introduction of a serial ANN classifier and its application to neuronmembrane detection. The use of context allows the classifier to close gaps in weak membranesand suppress intracellular structures by using increasingly non-local information with eachANN in the series. The second contribution is the use of raw image intensities sampled througha stencil as inputs to the series ANN rather than a predetermined filter bank. This providesincreased flexibility to the classifier which can then be trained to detect neuron membranes indatasets with significantly different characteristics. Also, it must be noted the choice ofsampling the image with a stencil rather than using the more traditional patch neighborhood.As shown in the results, utilizing a stencil yields significantly better results. This is because,for the same number of features, a stencil provides context information for a largerneighborhood. Although larger patches could be utilized, the number of features would growmore rapidly to impractical levels, and would be slower (and more complicated) to train theclassifier. These two contributions result in a neuron membrane algorithm that outperformsother methods.A direct comparison to Tu’s auto-context classification using a probabilistic boosting tree isdifficult to do. Applying the same filter bank to the data presented here results in storagecomplications and does not scale to larger datasets like the rabbit retina data, which is 16TB[6]. However, to compare the performances, our method was tested on the Weizmann Horsedataset [58], for which results using Tu’s method are available, without significant changes inperformance. The method used in this paper had an overall accuracy (or f-value) of 0.834,while Tu’s accuracy was 0.84, and the qualitative differences were negligible [59].Nevertheless, it must be emphasized that a major advantage in our method is that the filtersare learning directly from data, tremendously simplifying the user’s role. By incorporating asimilar architecture into the form of a series of ANNs, we have designed a method that performswell on EM images and aids in the building of 3-D models for neural circuit reconstruction, asdepicted in Figure 11.Med Image Anal. Author manuscript; available in PMC 2011 December 1.   I-NHPAAuthorManuscriptI-NHPAAuthorManuscriptI-NHPAAuthorManuscriptJurrus et al.Page 13Given the challenge of full 3D reconstructions, and the extremely anisotropic resolution ofserial section TEM, we approach this problem with a two-stage solution that consists of firstsegmenting neurons in 2-D sections and then linking them up the segments in 3-D. Therefore,the motivation for improving the accuracy of automatic neuron membrane detection methodsis to minimize user interaction required to correct the segmentation. Figure 10 demonstratessegmentations obtained by applying a simple flood fill operation to the image of detectedmembranes without any user corrections. In future work, segmentations obtained using theproposed method can be ex-tended to other sections, taking advantage of segmentations insequential sections having similar anatomy. Simple gap closing methods can also be appliedto close small remaining holes in the membrane for a better 2-D neuron segmentation. Finally,a similar classifier strategy could prove successful also in segmenting long tubular structuressuch as vasculature in MRI due to the capability of closing gaps in weak areas of elongatedstructures.AcknowledgmentsThis work was supported by NIH R01 EB005832 (TT), NIH EY0015128 (RM), EY002576 (RM), NEI Vision CoreEY014800 (RM), HHMI (EMJ), and NIH NINDS 5R37NS34307-15 (EMJ).References1. Sporns O, Tononi G, Ktter R. The human connectome: A structural description of the human brain.PLoS Comput. Biol 2005;1:e42. [PubMed: 16201007]2. Fiala JC, Harris KM. Extending unbiased stereology of brain ultra-structure to three-dimensionalvolumes. J Am Med Inform Assoc 2001;8(1):1–16. [PubMed: 11141509]3. Briggman KL, Denk W. Towards neural circuit reconstruction with volume electron microscopytechniques. Current Opinion in Neurobiology 2006;16(5):562–570. doi:http://dx.doi.org/10.1016/j.conb.2006.08.010, URL http://dx.doi.org/10.1016/j.conb.2006.08.010. [PubMed: 16962767]4. White J, Southgate E, Thomson J, Brenner F. The structure of the nervous system of the nematodeCaenorhabditis elegans. Phil. Trans. Roy. Soc. London Ser. B Biol. Sci 1986;314:1–340.5. Briggman KL, Denk W. Towards neural circuit reconstruction with volume electron microscopytechniques. Current Opinion in Neurobiology 2006;16(5):562–570. [PubMed: 16962767]6. Anderson J, Jones B, Yang J-H, Shaw M, Watt C, Koshevoy P, Spaltenstein J, Jurrus EUVK, WhitakerR, Mastronarde D, Tasdizen T, Marc R. A Computational Framework for Ultrastructural Mapping ofNeural Circuitry. PLoS Biology 2009;7(3):e74.7. Marc RE, Jones BW, Watt CB, Vazquez-Chona F, Vaughan DK, Organisciak DT. Extreme retinalremodeling triggered by light damage: implications for age related macular degeneration. Mol. Vis2008;14:782–806. [PubMed: 18483561]8. Marc RE, Jones BW, Anderson JR, Kinard K, Marshak DW, Wilson JH, Wensel T, Lucas RJ. Neuralreprogramming in retinal degeneration. Invest. Ophthalmol. Vis. Sci 2007;48:3364–3371. [PubMed:17591910]9. Marc RE, Jones BW, Watt CB, Strettoi E. Neural remodeling in retinal degeneration. Prog Retin EyeRes 2003;22:607–655. [PubMed: 12892644]10. Jones BW, Marc RE. Retinal remodeling during retinal degeneration. Exp. Eye Res 2005;81:123–137. [PubMed: 15916760]11. Jones BW, Watt CB, Frederick JM, Baehr W, Chen CK, Levine EM, Milam AH, Lavail MM, MarcRE. Retinal remodeling triggered by photoreceptor degenerations. J. Comp. Neurol 2003;464:1–16.[PubMed: 12866125]12. Jones BW, Watt CB, Marc RE. Retinal remodelling. Clin Exp Optom 2005;88:282–291. [PubMed:16255687]13. Peng YW, Hao Y, Petters RM, Wong F. Ectopic synaptogenesis in the mammalian retina caused byrod photoreceptor-specific mutations. Nat. Neurosci 2000;3:1121–1127. [PubMed: 11036269]14. Sutula T. Seizure-Induced Axonal Sprouting: Assessing Connections Between Injury, Local Circuits,and Epileptogenesis. Epilepsy Curr 2002;2:86–91. [PubMed: 15309153]Med Image Anal. Author manuscript; available in PMC 2011 December 1.   I-NHPAAuthorManuscriptI-NHPAAuthorManuscriptI-NHPAAuthorManuscriptJurrus et al.Page 1415. Pollard H, Khrestchatisky M, Moreau J, Ben-Ari Y, Represa A. Correlation between reactivesprouting and microtubule protein expression in epileptic hippocampus. Neuroscience 1994;61:773–787. [PubMed: 7838377]16. Koyama R, Yamada MK, Fujisawa S, Katoh-Semba R, Matsuki N, Ikegaya Y. Brain-derivedneurotrophic factor induces hyperexcitable reentrant circuits in the dentate gyrus. J. Neurosci2004;24:7215–7224. [PubMed: 15317847]17. Sorra KE, Harris KM. Overview on the structure, composition, function, development, and plasticityof hippocampal dendritic spines. Hippocampus 2000;10:501–511. [PubMed: 11075821]18. DeBello, WM.; Feldman, DE.; Knudsen, EI. Adaptive Axonal Remodeling in the Midbrain AuditorySpace Map; J. Neurosci. 2001. p. 3161-3174.URLhttp://www.jneurosci.org/cgi/content/abstract/21/9/316119. Jurrus E, Whitaker R, Jones B, Marc R, Tasdizen T. An Optimal-Path Approach for Neural CircuitReconstruction. Proceedings of the 5th IEEE International Symposium on Biomedical Imaging: FromNano to Macro 2008:1609–1612.20. Macke J, Maack N, Gupta R, Denk W, Schölkopf B, Borst A. Contour-propagation algorithms forsemi-automated reconstruction of neural processes. Journal of Neuroscience Methods 2008;167:349–357. [PubMed: 17870180]21. V. KU, Paiva A, Jurrus E, Tasdizen T. Automatic markup of neural cell membranes using boosteddecision stumps. To Appear, Proceedings of the 6th IEEE International Symposium on BiomedicalImaging 2009:1039–1042.22. Andres, B.; Köthe, U.; Helmstaedter, M.; Denk, W.; Hamprecht, FA. Segmentation of SBFSEMVolume Data of Neural Tissue by Hierarchical Classification. In: Rigoll, G., editor. PatternRecognition, vol. 5096 of LNCS. Springer; 2008. p. 142-152.ISBN 978-3-540-69320-8, doi:10.1007/978-3-540-69321-5_1523. Jain V, Murray J, Roth F, Turaga S, Zhigulin V, Briggman K, Helmstaedter M, Denk W, Seung H.Supervised Learning of Image Restoration with Convolutional Networks. IEEE 11th InternationalConference on Computer Vision 2007:1–8.24. Mishchenko Y. Automation of 3D reconstruction of neural tissue from large volume of conventionalserial section transmission electron micrographs. J Neurosci Methods. 200925. Tu Z. Auto-context and its application to high-level vision tasks. IEEE Conference on ComputerVision and Pattern Recognition 2008:1–8.26. Jurrus E, Hardy M, Tasdizen T, Fletcher P, Koshevoy P, Chien C-B, Denk W, Whitaker R. AxonTracking in Serial Block-Face Scanning Electron Microscopy. Medical Image Analysis 2009;13(1):180–188. [PubMed: 18617436]27. Vazquez L, Sapiro G, Randall G. Segmenting Neurons in Electronic Microscopy via GeometricTracing. Proc. of ICIP 1998:814–818.28. Vu, N.; Manjunath, B. Graph cut segmentation of neuronal structures from transmission electronmicrographs. Image Processing, 2008; ICIP 2008. 15th IEEE International Conference on, ISSN1522-4880; 2008. p. 725-728.doi:10.1109/ICIP.2008.471185729. Tasdizen T, Whitaker R, Marc R, Jones B. Enhancement of Cell Boundaries in Transmission ElectronMicroscopy Images. ICIP 2005:642–645.30. Freund, Y.; Schapire, RE. A decision-theoretic generalization of on-line learning and an applicationto boosting; EuroCOLT ’95: Proceedings of the Second European Conference on ComputationalLearning Theory; London, UK: Springer-Verlag; 1995. p. 23-37.ISBN 3-540-59119-231. Shashua A, Ullman S. Structural Saliency: The Detection Of Globally Salient Structures using ALocally Connected Network. Computer Vision 1988:321–327. Second International Conference on.32. Mahamud S, Williams L, Thornber K, Xu K. Segmentation of multiple salient closed contours fromreal images, Pattern Analysis and Machine Intelligence. IEEE Transactions on 2003;25(4):433–444.ISSN 0162-8828, doi:10.1109/TPAMI.2003.1190570.33. Fowlkes C, Belongie S, Chung F, Malik J. Spectral Grouping Using the Nyström Method. IEEETransactions on Pattern Analysis and Machine Intelligence 2004;26:214–225. [PubMed: 15376896]34. Zhu, Q.; Song, G.; Shi, J. Untangling Cycles for Contour Grouping. Computer Vision, 2007; ICCV2007. IEEE 11th International Conference on, ISSN 1550-5499; 2007. p. 1-8.doi:10.1109/ICCV.2007.4408929Med Image Anal. Author manuscript; available in PMC 2011 December 1.   I-NHPAAuthorManuscriptI-NHPAAuthorManuscriptI-NHPAAuthorManuscriptJurrus et al.Page 1535. Tang C-K, Medioni G. Curvature-augmented tensor voting for shape inference from noisy 3D data,Pattern Analysis and Machine Intelligence. IEEE Transactions on 2002;24(6):858–864. ISSN0162-8828, doi:10.1109/TPAMI.2002.1008395.36. Ren, X.; Malik, J. A Probabilistic Multi-scale Model for Contour Completion Based on ImageStatistics; ECCV ’02: Proceedings of the 7th European Conference on Computer Vision-Part I;London, UK: Springer-Verlag; 2002. p. 312-327.ISBN 3-540-43745-237. Ren, X.; Fowlkes, C.; Malik, J. Scale-invariant contour completion using conditional random fields.Computer Vision, 2005; ICCV 2005. Tenth IEEE International Conference on, vol. 2, ISSN1550-5499; 2005. p. 1214-1221.doi:10.1109/ICCV.2005.21338. Dollar, P.; Tu, Z.; Belongie, S. Supervised Learning of Edges and Object Boundaries. ComputerVision and Pattern Recognition; IEEE Computer Society Conference on, vol. 2, IEEE ComputerSociety; Los Alamitos, CA, USA. 2006. p. 1964-1971.ISSN 1063-6919, doi:http://doi.ieeecomputersociety.org/10.1109/CVPR.2006.29839. Shotton J, Blake A, Cipolla R. Multiscale Categorical Object Recognition Using Contour Fragments.Pattern Analysis and Machine Intelligence, IEEE Transactions on 2008;30(7):1270–1281. ISSN0162-8828, doi:10.1109/TPAMI.2007.70772.40. Haykin, S. Neural networks - A comprehensive foundation. 2nd edn.. Prentice-Hall; 1999.41. Principe, JC.; Euliano, NR.; Lefebvre, WC. Neural and Adaptive Systems: fundamentals throughsimulations. John Wiley & Sons; 2000.42. Pomerleau, D. Knowledge-based Training of Artificial Neural Networks for Autonomous RobotDriving. In: Connell, J.; Mahadevan, S., editors. Robot Learning. Kluwer Academic Publishing;1993. p. 19-43.43. Wells G, Venaille C, Torras C. Promising Research: Vision-Based Robot Positioning Using NeuralNetworks. IVC 1996;14(10):715–732.44. Rabi G, Lu S. Visual Speech Recognition by Recurrent Neural Networks. JEI 1998;7(1):61–69.45. Cottrell, G. Extracting features from faces using compression networks: face, identity, emotion andgender recognition using holons. Morgan Kaufmann; 1990. p. 328-337.46. Leung T, Malik J. Representing and Recognizing the Visual Appearance of Materials using Three-dimensional Textons. Int. J. Comput. Vision 2001;43(1):29–44. ISSN 0920-5691, doi: http://dx.doi.org/10.1023/A:1011126920638.47. Schmid, C. Constructing models for content-based image retrieval. Computer Vision and PatternRecognition, 2001; CVPR 2001. Proceedings of the 2001 IEEE Computer Society Conference on,vol. 2, ISSN 1063-6919; 2001. p. II–39-II–45.doi:10.1109/CVPR.2001.99092248. Varma, M.; Zisserman, A. Texture classification: are filter banks necessary?. Computer Vision andPattern Recognition, 2003; Proceedings. 2003 IEEE Computer Society Conference on, vol. 2, ISSN1063-6919; 2003. p. II–691p. II–698doi:10.1109/CVPR.2003.121153449. Awate SP, Tasdizen T, Whitaker RT. Unsupervised Texture Segmentation with NonparametricNeighborhood Statistics. Proceedings of the European Conference on Computer Vision 2006:494–507.50. Buades A, Coll B, Morel J-M. A non-local algorithm for image denoising. Proceedings of IEEEConference on Computer Vision and Pattern Recognition 2005:60–65.51. Awate SP, Whitaker RT. Unsupervised, information-theoretic, adaptive image filtering for imagerestoration, IEEE Trans. on Pattern Analysis and Machine Intelligence. 2006;28(3):364–376.52. Tasdizen T. Principal Components for Non-local Means Image Denoising. Proceeding of InternationalConference on Image Processing. 200853. Cybenko G. Approximation by superpositions of a sigmoidal function. Mathematics of Control,Signals, and Systems 1989;2(4):303–314. doi:10.1007/BF02551274.54. Hornik K. Approximation capabilities of multilayer feedforward networks. Neural Netw 1991;4(2):251–257. doi:10.1016/0893-6080(91)90009-T.55. Pizer, S.; Johnston, R.; Ericksen, J.; Yankaskas, B.; Muller, K. Contrast-limited adaptive histogramequalization: speed and effectiveness. Visualization in Biomedical Computing; Proceedings of theFirst Conference on (1990); 1990. p. 337-345.doi:10.1109/VBC.1990.10934056. Jin Y, Hoskins R, Horvitz HR. Control of type-D GABAergic neuron differentiation by C. elegansUNC-30 homeodomain protein. Nature 1994;372(6508):780–783. [PubMed: 7997265]Med Image Anal. Author manuscript; available in PMC 2011 December 1.   Jurrus et al.Page 1657. White JQ, Nicholas T, Gritton J, Truong L, Davidson ER, Jorgensen EM. The sensory circuitry forsexual attraction in C. elegans males. Curr. Biol 2007;17(21):1847–1857. [PubMed: 17964166]58. Borenstein, E.; Sharon, E.; Ullman, S. Combining Top-Down and Bottom-Up Segmentation; CVPRW’04: Proceedings of the 2004 Conference on Computer Vision and Pattern Recognition Workshop(CVPRW’04) Volume 4, IEEE Computer Society; Washington, DC, USA. 2004. p. 46ISBN0-7695-2158-459. Paiva AR, Jurrus E, Tasdizen T. Using Sequential Context for Image Analysis. Proceedings of theInternational Conference on Pattern Recognition. 2010I-NHPAAuthorManuscriptI-NHPAAuthorManuscriptI-NHPAAuthorManuscriptMed Image Anal. Author manuscript; available in PMC 2011 December 1.   I-NHPAAuthorManuscriptI-NHPAAuthorManuscriptI-NHPAAuthorManuscriptJurrus et al.Page 17Figure 1.(a) Example EM images. Top is from the C. elegans, bottom is from a rabbit retina. (b) Examplemembrane detection using thresholding after contrast enhancement and anisotropic directionalsmoothing to enhance membranes (top), and thresholding on the gradient magnitude (bottom).Both methods highlight the membrane boundaries but fail to remove internal structures.Med Image Anal. Author manuscript; available in PMC 2011 December 1.   Jurrus et al.Page 18I-NHPAAuthorManuscriptI-NHPAAuthorManuscriptFigure 2.Neural network diagram with one hidden layer. Inputs to the network include the imageintensity and the values of the image at stencil locations.I-NHPAAuthorManuscriptMed Image Anal. Author manuscript; available in PMC 2011 December 1.   Jurrus et al.Page 19Figure 3.Two image neighborhood sampling techniques: image pixels sampled using (a) a patch and(b) a stencil. For this example, the stencil contains the same number of samples, yet covers alarger area of the data. This is a more efficient representation for sampling the image space.I-NHPAAuthorManuscriptI-NHPAAuthorManuscriptI-NHPAAuthorManuscriptMed Image Anal. Author manuscript; available in PMC 2011 December 1.   Jurrus et al.Page 20I-NHPAAuthorManuscriptFigure 4.Serial neural network diagram demonstrating the flow of information between ANNs. I is theoriginal image, C is the output (probability map) from the classifier before thresholding, S isthe stencil that samples the image data, and T is the final output from the classifier thresholdedto produce a binary segmentation.I-NHPAAuthorManuscriptI-NHPAAuthorManuscriptMed Image Anal. Author manuscript; available in PMC 2011 December 1.   Jurrus et al.Page 21Figure 5.An example of am image during training (top two rows) and testing (bottom two rows) at eachstage (1–5) of the network series. The output from each network is shown in rows 1 and 3.Rows 2 and 4 demonstrate the actual membrane detection when that output is thresholded. Thenetwork quickly learns which pixels belong to the membranes within the first 2–3 stages, andthen closes gaps in the last couple of stages.I-NHPAAuthorManuscriptI-NHPAAuthorManuscriptI-NHPAAuthorManuscriptMed Image Anal. Author manuscript; available in PMC 2011 December 1.   I-NHPAAuthorManuscriptI-NHPAAuthorManuscriptI-NHPAAuthorManuscriptJurrus et al.Page 22Figure 6.ROC curves for the (a) training data and (b) testing data for each stage of the network.Med Image Anal. Author manuscript; available in PMC 2011 December 1.   I-NHPAAuthorManuscriptI-NHPAAuthorManuscriptI-NHPAAuthorManuscriptJurrus et al.Page 23Figure 7.(a) Cross-sections of the nematode C. elegans acquired using EM. Three demonstratedmembrane detection techniques: (b) intensity thresholding after directional anisotropicsmoothing [19], (c) thresholded boundary confidences from a single ANN trained usingHessian eigenvalues [24], (d) membrane detection from serial ANNs, trained using membranefilter banks and auto-context, and (e) membrane detection from serial ANNs, trained usingimage data sampled from stencils and auto-context.Med Image Anal. Author manuscript; available in PMC 2011 December 1.   I-NHPAAuthorManuscriptI-NHPAAuthorManuscriptI-NHPAAuthorManuscriptJurrus et al.Page 24Figure 8.Examples demonstrating how the proposed method removes intracellular structures (left twocolumns) and closes gaps in a weak membrane (right two columns). The top row is the originalimage, columns (a) and (c) show the classifier output, and columns (b) and (d) show the finalthresholded segmentation.Med Image Anal. Author manuscript; available in PMC 2011 December 1.   I-NHPAAuthorManuscriptI-NHPAAuthorManuscriptI-NHPAAuthorManuscriptJurrus et al.Page 25Figure 9.ROC curves for (a) training and (b) testing on the C. elegans data. “Jurrus et al.”: thresholdingafter directional anisotropic smoothing [19]. “Hessian”: single layer neural network operatingon Hessian eigenvalues similar to Mishchenko [24]. The remaining three curves demonstratethe results from different inputs to the proposed auto-context ANN approach.Med Image Anal. Author manuscript; available in PMC 2011 December 1.   Jurrus et al.Page 26I-NHPAAuthorManuscriptI-NHPAAuthorManuscriptI-NHPAAuthorManuscriptMed Image Anal. Author manuscript; available in PMC 2011 December 1.   I-NHPAAuthorManuscriptI-NHPAAuthorManuscriptI-NHPAAuthorManuscriptJurrus et al.Page 27Figure 10.[color] Segmentation of neurons using a flood-fill on the image of detected membranes. (a)Ground truth and (b) membranes detected with proposed method.Med Image Anal. Author manuscript; available in PMC 2011 December 1.   I-NHPAAuthorManuscriptI-NHPAAuthorManuscriptI-NHPAAuthorManuscriptJurrus et al.Page 28Figure 11.[color] (a) 3-D renderings of the four neurons competing for information from the muscles.The location of the synapses, which were extracted from user specified locations, are shownin red on the neurons. (b) Similar rendering of the muscles that run alongside the motor neurons.Med Image Anal. Author manuscript; available in PMC 2011 December 1.   Jurrus et al.Page 29Figure 12.(a) TEM images from a rabbit retina. Membrane detection with: (b) thresholding on the gradientmagnitude, (c) serial ANNs using the output of an edge detection filter bank, and (d) serialANNs using image intensities sampled from a stencil.I-NHPAAuthorManuscriptI-NHPAAuthorManuscriptI-NHPAAuthorManuscriptMed Image Anal. Author manuscript; available in PMC 2011 December 1.   I-NHPAAuthorManuscriptI-NHPAAuthorManuscriptI-NHPAAuthorManuscriptJurrus et al.Page 30Figure 13.Examples of locations in the data where intracellular structures are removed (left two columns)and gaps in membranes are closed (right two columns). The top row shows the raw images,columns (a) and (c) show the classifier output, and columns (b) and (d) are the final thresholdedsegmentations.Med Image Anal. Author manuscript; available in PMC 2011 December 1.   I-NHPAAuthorManuscriptI-NHPAAuthorManuscriptI-NHPAAuthorManuscriptJurrus et al.Page 31Figure 14.ROC curves computed on the retina data for the (a) training data and (b) testing data. Forcomparison, an ROC curve is included that shows the best membrane detection when thegradient magnitude is thresholded.Med Image Anal. Author manuscript; available in PMC 2011 December 1.   