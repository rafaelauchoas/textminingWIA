Artificial Intelligence 172 (2008) 1873–1896Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOn the completeness of orientation rules for causal discoveryin the presence of latent confounders and selection biasJiji Zhang a,ba Division of the Humanities and Social Sciences, California Institute of Technology, USAb Department of Philosophy, Lingnan University, Hong Konga r t i c l ei n f oa b s t r a c tArticle history:Received 28 October 2007Received in revised form 30 June 2008Accepted 6 August 2008Available online 14 August 2008Keywords:Ancestral graphsAutomated causal discoveryBayesian networksCausal modelsMarkov equivalenceLatent variables1. IntroductionCausal discovery becomes especially challenging when the possibility of latent confoundingand/or selection bias is not assumed away. For this task, ancestral graph models areparticularly usefulin that they can represent the presence of latent confounding andselection effect, without explicitly invoking unobserved variables. Based on the machineryof ancestral graphs, there is a provably sound causal discovery algorithm, known asthe FCI algorithm, that allows the possibility of latent confounders and selection bias.However, the orientation rules used in the algorithm are not complete. In this paper, weprovide additional orientation rules, augmented by which the FCI algorithm is shown tobe complete, in the sense that it can, under standard assumptions, discover all aspectsof the causal structure that are uniquely determined by facts of probabilistic dependenceand independence. The result is useful for developing any causal discovery and reasoningsystem based on ancestral graph models.© 2008 Elsevier B.V. All rights reserved.Directed acyclic graphs (DAGs) are now widely used both as statistical models and as causal models. This double in-terpretation of DAGs, better known as (causal) Bayesian networks in the AI literature, is the springboard for much of theresearch on automated causal discovery and reasoning [12,20,25]. Given a set of variables V, if the causal structure of Vcan be properly represented by a DAG, one can try to learn the causal structure from data by exploiting the statisticalimplications DAGs have as statistical models. In general the causal structure is underdetermined, as multiple DAGs may beequally compatible with the correlational pattern suggested by data. But these DAGs usually share common features, whichconstitute the aspects of the causal structure that are not underdetermined and are in principle learnable from observationaldata. To develop algorithms for inferring these learnable causal features from correlational patterns is an important goal inthe project of automated causal discovery.Assuming no confounding or selection effect due to unobserved variables, there are causal discovery algorithms that areprovably sound and complete, under some plausible assumptions relating causal structure to probability distribution [7,17,25,32]. However, the assumption of no latent confounding or selection effect is seldom appropriate, and it is desirable andeven necessary in many situations to relax it. Unfortunately, the problem becomes much more difficult when we drop theassumption, due to the fact that the causal structure may not be properly representable by a DAG unless latent variables areexplicitly invoked. Not only are DAG models with latent variables hard to handle statistically [5,11], they make an infinitesearch space unless we seriously constrain the number of latent variables or the topology of the unknown causal network.E-mail address: jiji@hss.caltech.edu.0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.08.0011874J. Zhang / Artificial Intelligence 172 (2008) 1873–1896Fig. 1. A causal mechanism with latent and selection variables.One way around this is to represent such models without explicitly introducing latent variables, especially if we arenot interested in the latent variables per se. A class of graphical models developed for this purpose is known as ancestralgraph models [23]. As we will describe in more detail, a major virtue of ancestral graphs is that for any DAG with latentconfounding and selection variables, there is a unique maximal ancestral graph (MAG) over the observed variables alonethat represents the conditional independence relations and causal relations entailed by the original DAG. Instead of directlytargeting the causal DAG, which for all we know might involve any number of latent variables, a more tractable goal forcausal discovery is to learn as many features of the causal MAG as possible.There is a provably sound procedure for this purpose, known as the FCI algorithm [26].1 Whether it is complete—thatis, whether it can in principle discover all causal information that is not underdetermined—has been an open problem[18,25].2 In fact, as we will explain later, the algorithm is not complete as it stands. In this paper, we provide additionalorientation rules (i.e., rules for inferring edge marks), and show that the augmented FCI algorithm is complete. The resultamounts to a constructive characterization of common features shared by an equivalence class of MAGs, which should beuseful in any system of causal discovery and reasoning based on ancestral graph models. In this regard, our result generalizesMeek’s characterization of commonalities shared by Markov equivalent DAGs [17], and builds directly on some earlier resultsestablished in [2].Causal discovery aside, this paper should be of interest to anyone interested in ancestral graph models, which havedrawn attention from both statisticians and computer scientists [1,2,9,10,23,30,37]. We also suspect that the results of thispaper (and especially some lemmas in Appendix A) will be useful in providing a characterization of equivalence classes ofMAGs in the style of Andersson et al.’s characterization of equivalence classes of DAGs [4].The rest of the paper is organized as follows. Section 2 introduces the relevant background on ancestral graphs. InSection 3, we describe the FCI algorithm and report an important step made in [2] towards the completeness result. Wethen present additional orientation rules in Section 4, with which we show that the augmented FCI algorithm is complete.We conclude in Section 5. Most proofs are postponed to the appendices.2. Ancestral graphs and their interpretationsThe following example attributed to Chris Meek in [22] illustrates nicely the primary motivation behind ancestral graphs:The graph [Fig. 1] represents a randomized trial of an ineffective drug with unpleasant side-effects. Patients arerandomly assigned to the treatment or control group ( A). Those in the treatment group suffer unpleasant side-effects(Ef ), the severity of which is influenced by the patient’s general level of health (H ), with sicker patients sufferingworse side-effects. Those patients who suffer sufficiently severe side-effects are likely to drop out of the study. Theselection variable (Sel) records whether or not a patient remains in the study, thus for all those remaining in thestudy Sel = StayIn. Since unhealthy patients who are taking the drug are more likely to drop out, those patients in thetreatment group who remain in the study tend to be healthier than those in the control group. Finally health status(H ) influences how rapidly the patient recovers (R) [22, p. 234].This simple case shows how the presence of latent confounders and selection variables matters. The variables of primaryinterest, A and R, are observed to be correlated, even though the supposed causal mechanism entails independence betweenthem. This correlation is not due to sample variation, but rather corresponds to genuine probabilistic association induced bydesign—only the subjects that eventually stay in the study are considered. The observed correlation is in effect a correlationconditional on the selection variable Sel, a canonical example of selection effect. On the other hand, H is a familiar latentconfounder that contributes to “spurious correlation”.1 FCI stands for fast causal inference, which is probably an overly optimistic name.2 These authors raised the problem with regard to an older version of the algorithm designed based on a representation called inducing path graphs. Thereis a very close relationship between inducing path graphs and MAGs, which is explained in detail in the appendix of [34]. It suffices to note here that thecompleteness problem addressed in this paper is an even harder problem than the completeness problem formulated in terms of inducing path graphs.Also, the FCI algorithm is sometimes claimed to be complete [28], but only in a much weaker sense than what we consider in this paper.J. Zhang / Artificial Intelligence 172 (2008) 1873–18961875A main attraction of ancestral graphs is that, without explicitly including latent variables, they can represent conditionalindependence relations and causal relations among observed variables when the underlying data generating process involveslatent confounders and/or selection variables. This of course requires a richer syntax than that of DAGs.2.1. Ancestral graphsA mixed graph is a vertex-edge graph that can contain three kinds of edges: directed (→), bi-directed (↔) and undi-rected (—), and at most one edge between any two vertices. The two ends of an edge we call marks or orientations. Thetwo marks of a bi-directed edge are both arrowheads (>), the two marks of an undirected edge are both tails (−), and adirected edge has one of each. We say an edge is into (or out of) a vertex if the edge mark at the vertex is an arrowhead(or a tail).Two vertices are said to be adjacent in a mixed graph if there is an edge (of any kind) between them. Given a mixedgraph G and two adjacent vertices A, B therein, A is a parent of B and B is a child of A if A → B is in G; A is called aspouse of B (and B a spouse of A) if A ↔ B is in G; A is called a neighbor of B (and B a neighbor of A) if A—B is inG. A path in G is a sequence of distinct vertices (cid:4)V 0, . . . , V n(cid:5) such that for 0 (cid:2) i (cid:2) n − 1, V i and V i+1 are adjacent in G.A directed path from V 0 to V n in G is a sequence of distinct vertices (cid:4)V 0, . . . , V n(cid:5) such that for 0 (cid:2) i (cid:2) n − 1, V i is a parentof V i+1 in G. A is called an ancestor of B and B a descendant of A if A = B or there is a directed path from A to B. LetAnG (B) denote the set of ancestors of B in G. A directed cycle occurs in G when B → A is in G and A ∈ AnG (B). An almostdirected cycle occurs when B ↔ A is in G and A ∈ AnG (B).Definition 1. A mixed graph is ancestral if the following three conditions hold:(a1) there is no directed cycle;(a2) there is no almost directed cycle;(a3) for any undirected edge V 1—V 2, V 1 and V 2 have no parents or spouses.Obviously DAGs are special cases of ancestral graphs. The first condition in Definition 1 is just the familiar one forDAGs. Together with the second condition, they define a nice connotation of arrowheads in ancestral graphs: an arrowheadimplies non-ancestorship. The third condition requires that there be no edge into any vertex in the undirected component ofan ancestral graph. This property simplifies parameterization and fitting of ancestral graphs [9,23], but still allows selectioneffect to be properly represented.2.2. Probabilistic interpretation of ancestral graphsAs a statistical model, the vertices of an ancestral graph represent random variables, and the graph is interpreted asencoding a set of conditional independence3 relations by a graphical criterion, called m-separation, which generalizes thewell known d-separation criterion for DAGs [19]. Given a path p in a mixed graph, a non-endpoint vertex V on p is calleda collider if the two edges incident to V on p are both into V ; otherwise V is called a non-collider on p. In Fig. 2(a), forexample, B is a collider on the path (cid:4) A, B, D(cid:5), but is a non-collider on the path (cid:4)C, B, D(cid:5).Definition 2 (m-separation). In a mixed graph, a path p between vertices X and Y is active (m-connecting) relative to a(possibly empty) set of vertices Z ( X, Y /∈ Z) if(i) every non-collider on p is not a member of Z;(ii) every collider on p has a descendant in Z.X and Y are said to be m-separated by Z if there is no active path between any vertex in X and any vertex in Y relativeto Z.The probabilistic interpretation of ancestral graphs is given by its (global) Markov property: if X and Y are m-separatedby Z, then X and Y are probabilistically independent conditional on Z. This interpretation is obviously consistent with thatof DAGs, for m-separation reduces to d-separation in the case of DAGs.The following property is true of DAGs: if two vertices are not adjacent, then there is a subset of other vertices thatm-separates (d-separates) the two. This, however, is not always true of ancestral graphs. For example, the graph (a) in Fig. 2is an ancestral graph that fails this condition: C and D are not adjacent, but no subset of { A, B} m-separates them.This motivates the following definition:3 We refer to the standard notion of conditional independence in probability theory.1876J. Zhang / Artificial Intelligence 172 (2008) 1873–1896Fig. 2. (a) An ancestral graph that is not maximal; (b) a maximal ancestral graph.Definition 3 (maximality). An ancestral graph is said to be maximal if for any two non-adjacent vertices, there is a set ofvertices that m-separates them.DAGs are all maximal. In fact, maximality corresponds to the so-called pairwise Markov property: every missing edgecorresponds to a conditional independence relation, which is the basis for inferring the adjacency skeleton of the unknowncausal graph in many causal discovery procedures, including the FCI algorithm we will discuss later.Maximality is closely related to the notion of inducing path. The definition of the latter is quite convoluted, but the basicmotivation is the following question. Partition the set of vertices into V = O ∪ L ∪ S, and consider m-separation relationsof the form: X and Y are m-separated by Z ∪ S, for X, Y ∈ O and Z ⊆ O\{ X, Y }.4 When is it true that X and Y are notm-separated by Z ∪ S for any Z ⊆ O\{ X, Y }? The answer is given by the notion of inducing path.Definition 4 (inducing path). In an ancestral graph, let X, Y be any two vertices, and L, S be two disjoint sets of vertices notcontaining X, Y . A path p between X and Y is called an inducing path relative to (cid:4)L, S(cid:5) if every non-endpoint vertex on pis either in L or a collider, and every collider on p is an ancestor of either X , Y , or a member of S.When L = S = Ø, p is called a primitive inducing path between X and Y .An important fact established by Richardson and Spirtes [23, Theorem 4.2] is that X and Y are not m-separated by Z ∪ Sfor any Z ⊆ V\(L ∪ S ∪ { X, Y }) if and only if there is an inducing path between X and Y relative to (cid:4)L, S(cid:5). For example, inFig. 1 the path (cid:4) A, E f , H, R(cid:5) is an inducing path relative to (cid:4){H}, {Sel}(cid:5), and A is not m-separated from R by either {Ef , Sel}or {Sel}. This fact plays an important role below in constructing a MAG that represents a given DAG.As a special case of this fact, the presence of a primitive inducing path is sufficient and necessary for two vertices not tobe m-separated by any set of other variables in an ancestral graph, which is obviously connected to maximality.Proposition 1. An ancestral graph is maximal if and only if there is no primitive inducing path between any two non-adjacent verticesin the graph.For example, in Fig. 2(a), the path (cid:4)C, A, B, D(cid:5) is a primitive inducing path between C and D, so the graph is notmaximal. It is shown in [23, Theorem 5.1] that every non-maximal ancestral graph has a unique supergraph that is ancestraland maximal, and every non-maximal ancestral graph can be transformed into the maximal supergraph by a series ofadditions of bi-directed edges. For example, in Fig. 2, (b) is the unique maximal supergraph of (a), which has an extrabi-directed edge between C and D. From now on, we focus on maximal ancestral graphs (MAGs).2.3. Causal interpretation of maximal ancestral graphsThe simple motivating example in Fig. 1 suggests that the correlational structure of a set of observed variables can bemisleading about causal structure for at least two reasons. First, there may be unobserved common causes or confoundersthat contribute to the observed association. Second, the samples are representative of but a subpopulation of the populationof interest. The subpopulation, in particular, is characterized by a set of unobserved selection or conditioning variables suchthat units in the subpopulation share values of the selection variables. Hence any observed association or independence isde facto conditional on the selection variables.One can formally represent such a situation by a causal DAG over the union of three disjoint sets of variables, V =O ∪ L ∪ S, where O denotes a set of observed variables, L denotes a set of latent or unobserved variables, and S denotes aset of unobserved selection variables to be conditioned upon. The DAG entails a set of conditional independence constraintsamong V. Among these constraints, what are in principle observable or testable are ones of the form A⊥⊥B|C ∪ S,5 whereA, B, C ⊆ O are disjoint sets of observed variables.4 These m-separation relations are particularly interesting because L is intended to be a set of latent variables which are marginalized in the observabledistribution, and S is intended to be a set of selection variables upon which the observable distribution conditions.5 ⊥⊥ is a symbol that denotes probabilistic independence introduced by Dawid [8]. The vertical bar | denotes conditioning. Strictly speaking, we areconditioning on a specific value or vector of values of S, so it is more accurate to write A⊥⊥B|C ∪ S = s.J. Zhang / Artificial Intelligence 172 (2008) 1873–18961877A distinctive virtue of MAGs is that they can represent such in-principle-testable constraints without explicitly introduc-ing L and S. Given any DAG G over V = O ∪ L ∪ S, there exists a MAG over O alone such that for any three disjoint sets ofvariables A, B, C ⊆ O, A and B are entailed to be independent conditional on C ∪ S by G if and only if A and B are entailedto be independent conditional on C by the MAG. When this is the case, we say the MAG probabilistically represents the DAG.The following construction gives us such a MAG:Input: a DAG G over V = O ∪ L ∪ SOutput: a MAG MG over O(1) for each pair of variables A, B ∈ O, A and B are adjacent in MG if and only if there is an inducing path relative to(cid:4)L, S(cid:5) between them in G;(2) for each pair of adjacent vertices A, B in MG , orient the edge between them as follows:(a) orient it as A → B in MG if A ∈ AnG (B ∪ S) and B /∈ AnG ( A ∪ S);(b) orient it as A ← B in MG if B ∈ AnG ( A ∪ S) and A /∈ AnG (B ∪ S);(c) orient it as A ↔ B in MG if A /∈ AnG (B ∪ S) and B /∈ AnG ( A ∪ S);(d) orient it as A—B in MG if A ∈ AnG (B ∪ S) and B ∈ AnG ( A ∪ S).It can be shown that MG is indeed a MAG and probabilistically represents G—it follows from Theorem 4.18 of [23]. More-over, it is easy to see that MG also causally represents G in that it retains ancestral relationships in G. So, if G representsthe causal structure for V, it is fair to call MG the causal MAG for O, in which edges encode causal information about thepresence or absence of causal pathway in the underlying structure. Specifically,• A → B means that A is a cause of B or of some selection variable, but B is not a cause of A or of any selectionvariable;6• A ↔ B means that A is not a cause of B or of any selection variable, and B is not a cause of A or of any selectionvariable;7• A—B means that A is a cause of B or of some selection variable, and B is a cause of A or of some selection variable.8Put more simply, the edge marks in a causal MAG represent qualitative causal information: arrowheads represent nega-tive causal information about “non-cause”, and tails represent positive causal information about “cause”. The positive causalinformation is admittedly less informative than one would wish, when the possibility of selection bias is allowed. This re-flects the fact that the presence of selection bias seriously limits the possibility of inferring useful causal information fromobservations. If the only worry is confounding but not selection bias, A → B can be read unambiguously as “ A is a causeof B”. Of course even the disjunctive information may be combined with other information to deduce more useful facts.9Detailed exploration of how to use the causal information carried by ancestral graphs in causal reasoning is beyond thescope of this paper.10 Our present concern is to what extent can such information be discovered from the correlationalpattern. It is limited by Markov equivalence.2.4. Markov equivalenceTwo different MAGs carry different causal information, but may share the exact same m-separation structure, and henceentail the same set of conditional independence constraints. Such MAGs are not distinguishable by correlational patternalone.Definition 5 (Markov equivalence). Two MAGs G1, G2 (with the same set of vertices) are Markov equivalent if for any threedisjoint sets of vertices X, Y, Z, X and Y are m-separated by Z in G1 if and only if X and Y are m-separated by Z in G2.Several characterizations of the Markov equivalence between MAGs are available [1,27,35,37]. We will rely on the char-acterization of [27] in this paper.Definition 6 (unshielded path). In a MAG, a path consisting of a triple of vertices (cid:4) X, Y , Z (cid:5) is said to be unshielded if X andZ are not adjacent. The triple is called an unshielded collider if both the edge between X and Y and the edge between Yand Z are into Y .6 By saying A is (or is not) a cause of B, all we mean is that there is (or is not) a directed path from A to B in the underlying causal structure.7 This, together with the adjacency of A and B in the MAG, implies that there is a latent common cause of A and B.8 Due to the assumed acyclicity of causal structure, this is equivalent to saying that A is a cause of some selection variable, and B is a cause of someselection variable.9 For example, if there is A → B in a MAG, and also another edge into A, then it can be deduced that A is not a cause of any selection variable, but acause of B.10 Some relevant results can be found in [24] and [34].1878J. Zhang / Artificial Intelligence 172 (2008) 1873–1896Fig. 3. A discriminating path between X and Y for V .It is well known that two DAGs are Markov equivalent if and only if they have the same adjacencies and the sameunshielded colliders [32]. These conditions are still necessary for Markov equivalence between MAGs, but are not sufficient.For two MAGs to be Markov equivalent, some shielded colliders may have to be present in both or neither of the graphs.The next definition is related to this.Definition 7 (discriminating path). In a MAG, a path between X and Y , p = (cid:4) X, . . . , W , V , Y (cid:5), is a discriminating pathfor V if(i) p includes at least three edges;(ii) V is a non-endpoint vertex on p, and is adjacent to Y on p; and(iii) X is not adjacent to Y , and every vertex between X and V is a collider on p and is a parent of Y .A canonical depiction of an discriminating path is given in Fig. 3. Note that we write a discriminating path in such aform p = (cid:4) X, . . . , W , V , Y (cid:5); that is, we specify the endpoints and the vertices adjacent to V , the vertex being discriminated.The ellipsis therein designates any number (possibly zero) of other vertices.The following proposition is proved by Spirtes and Richardson [27].Proposition 2. Two MAGs over the same set of vertices are Markov equivalent if and only if(e1) They have the same adjacencies;(e2) They have the same unshielded colliders;(e3) If a path p is a discriminating path for a vertex V in both graphs, then V is a collider on the path in one graph if and only if it is acollider on the path in the other.Given an MAG G, we denote its Markov equivalence class, the set of MAGs Markov equivalent to G, by [G]. According toProposition 2, all members of [G] have the same adjacencies. But between two adjacent vertices, the edge, and hence oneor both of the marks on the edge, may be different in different members of [G]. We call a mark in G invariant if the markis the same in all members of [G]. It is the adjacencies and the invariant marks of the unknown causal MAG that we canhope to discover from the correlational pattern.3. The FCI algorithm and arrowhead completenessThe MAG representation gives us a relatively tractable problem of causal discovery in the presence of latent confoundersand selection variables: to infer features of the causal MAG from data. In the case of learning causal DAGs (assuming nolatent confounders and selection variables), two assumptions are commonly adopted, known as the Causal Markov Conditionand the Causal Faithfulness Condition. These two conditions amount to assuming that conditional independence relationsthat hold in the population distribution are precisely the conditional independence relations entailed by the causal DAG byd-separation.11 If we assume these two conditions for the underlying causal DAG with latent variables, it follows that thereis an exact correspondence between the observable conditional independence relations among the observed variables andm-separation relations in the causal MAG, because the causal MAG probabilistically represents the causal DAG.Under these two assumptions, therefore, one can learn what the m-separation relations are in the causal MAG from thecorrelational pattern—facts of conditional independence and dependence. The correlational pattern, in turn, is built basedon statistical tests of conditional independence. The constraint-based approach to causal discovery seeks to employ theseconditional independence or m-separation constraints to recover features of the causal MAG.In this paper we will sidestep the statistical problem of inferring genuine conditional independence from data, and focuson the problem of inferring causal information from facts of conditional independence. As an idealization, we will supposethat a perfect oracle for conditional independence is available, which of course can only be approximated in practice.1211 For detailed exposition and discussion of the two conditions, see [20] and [25]. The causal Markov condition generalizes the familiar principle of thecommon cause, and as such has been a subject of philosophical debate [3,6,13,15]. Recent reflections on the causal Faithfulness condition include [29] and[36]. In this paper, we assume the two conditions and explore the consequence.12 There are of course important practical issues that require further investigations, such as developing more powerful and robust statistical tests ofconditional independence, quantifying uncertainty, and handling inconsistency arising from an imperfect oracle.J. Zhang / Artificial Intelligence 172 (2008) 1873–18961879For any query about conditional independence among the given observed variables, the oracle supplies a correct answerregarding whether the conditional independence in question holds or not. Moreover, given the causal Markov and Faithful-ness assumptions mentioned above, the unknown true causal MAG should be perfectly consistent with the oracle, in thesense that the true conditional independence relations as judged by the oracle are precisely the conditional independencerelations entailed by the MAG.Such an oracle would supply information about the m-separation relations in the true causal MAG, which we denote byGT . In general, however, the m-separation relations do not uniquely determine a MAG, but a Markov equivalence class ofMAGs, which we denote by [GT ]. So the causal information that is in principle identifiable given the oracle corresponds tothe invariant features of the true causal MAG, i.e., features shared by all MAGs in [GT ]. The question is how to recover thesefeatures from the oracle.A provably sound algorithm for this task is known as the FCI algorithm, whose latest version was presented in [26].13The algorithm consists mainly of two stages. In the first stage, the algorithm determines the adjacencies in the causal MAG.The inference of adjacencies is based on the fact that two variables are adjacent in a MAG if and only if they are notm-separated by any set of other variables in the MAG. So the basic idea is to search, for every pair of variables, a set ofother variables that renders them conditionally independent. They are not adjacent if and only if such a set is found. TheFCI algorithm uses several tricks to make this search efficient, the details of which shall not concern us here. Suffice it toknow that it is proved in [26] that given a reliable oracle of conditional independence, the FCI algorithm finds the correctadjacencies.14Our concern is with the second stage, the stage of inferring edge marks. In this stage, the algorithm executes a set oforientation rules (i.e., mark inference rules) to introduce arrowheads or tails, with circles (◦) representing undeterminededge marks. The output of the algorithm is referred to as a partial ancestral graph, or a PAG for short.15 It is intended to bea representation of the Markov equivalence class determined by the oracle of conditional independence.Definition 8 (partial ancestral graph). Let [G] be the Markov equivalence class of a MAG G. A partial ancestral graph (PAG)for [G] is a graph P with possibly three kinds of marks (and hence six kinds of edges: —, →, ↔, ◦−−, ◦−−◦, ◦→), suchthat (1) P has the same adjacencies as G (and any member of [G]) does; and (2) every non-circle mark in P is an invariantmark in [G].If it is furthermore true that (3) every circle in P corresponds to a variant mark in [G], P is called the maximallyinformative PAG for [G].It is known that the FCI algorithm is sound, which means that given a perfect oracle of conditional independence, thealgorithm outputs a PAG for [GT ], the Markov equivalence class of the true causal MAG. Whether it is also complete is amatter of whether the output is the maximally informative PAG for [GT ].We now describe (an equivalent version of) the FCI algorithm from [26], omitting the details of the adjacency stage. (Instating the orientation rules, a meta-symbol, asterisk (∗), is used as a wildcard that denotes any of the three marks.16 Morespecifically, if “∗” appears in the antecedent of a rule, that means it does not matter whether the mark at that place is anarrowhead, a tail, or a circle. If “∗” appears in the consequent of a rule, that means the mark at that place remains what itwas before the firing of the rule. Greek letters are used to denote generic variables/vertices.)FCI algorithmF1 Form a complete graph U on the set of variables, in which there is an edge ◦−−◦ between every pair of variables;F2 For every pair of variables α and β, search in some clever way for a set of other variables that render the two indepen-dent. If such as set S is found, remove the edge between α and β in U , and record S as Sepset(α, β);F3 Let P be the graph resulting from step F2. Execute the orientation rule:R0 For each unshielded triple (cid:4)α, γ , β(cid:5) in P , orient it as a collider α∗→ γ ←∗β if and only if γ is not in Sepset(α, β).F4 Execute the following mark inference rules until none of them applies:R1 If α∗→ β◦−−∗ γ , and α and γ are not adjacent, then orient the triple as α∗→ β → γ .R2 If α → β∗→ γ or α∗→ β → γ , and α ∗−◦ γ , then orient α ∗−◦ γ as α∗→ γ .R3 If α∗→ β ←∗γ , α ∗−◦ θ ◦−∗ γ , α and γ are not adjacent, and θ ∗−◦ β, then orient θ ∗−◦ β as θ∗→ β.13 The algorithm was initially designed based on what is called inducing path graphs [25], and was then reinterpreted in terms of (partial) ancestralgraphs. Not only are ancestral graph models more amenable to statistical analysis than inducing path graphs, causal discovery based on the former can inprinciple reveal more causal information than causal discovery based on the latter, for reasons elaborated in [33, Appendix].14 There is an ambiguity in the original formulation of the algorithm in [25], which, if not interpreted in the right way, suggests a flaw in the algorithm[16]. But when interpreted as intended, the algorithm is provably correct.15 PAGs were first invented by Richardson [21] in the context of learning causal models with feedback. They were then reinterpreted to represent theoutput from the FCI procedure, and to represent a Markov equivalence class of MAGs.16 By this we mean the rule in question applies no matter which of the three marks actually appears in the position of ∗. It does not imply that all threemarks can appear in that position.1880J. Zhang / Artificial Intelligence 172 (2008) 1873–1896R4 If u = (cid:4)θ, . . . , α, β, γ (cid:5) is a discriminating path between θ and γ for β, and β◦−−∗ γ ; then if β ∈ Sepset(θ, γ ), orientβ◦−−∗ γ as β → γ ; otherwise orient the triple (cid:4)α, β, γ (cid:5) as α ↔ β ↔ γ .17R0–R3 are essentially (with slight generalization) the inference rules used in the context of learning causal DAGs, and areshown to be sound and complete for that purpose [17]. R4 is peculiar to MAGs with bi-directed edges. It is motivatedby condition (e3) for Markov equivalence in Proposition 2 (Section 2.4), and justified by the fact that discriminating pathsbehave similarly to unshielded triples in the following way: if a path between X and Y is discriminating for V , then V is acollider on the path if and only if every set that m-separates X and Y does not contain V ; and V is a non-collider on thepath if and only if every set that m-separates X and Y contains V . For a proof of this fact and the soundness of R0–R4(and of the FCI algorithm), see [26].To establish completeness, we need to show that the PAG returned by FCI is also maximally informative; that is, everycircle in the PAG corresponds to a variant mark in [GT ]. In other words, we need to show that for every circle in the PAG,there is a MAG perfectly consistent with the oracle of conditional independence and hence Markov equivalent to GT , inwhich the circle is oriented as a tail; and there is such a MAG in which the circle is oriented as an arrowhead.This turns out to be a highly non-trivial problem. An important step was made by Ali et al. [2]. Their result amountedto showing that R0–R4 are complete with respect to invariant arrowheads.18 In other words, for every circle in the PAGoutput by FCI, there is a MAG Markov equivalent to GT in which the circle is marked as a tail.The present paper aims to establish the full completeness result. The FCI algorithm, as it stands, is not yet complete.There could be invariant tails that fail to be picked up by R0–R4, as we will illustrate by a simple example shortly. Inthe next section we provide extra tail inference rules that we show are able to pick up all (remaining) invariant tails. Thedemonstration, unfortunately, is even more difficult than that of arrowhead-completeness.4. Extra orientation rules and tail completenessTo introduce the extra tail inference rules, we need to note a couple of special paths. In the definitions below, we call agraph that can contain three kinds of edge marks—arrowhead, tail and circle—a partial mixed graph (PMG).Definition 9 (uncovered path). In a PMG, a path p = (cid:4)V 0, . . . , V n(cid:5) is said to be uncovered if for every 1 (cid:2) i (cid:2) n − 1, V i−1 andV i+1 are not adjacent, i.e., if every consecutive triple on the path is unshielded.A distinctive property of uncovered path is of course that after R0 is executed, every consecutive triple on the path hasa definite status either as a collider or as a non-collider.Definition 10 (potentially directed path). In a PMG, a path p = (cid:4)V 0, . . . , V n(cid:5) is said to be potentially directed (abbreviated asp.d.) from V 0 to V n if for every 0 (cid:2) i (cid:2) n − 1, the edge between V i and V i+1 is not into V i or out of V i+1.Intuitively, a p.d. path is one that could be oriented into a directed path by changing the circles on the path intoappropriate tails or arrowheads. As we shall see, uncovered p.d. paths play an important role in locating invariant tails.A special case of a p.d. path is where every edge on the path is of the form ◦−−◦; we call such a path a circle path.Here is the first block of additional rules:R5 For every (remaining) α◦−−◦β, if there is an uncovered circle path p = (cid:4)α, γ , . . . , θ, β(cid:5) between α and β s.t. α, θ arenot adjacent and β, γ are not adjacent, then orient α◦−−◦β and every edge on p as undirected edges (—).R6 If α—β◦−−∗ γ (α and γ may or may not be adjacent), then orient β◦−−∗ γ as β −−∗ γ .R7 If α −−◦ β◦−−∗ γ , and α, γ are not adjacent, then orient β◦−−∗ γ as β −−∗ γ .A pictorial illustration of R5–R7 is given in Fig. 4. These rules are obviously related to undirected edges. R5 lead toundirected edges, and R6 depend on undirected edges. So if it is known that the true casual MAG does not containundirected edges—for example, in those cases where selection bias is known to be absent—these two are not needed.In that case, moreover, R7 will not get triggered at all, because neither R0–R4 introduced earlier nor R8–R10 to beintroduced shortly can lead to −−◦ edges, which are in the antecedent of R7.17 See [2] for an alternative and perhaps more efficient formulation of this rule that takes on a special kind of discriminating paths.18 Ali et al. [2] employed a slightly different graphical object, called Joined Graphs, to represent Markov equivalence classes of MAGs. The differencebetween Joined Graphs and PAGs is just that the former only represent invariant arrowheads, and do not distinguish between tails and circles. This makesJoined Graphs syntactically simpler, at the price of losing information about invariant tails. Our result in this paper can also be seen as an attempt todistinguish between real tails and pseudo tails in joined graphs.J. Zhang / Artificial Intelligence 172 (2008) 1873–18961881Fig. 4. Graphical illustrations of R5–R7.That is why we introduce these three rules as a block. If there is no issue of selection bias, we would only considerMAGs with directed and bi-directed edges, in which case R5–R7 can be ignored in principle.19 The next block of rules, bycontrast, may still be applicable.R8 If α → β → γ or α−−◦β → γ , and α◦→γ , orient α◦→γ as α → γ .R9 If α◦→γ , and p = (cid:4)α, β, θ, . . . , γ (cid:5) is an uncovered p.d. path from α to γ such that γ and β are not adjacent, thenorient α◦→ γ as α → γ .R10 Suppose α◦→γ , β → γ ← θ , p1 is an uncovered p.d. path from α to β, and p2 is an uncovered p.d. path from α toθ . Let μ be the vertex adjacent to α on p1 (μ could be β), and ω be the vertex adjacent to α on p2 (ω could be θ ).If μ and ω are distinct, and are not adjacent, then orient α◦→γ as α → γ .These rules are visualized in Fig. 5. All of them are about turning partially directed edges ◦→ into directed ones →, whichare valuable because ↔ and → represent very different causal information.Call the FCI algorithm supplemented with these rules the Augmented FCI (AFCI) algorithm.20 We first show that theserules are sound.Theorem 1. Let PFCI be the output of the FCI algorithm, and PAFCI the graph resulting from applying R5–R10 to PFCI until none ofthem applies. The extra tails introduced in PAFCI are invariant.Proof. For each rule, we just need to show that any mixed graph that violates the rule does not belong to [GT ], i.e., is eithernot a MAG or not Markov equivalent to GT . The theorem then follows by a simple induction.R5: The antecedent of this rule implies that (cid:4)α, γ , . . . , θ, β, α(cid:5) forms an uncovered cycle that consists of ◦−−◦ edges.Suppose a mixed graph, contrary to what the rule requires, has an arrowhead on this cycle. In light of R1, the cycle mustbe oriented as a directed cycle to avoid unshielded colliders not in GT . But then the graph is not ancestral.R6: if any graph, contrary to what the rule requires, contains α—β←∗γ , the graph is not ancestral.R7: Suppose a mixed graph, contrary to what the rule requires, has an arrowhead at β on the edge between β and γ .Then either α—β←∗γ is present, in which case the graph is not ancestral; or α → β←∗γ is present, in which case thegraph contains an unshielded collider not in GT .R8: This rule is analogous to R2. Obviously if a mixed graph, contrary to what the rule requires, contains α ↔ γ , theneither an almost directed cycle is present or there is an arrowhead into an undirected edge, and hence the graph is notancestral.19 We add “in principle” here to caution that this is only true with a prefect conditional independence oracle. In practice, there may be occasions whereR5 and R7 are applicable even though in theory they should never be invoked.20 We will not worry about implementation here. Note that the antecedent of each rule that involves checking the presence of a certain kind of paths,like that of R4, can be checked in O (mn) with a generic algorithm for checking ‘reachability’, with m being the number of edges and n being the numberof vertices in the graph. So in big O notation, the time complexity of the AFCI algorithm is the same as that of the FCI algorithm [26].1882J. Zhang / Artificial Intelligence 172 (2008) 1873–1896Fig. 5. Graphical illustrations of R8–R10.Fig. 6. An example where R9 is needed. (a) is the (unknown) causal MAG. (b) gives the FCI output, to which R9 can be applied (twice) to yield (c).R9: The essentially same argument for the soundness of R5 applies here.R10: The antecedent of the rule implies that the triple (cid:4)μ, α, ω(cid:5) is not a collider in GT , which means at least one ofthe two edges involved in the triple is out of α in any MAG in [GT ]. Suppose a graph in [GT ], contrary to what the rulerequires, contains α ↔ γ . Then the edge(s) out of α must be a directed edge for the graph to be ancestral. It follows thateither p1 or p2 is a directed path in the graph to avoid unshielded colliders not in GT . In either case, α is an ancestor of γ ,and hence the graph is not ancestral; a contradiction. (cid:2)Here is a simple example in which R9 is needed. Suppose the true causal MAG is the one in Fig. 6(a). Given an oracleconsistent with this MAG, the FCI algorithm (with R0–R4) gives us the graph in 6(b), to which we can further apply R9to get more tails, as shown in 6(c) (B → D and C → D). Given the soundness of R9, we know the additional tails areinvariant. So the FCI algorithm with just R0–R4 is not yet complete. In fact, it is not hard to construct cases to show thatall the orientation rules given above except possibly R8 are independent. We do not yet know if R8 is independent—wecan neither construct a case in which only R8 is applicable, nor derive R8 from other rules—but the current proof ofcompleteness uses R8.The main result to be established is that R5–R10 are also sufficient for picking up all remaining invariant tails. Let PAFCIdenote the output of the AFCI algorithm. We need to demonstrate that for every circle in PAFCI, there is a MAG in [GT ] inwhich the corresponding mark is an arrowhead. As we shall see, the main difficulty of proving this fact lies with circles onthe ◦→ edges. For circles on the other two kinds of edges, ◦−− and ◦−−◦, the argument is quite analogous to the argumentfor arrowhead completeness given in [2] or [33]. We will deal with these two first in Section 4.1, and then take up the moredifficult task in Section 4.2 to show that no circle on ◦→ edges in PAFCI hides an invariant tail.4.1. Circles on ◦−− and ◦−−◦ edgesSince PAFCI is sound, any MAG in [GT ] is a further orientation of PAFCI; that is, all the unambiguous edge marks (arrow-heads and tails) already in PAFCI will be retained in the MAG, and the circles in PAFCI are turned into appropriate arrowheadsJ. Zhang / Artificial Intelligence 172 (2008) 1873–18961883or tails in the MAG. Let us call the subgraph of PAFCI consisting of all the ◦−−◦ edges in PAFCI the circle component of PAFCI,and denote it by P CAFCI. The first thing to note is that P CAFCI has the following property:AFCI, P CLemma 4.1. For every edge A◦−−◦B in P Cand can also be oriented into a DAG with no unshielded colliders in which A ← B appears.AFCI can be oriented into a DAG with no unshielded colliders in which A → B appears,The proof is given in Appendix A, which makes use of Lemma 5 in Meek (1995). This fact is relevant because of thefollowing theorem:Theorem 2. Let H be the graph resulting from the following procedure applied to PAFCI:(1) orient the circles on ◦→ edges in PAFCI as tails, and orient the circles on −−◦ edges in PAFCI as arrowheads (that is, turn all ◦→edges and all −−◦ edges into directed edges →); andAFCI into a DAG with no unshielded colliders.(2) orient P CThen H is a member of [GT ].The proof of this theorem is given in Appendix A. The theorem has a couple of important implications. First, it suggests away to turn PAFCI, a representation of a Markov equivalence class of MAGs, into a representative MAG. What is special aboutthis construction is that no extra undirected edges or bi-directed edges are introduced. So the outcome is a representativemember of the Markov equivalence class with the fewest undirected edges and bi-directed edges. Such a representative isconceivably easier to fit and score than other members in the class, in light of the fact that UGs are in general harder tofit than DAGs and the results presented in [10] suggesting that it is better to have fewer bi-directed edges in fitting a MAGmodel. If so, it will be particularly useful for developing score-based causal discovery algorithm based on MAGs.More importantly for our present purpose, Theorem 2 together with Lemma 4.1 entail that for every circle on a −−◦edge or a ◦−−◦ edge in PAFCI, there is a member in [GT ] in which the corresponding mark is an arrowhead. In other words,no circle on −−◦ or ◦−−◦ edges in PAFCI corresponds to an invariant tail. Therefore, what is left to show in order to establishcompleteness is just that circles on ◦→ edges in PAFCI do not hide invariant tails.4.2. Circles on ◦→ edgesLetThis last task, however, turns out to be the most difficult to fulfill. Unlike circles on the −−◦ edges of PAFCI, which can besimultaneously turned into arrowheads as we saw in Theorem 2, circles on the ◦→ edges in general cannot be turned intoarrowheads simultaneously in order to make a MAG in [GT ]. The simplest example is X←◦Y ◦→Z , an unshielded path thatcan appear in PAFCI. If we turn both of the circles into arrowheads, a new unshielded collider is created, and the resultinggraph will not belong to [GT ]. By contrast, an unshielded triple such as X−−◦Y ◦−− Z will not appear in PAFCI in light of R7.So we cannot handle ◦→ edges in a wholesale manner.J ◦→K denote an arbitrary ◦→ edge in PAFCI. We need to show that there is a MAG in [GT ] in which the edgeappears as J ↔ K . Our argument consists of two major steps. In the first step, we show that we can orient P CAFCI—thecircle component of PAFCI—into a DAG with no unshielded colliders that satisfies certain conditions relative to J ◦→K . This DAGorientation of P CAFCI together with operation (1) in Theorem 2 yield a MAG in [GT ].This MAG is not yet what we want, because J ◦→K is oriented as J → K rather than J ↔ K by operation (1) in Theo-rem 2. In the second step of our argument, we make use of a result on equivalence-preserving mark changes given in [30]and [35], and prove that the MAG constructed in the first step can be transformed into a MAG containing J ↔ K througha sequence of equivalence-preserving changes of → into ↔. It then follows that the resulting MAG with J ↔ K is alsoMarkov equivalent to GT , which is what we need.The following definitions specify the conditions we want a DAG orientation of P CAFCI to satisfy.Definition 11 (Relevance). Let J ◦→K be an arbitrary ◦→ edge in PAFCI. For any A◦→B in PAFCI, it is said to be relevant toJ ◦→K if(i) A = J or there is a p.d. path from J to A in PAFCI such that no vertex on the path (including the endpoints) is a parentof K ; and(ii) B = K or B is a parent of K (namely B → K ) in PAFCI.If A◦→B is relevant to J ◦→K , we say that A is circle-relevant to J ◦→K , and B is arrowhead-relevant to J ◦→K .Intuitively, relevant edges are those that may have to be turned into bi-directed edges (↔) in order for J ◦→K to beJ ◦→B is oriented asso oriented, on pain of creating almost directed cycles. This is most obvious in Fig. 7(a), in which ifJ → B, then J ◦→K cannot be oriented as J ↔ K , lest an almost directed cycle be created.1884J. Zhang / Artificial Intelligence 172 (2008) 1873–1896Fig. 7. Configurations of relevance. (a) J ◦→B is relevant to J ◦→K , because B is a parent of K ; (b) A◦→K is relevant to J ◦→K , because there is a p.d. pathfrom J to A (with no parent of K on the path); (c) A◦→B is relevant to J ◦→K , because there is a p.d. path from J to A (with no parent of K on the path)and B is a parent of K .Let REL( J ◦→K ) denote the set of ◦→ edges relevant to J ◦→K in PAFCI. Notice that J ◦→K itself belongs to this set,and we will eventually show that all edges in REL( J ◦→K ), and so J ◦→K in particular, can be turned into bi-directededges simultaneously. For easy reference, let us denote the set of circle-relevant vertices by CR( J ◦→K ), and the set ofarrow-relevant vertices by AR( J ◦→K ).Definition 12 (Agreeable orientation). A DAG orientation of P CJ ◦→K if the following three conditions hold:AFCI—the circle component of PAFCI—is said to be agreeable toC1 For every A◦→B◦−−◦C in PAFCI such that A◦→B ∈ REL( J ◦→K ) and C /∈ AR( J ◦→K ), B◦−−◦C is oriented as B → C in theC2 For every C◦−−◦ A◦→B in PAFCI such that A◦→B ∈ REL( J ◦→K ) and C is a parent of B (namely C → B) in PAFCI, C◦−−◦ AC3 For every C◦−−◦ A◦→B in PAFCI such that A◦→B ∈ REL( J ◦→K ) and C is not adjacent to B in PAFCI, C◦−−◦ A is orientedDAG;is oriented as C → A in the DAG;as C ← A in the DAG.Roughly speaking, C1–C3 are motivated as necessary conditions for orienting a ◦→ edge (relevant to J ◦→K ) into a bi-directed edge. This is especially clear for C2 and C3. Regarding a relevant edge A◦→B, if C2 is violated, then A◦→B cannotbe turned into a bi-directed edge, on pain of creating an almost directed cycle; similarly if C3 is violated, on pain of creatinga new unshielded collider. The rationale behind C1 is less obvious, but is basically along the same line, and will be revealedin the proof of Theorem 3.The first question is whether we can orient P CAs the proof for Lemma 4.1 goes (in Appendix A), the reason why P Ccolliders is because P Ccolliders is due to Meek [17]:AFCI into a DAG with no unshielded colliders that is also agreeable to J ◦→K .AFCI can be oriented into a DAG with no unshieldedAFCI is chordal (a.k.a triangulated). One way to orient a chordal graph into a DAG free of unshieldedMeek’s AlgorithmInput: a chordal unoriented graph UOutput: a DAG orientation of U (with no unshielded colliders)Repeat(1) choose a yet unoriented edge A◦−−◦B in U ;(2) orient the edge into A → B (or A ← B), and close orientations under the following rules:21UR1 If A → B◦−−◦C , A and C are not adjacent, orient as B → C .UR2 If A → B → C and A◦−−◦C , orient as A → C .UR3 If A → B → C , A◦−−◦D◦−−◦C , B◦−−◦D, and A and C are not adjacent, orient D◦−−◦C as D → C .Until every edge is oriented in H.So the idea is very simple. In each round, choose an arbitrary unoriented edge to orient in any direction, and propagatethe orientation using the three rules. Then repeat this until every edge is oriented. We now adapt the algorithm to fit ourpurpose. Given an edge J ◦→K in PAFCI, let Ei (i = 1, 2, 3) be the set of ◦−−◦ edges in PAFCI whose orientations are requiredby condition Ci in Definition 12. (Note that Ei ’s are not necessarily disjoint.)21 There is another rule in [17]. However, the antecedent of that rule involves an unshielded collider, which will not be triggered in orienting a chordalgraph into a DAG with no unshielded colliders. So we need not include that one here.J. Zhang / Artificial Intelligence 172 (2008) 1873–18961885Orientation algorithm for the circle component of PAFCIInput: P CAFCI, PAFCI, and an edge J ◦→K thereinOutput: a DAG orientation of P CAFCI with no unshielded collidersLet D = P CRepeatAFCIIf some edge in E1 is not yet oriented in D(a) choose such an edge A◦−−◦B ∈ E1, and orient it as condition C1 requires;(b) close orientations under UR1, UR2, UR3.Else If some edge in E2 is not yet oriented in D;(a) choose such an edge A◦−−◦B ∈ E2, and orient it as condition C2 requires;(b) close orientations under UR1, UR2, UR3.Else If some edge in E3 is not yet oriented in D;(a) choose such an edge A◦−−◦B ∈ E3, and orient it as condition C3 requires;(b) close orientations under UR1, UR2, UR3.Else(a) choose a yet unoriented edge A◦−−◦B in D;(b) orient the edge into A → B and close orientations under UR1, UR2, UR3.Until every edge is oriented in DReturn DThis is just a more restricted version of Meek’s algorithm. Therefore, given the correctness of Meek’s algorithm, thisAFCI with no unshielded colliders. Moreover, we can showOrientation Algorithm obviously returns a DAG orientation of P Cthat it is agreeable to J ◦→K .Lemma 4.2. Let D J◦→K be the DAG output of the Orientation Algorithm. D J◦→K is a DAG orientation of P Ccolliders and agreeable to J ◦→K .AFCI free of unshieldedThis lemma is the most difficult to establish in the whole argument, and a proof is given in Appendix B. The reason totake the trouble is that Lemma 4.2 enables us to prove the following fact.Theorem 3. Let J ◦→K be a ◦→ edge in PAFCI. Construct H from PAFCI by the following procedure:(1) orient ◦→ edges in REL( J ◦→K ) as ↔, and orient other ◦→ edges as →;(2) orient −−◦ edges in PAFCI as →;(3) orient P CAFCI into D J◦→K with the Orientation Algorithm.Then H is a member of [GT ].See Appendix B for the proof. As hinted above, the basic idea of the proof is to start with a MAG constructed via theprocedure in Theorem 2, and then show that the MAG can be transformed into the graph constructed here by a sequenceof equivalence-preserving changes of → into ↔.The main theorem of this paper readily follows:Theorem 4 (Completeness). The Augmented FCI algorithm (with the additional tail inference rules R5–R10) is complete, in the sensethat given a perfect conditional independence oracle, the algorithm returns the maximally informative PAG for the true causal MAG.Proof. Theorem 2 implies that for every circle on ◦−−◦ and −−◦ edges in the AFCI output, there is a MAG Markov equivalentto the true causal MAG in which the circle is marked as an arrowhead; Theorem 3 implies that this is also the case for everycircle on ◦→ edges. Hence, no circle in the AFCI output can be an invariant tail. Together with the arrowhead-completenessresult, we have shown that the AFCI algorithm is complete. (cid:2)5. ConclusionCausal discovery from data becomes especially challenging when the possibility of latent confounding and selection biascannot be ruled out. Maximal ancestral graphs provide a neat representation of such causal systems without explicitly in-troducing unobserved variables, which facilitates automated search over (classes of) causal structures based on correlational1886J. Zhang / Artificial Intelligence 172 (2008) 1873–1896information. We have established a completeness result in this framework, concerning the extent to which causal infor-mation can be extracted from facts of probabilistic independence and dependence, under the standard causal Markov andFaithfulness assumptions.Although we presented the result in the context of the FCI algorithm, its significance goes beyond this particular algo-rithm, because we have in effect shown that the orientation rules R0–R10 provide a complete characterization of invariantmarks in a Markov equivalence class of MAGs. In particular, given an arbitrary MAG, these orientation rules can be usedto identify its invariant marks. This will be useful in any causal discovery algorithm or causal reasoning system based onMAGs.The orientation rules fall naturally into three independent blocks. R0–R4 are arrowhead complete. R5–R7 are relevantonly when selection bias may be present. In fact, it is more common in the literature to consider latent confoundingwithout selection bias, in which case R5–R7 may be either ignored or serve as a check of the assumption of no selectionbias. Moreover, when there is no selection bias, a directed edge in the causal MAG carries especially clear qualitative causalinformation. R8–R10 are then particularly valuable, as they can pick up directed edges missed by R0–R4.Besides the constraint-based approach to causal discovery, of which the FCI algorithm is a representative, there is alsothe score-based or Bayesian approach to causal discovery in the literature [7,14]. It is an ongoing project to develop a score-based causal discovery procedure based on MAGs. Not only are the orientation rules relevant to this problem, Theorem 2 inSection 4.1 is probably also useful for the purpose of scoring an equivalence class of MAGs, in that it gives a procedure forconstructing a representative MAG with the fewest undirected edges and bi-directed edges.We close by noting two related open problems. First, we have implicitly assumed that no substantial background causalknowledge is available, and so the causal MAG can only be determined up to Markov equivalence. When prior causalknowledge or limited experimental control is available, it is possible to discriminate between some Markov equivalent MAGs,and hence more edge marks than the invariant ones of the true causal MAG may be identifiable. How to adapt the AFCIalgorithm to handle such background knowledge and whether the adapted algorithm is complete are worth investigating.Second, it should be emphasized that our completeness result is in regard to causal information that can be inferredfrom probabilistic independence and dependence facts. But there may be other kind of probabilistic facts that are infor-mative about causation. In fact, it is well known that causal DAGs with latent variables can entail testable constraints onthe marginal probability of observed variables that do not take the form of conditional independence (see [31] for an illu-minating discussion). Such constraints are not retained in the MAG representation of the underlying causal structure. Thisis a limitation of the MAG framework, and how to effectively employ non-independence constraints in automated causaldiscovery remains an intriguing open question.AcknowledgementsI thank Peter Spirtes and Thomas Richardson for many suggestions and especially for their time in checking the proofs.I am also grateful to the referees for useful comments.Appendix A. Proof of Lemma 4.1 and Theorem 2We need some utility lemmas about PAFCI.Lemma A.1. In PAFCI, the following property holds:P1 for any three vertices A, B, C , if A∗→ B◦−−∗ C , then there is an edge between A and C with an arrowhead at C , namely, A∗→ C .Furthermore, if the edge between A and B is A → B, then the edge between A and C is either A → C or A◦→C (i.e., it is notA ↔ C ).This is a key lemma for proving arrowhead completeness, and only concerns R0–R4, because the extra inference rulesdo not supply arrowheads. See the proof of Lemma 4.1 in [2], which is formulated in a different but equivalent way. Weomit details for interest of space.Lemma A.2. In PAFCI, the following property holds:P2 For any two vertices A, B, if A−−◦B, then there is no edge into A or B.Proof. By P1, for any A−−◦B in PAFCI, if there is an edge C∗→ B, there is also an edge C∗→ A. So it suffices to prove thatthere is no edge into A. Let E = { X−−◦Y in PAFCI|∃Z s.t. Z ∗→ X is in PAFCI}. We need to show that E is empty. Supposethat it is not empty. Let X0−−◦Y 0 ∈ E be the first member of E that gets so oriented—i.e., the tail marks on other edges in E,if any, get oriented after X0◦−−◦Y 0 is oriented as X0−−◦Y 0. Choose any Z0 such that Z0∗→ X0 is in PAFCI. Since X0◦−−◦Y 0is oriented as X0−−◦Y 0 either by R6 or R7, we consider the two cases one by one:Case 1: It is oriented by R6. That means there is a vertex W such that W — X0 is in PAFCI. But then Z0∗→ X0—W violates(a3) in the definition of ancestral graphs, which contradicts the soundness of PAFCI.J. Zhang / Artificial Intelligence 172 (2008) 1873–18961887Case 2: It is oriented by R7. That means, at the time of the orientation, there is a vertex W such that W , Y 0 are notadjacent, and there is an edge W −−◦ X0 between them. This implies that either W −−◦ X0 or W — X0 appears in PAFCI (asno arrowhead is added by any of R5–R10). The latter case is again ruled out by (a3) in the definition of ancestral graphs.In the former case, since Z0∗→ X0 is in PAFCI, by P1, Z0∗→ W is also in PAFCI. But then W −−◦ X0 is in E and gets orientedbefore X0−−◦Y 0 does, which contradicts our choice of X0−−◦Y 0.Hence the supposition that E is not empty is false. CP2 holds of PAFCI. (cid:2)Call (cid:4)V 0, . . . , V n(cid:5) a tail-circle path from V 0 to V n if for every i (0 (cid:2) i (cid:2) n − 1), the edge between V i and V i+1 isV i−−◦V i+1.Lemma A.3. In PAFCI, the following hold:(i) For any A−−◦B, there is an uncovered tail-circle path from an endpoint of an undirected edge to B that ends with the edge A−−◦B.(ii) If p is an uncovered tail-circle path, then no two non-consecutive vertices on p are adjacent.Proof. Let TC be the set of −−◦ edges in PAFCI. Order the members of TC by their order of occurrence in the orientationprocess. We show (i) by induction.Base case: Let X−−◦Y be the “first” edge in TC—that is, it gets oriented as such before any other member of TC does. Ofall the mark inference rules, only R6 and R7 could yield −−◦ edges. If X−−◦Y is oriented by R6, then obviously X is anendpoint of an undirected edge. Suppose X−−◦Y is oriented by R7, which means there is a vertex Z such that Z , Y arenot adjacent, and Z −−◦ X◦−−◦Y is the configuration at the point of orienting X◦−−◦Y . If Z −−◦ X remains in PAFCI, then itbelongs to TC, and it occurs earlier than X−−◦Y does, which contradicts our choice of X−−◦Y . So in PAFCI it must be Z — X(because no inference rule will orient −−◦ into →). Hence X is still an endpoint of an undirected edge. Then X−−◦Y is anuncovered tail-circle path from an endpoint of an undirected edge to Y .Inductive step: Suppose the first n edges in TC satisfy (i); consider the n + 1st edge, U −−◦W , in TC. Again, it is orientedby R6 or R7. If it is oriented by R6, then U is an endpoint of an undirected edge, and U −−◦W constitutes an uncoveredtail-circle path from U to W . Suppose it is oriented by R7, then there is a vertex V such that V , W are not adjacent, andV −−◦U ◦−−◦W is the configuration at the point of orienting X◦−−◦Y . If V −−◦U remains in PAFCI, then it is one of the firstn edges in TC. By the inductive hypothesis, there is an uncovered tail-circle path, p, from an endpoint of an undirectededge to U that includes the edge V −−◦U . Since V , W are not adjacent, p appended to U −−◦W constitutes an uncoveredtail-circle path from an endpoint of an undirected edge to W . If, on the other hand, V −−◦U is not in PAFCI, then it must beV —U , which makes U an endpoint of an undirected edge, and U −−◦W the desired path. Therefore, for every edge in TC,the property stated in (i) holds.Next we prove (ii). If p has only one edge, the proposition trivially holds, because there is no pair of non-consecutivevertices; if p has two edges, the proposition also trivially holds, because p is uncovered, and the only pair of non-consecutivevertices on p are by definition non-adjacent.Now suppose the proposition holds for those uncovered circle-tail paths that have fewer than n edges. Consider an un-covered circle-tail path with n edges: V 0−−◦V 1 · · · V n−1−−◦V n. By the inductive hypothesis, the only pair of non-consecutivevertices that could be adjacent is V 0 and V n. By P2 (Lemma A.2), the edge between V 0 and V n is not into V 0 or V n. It isnot an undirected edge either, for otherwise the circle at V n on V n−1−−◦V n should have been oriented by R6. However,(cid:4)V 0, V 1, . . . , V n−1, V n, V 0(cid:5) forms an uncovered cycle, so at least one of the ◦−−◦ edges on the cycle should have been ori-ented as — by R5 before any—edge appears, which contradicts the fact that there is no—edge on the cycle. So V 0 and V nare not adjacent. (cid:2)The main use of Lemma A.3 is to establish two more properties of PAFCI.Lemma A.4. In PAFCI, the following property holds:P3 For any three vertices A, B, C , if A−−◦B◦−−∗C , then A and C are adjacent. Furthermore, if A−−◦B◦−−◦C , then A−−◦C ; ifA−−◦B◦→C , then A → C or A◦→C .Proof. The first claim is obvious. If A−−◦B◦−−∗C , but A, C are not adjacent, then the circle at B on B◦−−∗C should havebeen oriented by R7.Suppose, more specifically, that A−−◦B◦−−◦C . Consider the edge between A and C . P1 (Lemma A.1) implies that it isnot into C . P2 (Lemma A.2) implies that it is not into A. It is not undirected either, for otherwise the circle at C on B◦−−◦Ccould be oriented by R6. Hence it is either (1) A◦−−C ; or (2) A◦−−◦C ; or (3) A−−◦C . We now show that (1) and (2) areimpossible.Suppose for contradiction that (1) or (2) is the case. By (i) in Lemma A.3, there is an uncovered tail-circle path p fromE, an endpoint of an undirected edge, to B that includes the edge A−−◦B. We claim that for every vertex V on p, eitherV ◦−−◦C or V ◦−−C is present. The argument goes by induction. Obviously B and A satisfy the claim. Suppose, starting from1888J. Zhang / Artificial Intelligence 172 (2008) 1873–1896B, the nth vertex on p, V n, satisfies the claim. Consider the n + 1st vertex on p, V n+1. Since p is a tail-circle path, we haveV n+1−−◦V n. By the inductive hypothesis, V n◦−−◦C or V n◦−−C . So, as already established, V n+1 and C must be adjacent.Again, P1 implies that the edge between them is not into C . P2 implies that the edge between them is not into V n+1.The edge is not undirected either, for otherwise the circle at C on B◦−−◦C could be oriented by R6. Furthermore, by (ii)in Lemma A.3, V n+1 and B are not adjacent. So the edge between V n+1 and C can’t be V n+1−−◦C , for otherwise the circleat C on C◦−−◦B could be oriented by R7. It follows that either V n+1◦−−◦C or V n+1◦−−C . Therefore, every vertex on p, inparticular the endpoint E, satisfies the claim. So either E◦−−◦C or E◦−−C occurs. But E is an endpoint of an undirectededge, and hence the circle at E on E◦−−◦C or E◦−−C could be oriented. Contradiction.Hence neither (1) nor (2) is the case, which means A−−◦C occurs in PAFCI.On the other hand, if it is A−−◦B◦→C that occurs in PAFCI, then P2 implies that the edge between A and C is not intoA (due to the presence of A−−◦B). It follows that the edge mark at C is not a tail, for otherwise either PAFCI would not besound (with an arrowhead incident to an undirected edge) or P2 would be violated (with an arrowhead incident to a −−◦edge). Note moreover that the edge mark at C cannot be a circle, for otherwise P1 would be violated. Hence the edge markat C is an arrowhead, and the edge is either A → C or A◦→C . (cid:2)Lemma A.5. In PAFCI, the following property holds:P4 For any A−−◦B, there is no tail-circle path from B to A. That is, there is no such cycle as A−−◦B−−◦C−−◦ · · · −−◦ A.Proof. We first argue that if there is any such cycle in PAFCI, then there is a cycle with only three edges,i.e.,A−−◦B−−◦C−−◦ A. To show this, note that for any such cycle c = (cid:4)V 0, V 1, V 2, . . . , V n, V 0(cid:5) with more than three edges,c can’t be uncovered, otherwise every edge on c would have been oriented as — by R5. That means there is a consecutivetriple on c which is shielded. Without loss of generality, suppose (cid:4)V 0, V 1, V 2(cid:5) is shielded, i.e., V 0 and V 2 are adjacent. Theedge between V 0 and V 2 can’t contain an arrowhead, as Lemma A.2 shows; it can’t be undirected, for otherwise some circleon c should been oriented by R6; it can’t be ◦−−◦, as implied by Lemma A.4 (because V 0−−◦V 1−−◦V 2 is present). So itis either V 0−−◦V 2 or V 2−−◦V 0. In either case, there is a shorter cycle than c that consists of −−◦ edges. Hence we haveestablished that for any such cycle with more than three edges, there is a shorter one. It follows that if there is such a cycleat all, there must be one with only three edges.So, to prove P4, it suffices to show that A−−◦B−−◦C−−◦ A is impossible. Suppose for contradiction that A−−◦B−−◦C−−◦ Aappears in PAFCI. By (i) in Lemma A.3, there is an uncovered tail-circle path p from E, an endpoint of an undirected edge,to B that includes the edge A−−◦B. We claim that for every vertex V on p between A and E (including A and E), C−−◦Vis present in PAFCI. The argument is by induction. The vertex A, by supposition, satisfies the claim. Suppose, starting fromA, the nth vertex on p, V n, satisfies the claim. Consider the n + 1st vertex on p, V n+1. Since p is a tail-circle path, wehave V n+1−−◦V n. By the inductive hypothesis, C−−◦V n. So by Lemma A.4, V n+1 and C are adjacent. Lemma A.2 impliesthat the edge between them is not into either vertex. The edge is not undirected either, for otherwise the circle at C onB−−◦C could be oriented by R6. Furthermore, by (ii) in Lemma A.3, V n+1 and B are not adjacent. Since B−−◦C , the edgebetween V n+1 and C must be oriented as C−−◦V n+1. Therefore, every vertex between A and E, in particular the endpointE, satisfies the claim. But E is an endpoint of an undirected edge, and hence the circle at E on C−−◦E could be oriented.This is a contradiction. (cid:2)With P1–P4, we are ready to prove Lemma 4.1 and Theorem 2.Lemma 4.1. For every edge A◦−−◦B in P Cand can be oriented into a DAG with no unshielded colliders in which A ← B appears.AFCI can be oriented into a DAG with no unshielded colliders in which A → B appears,AFCI, P CProof. Given Lemma 5 in [17]—which showed that all chordal undirected graphs have the desired property—it suffices toshow that P CAFCI is chordal. Suppose for the sake of contradiction that there is a chordless cycle with four edges or more inP CAFCI. Let (cid:4)V 0, V 1, V 2, V 3, . . . , V 0(cid:5) be a shortest such cycle, which implies that no two non-consecutive vertices on the cycleare adjacent in P CAFCI. For every such pair of non-consecutive vertices V i and V j , they are not adjacent in PAFCI either. Thereason is that V i and V j are connected by a circle path in PAFCI, given which it is easy to derive from P1 and P3 that if V iand V j are adjacent in PAFCI, the edge between them must be ◦−−◦, and hence they would be adjacent in P CAFCI. Therefore,the cycle remains a shortest chordless cycle consisting of ◦−−◦ edges in PAFCI, which should have been oriented by R5.A contradiction. (cid:2)Theorem 2. Let H be the graph resulting from the following procedure applied to PAFCI:(1) orient the circles on ◦→ edges in PAFCI as tails, and orient the circles on −−◦ edges in PAFCI as arrowheads (that is, turn all ◦→edges and all −−◦ edges into directed edges →); andAFCI into a DAG with no unshielded colliders.(2) orient P CThen H is a member of [GT ].J. Zhang / Artificial Intelligence 172 (2008) 1873–18961889Proof. For interest of space, we will not give all the details, which are easy to construct given the sketch here. (Most detailsare also extremely similar to the proof of Theorem 4.2 in [2].) P2 and P4 together ensure that turning all circles on −−◦edges into arrowheads will not create any directed cycle or almost directed cycle. P1 and P3 ensure that further turning allcircles on ◦→ edges into tails will not create any directed cycle or almost directed cycle. So after operation 1, no directedcycle or almost directed cycle is created.For operation 2, P1 and P3 guarantee that no matter how we orient a ◦−−◦ edge, it will not yield a directed cycle orAFCI is oriented into a DAG, no directed cycle or almostAFCI. So if P Calmost directed cycle that involves an edge outside P Cdirected cycle will be created in H.Furthermore, no new undirected edges or bi-directed edges are created in constructing H, and hence every undirectededge and bi-directed edge in H are already in PAFCI. It is then easy to show, given the soundness of PAFCI, that in H thereis no edge into any vertex incident to an undirected edge, and that there is no inducing path between any two non-adjacentvertices. Therefore H is both ancestral and maximal.To show Markov equivalence between H and GT , we just need to check that the conditions in Proposition 2 are satisfied.They have the same adjacencies given the correctness of the adjacency inference step in the FCI algorithm. P2 and P3 ensurethat turning all circles on −−◦ edges in PAFCI into arrowheads will not create any new unshielded collider. P1 implies thatno matter how we orient a ◦−−◦ edge, it will not create a new unshielded collider that involves an edge outside P CAFCI. Soif P CAFCI is oriented into a DAG with no unshielded colliders, no more unshielded colliders than those already in PAFCI areconstructed in H. So H and GT have the same unshielded colliders. Finally, since no new bi-directed edges are created inconstructing H, it is not hard to verify condition (e3) in Proposition 2 concerning discriminating paths. It then follows thatH is a member of [GT ]. (cid:2)Appendix B. Proof of Lemma 4.2 and Theorem 3The proof of Lemma 4.2 is the most difficult part of our argument, and requires quite a few utility lemmas. Again, forinterest of space, we will often note and skip easy or similar steps. We begin by noting some facts about (uncovered) p.d.paths (Definition 10) in PAFCI.Lemma B.1. If p = (cid:4) A, . . . , B(cid:5) is a p.d. path from A to B in PAFCI, then some subsequence of p forms an uncovered p.d. path from A toB in PAFCI.Proof. The proof is by induction on the length of p. If there is only one edge on p, then it is trivially a (degenerate)uncovered p.d. path from A to B. If there are two edges on p, namely p = (cid:4) A, C, B(cid:5), either it is already uncovered, or it iscovered so that A and B are adjacent. In the latter case, we show that the edge between A and B is not into A or out of B,and hence it constitutes a desired path between A and B.We first argue that it is not into A. Suppose for contradiction that the mark at A on the edge between A and B is anarrowhead. Then the edge between A and C can’t have a circle mark at A, for otherwise by P1 (Lemma A.1), the edgebetween C and B has an arrowhead at C , which contradicts the fact that p is potentially directed. It follows that the edgebetween A and C must have a tail at A in PAFCI. Since the edge between A and B is into A, it follows from P2 (Lemma A.2)that the edge between A and C is A → C . Then the mark at C on the edge between C and B must be an arrowhead, asimplied by R2, a contradiction. So the edge between A and B is not into A.Next we show that it is not out of B either. Suppose for contradiction that the mark at B on the edge between A and Bis a tail. Then it is either A—B or A◦−−B. The former implies that the edge between C and B has a tail at B by R6, whichcontradicts the fact that p is potentially directed. So it can only be A◦−−B. Then P2 implies that there is no arrowhead intoB. Since p is potentially directed, the edge between C and B is not out of B. Hence the mark at B on the edge between Cand B is a circle. It is then easy to check that the only possible configurations consistent with P1, P2, and the fact that p ispotentially directed are A◦−−◦C◦−−◦B, or A◦−−◦C−−◦B, or A−−◦C◦−−◦B or A−−◦C−−◦B. The first three cases contradict P3(Lemma A.4), and the last case contradicts P4 (Lemma A.5).The inductive step is easy. Suppose the proposition holds when the length of p is n − 1 (n (cid:3) 3). Consider the case wherep has n edges. Either p is already uncovered, or there is a triple (cid:4) X, Y , Z (cid:5) on the path which is shielded. In the latter case,by the foregoing argument, the edge between X and Z is not into X or out of Z . So if we replace (cid:4) X, Y , Z (cid:5) with the edgebetween X and Z on p, we get a subsequence of p which is a p.d. path from A to B with length n − 1. By the inductivehypothesis, a subsequence of the new path, which is also a subsequence of p, forms an uncovered p.d. path from A to B. (cid:2)Lemma B.2. If p is an uncovered p.d. path from A to B in PAFCI, then(i) if there is an ◦→ or −−◦ edge on p, then any ◦−−◦ edge on p is before that edge, and any → edge on p is after that edge;(ii) p does not include both a ◦→ edge and a −−◦ edge; and(iii) there is at most one ◦→ edge on p.Proof. To see (i) is true, notice that since p is uncovered and potentially directed, any edge after a ◦→ edge or a → edgeon p must be oriented as → by R1. So no ◦−−◦ can appear after a ◦→ edge on p, and no → can appear before a ◦→ edge1890J. Zhang / Artificial Intelligence 172 (2008) 1873–1896on p. The same is true with a −−◦ edge. Since p is uncovered, any edge on p after −−◦ will be oriented as −−◦ or → byeither R7 or R1.(ii) and (iii) are evident given the argument for (i). For (iii), just note that any edge after a ◦→ edge on p must beoriented as a → edge. For (ii), suppose for contradiction that p contains both a ◦→ edge and a −−◦ edge. Then the −−◦edge does not appear after the ◦→ edge on p, because any edge after ◦→ on p must be oriented as → by R1. On the otherhand, the ◦→ does not appear after the −−◦ edge on p, because any edge after −−◦ on p is either −−◦ or →. This is acontradiction. (cid:2)Lemma B.3. In PAFCI, if there is a circle path—a path consisting of ◦−−◦ edges—between A and B, then for any other vertex C , C∗→ Aif and only if C∗→ B.Proof. This easily follows from P1. (cid:2)Lemma B.4. In PAFCI, if there is a p.d. path from A to B, then the edge between A and B, if any, is not into A.Proof. By Lemma B.1, there is an uncovered p.d. path p from A to B. Suppose for contradiction that there is an edgebetween A and B which is into A, namely A←∗B. There can not be a −−◦ edge on p for the following reason: the first−−◦ edge, if any, is either incident to A or is connected to A by a circle path, according to Lemma B.2. In either case, byLemma B.3, there is an edge into the tail endpoint of the −−◦ edge, which contradicts P2 (Lemma A.2).So, by Lemma B.2, p is of the form: A◦−−◦ · · · ◦−−◦ X◦→Y → · · · → B, where it could be that A = X (there is no ◦−−◦edge) and/or X = Y (there is no ◦→ edge) and/or Y = B (there is no directed edge). If Y = B, it is easy to see that P1 isviolated due to the supposed presence of A←∗B. If Y (cid:14)= B, then P1 and the supposed presence of A←∗B entail that thereis an edge between B and Y that is into Y . But Y is an ancestor of B. This contradicts the soundness of PAFCI. Hence theinitial supposition of A←∗B is false. (cid:2)Lemma B.5. In PAFCI, if there is a p.d. path from A to B that is into B, then every uncovered p.d. path from A to B is into B.Proof. Suppose for contradiction that there is an uncovered p.d. path from A to B not into B. Then the last edge on thepath must be ◦−−◦. (It is not −−◦ in light of P2, because there is a p.d. path into B.) It then follows from Lemma B.2 thatthe path is a circle path. Let C be the vertex adjacent to B on the p.d. path into B, so C∗→ B. It follows from Lemma B.3that C∗→ A. But there is a p.d. path from A to C , which contradicts Lemma B.4. (cid:2)Corollary B.6. In PAFCI, if A, B are adjacent, and there is a p.d. path from A to B that is into B, then the edge between A and B is eitherA◦→B or A → B.Proof. This easily follows from Lemmas B.4, B.5, and A.2. (cid:2)Lemma B.7. If there is a circle path between two adjacent vertices in PAFCI, then the edge between the two vertices is ◦−−◦.Proof. This is very easy to see given P1 (or Lemma B.3) and P3. (cid:2)Lemma B.8. Let u be an uncovered circle path in PAFCI. If A and B are two non-consecutive vertices on u, then A and B are notadjacent in PAFCI.Proof. It follows from Lemma B.7 and the fact that P CAFCI is chordal. (cid:2)The next two lemmas are useful facts about edges in REL( J ◦→K ) (Definition 11).Lemma B.9. For every A◦→B ∈ REL( J ◦→K ), there is an uncovered p.d. path u from J to B in PAFCI such that for every vertex V on uother than B, there is an edge V ◦→K .Proof. The lemma holds trivially if A = J or B = K . Suppose A (cid:14)= J and B (cid:14)= K . By Definition 11, there is a p.d. path fromJ to A in PAFCI such that no vertex on the path (including the endpoints) is a parent of K . Note that B is not on this p.d.path, for otherwise there would be a p.d. path from B to A, which, together with the presence of A◦→B, would contradictLemma B.4. So we can concatenate the p.d. path with A◦→B to form a p.d. path from J to B that is into B. In light ofLemma B.1, it follows that there is an uncovered p.d. path u from J to B such that every vertex on u other than B is not aparent of K . We can then prove by induction that for every vertex V on u other than B, there is an edge V ◦→K in PAFCI.The base case J ◦→K is obvious. Suppose it holds of the nth vertex on u, V n. Consider V n+1 (cid:14)= B. Since B (cid:14)= K , byDefinition 11, B is a parent of K . This implies that there is a p.d. path from V n+1 to K . By Corollary B.6, if V n+1 and K areJ. Zhang / Artificial Intelligence 172 (2008) 1873–18961891adjacent, then the edge is either V n+1 → K or V n+1◦→K . But no vertex on u other than B is a parent of K , so it sufficesto show that V n+1 is adjacent to K . Suppose otherwise. It is then easy to show that the circle at V n on V n◦→K could havebeen oriented by R9, which is a contradiction. Therefore V n+1 and K are adjacent, and the edge is V n+1◦→K in PAFCI. (cid:2)Lemma B.10. If A◦→B ∈ REL( J ◦→K ), then A◦→K appears in PAFCI.Proof. The lemma trivially holds if A = J or B = K . Suppose A (cid:14)= J and B (cid:14)= K . Since A◦→B ∈ REL( J ◦→K ), there is anuncovered p.d. path u from J to B satisfying the condition of Lemma B.9. By Lemma B.5, we know u is also into B. LetX∗→ B be the last edge on u. By Lemma B.9, we have X◦→K in PAFCI. Also, because B (cid:14)= K , B → K is in PAFCI, so the edgebetween X and B can’t be X → B, for otherwise X◦→K could be oriented by R8. It follows that the edge is X◦→B in PAFCI.Note that if A and K are not adjacent, then the path (cid:4) A, B, X, K (cid:5) is a discriminating path for X (Definition 7). Hence thecircle on X◦→K could have been oriented by R4, a contradiction. So A is adjacent to K . By Corollary B.6, the edge betweenA and K is either A → K or A◦→K . But by Definition 11, A is not a parent of K , so it must be A◦→K in PAFCI. (cid:2)Our goal is to show that in the course of the Orientation Algorithm, no violation of C1–C3 (Definition 12) would occur.The next block of lemmas are important steps towards this goal. They amount to showing that if we choose a ◦−−◦ edgeto orient away from violation of C1–C3 (as the Orientation Algorithm does), that orientation will not trigger any violation ofC1–C3 by applications of UR1 alone.Lemma B.11. For any two vertices B, C ∈ AR( J ◦→K ), there is no uncovered circle path between B and C consisting of more than oneedge in PAFCI.Proof. Given Lemma B.8, it suffices to show that B and C are adjacent. This is obviously true if one of B and C is K .Suppose B (cid:14)= K and C (cid:14)= K , and hence both of them are parents of K by Definition 11. Let A be such a vertex that A◦→B ∈REL( J ◦→K ). It follows from Lemma B.3 that either A◦→C or A → C is in PAFCI. But it can’t be A → C for otherwiseA◦→K (shown to be present in Lemma B.10) could be oriented by R8. So it is A◦→C . Then B and C must be adjacent, forotherwise A◦→K could be oriented by R10. (cid:2)Lemma B.12. Suppose A◦→B ∈ REL( J ◦→K ). If A◦−−◦C appears in PAFCI and C is a parent of B in PAFCI (i.e. the edge A◦−−◦C isrequired by condition C2 to be oriented as A ← C ), then C is a parent of K in PAFCI.Proof. If B = K , it is trivial. Suppose B (cid:14)= K , and so B is a parent of K . By Lemma B.10, A◦→K is present in PAFCI. It followsthat C is adjacent to K , for otherwise (cid:4)C, B, A, K (cid:5) would constitute a discriminating path for A in PAFCI to orient A◦→K byR4. Furthermore, the edge between C and K must be C → K , as required by R2 and R8. Hence C is a parent of K . (cid:2)Lemma B.13. Suppose A◦→B ∈ REL( J ◦→K ), A◦−−◦C and C is a parent of B in PAFCI (i.e. the edge A◦−−◦C is required by conditionC2 to be oriented as A ← C ). Then(1) if for some D ∈ AR( J ◦→K ), C◦−−◦D is in PAFCI, then C ∈ AR( J ◦→K ) (so that the edge C◦−−◦D is not subject to C1);(2) If u = (cid:4)C, A, . . .(cid:5) is an uncovered circle path, no vertex on u except possibly C is in AR( J ◦→K ).Proof. To show (1), note that if D ∈ AR( J ◦→K ), then there is some vertex X such that X◦→D ∈ REL( J ◦→K ). By P1(Lemma A.1), X◦→C or X → C is in PAFCI. By Lemma B.12, C is a parent of K . So it is not X → C in PAFCI, otherwiseX◦→K , which is shown to be present by Lemma B.10, could be oriented as X → K by R8. So it must be X◦→C in PAFCI.Since X◦→D ∈ REL( J ◦→K ) and C is a parent of K , X◦→C satisfies Definition 11, which means C ∈ AR( J ◦→K ).To prove (2), suppose for contradiction that some vertex E (cid:14)= C on u is in AR( J ◦→K ). Obviously E (cid:14)= K , otherwise A◦→Ewould be present in PAFCI by Lemma B.10, which contradicts Lemma B.3. So E is a parent of K . Now consider the edgeA◦→K , shown to exist by Lemma B.10. A◦−−◦C is an uncovered p.d. path from A to C , a parent of K by Lemma B.12;u( A, E) is an uncovered p.d. path from A to E, a parent of K . Since u is uncovered, A◦→K could be oriented as A → K byR10; a contradiction. (cid:2)Lemma B.14. For every uncovered circle path u = (cid:4) A, . . . , E(cid:5) in PAFCI, either the edge incident to A is not required by C2 to be orientedout of A, or the edge incident to E is not required by C2 to be oriented out of E.Proof. Suppose for contradiction that the contrary is true. By Lemma B.12, both A and E are parents of K . Let B be thevertex adjacent to A on u. By supposition and Definition 12, there is a vertex C such that B◦→C ∈ REL( J ◦→K ) (and A isa parent of C ). Consider B◦→K (cf. Lemma B.10). B◦−−◦ A constitutes an uncovered p.d. path from B to A, a parent of K ;u(B, E) constitutes an uncovered p.d. path from B to E, a parent of K . A and E are not adjacent by Lemma B.8. Thus B◦→Kcould be oriented as B → K by R10; a contradiction. (cid:2)1892J. Zhang / Artificial Intelligence 172 (2008) 1873–1896Lemma B.15. If A◦→B ∈ REL( J ◦→K ), and u = (cid:4) A, C, . . .(cid:5) is an uncovered circle path such that C is not adjacent to B in PAFCI (sothat the edge between A and C is required by C3 to be oriented as A → C ), then no vertex on u is a parent of K in PAFCI.Proof. Since A◦→B ∈ REL( J ◦→K ), by Lemma B.10, A◦→K is present in PAFCI. Suppose for contradiction that a vertex D(which could be C ) on u is a parent of K . We consider the two possible cases one by one.Case 1: B = K , and hence K and C are not adjacent (which means D can’t be C in this case). So u( A, D) ⊕ D → K is ap.d. path from A to K such that the vertex adjacent to A on the path, namely C , is not adjacent to K . Let E be the firstvertex after C on the path which is adjacent to K (there must be one, because D is adjacent to K ). The edge between Eand K , by Corollary B.6, is either E◦→K or E → K . It follows that (cid:4) A, C, . . . , E, K (cid:5) forms an uncovered p.d. path from A toK such that C and K are not adjacent. Hence A◦→K could be oriented as A → K by R9; a contradiction.Case 2: B → K is in PAFCI. Then u( A, D) is an uncovered p.d. path from A to D, a parent of K , and A◦→B is an uncoveredp.d. path from A to B, a parent of K . Since C and B are not adjacent, the edge A◦→K could be oriented as A → K by R10;a contradiction. (cid:2)Lemma B.16. Suppose A◦→B, C◦→D ∈ REL( J ◦→K ), A (cid:14)= C and u = (cid:4) A, . . . , C(cid:5) is an uncovered circle path in PAFCI. Either the vertexnext to A on u is adjacent to B (so that C3 does not require orienting the edge out of A), or the vertex next to C on u is adjacent to D(so that C3 does not require orienting the edge out of C ).Proof. Suppose for contradiction that the contrary is true. We consider three cases separately and derive a contradiction ineach.Case 1: B = D. In this case, since D is not adjacent to the vertex next to C on u, u ⊕ C◦→B is an uncovered p.d. pathfrom A to B such that the vertex adjacent to A on the path is not adjacent to B. Hence A◦→B could be oriented by R9 asA → B, a contradiction.Case 2: B (cid:14)= D and one of them is K . Without loss of generality, suppose B = K . Since C◦→D ∈ REL( J ◦→K ), and D (cid:14)= K ,by Definition 11, D is a parent of K (B). Then u ⊕ C◦→D constitutes an uncovered p.d. path from A to D such that thevertex adjacent to A on the path is not adjacent to B. This is the same situation as Case 1 in the proof of Lemma B.15, whichleads to a contradiction.Case 3: B (cid:14)= D and neither of them is K . So both B and D are parents of K . Consider the edge A◦→K , which is shown tobe present by Lemma B.10. Since A◦→B is an uncovered p.d. path from A to B, a parent of K , u ⊕ C◦→D is an uncoveredp.d. path from A to D, a parent of K , and that the vertex next to A on u is not adjacent to B, the edge A◦→K could beoriented as A → K by R10, a contradiction. (cid:2)Now it is time for our key lemma:Lemma 4.2. Let D J◦→K be the DAG output of the Orientation Algorithm. D J◦→K is a DAG orientation of P Ccolliders and agreeable to J ◦→K .AFCI free of unshieldedProof. As noted in the main text, the correctness of Meek’s algorithm [17] guarantees that D J◦→K is a DAG free of un-shielded colliders. We need to show that it is also agreeable (Definition 12). In other words, we need to show that noviolation of C1–C3 occurs in D J◦→K . Below we give the details of our argument regarding C1. The argument regarding C2and that regarding C3 are extremely parallel, of which we omit details.Note that if any violation were to occur, it could only occur by the end of the third stage of the Orientation Algorithm,before all ◦−−◦ edges in E1 ∪ E2 ∪ E3 get oriented. So it suffices to show that by that stage, no violation of C1 occurs. In fact,we can prove something stronger. We show that for every vertex W ∈ AR( J ◦→K ), there is no ◦−−◦ edge that gets orientedas into W by the end of the third stage. Suppose for sake of contradiction that such an orientation occurs. Let the firstoccurrence be A◦−−◦B being oriented as A → B, where B ∈ AR( J ◦→K ). We consider all the possible ways in which thisorientation could occur and derive a contradiction in each. (We assume, without loss of generality, that UR1 has priorityover UR2 and UR3.)Case 1: A◦−−◦B is oriented as A → B to satisfy one of C1–C3. Since B ∈ AR( J ◦→K ), C1 does not dictate this orientation.Neither does C2, as entailed by (2) in Lemma B.13. So it is due to C3, which means there is a vertex E such that A◦→E ∈REL( J ◦→K ) and E, B are not adjacent. Then Lemma B.15 implies that B is not a parent of K . Furthermore, by Lemma B.10,A◦→K is present in PAFCI, which implies that B (cid:14)= K (because of A◦−−◦B). It follows that B /∈ AR( J ◦→K ); a contradiction.Case 2: A◦−−◦B is oriented as A → B by an application of UR2.22 That is, there is a vertex C such that A◦−−◦C◦−−◦B is inP CAFCI, and is oriented as A → C → B before A◦−−◦B is oriented. Then C◦−−◦B being oriented as C → B would be an earlieroccurrence of orientation into B. This contradicts our choice of A◦−−◦B.Case 3: A◦−−◦B is oriented as A → B by an application of UR3. Again, it is easy to see that this contradicts the assumptionthat A → B is the first orientation into B.22 The case with UR1 is more complicated, and will be considered last.J. Zhang / Artificial Intelligence 172 (2008) 1873–18961893Case 4: A◦−−◦B is oriented as A → B by an application of UR1. Generically this is the last (and possibly only) step in achain of applications of UR1 to an uncovered circle path, initiated by a directed edge that is not oriented by UR1. Regardingthis first initiating edge, there are three subcases to consider:Case 4.1: the first edge is oriented to satisfy one of C1–C3. It can not be due to C1, for otherwise there would be anAFCI with more than one edge between two vertices in AR( J ◦→K ), which contradicts Lemma B.11.uncovered circle path in P CThe rest goes exactly like the argument in Case 1.Case 4.2: the first edge is oriented by UR2. That is, there are three vertices X , Y and Z ( Z could be A) such thatX◦−−◦Y ◦−−◦ Z is in P CAFCI, and is oriented as X → Y → Z , which in turn orients the edge X◦−−◦Z as X → Z . And X → Zinitiates a chain of UR1 applications on an uncovered circle path u = (cid:4) X, Z , . . . , B(cid:5) that eventually leads to the orientation ofA → B. We claim that for every vertex V on u between Z and B (including B), there is an edge between Y and V alreadyoriented as Y → V before X → Z is thus oriented. The argument is by induction. For the base case, let V 1 be the firstvertex next to Z on u (V 1 is B if Z is A). Y and V 1 must be adjacent in P CAFCI, for otherwise Z ◦−−◦V 1 would be orientedas Z → V 1 by UR1 before X◦−−◦ Z is oriented by UR2, according to our convention for the priority of UR1. Since X and V 1are not adjacent (because u is uncovered), Y ◦−−◦V 1 should be oriented as Y → V 1 by UR1 before X → Z is thus oriented.The inductive step is extremely similar. Therefore, the claim holds of every vertex V on u between Z and B, including B. Inparticular, Y → B is already present before X◦−−◦ Z gets oriented, and hence before A◦−−◦B gets oriented. This contradictsour choice of A◦−−◦B.Case 4.3: the first edge is oriented by UR3. That is, there are four vertices X, Y , Z , W ( Z could be A) such thatW ◦−−◦Y ◦−−◦ Z , W ◦−−◦ X◦−−◦Z , X◦−−◦Y are in P CAFCI, and that W , Z are not adjacent. Furthermore, W ◦−−◦Y ◦−−◦ Z is ori-ented as W → Y → Z , which in turn orients the edge X◦−−◦Z as X → Z . This then initiates a chain of UR1 applicationson an uncovered circle path u = (cid:4) X, Z , . . . , B(cid:5) that eventually leads to the orientation of A → B. Notice that W , Z are notadjacent, so (cid:4)W , X, Z , . . . , B(cid:5) is also an uncovered circle path in P CAFCI, which implies that W is not adjacent to any vertexon u between Z and B. Then we can run the exact same argument as in Case 4.2 to derive a contradiction with our choiceof A◦−−◦B.Therefore, there is no occurrence of orienting a ◦−−◦ edge into W for any W ∈ AR( J ◦→K ) by the end of the third stageof the Orientation Algorithm. It follows that no violation of C1 occurs in D J◦→K .The arguments regarding C2 and C3 are extremely similar, with different utility lemmas cited.23 We omit the details tosave space and tediousness. (cid:2)To prove Theorem 3, we need two more relatively simple facts about PAFCI.Lemma B.17. For any A◦→B in PAFCI, if there is a p.d. path u other than A◦→B from A to B, then some vertex on u is adjacent to bothA and B.Proof. The argument is an easy induction on the length of u, with the upshot that if there is no such vertex, A◦→B couldhave been oriented by R9. (cid:2)Lemma B.18. Suppose C←◦ A◦→B is in PAFCI. If C and B are not adjacent, then A◦→B /∈ REL( J ◦→K ) or A◦→C /∈ REL( J ◦→K ).Proof. Suppose for contradiction that A◦→B ∈ REL( J ◦→K ) and A◦→C ∈ REL( J ◦→K ). By Lemma B.10, A◦→K is in PAFCI. Italso follows that B (cid:14)= K and C (cid:14)= K , for otherwise B and C would be adjacent. Then, by Definition 11, both B and C areparents of K , which implies that A◦→K could be oriented by R10 because C and B are not adjacent; a contradiction. (cid:2)Finally we can prove Theorem 3.Theorem 3. Let J ◦→K be a ◦→ edge in PAFCI. Construct H from PAFCI by the following procedure:(1) orient ◦→ edges in REL( J ◦→K ) as ↔, and orient other ◦→ edges as →;(2) orient −−◦ edges in PAFCI as →;(3) orient P CAFCI into D J◦→K with the Orientation Algorithm.Then H is a member of [GT ].Proof. By Theorem 2, we can construct a member of [GT ] by turning all ◦→ edges and −−◦ edges into directed edges, andorienting P CAFCI into D J◦→K . Denote this member by H J◦→K . It suffices to show that H is a MAG and Markov equivalent toH J◦→K .23 The argument for C2 is almost identical. The one regarding C3 is slightly more complicated in detail, but has the exact same structure.1894J. Zhang / Artificial Intelligence 172 (2008) 1873–1896Notice that the difference between the two is in regard to edges in REL( J ◦→K )—they correspond to directed edges inH J◦→K , but bi-directed edges in H. In what follows, we show that REL( J ◦→K ) can be transformed to H be a series ofchanges of directed edges into bi-directed edges, one edge at a time, such that each change will preserve MAG-ness andMarkov equivalence. Our theorem then follows.To show this, it suffices to establish the following. Let M be any MAG identical to H J◦→K except possibly that some ◦→edges in REL( J ◦→K ) are oriented as ↔ (instead of →) in M. (Note that H J◦→K is such a MAG.) LetDIFF =(cid:2)(cid:3)A → B in M| A◦→B is in PAFCI and A◦→B ∈ REL( J ◦→K ).We show that if DIFF is not empty, then some edge therein can be changed to ↔ while preserving MAG-ness and Markovequivalence with M. In other words, as long as M and H are still different, we can identify a directed edge in M thatcorresponds to an edge in REL( J ◦→K ), and safely change it into a bi-directed edge so as to decrease the number ofdifferences between M and H. If it is true, obviously there is a desired transformation from H J◦→K to H.We now prove it is true. Suppose DIFF is not empty. Let W = {B|∃ A s.t. A → B ∈ DIFF}. W is also non-empty. Let Y be amember of W such that no proper ancestor of Y in M belongs to W. Let X be a vertex such that X → Y ∈ DIFF and no properdescendant of X in M has this property. Let M∗be the graph resulting from changing X → Y in M into X ↔ Y . We showthat M∗is a MAG, and is Markov equivalent to M.Obviously no directed cycle is created in this change. It does not create an almost directed cycle unless there is a directedpath from X to Y in M other than the edge X → Y . Suppose for sake of contradiction that there is a directed path fromX to Y in M that does not contain X → Y . The corresponding path in PAFCI must be potentially directed. It follows fromLemma B.17 that some vertex Z on the path is adjacent to both X and Y . Since M is a MAG, we have X → Z → Y inM, and so the corresponding path (cid:4) X, Z , Y (cid:5) in PAFCI is potentially directed. Notice that the edge between Z and Y can’tbe Z −−◦Y in PAFCI according to P2 (Lemma A.2), because X◦→Y is present. So, by the definition of p.d. path, the edgebetween X and Z is either X◦−−◦Z or X → Z or X◦→Z or X−−◦Z , and the edge between Z and Y is either Z ◦−−◦Y orZ → Y or Z ◦→Y . But none of the 12 combinations is possible. It would be tedious to go through them one by one. So wewill just illustrate the kind of argument we would give by considering whether it is possible for X◦→Z ◦−−◦Y to appear inPAFCI.Suppose it is possible. Then Z /∈ AR( J ◦→K ), for otherwise X◦→Z ∈ REL( J ◦→K ), and Z is a proper ancestor of Y in M,which contradicts our choice of Y . However, Z ◦−−◦Y is oriented as Z → Y , which means that D J◦→K is not agreeable toJ ◦→K (C1 being violated). This contradicts Lemma 4.2. The other 11 cases can be similarly or more easily handled, in eachof which one can derive a contradiction. So the initial supposition of a directed path from X to Y other than X → Y in Mis false, and there is no almost directed cycle in M∗Moreover, there is no configuration in M∗either.that violates (a3) in Definition 1. Suppose the contrary is true. Then the. But it is obvious that Z — X must be also in PAFCI, which meansconfiguration can only be Z — X ↔ Y for some Z in M∗X◦→Y in PAFCI could have been oriented by R6; a contradiction. So M∗is ancestral.is also maximal, and is Markov equivalent to M. For this purpose, as established byWhat is left to show is that M∗Zhang and Spirtes [35] (their Lemma 1, see also [30]), it suffices to show the following hold of M:(T2) For every Z → X in M, there is also an edge Z → Y in M; for every Z ↔ X in M, there is also an edge Z → Y orZ ↔ Y in M.(T3) In M, there is no discriminating path for X on which Y is the endpoint adjacent to X .We first establish (T2). For every Z → X in M, it corresponds to either Z → X or Z ◦→ X or Z ◦−−◦ X or Z −−◦ X in PAFCI.We claim Z and Y are adjacent in any case. In the former two cases, by P1, Z and Y are adjacent (since X◦→Y is in PAFCI).In the case of Z ◦−−◦ X , since it is oriented as Z → X in M, Z is adjacent to Y , for otherwise D J◦→K is not agreeable toJ ◦→K , which contradicts Lemma 4.2. In the case of Z −−◦ X , by P3, Z and Y are adjacent. Moreover, the edge between Zand Y must be Z → Y in M, because Z → X → Y is in M and M is a MAG.For every Z ↔ X in M, it corresponds to either Z ↔ X or Z ◦→ X or Z←◦ X in PAFCI. In the former two cases, Z andY are adjacent by P1. In the latter case, Z←◦ X ∈ REL( J ◦→K ) by our assumption about bi-directed edges in M. It thenfollows from Lemma B.18 that Z and Y are adjacent. So in any case, Z and Y are adjacent in M. Moreover, since M is aMAG, the edge between Z and Y is either Z → Y or Z ↔ Y in M. (T2) is true.For (T3), suppose for sake of contradiction that in M there is a path p = (V 0, V 1, . . . , V n = X, Y ) which is discriminatingfor X . Without loss of generality, suppose p is a shortest such path. Below we derive a contradiction by (eventually) showingthat p is already a discriminating path in PAFCI, and hence the circle at X on X◦→Y could have been oriented by R4.Note first that the subpath p(V 0, X) is into X in M, for otherwise there would be a directed path from X to Y otherthan the edge X → Y (which follows from the definition of discriminating path). It follows that every edge on the subpathp(V 1, X) is bi-directed in M.Next we claim that in PAFCI the edge between V 0 and V 1 is V 0∗→ V 1, i.e., is into V 1. Suppose for contradiction thatthe contrary is true. Then the mark at V 1 must be a circle. Hence the edge is either V 0−−◦V 1 or V 0◦−−◦V 1 or V 0←◦V 1in PAFCI. In each of the three cases we can derive a contradiction. And two facts are useful for showing this: (i) V 1 ↔ V 2(V 2 could be X ) appears in M (as already noted); and (ii) In PAFCI there isn’t an edge between V 0 and V 2 that is into V 2.J. Zhang / Artificial Intelligence 172 (2008) 1873–18961895For otherwise either (cid:4)V 0, V 2, . . . , V n = X, Y (cid:5) constitutes a shorter discriminating path in M (if V 2 (cid:14)= X ), or X◦→Y in PAFCIcould be oriented as X → Y by R1 (if V 2 = X ), either of which is a contradiction.Again, we won’t go through all three cases, and just use the most complicated case to illustrate our argument. ConsiderV 0◦−−◦V 1. Suppose this is true in PAFCI. Then V 1 ↔ V 2 is not already in PAFCI, for otherwise by Lemma B.3, there would alsobe an edge V 0 ↔ V 2 in PAFCI, which contradicts fact (ii). By our assumption about bi-directed edges in M, either V 1◦→V 2or V 1←◦V 2 appears in PAFCI and belongs to REL( J ◦→K ). In the former case (V 1◦→V 2), V 0 must be adjacent to V 2, forotherwise the orientation of V 0◦−−◦V 1 (into V 0 → V 1) is not agreeable to J ◦→K (C3 being violated). By Corollary B.6, theedge between V 0 and V 2 is either V 0 → V 2 or V 0◦→V 2 in PAFCI, which contradicts fact (2). In the latter case (V 1←◦V 2), byLemma B.3, either V 0 ← V 2 or V 0←◦V 2 is in PAFCI. Now if V 0 is not a parent of K , which means V 0 /∈ AR( J ◦→K ) (V 0 (cid:14)= Kbecause Y belongs to AR( J ◦→K ) but is not adjacent to V 0 by the definition of discriminating path), then the orientationof V 0◦−−◦V 1 (into V 0 → V 1) is not agreeable (C1 being violated). So V 0 is a parent of K —which also implies that Y (cid:14)= K .But then the edge V 2◦→K —which is implied to be present in PAFCI by Lemma B.10—could be oriented as V 2 → K by R10(because V 0 and Y are not adjacent by the definition of discriminating path, and the edge between V 2 and V 0 in PAFCIconstitutes an uncovered p.d. path from V 2 to V 0, and the edge between V 2 and Y constitutes an uncovered p.d. path inPAFCI from V 2 to Y ); a contradiction.The other two cases can be handled more easily. It follows that the edge between V 0 and V 1 in PAFCI is V 0∗→ V 1.Finally we show that the supposed p would also be a discriminating path for X in PAFCI. We prove by induction thatfor every 1 (cid:2) i (cid:2) n − 1, V i is a collider on p in PAFCI and is a parent of Y in PAFCI. Consider V 1 as the base case. Since wehave shown that V 0∗→ V 1 appears in PAFCI, and V 0 is not adjacent to Y , the edge between V 1 and Y is V 1 → Y in PAFCIin virtue of R1. So V 1 is a parent of Y in PAFCI. Suppose for contradiction that V 1 is not a collider on p in PAFCI. Since wehave V 0∗→ V 1 in PAFCI, and we have V 1 ↔ V 2 in M, the edge between V 1 and V 2 must be V 1◦→V 2 in PAFCI. And by ourassumption about bi-directed edges in M, V 1◦→V 2 ∈ REL( J ◦→K ). Then Lemma B.10 implies that there is an edge V 1◦→Kin PAFCI. But either Y = K or Y is a parent of K in PAFCI, which implies that V 1 is a parent of K or can be oriented as aparent of K by R8 in PAFCI; a contradiction. So V 1 is a collider on p in PAFCI and is a parent of Y in PAFCI.The inductive step is very similar, except we will invoke R4 where the base case invoked R1. Therefore (T3) is also true.This concludes the proof. (cid:2)References[1] R.A. Ali, T. Richardson, P. Spirtes, Markov equivalence for ancestral graphs, Technical Report 466, Department of Statistics, University of Washington,2004.[2] R.A. Ali, T. Richardson, P. Spirtes,in: Proceedings of the 21th Conference on Uncertainty in Artificialables,http://www.stat.washington.edu/www/research/reports/2005/tr476.pdf.J. Zhang, Towards characterizing Markov equivalence classes for directed acyclic graphs with latent vari-Intelligence, AUAI Press, 2005, pp. 10–17. Full version available at[3] F. Artzenius, The common cause principle, in: D. Hull, K. Okruhlik (Eds.), Philosophy of Science Proceeding, vol. 2, East Lansing, MI, 1992, pp. 227–237.[4] S.A. Andersson, D. Madigan, M.D. Perlman, A characterization of Markov equivalence classes of acyclic digraphs, The Annals of Statistics 25 (2) (1997)505–541.[5] K.A. Bollen, Structural Equations with Latent Variables, Wiley, New York, 1989.[6] N. Cartwright, The Dappled World, Cambridge University Press, Cambridge, 1999.[7] D.M. Chickering, Optimal structure identification with greedy search, Journal of Machine Learning Research 3 (2002) 507–554.[8] P. Dawid, Conditional independence in statistical theory, Journal of the Royal Statistical Society, Series B 41 (1979) 1–31.[9] M. Drton, T. Richardson, Iterative conditional fitting for Gaussian ancestral graph models, in: Proceedings of the 20th Conference on Uncertainty inArtificial Intelligence, Morgan Kaufmann, 2003, pp. 130–137.[10] M. Drton, T. Richardson, Graphical answers to questions about likelihood inference in Gaussian covariance models, Technical Report 467, Departmentof Statistics, University of Washington, 2004.[11] D. Geiger, D. Heckerman, H. King, C. Meek, Stratified exponential families: graphical models and model selection, The Annals of Statistics 29 (2001)505–529.[12] C. Glymour, G. Cooper (Eds.), Computation, Causation, and Discovery, MIT Press, Cambridge, MA, 1999.[13] D.M. Hausman, J. Woodward, Independence, invariance and the causal Markov condition, British Journal for the Philosophy of Science 50 (1999) 521–583.[14] D. Heckerman, C. Meek, G.F. Cooper, A Bayesian approach to causal discovery, in: C. Glymour, G. Cooper (Eds.), Computation, Causation, and Discovery,MIT Press, Cambridge, MA, 1999, pp. 141–165.[15] K.D. Hoover, Causality in Macroeconomics, Cambridge University Press, Cambridge, 2001.[16] M.A. Klopotek, On a deficiency of the FCI algorithm learning Bayesian networks from data, Demonstratio Mathematica XXXIII (1) (2000) 181–194.[17] C. Meek, Causal inference and causal explanation with background knowledge, in: Proceedings of the Eleventh Conference on Uncertainty in ArtificialIntelligence, Morgan Kaufmann, 1995, pp. 403–411.[18] R.E. Neapolitan, Learning Bayesian Networks, Prentice Hall, Upper Saddle River, NJ, 2004.[19] J. Pearl, Probabilistic Reasoning in Intelligent Systems, Morgan Kaufmann, San Mateo, California, 1988.[20] J. Pearl, Causality: Models, Reasoning, and Inference, Cambridge University Press, Cambridge, UK, 2000.[21] T. Richardson, Models of Feedback: Interpretation and Discovery, PhD Thesis, Department of Philosophy, Carnegie Mellon University, 1996.[22] T. Richardson, Chain graphs and symmetric associations, in: M. Jordan (Ed.), Learning in Graphical Models, Kluwer, Dordrecht, 1998, pp. 231–259.[23] T. Richardson, P. Spirtes, Ancestral graph Markov models, The Annals of Statistics 30 (4) (2002) 962–1030.[24] T. Richardson, P. Spirtes, Causal inference via ancestral graph models, in: P. Green, N. Hjort, S. Richardson (Eds.), Highly Structured Stochastic Systems,Oxford University Press, 2003, pp. 83–105.[25] P. Spirtes, C. Glymour, R. Scheines, Causation, Prediction and Search, Springer-Verlag, New York, 1993, second ed., MIT Press, Cambridge, MA, 2000.[26] P. Spirtes, C. Meek, T. Richardson, An algorithm for causal inference in the presence of latent variables and selection bias, in: C. Glymour, G. Cooper(Eds.), Computation, Causation, and Discovery, MIT Press, Cambridge, MA, 1999, pp. 211–252.1896J. Zhang / Artificial Intelligence 172 (2008) 1873–1896[27] P. Spirtes, T. Richardson, A polynomial time algorithm for determining DAG equivalence in the presence of latent variables and selection bias, in:Proceedings of the 6th International Workshop on Artificial Intelligence and Statistics, 1996, http://citeseer.ist.psu.edu/spirtes97polynomial.html.[28] P. Spirtes, T. Verma, Equivalence of causal models with latent variables, Technical Report Phil-36, Department of Philosophy, Carnegie Mellon University,1992.[29] D. Steel, Homogeneity, selection, and the faithfulness condition, Minds and Machines 16 (2006) 303–317.[30] J. Tian, Generating Markov equivalent maximal ancestral graphs by single edge replacement, in: Proceedings of the 21th Conference on Uncertainty inArtificial Intelligence, AUAI Press, 2005, pp. 591–598.[31] J. Tian, J. Pearl, On the testable implications of causal models with hidden variables, in: Proceedings of the 18th Conference on Uncertainty in ArtificialIntelligence, Morgan Kaufmann, 2002, pp. 519–552.[32] T. Verma, J. Pearl, Equivalence and Synthesis of Causal Models, in: Proceedings of the 6th Conference on Uncertainty in Artificial Intelligence, 1990, pp.220–227.[33] J. Zhang, Causal inference and reasoning in causally insufficient systems, PhD Thesis, Department of Philosophy, Carnegie Mellon University, 2006,available at www.hss.caltech.edu/~jiji/dissertation.pdf.[34] J. Zhang, Causal reasoning with ancestral graphs, Journal of Machine Learning Research 9 (2008) 1437–1474.[35] J. Zhang, P. Spirtes, A transformational characterization of Markov equivalence for directed acyclic graphs with latent variables, in: Proceedings of the21th Conference on Uncertainty in Artificial Intelligence, AUAI Press, 2005, pp. 667–674.[36] J. Zhang, P. Spirtes, Detection of unfaithfulness and robust causal inference, Minds and Machines 18 (2008) 239–271.[37] H. Zhao, Z. Zheng, B. Liu, On the Markov equivalence of maximal ancestral graphs, Science in China (Mathematics) 48 (4) (2005) 548–562.