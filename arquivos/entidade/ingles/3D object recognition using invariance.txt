Artificial Intelligence 78 ( 1995) 239-288 Artificial Intelligence 3D object recognition using invariance Andrew Zisserman a,*, David Forsyth b, Joseph Mundy c, Charlie Rothwell d, Jane Liu e, Nit Pillow a ’ Robotics Research Group, Department of Engineering Science, University of Oxford, Parks Rd, Oxford, UK h Department of Computer Science, University of Iowa, Iowa City, IA, USA ’ GE Corporate Research and Development, Schenectady, M: USA d INRIA, 2004, Route des Lucioles. Sophia Antipolis, France e Rensselaer Polytechnic Institute, Troy, Ne USA Received September 1993; revised November 1994 Abstract The systems and concepts described in this paper document the evolution of the geometric invariance approach to object recognition over the last five years. Invariance overcomes one of the fundamental difficulties in recognising objects from images: that the appearance of an object depends on viewpoint. This problem is entirely avoided if the geometric description is unaffected by the imaging transformation. Such invariant descriptions can be measured from images without any prior knowledge of the position, orientation and calibration of the camera. These invariant measurements can be used to index a library of object models for recognition and provide a principled basis for the other stages of the recognition process such as feature grouping and hypothesis verification. Object models can be acquired directly from images, allowing efficient construction of model libraries without manual intervention. A significant part of the paper is a summary of recent results on the construction of invariants for 3D objects from a single perspective view. A proposed recognition architecture is described which enables the integration of multiple general object classes and provides a means for enforcing global scene consistency. Various criticisms of the invariant approach are articulated and addressed. 1. Introduction The computer recognition the last 25 years. It is now widely accepted of objects has attracted considerable that object recognition, research effort over in the setting of real * Corresponding author. E-mail: az@robots.oxford.ac.uk. 0004-3702/95/$09.50 SSDI 0004-3702( 95)00023-2 @ 1995 Elsevier Science B.V. All rights reserved 240 A. Zissermun et al. /Arrijicral Intelligence 78 (1995) 239-288 in a scene It is also accepted that the most reliable the use of object models is derived in the form of 2D geometric shading. Thus, object recognition world scenes and based on a single perspective view, is a difficult problem and cannot to guide the processing of image data and be achieved without to confirm object hypotheses. information which from a geometric description of the object based on is available to, for example, its projection its intensity systems draw on a library of geometric models, which usually contain known objects, or image sequence. Recognition in an image can be explained object. the shape and appearance of a set of image as a perspective projection of a geometric model of the if any, of those objects appear if the geometric configuration image features, as opposed to determine which, is considered in a given information successful about At present, 3D recognition tively simple objects. Progress systems generally have small modelbases containing rela- is needed on three fronts: l Larger modelbases: Systems should be able to thousands of models. The methods of pose consistency to deal with modelbases containing hundreds Section 1.1)) which are commonly are infeasible with such sizes clearly for large modelbases because of the computational requires some partitioning of the modelbase. in used for modelbases with only a few objects, expense. Coping (reviewed l More general shape models: Typically polyhedra are used, which are a poor model is required. for curved objects. A direct representation for nontrivial curved objects l Automatic segmentation and grouping: This is the process, also called figure-ground and grouping. including separation, of extracting outlines without such grouping In addition mechanisms is a significant barrier to representing for their feature segmentation a framework the background image feature groups which correspond to individual object and other occluding objects. The lack of in current systems. the shape of 3D objects, models will have to provide to successful recognition the camera This paper establishes for the next generation of 3D model-based systems which will have large modelbases, with objects partitioned vision into a images of the objects could be partially occluded, and library. The object classes are defined in terms of symmetry or other 3D geometric constraints. The constraint invariants of a 3D object in the class to be extracted from a single image of the that enable recognition number of different 3D object classes. Recognition scenes, where the scene might contain objects not in the model geometrically enables object outline; grouping. relations on the image outline is from single perspective and also generates is uncalibrated, invariant Although the paper concentrates in weak-perspective applicable linear approximation is small compared lines are imaged as parallel valid for weak-perspective. to distance to perspective, (or “affine”) images, imaging on perspective the methods are, of course, a is appropriate as a camera model when object relief is that parallel world imaging are also situations. Weak-perspective, for perspective computed from the camera. A consequence lines. Invariants A major constraint underlying the work presented here is that recognition view of a scene. Our motivation is that this restriction applies one uncalibrated of the current and future applications image database query processing, for object recognition, image-hypertext and is based on in many such as aerial surveillance, images if more editing. Even A. Zisserman et al. /Art$icial Intelligence 78 (199.5) 239-288 241 are available, generally be known up to some ambiguity views. for example in the case of video processing, initially. Any grouping, recognition from a single image, can be propagated camera calibration will not hypothesis, or object recovered to subsequent to advantage A central question explored in this paper is the nature of the shape representation representations systems. However, under the most general imaging conditions, (metric) nec- are routinely used in many struc- recognition transformation for recognition. Euclidean essary existing ture is recovered up to a projective than Euclidean). We demonstrate nition. A stratification groups: projective, tation hierarchy projectively concerned with the projective other strata will be used to advantage at particular is progressively more of representations affine, similarity that projective equivalent need not be affine or similarity (i.e., a more general transformation representations are adequate for recog- is provided by the hierarchy of transformation and Euclidean. This represen- two objects (scaled Euclidean), restrictive; for example, that are stratum, since this covers the “worst-case” equivalent. We will be primarily ambiguity. The that is the use of quasi-invatiants A related area property or relation over a useful range of views. Invariants of other transformation given above are sometimes quasi-invariants in grouping Examples of quasi-invariants are given in the paper. to projective and partial invariant indexing though is not [5]. Quasi-invariants even stages of the recognition process. [4]. A quasi-invariant transformations, groups is an object is stable but in the hierarchy can be very effective they vary under perspective projection. Our geometric notion of class differs from the more usual functional one. For example, in our definitions, a vase is considered as a surface of revolution as opposed to a container for flowers and water. A geometric class is not specific to a particular object but instead relations. describes a family of objects which are unified by their common 3D constraint A number of examples of these 3D object classes are given in Section 3. from through image grouping architecture which integrates and 3D scene constraints. Recognition based on image curves, and subsequently We have defined a recognition ences each level of the architecture, the modelbase by a classification ticular model within many existing architecture, a large-scale This effort will culminate class of 3D structures with thousands of individual object instances these ideas. Class influ- to organisation of first proceeding of a par- the class using values of geometric attributes. This contrasts with identified. The demonstrates that is now warranted. a broad in the model library. combined with the success of existing system systems where a particular object in an object recognition based on an invariant that can recognise the identification implementations, implementation is class-based, recognition framework is directly system 1.1. Related approaches to object recognition Recognition is the establishment of a correspondence between features. Most recent approaches to those defined (similar The aim of grouping ground discrimination) come from a single object to recognition have been implemented indexing, and verification. in [ 271) : grouping, (also called perceptual organisution [ 371, selection, or $gure- to have is to provide an association of features together using in a scene. Features are typically grouped that are likely image and model in three stages 242 A. Zissermun CI ul. /Artificial Intelligence 78 (1995) 239-288 features, and features on a model [ 12,611. The indexing cues such as proximity, parallelism curvature image determines match is used to project hypothesis and model-to-image support. the consistency and approximate stage hypothesises [ 3,371 collinearity, in the grouped in the library. The final stage, verification, of this hypothesis with the image data. The image-model the model onto the image, and to test the validity of the model image determined by measuring an association between feature correspondences continuity There are three distinct categories of algorithm that have been used to compute correspondence: ( I ) Interpretation this has proved task as a search and then control reliable images are to include useful notions about [ 141. However, interpretation images of three-dimensional inefficient, for a small modelbase when single trees frame the model-to-image this search process. Although correspondence tree to allow all possible model and image feature associations, and prune recognition for planar object used [28], and has been extended by Ettinger how hierarchical object descriptions trees are not generally objects [ 2,28,47,48,5 sup-inf interpretation objects. Brooks’ work has been extended by both Fisher for different types of sensor and constraint parameterisations can be realised to work with single l] ). Interpretation for geometric have been suggested by Grimson trees are not restricted tree to account for tolerance framework able (though effective when 3D data is provided as direct input to the system the the to rigid objects; [ 81 allows reasoning used in ACRONYM interval constraints on parameterised [53] to treat framework. Other ways [ 191 and Reid (2) Hypothesise and test, also called alignment, [ 271. first aligns a model to yield an initial estimate of pose. This hypothesised [ 3 I] ture tested by searching model pose of data formats and feature curved surfaces have even been created (verification). for other model-to-image correspondence This algorithm has been [ I, 6, 16,24,38,68]. types implemented In fact, extensions to image fea- is alignment predicted by the for a variety to 3D [ 13,331. (3) Pose clustering the object pose from a group of in an accu- local groups have the same pose, a hypothesis called generulised Z-lough) (six degrees of is high-dimensional the estimate in pose space; is implemented by computing to a particular model, and storing if enough is formed. This approach features corresponding mulator for the model has the disadvantage freedom Two ways round ble parameters approach eliminates cells by constructing and on the expected error bounds of the pose measurements space), so searching this are to use a decomposition [ 44,671, or to use an adaptive Hough the requirement a quantisation that the pose space for 3D Euclidean (frequently for consistent pose is expensive. of the pose space into separa- [ 651. Another the pose space into rectangular to quantise that depends both on the estimates of pose, transform For a small number of models, to try to find image feature support [ 1,2,27,3 1,38,47,5 existing systems approach becomes computationally potential models two or three, for example for each model. This approach I]. As the size of the model library simply is typical of many this increases, to choose image features. That is, image It is then more effective too expensive. from the library based on the observed [ lo]. it is reasonable A. Zsserman et al. /Artificial Intelligence 78 (I 995) 239-288 243 feature measurements functions, of object pose. In constructing invariance plays a major role, since a model should be identified are used to index into the modelbase. such index irrespective 1.2. Geometric invariants in modelling and recognition Invariants an appropriate in determining For example, planes tangency transformation; also be computed. Examples are given in Section 2.1. are properties of geometric configurations which remain unchanged under class of transformations. Within the context of vision we are interested the invariants of an object under perspective projection onto an image. the perspective projection between object and image and values can such as intersection, for a planar object by a projective is a projective are unaffected transformation. collinearity, Properties however, invariant More formally, under a linear of coordinates, X’ = TX, the invariant, I(P), of a configuration P transforms transformation as Z(P’) = ITI”‘Z(P) in scalar invariants to projective in this paper. transformations, and is called a relative invariant of weight w, where P’ is the transformed If w = 0, the invariant We will only be interested is unchanged under transformations configuration. and is called a scalar invariant, In general we seek invariance so T is a general nonsin- the invariants coordinates. For planar configurations gular square matrix acting on homogeneous 3 x 3, and for 3D configurations a transformation, which is to measure the image may have a lower dimension matrix that covers a 3D Euclidean projection onto the image. For planar objects dimension This is discussed image spaces are no longer of the same dimension homogeneous 3.2. it is 4 x 4. Note that invariants are computed with respect to is a mapping between spaces of the same dimension. The goal from a perspective projection of the configuration, where than the object. We write P for the projection of the object followed by perspective the original and image spaces are the same represented by a 3 x 3 matrix. the original and and P is a 3 x 4 matrix mapping 3D in Section in Section 2. For three-dimensional and P is simply a projective the image plane. This transformation transformation is described coordinates in detail in detail objects, onto 1.2.1. Indexing One of the most important uses of invariants in vision recognition between based on the consistency a correspondence In traditional model-based hypothesising the hypothesis image features. This constitutes and is generally of a complexity each model must be evaluated. simultaneously linear systems (Section 1.1) , recognition is as indexing functions. proceeds by image and object features, and then evaluating of the best projection of the model onto the finding pose and performing recognition, in the number of models in the library, since An index function provides direct access to a certain model in the modelbase without the index constant about the model, or model pose in advance. retrieve a model information should uniquely Ideally, facilitating using specific function the library (thus from 244 A. Zissermun et ul. /Artificial lnrelligence 7X (I 995) 239-288 but in practice it is likely that a index. Even so, the search cost a is typically the full library. The index to the library), to linear, access time, as opposed small number of models are retrieved with the same is considerably vector of independent More formally: from that of testing invariant measurements. reduced below is considered the index index the library. The model features only, where f = PF, with F object features, and f features. Assuming features, images of the object then library values for M can be constructed that M can be computed is a function M(f) in isolation. to be a vector, M, which selects a particular of a set of projected object image from any image projection of the object simply by acquiring one or a few the corresponding For planar objects, P is a planar projective transformation, T, from the object in an arbitrary pose onto the image plane, and M(T(F)) = M(F), from a group of image features such as tonics, i.e., the index has the same value computed on the original object and after the transfor- (a scalar invariant). Each element of the index vector M is an invariant measure mation lines, points and plane curve computed segments. A typical example the same function to object and image, since they differ in dimension. However, again cannot be applied M is defined so that each element that is measured image. Examples are given in Section 3. invariant of the 3D structure in Fig. 1. For 3D objects from the perspective is a projective is shown 1.2.2. Invariance and representation The term “invariance” does not simply refer to the viewpoint-invariant measurement from an invariant value. For example, vector described above. The term also includes is distinct four collinear points. The collinearity between the points which of generic geometric important values. issue for representation the identification is independent classes, than the idea of an invariant the cross-ratio of the points of the cross-ratio is a projectively value. relations of invariant the computation of specific relation, which is an invariant value of relation invariant In the definition is often a more indexing invariant Another general aspect of the analysis. invariant It is often and algebraic geometric the first clue to the nature of invariants algebraic analysis can generalise and simplify additional insight. approach is the symbiotic the case that geometric of application insights provide for a particular object class. Then subsequent and in turn provide invariant computation, 1.2.3. Model acquisition from A model consists of the set of significant geometric images known up to a projective, or more Projective models can be constructed intrinsic camera parameters objects generally required. Model acquisition the model can be acquired restrictive, from images without or known 3D ground control points. features of the object boundary affine). (for example requiring knowledge of the In the case of 2D from a single image, for 3D objects more images are transformation is discussed further in Sections 2.3 and 4.3. A. Zissermun et al. /ArtQicial Intelligence 78 (1995) 239-288 245 Before proceeding mature system in object recognition of recognition to the case of more general 3D object recognition, we review a for 2D object recognition. This review will illustrate many of the issues by invariants and provide a context for our more general discussion architectures at the end of the paper. Notation We adopt the notation that corresponding entities by upper and lower case. In general for 3D quantities. Vectors are written in two different coordinate frames lower case is used for image in bold font, e.g., x and in typewriter font, e.g., c and C. With homogeneous quantities, are distinguished quantities, X. Matrices are written equality and upper is up to a nonzero scale factor. For smooth surfaces the projile (also called the surface generator, where rays from the optical centre are contained It is the image projection in the image. the apparent contour) is the outline of the contour in the surface tangent plane. of a surface curve, 2. The planar recognition system for planar object recognition is particularly The use of planar projective invariants and straightforward appropriate image planes covers all the major the composed tivity models (camera extrinsic parameters), plane affine transformation parameters. Consequently, of these parameters, have a high currency of the final projective Here we summarise the main because a projective transformation imaging transformations: effects of 3D rigid rotation and translation the plane-to-plane between object and projec- of the world to the image plane, and an perspective projection image which covers the effects of camera intrinsic invariants, which are unaffected with respect [ 40,49,54,56,58,59,69,70]. system for this domain features of a planar object the past four years. The projective to all in the system has the key advantages of simple model acquisition are used to construct has been developed during used images), index functions. Recognition invariants index value coincides with generated. Recognition joint hypotheses, provided are then verified. The system’ varying in [56]. levels of occlusion proceeds by measuring index vectors that associated with a model, a recognition (direct invariants or object pose computation, recognition representation that of shape from and the use of in the target image. The If the from the library. is to form hypotheses tested on a large set of images and under of this system appears to the same object are merged compatible. The (joint) to select models hypothesis and clutter. A detailed description hypotheses corresponding they are geometrically has been no need for camera calibration The projective nature of the representation is utilised at a number of stages process, for example recognition tion, any image provides a projective model of the object outline because object planes are related by a projective mapped by a perspective onto the image, and perspective in both model acquisition transformation. transformation This is because and verification. in the In acquisi- the image and is the object is a restricted ’ The system is called LEWIS. The motivation for this name is explained in Section 4.4. 246 A. Zlssrrnzun er cd. /Arti$cial Intelligence 78 (1995) 239-288 to the model transformation. form of a projective tively related is a projective transformation of the model image outline. Plane projective of projective closure 1. transformations equivalent is In verification, image outline. This follows because the target image outline of the object outline, which is a projective transformations to a single projective is projec- the target image outline transformation are a group, and a sequence (group transformation 2.1. Projective invariants used There are three different constructions lines; a conic and two lines; and a conic pair. For example lines are given by algebraic invariant used five in the system: the two invariants of five IN~~IIINs~II / N421I I h’s321 ” = IN42,lbkd’ ‘2 = lN4i2llNs2tl’ (1) (N;,kl is the determinant, and E = (11,12,13) is the homogeneous where Ni;k = (l;,l,i,lk), representation gives examples of these invariants from the images shown have varying degrees of perspective distortion. These are applicable that are “algebraic” frame invariants a concavity delineated by a bitangent. of a line: Ilx + 12~ + 11 = 0. (See 1451 for the other invariants.) Table 1 in Fig. 1, which to image curves smooth curve segments canonical from projective coordinates of are used. These arc constructed For nonconvex computed [45,58] tonics). (lines, a c Fig. I. The lines used to compute the tive-line planar projective invariant for the above images are highlighted in white. The values are given in Table I. Table I Values of plane projective invariants measured on the object, and from images with varying perspective effects. The values vary (due to measurement noise) by less than 0.4% Measured on Object Figure I (a) Figure I (b) Figure I (c) Five-line invariants II 0.840 0.842 0.840 0.843 12 1.236 I.234 I.232 I.234 A. Zisserman et al. /Art$cial Intelligence 78 (1995) 239-288 247 Edge Detection Feature Extraction InvarIant Formation Indexing Hypothesis Mergmg Verlficatlon R E C 0 G N I T I 0 N Library FormatIon L_ Joint Hypotheses f Results 7 Fig. 2. The recognition with associated paths. The recognition merging stages. confidence values. Many of the processes are shared by the acquisition system has a single grey scale image as input and the outputs are verified hypotheses and the recognition in all but the indexing and hypothesis to previous is similar systems system [27] is tolerance In all cases there if part of the outline i.e., not global, formed descriptions, are a number of different descriptors requirement tonics can still be extracted for any single object i.e., the invariants to partial occlusion, is occluded. This is a result of using semi-local like moments of the entire boundary, and redundancy: can still be invariant there for each object so that there is not an excessive In the algebraic case lines and to be visible. region if part of the curve is occluded. 2.2. Architecture The stages of recognition these stages extending in sufficient detail are shown in Fig. 2. In the following issues the important to expose sections we describe in for consideration these ideas to 3D object recognition. 2.2.1. Feature extraction and invariant formation The goal of the segmentation invariants. is the extraction of geometric primitives for lines and tonics, and curves, concavities delineated by bitangents. An example of algebraic In the algebraic case this involves straight suitable constructing for non-algebraic segmentation is shown in Fig. 4. 248 A. Zisserman et a/. /Artijicial Intelligence 78 (1995) 239-288 A local implementation of Canny’s edge detector is made of local image feature topology. In many recognition to subpixel accuracy. These edgels are linked into chains, extrapolating over any small gaps. Consid- erable advantage systems, is ignored; but we have found the local connectivity provided by edge1 chains and proximity, that feature grouping, based on the connectivity allows to the number of image features. to have a low complexity with respect of edge1 chains and fitted features is used to find edgels index formation For algebraic invariants, connectivity five-line invariants segments. For example, within single edge1 chains at a cost that is linear (i.e., 0( 1), compared to 0( I”) curve again provides an ordering points in the number of lines are attempted). if all groupings for the feature points used (bitangent [ 721) and only the two cases of global curve reversal have to be considered. from sets of consecutive and ordering of line lines in the scene the and cast tangent For concavities, enables efficient are formed linking Once sets of grouped features, are computed. Each set of grouped f, have been produced, invariants produces a number of invariant values which are collected invariant vector formed by the above process represents a point in the multi-dimensional invariant represented by a collection of points of which depends upon the measured variance to enable hashing. Each object feature group is in the invariant space, the size space. The space is quantised in the invariant value.’ features, or concavity that define a region the algebraic and canonical curve, generally The into a vector M(f). 2.2.2. Indexing to generate recognition hypotheses The invariant values computed in the library. values is generated pair) separately generate hypotheses. If the value for the corresponding from the target image are used to index against invariant recognition hypothesis (e.g., five lines, conic is in the library a preliminary object. Each type of invariant This process is made more efficient using a hash table that allows simultaneous indexing on all elements of the measurement not been any significant problem with collisions should not be confused with the intersection of object space. These the verification to date there has in the hash table. Hash table collisions 3 in index lead to erroneous hypotheses which cost some effort during stage, but are usually eliminated. vector. In the experiments invariant measurements intersections 2.2.3. Hypothesis merging Many collections of primitives may come from the same model instance: for example, an object consisting of a square plate with a circular hole in it admits four collections, lines. Each collection has an invariant each consisting which may generate a recognition compatible instance could explain all of them simultaneously. hypothesis. Such a set of recognition of a conic and two connected if a single model hypotheses is Prior 2 See Section 2.3. ’ A hash table collision occurs when a number of models have the same hash index. Such a collision can occur when the number of hash buckets is smaller than the model population or when the hashing function is not uniform and causes many models to hash to the same bucket. A. Zisserman et al./Artifcial Intelligence 78 (1995) 239-288 249 b anda conic three-lineinvariantthat Fig. 3. Hypothesis compatibility: (a) If the same model is indexed by a five-line invariant (due to lines li, i E {1,...,5}), then it is wise to verify both hypotheses together. The invariants are compatible if the ordering of the image lines are consistent with those on the model. (b) For a pair of concavity curves there are 8 distinguished points which could be used to form 2 x 8 - 8 = 8 different five-point invariants. Rather than computing so many, which is unnecessary, invariants are computed between the four distinguished points of each concavity, and the “central” point of the other. This yields four invariants, and does so using a symmetric construction. These invariants are sufficient to hypothesise compatibility. iscompatible with it (dueto C and li, iE {2,...,4}), to verification, compatible number of reasons why hypothesis merging hypotheses is desirable: are combined into joint hypatheses. There are ( 1) Backprojection and searching for image support is computationally it is more efficient to validate several hypotheses of the same object expensive and together. (2) More features facilitates more accurate (there are more matched model and image features), least squares calculation of the backpro- and transformation jection consequently (3) Many hypotheses a reduced error in measuring image support. cantly indexing increase confidence The hypothesis merging process indexed object based on is controlled (ordering plemented the feature groups used to compute each individual hypothesis. This is illustrated the same object in a single part of the scene signifi- that the match is correct. is equivalent the features which and geometric is illustrated by topological and connectedness) efficiently by a second use of invariants-this to forming an interpretation tree for the index a particular model. The merging consistency The topological compatibility. in Fig. 3(a). Geometric time joint consistency is im- invariants between in Fig. 3(b). 2.2.4. Veri$cation There are two steps involved in verification, both of which can reject a (joint) to compute a common projective transformation recog- nition hypothesis. The first is to attempt between The second transformation is to use this image, and then measure image support. the model features and the putative corresponding features to project the entire model onto in the target image. the target 250 A. Zissernmn et al. /Art[jiciul hfelligence 78 (199.5) 239-288 Incorrect hypotheses arise because grouped the matching model and image (within that coincides value used to produce to compute this will be over-constrained-many projective transformation be computed the projective are available. Consequently, transformation the error bounds) with one between if a common the model and more constraints image features happen to have an invariant in the library. The features invariants provide sufficient constraints In general image. than the eight unknowns of the cannot transformation is rejected. not to (within 5 pixels and 15”). If more than a certain (the threshold used is 50%)) there is is confirmed. The final as 0( 10”) edgels need to be mapped onto the image. transform equivalent and the hypothesis involves the distances using the 3-4 distance the entire model boundary, hypothesis lies close just image edgels with similar orientation proportion of the projected model data is supported sufficient part of the process Efficiency of Borgefors is expensive is improved by approximating support for the model, and the recognition [ 71. Backprojection the features are not projectively searching the features used to form the invariant. Projected mode1 edgels must and subsequent 2.3. Model acquisition and lihraq formation One benefit of using only projective representations, rather than Euclidean ones, is that a model can be acquired directly are required. Acquisition have to be matched entirely by hand between segmentation and invariant computation is simple and semi-automatic from an image. No special orientations or calibrations (for using curves do not for the same software instance, images), as used during recognition. A model consists of the following: a name; a set of edges from an acquisition in the backprojection to the edges; the expected they correspond. from a variety of “standard’ connectivity and geometric stage of verification); the lines, view and invariant values and to which algebraic (The mean and variance of the invariant of the object.); and, feature groups used in viewpoints relations between tonics fitted (used of the object concavities features and curve portions values are computed finally, the construction The library of joint is partitioned topological invariants. into different another sublibraries, one for each type of invariant for the conic pair). Each sublibrary then tagged with an object name, and is structured (e.g.. one for the five-line has a list of each of the invariant values as a hash table. invariant, 2.4. Recognition examples Only a small number of examples are included In each case successful recognition the image. Segmentation in the scene which are contained 56,591. outline onto two objects using algebraic clutter. 1049 invariants are computed which invariants computed for algebraic since others appear elsewhere is demonstrated features [45, the mode1 in Fig. 4. The recognised from these features despite substantial occlusion and index 41 hypotheses. These are converted by projecting is shown in the library are successfully a b c two objects Fig. 4. (a) A scene containing (27) superimposed by texture, and that some of the tonics correspond different single from the modelbase, with fitted lines (100 of them) and tonics in (b). These numbers are typical for images of this type. Note that many lines are caused to edge data over only a small section. The lines form 70 the lock striker plate matched with a invariant and 50.9% edge match, and the spanner with three invariants and 70.7% edge match. the two objects correctly line groups. (c) shows recognised, a b Fig, 5. Single concavities of the canonical The left-hand object gained 67.1% boundary representation are sufficient frame to recognise gives much better support, and the right object 8 1.6%. the two model instances shown tolerance to occlusion in (b). The redundancy than global shape methods. into 131 joint hypotheses4 stage verification, stage, based on image support. based on valid projective that have to be verified, of which 13 are rejected by first the second and 78 require transformations, Fig. 5 shows recognition based on canonical canonical of both types. Fig. 6 shows an example of recognition frame invariants can be independently frame invariants. The algebraic and applied to an image to recognise objects together. for both index methods 2.5. Summary of pelformance Fig. 7 shows data collected over fifty evaluations of the recognition the modelbase was placed in which in a scene and partially occluded by a single object system from 4 The joint hypothesis list consists of combinations of compatible hypotheses, together with all the original hypotheses. 252 A. Zisserman rr a/. /Artificiul Intelligence 78 (1995) 239-288 Fig. 6. A demonstration image. The bracket that both types of invariant index can be used is indexed using algebraic invariants and the spanner to recognise objects is indexed using the canonical in a single frame signature. that are not in the modelbase (clutter). The average number of hypotheses other objects is plotted. The first model added computed as more models were added to the library always corresponded in in the scene. With 33 models the library, on average 15.8% of the hypotheses were for the correct model. Although predominately the graph has a very low gradient. to the actual object to the library linear, if an alignment The real benefit of indexing becomes apparent when one considers how many hy- the same for each image, for each model feature group in the library there are four or five feature groups per object and so the situation would be for the entire modelbase com- is used. As these all have to be verified potheses would be produced grouping methods. On average, over 2000 feature groups are produced and so 2000 hypotheses would be generated (generally far worse). This would result in about 7 x lo4 hypotheses pared to fewer than 60 produced when indexing it is clear that indexing produces a dramatic in the system efficiency. is used, maintaining improvement technique 2.6. Appraisal This system is an effective and reliable recognition system, and demonstrates a number of features that are likely to be important in building l Hypothesis combination. Simply verifying each indexed model features. Hypothesis for complex objects with many ticularly effective way of combining to obtain a single recognition semi-local information hypothesis. the next-generation system: is prohibitive, combination par- is an from different parts of the scene l Untrustworthy und expensive verijcation. Verification is neither cheap nor reliable, for distance as it involves backprojecting image events. Verification scores can between to false be incorrectly positives. The next-generation system must have more extensive verification mech- anisms using region properties as well as edge geometry. Also much more careful a large number of features, and testing those features and possibly unrelated clutter and texture which to background high, due leads A. Zisserman et al. /Artificial Intelligence 78 (I 99.5) 239-288 253 # hypotheses 1 z - --Zwithout indexing 2ooo- looo- o- 0 with indexing # models 5 10 1s 20 25 30 35 Fig. 7. The number of hypotheses that have to be verified as the number of models in the library is varied. The results show an average over fifty scenes containing only one object in the library, but with other clutter and occlusion present. Over 2000 indexes are created for the scene, which corresponds to the number of hypotheses that would have to be verified per model feature group if alignment is used. Therefore, there is a rapid linear growth in the number of hypotheses created as the model base is expanded. However, the number of hypotheses created through indexing remains substantially lower-there is a linear growth, but with a very low constant of proportionality. analysis of edge and junction constraints be supervised by the model hypothesis. intensity imposed by the model. For example, events must be carried out with respect specialised corner detection to can l A need for global scene analysis. In many cases, ambiguities arise which must be image consistent? by global e.g., A is on top of and partially occluding B. In this case we can for B, available settled globally by a scene analysis line come from object A or object B? Are the recognition The relationships, predict once A is recognised. hypotheses can be augmented the features which are potentially for example, does a given for a model hypothesis lack of local support to support hypotheses approach: Next, we take up the problem of 3D object the existence of invariants discussed. for the perspective projection recognition. First, the central question of is of general 3D structures 3. Extending invariant descriptions to 3D structures Much recent debate has focused around a theorem, proven by a number of authors [ 9, for a 3D set of points from a single view. The theorem has frequently been misinterpreted 11,421, which states that invariants cannot be measured position that no invariants the theorem the points must be completely unconstrained can be formed for three-dimensional objects from a single to hold, however, in general to mean image. For (like a cloud 254 A. Zis.wrrnor~ rt cd. /Art#ciul In/elli~ence 78 (199.5) 239-288 Fig. X. A “butterfly” configuration ol stx 31) points with a projective invariant measurable from a single perspective image. Points ABCD and CDEb’ lie on two planes intersecting in the line CD. The lines AB and EF intersect the line CD generating four collinear points. This construction can he carried out in 3D and the image to generate corresponding points. The cross-ratio of these points is the projective invariant. Note that the planes can articulate about the line CD without altering the value of the cross-ratio. Many analogous structures exist e.g.. if the points A8 arc replaced by a line. of gnats). six points constrained have a cross-ratio the entire 3D structure, contains only four points invariant from points alone). If a 3D structure is cotutrait~ed, then invariants to lie on two planes that can be measured in a “butterfly” configuration, in the image. This is a projective are available. For example, as in Fig. 8, invariant of since each plane invariant, to form a plane projective and not simply a disguised planar (five coplanar points are required in space in general position In fact, a set of points is a poor model of what we see: the world is full of curves, polyhedra, and surfaces; sets of isolated points are an in the case of irregular occurrence. An analogue of the above “no-invariants” in a single surfaces, would be to ask whether a generic surface has invariants measurable (from image the sign of the profile curvature the profile of invariant can be obtained. A similar result holds for a transparent surface) no projective space curves. However, from a single if the surface satisfies constraints, much can be recovered [ 321) and the Euler characteristic than qualitative descriptions image, as the following from its profile. Other such as nonconvexity section demonstrates. theorem, (from 3. I. Object classes and grouping strategies invariants of the 3D surface can be recovered The form of the constraint on the object defines an object class. The class determines both the process by which the 3D invariants are measured in images, and the particular that are applied during “early vision”. For example, segmentation surfaces of revolution define a class, with a specific vase or wine glass being particular instances of the class. Projective from the image profile, and further “sides” of the profile are projectively (Section 3.5). That is, one side can be mapped onto the other by a projective equivalent transformation. The segmentation for this class is guided by the association of these projectively this notion of geometric class from the idea of a generic It is important is not the same as the rype. For example, type category of wine glass. There can be many different shapes of wine glass generic but the class of rotationally the functional notion of a wine drinking container. A related discussion of class is given by is still larger and does not capture related to distinguish the class of rotationally symmetric objects symmetric objects the two matching image contours. and grouping A. Zisserman et al. /Artificial Intelligence 78 (1995) 239-288 255 [42] who contrast the notions of generic and specific classes with Moses and Ullman regard to recognition Another significant functions. aspect of the class definition in the image. This consideration and test paradigm of conventional model-based can be measured and verified from the hypothesise operating on specific objects. Here, the class assumption without rotationally planar projective when a pair of image profile curves are hypothesised to the full chain of recognition object, transformation committing symmetric processing. For example, for a the two “sides” of the image outline are related by a tested to an object of class (Section 3.5). This relation can be immediately as belonging is its imposition of constraints which is a significant departure systems confirmed can be immediately recognition rotationally symmetn’c. In the following sections we catalogue a number of object classes where each is defined by an associated constraint. and other geometric consequences, In each case the recovery of invariants such as invariant relations, described. is illustrated 3.2. Dejinitions-3D projective invariants In what follows, we assume a perspective camera with unknown and measure only projective properties only projective properties of the 3D objects can be recovered. Algebraically, is modelled in the image. In turn, this means as x = PX: internal parameters, in general that the camera where scaling: (x, y)T are image coordinates, in this case, k = (p31X + p32Y + p33Z +p34)-l. and (X, eZ)T world coordinates, (2) and k is a We now introduce 3D projective that we can hope invariants These are invariants under projective Je written as: of P3 can 1 to recover invariants because they are the basis from a single view of a constrained transformations of P3. A projective for image structure. transformation k X’ Y’ Z’ 1 i are required the appropriate the fourth coordinate is one. Fifteen scaling to ensure where k is again transformation matrix up to an arbi- to define the 3D projective parameters to construct a projective coordinate trary scale factor. Thus five 3D points are sufficient system. A sixth point will in the projective basis defined by the other five. These 3D point invariants can also be interpreted as the cross- then have invariant 3D coordinates 2% A. Zisserman et ul./Artijicial Intelligence 78 (1995) 239-288 ratio of tetrahedral volumes computed by taking determinants at a time. For example, an invariant for six 3D points is given by of point coordinates, four ~~~~s(XI,XZ,XZ,X~,X~.X~) = /XI x2 x3 x4/ /XI x2 x5 x6/ /XI x2 x3 &I IX, x2 x4 X6/’ where X, = (Xi, E, Z;, 1 )T. This invariant has the familiar property of invariants that i.e., both the value and the form of the expression are unaffected by the transformation. By assuming that a set of constraints hold among the 3D projective point set, it becomes possible following section interpretation illustrates for the measurable invariants. to measure 3D projective invariants the nature of these constraints invariants of a in a single view. The and provides a geometric 3.3. Constrained point sets that an invariant to predict whether is or is not possible, to be true. A complication in general from images, by counting invariants of a three-dimensional the number of image measurements structure It is possible can be measured available. While such counting arguments cannot cover every degeneracy, and therefore never offer a proof is likely configuration, isotropies. An isotropy of a configuration. rotation about reduces the effective number of transform parameters, and generally of invariants. is the existence of is an action of a transformation which does not alter the geometry the tangent direction of a line or the centre of a circle does not affect the structure. Therefore an isotropy the number the number of parameters of a transformation, the degrees of freedom of a geometric they offer a useful guide For example, in counting translation increases to what along and Consider a 3D configuration M. Plane projective invariants are denoted 12, and pro- jective invariants of 3D denoted 13. Then, For m perspective recover nh functionally M from image images of M, if there is no isotropy group acting in P3, then to structure invariants of the three-dimensional independent information alone, the following inequality must be satisfied: m x ni2 3 nj, + 3m, where nf2 is the number of functionally of the image of M. If there is an isotropy group of dimension then (provided dim 1~ < 3) the following independent inequality must be satisfied: plane projective invariants (dim Is) acting, m x n12 > nh + m(3 - dimIs). We sketch the reasoning when there a single image. The invariants of the configuration image projective consisting is no isotropy group acting are functions invariants only of the projective of M taken together with the optical centre, for the case of A. Zisserman et al. /Artificial Intelligence 78 (1995) 239-288 257 of P3. This projectively the image plane geometry distorts is that the projective are unaffected. The can depend only on the rays linking 0 to points of M, and the image projective and the 3D configuration This means therefore, on the optical centre 0 as well as on M. Since transformation transformation. by only a plane projective a projective and the image plane. However, 0. To see this, consider the {M, 0) configuration transformed invariants of both the image configuration image projective depend, invariants are unaffected by the position of the image plane, 2D projective of the three unknown or more such image contribution of the optical centre. (in principle) it is possible coordinates invariants, invariants image invariants and the 3D projective object invariants of the centre of projection. Provided to eliminate the relationship between the is a function only there are three the (unknown) argument invariants then simply in m views the number of unknowns relates there are 3m unknowns The counting of measurements: unknown 3D projective is n12 in each of the m images. Note that, like most such arguments, necessary counting fact they cannot. The significance analysis may be useful. but may not be sufficient; indicates can be measured of the argument that invariants this means argument the condition that there could be cases where is the in is that it indicates where a further from the image, when and the number for the optical centres, and nl, for the configuration M; the number of measurements As an example, consider the case of six points in space which have three 3D projective above. configuration. If we specify, or assume, are zero, which corresponds as discussed then we can compute the values the value of the third from a single in Fig. 8 is an example where we assume invariants, invariants, called butterfly configuration 3D invariants in the six-point degrees of freedom projective group gives nl, = 4. For six points of freedom (3 for each point, projective group, gives nl, = 1. There are also three unknown of projection. Thus the counting argument in a single view, i.e., measured for two of the image. The so- that two of the to the coplanarity of two sets of four points the number of less 8 for the plane there are 16 degrees less 15 for the 3D coordinates of the centre shows that the unknown 3D invariant can be is 12 (2 for each point) in space on two planes constraints) argument goes as follows: less 2 for the planarity for the image points The counting 1x431+1x3. Table 2 Examples of the counting argument with two points of wing replaced by line (four points, one line) ; C = butterfly with lines on both wings points, structures. A = six-point butterfly; B = butterfly (two for various butterfly-like two lines) dof dim Is “13 “12 dof of 0 that matter Counting relation A 16 0 1 4 3 B 14 2 1 2 1 C 12 4 1 I 0 4=1+3 2=1+1 1=1+0 258 A. Zissermun et trl. /Artijiciul Intelligence 78 (1995) 239-288 for a number of butterfly analogues Similar counts Table 2. Sparr [ 621 has constructed many other examples of butterfly-like and provides a method for generating such invariants algebraically. in the case of isotropies are given in configurations, from In this case, their profiles. The counting argument is used in this manner to focus attention on configurations algebraic [ i(d + invariants. The profile where invariants may be available. As a further example, consider surfaces 3) (d + 2) (d + 1) - has degree d (d - I ) . and has [ $ ( I -d +d2) (2 -d +d2) - 1 ] - 8 functionally projective exceeds recover be recovered, the number of invariants of the surface, and so it is reasonable invariants independent invariants. For d > 2, the number of invariants of the profile substantially the surface has degree d, and has independent projective is complicated; details are given in [ 201. from the profile of an algebraic surface. In fact, such invariants IS functionally the procedure recognising to expect though I ] - to can 3.4. Repeated structure Structures that repeat in a single to multiple views instance of the structure. Thus, for example, a view of two similar cars in a to translations image of a scene are equivalent of one another, is equivalent of a single car park where the cars are parked within a stereo pair of images of one such car, with the cameras The 3D shape of the car can be recovered by the familiar formally, related by a pure translation. techniques of stereopsis. More A repeated structure tion I, which generates a transformed in the same perspective S’ are viewed copy of S, image. i.e., S’ = 7(S). Both S and is defined by a geometric structure S, and a 3D transforma- is mathematically image of a repeated structure identical the two cameras are related by the transformation In many cases the internal calibration parameters of the camera will be unknown. case a single stereo pair where S’. It has been shown by Faugeras out stereo reconstruction can differ transformation. value as projective the reconstruction images, geometry of the object by a 3D projective invariants of this recovered structure have the same between S and [ 301 that if one carries invariants measured on the actual Euclidean [ 151 and Hartley et al. the actual 3D Euclidean from two uncalibrated Thus, 3D projective to an uncalibrated perspective structure. In this from the case where 7 between corresponding structure can be defined within a features is a 3D trans- it can be 3D structure can be recovered. Lines in 3D and are imaged as a set of In this case, The equivalence with stereo means that epipolar i.e., S and S’ are related by a simple 3D translation. [ 4 I ] that afine, relationship rather the geometric than projective, image and represents single on the object copies. As a simple example, consider lation, shown joining corresponding lines converging point are the analogue of “epipolar only, from now on. For translation in S and S’ relation auto-epipolar the more general idea that repeated 3D geometric points on S and S’ are parallel lie on the same epipolar correspondence. This correspondence structure line. We call to a vanishing point. These imaged correspondence lines and vanishing lines” and “epipole”, and these terms will be used points there is a single epipole and corresponding this convenient correspondence relation is an example of imposes 2D constraints on A. Zisserman ef al. /Artificial Intelligence 78 (1995) 239-288 259 corresponding tion. image features which can be used to advantage in grouping and verifica- terminology We reserve the epipolar for the case where the centres of projection of the two cameras are displaced. For some repeated structures, between S and S’ does not alter the camera centre and thus does not yield an epipolar structure. However, in the image which to construct a correspondence is not an epipolar geometry but has many similar advantages. An example of this is given in Section 3.5 for surfaces of revolution. it is still possible the transformation structure Thus we have two recurring in most cases where object class produces image view: issues that arise in the context of repeated structures and in a single that can be measured invariants ( 1) the computation (2) the correspondence and associated grouping relationship between strategies. of image-measureable 3D invariants; the imaged features of the 3D structure, In the next few sections we review some mature examples of repeated structure where the discussion is organised around these two issues. [ 36,461 3.4.1. Bilateral symmetry In the case of a single bilateral symmetry, is equivalent is transformed to two identical on one side of the symmetry plane. A single camera object camera similar observation was made in [ 26,391, Below we give examples symmetry. to the other by a reflection of 3D point cameras, viewing imaging a bilaterally the repeated structure is the half object symmetric the half structure, where one in the object symmetry plane. A though in the context of a calibrated camera. sets and space curves with a single bilateral 30 geometry Lines joining corresponding points allel and orthogonal provided by these correspondence correspondence points. lines intersect to the plane of symmetry. There (on either side of the symmetry plane) is a natural coordinate are par- system (Fig. 9). The directions and the symmetry plane the symmetry plane at the midpoint of the corresponding Measuring invariants Perspective projection does not preserve midpoints. However, can be computed plane). There (see below). All 3D midpoints is a projective transformation midpoints the symmetry midpoints can be measured and the 3D points on the plane of symmetry. Thus planar projective in the image from the computed midpoints. (see The image of the 3D midpoints points with a point at infinity have a harmonic line joining two corresponding Fig. can be computed using a property of equally spaced [63] ): three collinear points, separated by the same distance, and taken the point at infinity on the cross-ratio. Since (see below, and in the image can be is imaged as a vanishing point the position of the midpoint it can be observed. Thus, points lo), are coplanar the images of the 3D lie on (they the set of imaged invariants between i: ‘Midpoints Fig. 9. The natural coordinate frame Ibr an object with bilateral symmetry. The XY plane is the plane of reflection. and the Z axis is parallel to lines joining corresponding points. Note, all midpoints are coplanar. from the image coordinates of the corresponding computed coordinates of the vanishing point. Furthermore, cross-ratio with respect geometric methods pairs or triplets. to three other points for computing since computing points and from the image a point that has a fixed there is a unique solution. Other are available, based on point is linear, the imaged midpoint The 3D structure can be reconstructed up to a projective equivalence with uncalibrated from this recovered to better than a projective in the “natural” coordinate [ 15,301. 3D projective stereo In the case of bilateral symmetry, ambiguity because of the orthogonality frame [ 18,561, structure. ambiguity, based on the invariants can be measured is recovered available constraints structure Cosrespondence arid grouping The epipolar structure in this case arises from the parallel lines joining corresponding these correspondence image (the epipolars) to a family of lines converging (on each side of the object). Under perspective projection, points to a single vanishing point lines points (the epipole). The epipole can be determined using are found by (Fig. IO). Once the epipole has been computed, a ID search on the epipolar that define the object class not only show how invariants may be recovered, but also facilitate and direct the image grouping. two pairs of corresponding line. This is a recurring further correspondences constraints theme-the We demonstrate two examples of bilateral symmetry, a polyhedral point set and a space curve. A. Zissennan et al. /ArtQicial Intelligence 78 (1995) 239-288 261 // corresponding points a IO. (a) The epipole can be located using the intersection of lines between two corresponding points on symmetric object (the points are marked by solid circles). Epipolrus can then be constructed Fig. a bilaterally through the epipole to aid correspondence. (b) Typical corresponding points determined in this manner. a C b a Fig. 11. Three-dimensional marked on the stapler of the original recovered structure. structure is recovered, module a projectivity, from the single view of the points in Fig. IO(b). Four typical views are shown with only (a) at a viewpoint close to that the accuracy of the image. Note the collinearity of the line segments this demonstrates in (b), ( 1) 30 poZyhedron. Fig. 1 I shows different views of the 3D reconstruction from a single view. The reconstruction is placed of a of the object shape, but any projective in a Euclidean frame stapler obtained frame to give a normal presentation could be used. 262 A. Zissermun et ul. /Artijicial Intelligence 78 (1995) 239-288 c d 12. A single view of an object with a plane of bilateral a full 3D projective symmetry, reconstruction. Only two pairs of distinguished from surface markings and can be used to determine structure an arbitrary number of correspondences Fio all& these are recovered Using this epipolar are shown of the 3D reconstruction planarity of the handle recovered such as a teaspoon, points are needed for the approach, the epipolar structure of the image. can be produced. Four different views the image. The construction works very well: note the in (b), and the full 3D shape in all of the images. computed from is sufficient to (2) A space curve. Corresponding points on the two imaged space curves are de- termined using for the outline of a spoon are shown in Fig. 12 (the 3D projective has again been constrained the epipolar geometry. Four different views of the reconstruction representation to lie in a believable Euclidean frame). The reasoning outlined above can be applied symmetry try. [ 181 and to objects projectively 3.4.2. Trunslational repetition to objects with more than one bilateral symme- to ones with bilateral equivalent In this case the structures, S and S’, are related by a 3D translation. As described from a single the structure of S can be recovered up to an affine ambiguity, above, image of the duplicate structure. image invariants are computed in this projective coordinate the perspective ambiguity using uncalibrated invariants from is recovered up to a projective [ 631 is determined to its counterpart on S’, so the intersection of corresponding Measuring in three stages. First, Aftine stereo. Second, structure frame as follows: a the plane at infinity lines line on S is parallel is a point P on the plane at infinity. The image, p, of P is computed by intersecting the imaged corresponding be determined is projectively structure X4 = 0. The structure measured Euclidean its 3D position, P, can the form invariants transformed is then known up to an affine ambiguity, this structure have the same value as invariants measured on the 3D such that the plane at infinity has the standard by stereo. Three such points determine lines. Since p lies on both from structure S. the plane at infinity. Third, and affine lines A. Zisserman et al. /ArtQicial Intelligence 78 (1995) 239-288 263 d Fig. 13. One object are shown (d) Affine invariants computed (a speaker) in (b). The translation vector repeated under translation. The epipolar correspondence lines for image is different for images from these images are compared (a) and (c) and the same between in Table 3. (a) (c) and Table 3 Comparison of one comer of the speaker fairly stable, even though of 3D affine invariants computed for the speaker is the 3D position in an affine frame defined by four other points on the speaker. The values are translation vectors and viewpoints from Fig. 13. The invariant the images have different Image (a) -0.2249 -0.0642 I .2833 Image (c) -0.2324 -0.0685 1.2979 Image (d) -0.2317 -0.0626 1.2849 Correspondence and grouping As in the bilateral symmetry case, lines joining is again auto-epipolar corresponding (all corresponding 3D points are parallel. lines intersect in a invariants are calculated in Fig. 13. The The image correspondence single epipole) . As an example, structures shown in each case demonstrating i.e., S. Affine using given in Table 3. The differences between small, even though are computed invariants the epipolar geometry of the translated translation that the invariants the translation vector between between the duplicated are associated with the structure from the images of two translated polyhedral structure differs itself, for the 3D vertex positions which are computed are from each image are the speakers and the viewpoint varies copies. The values of the invariants the invariants computed 264 A. Zissernum e/ 01. /Artificial Intelligence 78 (1995) 239-288 significantly. connected, but this example translation vector as well. In many cases of such repeated structures, illustrates that the affine invariants the object copies are rigidly of the are independent 3.4.3. Other repeated structures The notion of structure It is not necessary situations. translation. The copy transformation still preserving of the object geometry space. repetition under a transformation to more general that the copies be Euclidean equivalent and repeated under transformation whilst can be a full 3D projective is extensible an epipolar correspondence within the image. The 3D reconstruction is then known only up to a 3D projective transformation of In the case that there are three or more Euclidean equivalent can be recovered up to a 3D similarity. This follows to three views of a single object demonstrated It is also that structure can be recovered up to a 3D similarity to speculate about approximately-repeated taken with an identical interesting structures, the geometry from the equivalence of this case it has been camera, where repetition occurs [ 171. structures. Suppose but is only an in natural that the invariants which one can repetition will not be very far from it or is texture which can in a bunch of grapes, is not repeated according to a rigid 3D transformation to such a transformation. and vegetation. This approximate It seems form of the approximate of the actual structure. For example such as animals from an idealised that the structure approximation objects compute an invariant description can be assumed that each grape perhaps even a scaled Euclidean be thought of as a statistical is copy of the other under an affine transformation transformation. Another example repeated structure. The image curves transformation, 3.5. Rotational symmetr) Surfaces of revolution attention, have had considerable [ 131, or as a special case of a generalised though generally with cali- cylinder [ 52,711. brated cameras Projile geometry forming the two “sides” of the profile are related by a plane pro- that T’ = I. Such a projective transformation (whose conjugating [63]. It arises reflection is a conjugate T, with the property To see this, construct jective is called a planar harmonic homology age transformation transformation). the optical centre. The surface cone of rays through profile when it is intersected with the image plane. Clearly, in general, is perpendicular but the profile for any other perpendicular related by a mirror symmetry the optical centre and tangent to the plane of symmetry, then has a mirror symmetry the plane containing space curves, image plane then in this case because element the im- is a projective the axis of the surface and in this plane, as does the the the contour generators are, in space. If the image plane symmetry; to the surface. This cone yields the profile has a mirror is within a projective transformation of the plane. In this case, there try plane does not move is no epipolar geometry defined, since reflection the optical centre. However, a correspondence in the symme- still relation A. Zssernuw et al. /Art$cial Intelligence 78 (1995) 239-288 265 Fig. 14. The profile of a surface of revolution is projectively equivalent to two curves with bilateral symmetry. Under a projective transformation parallel correspondences (left) converge to a vanishing point (right). Corresponding points x H x’ are related in this case by a particular plane projective transformation, T, called a planar harmonic homology. The transformation has a line of fixed points, the image of the axis of symmetry, which result from two of the eigenvalues of T being equal. There is also a fixed point, et, not on the line, called the centre of the homology which defines correspondences between symmetrical points on each side of the contour. That is, corresponding point pairs and the centre of the homology are collinear. The cross-ratio of et, the corresponding points x, x’, and the intersection of their join with the axis, is harmonic. (The line of fixed points is ez x e3, where ez and e3 are the eigenvectors with equal eigenvalues. The third eigenvector, et, is distinct and nonzero, and is the centre for a pencil of fixed lines.) is generated by the planar homology exists and nar harmonic homology Fig. 20(b)) for which For planar homologies lines which define correspondence line of the pencil, eras. the characteristic there is a fixed point which between (see Fig. 14) is a special case of a planar homology is harmonic invariant of the homology the opposing sides. A pla- (see [ 631. is the centre of a pencil of fixed lie on the same cam- points in the same manner as the epipolar geometry of translated pairs. That is, corresponding of “corresponding” Measuring invariants The intersections object’s axis. The image between planes bitangent independent. This is shown schematically measure a cross-ratio symmetry). surface In this manner a projective [21,35,45]. The construction of the intersection points to the surface and the 3D object axis. This point is viewpoint- profile bitangents points are projections lie on the projection of the intersection in Fig. 15. Four such points are sufficient to (the points are collinear in space, all lying on the axis of rotational invariant (the cross-ratio) is associated with the extends the intersections to straight homogeneous of corresponding generalised profile bitangents 3D point, and are collinear, so cross-ratios images of a surface of revolution with the calculated cylinders (SHGCs) to a correspond can be formed. Fig. in invariants given [3,35]. Again, viewpoint-invariant 16 shows Table 4. 266 A. Zissernmn et al. /Artificial Intelligence 78 (I 995) 239-288 symmetric object, and the planes bitangent Fig. 15. A rotationally the optical through centre. are shown. It is clear from the figure that the intersection of these planes is a line, also passing the optical centre. Each plane appears as a line in the image: the intersection of the planes appears as a point. p, which is the image of the point, P, at which to the object and passing the axis of symmetry. the bitangent planes intersect through Fig. 16. Five perspective given in Table 4. images of a surface of revolution at different inclinations. The invariant values are is the inclination Table 4 Stability of invariants angle ratio) and projective extreme angles, whereas place of the axis of the lamp-base for a surface of revolution. The invariants are computed from measured points. The (Fig. 16). Typical affine (length invariants are shown. Note that the value of the affine invariant changes at invariant remains stable to the second decimal to the camera plane figures the projective to two significant (cross-ratio) Angle 45.0 40.0 35.0 2S.0 IS.0 0.0 Cross-ratio 0.486187 0.490.561 0.486796 0.486640 0.486260 0.494849 Lzngth ratio I .40862 1.98153 2.14017 2.38409 2.70539 4. I3687 A. Zkserman et al. /Artificial Intelligence 78 (I 995) 239-288 261 Correspondence and grouping AS described surface can be separated two “sides”, which are related by a planar harmonic homology, T. There are a the profile of a rotationally symmetric above, into number of consequences of this result: (I) The two sides of the profile can be grouped by associating equivalent. For example, by matching projectively can be achieved automatically curves which are con- by the planar equivalent (2) system described projectively cavity curves. This correspondence recognition If the projective harmonic homology, surface of revolution. This is simply real imaging conditions transformation in Section 2. between related curves then the grouped curves can be ruled out as arising tested by checking two projectively if T2 = I. is not a from a (3) Under the transformation profile will be close to affine. This quasi-invariant ways: first, lines joining corresponding be almost parallel. Second, match concavity T relating condition the two sides of a can be used in two points on the two sides of the profile will (not scalar) affine invariants can be used to relative [43]. curves (4) T provides point-to-point can be used to disambiguate to repair missing profile portions, the other side of the profile. correspondence between bitangent matches. This correspondence this can be used filling in gaps by transforming over points from the sides of the profile, (5) The projected axis can be determined directly from the projectivity as a line of fixed points of the homology [63]. To illustrate the power of this grouping of various into sets, and the profile curves corresponding constraint, Fig. 17 shows an image with are to each set are grouped. The and relies only on the properties of the homology between types and sizes. The matched concavities many surfaces of revolution partitioned entire process symmetrical is automatic portions of the profile. 3.6. Canal surfaces A canal surface are a fixed perpendicular the envelope of a sphere swept with the centre on the curve. Common in plumbing. pipes or tubes such as occur for which the generating is the parallel surface of a space curve. It is the locus of points which it can be generated as are In the following we consider canal surfaces curve, LY, is planar. For such surfaces we have: from the curve. Equivalently examples distance conditions, Under general viewing rise to two inflections contour generator at the pre-images of the profile inflections, the generating curve gives in the profile, one on either “side”. The tangents on the and the tangent at in the generating curve inflection, an inflection are parallel. The consequence vanishing point of the generating the vanishing in Fig. 18(a). Note that a straight can be obtained from a piecewise of this is that tangents at the paired profile inflections curve inflection intersect tangent. This vanishing point in the lies on line of the plane of the canal surface generating line is simply a degenerate curve. This is illustrated so invariants inflection, linear generating curve. 268 A. Zissermun e/ d. /Art&id Intelligence 78 (1995) 239-288 Fig. 17. (a) Original (a). (c) Extracted based on a harmonic homology. original image. image containing several surfaces of revolution, surface of revolution profiles with axes computed automatically (b) The linked edges computed from using grouping constraints (d) Extracted surface of revolution profiles and axes superimposed on the b Fig. 18. For a canal surface with a planar axis. (a) of the axis. The intersection of a pair of inflection at the axis inflection. Two such vanishing points determine (h) corresponding intersect on I,. Their intersection point is the vanishing point of the corresponding (profile points arising tangents determines in the profile occur profile tangents the vanishing intlections line, I,, from the same surface circular cross-section) line. axis tangent in pairs for each inflection line of the plane of the axis; also the vanishing point of the tangent Computing invariants The canal surface is the envelope of spheres, and the canal profile of sphere profiles correct aspect ratio (scaled orthographic projection), [ 601. Under affine imaging conditions, provided the sphere profile the envelope the image has the is a circle, and A. Zissermm et al. /Art@cial Intelligence 78 (1995) 239-288 269 d Fig. 19. Affine normalisation of canal surface symmetry sets. Each row shows two images of the same pipe, and the symmetry set from these views and others transformed to an affine canonical frame. The canonical frames (c) and ( f) contain symmetry sets generated from thirteen and five images respectively. At least half of each set show significant perspective distortions, Note the variation in pipe width in the middle column due to perspective. Affine (as opposed to projective) normalisation can be achieved because the vanishing line of the plane of the generating curve is known (It is computed using the construction of Fig. 18 (a) ) The canonical frame curves are clearly very stable against variation in viewing position. Moreover, different pipes can be distinguished based solely on this affine representation [ 501. The slight instability present towards the ends of the canonical frame curves are due to errors in the extracted symmetry set which occur where the pipe radius changes. to the circle centre. The circle centre can be recovered from the is exact under affine the sphere centre projects symmetry set 5 of the canal profile, which is thus projectively curve, LY. This relation good approximation a quasi-invariant. Consequently, of the generating on the symmetry of Lamdan et al. [ 341. Fig. 19 shows examples of such curves. under perspective with a realistic invariants computed curve. For example, set curve in a canonical invariants imaging conditions, can be computed frame in a similar manner field of view-another for the symmetry related to the generating and is an extremely example of set are invariants from measurements to the “footprints” Correspondence and grouping As in the case of bilateral symmetry, curve establishes generating vanishing points determine curve. Subsequently, tangents on constraint holds for all corresponding this vanishing a planar projective constraint the constraint of a canal surface with a planar in the image. In this case two the vanishing line, l,, of the plane containing inflections on the profile can be paired by the intersections the generating of their line. Furthermore, it can be shown that this intersection profile points, i.e., 5 The symmetry set is the locus of centres of circles bitangent to a plane curve. It is studied in detail by Giblin and Brassett 1231. 270 A. Zissertnc7n et trl. /A@iciul Intelligence 78 (I 995) 239-288 Corresponding circular cross-section) profile tangents intersect on 1,. (i.e., points whose pre-image is on the same Set Fig. 18(b). Under affine imaging conditions symmetry profile curves being set. set (the projection of the generating the two sides of the profile are parallel curves of the from the curve). This follows directly circles swept along the symmetry the envelope of constant-radius 3.7. Polylzedru Recovering the structure of polyhedral objects the incidence explored, with the most detailed study appearing that equations image, lead to a linear system of equations and image observations. between polyhedral in [66]. from a single view has been widely In this work, Sugihara shows in the faces vertices and faces, observed in the coefficients of the polyhedron’s The equations in this system are incidence equations for vertices of the polyhedron incident on plane faces. In particular, given vertex V; = (Xi, I$, Zi) lying on face F; = (A;,B.i,C,, it must be the case that l), A,X; + lIiK + C,,Z, + I = 0. that the camera image plane is the plane Z = 1 and the focal point these assumptions can be accounted for by the geometric ambiguity Then Vi projects to image point (ui, u;) = (Xi/Zi, K/Z,). lies on face Fk, we can divide the incidence equations by Z; and subtract is at in the If vertex Vi to Assume (O,O, 0); reconstruction. also eliminate 1 /Zi, obtaining: (A, - 4)~; + (B., - ~k)t’, + cc, - ck) = 0, (since a plane cannot be made is four-dimensional, that is projectively is a system of planes If the family of solutions family of solutions, corresponding always has at least a three-dimensional figure has three then equivalent where u; and L’; are known, and the coefficients of the planes are unknowns. This system of equations to a polyhedron where all faces are the same plane degrees of freedom in 3D space). a generic element of the family to the faces of the original polyhedron. This case holds when the polyhedron “position free” in the terminology have at least four vertices per face. Although it is a useful case because many human artifacts satisfy added assumption only two edges are visible; leads to a novel formulation are necessary for effective of triangular can always be triangulated the faces for which thus, on viewing a cube, all six faces can be recovered. This fewer aspects consists only set of points. That is, a set of points to form a polyhedron. As in the case of a general point set of the aspect graph idea, where substantively representation. The case where the polyhedron of Sugihara, and many or most of the visible impossible by a small shift of the vertices, this is by no means a generic polyhedron, of that is, is faces that vertices are trihedral, these constraints. Given to an unconstrained faces is equivalent the reconstruction to reconstruct it is possible A. Zisserman et al. /Artificial Intelligence 78 (1995) 239-288 271 (Section 3), vertex positions are unconstrained be constructed. by the image view and no invariants can Computing invariants camera, Assuming an uncalibrated it can be shown lead to a system of equations having a four-dimensional any solution of this system is projectively dron. Consequently, on the original polyhedron. that [56,57] solution space (such as cubes) polyhe- (Euclidean) to the original invariants of the solution are the same as those measured that for polyhedra equivalent projective Correspondence and grouping Approaches to grouping and correspondence for this class are well established from the decade or so of blocks world vision research. The main basis for grouping where one seeks relations between vertices, edges and faces. a complete polyhedral to construct structure with consistent is topological, incident For particular subclasses of polyhedra, and for particular aspects, further constraints a cube has three major directions which define a triple in the image. All edges aligned with a major direction must pass apply to any polyhedra constraints incidence the same vanishing point. Similar are available. For example, of vanishing points through projectively polyhedral wireframe equivalent to a cube. Constraints of this type can be used to extract a from a polyhedral silhouette, inferring internal boundaries. 3.8. Extruded surfaces An extruded surface cut from a general cone by two planes surface does not include of a surface be extruded components, and many plastic bottles. formed by a system of parallel from a nozzle). Extruded are extremely common-examples is a special case of a generalised formed by a section (see Fig. 20(a) ) in such a way that the section of cylinder, the vertex of the cone [ 221. This is the projective generalisation lines, with plane ends (such a surface can surfaces, and surfaces made up from extruded tin cans, boxes, books, include most Outline geometry related T. This transformation The base and top curve are perspectively transformation, by a projective five degrees of freedom: by the vertex, a pair of corresponding these points with by the homology.6 As in the case of a planar harmonic homology homology has a line of fixed points and a fixed point not on this line: in 3D, and thus related in the image is a planar homology [ 631. It has (2 dof), axis (2 dof) and the cross-ratio defined of the line joining related (Fig. 14) a planar points, and the intersection is the same for all points (1 dof). The cross-ratio the vertex the axis h In the case of a harmonic four remaining degrees of freedom. The sides of the profile of a surface of revolution arc related by a harmonic homology, so there are only in Section 3.5. the cross-ratio is harmonic, i.e., known, as described homology, A. Zissermun er al. /Arrijiciul Inlelli~ence 78 (I 995) 239-288 (a) (b) surfaces; note that for most examples, is a section cut from a general cone by two planes. Fig. 20. An extruded surface extruded Cl and C2, of an extruded homology. Corresponding centre or vertex). The line L, which is the image of the intersection of the two planes that cut the “cone”, a line of fixed points of the transformation (a) A range of examples of (b) The top and base image curves, T, called a planar (the is surface are related by a particular projective is the fixed point of the transformation lie on lines through V, which the vertex is at infinity. transformation (the axis ). points ( 1) The homology vertex is the projection of the 3D cone vertex. It is the fixed point of T. (2) The homology axis is the projection of the line of intersection of the top and base planes. It is the line of fixed points of T. The profile curves of an extruded surface are a pair of lines which intersect at the image vertex. Computing invariants The projective geometry of an extruded surface ments: a plane cross-section; The plane cross-section pencil of planes which elements can be recovered cone is determined up to a projective curve, and the line top and base image curves. and vertex together define the cone intersect is completely defined by three ele- a cone vertex, not on the plane; and, a line in the plane. the cone. The line is the axis of the the top and base curves. These of the the cross-section from the imaged base curve or top relating transformation from an image of the surface since transformation to generate is the line of tixed points of the projective In essence, in the plane, obtained the invariants of an extruded surface are those of the plane cross-section of the base and top planes. from intersection in alone. For example, the top curve In the case that the top and base planes are parallel, affine plus an extra line Thus extra invariants Fig. 20 a five-line only contains four lines. invariants of the curve can be measured are available over the plane cross-section from a perspective image. from the image, although can be computed invariant Correspondence and grouping As described above, for an extruded surface the top and base image curves are related by a planar homology, T. Grouping proceeds by finding curves which are projectively A. Zisserman et al. /Art$cial Intelligence 78 (1995) 239-288 273 related. The class assumption can then be tested immediately since the projective trans- formation must be a homology if the curves are from an extruded surface (for example, two of the eigenvalues will be equal). The homology then defines the vertex, axis, and correspondence for the surface, which is used for further grouping. Additionally, since the surface is ruled, and all rulings pass through the vertex, the intersection of line segments in the profile determines the imaged vertex. Similarly, all corresponding point pairs on C and C’ (Fig. 20(b)) define a pencil of lines which pass through the vertex, and corresponding tangents intersect on the line of fixed points, 1. 3.9. Algebraic surfaces Algebraic surfaces are surfaces for which a single polynomial vanishes: examples include spheres (x2 + y2 + z* - 1 = 0) and ellipsoids which are both degree-two surfaces (quadrics) , and a wide range of popular surfaces in modelling such as rational bicubic patches. Smooth quadrics are all projectively equivalent (just as all tonics are projectively equivalent) so that there are no projective invariants of the surface to recover from images. Although a single quadric does not have any projective invariants, two or more quadrics do. Similarly, if the surface has degree 3 or greater, there are projective invariants to recover from images. In theory these invariants can be recovered from the surface profile alone [20], though this has not been implemented in practice. 4. An architecture for a 3D recognition system We have demonstrated that a large vocabulary of 3D invariants can be derived from the geometric constraints associated with object class definitions, e.g., that of a surface of revolution. In general, these curve, surface or volume class constraints enable the construction of invariants, and permit at least partial reconstruction of the 3D structure from a single perspective view. Class constraints also provide image feature grouping mechanisms and associated indexing machinery. The work to date, however, has focused on the derivation of invariants, structure recov- ery, and grouping for single object classes. Experimental validation has been restricted to isolated objects of a given class against an uncluttered background. An important next step is to integrate the approaches which have been developed into a unified 3D object recognition system. It is only in the context of a full system that the effectiveness of a class-based invariant representation for recognition can be convincingly demonstrated. 4.1. Fundamental principles Object recognition should be based on 3D geometric descriptions, both of objects and of the relationships between objects. To date, systems have largely ignored these in inter-object relationships yields relationships; as we show below, requiring consistency substantial information. In the architecture we describe, this information is encapsulated in an internal database, known as the scene. The scene provides a working reconstruction against which hypotheses can be checked to provide immediate detection of a false 274 A. Zisserman et (11. /Artijicial Intelligence 78 (I 995) 239-288 hypothesis. For example, in such a way that recognition one must be wholly occluded by the other, then at least one of the object hypotheses must be wrong. if two objects are hypothesised to the architecture small interpretations Central for relatively and model interpretation, hypothesis generation be based on a tradeoff between is efficient management images, vast numbers of hypotheses of control of each level. Even for feature correspondences can be constructed. It is impossible to explore all avenues of so some basis must be established for scheduling feature combination, and verification of hypotheses. The priority of scheduling should the cost and the benefit of a computation. Finally, class pervades and hypothesis confirmation. the architecture, influencing segmentation, grouping, indexing, 4.1.1. Class The idea that objects should be organised to recognition in a taxonomy is a natural and well-accepted is that many ontological distinctions ceeding philosophy for example, erties, geometric approach strength image observable distinctions. Object class has its most important effects in considering feature grouping and the structure of the modelbase. and classified before pro- principle. The problem with this in observable prop- and a solid block. Our its main so much as in the difference between a hollow container to object classification is based directly on visible features; in abstract, philosophical is that it is not vested are not manifested differences, as opposed Class drives grouping, to the usual “heuristics” relation. For this reason, object class is typically features. Each object class defines a grouping mechanism that are used to associate based on its image image settled at an early stage in invariant access. For example, the grouping process, and identity emerges only after modelbase for polyhedral class grouping, there is no point to recognise a rotationally requires symmetry hypothesis image curves related by a planar harmonic homology. The projective matching of these invariants of the curves. curves can be carried out by computing This is an application of planar object recognition lines into faces, as required symmetric object. A rotational techniques within a single and matching projective in grouping image. Class determines the access functions and partitioning in such a way as to allow easy retrieval; a hashing mechanism of the modelbase. The model- base itself is a collection of facts about objects and their properties. These facts must be organised By the time the modelbase hypothesis about object class-for to the polyhedral hashing mechanism. conventional is appropriate. implicit cannot be passed In fact, the modelbase can be viewed as a rather to answer certain queries very efficiently. the object group will contain a strong example, a pair of concavity-curves database, organised is accessed, 4.1.2. Consistem) Consistency tests arise from computing and representing To date, there have been few “hard” geometric consistency In fact, strong geometric Euclidean Euclidean frame and identity of objects even if the calibration of the camera tests emerge from the observation the same camera. These tests make relationships between objects. relations. tests for inter-object that objects share the same the it possible to recover is initially unknown. A. Zisserman et al. /Art$cial intelligence 78 (1995) 239-288 Fig. 2 I. (a) A scene containing polyhedra all of which are projectively equivalent, but Euclidean inequivalent. (b) A labelling of the scene. (c) A Euclidean reconstruction of the polyhedral world shown in (a). The optical centre is the marked point in the top right-hand comer of the figure. to each object. The cones are determined transformation, that models are Euclidean (i.e., as opposed the model and object Suppose of the 2D is an Euclidean for a number of system), recognition objects. Even though the Euclidean consistency of the recog- nition hypotheses can be tested by a comparison of the set of ray cones from the optical centre the relation between to the projective and recognition the camera hypotheses have been formed is uncalibrated, transformation Given a hypothesised and the image features by standard P as P = [M 1 -Mt] cone of rays from the optical centre constructed. object, P is determined from P, the rank three, 3 x 4 projection matrix of Eq. (2). from the known 3D Euclidean geometry [55]). Partitioning (as in, for example resectioning [ 301, then t is the optical centre which is the null space of P. A in the scene can then be to other Euclidean objects If the hypotheses for each object are correct, for each object should equivalent. That is, there will be a rotation about the optical centre which be Euclidean superimposes hy- the cones potheses can be detected by the failure of this test and the goal is to build up the largest pairwise and reconstruction set of object hypotheses. An example of hypothesis from each hypothesis. Thus, is shown in Fig. 21. for each object the ray cones inconsistent consistent labelling Another consistency test involves decomposing the matrix A4 (above) as M = KR by [ 25 J , where R is a rotation matrix, and K an upper triangular matrix the intrinsic parameters of the camera. Each hypothesis must agree on the from differing hypotheses can be detected and inconsistent intrinsic parameters QR decomposition containing camera decompositions Given an for K. image containing a large number of known objects, once and used to construct have been recognised be accepted and used to prune additional hypotheses tency. At this point, hypotheses individual error. Furthermore, ing and indexing database. tested against is accepted, can be if this frame activities. The Euclidean than searching rather a consistent world frame, the first few this frame can search for consis- groups of object hypotheses, in a depth-first for consistent risk of frame with the established then it can be used to condition group- of the world forms the scene little reconstruction 216 A. Zisserman er al. /Artijiciul Intelligence 78 (1995) 239-288 Fig. 22. The proposed architecture grouping and indexing methods. 4.2. The architecture for object recognition organised around geometric classes with associated Representation is organised in Fig. 22. These architectures, the three principles of class, global consistency and control provide a unifying into a number of layers as illustrated are not very different from other recognition stages of representation however theme. Segmentation and grouping The key to successful is efficient and robust recognition grouping. There are four levels of image feature representation feature segmentation and and grouping: l Level I: Pixel-level features. These are defined with respect to an image coordinate system and reflect the quantised nature of pixel coordinates. Typically, features will be produced using an edge operator with subpixel accuracy, and the resulting edgels linked the topology of the image boundaries. into a network reflecting l Level II: Geometricfeatures. in terms of geometric primitives, where appropriate. For example, algebraic curves such as line segments and tonics, smooth curves, and concavities defined by bitangents. Curves from level I are described (jumping is applied l Level III: Generic grouped features. This level of grouping to all fea- tures produced at level II. The output is a number of groupings and databases which includes: are used by the class-based groupers described below, Generic grouping collinear- small gaps, completing near-incidence ity; marking bitangent line segments; These example, and above a certain collinear with the given is no attempt at enforcing of curve segments to a spatially organised database. For line lines are there if a grouper or “what other In the current design For example, equivalence can be viewed as queries typical queries might be: “what other lines are parallel image?‘. compatibility”. in the region of interest?‘, finding sets of parallel and other distinguished corners and junctions); line over the entire affine or projective (e.g., concavities), “backwards to a given relations points; length A. Zisserman et al./Artijcial Intelligence 78 (1995) 239-288 277 at level III hypothesises that two curves should be joined there is no attempt to correct the level II representation. Ultimately, it may be important to ensure such consistency between levels. l Level IV: Class-based grouping. Each class has an associated “class-based grouper” that interrogates the level III groupings and databases, and attempts to form groups appropriate for its class. The grouping mechanism is based on the image invariant- relation as described in Section 3 for each class. A good example is given by the rotationally symmetric class which defines a grouping constraint in terms of the harmonic homology between the corresponding sides of the profile (Section 3.5). In addition to grouping, such constraints can be used to repair missing portions of the outline due to occlusion or poor contrast. For example, for a surface of revolution, a “snake” or deformable template can be defined by one side and applied to the other under the transformation of the homology. The transformation between both sides can be iterated to improve the geometric correspondence of both sides. Such class-based snakes can also augment the initial edge1 extraction process. Fig. 23 shows an example of repair and augmentation, where a polyhedral class snake recovers poorly defined interior edges from the exterior polyhedra outline, again based on the class constraints. Indexing and hypothesis combination The groups defined by each class also define the indexing function used to retrieve specific objects from the modelbase. For example, for a canal surface the indexes are computed from the symmetry set of the profile, for a surface of revolution from distinguished points on the axis. Indexing is handled by a series of hash tables, one per class, that take the invariants of a set of grouped features and associate with them models in the modelbase. For complex objects, there may be many feature groups that index to the object, leading to a situation where a single instance could generate many recognition hypotheses. In the planar recognition system, this problem is handled by merging consistent object hypotheses into joint hypotheses. Forming joint hypotheses (cliques) is fairly successful for small numbers of feature groups, but for more complex objects, there are potentially quite substantial combinato- rial problems. However, the principle that feature groups belonging to the same object should accrete into a more complex feature grouping is a good one. This accretion can be implemented in a more general fashion as follows: if a feature group results in a successful indexing attempt to a relatively small number of models, it leaves a record of that attempt in an image-scene relational data structure. When another feature group indexes to the same object or list of objects, and is within some grouping horizon of the first group, the two feature groups can be associated in a larger feature grouping, based on their correspondence to the same object structure. To make this record, the system forms a collection of keys out of the image feature position and each possible object model in turn, and stores a unique identifier for the image feature group in an image- scene database using these keys. The storage mechanism is such that, if the database is queried using a model identity and feature position, it will return any image features that indexed that model and are “near” (for some horizon) the original feature group. Note 278 A. Zissermun et al. /Arrijicial Intelligence 78 (1995) 239-288 that other forms of image-scene distance in the image; pose or frame hypothesis. information could be used in addition to Euclidean for example, an indexing hypothesis might be associated with a kijcation In the planar system, two stages of verification were used: plausibility of the projec- the object from the mode1 to image frame, and image support tive transformation that lines up with im- measured by the proportion of the backprojected mode1 perimeter age features. Such verification, based only on object outline, can fail through accidental correspondences with texture (for example, oriented markings such as wood grain). taking texture will be stored for each object in the model surface properties of an object can be compared with in a number of ways. First, surface library. During the To avoid this problem, verification is augmented the internal markings and surface verification, properties actually observed of verification will be improved by scene consistency is deemed be inconsistent More generically, the “score” perimeter cannot be matched, For example, one piece of evidence each end of the occlusion. to declare a large portion of confirmed boundary for a hypothesis there is independent for occlusion is improved in the interior of a mode1 hypothesis. Second, analysis. For example, to be behind another with respect to a given camera viewpoint, the reliability if one object then it would for the occluded object. if, when portions of the evidence of an occlusion occurring. is that aligned “T” junctions occur at The mode/base The modelbase will be organised around object class. For each class hash appropriate surfaces and surfaces of revolution will have separate spectively affine and projective for indexing, tables invariants, and separate model and a database of models. For example, indexing tables, containing libraries. there will be canal re- In the 2D recognition that contained geometric models, and was indexed system (Section 2.3) the modelbase typically acted as a passive to identify an object. The than this. It can also store aggregated statistics derived in each class library. These can be used to improve efficiency. For number of undulations if a putative profile this, there trihedral vertices to attempt is no point computing for any polyhedra, to group or index with four concurrent of any surface of revolution is returned by the grouper which invariants or indexing. then there is no need lines. the performance of the in this manner can greatly strengthen suppose the maximum repository modelbase can be more powerful from all the models example, in the library has more undulations Similarly, for the polyhedral Exploiting system. than if there are only grouper is stored. Then the modelbase Objects which do not correspond [ 7 1 ] image objects, will have multiple in the composite segmentation (the han- 3D structure class, as a surface of revolution dle). Equally, as a digital plane curve, and the mug body as a canal surface or extruded surface. All such representations will be included to a single volumetric primitive, each representation and grouping. For example, a mug might be represented, i.e., composite covering a possible the handle could be represented together with a canal surface representations: A. Zisserman et al./Artificial Intelligence 78 (1995) 239-288 279 It is only through recognition that the common concept “mug” is in the modelbase. achieved. The scene An additional and parameters source of constraints is the 3D scene, which can also be of the world and cameras. currently available about the common frame in which objects reside. This 3D spatial layout can be used at a number and viewed as a database which reflects the current configuration It provides a representation Euclidean of stages, for example, for camera viewpoint relations amongst model hypotheses, to determine occlusion of all the information consistency. 4.3. Model acquisition Typically, models will be acquired from multiple views of objects. The fact that such is a major advantage of tool four or five to recognition. Our goal is to provide a model acquisition to the model models can serve as sufficient the invariance approach which permits additions unoccluded system, where only one or two unoccluded views were required in the planar object recognition to construct a model. views of the object. This goal was achieved to be as simple as providing for recognition representations library Of course, is more difficult properties of an image feature group are unlikely for 3D objects, but the partitioning the efficient grouping and correspondence into the problem con- classes, based on geometry, will permit for model description. Since the object classes consist of 3D volumet- struction required ric primitives, we expect for most that only a small number of views will be required objects, and that these views will be defined by the extraction of a sufficient set of stable of aspect features over a wide range of viewpoints. This contrasts with the construction [ 641, which define a large number of aspects, or distinct graphs based on topology from image feature groups. That is, fine views, which cannot be reliably distinguished recovered topological from image segmentation topology is a secondary Euclidean to be reliably and grouping. The integrity of the object boundary information to work. One approach views. Three or more general views with a single camera are sufficient reconstruction camera parameters (CAD) models can be used to the case that it is often to the man- is more “realistic” in a CAD model, such certain CAD features may be irrelevant For manufactured provide a Euclidean that CAD models used for part design do not necessarily correspond exactly ufactured version of the part. The description obtained and incorporates many details which are not practical as filets and attachment hardware. Conversely, in practice since [ 17,291, and a 3D scaled Euclidean objects, Computer Aided Design description, However, techniques camera to derive internal for point sets. recognition hypothesis has occurred. is to derive the Euclidean properties from imagery to include they are not manifested visually result achieved after an initial for scene consistency it should be noted from self-calibrated in object models in any image. is required On the other hand, it is important of a model description. For example, be interpreted image feature as an instance of an “ideal” is never perfectly straight. Similarly, to develop if an image curve line even the idea of Platonic generalisation is sufficiently it can as an a pair of profile curves may match straight, its manifestation though 280 A. Zisserman et ~1. /Arrijicial Intelligence 78 (1995) 239-288 to be considered the outline of a rotationally symmetric they are not perfect idea1 description closely enough though Platonic the idea1 description the Platonic description instances of such a projection. The benefit of constructing is that over a large set of views and feature reconstructions, represents the natural mean over the set of reconstructions. Also, constraints used is in accordance with the formal mathematical object, even a a ./ ,,_- -..X / _’ 4 ,L _,J’ -‘iI /“ _, image containing Fig. 23. (a) Original (b) The linked edges computed edges by the class-based groupers, edge1 chains have been repaired outlines. grouped, and no false instances grouped. ( f) Extracted profiles superimposed two surfaces of revolution, from (a). Profiles are extracted and grouped automatically two canal surfaces, and two polyhedra. from these linked (c) Extracted surface of revolution profiles with axes. Note that gaps in the in the recovered profile. (d) Extracted canal profiles. on original image. All the correct (e) Extracted polyhedra instances of a class have been A. Zisserman et al. /Artificial Intelligence 78 (1995) 239-288 281 4.4. MORSE These ideas are being incorporated into a system, called MORSE, whose implemen- tation is currently underway. MORSE is named after the detective character originated by Colin Dexter, who is able to ferret out truth given apparently unpromising evidence. Our earlier system for 2D object recognition is called LEWIS, the name of Morse’s less capable assistant. MORSE will provide an environment for research on object represen- tation for recognition, by providing a context in which issues such as the distinctiveness of representations, the usefulness of feature groups, and the significance of consistency, can be addressed. The system is being implemented in C++ using a class hierarchy based on the Image Understanding Environment (WE). 7 The current state of progress of MORSE is illustrated in Fig. 23. Class-based groupers have been implemented for surfaces of revolution (Section 3.5), canal surfaces (Section 3.6), and polyhedra (Section 3.7). In each case the grouping is based solely on the constraints on the structure of the profiles for each class. Profiles for each class are ex- tracted completely automatically. As is demonstrated in the figure, recognition proceeds by first recognising an object as belonging to one of the classes (for example a surface of revolution). Subsequently the object will be identified (for example as a particular vase). 5. Discussion 5.1. Critique of the invariance approach To conclude, it is useful to clarify many of the points just presented by responding to a number of major criticisms which can be made of the invariance approach to recognition. It will be instructive to employ these critical points as a benchmark of the progress in recognition which can be attributed to the invariant framework. ( 1) The extreme nature of projective ambiguity. Invariance concentrates on projec- tive representations, In practice, perspective distortions in images are small and so can be ignored. Furthermore, the projective equivalence class is too large-a sphere and an ellipsoid are in the same class, as are a cube and a truncated pyramid. Thus, the recognition system cannot distinguish between them. Response. First, we have demonstrated with the planar recognition system that a projective representation is sufficient for many practical examples. Second, al- though it is almost always the case that only projective structure can be recovered in a single uncalibrated image of an object, this does not mean that the recogni- tion system is bound to projective ambiguities. For example, for certain classes, 7 The IUE is an ARPA funded project to produce an object-oriented programming environment for vision research. A central object hierarchy in the IUJ? is the spatial-object which incorporates many of the descriptive requirements described in the previous sections. The IUE also has an extensive set of classes for object and image transformations which are a central issue in MORSE. 282 A. Zisserman et (11. /Artificial Intelligence 78 (1995) 239-288 invariants affine or similarity structure 4.1.2, can be used to reduce ambiguity of multiple objects. repeated by translation can be measured in a perspective (Section 3.4). Euclidean from projective to similarity image, e.g., a consistency, Section for an image (2) The exclusiveness of geometry. Invariance at present concentrates on geometry to the exclusion of other recognition (e.g., pictures or lettering on a can), and surface properties dielectric). important object properties texture system such as: colour, (e.g., wood grain), surface markings (e.g., metal versus that should be used in a is some way to go before colour, largely dominates object descriptions in the system Response. Geometry very texture, surface mark- sketched above. There informa- ings or surface properties can stand on an equal footing with geometric compared tion. These are, at present, measured such cues fit into the proposed architecture. For ex- to geometry. Nevertheless, ample surface markings indexes (see Section 5.2), and could certainly be used as additional measures during verification. and texture can be used as additional relatively unreliably in images invariant identification. Invariance does not address (3) The lack of abstract classification. only classification, which an object belongs can be determined only by recognising object. For example, Mazda 323 Hatchback’, which bership a car, as distinct the problem of the class to it as a specific as a “1991 Red is a member of the class “car”. This class mem- identified as reasoning: the differences between an unknown object might be identified is determined by subsequent In a typical model-based it cannot be directly from a fish, despite the two classes. system, to address in its broadest sense presents severe conceptual Response. Abstract classification and philosophical is possible between a general that distinguished what a program would do, they will be difficult to solve. However, contains a first step in this direction, by distinguishing on the basis of the techniques In particular, profile of a rotationally classification T, on the profile, such that T* = I). problems, which we have carefully avoided addressing. Until it these problems concretely, by, for example, stating exactly fish and a general bicycle the architecture proposed between classes of object from images. the that techniques that there is a projective equivalence, as, for example, exist for confirming if a group of edge segments (in this case, by determining symmetric object, representations is classified to construct required (4) The rigidity of exact geometry. Geometry to represent objects such as clothes, plants and animals, which can articulate and such as a set deform. A deformable such objects. of colour histograms, may be much more effective descriptions, in representing template, or even non-geometric is not the appropriate language Response. for objects distinguish It is not yet clear what representations that have no clearly defined geometry one shirt from another?). As a result, exact geometry one would want to extract (for example, what aspects is probably A. Zisserman et al. /Art@cial Intelligence 78 (1995) 239-288 283 recognition to dominate going a need for a hybrid of geometric deformation; would cover the deformation. invariance would allow for some time to come. However, there is clearly for certain classes of for change of viewpoint, while statistics and statistics invariance (5) Complex objects.. Invariants might be suitable for representing and recognising “simple” parts, such as surfaces of revolution or quadrics yet cover assembling these shapes aeroplanes. but do not into complex objects, such as telephones or (“geons”) in representing 3D objects-for Response. Some of the 3D classes, surfaces, are “simple’‘-essentially, affect their usefulness of objects are more genuinely polyhedra. Objects addressed use of geometric as those shown advance individually that results from the consistency in such a way as to make up a composite object. consisting in this approach. However, relations between in Fig. 3, in forming and then using projective, or Euclidean the system architecture of, for example, checking, above for example, surfaces of revolution or canal little more than plane curves. This does not a large number of real objects. Other classes repeated structures or example, a hierarchy of parts, are not explicitly feature groups (intra-object in the the seeds of a solution are present such invariants), hypotheses. One could parts thing, recognising about object pose lie joint recognition to do the same to determine whether components information Concerning segmentation, for each class provide a natural means of segmenting primitive profile ceases finished. to apply this would indicate parts. For example, when it may be the case that the grouping relations defined into on the that the surface of revolution part had the harmonic homology a complex outline volumetric Of course, a combination currently difficult perspective which can support reliable for future systems there will be objects, e.g., potatoes, that cannot be represented by of the classes described here. However, such generic shapes are under the distortions of imaging. Our view is that it is better to proceed with a set of classes and establish a benchmark of performance to distinguish with any representation to build on. recognition 5.2. Avenues of future research techniques Indexing allows fast recognition of objects drawn from a diverse collection of classes: for a range of specific indexing various object classes has been displayed and demonstrated. These ideas have that should be capable of been handling recently raised about and that addresses many of the concerns systems. large, diverse modelbases, in recognition to produce a recognition system architecture for recovering the projective integrated necessary invariants indexing However, object recognition is not yet “solved”. There are a range of avenues of research to us: that promise exciting developments; we indicate a few topics most interesting 284 A. Zissermun et ul./Arr~cial Intelligence 78 (1995) 239-288 to ensure for indexing if the “wrong” object l The role of quasi-invariants. Using quasi-invariants its domain of stability. Avoiding is a problem, is indexed by a quasi-invariant this requires complex hypothesis the “right” object is indexed. The benefit of quasi-invariants because of the cost incurred applied outside combination is the use of simpler feature groups at the start of the recognition process. However, that simple quasi-invariants identified in this paper sides of a surface of revolution the affine relation between profile), can be used to schedule promising groups for further growth. should be used to schedule grouping. The quasi-invariants feature groups are often not very discriminating. Instead, we propose (e.g., l Learning views, Invariant invariants. indexes are a good goal for a learning algorithm; an ideal algorithm would, given a large modelbase, determine by some offline process of generating in indexing invariants could be extracted from a large number models effectively. Alternatively, taken from varying viewpoints. The advantage of the of real images of an object latter that could be involve reliably measured is that the invariant descriptors would only features most useful the functions features image and in images. l The use of texture and surface markings. Clearly, a part to play in verification. However, surface markings, of certain surface classes, can be used to generate example, by facilitating class. These marking alone. For example, without surface markings, quadrics are projectively but four points space, which can be recovered on a quadric surface have two projective image. texture and surface markings have together with the profile invariants. For of the markings onto the surface for that indexes based on the object profile equivalent, the backprojection further projective from a single can augment invariants in (markings) invariants l Extensions to grouping computation. in edge1 curve and line segment the topological symmetric objects and repeated structures, In recent experiments with control for group- the idea of in symmetric object, the to control linking has emerged. For example links along the profile of a rotationally to use the constraints of the planar homology association. Once a single concavity In a complex scene with many possible edge1 chain connections, the number of feasible paths generated the rest of the algorithm. As new can be transform parameters edge following are confirmed, the homology is determined, reduce can be recovered by a synchronised for rotationally ing features synchrony exploring it should be possible linking sequence. these constraints will considerably for symmetrical boundary parts of the boundary iteratively refined. The same type of strategy can be followed for any geometric symmetry or structural extended implemented. repetition. The constraints right down to the edge1 linking stage. Such an approach inherent class based on in these classes can be is currently being Acknowledgements We are grateful for discussions with Santanu Chaudhury, Peter Giblin, Richard Hart- ley, Jitendra Malik, Yael Moses, Sven Utcke and Luc Van Gool. Ellen Walker of RPI A. Zisserman er al. /ArtQicial Inrelligence 78 (1995) 239-288 285 provided support and guidance for Jane Liu. Martin Armstrong and Paul Beardsley com- puted the affine invariants for the translational repeated structure. Financial support was provided by several agencies: ESPRIT Project 6448 “VIVA”; a NSF Young Investigator Award with matching funds from GE, Tektronix, Rockwell International and Eugene Rikel; NSF grant no. IRI-9209729; US Air Force Office of Scientific Research grant no. AFOSR-91-0361; General Electric; and The Newton Institute, Cambridge, under SERC grant GRG5998 1. References 11 I N. Ayache and O.D. Faugeras, HYPER: a new approach for the recognition and positioning of two- dimensional objects, IEEE Trans. Pattern Anal. Much. Intell. 8 ( 1) (1986) 44-54. 121 N. Ayache and O.D. Faugeras, Building a consistent 3D representation of a mobile robot environment by combining multiple stereo views, in: Proceedings IJCAI-87, Milan, Italy (1987) 808-810. [ 31 T.O. Binford, Inferring surfaces from images, Artij Inrell. 17 (1981) 205-244. 141 T.O. Binford and T.S. Levitt, Quasi-invariants: theory and explanation, in: Proceedings DARPA I(/ Workshop (1993) 819-829. [ 51 T.O. Binford, D. Kapur and J.L. Mundy, The relation between invariants and quasi-invariants, in: Proceedings Asian Conference in Computer Vision, Osaka, Japan ( 1993). [ 61 R.C. Bolles and R. Horaud, 3DPO: a three-dimensional part orientation system, in: T. Kanade, ed., Three Dimensional Vision (Kluwer Academic Publishers, Boston, MA, 1987) 399-450. [ 71 G. Borgefors, Hierarchical chamfer matching: a parametric edge matching algorithm, IEEE Trans. Pattern Anal. Much. Intell. 10 (6) (1988) 849-865. [ 81 R.A. Brooks, Model-based three-dimensional interpretations of two-dimensional images, IEEE Trans. Pattern Anal. Mach. Intell. 5 (2) (1983). 191 J.B. Bums, R.S. Weiss and E.M. Riseman The non-existence of general-case view-invariants, in: J.L. Mundy and A. Zisserman, Geometric Invariance in Computer Vision (MIT Press, Cambridge, MA, 1992). [lo] T.A. Cass, Polynomial-time object recognition in the presence of clutter, occlusion, and uncertainty, in: Proceedings European Conference on Computer Vision, Lecture Notes in Computer Science 588 ( Springer-Verlag, Berlin, 1992) 834-842. [ 111 D.T. Clemens and D.W. Jacobs, Model group indexing for recognition, IEEE Truns. Pattern Anal. Much. Intell. 13 (10) (1991) 1007-1017. [ 121 I.J. Cox, J.M. Rehg and S. Hingorani, A Bayesian multiple hypothesis approach to contour grouping, in: Proceedings European Conference on Computer Vision, Lecture Notes in Computer Science 588 ( Springer-Verlag, Berlin, 1992) 72-77. [ 131 M. Dhome, J.T. Lapreste, G. Rives and M. Richetin, Spatial localization of modelled objects of revolution in monocular perspective vision, in: Proceedings European Conference on Computer Vision, Lecture Notes in Computer Science 427 (Springer-Verlag, Berlin, 1990) 475-485. [ 141 G.J. Ettinger, Large hierarchical object recognition using libraries of parameterized model sub-parts, in: Proceedings CVPR88 ( 1988) 32-41. [ 151 O.D. Faugens, What can be seen in three dimensions with an uncalibrated stereo rig? in: Proceedings European Conference on Computer Vision. Lecture Notes in Computer Science 588 (Springer-Verlag, Berlin, 1992) 563-578. [ 161 O.D. Faugeras and M. Hebert, The representation, recognition, and locating of 3-D objects, Int. J. Rob. Res. 5 (3) (1986) 27-52. [ 171 O.D. Faugeras, Q.T. Luong and S.J. Maybank, Camera self-calibration: theory and experiments, in: Proceedings European Conference on Computer Vision, Lecture Notes in Computer Science 588 ( Springer-Verlag, Berlin, 1992). [ 181 R. Fawcett, A. Zisserman and J.M. Brady, Extracting structure from an affine view of a 3D point set with one or two bilateral symmetries, Image and Vision Computing 12 (9) ( 1994) 615-622. 286 1191 1201 1211 1221 123) 1241 12.51 1261 1271 WI 1-1 1301 131 132 133 I 34 1351 1361 1371 A. Zissermun et (11. /Ariijiciul Intelligence 78 (1995) 239-288 (Wiley, surfaces algebraic and C.A. Rothwell, Recognising from their outlines, bit. J. Comput. Vision (to appear). to Objects: Computer Vision und Three Dimensional Scene Analysis from their in: Proceedings European Conference on Cornpurer Vision, Lecture Notes in Computer Science K.B. Fisher, From Surfaces New York, 1989). D.A. Forsyth, Recognizing D.A. Forsyth, J.L. Mundy, A.P. Zisserman outlines, 588 (Springer-Verlag. D.A. Forsyth and CA. Rothwell Representations Mundy, A. Zisserman Notes in Computer Science 825 ( Springer-Verlag, Berlin, 1994). P.J. Giblin and S.A. Brassett. Local symmetry of plane curves, Amer. Math. Monthly 92 (10) 689-707. C. Goad, Special purpose automatic programming in: J.L. in Cornpurer Vision, Lecture and D.A. Forsyth. eds., Applications of 3D objects that incorporate for 3D model-based vision, in: Proceedings DARPA Berlin, 1992) 639-648. surface markings, curved surfaces of Invariance (1985) (John Hopkins University Press, Baltimore, MD, Intelligent Robots and Computer (1983) 371-381. in: Proceedings SPIE Conference IL’ Workshop G.H. Golub and C.F. Van Loan, Matrix Computations 1983). G. Gordon, Shape from symmetry, Vision VIII, Philadelphia, PA ( 1989). W.E.L. Grimson, Object Recognition Cambridge, MA, 1990). W.E.L. Grimson and T. Lozano-Perez. Localizing overlapping parts by searching IEEE Trans. Pattern Anal. Mach. hue/l. 9 (4) ( 1987) 469-482. R.I. Hartley, Euclidean Forsyth, eds., Applications (Springer-Verlag. R.I. Haaley, R. Gupta and T. Chang, Stereo from uncalibrated 761-764. D.I? Huttenlocher Cot~erence on Computer Vision, London J.J. Koenderink, What does the occluding contour D.J. Kriegman and J. Ponce, On recognizing IEEE Trans. Pattern Anal. Mach. Y. Lamdan, Intel(. 12 (12) and H.J. Wolfson, Object and S. Ullman, Object recognition using alignment, (1990) 1127-l 137. ( 1987) 102-I Il. from uncalibrated and positioning Berlin, 1994). J.T. Schwartz reconstruction of Invariance recognition by affine cameras, by Computer; The Role of Geometric Constraints (MIT Press, the interpretation tree, views, in: J.L. Mundy, A. Zisserman and D.A. in Computer Vision, Lecture Notes in Computer Science 825 tell us about solid shape’?, Perception 13 ( 1984). curved 3-D objects from image contours, invariant matching, in: in: Proceedings CVPR92 ( 1992) in: Proceedings Firsr International (1988) 335-344. surfaces and straight homogeneous Proceedings CVPR88 IS. Liu, J.L. Mundy, D.A. Forsyth, A. Zisserman and CA. Rothwell, Efficient recognition of rotationally symmetric IS. Liu, J.L. Mundy and E.L. Walker. Recognizing Proceedings Asian Conference D.G. Lowe, Perceptual Organization MA, 1985). in Computer Vision, Osaka, Japan (Kluwer Academic Publishers, Boston. in: Proceedings CVPR ( 1993). from multiple projections, generalized cylinders, and Visual Recognition arbitrary objects (1993). in: 1381 D.G. Lowe, The viewpoint consistency 1391 H. Mitsumoto, S. Tamura, K. Okazaki, N. Kajimi and Y. Fukui, 3D reconstruction Intell. 14 (9) recovery method, Pattern Anal. Mach. Irrt. .I. Compuf. Vision 1 (I) based on a plane symmetry constraint, (1987) 57-72. using mirror images (1992) 941-945. I40 I R. Mohr, L. Morin and E. Grosso, Relative positioning with uncalibrated cameras, in: J.L. Mundy and A. Zisserman, Geometric Invuriance in Computer Vision (MIT Press, Cambridge, MA, 1992). 14 I 1 T. Moons, L. Van Goal, M. Van Diest and E. Pauwels Affine structure from perspective images pairs, in: J.L. Mundy, A. Zisserman Lecture Notes in Computer Science 825 ( Springer-Verlag, Berlin, 1994). and D.A. Forsyth, eds.. Applications of Invariance in Computer Vision, I42 I Y. Moses and S. Ullman, Limitations of non model-based in: Proceedings European Conference on Computer Vision, Lecture Notes in Computer Science 588 (Springer-Verlag, Berlin, 1992) X20-828. recognition systems, [ 43 I D.P. Mukherjee, A. Zisserman and J.M. Brady, Shape from symmetry-detecting and exploiting symmetry in affine images, in: Proc. Royal Sot. 351 ( 199.5) 77-106. 1441 J.L. Mundy and A.J. Heller, The evolution and testing of a model-based object recognition system, in: Proreedings Third International Conference on Computer Vision ( 1990) 268-282. A. Zissermun et al. /Ar@cial Inrelligence 78 (1995) 239-288 287 145 I J.L. Mundy and A. Zisserman, Geometric Invariance in Computer Won (MIT Press, Cambridge, MA, 1992). (461 J.L. Mundy and A. Zisserman, Repeated structures: image correspondence constraints and 3D structure in Computer recovery, in: J.L. Mundy, A. Zisserman and D.A. Forsyth, eds., Applications oflnvariance Vision, Lecture Notes in Computer Science 825 (Springer-Verlag, Berlin, 1994). [47 I D.W. Murray, Model-based recognition using 3D structure from motion, Image fission Compur. 5 ( 1987) 85-90. 1481 D.W. Murray and D.B. Cook, Using the orientation of fragmentary 3D edge segments for polyhedral object recognition, Inf. J. Compur. Vision 2 (1988) 153-169. 1491 L. Nielsen, Automated guidance of vehicles using vision and projective invariant marking, Automatica 24 (1988) 135-148. [50] N. Pillow, S. Utcke and A. Zisserman, Viewpoint-invariant representation of generalized cylinders using the symmetry set, Image Vision Comput. 13 (5) ( 1995) 355-365. IS1 1 S.B. Pollard, TX Pridmore, J. Ponill, J.E.W. Mayhew and J.P. Frisby, Geometrical modeling from multiple stereo views, Int. .I. Rob. Res. 8 (4) (1989) 132-138. I52 I J. Ponce, Invariant properties of straight homogeneous generalised cylinders, IEEE Pattern Anal. Mach. Intell. 11 (9) (1989) 951-965. I53 ] 1. Reid, Recognising parameterized models from range data, D.Phil. Thesis, Department of Engineering Science, University of Oxford, Oxford ( 1991). 1541 T.H. Reiss, Recognizing Planar Objects Using Invariant Image Features, Lecture Notes in Computer Science 676 ( Springer-Verlag, Berlin, 1993). 1551 L.G. Roberts, Machine perception of three-dimensional solids, in: J. Tippett et al., eds., Optical and Electra-Optical Information Processing (MIT Press, Cambridge, MA, 1965). [56 I C.A. Rothwell, Recognition using projective invariance, D.Phil. Thesis, Department of Engineering Science, University of Oxford ( 1993). [ 571 C.A. Rothwell, D.A. Forsyth, A. Zisserman and J.L. Mundy, Extracting projective structux from single perspective views of 3D point sets, in: Proceedings International Conference on Computer Vision ( 1993) 573-582. 1581 C.A. Rothwell, A. Zisserman, D.A. Forsyth and J.L. Mundy, Canonical frames for planar object recognition, in: Proceedings European Conference on Computer Vision, Lecture Notes in Computer Science 588 (Springer-Verlag, Berlin. 1992) 757-772. [ 591 C.A. Rothwell, A. Zisserman, J.L. Mundy and D.A. Forsyth, Efficient model library access by projectively invariant indexing functions, in: Proceedings CVPR92 (1992) 109-I 14. [ 601 I.E. Rycroft, A geometrical investigation into the prqjections of surfaces and space curves, Ph.D. Thesis, University of Liverpool ( 1992), [ 611 A. Sha’ashua and S. Ullman, Structural saliency: the detection of globally salient structures using a locally connected network, in: Proceedings Second International Conference on Cornpurer Msion, Tampa, FL (1988) 321-327. [ 621 G. Span; Notes on geometric invariants in vision, Lund Research Report ( 1993). 1631 C.E. Springer, Geometry and Analysis of Projective Spaces (Freeman, San Francisco, CA, 1964). 1641 J. Stewman and K.W. Bowyer, Creating the perspective projection aspect graph of polyhedral objects, in: Proceedings Second International Conference on Computer Vision, Tampa, FL ( 1988). 1651 G. Stockman, Object recognition and localization via pose clustering, Comput. Vision Graph. Image Process. 40 (1987) 361-387. 1661 K. Sugihara, Machine interpretation of Line Drawings (MIT Press, Cambridge, MA, 1986). 167) D.W. Thompson and J.L. Mundy, Three-dimensional model matching from an unconstrained viewpoint, in: Proceedings International Conference on Robotics and Auromalion, Raleigh, NC ( 1987) 208-220. 1681 S. Ullman and R. Basri, Recognition by linear combination of models, Pattern Anal. Mach. Intell. 13 (10)(1991)992-1006. 1691 L. Van Gool, P. Kempenaers and A. Oosterlinck, Recognition and semi-differential invariants, in: Proceedings CVPR9I ( 199 1) 454-460. [70] 1. Weiss, Geometric invariants and object recognition, Int. J. Cornput Vision 10 (3) ( 1993). [ 7 I ] M. Zerroug and R. Nevatia, Using invariance and quasi-invariance for the segmentation and recovery of curved objects, in: J.L. Mundy, A. Zisserman and D.A. Forsyth, eds., Applications of Invariance in Computer Vision, Lecture Notes in Computer Science 825 (Springer-Verlag, Berlin, 1994). 288 A. Zisserman et al. /Artificial Intelligence 78 (1995) 239-288 [ 72 1 A. Zisserman, D.A. Forsyth, J.L. Mundy and C. Rothwell, Recognizing general curved objects efficiently, in Computer Vision (MIT Press, Cambridge, Invariance in: J.L. Mundy and A. Zissennan. Geometric MA, 1992). 