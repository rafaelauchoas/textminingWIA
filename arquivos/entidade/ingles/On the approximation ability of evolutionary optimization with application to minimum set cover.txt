Artificial Intelligence 180–181 (2012) 20–33Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOn the approximation ability of evolutionary optimization withapplication to minimum set coverYang Yu a, Xin Yao b, Zhi-Hua Zhou a,∗a National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210093, Chinab Center of Excellence for Research in Computational Intelligence and Applications, School of Computer Science, University of Birmingham, Birmingham B15 2TT, UKa r t i c l ei n f oa b s t r a c tArticle history:Received 23 December 2010Received in revised form 8 December 2011Accepted 8 January 2012Available online 10 January 2012Keywords:Evolutionary algorithmsApproximation algorithmApproximation ratiok-Set coverTime complexity analysisEvolutionary algorithms (EAs) are heuristic algorithms inspired by natural evolution. Theyare often used to obtain satisficing solutions in practice. In this paper, we investigate alargely underexplored issue: the approximation performance of EAs in terms of how closethe solution obtained is to an optimal solution. We study an EA framework named simpleEA with isolated population (SEIP) that can be implemented as a single- or multi-objectiveEA. We analyze the approximation performance of SEIP using the partial ratio, whichcharacterizes the approximation ratio that can be guaranteed. Specifically, we analyzeSEIP using a set cover problem that is NP-hard. We find that in a simple configuration,SEIP efficiently achieves an Hn-approximation ratio, the asymptotic lower bound, for theunbounded set cover problem. We also find that SEIP efficiently achieves an (Hk − k−18k9 )-approximation ratio, the currently best-achievable result, for the k-set cover problem.Moreover, for an instance class of the k-set cover problem, we disclose how SEIP, usingeither one-bit or bit-wise mutation, can overcome the difficulty that limits the greedyalgorithm.© 2012 Elsevier B.V. All rights reserved.1. IntroductionEvolutionary algorithms (EAs) [3] have been successfully applied to many fields and can achieve extraordinary perfor-mance in addressing some real-world hard problems, particularly NP-hard problems [16,18,17,4]. To gain an understandingof the behavior of EAs, many theoretical studies have focused on the running time required to achieve exact optimal so-lutions [14,33,26,2]. In practice, EAs are most commonly used to obtain satisficing solutions, yet theoretical studies of theapproximation ability of EAs have only emerged recently.He and Yao [15] first studied conditions under which the wide-gap far distance and the narrow-gap long distance problemsare hard to approximate using EAs. Giel and Wegener [12] investigated a (1 + 1)-EA for a maximum matching problem andfound that the time taken time to find exact optimal solutions is exponential but is only O (n2(cid:3)1/(cid:2)(cid:4)) for (1 + (cid:2))-approximatesolutions, which demonstrates the value of EAs as approximation algorithms.Subsequently, further results on the approximation ability of EAs were reported. For the (1 + 1)-EA, the simplest typeof EA, two classes of results have been obtained. On one hand, it was found that the (1 + 1)-EA has an arbitrarily poorapproximation ratio for the minimum vertex cover problem and thus also for the minimum set cover problem [11,28]. On theother hand, it was also found that (1 + 1)-EA provides a polynomial-time randomized approximation scheme for a subclass ofthe partition problem [32]. Furthermore, for some subclasses of the minimum vertex cover problem for which the (1 + 1)-EAgets stuck, a multiple restart strategy allows the EA to recover an optimal solution with high probability [28]. Another result* Corresponding author.E-mail addresses: yuy@lamda.nju.edu.cn (Y. Yu), x.yao@cs.bham.ac.uk (X. Yao), zhouzh@nju.edu.cn (Z.-H. Zhou).0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2012.01.001Y. Yu et al. / Artificial Intelligence 180–181 (2012) 20–3321for the (1 + 1)-EA is that it improves a 2-approximation algorithm to a (2 − 2/n)-approximation on the minimum vertexcover problem [10]. This implies that it might sometimes be useful as a post-optimizer.Recent advances in multi-objective (usually bi-objective) EAs have shed light on the power of EAs as approximationoptimizers. For a single-objective problem, multi-objective reformulation introduces an auxiliary objective function for whicha multi-objective EA is used as the optimizer. Scharnow et al. [30] first suggested that multi-objective reformulation couldbe superior to use of a single-objective EA. This was confirmed for various problems [24,25,11,27] by showing that while asingle-objective EA could get stuck, multi-objective reformulation helps to solve the problems efficiently.Regarding approximations, it has been shown that multi-objective EAs are effective for some NP-hard problems. Friedrichet al. [11] proved that a multi-objective EA achieves a (ln n)-approximation ratio for the minimum set cover problem, andreaches the asymptotic lower bound in polynomial time. Neumann and Reichel [23] showed that multi-objective EAs achievea k-approximation ratio for the minimum multicuts problem in polynomial time.In the present study, we investigate the approximation ability of EAs by introducing a framework called simple evolu-tionary algorithm with isolated population (SEIP), which uses an isolation function to manage competition among solutions.By specifying the isolation function, SEIP can be implemented as a single- or multi-objective EA. Multi-objective EAs previ-ously analyzed [22,11,23] can be viewed as special cases of SEIP in term of the solutions maintained in the population. Byanalyzing the SEIP framework, we obtain a general characterization of EAs that guarantee approximation quality.We then study the minimum set cover problem (MSCP), which is an NP-hard problem [9]. We prove that for the un-bounded MSCP, a simple configuration of SEIP efficiently obtains an Hk-approximation ratio (where Hk is the harmonicnumber of the cardinality of the largest set), the asymptotic lower bound [9]. For the minimum k-set cover problem, thisapproach efficiently yields an (Hk − k−18k9 )-approximation ratio, the currently best-achievable quality [13]. Moreover, for asubclass of the minimum k-set cover problem, we demonstrate how SEIP, with either one-bit or bit-wise mutation, canovercome the difficulty that limits the greedy algorithm.The remainder of the paper is organized as follows. After introducing preliminaries in Section 2, we describe SEIP inSection 3 and characterize its behavior for approximation in Section 4. We then analyze the approximation ratio achievedby SEIP for the MSCP in Section 5. In Section 6 we conclude the paper with a discussion of the advantages and limitationsof the SEIP framework.2. PreliminariesWe use bold small letters such as w, x, y, z to represent vectors. We denote [m] as the set {1, 2, . . . , m} and 2S as thei for the nth harmonic number. Note that Hn ∼ ln npower set of S, which consists of all subsets of S. We denote Hn =since ln n (cid:2) Hn (cid:2) ln n + 1.(cid:2)ni=11In this paper, we consider minimization problems as follows.Definition 1 (Minimization problem). Given an evaluation function f and a set of feasibility constraints C, find a solutionx ∈ {0, 1}n that minimizes f (x) while satisfying constraints in C. A problem instance can be specified by its parameters(n, f , C).In the definition of the minimization problem, solutions are represented in binary vectors. When the aim of a minimiza-tion problem is to find a subset from a universal set, we can equivalently use a binary vector to represent a subset, whereeach element of the vector indicates the membership of a corresponding element of the universe set. For example, givena universal set U = {1, 2, 3, 4, 5}, its subset S = {1, 3, 5} can be represented by a binary vector v = (1, 0, 1, 0, 1), and wedefine U (v) = S. Considering the equivalence between sets and binary vectors, we apply set operators (| · |, ∩, ∪, −, ⊆, ∈) tobinary vectors when there is no confusion. For example, |(1, 0, 1, 0, 1)| = 3, (1, 0, 1, 0, 1) ∩ (0, 0, 0, 1, 1) = (0, 0, 0, 0, 1), and(1, 0, 1, 0, 1) − (0, 0, 0, 1, 1) = (1, 0, 1, 0, 0). We denote x∅ = (0, . . . , 0) as the vector corresponding to the empty set.We investigate the minimum set cover problem (MSCP), which is an NP-hard problem.Definition 2 (Minimum set cover problem (MSCP)). Given a set of n elements U = [n] and a collection C = {S 1, S2, . . . , Sm} of mnonempty subsets of U , where each S i is associated with a positive cost w(S i), find a subset XS∈ X ∗ w(S)is minimized with respect to∗ ⊆ C such that(cid:2)(cid:3)S∈ X ∗ S = U .Using binary vector representation, we denote an instance of the MSCP by its parameters (n, w, C, U ), where |C| = m, byand w is the cost vector. The MSCP involves finding a vector xOPT , which is equivalent to its set representation Xsolving a constrained optimization problem∗xOPT = arg minx∈{0,1}m(cid:4)w · xS = U ,s.t.S∈C(x)22Y. Yu et al. / Artificial Intelligence 180–181 (2012) 20–33where w · x is the inner product between vectors w and x, and C(x) denotes a set consisting of elements in the collectionC that are indicated by binary vector x.Definition 3 (Minimum k-set cover problem). An MSCP (n, w, C, U ) is a k-set cover problem if, for some constant k, it holdsthat |S| (cid:2) k for all S ∈ C , denoted as (n, w, C, U , k).A solution is called feasible if it satisfies all the constraints in C; otherwise, it is called an infeasible solution, or a partialsolution in this paper. Here, we assume that the evaluation function f is defined on the full input space, that is, it evaluatesall possible solutions regardless of their feasibility. For example, if we evaluate a solution x of the MSCP using w · x, thisevaluation function can be calculated for any solution.Given a minimization problem, we denote xOPT as an optimal solution of the problem, and OPT = f (xOPT ). For a feasibleOPT as its approximation ratio. If the approximation ratio of a feasible solution is upper-solution x, we regard the ratio f (x)bounded by some value r, that is,1 (cid:2) f (x)OPT(cid:2) r,the solution is called an r-approximate solution. An algorithm that guarantees to find an r-approximate solution for anarbitrary problem instance in polynomial time is an r-approximation algorithm.The greedy algorithm [5] described here as Algorithm 1 is the most well-known approximation algorithm for the MSCP.This greedy algorithm consists of a sequence of steps. The cost of a candidate set is defined as its weight divided bythe number of its elements that have not been covered yet (i.e., the quantity r S in line 3). The algorithm then picks thecandidate set with the smallest cost for the solution (line 4) and marks the newly covered elements (line 6). This simplealgorithm yields an Hn-approximation ratio or, more exactly, Hk, where k is the cardinality of the largest set [5]. The keyto the proof of the approximation ratio is the definition of the price of elements, as in line 5. The price of an elementequals the cost of the set that first covers it; therefore, the total price of all elements equals the total cost of the solution.Furthermore, it should be noted that when an element is covered by a set with the lowest cost, it would also be covered byone set of an optimal solution but with a higher cost. Therefore the price of the element is upper-bounded by the optimalcost and hence the approximation ratio is upper-bounded. For a detailed proof please refer to Cheátal [5].Algorithm 1 (Greedy algorithm). (See [5].)Given a minimum k-set cover problem (n, w, C, U , k), the greedy algorithm consists of the following steps:1: X ← ∅; R ← ∅2: while R (cid:12)= U do3:4:5:∀S ∈ C: |S − R| > 0, let r S ← w(S)|S−R|ˆS ← arg minS r Slet price(e) ← r ˆS for all e ∈ ˆS − Rlet R ← R ∪ ˆS, and X ← X ∪ { ˆS}.6:7: end while8: return XSeveral studies have shown that the approximation ratio of the MSCP is lower-bounded by Ω(ln n) unless P = NP thatis unlikely [29,31,9,1]. Therefore, the greedy algorithm achieves the asymptotic lower bound of the approximation ratio forthe MSCP.Although the Hn-approximation ratio is asymptotically tight for the unbounded MSCP, a better approximation ratio canbe achieved for the minimum k-set cover problem, where k is a constant. It has been proved that for the unweightedminimum k-set cover problem, an (Hk − 12 )-approximation ratio can be achieved [8] and, if k (cid:3) 4, an improved ratio (Hk −196390 ) can be achieved [20]. For the weighted minimum k-set cover problem, a greedy-algorithm-with-withdrawals (GAWW)was presented and achieved an Hk − k−18k9 -approximation ratio [13].The GAWW algorithm presented here as Algorithm 2 is a modification of the greedy algorithm. In every iteration, thealgorithm chooses between taking a greedy step, which is the same as in the greedy algorithm, and a withdrawal step,which replaces a set in the current solution with at most k candidate sets. It evaluates the cost of candidate sets as in thegreedy algorithm, and also evaluates the benefit of the withdrawal (calculated in lines 4 and 5). When the benefit of thewithdrawal step is not large enough according to the criterion in line 6, the algorithm takes the greedy step, and otherwisetakes the withdrawal step. To prove the approximation ratio, the price of elements is defined similarly in line 7 for thegreedy step and line 10 for the withdrawal step, which is used later in the proofs for this paper.Algorithm 2 (GAWW). (See [13].)Given a minimum k-set cover problem (n, w, C, U , k), GAWW consists of the following steps.1: X ← ∅; R ← ∅; αk ← 1 − 1k3Y. Yu et al. / Artificial Intelligence 180–181 (2012) 20–33232: while R (cid:12)= U do3:∀S ∈ C: |S − R| > 0, let r S ← w(S)|S−R|∀S ∈ X, Q ⊆ C: |Q | (cid:2) k ∧ |ˆS ← arg minS r ˆS , and ( ˜S, ˜Q ) ← arg min(S,Q ):|Q |(cid:2)k r(S,Q )if r ˆS(cid:15) − R| > 0, let r(S,Q ) ←S(cid:15)∈Q S(cid:3)· αk (cid:2) r( ˜S, ˜Q ) then {greedy step}let price(e) ← r ˆS for all e ∈ ˆS − Rlet R ← R ∪ ˆS, and X ← X ∪ { ˆS}else {i.e., r( ˜S, ˜Q ) < r ˆS· αk, withdrawal step}(cid:3)let price(e) ← r( ˜S, ˜Q ) for all e ∈let R ←S∈Q S − RS∈Q S ∪ R, and X ← X ∪ Q − { ˜S}(cid:3)4:5:6:7:8:9:10:11:(cid:2)(cid:3)S|(cid:15) −c S(cid:15)∈Q c S(cid:15)∈Q S(cid:15)−R|S{choose the minimal number of sets in cases of ties}end if12:13: end while14: return XThe (1 + 1)-EA is the simplest EA implementation, as described in Algorithm 3. Starting from a solution generateduniformly at random, the (1 + 1)-EA repeatedly generates a new solution from the current one using a mutation operator,and the current solution is replaced if the new solution has better (or equal) fitness.Algorithm 3 ((1 + 1)-EA).Given a minimization problem (n, f , C), each solution is encoded as a binary vector of length m and the (1 + 1)-EA-minimizing f consists of the following steps.1: x ← a solution generated uniformly at random2: while stop (cid:12)= true do(cid:15)3: Mutate x to generate x(cid:15)) (cid:2) f (x) thenif x is feasible and f (x4:5:(cid:15)x ← xend if6:7: end while8: return xTwo mutation operators are commonly used to implement the “mutate” step in line 3:One-bit mutation: Flip one randomly selected bit position of x to generate xBit-wise mutation: Flip each bit of x with probability 1(cid:15)m to generate x.(cid:15).It has been shown that the (1 + 1)-EA has an arbitrarily poor approximation ratio for the MSCP [11]. Laumanns et al. [19]used a multi-objective reformulation with a multi-objective EA named SEMO to achieve a (ln n)-approximation ratio. TheSEMO algorithm is described in Algorithm 4, where two objectives are presented as ( f 1, f 2). To apply SEMO to the MSCP,let f 1 evaluate the cost of the solution and f 2 evaluate the number of uncovered elements. Thus, SEMO minimizes the costand the number of uncovered elements of solutions simultaneously. A notable difference between SEMO and (1 + 1)-EAis that SEMO uses a non-dominance relationship, implemented using the dominate function in SEMO. The population ofSEMO maintains non-dominant solutions, that is, no solution is superior to another for both of the two objectives.Algorithm 4 (SEMO). (See [19].)Given a two-objective minimization problem (n, ( f 1, f 2)), each solution is encoded as a binary vector of length m. SEMOminimization of ( f 1, f 2) consists of the following steps.∅ = (0, 0, . . . , 0)}1: P ← {x2: while stop (cid:12)= true do3:(cid:15)4: Mutate x to generate x5:Choose x ∈ P uniformly at randomif ∀x ∈ P : dominate(x, x6:7:Q ← {x ∈ P | dominate(x(cid:15)} − QP ← P ∪ {x(cid:15)) = false then(cid:15), x) = true}end if8:9: end while10: return Pwhere the dominate function of two solutions is defined such that dominate(x, y) is true if any one of the followingthree rules is satisfied:24Y. Yu et al. / Artificial Intelligence 180–181 (2012) 20–331) f 1(x) < f 1( y) and f 2(x) (cid:2) f 2( y)2) f 1(x) (cid:2) f 1( y) and f 2(x) < f 2( y)3) f 1(x) = f 1( y) and f 2(x) = f 2( y) and |x| < | y|and dominate(x, y) is false otherwise.3. SEIPThe SEIP framework is depicted in Algorithm 5. It uses an isolation function μ to isolate solutions. For some integer q, thefunction μ maps a solution to a subset of [q]. If and only if two solutions x1 and x2 are mapped to subsets with the samecardinality, that is, |μ(x1)| = |μ(x2)|, the two solutions compete with each other. In that case, we say the two solutions arein the same isolation, and there are at most q + 1 isolations since the subsets of [q] have q + 1 different cardinalities.Algorithm 5 (SEIP).Given a minimization problem (n, f , C), an isolation function μ encodes each solution as a binary vector of length m. SEIPminimization of f with respect to constraint C consists of the following steps.∅ = (0, 0, . . . , 0)}1: P ← {x2: while stop (cid:12)= true do3:(cid:15)4: Mutate x to generate x5:Choose x ∈ P uniformly at randomif ∀x ∈ P : superior(x, x6:7:Q ← {x ∈ P | superior(x(cid:15)} − QP ← P ∪ {x(cid:15)) = false then(cid:15), x) = true}end if8:9: end while10: return the best feasible solution in Pwhere the superior function of two solutions determines whether one solution is superior to the other. This is definedas follows: superior(x, y) is true if both of the following rules are satisfied:1) |μ(x)| = |μ( y)|2) f (x) < f ( y), or f (x) = f ( y) but |x| < | y|and superior(x, y) is false otherwise.When the isolation function puts all solutions in an isolation for a particular instance, it degrades to the (1 + 1)-EA. The isolation function can also be configured to simulate the dominance relationship of multi-objective EAs such asSEMO/GSEMO [19] and DEMO [23]. If we are dealing with k-objective optimization with discrete objective values, a simpleapproach is to use one of the objective functions, say f 1, as the fitness function and use the combination of the values ofthe remaining k − 1 objective functions (say f 2, . . . , fk) as the isolation functions. Thus, two solutions compete (for f 1) onlywhen they share the same objective values for f 2, . . . , fk. This simulation shows that all the non-dominant solutions of amulti-objective EA are also kept in the SEIP population, and if a non-dominant solution does not reside in the SEIP popu-lation, there must be another solution that dominates it. Hence, SEIP can be viewed as a generalization of multi-objectiveEAs in terms of the solutions retained. This simulation also reveals that SEIP retains more solutions than a multi-objectiveEA using the dominance relationship. This, on one hand, SEIP takes more time to manipulate a larger population than amulti-objective EA does, which could be overcome by defining an isolation function that aggregates nearby solutions, as hasbeen done for DEMO [23]. On the other hand, SEIP has more opportunities available to find a better approximation solution,since the relationship “a dominates b” does not imply that a definitely leads to a better approximation solution than b.Taking the MSCP (n, w, C, U ) as an example, we can use the fitness function f (x) = w · x, which is the sum of costs ofthe selected sets. For the isolation function, we can use μ(x) as ∅ if x is feasible and {1} if x is infeasible, which isolates thefeasible from the infeasible solutions (and thus q = 1); we can also use the isolation function μ(x) =S∈x(C) S, and thusthe solutions compete only when they cover the same number of elements (and thus q = n).(cid:3)The mutation operator can use either one-bit or bit-wise mutation. Usually, one-bit mutation is considered for localsearches, while bit-wise mutation is suitable for global searches as it has a positive probability for producing any solution.We denote SEIP with one-bit mutation as LSEIP and SEIP with bit-wise mutation as GSEIP, where “L” and “G” denote “local”and “global”, respectively.For convenience, SEIP is set to start from solution xrather than from a random solution, as commonly done for otherEAs. Under the condition that any solution will have a better fitness if any 1 bit is turned to 0, we can bound the difference. From a random solution, SEIP takes at most O (qm ln m) expected stepsbetween random initialization and starting from x∅according to the following argument. Suppose the worst case whereby random initialization generates a solutionto find xis equivalent to solving the OneMax problem using awith all 1 bits; according to the fitness function condition, finding xrandomized local search and the (1 + 1)-EA, which takes O (m ln m) steps for both LSEIP and GSEIP [7]. Furthermore, notethat there can be at most q solutions in the population, and thus it costs SEIP q expected steps to choose one particularsolution from the population.∅∅The stop criterion is not described in the definition of SEIP, since EAs are usually used as anytime algorithms in practice.We now analyze the approximation ratio and the corresponding computational complexity of SEIP.∅Y. Yu et al. / Artificial Intelligence 180–181 (2012) 20–33254. General approximation behavior of SEIPFor minimization problems, we consider linearly additive isolation functions. μ is a linearly additive isolation function if,(cid:5)for some integer q,μ(x) = [q],μ(x ∪ y) = μ(x) ∪ μ( y),for all feasible solutions x,for all solutions x and y.The quality of a feasible solution is measured in terms of the approximation ratio. To measure the quality of a partial(infeasible) solution, we define a partial reference function and partial ratio as follows.Definition 4 (Partial reference function). Given a set [q] and a value v, a function L[q],v : 2function if[q] → R is a partial reference1) L[q],v ([q]) = v,2) L[q],v (R1) = L[q],v (R2) for all R1, R2 ⊆ [q] such that |R1| = |R2|.For a minimization problem with optimal cost OPT and an isolation function μ mapping feasible solutions to the set [q],we denote a partial reference function with respect to [q] and OPT as L[q],OPT . When the problem and the isolation functionare clear, we omit the subscripts and simply denote the partial reference function as L.Definition 5 (Partial ratio). Given a minimization problem (n, f , C) and an isolation function μ, the partial ratio of a (partial)solution x with respect to a corresponding partial reference function L isp-ratio(x) = f (x)L(μ(x)),and the conditional partial ratio of y conditioned on x isp-ratio(x | y) =f ( y | x)L(μ( y) | μ(x)),where f ( y | x) = f (x ∪ y) − f (x) and L(μ( y) | μ(x)) = L(μ( y) ∪ μ(x)) − L(μ(x)).The partial ratio is an extension of the approximation ratio. Note that the partial ratio for a feasible solution equalsits approximation ratio. We have two properties of the partial ratio. One is that it is non-increasing in SEIP, as stated inLemma 1, and the other is its decomposability, as stated in Lemma 2.Lemma 1. Given a minimization problem (n, f , C) and an isolation function μ, if SEIP has generated an offspring x with partial ratiop with respect to a corresponding partial reference function L, then there is a solution y in the population such that |μ( y)| = |μ(x)|,and the partial ratio of y is at most p.Proof. x is put into the population after it is generated; otherwise there is another solution xf (xnon-increasing. (cid:2)(cid:15))| = |μ(x)| and. The lemma is proved since L(x) = L( y) and by the superior function the cost is(cid:15)) (cid:2) f (x), and in this case let x = xwith |μ(x(cid:15)(cid:15)From Lemma 1, we know that the partial ratio in each isolation remains non-increasing. Since SEIP repeatedly tries togenerate solutions in each isolation, SEIP can be considered as optimizing the partial ratio in each isolation.Lemma 2. Given a minimization problem (n, f , C) and an isolation function μ, for three (partial) solutions x, y and z such thatz = x ∪ y, we havep-ratio(z) (cid:2) max(cid:6)(cid:7)p-ratio(x), p-ratio( y | x),with respect to a corresponding partial reference function L.Proof. Since z = x ∪ y, we have, by definition,f (z) = f (x) + f ( y | x),andμ(z) = μ(x ∪ y) = μ(x) ∪ μ( y).26Y. Yu et al. / Artificial Intelligence 180–181 (2012) 20–33Thus, we havep-ratio(z) = f (z)L(μ(z))(cid:5)== f (x) + f ( y | x)L(μ(x) ∪ μ( y))f ( y | x)L(μ( y) | μ(x)).f (x)L(μ(x))(cid:6)(cid:7)p-ratio(x), p-ratio( y | x),f (x) + f ( y | x)L(μ(x)) + L(μ( y) | μ(x))(cid:8)(cid:2)(cid:2) max= maxLemma 2 reveals that the partial ratio for a solution is related to the conditional partial ratio of a building block. This canbe considered as the way in which SEIP optimizes the partial ratio in each isolation, that is, by optimizing the conditionalpartial ratio of each building block partial solution. We then have the following theorem.Theorem 1. Given a minimization problem (n, f , C) and an isolation function μ mapping to subsets of [q], assume that every solutionis encoded in an m-length binary vector. For some constant r (cid:3) 1 with respect to a corresponding partial reference function L, if1. p-ratio(x2. for every partial solution x such that p-ratio(x) (cid:2) r, SEIP takes x as the parent solution and generates an offspring partial solution∅) (cid:2) r,y such that μ(x) ⊂ μ(x ∪ y) and p-ratio( y | x) (cid:2) r in polynomial time in q and m,then SEIP finds an r-approximate solution in polynomial time in q and m.∅Proof. Starting from x, we can find a sequence of partial solutions x1, x2, . . . , x(cid:5), such thatx =(cid:5)(cid:4)i=1xi is feasible,and that(cid:9)∀i = 1 . . . (cid:5): p-ratio∅xi | x(cid:10)x j(cid:2) r,i−1(cid:4)j=1because of the conditions. Note that when a partial solution is added to the solution, the offspring solution is in a differentisolation to the parent solution. Since the isolation function is linearly additive, the length of the sequence (cid:5) cannot begreater than the number of isolations q + 1.Let t be the time expected for SEIP to generate a partial solution xi in the sequence from its parent solution, which ispolynomial to q and m by the condition. It takes at most O (q) expected steps for SEIP to pick the parent, since there are atmost q + 1 solutions in the population. Therefore, the total time to reach a feasible solution x is O (t · q · (cid:5)), that is, O (t · q2),which is still polynomial in q and m.By Lemma 2, since the feasible solution x is composed of xand partial solutions x1, x2, . . . , xm, the approximation ratiofor x is at most as large as the maximum conditional partial ratio for the partial solutions, r. (cid:2)∅Theorem 1 reveals how SEIP can work to achieve an approximate solution. Starting from the empty set, SEIP uses itsmutation operator to generate solutions in all isolations, and finally generates a feasible solution. During the process, SEIPrepeatedly optimizes the partial ratio in each isolation by finding partial solutions with better conditional partial ratios.Since the feasible solution can be viewed as a composition of a sequence of partial solutions from the empty set, theapproximation ratio is related to the conditional partial ratio of each partial solution.In Theorem 1, the approximation ratio is upper-bounded by the maximum conditional partial ratio, while some building-block partial solutions may have lower conditional partial ratios but are not utilized. Moreover, in Theorem 1 we restrictSEIP to append partial solutions, while GSEIP can also remove partial solutions using bit-wise mutation. The approximationratio can have a tighter bound if we consider these two issues. Applying the same principle as for Theorem 1, we present atheorem for GSEIP in particular that leads to a tighter approximation ratio.Definition 6 (Non-negligible path). Given a minimization problem (n, f , C) and an isolation function μ mapping to subsetsof [q], assume that every solution is encoded in an m-length binary vector. A set of solutions N is a non-negligible path withratios {ri}q−1−) ∈ N, where thepair of solutions ( y∅ ∈ N and, for every solution x ∈ N, there exists a solution xi=0 and gap c if x−) satisfies(cid:15) = (x ∪ y+ − y+, y−| (cid:2) c,+| + | y1. 1 (cid:2) | yf ( y2.3. if |μ(x)| < q, |μ(x ∪ y− | x) (cid:2) r|μ(x)| · OPT,+ − y+ − y−)| > |μ(x)|.Y. Yu et al. / Artificial Intelligence 180–181 (2012) 20–3327Theorem 2. Given a minimization problem (n, f , C) and an isolation function μ mapping to subsets of [q], assume that every solutionis encoded in an m-length binary vector. If there exists a non-negligible path with ratios {ri}q−1q−1i=0 ri)-approximate solution in expected time O (q2mc).i=0 and gap c, then GSEIP finds a ((cid:2)Proof. We prove the theorem by tracking the process of GSEIP over the non-negligible path. We denote by xcur the solutionwe want to operate on. Initially, xcur = x, and thus |μ(xcur)| = 0.GSEIP takes at most O (q) expected steps to operate on xcur, since there are at most q + 1 solutions in the population∅and GSEIP selects one to operate on in each step.According to the definition of the non-negligible path, there exists a pair of solutions ( y. The probability that the mutation operator generates solution x+, y−) with respect to xcur suchis(cid:15)that 1 (cid:2) | yat least ( 1+| + | ym )c( m−1−| (cid:2) c. We denote x(cid:15) = xcur ∪ y+ − y−m )l−c , which implies O (mc) expected steps.According to the definition of the non-negligible path, suppose that |μ(xcur)| = i; we also have f ( y+ − y(cid:15)) can be decomposed recursively, and thus according to the theorem conditions, we have− | xcur) (cid:2)ri · OPT. Note that f (x(cid:12)(cid:15)x(cid:11)(cid:11)f+ − y= fy= ri · OPT + f− | xcur(cid:12)(cid:11)xcur+ f= · · ·(cid:12)(cid:11)(cid:12)xcur=i(cid:13)j=0r j · OPT + f(cid:12)(cid:11)∅x=i(cid:13)j=0r j · OPT.Let L be a corresponding partial reference function. Thus, p-ratio(x(cid:15)) =(cid:2)ij=0 r j ·OPTL(μ(x(cid:15))).Given |μ(xcur)| = i, again according to the definition of the non-negligible path, we have |μ(x(cid:15)solution xin the population; otherwise there exists another solution x(cid:15)ratio than xby Lemma 1 when we substitute x(cid:15)(cid:15)(cid:15)(cid:15)with |μ(x(cid:15)(cid:15))| = |μ(x(cid:15))| > |μ(x)|. Then we storehas a smaller partial(cid:15)(cid:15)(cid:15))| and xj=0. We have p-ratio(xcur) (cid:2)(cid:15)Now let xcur be xAfter at most q iterations of the above update of xcur, we have |μ(xcur)| = q, which means xcur is feasible. Thus, theq−1j=0 r j , is its approximation ratio.partial ratio of xcur, p-ratio(xcur) =q−1j=0 r j ·OPTOPTq−1j=0 r j ·OPTL(μ(xcur))Thus, at most q jumps are needed to reach a feasible solution, each takes O (mc) expected steps for operation on aparticular solution, and it takes O (q) expected steps to choose the particular solution. Overall, it takes O (q2mc) expectedsteps to achieve the feasible solution. (cid:2)L(μ(x(cid:15)))(cid:2)==(cid:2)(cid:2).(cid:15)for x.(cid:2)|μ(xcur )|−1r j ·OPTUsing Theorem 2 to prove the approximation ratio of GSEIP for a specific problem, we need to find a non-negligible pathand then calculate the conditional evaluation function for each jump on the path. One way of finding a non-negligible pathfor a problem is to follow an existing algorithm for the problem. This will lead to a proof that the EA can achieve the sameapproximation ratio by simulating the existing algorithm. Similar ideas have been used to confirm that EAs can simulatedynamic programming [6]. In addition, note that the concrete form of the partial reference function is not required in thetheorem.5. SEIP for the MSCPTo apply SEIP to the MSCP, we use the fitness functionf (x) = w · x,which has the objective of minimizing the total weight. For a solution x, we denote R(x) =set of elements covered by x. We use the isolation functionμ(x) = R(x),(cid:3)S∈x(C) S, that is, R(x) is the(cid:15), Cwhich, owing to the effect of the isolation function, makes two solutions compete only when they cover the same numberof elements. We could regard a partial reference function L of x to be the minimum price that optimal solutions pay forcovering the same number of elements covered by x, although it is not necessary to calculate the partial reference function.Instead of directly assessing a minimum k-set cover problem (n, w, C, U , k), we analyze EAs for the extended input(cid:15), U , k) [13]. The original problem is extended by first taking a closure of C under the subset operation, that is,(n, w(cid:15)(S j)} if(cid:15) = C ∪ {2S | ∀S ∈ C}, and the weight vector wCis extended accordingly by wS ⊆ S1, S2, . . . , S j . Then if an optimal solution contains a set with less than k elements, we construct a new problem in-stance in which to U are added a minimum number of dummy elements such that all sets of the optimal solution arefilled to be k-sets using dummy elements while keeping their weights unchanged. Therefore, the extended problem has anoptimal solution containing k-sets. Analysis on the extended input leads to the same result as for the original problem, asshown in Lemma 3. The lemma is derived from Lemmas 2 and 3 of [13].(cid:15)(S) = min{w(cid:15)(S2), . . . , w(cid:15)(S1), w(cid:15)28Y. Yu et al. / Artificial Intelligence 180–181 (2012) 20–33Fig. 1. The matrix M∗representation [13] of elements for the minimum k-set cover problem, containing exactly k rows.Lemma 3. The extended input does not affect the optimal cost or the optimal solutions. We can then assume without loss of generality| = k for all i.that an optimal solution xOPT consists of k-sets {S} and is disjoint, that is, S= ∅ for all i and j and |S∩ S∗1, S∗2, . . . , S∗L∗i∗j∗iThus, an optimal solution can be represented as a matrix M∗sponds to the elements in Sexactly k elements. For an element e, we denote Mcontains e. We also denote wthe time at which e is covered.∗(e) as the cost of M∗i . Note that there are exactly k rows in Mof elements, as plotted in Fig. 1, where column i corre-, since each set in an optimal solution contains∗(e) as the column to which e belongs, that is, the set in xOPT that∗(e) at∗(e), and N(e) as the number of uncovered elements in column M∗5.1. SEIP ratio for the (unbounded) MSCPIn Theorem 3 we show that SEIP achieves an Hk-approximation ratio, where k is the cardinality of the largest set. It hasbeen proved that SEMO [11] achieves an Hn-approximation ratio for the MSCP, which is known as the asymptotic lowerbound for the problem. The theorem confirms that SEIP can simulate multi-objective EAs in terms of the solution retained,so that SEIP is able to achieve the approximation ratio obtained by multi-objective EAs.Theorem 3. Given an MSCP (n, w, C, U ) where |C| = m, GSEIP finds an Hk-approximate solution in expected time O (mn2), where kis the size of the largest set in C .The theorem is proved by simulating the greedy algorithm and using the property of the greedy algorithm as in Lemma 4,which is derived from [5].Lemma 4. Given an MSCP (n, w, C, U ) and an arbitrary partial solution x, let ˆS = arg minS r S with respect to x. For every elemente ∈ ˆS, there exists a set M∗(e) of an optimal solution that covers e, and it holds that,price(e) (cid:2)w(M∗(e))|M∗(e) − R(xcur)|.Proof of Theorem 3. We find a non-negligible path following the greedy rule; given the current partial solution, add the setˆS with minimum r ˆS , as in Algorithm 1.We denote xcur as the current solution to be operated on. We find yto xcur. Let y− = ∅. Thus, we have | y+| + | y−| = 1 and |μ(x ∪ y+ − y−)| (cid:3) |μ(x)| + 1 for partial solution x.By Lemma 4, for all e ∈ ˆS − R(xcur), there exists a set M∗(e) of an optimal solution that covers e, and suppose+ = { ˆS} where the set ˆS minimizes r ˆS with respectprice(e) (cid:2)w(M∗(e))|M∗(e) − R(xcur)|.In the worst case, | ˆS − R(xcur)| = 1, that is, the added set only covers one uncovered element e. In this case, according tothe definition of price(e), we have w( ˆS) = price(e). We then have(cid:11)f+ − y− | xcury(cid:12)(cid:11)= fxcur ∪ y(cid:12)+(cid:11)(cid:12)xcur− f1|M∗(e) − R(xcur)|(cid:11)∗(cid:12)(e).M· w= w( ˆS) (cid:2)Thus, we find a non-negligible path with gap 1 and sum of ratiosY. Yu et al. / Artificial Intelligence 180–181 (2012) 20–3329(cid:13)e1|M∗(e) − R(xcur(e))|(cid:11)∗(cid:12)(e)M· w==(cid:2)=|xOPT |(cid:13)(cid:13)j=1e∈S∗j|xOPT |(cid:13)(cid:13)j=1e∈S∗j1|M∗(e) − R(xcur(e))|(cid:11)∗(cid:12)(e)M· w1|M∗(e) − R(xcur(e))|(cid:11)(cid:12)∗jS· w1|M∗(e) − R(xcur(e))||xOPT |(cid:13)j=1|xOPT |(cid:13)(cid:11)(cid:12)·∗jSwk(cid:13)i=1(cid:11)(cid:12)∗jSw· Hkj=1= Hk · OPT,where xcur(e) denotes the partial solution that will cover e in its next step, and k is the size of the largest set in C .By Theorem 2, GSEIP finds an Hk-approximate solution. Note that the isolation function maps to at most n isolations,the non-negligible path has a constant gap of 1, and the solution is encoded in an m-length binary vector; thus, GSEIP takesexpected time O (mn2). (cid:2)Note that in the proof of Theorem 3, with respect to xcur, we find | y−| = 0 and | y+| = 1. Thus, the proof can be adaptedto LSEIP directly, as in Theorem 4.Theorem 4. Given an MSCP (n, w, C, U ) where |C| = m, LSEIP finds an Hk-approximate solution in expected O (mn2) time, where kis the size of the largest set in C .5.2. Ratio for GSEIP for the minimum k-set cover problemIn this section, we prove in Theorem 5 that GSEIP achieves the same (Hk − k−18k9 )-approximation ratio as GAWW (Algo-rithm 2) [13], the current best algorithm for the minimum k-set cover problem. This result reveals that when the problem isbounded, which is very likely in real-world situations, GSEIP can yield a better approximation ratio than in the unboundedsituation. Since the greedy algorithm cannot achieve an approximation ratio lower than Hn, the result also implies thatGSEIP has essential non-greedy behavior for approximations.Theorem 5. Given a minimum k-set cover problem (n, w, C, U , k), where |C| = m, we denote R(x) =R(x) finds an (Hk − k−18k9 )-approximate solution in expected time O (mk+1n2).(cid:3)S∈x S. GSEIP using μ(x) =When applying the GAWW rule to select sets, we use Lemmas 5 and 6. Owing to the assignments of price(·), the totalprice of elements covered by X equals the cost of X . We say a set S is last-covered if ∀e ∈ S: N(e) = 0.Lemma 5 (Lemma 4 of [13]). In each step of GAWW, its partial solution H is disjoint.Lemma 6 (Lemma 5 of [13]). In each step of GAWW, we can assume without loss of generality that the set added to X (i.e., Shas no more than one element in common with every set in xOPT .∗or ˜Q )Lemmas 7 to 10 are derived from Lemmas 8, 9 and 10 in [13] and are required for calculating the weights of sets thatGSEIP selects following the GAWW rule.Lemma 7. Given a minimum k-set cover problem (n, w, C, U , k) and an arbitrary partial solution x, if the GAWW rule uses a with-drawal step to add sets ˜Q = {S1, S2, . . . , Sl} to x and withdrawal ˜S ∈ x, denoting R =(cid:3)S∈ ˜Q S, then(cid:13)S∈ ˜Qw(S) (cid:2) w( ˜S) +(cid:13)e∈R− ˜S∗(e)wN(e) + 1−(cid:13)e∈R− ˜Sw∗(e)k4.30Y. Yu et al. / Artificial Intelligence 180–181 (2012) 20–33Lemma 8. Given a minimum k-set cover problem (n, w, C, U , k) and an arbitrary partial solution x, if the GAWW rule selects a set Sthat is not last-covered to add to x (greedy step), and there is an element e(cid:15) ∈ S such that(cid:12)(cid:11)e(cid:15)∗(cid:12)(cid:11)e(cid:15)< wprice(cid:14)1Li + 1− 14k5(cid:15),thenw(S) (cid:2)(cid:13)e∈S∗(e)wN(e) + 1−(cid:13)e∈S∗(e)w8k8.Lemma 9. Given a minimum k-set cover problem (n, w, C, U , k) and an arbitrary partial solution x, if the GAWW rule selects a set Sthat is not last-covered to add to x (greedy step), followed by another set S, and for all elements e ∈ S for which(cid:15)price(e) (cid:3) w(cid:14)∗(cid:12)(cid:11)e(cid:15)1hi + 1− 14k5(cid:15),thenw(S) + w(cid:12)(cid:15)(cid:11)S(cid:2)(cid:13)e∈S∗(e)wN(e) + 1−(cid:13)e∈S∗(e)w8k8.Lemma 10. Given a minimum k-set cover problem (n, w, C, U , k) and an arbitrary partial solution x, if the GAWW rule selects a set Sthat is last-covered to add to x (greedy step), then∗(e)wN(e) + 1w(S) (cid:2)(cid:13).e∈SProof of Theorem 5. We find a path of isolations following the GAWW rule. Note that there are at most n + 1 isolations.For every xcur belonging to an isolation |μ(xcur)| on the path, if the GAWW rule selects sets satisfying Lemmas 7, 8, 9and 10, we find ycontaining the sets added and y+−containing the set withdrawn. Thus, | y+ − ySince the GAWW rule covers at least one uncovered element, we have |μ(xcur ∪ yAs long as no last-covered set is included, by Lemmas 7, 8 and 9, the partial ratio of f ( y−| (cid:2) k + 1.+| + | y−)| > |μ(xcur)|.+ − y− | xcur) = w( y+) − w( y−)is upper-bounded as(cid:11)wy(cid:12)+(cid:12)−(cid:11)y(cid:2)− w(cid:13)(cid:14)(cid:3)e∈(+ )−(S∈ y(cid:3)− )S∈ y∗(e)wN(e) + 1− w∗(e)8k8(cid:15);otherwise, when the GAWW rule selects a last-covered set using a greedy step, by Lemma 10, noting y∗(e)wN(e) + 1− w(cid:13)(cid:2)(cid:14)(cid:15)w(cid:3)(cid:3)+−yy(cid:12)(cid:11)(cid:12)(cid:11).e∈(+ )−(S∈ y− )S∈ y− = ∅,In the worst case, there are 1/k among all the elements that are last-covered. Therefore, we find a non-negligible path.By Theorem 2, GSEIP finds a solution with approximation ratio(cid:14)(cid:13)ki=11OPT(cid:15)OPTi− k − 1kOPT8k8= Hk − k − 18k9,in expected time O (mk+1n2). (cid:2)5.3. Comparison of the greedy algorithm, LSEIP and GSEIPWe assess the greedy algorithm, LSEIP and GSEIP for a subclass of the minimum k-set cover problem, denoted as prob-lem I . We show in Propositions 1 to 3 that LSEIP and GSEIP can overcome the difficulty that limit the greedy algorithm,and thus yield better approximation ratios.Problem I is a minimum k-set cover problem (n, w, C, U ) constructed as follows. Note that n = kL for some integer L.}Li=1, each of which contains k elements in U . Imagine that∗i . The collection of sets C consists of all∗i weight 1 + (cid:2) for some (cid:2) > 0, and assign each S i j weight 1/ j. Problem I thus constructedThe optimal solution consists of L non-overlapping sets {Selements in each S∗sets of Si and S i j . Assign each Sis shown in Fig. 2.∗i are ordered and let S i j contain only the jth element of set S∗iY. Yu et al. / Artificial Intelligence 180–181 (2012) 20–3331Fig. 2. Subclass I of the minimum k-set cover problem.Proposition 1. Given an arbitrary value ξ > 0, the approximation ratio of the greedy algorithm for problem I is lower-boundedby Hk − ξ .∗Proof. Note that the greedy algorithm adds the set with the minimum cost to the solution at each step. On initialization,k of S ik, the smallest cost. Thus, S ik for all i will be added to thethe cost of Sk−1 for S i(k−1). The greedy algorithm continues to choose(cid:2)1+(cid:2) . Leti for all i is 1+(cid:2)solution. Then the cost of Sa non-optimal set. Finally, all sets S i j will be added to the solution. The approximation ratio is therefore Hk − Hk ·ξ = Hk ·(cid:2)1+(cid:2) . ξ can be an arbitrarily small positive value as (cid:2) can be arbitrarily small. (cid:2)k , which is higher than the cost 1i for all i is 1+(cid:2)∗k−1 , which is higher than 1Proposition 2. With probability of at least 1 − 11k )n3) expected steps.k+1 , LSEIP finds an (Hk − kn (Hk − 1))-approximate solution for problem I in O ((1 +Proof. Let LSEIP run until there are k elements uncovered by any solution identified. This takes O (mn2) expected steps by}. In theTheorem 4, which is O ((1 + 1worst case, we assume the k elements are in one set Sk )n. The uncovered k elements would be covered by sets in {Sk )n3) since m = (1 + 1∗iGiven a solution to be operated on, Sprobability kcover one of the k elements, Sm ; set Sˆi j for j ∈ {1, 2, . . . , k} is selected withm ; with the remaining probability, no more elements will be covered and we return to the solution. Therefore, tok+1 ; and set Sˆi j for j ∈ {1, 2, . . . , k} is selected with probabilityis selected with probability 1∗ˆi∗ˆifor ˆi.is selected with probability 1∗ˆikk+1 .Suppose one set Sˆi ˆj is selected. To cover one more uncovered element, S{1, 2, . . . , ˆj, . . . , k} is selected with probability k−1k . Therefore, the set Sis selected with probability∗ˆi∗ˆiis selected with probability 1k ; Sˆi j for j ∈1k + 1+ 1k(cid:15)(cid:14)1 − 1k + 1+ · · · + 12(cid:14)k+1(cid:16)(cid:15)1 − 1ii=3+ · · · + 12·2k + 1= 1k + 1= kk + 1+ 1k· k + 1k + 1= 1 − 1k + 1kk + 1·,and within O ((k + 1)mn) steps, which is overwhelmed by O (mn2).In the worst case, only one set Sratio is∗ˆiof an optimal solution is selected for the feasible solution. Thus, the approximation(L − 1)Hk + 1 + (cid:2)L(1 + (cid:2))(cid:2) L − 1LHk + 1L= Hk − 1L(Hk − 1) = Hk − kn(Hk − 1).(cid:2)Proposition 3. GSEIP finds the optimal solution for problem I in O ( 1k· (1 + 1k )k+1 · nk+3) expected steps.32Y. Yu et al. / Artificial Intelligence 180–181 (2012) 20–33Proof. Let GSEIP run until a feasible solution is found, which takes O (mn2) expected steps according to Theorem 3. In theworst case, suppose the feasible solution found consists of all sets S i j , so that the approximation ratio is Hk − ξ for anarbitrary small value ξ > 0.Keep GSEIP running until an optimal solution is found. GSEIP chooses to operate on the feasible solution with probabilityof at least 1n as there are n isolations, which implies there are O (n) steps.∗Operating on the feasible solution, for some i, GSEIP uses its mutation operator to replace sets S i j for alli with probability ( m−1Ssteps. Once sets S i j for allsolution is retained.j and withm )k+1, since k + 1 bits in the solution are to be flipped, which implies there are O (mk+1)∗i , the partial ratio (approximation ratio) decreases and thus the mutatedk )k+1Therefore, GSEIP takes O (mn2 +nmk+1 L) steps in all; note that O (mn2 +nmk+1 L) = O (mn2 +n2mk+1/k) = O ( 1km )m−k−1( 1j are replaced with S·(1+ 1· nk+3), since m = n(1 + 1k ). (cid:2)For GSEIP, we can also derive Proposition 4, proof of which is similar to that for Proposition 3.Proposition 4. GSEIP finds an (Hk − c kc = 0, 1, . . . , nk .n (Hk − 1))-approximate solution for problem I in O (mn2 + cn2mk+1/k) expected steps, forThis proposition illustrates an interesting property: compared with the greedy algorithm, whose performance cannotbe improved given extra time, SEIP always seeks better approximate solutions. Users can allocate more running time in atrade-off for better solutions. However, the solution quality may not be improved by an EA over a long time for practicalHP-hard problems. Thus, users should not assume any useful relationship between time allocated and the approximate ratio.6. ConclusionWe studied the approximation performance of an EA framework. SEIP introduces an isolation function to manage com-petition among solutions, which can be configured as a single- or multi-objective EA. We analyzed the approximationperformance of SEIP using the partial ratio and obtained a general characterization of the SEIP approximation behavior. Ouranalysis confirms that SEIP can achieve a guaranteed approximate solution: it tries to optimize the partial ratio of solu-tions in every isolation by finding good partial solutions, then these partial solutions form a feasible solution with a goodapproximation ratio.We studied the performance of SEIP for the MSCP, which is NP-hard. Previous studies [11,28] showed that (1 + 1)-EAis not a good solver for MSCP, while a multi-objective EA achieves a similar approximation ratio to that of the greedyalgorithm. Our analysis extends previous work to show that for the unbounded MSCP, SEIP achieves an Hk-approximationratio (where Hk is the harmonic number of the cardinality of the largest set), the asymptotic lower bound. For the minimumk-set cover problem, it achieves an (Hk − k−18k9 )-approximation ratio, the current best-achievable result [13], which is beyondthe ability of the greedy algorithm. Moreover, for a subclass of the MSCP, we show how SEIP with either one-bit or bit-wisemutation can overcome the difficulty that limits the greedy algorithm.We discussed some advantages and limitations of SEIP for approximations. To prove the SEIP approximation ratio for theMCSP problem, we used SEIP to simulate the greedy algorithm. Since the greedy algorithm is a general scheme for approxi-mations and has been analyzed for many problems, SEIP analysis can be extended to cases for which the greedy algorithmhas been applied, and therefore we can easily show that SEIP is a 1k -approximation algorithm for k-extensible systems [21],including b-matching, maximum profit scheduling and maximum asymmetric TSP problems. Moreover, to prove the approx-imation ratio of SEIP for the minimum k-set cover problem, we used SEIP to simulate the GAWW algorithm, which impliesthat SEIP also has extra behaviors that provide opportunities to exceed the greedy algorithm. However, limitations of SEIPare found from Theorem 2. There are some situations in which SEIP may fail. SEIP is required to flip a number of bits at atime, which depends on n, to achieve a good solution. In this situation, to flip the required number of bits, one-bit mutationis limited since it only flips one bit at a time, and bit-wise mutation is also limited as it requires exponential time. Furtherdesigns for elegant mutation operators may be possible. However, since the solution space has size 2n, any mutation has toassign an exponentially small probability to some distant mutations. Once these distant mutations are required, exponentialtime is required. Another view of this limitation is that since the mutation operator only allows limited steps, SEIP may alsoover-optimize partial ratios, just like the greedy algorithm over-optimizes each step.Our theoretical analysis suggests that EAs can achieve solutions with guaranteed performance. We believe that guaran-teed and better approximation performance can be achieved by better EA design in the future.AcknowledgementsWe thank Dr. Per Kristian Lehre and Dr. Yitong Yin for helpful discussions. This work was partly supported by theNational Fundamental Research Program of China (2010CB327903), the National Science Foundation of China (61073097,61021062), EPSRC (UK) (EP/I010297/1), and an EU FP7-PEOPLE-2009-IRSES project under Nature Inspired Computation andits Applications (NICaiA) (247619).Y. Yu et al. / Artificial Intelligence 180–181 (2012) 20–3333References[1] N. Alon, D. Moshkovitz, S. Safra, Algorithmic construction of sets for k-restrictions, ACM Transactions on Algorithms 2 (2) (2006) 153–177.[2] A. Auger, B. Doerr, Theory of Randomized Search Heuristics – Foundations and Recent Developments, World Scientific, Singapore, 2011.[3] T. Bäck, Evolutionary Algorithms in Theory and Practice: Evolution Strategies, Evolutionary Programming, Genetic Algorithms, Oxford University Press,Oxford, UK, 1996.[4] E. Benkhelifa, G. Dragffy, A. Pipe, M. Nibouche, Design innovation for real world applications, using evolutionary algorithms, in: 2009 IEEE Congress onEvolutionary Computation, Trondheim, Norway, 2009, pp. 918–924.[5] V. Chvátal, A greedy heuristic for the set-covering problem, Mathematics of Operations Research 4 (3) (1979) 233–235.[6] B. Doerr, A.V. Eremeev, C. Horoba, F. Neumann, M. Theile, Evolutionary algorithms and dynamic programming, in: Proceedings of the 11th ACMConference on Genetic and Evolutionary Computation Conference (GECCO’09), Montreal, Canada, 2009, pp. 771–778.[7] S. Droste, T. Jansen, I. Wegener, A rigorous complexity analysis of the (1 + 1) evolutionary algorithm for linear functions with boolean inputs, Evolu-tionary Computation 6 (2) (1998) 185–196.[8] R. Duh, M. Fürer, Approximation of k-set cover by semi local optimization, in: Proceedings of the 29th Annual ACM Symposium on Theory of Computing(STOC’97), El Paso, TX, 1997, pp. 256–264.[9] U. Feige, A threshold of ln n for approximating set cover, Journal of the ACM 45 (4) (1998) 634–652.[10] T. Friedrich, J. He, N. Hebbinghaus, F. Neumann, C. Witt, Analyses of simple hybrid algorithms for the vertex cover problem, Evolutionary Computa-tion 17 (1) (2009) 3–19.[11] T. Friedrich, J. He, N. Hebbinghaus, F. Neumann, C. Witt, Approximating covering problems by randomized search heuristics using multi-objectivemodels, Evolutionary Computation 18 (4) (2010) 617–633.[12] O. Giel, I. Wegener, Evolutionary algorithms and the maximum matching problem, in: Proceedings of the 20th Annual Symposium on TheoreticalAspects of Computer Science, Berlin, Germany, 2003, pp. 415–426.[13] R. Hassin, A. Levin, A better-than-greedy approximation algorithm for the minimum set cover problem, SIAM Journal on Computing 35 (1) (2005)189–200.[14] J. He, X. Yao, Drift analysis and average time complexity of evolutionary algorithms, Artificial Intelligence 127 (1) (2001) 57–85.[15] J. He, X. Yao, An analysis of evolutionary algorithms for finding approximation solutions to hard optimisation problems, in: Proceedings of 2003 IEEECongress on Evolutionary Computation (CEC’03), Canberra, Australia, 2003, pp. 2004–2010.[16] T. Higuchi, M. Iwata, D. Keymeulen, H. Sakanashi, M. Murakawa, I. Kajitani, E. Takahashi, K. Toda, N. Salami, N. Kajihara, N. Otsu, Real-world applicationsof analog and digital evolvable hardware, IEEE Transactions on Evolutionary Computation 3 (3) (1999) 220–235.[17] G.S. Hornby, A. Globus, D.S. Linden, J.D. Lohn, Automated antenna design with evolutionary algorithms, in: Proceedings of 2006 American Institute ofAeronautics and Astronautics Conference on Space, San Jose, CA, 2006, pp. 19–21.[18] J.R. Koza, M.A. Keane, M.J. Streeter, What’s AI done for me lately? Genetic programming’s human-competitive results, IEEE Intelligent Systems 18 (3)(2003) 25–31.[19] M. Laumanns, L. Thiele, E. Zitzler, E. Welzl, K. Deb, Running time analysis of multi-objective evolutionary algorithms on a simple discrete optimizationproblem, in: Proceedings of the 7th International Conference on Parallel Problem Solving from Nature (PPSN’02), London, UK, 2002, pp. 44–53.[20] A. Levin, Approximating the unweighted k-set cover problem: Greedy meets local search, SIAM Journal on Discrete Mathematics 23 (1) (2008) 251–264.[21] J. Mestre, Greedy in approximation algorithms, in: Proceedings of the 14th Annual European Symposium on Algorithms (ESA’06), Zurich, Switzerland,2006, pp. 528–539.[22] F. Neumann, M. Laumanns, Speeding up approximation algorithms for NP-hard spanning forest problems by multi-objective optimization, in: Proceed-ings of the 7th Latin American Symposium on Theoretical Informatics, Valdivia, Chile, 2006, pp. 745–756.[23] F. Neumann, J. Reichel, Approximating minimum multicuts by evolutionary multi-objective algorithms, in: Proceedings of the 10th International Con-ference on Parallel Problem Solving from Nature (PPSN’08), Dortmund, Germany, 2008, pp. 72–81.[24] F. Neumann, I. Wegener, Minimum spanning trees made easier via multi-objective optimization, in: Proceedings of the 7th ACM Annual Conference onGenetic and Evolutionary Computation Conference (GECCO’05), Washington DC, 2005, pp. 763–769.[25] F. Neumann, I. Wegener, Can single-objective optimization profit from multiobjective optimization? in: J. Knowles, D. Corne, K. Deb (Eds.), Multiobjec-tive Problem Solving from Nature – From Concepts to Applications, Springer, Berlin, Germany, 2007, pp. 115–130.[26] F. Neumann, C. Witt, Bioinspired Computation in Combinatorial Optimization – Algorithms and Their Computational Complexity, Springer-Verlag, Berlin,Germany, 2010.[27] F. Neumann, J. Reichel, M. Skutella, Computing minimum cuts by randomized search heuristics, in: Proceedings of the 10th ACM Annual Conferenceon Genetic and Evolutionary Computation (GECCO’08), Atlanta, GA, 2008, pp. 779–786.[28] P. Oliveto, J. He, X. Yao, Analysis of the (1 + 1)-EA for finding approximate solutions to vertex cover problems, IEEE Transactions on EvolutionaryComputation 13 (5) (2009) 1006–1029.[29] R. Raz, S. Safra, A sub-constant error-probability low-degree test, and a sub-constant error-probability PCP characterization of NP, in: Proceedings ofthe ACM Symposium on Theory of Computing (STOC’97), El Paso, TX, 1997, pp. 475–484.[30] J. Scharnow, K. Tinnefeld, I. Wegener, Fitness landscapes based on sorting and shortest paths problems, in: Proceedings of the 7th InternationalConference on Parallel Problem Solving from Nature (PPSN’02), Granada, Spain, 2002, pp. 54–63.[31] P. Slavík, A tight analysis of the greedy algorithm for set cover, Journal of Algorithms 25 (2) (1997) 237–254.[32] C. Witt, Worst-case and average-case approximations by simple randomized search heuristics, in: Proceedings of the 22nd Annual Symposium onTheoretical Aspects of Computer Science (STACS’05), Stuttgart, Germany, 2005, pp. 44–56.[33] Y. Yu, Z.-H. Zhou, A new approach to estimating the expected first hitting time of evolutionary algorithms, Artificial Intelligence 172 (15) (2008)1809–1832.