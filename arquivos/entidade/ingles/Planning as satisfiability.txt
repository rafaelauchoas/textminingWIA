Artificial Intelligence 193 (2012) 45–86Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintPlanning as satisfiability: HeuristicsJussi RintanenInstitute for Integrated and Intelligent Systems, Griffith University, Queensland, Australiaa r t i c l ei n f oa b s t r a c tArticle history:Received 7 June 2011Received in revised form 2 May 2012Accepted 9 August 2012Available online 5 September 2012Keywords:PlanningSATHeuristics1. IntroductionReduction to SAT is a very successful approach to solving hard combinatorial problems inArtificial Intelligence and computer science in general. Most commonly, problem instancesreduced to SAT are solved with a general-purpose SAT solver. Although there is the obviouspossibility of improving the SAT solving process with application-specific heuristics, thishas rarely been done successfully.In this work we propose a planning-specific variable selection strategy for SAT solving. Thestrategy is based on generic principles about properties of plans, and its performance withstandard planning benchmarks often substantially improves on generic variable selectionheuristics, such as VSIDS, and often lifts it to the same level with other search methodssuch as explicit state-space search with heuristic search algorithms.© 2012 Elsevier B.V. All rights reserved.Translation into SAT, the satisfiability problem of the classical propositional logic, is one of the main approaches to solvingthe planning problem in AI. The basic idea, first presented by Kautz and Selman [1], is to consider a bounded-horizonplanning problem, to represent the values of state variables at every time point as propositional variables, to representthe relation between two consecutive states as a propositional formula, and then to synthesize a propositional formulathat is satisfiable if and only if there is a plan of the given bounded length. This idea is closely related to the simulationof nondeterministic polynomial-time Turing machines in Cook’s proof of NP-hardness of SAT [2]. Kautz and Selman’s ideawas considered to be only of theoretical interest until 1996 when algorithms for SAT had developed far enough to makeplanning with SAT practical and competitive with other search methods [3]. Later, SAT and its extensions have become amajor state-space search method in computer-aided verification [4] and in many other areas.In this work we investigate SAT solving for planning with the conflict-driven clause learning (CDCL) algorithm [5,6], thecurrently leading framework for SAT solving for structured problems. Instead of using standard generic CDCL heuristics suchas VSIDS [7], we propose planning-specific heuristics which radically differ from generic CDCL heuristics and are based on asimple property all solutions to a planning problem have to satisfy. The work is motivated by the need to better understandwhy SAT solvers are successful in solving AI planning and other reachability problems, and by the need and opportunity todevelop more powerful, problem-specific heuristics for SAT.Our heuristic chooses action variables that contribute to the goals or subgoals, based on the current partial valuationof the CDCL algorithm, representing a tentative plan and a state sequence corresponding to its execution. The principle isextremely simple: for a given (sub)goal, choose an action that achieves the (sub)goal and that can be taken at the earliest time inwhich the (sub)goal can become (and remain) true. Intuitively, this principle expresses a preference for short and simple plans.After choosing an action, its preconditions become new subgoals for which supporting actions are found in the same way.The principle is easy to implement: start from a goal (or a subgoal), go backwards step by step until a time point in whichE-mail address: jussi@cecs.anu.edu.au.0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.08.00146J. Rintanen / Artificial Intelligence 193 (2012) 45–86the goal is false, and choose any of the actions that can turn it from false to true at that time point. If such an action existedin the plan already, perform the procedure recursively with the preconditions of the action as the subgoals.Interestingly, it turns out that heuristics based on the above principle are often far more effective in finding plans thanthe sophisticated heuristics used by modern general-purpose SAT solvers. Furthermore, a naïve application of the principle –leading to a depth-first backward chaining planning algorithm inside the CDCL framework – lifts the efficiency of SAT-basedplanning close to level with the best earlier planners which use other search methods. This is a very significant result,because the currently best state-space search planners, which have their origins in the work of Bonet and Geffner [8], usefar more complex heuristics and additional pruning techniques to achieve a comparable performance.The simplicity and effectiveness of the principle immediately suggests that there are additional heuristics to obtainfurther efficiency improvements. Instead of finding motivation for such heuristics from standard benchmarks, we look atgeneric properties of planning problems and generic structural properties of the search trees generated by the principle. Wepresent heuristics for ordering the new subgoals and for choosing one of the applicable actions, as well as propose a schemethat replaces the pure depth-first backward search by a less directional form of search. For standard benchmark problemsin planning, the additional heuristics lift the performance of the new variable selection scheme still further.We view this work as a step toward developing efficient SAT-based techniques for planning and other related problemssuch as model-checking [4] and discrete-event systems diagnosis [9]. More advanced heuristics for these applications arelikely to also incorporate features from VSIDS, including the computation of weights of variables based on their occurrencein recently learned clauses. We believe that the success of the planner developed in this work with the standard planningbenchmark problems is more an indication of the simple structure of these benchmarks, and that more challenging problemswill need more complex variable selection heuristics. This observation is supported by earlier works that illustrate thescalability of typical planners in solving combinatorially hard problems [10,11].The structure of the paper is as follows. Section 2 describes the background of the work in planning with SAT. InSection 3 we present the variable selection scheme for planning, and in Section 4 we propose additional heuristics for it.Section 5 describes the implementation of a planning system that is based on the preceding two sections and our earlierworks [12]. In Section 6 we experimentally evaluate the planning system, and in Section 7 we discuss related work beforeconcluding the paper in Section 8.2. Planning as satisfiability2.1. BackgroundReduction to the SAT problem was proposed as a way of solving the planning problem in the 1992 paper by Kautz andSelman [1]. At the same time, algorithms for solving the SAT problem were progressing rapidly, and in 1996 Kautz andSelman were able to show their planning system to scale up better than Graphplan [13] and other planning systems of thetime [3]. These results were obtained with SAT solvers such as WalkSat [14,15] and Tableau [16].The reduction to SAT and the general solution method outlined by Kautz and Selman dominated the SAT approach toplanning for the next several years, and became the basis of scientifically and commercially very successful computer-aidedverification methods in the form of bounded model-checking [4]. In the planning community, however, the focus shifted toheuristic state-space search algorithms as proposed by Bonet, Loerincs and Geffner in the HSP planner starting in 1997[17,8].The decreasing interest of planning researchers in SAT at this time can be traced to two factors: the impractically largesize of the CNF formulas generated from the standard benchmark problems with the early encoding schemes, and the veryhigh computational cost of completing the satisfiability tests for horizon lengths shorter than the shortest plan.As proposed by Kautz and Selman, the planners sequentially went through horizon lengths 0, 1, 2, and so on, until theyreached a horizon length for which the formula is satisfiable, yielding a plan. Essentially, Kautz and Selman’s procedurecorresponds to breadth-first search, and these planners proved that the plan that was found had the shortest possiblehorizon. However, guaranteeing that plans have the shortest possible horizon is unimportant, as the horizon length doesnot, for commonly used notions of parallel plans, coincide with relevant plan quality measures, such as the sum of actioncosts. The notion of parallelism also does not correspond to actual temporal concurrency, but the possibility of reordering theparallel actions to a valid sequential plan [12], and therefore should be viewed as a way of inducing a smaller search space.The unsatisfiability proofs could be avoided by using parallelized search strategies [18]. These often speed up planning byorders of magnitude. At the same time, compact linear-size encodings were proposed. Earlier encodings, such as those basedon the planning graphs of Graphplan [13], had a quadratic size, due to the encoding of action mutexes in the most straight-forward way as binary clauses. The linear-size encodings largely eliminated the problem of excessive memory consumption,and also otherwise yielded substantial performance improvements [19,12]. These developments bridged the performancegap between SAT-based planning and explicit state-space search substantially (for standard benchmarks), and reduced thememory consumption so that it was not an obstacle to efficient planning.Since mid-1990s, there have also been substantial improvements in the performance of algorithm implementations forSAT. The SATZ solver of Li and Anbulagan [20] was influential in the late 1990s, and its implementation techniques werea basis of a very efficient planner with a specialized built-in SAT-style search algorithm [21]. Practically all of the efficientSAT solvers since 2000 have been based on ideas popularized in the zChaff solver [7] which replaced the earlier almostJ. Rintanen / Artificial Intelligence 193 (2012) 45–8647exclusively used Davis–Putnam–Logemann–Loveland procedure [22] by the related conflict-driven clause learning algorithm[5,6], and introduced the very effective VSIDS heuristic as well as new data structures for very efficient unit propagation.These techniques are also applied in the SAT solver used in this work.2.2. Formalization of planningThe classical planning problem involves finding an action sequence from a given initial state to a goal state. The actionsare deterministic, which means that an action and the current state determine the successor state uniquely. A state s : X →{0, 1} is a valuation of X , a finite set of state variables. In the simplest formalization of planning, actions are pairs (cid:3)p, e(cid:4)where p and e are consistent sets of propositional literals over X , respectively called the precondition and the effects. Wedefine prec((cid:3)p, e(cid:4)) = p. Actions of this form are known as STRIPS actions for historical reasons. An action (cid:3)p, e(cid:4) is executable(cid:6) = exec(cid:3)p,e(cid:4)(s) isin a state s if s |(cid:5) p. For a given state s and an action (cid:3)p, e(cid:4) executable in s, the unique successor state s(cid:6)(x) = s(x) for all x ∈ X such that x does not occur in e. This means that the effects are true indetermined by sthe successor state, and all state variables not affected by the action retain their values. Given an initial state I , a plan toreach a goal G (a set of literals) is a sequence of actions a1, . . . , an such that execan (execan−1 (· · · execa2 (execa1 (I)) · · ·)) |(cid:5) G.(cid:6) |(cid:5) e and s2.3. Reduction of planning to SATKautz and Selman [1] proposed finding plans by a reduction to SAT. The reduction is similar to the reduction of NP Turingmachines to SAT in Cook’s proof of NP-hardness of SAT [2]. The reduction is parameterized by a horizon length T (cid:2) 0. Thevalue of each state variable x ∈ X in each time point t ∈ {0, . . . , T } is represented by a propositional variable x@t. For eachaction a and t ∈ {0, . . . , T − 1} we similarly have a propositional variable a@t indicating whether action a is taken at t.A given set X of state variables, an initial state I , a set A of actions, goals G and a horizon length T is translatedinto a formula ΦT such that ΦT ∈ SAT if and only if there is a plan with horizon 0, . . . , T . This formula is expressed interms of the propositional variables x@0, . . . , x@T for all x ∈ X and a@0, . . . , a@T − 1 for all a ∈ A. For a given t (cid:2) 0, thevaluation of x1@t, . . . , xn@t, where X = {x1, . . . , xn}, represents the state at time t. The valuation of all propositional variablesrepresents a state sequence, and the difference between two consecutive states corresponds to taking zero or more actions.The conditions for allowing multiple actions at the same step can be defined in alternative ways [12]. For our purposesby a set E of executed actions satisfies the following three properties:it is sufficient that the change from state s to s(cid:6) = execan (execan−1 (· · · execa2 (execa1 (s)) · · ·)) for some ordering1) s |(cid:5) p for all (cid:3)p, e(cid:4) ∈ E, 2) sa1, . . . , an of E. These conditions are satisfied by all main encodings of planning as SAT [23]. The only encodings that do notsatisfy these conditions (part 1, specifically) are the relaxed ∃-step semantics encoding of Wehrle and Rintanen [24] and theencodings by Ogata et al. [25], which allow the precondition of an action to be supported by parallel actions, instead of thepreceding state.(cid:2)To represent planning as a SAT problem, each action a = (cid:3)p, e(cid:4) and time point t ∈ {0, . . . , T − 1} is mapped to formulasa@t →l∈e l@(t + 1).1 These two formulas respectively correspond to the executability condition andthe first part of the definition of successor states. The second part, about state variables that do not change, is encoded asfollows when several actions can be taken in parallel. For each state variable x ∈ X and time point t ∈ {0, . . . , T − 1} we have(cid:6) |(cid:5) e for all (cid:3)p, e(cid:4) ∈ E, and 3) sl∈p l@t and a@t →(cid:2)(cid:6)x@(t + 1) →(cid:3)x@t ∨ ax1@t ∨ · · · ∨ axn@t(cid:4)where axas well as1, . . . , axn are all the actions that have x as an effect, for explaining the possible reasons for the truth of x@(t + 1),¬x@(t + 1) →(cid:3)¬x@t ∨ a¬x1 @t ∨ · · · ∨ a¬xm @t(cid:4),¬x1 , . . . , a¬xm are all the actions with ¬x as an effect, for explaining the possible reasons for the falsity of x@(t + 1).where aThese formulas (often called the frame axioms) allow inferring that a state variable does not change if none of the actionschanging it is taken.Additional constraints are usually needed to rule out solutions that don’t correspond to any plan because parallel actionscannot be serialized. For example, actions (cid:3){x}, {¬ y}(cid:4) and (cid:3){ y}, {¬x}(cid:4) cannot be made to a valid sequential plan, becausetaking either action first would falsify the precondition of the other. In our planners, we use the linear-size ∃-step semanticsencoding of Rintanen et al. [12], which often requires only few or no additional constraints.There is one more component in efficient SAT encodings of planning, which is logically redundant but usually critical forefficiency: invariants [21,26]. Invariants l ∨ lwith two literals express binary dependencies between state variables. Manyof the standard planning benchmarks represent many-valued state variables in terms of several Boolean ones, and a typicalinvariant ¬x1 ∨ ¬x2 says that a many-valued variable x can only have one of the values 1 and 2 at any given time.(cid:6)1 For negative literals l = ¬x, l@t means ¬(x@t), and for positive literals l = x it means x@t. Similarly, we define the valuation v(l@t) for negative literalsl = ¬x by v(l@t) = 1 − v(x@t) whenever v(x@t) is defined. The complement l of a literal l is defined by x = ¬x and ¬x = x.48J. Rintanen / Artificial Intelligence 193 (2012) 45–86Initialize v to satisfy all unit clauses in C ;Extend v by unit propagation with C ;level := 0;1: procedure CDCL(C )2:3:4:5: do6:7:8:9:10:11:12:13:14:15:16: while some variable is not assigned in v;17:if level = 0 and v (cid:10)|(cid:5) c for some c ∈ C then return false;Choose a variable x with v(x) undefined;Assign v(x) := 1 or v(x) := 0;level := level + 1;Extend v by unit propagation with C ;if v (cid:10)|(cid:5) c for some c ∈ Cthenreturn true;end ifInfer a new clause c and add it to C ;Undo assignments until x so that c is not falsified and decrease level accordingly;Fig. 1. Outline of the CDCL algorithm.For a given set X of state variables, initial state I , set A of actions, goals G and horizon length T , we can compute (inlinear time in the product of T and the sum of sizes of X , I , A and G) a formula ΦT such that ΦT ∈ SAT if and only ifthere is a plan with horizon 0, . . . , T . ΦT includes the formulas described above, the unit clause x@0 if I(x) = 1 and ¬x@0if I(x) = 0 for x ∈ X , and l@T for all l ∈ G. These formulas are in CNF after trivial rewriting.A planner can do the tests Φ0 ∈ SAT, Φ1 ∈ SAT, Φ2 ∈ SAT, and so on, sequentially one by one, or it can make several ofthese tests in parallel (interleave them). For this we will later be using Algorithm B of Rintanen et al. [12] which allocatesCPU time to different horizon lengths according to a decreasing geometric series, so that horizon length t + 1 gets γtimes the CPU the horizon length t gets, for some fixed γ ∈]0, 1[. In general, the parallelized strategies can be ordersof magnitudes faster than the sequential strategy because they do not need to complete the test Φt ∈ SAT (finding Φtunsatisfiable) before proceeding with the test Φt+1 ∈ SAT. Since the unsatisfiability tests, which tend to be far more difficultthan determining a formula to be satisfiable, don’t need to be completed, it is far more important to efficiently determinesatisfiability than unsatisfiability.2.4. The CDCL algorithmIn this section we briefly describe the standard conflict-driven clause learning (CDCL) algorithm [5] for solving the SATproblem. This algorithm is the basis of most of the currently leading SAT solvers in the zChaff family [7]. For a detailedoverview of the CDCL algorithm and its implementation see standard references [27,28].The main loop of the CDCL algorithm (see Fig. 1) chooses an unassigned variable, assigns a truth-value to it, and thenperforms unit propagation to extend the current valuation v with forced variable assignments that directly follow from theexisting valuation by the unit resolution rule. If one of the clauses is falsified, a new clause which would have preventedconsidering the current valuation is derived and added to the clause set. This new clause is a logical consequence ofthe original clause set. Then, some of the last assignments are undone, and the assign-infer-learn cycle is repeated. Theprocedure ends when the empty clause has been learned (no valuation can satisfy the clauses) or a satisfying valuation hasbeen found.The selection of the decision variable (line 7) and its value (line 8) can be arbitrary (without compromising the cor-rectness of the algorithm), and can therefore be based on a heuristic. The currently best generic SAT solvers use differentvariants and successors of the VSIDS heuristic [7]. The heuristic is critical for the efficiency of the CDCL algorithm.On lines 3 and 10 the standard unit propagation algorithm is run. It infers a forced assignment for a variable x if thereis a clause x ∨ l1 ∨ · · · ∨ ln or ¬x ∨ l1 ∨ · · · ∨ ln and v |(cid:5) ¬l1 ∧ · · · ¬ ∧ ln. The inference of a new clause on line 13 is thekey component of CDCL. The clause will prevent generating the same unsatisfying assignment again, leading to traversing adifferent part of the search space.The amount of search performed by the CDCL algorithm can be characterized by the numbers of decisions and conflicts.The number of decisions is the number of assignments of decision variables, that is, the number of executions of lines 7and 8. The number of conflicts is the number of executions of line 13. This is usually the number of new clauses learned,although some CDCL implementations may learn multiple clauses from one conflict.2.4.1. The VSIDS heuristicThe VSIDS (Variable State Independent Decaying Sum) heuristic [7] for choosing the next decision variable in the CDCLalgorithm is based on weights of the propositional variables. When the SAT solving process is started, the weight of avariable is initialized to the number of times it occurs in the input clauses. When the CDCL algorithm learns a new clause,the weight of each variable occurring in the clause is increased by one. To decrease the importance of clauses learnedearlier, the weights of all variables are divided by some constant at regular time intervals. The VSIDS heuristic chooses asthe new decision variable one of the unassigned variables with the maximal weight.J. Rintanen / Artificial Intelligence 193 (2012) 45–86492.4.2. RestartsAn important component in the performance of CDCL is restarts [7,29]. Line 14 makes CDCL a form of backtracking,and long sequences of earlier variable assignments may remain untouched, which often reduces the possibilities of findinga satisfying assignment. To prevent this, the current SAT solvers perform a restart at regular intervals (for example afterevery 100 conflicts), which means terminating the CDCL algorithm, and starting it from the beginning, but retaining all thelearned clauses and the current variable weights. Since the variable weights have changed since the previous restart, theCDCL algorithm will make a different sequence of variable assignments than before, moving the search to a different part ofthe search space. For the completeness of CDCL with restarts it is important that the same assignments are not consideredrepeatedly. Clause deletion to avoid memory overflows and slow down of CDCL [7] risks this, but completeness of CDCL canbe theoretically guaranteed by increasing the time interval in which clause deletion is performed. This is what many SATsolvers do, also the one used in our work.3. The heuristicThe goal of our work is to present a new way of choosing the decision variables (lines 7 and 8 in the CDCL procedure inFig. 1) specific to planning. Our proposal only affects the variable selection part, and hence it doesn’t affect the correctnessor completeness of the CDCL algorithm.The main challenge in defining a variable selection scheme is its integration in the CDCL algorithm in a productive way.To achieve this, the variable selection depends not only on the initial state, the goals and the actions represented by theinput clauses, but also the current state of execution of the CDCL algorithm. The state of the execution is characterized byA) the current set of learned clauses and B) the current (partial) valuation reflecting the decisions (variable assignments)and inferences (with unit propagation) made since the last restart. We have restricted the variable selection to use only partB of the SAT solver state, the current partial valuation.The variable selection scheme is based on the following observation: each of the goal literals has to be made true byan action, and the precondition literals of each such action have to be made true by earlier actions (or, alternatively, theseliterals have to be true in the initial state). Hence, to find the next decision variable for the CDCL algorithm, we find one(sub)goal that is not in the current state of search supported (made true) by an action or the initial state.More concretely, we proceed as follows. The first step in selecting a decision variable is finding the earliest time point at(cid:6) < t in whichwhich a (sub)goal (for time t) can become and remain true. This is by going backwards from t to time point tI) an action making l true is taken or II) l is false (and l is true or unassigned thereafter). The third possibility is that theinitial state at time point 0 is reached and l is true there, and hence nothing needs to be done. In case I the plan alreadyhas an action that makes the subgoal true, and in case II we choose any action that can change l from false to true between(cid:6)t(cid:6) + 1, and use it as a decision variable.2 In case I we recursively find support for the literals in the precondition.and tThe computation is started from scratch at every iteration of the CDCL procedure because a particular support for a(sub)goal, for example the initial state, may become irrelevant because of a later decision, and a different support needs tobe found.When all (sub)goals have a support, the current partial assignment represents a plan. The assignment can be made totalby assigning unassigned action variables false and unassigned fact variables the value they have in the closest precedingtime point with a value.Notice that the only part of the above scheme for selecting a decision variable that has the flavor of a heuristic is therestriction to the earliest time points in which the (sub)goal can be true, corresponding to a preference for short and simpleplans.To find a satisfying assignment for the SAT instance, every (sub)goal has to be made true, and the core of our scheme isthe focus on the shortest or simplest action sequences for achieving this. This works very well with CDCL because the partialassignments maintained by the CDCL algorithm give useful information about the possibilities of achieving the (sub)goals.Often, when reaching a (sub)goal l seems to be possible at time t but not earlier (meaning that v |(cid:5) l@(t − 1) and l@tis unassigned), it is a useful guess that l@t can indeed be made true at that point. And if this is not possible, the CDCLalgorithm will often detect this quickly, which leads to trying to make l true at a later time point instead.Example 1. We illustrate the search for an unsupported (sub)goal and the selection of an action with a problem instancewith goals a and b and actions X = (cid:3){d}, {a}(cid:4), Y = (cid:3){e}, {d}(cid:4), and Z = (cid:3){¬c}, {b}(cid:4).variableabcde00000110000200540316112 Such an action necessarily exists because otherwise l would have to be false also at t(cid:6) + 1. This is by the frame axiom for l.50J. Rintanen / Artificial Intelligence 193 (2012) 45–86Empty the priority queue;for all l ∈ G do insert l@T into the queue according to < and mark it;Z := ∅;if v(a@tthen1: procedure support(G, A, T , v)2: Unmark all literals;3:4:5:6: while the queue is non-empty doPop l@t from the queue;7:(cid:6) := t − 1;t8:found := 0;9:10:repeat11:12:13:14:15:16:17:18:19:20:21:22:23:24:25:26:(cid:6)insert lfound := 1;(cid:6) − 1;(cid:6)insert lfound := 1;until found = 1 or tend whilereturn Z ;for all unmarked l(cid:6)) = 0 thenelse if v(l@t(cid:6) < 0;(cid:6) := t@t@tt(cid:6)(cid:6)(cid:6)) = 1 for some a ∈ A with l ∈ eff(a)(cid:6) ∈ prec(a) dointo the queue according to < and mark it;a := any a ∈ A such that l ∈ eff(a) and v(a@tZ := Z ∪ {a@tif terminate(Z , a@tfor all unmarked l(cid:6)) then return cleanup(Z , a@t(cid:6) ∈ prec(a) do(cid:6)};(cid:6));into the queue according to < and mark it;(* Take one (sub)goal. *)(* The subgoal is already supported. *)(cid:6)) (cid:10)= 0;(* Earliest time it can be made true *)Fig. 2. Computation of supports for (sub)goals.Consider the goal a at time point 6. The latest time point at which a is false is 4, and hence it seems that a couldbecome true at 5 and remain true until 6.Let’s assume that X@4 is unassigned, and hence could make a true at 5. We can then choose X@4 as a support for a@5,and use X@5 as the next decision literal in the CDCL algorithm.After X@5 is assigned true, we would need support for its precondition d at time point 4. The new subgoal d couldchange from false to true between time points 2 and 3, and the action Y could be cause of this change. After Y @2 has beenused as the decision literal, we would need support for its precondition e@2, and would determine that no further actionsare needed as e is already true in the initial state and can remain true until time point 2.For the second top-level goal b, assume that Z @2 is assigned true and hence explains the change of b from false to truebetween time points 2 and 3. Since Z ’s precondition ¬c is satisfied by the initial state, again no further action is required.We have marked those timed variables in boldface which change from false to true above.The procedure in Fig. 2 implements the variable selection scheme as described above. The subprocedure terminate( X, a@t)implements a termination condition, which in our baseline case is terminate(Z , a@t) iff | Z | = 1, i.e. the first action foundis used as the next decision variable. The subprocedure cleanup( X, a@t) decides whether (after identifying action a@t) toreturn the whole set Z or something less. The baseline implementation returns Z as is, i.e. cleanup(Z , a@t) = Z . In Section 4we consider alternative implementations of these subprocedures. Given the goal G, the actions A, the horizon length T , anda partial valuation v of the propositional variables representing the planning problem with horizon length T , the procedurecall support(G, A, T , v) will return a set of candidate decision variables.The procedure starts with inserting all goal literals in G to a priority queue. The ordering of the literals in the queuedetermines the order in which candidate actions are generated. In the baseline version of the variable selection scheme wedefine <0 as the empty relation, so that the queue acts as a stack (last in, first out.) Later we will consider more informedorderings. The priority queue as a stack together with the computation of only one action for the next decision variableforce the CDCL algorithm to do a form of backward chaining depth-first.On line 7 the next (sub)goal literal l@t is taken from the queue. The loop between lines 10 and 24 identifies an actionthat supports or could support l@t. It goes from time point t − 1 step by step to earlier time points, until it finds an actionthat supports l@t (line 11) or the earliest time point tat which l@t can become and remain true (16).(cid:6)If an action was found, the search must continue with finding support for the preconditions of the action. For thispurpose the preconditions are inserted in the priority queue on line 13.(cid:6)If the earliest time t(cid:6)in which l can be supported was found without an action, then one of the actions that can maketrue is chosen on line 17. This action is added to the set Z on line 18, and the set is returned if the terminationl@tcondition is met. If the termination condition is not yet met, the preconditions of the action are inserted in the priorityqueue on line 20.The choice of a on line 17 of Fig. 2 is arbitrary, but it should be fixed for example by choosing the first a ∈ A thatsatisfied the two conditions in some fixed ordering. Intuitively, this is important to avoid losing focus in the CDCL search.Similarly the ordering of (sub)goal literals in the priority queue in situations in which < does not strictly order one beforethe other is arbitrary, but should be similarly fixed for the same reason.J. Rintanen / Artificial Intelligence 193 (2012) 45–86511:2:3:4:5:6:S := support(G, A, T , v);if S (cid:10)= ∅ then v(a@t) := 1 for a@t = choose(S);else(* Found an action. *)if there are unassigned x@t for x ∈ X and t ∈ {1, . . . , T }then v(x@t) := v(x@(t − 1)) for any unassigned x@t with minimal telse v(a@t) := 0 for any a ∈ A and t ∈ {0, . . . , T − 1} with a@t unassigned;Fig. 3. Variable selection for planning with the CDCL algorithm.return randomly chosen element of S;1: procedure chooserandom(S)2:3:4: procedure chooseweighted(S)5:return an element of S with the highest VSIDS weight, with ties broken randomly;3.1. Integration in the CDCL algorithmFig. 4. Procedures from selecting one of several candidate actions.The procedure in Fig. 2 is the main component of the variable selection scheme for CDCL given in Fig. 3,in whichan action is chosen as the next decision variable for the CDCL algorithm if one is available. If several are available, one ischosen either randomly (formalized as the procedure chooserandom(S) in Fig. 4) or according to the weights as calculatedfor VSIDS-style heuristics when learning a new clause (formalized as the procedure chooseweighted(S) in Fig. 4). The weightparameter of an action occurrence a@t is increased for its every occurrence in a learned clause, and all the weights aredivided by two in regular intervals, after every 32 conflicts.If no actions are available, all goals and subgoals are already supported. The current valuation typically is still notcomplete, and it is completed by assigning unassigned fact variables the value they have in the predecessor state (line 5)and assigning unassigned action variables the value false (line 6). The code in Fig. 3 replaces VSIDS as the variable selectionheuristic in the CDCL algorithm of Fig. 1. This is by removing lines 7 and 8 and replacing them by the code in Fig. 3. Notethat some actions are inferred by unit propagation on line 10 in the CDCL algorithm, and these actions are later handledindistinguishably from actions chosen by the heuristic.3.2. Complexity of the variable selection algorithmIf there are n state variables and the horizon length is T , then there are nT variables that represent state variables atdifferent time points. Since each literal is inserted into the priority queue at most once, the algorithm does the outermostiteration on line 6 for each goal or subgoal at most once, and hence at most nT times in total. The number of iterations ofthe inner loop starting on line 10 is consequently bounded by nT 2.The actual runtime of the algorithm is usually much lower than the above upper bound. A better approximation for thenumber of iterations of the outer loop is the number of goals and the number of preconditions in the actions in the planthat is eventually found. In practice, the runtime of the CDCL algorithm with our heuristic is still strongly dominated byunit propagation, similarly to CDCL with VSIDS, and computing the heuristic takes somewhere between 5 and 30 per centsof the total SAT solving time, depending on the properties of the problem instance.4. Refinements to the heuristicThe variable selection scheme from Section 3 alone, without any further heuristics, leads to a powerful planner. However,experience from SAT solvers and from the application of SAT solving to planning specifically [21] suggests that the fixed goalorderings and the strict backward chaining depth-first search are not the best possible way of using CDCL. In this sectionwe consider three strategies to more effectively take advantage of the strengths of the CDCL algorithm.First, we will present a goal-ordering heuristic for controlling the priority queue. The order in which the algorithm inFig. 2 encounters actions directly determines the ordering in which variables are assigned in the CDCL algorithm, assumingthat only the first action found is returned.Second, we can use a heuristic for choosing which action to use to achieve a subgoal, instead of choosing an arbitraryaction.Third, the search with strict backward chaining will be relaxed. Backward chaining means selecting an action with aneffect x given a goal x, and taking the preconditions of the action as new goals, for which further actions are chosen. Thesearch with backward chaining proceeds step by step toward earlier time points (until some form of backtracking takesplace). With CDCL and other SAT algorithms, the search does not have to be directional in this way, and actions less directlysupporting the current (sub)goals could be chosen, arbitrarily many time points and actions earlier. The algorithm in Fig. 2can be forced to compute a complete set of candidate actions for supporting all goals and subgoals and their preconditions,but randomly choosing one action from this set is not useful, and we need a more selective way of using them.Next we will consider these three possible areas of improvement, and in each case propose a modification to the basicvariable selection scheme which in Section 6 will be shown to lead to substantial performance improvements.52J. Rintanen / Artificial Intelligence 193 (2012) 45–86return S;if |S| = 1 return true;return false;1: procedure terminate0(S, a@t)2:3:4:5: procedure cleanup0(S, a@t)6:7:8: procedure terminate1(S, a@t)9:10:11:12: procedure cleanup1(S, a@t)13:return S\{a@t};if |S| (cid:2) 10 or t (cid:2)bound return true;return false;4.1. Goal orderingFig. 5. Different subprocedures of the selection scheme.Using the priority queue as a stack, as in the baseline implementation of the variable selection scheme in Section 3,leads to depth-first search in which the traversal order of the children of a node is arbitrarily determined by the order inwhich they are inserted in the queue.As an alternative to using the queue as a stack, we considered the ordering <v which orders (sub)goals as l1@t1 <v l2@t2(cid:6)) (cid:10)= 1if and only if mv (l1@t1) < mv (l2@t2), where mv (l@t) is defined as the maximal t(cid:6)) is unassigned. According to this ordering, l gets a higher priority if it must have been madeincludes the case that v(l@ttrue earlier than other subgoals. The most likely plan first makes l true, followed by the other subgoals. Intuitively, thismeasure is an indicator of the relative ordering of the actions establishing different preconditions of a given action.(cid:6) < t such that v(l@t(cid:6)) (cid:10)= 1. Here v(l@tWe tried out some other similar simple orderings, but experimentally they did not improve the planner performance.A key property of the mv measure is that for every goal or subgoal l@t, the new subgoals l1@t − 1, . . . , ln@t − 1 all havea higher priority than their parent l@t. This will still lead to depth-first search, but the ordering of the child nodes will bemore informed.4.2. Choice of actionOn line 17 in the algorithm in Fig. 2 the choice of the action is left open. For each action a@t we calculate a score that(cid:6) > t suchis the number of time points following t that the action a could be taken (that is, the number of time points tthat the variable a@t is unassigned). Then we choose an action occurrence a@t with a minimal score. Intuitively, this scoremeasures how constrained the candidate actions are. More constrained actions are more likely to lead to further inferencesor an early detection of a contradiction for the current partial plan.4.3. Computation of several actionsTo make the plan search less directional, we experimented with computing a set S of some fixed number N of actionsand randomly choosing one a@t ∈ S. In the framework of the algorithm in Fig. 2 this means defining terminate(S, a@t) toreturn true when |S| = N. The initial experiments seemed very promising in solving some of the difficult problems muchfaster. However, the overall improvement was relatively small, and it very surprisingly peaked at N = 2.What happened is the following. For a given top-level goal l ∈ G, several of the first actions that were chosen supportedthe goals. However, after everything needed to support l was included, the computation continued from the next unsupportedtop-level goal. Consequently, at the final stages of finding support for a top-level goal we would be, in many cases, selectingsupporting actions for other top-level goals, which distracts from finding support for l. With N = 2 the distraction is smallenough to not outweigh the benefits of considering more than one action.This analysis led us to a second variant, which proved to be very powerful. We record the time-stamp t of the firstaction found. Then we continue finding up to N actions, but stop and exit if the time-stamp of a would-be candidate actionis (cid:2) t. This means defining terminate(S, a@t) as true if |S| = N or t > bound, where bound is initialized right after line 17by if Z = ∅ then bound := t, and cleanup(S, a@t) = S\{a@t} if t > bound and S otherwise. With this variant we obtained asubstantial overall improvement with higher N. In our experiments we used N = 40.4.4. Variants of our plannerLater in Section 6 we refer to different variants of our planner as follows, based on different implementations ofterminate(S, a@t) and cleanup(S, a@t) from Fig. 5, and either the trivial ordering <0 of the priority queue leading to astack behavior or the more informed ordering <v from Section 4.1. The base planner uses the uninformed selection of sub-goals and does backward chaining. Backward chaining is enforced by only computing one action that supports the currentsubgoal. The less directed form of search is obtained by computing several actions, and then choosing one of them randomlyJ. Rintanen / Artificial Intelligence 193 (2012) 45–8653Table 1List of features of different planner configurations.FeatureTerminationGoal orderingAction choiceSearchbasea---g---m--wterminate0, cleanup0terminate1, cleanup1terminate1, cleanup1<0<varbitraryinformedbackward chainingnon-directional, chooserandom(S)non-directional, chooseweighted(S)with chooserandom(S) or according to the VSIDS-style weights with chooseweighted(S) (Fig. 4). The informed action selection,based on a heuristic, is as described in Section 4.2.The different features with which our planner can be configured are listed in Table 1. The feature a denotes the informedaction selection from Section 4.2, the feature g the ordering of goals from Section 4.1, and the features m and w therelaxed action selection from a set of actions respectively by random choice and by VSIDS weights. The two choices withand without a, the two choices with and without g, and the three choices with m or w or neither, induce 12 differentconfigurations in which the new heuristic can be used. Our planner with the agw configuration is called Mp, and ourplanner configured to use the generic SAT heuristic VSIDS is called M. Essentially, M is an efficient implementation of theplanner described in our work from 2006 [12]. The 12 different configurations of the planner are experimentally comparedin Section 6.6.1.4.5. DiscussionThe good performance of the fixed and uninformed variable selection is due to its focus on a particular action sequence.Any diversion from a previously tried sequence is a consequence of the clauses learned with CDCL. This maximizes theutility of learned clauses, but also leads to the possibility of getting stuck in a part of the search space void of solutions.A remedy to this problem in current SAT solvers is restarts [7]. However, with deterministic search and without VSIDS-stylevariable (or action) weighting mechanism, restarts make no difference, as the assignment right before the restart wouldnecessarily be generated right after the restart. In SAT algorithms that preceded VSIDS, a small amount of randomizationin the selection of the decision variable was used to avoid generating the same assignments repeatedly [30]. However, toolarge diversion from the previous action sequences makes it impossible to benefit from the clauses learned with CDCL.Hence the key problem is finding a balance between focus to recently traversed parts of the search space and pursuingother possibilities.The flexible depth-first style search from Section 4.3 provides a balance between focus and variation. The candidateactions all contribute to one specific way of supporting the top-level goals, but because they often don’t exactly correspondto an actual plan (except for at the very last stages of the search), varying the order in which they are considered seems tobe an effective way of probing the “mistakes” they contain.5. ImplementationThe implementation of the planner uses the techniques introduced in our earlier works, including the compact linear-size encoding of the ∃-step semantics [12] and the parallel evaluation strategy implemented by Algorithm B [18,12]. Nextwe describe the different components of the planner in detail.5.1. EncodingThe ∃-step encoding we use in our planners differs from the traditional encodings with respect to parallelism. Traditionalencodings (called ∀-step encodings in our earlier works [12]) allow a set of actions in parallel if imposing any total orderingon them results in an executable action sequence. A sufficient condition for this is that the actions don’t interfere: noaction disables a parallel action or affects its (conditional) effects. The traditional way to encode this condition is to useaction mutexes ¬a1@t ∨ ¬a2@t to state that interfering actions a1 and a2 cannot be taken simultaneously. In the worst case,the number of these mutexes is quadratic in the number of actions, and this is a main reason for the very large size oftraditional encodings.The ∃-step plans relax ∀-step plans by only requiring that there is at least one total ordering of the parallel actions. Thereare several alternative ways of implementing this substantially more relaxed condition [12]. The simplest modification totraditional encodings is to only change the action mutexes. Instead of requiring that the disables/affects relation restrictedto the simultaneous actions is empty, it is only required that this relation is acyclic [12]. There is a simple encoding for thisthat is linear in the size of the actions’ effects [12], based on imposing a fixed total ordering on the actions and requiringthat no action disables/affects a later action.Further, for almost all of the standard planning competition benchmarks the disabling/affects relation restricted to setsof actions without mutually contradicting preconditions or effects can contain only small cycles or no cycles at all: this canbe shown by computing the strongly connected components (SCC) of a disabling graph [12]. Any cycle must be contained54J. Rintanen / Artificial Intelligence 193 (2012) 45–86in an SCC. SCCs of size 1 cannot be involved in a cycle, and if all SCCs are of size 1, no action mutexes are needed at all.Hence many and sometimes all of the cycles are eliminated already because sets of actions with mutually contradictingpreconditions or effects cannot be taken in parallel anyway.Also the general linear-size encoding scheme for action mutexes is improved when it can be restricted to small SCCsrather than the whole action set. For small SCCs some of the auxiliary variables required in the general for of the encodingcan be easily eliminated. Also, our planner can choose between the general linear-size encoding and the trivial worst-casequadratic explicit encoding of action mutexes which does not require auxiliary variables [12]. The latter can be better if theSCC is small and many pairs of actions have mutually contradictory preconditions or effects.In summary, the two benefits of ∃-step encodings over the traditional ∀-step encodings are that more actions are al-lowed in parallel, reducing the horizon lengths and therefore speeding up search, and the number and complexity of actionmutexes is reduced and they are often not needed at all, further speeding up search and reducing memory requirements.The computation of the disabling graphs is one of two time-consuming parts of the front-end of our planner, when thenumber of actions is tens or hundreds of thousands. This is because the number of arcs in the graphs can be quadratic in thenumber of actions (nodes) in the worst case. For 80 per cent of the planning competition instances (which are experimentedwith in Section 6.6) the graphs are computed in less than 2 seconds, and for 16 instances it took more than 60 seconds. Thiscomputation is highly optimized. Naïve implementations would slow down the planner considerably. For example, insteadof constructing the disabling graph explicitly before running Tarjan’s strongly connected components algorithm, it is muchmore efficient to generate on the fly only those arcs that are actually followed by Tarjan’s algorithm. Explicit generation ofthe graph would unnecessarily spend substantial amounts of time determining existence of irrelevant arcs. Also, we usedcompact data structures which increase locality of memory references and decrease the number of cache misses.5.2. InvariantsAn important part of efficient SAT encodings of planning is invariants, facts that hold in the initial state and will continueto hold after any number of actions have been taken. Computing invariants is the second part of the planner’s front-endsometimes with a high overhead.The identification of invariants is important for many types of planning problems represented in languages like PDDLand STRIPS that only support Boolean state variables. What would naturally be a many-valued state variable in higherlevel languages is often represented as several dependent Boolean variables in PDDL and STRIPS. Recognizing and explicitlyrepresenting these dependencies, that an n-valued state variable cannot have two different values simultaneously, is criticalfor efficiently solving most of the standard benchmark problems with SAT. As in most works on planning, we restrict to2-literal invariants l ∨ lwhich are sufficient for representing the most important variable dependencies.We used a powerful yet simple fixpoint algorithm for computing invariants [31]. Our implementation works with thegrounded problem instance, and it slows down when the number of ground actions increases to tens or hundreds ofthousands. The computation of invariants for 90 per cent of the planning competition instances in Section 6.6 takes lessthan 2 seconds, and for 42 instances it takes over 60 seconds. For the largest instances of AIRPORT/ADL and VISITALL it takesseveral minutes. Similarly to disabling graphs, the invariant computation is highly optimized to minimize cache misses.(cid:6)Our planner simplifies action sets based on information given by invariants. Actions that have a precondition that contra-dicts an invariant and therefore cannot be a part of a valid plan, are eliminated. If the literal l is an invariant, its occurrencesare eliminated from all actions. Pairs of literals l and lare invariants (which is equivalent tol ↔ l) always have the same value. All occurrences of one of the literals are replaced by the other literal.such that both l ∨ l(cid:6) and l ∨ l(cid:6)(cid:6)(cid:6)5.3. SAT solverUnlike in the experiments described in the earlier article [12], the new planner uses our own SAT solver implementation,with data structures supporting the interleaved solution of several SAT instances for different horizon lengths of the sameproblem instance inside one process and thread. The solver goes through the instances in a round-robin manner, switchingfrom instance to instance at every restart. The solver’s clause database is shared by all of the SAT instances, and also someother data structures are shared, including the binary input clauses which typically strongly dominate the size of the clausesets that represent planning problems. As there is a copy of the same binary clauses for representing actions and invariantsfor every time point, our SAT solver represents the clauses in a parameterized form, with time as the parameter [32]. Thisoften decreases memory consumption substantially, and reduces the number of cache misses when accessing the clauses.The CDCL implementation in our SAT solver is conventional. It includes the VSIDS heuristic as an alternative heuristic,the phase selection heuristic from RSAT to enhance VSIDS [33], and a watched literal implementation of unit propagationas in the zChaff solver [7]. We tried different clause learning schemes and decided to use the Last UIP scheme as it seemsequally good as the more commonly used First UIP scheme [28]. We make a restart after every 60 learned clauses.The computation of the new heuristic is relatively expensive, but not substantially more so than VSIDS. For a smallcollection of hard planning problems for which a substantial amount of search was needed, the SAT solver spent 59.76 percent of the time doing unit propagation, 22.54 per cent of the time computing the heuristic, and the remaining 17.7 percent with the rest of the CDCL algorithm, including learning clauses and maintaining the clause set. These percentages weremeasured with the gprof profiler with code instrumented by the gcc compiler. The code was compiled without functionJ. Rintanen / Artificial Intelligence 193 (2012) 45–8655inlining to enable measurement by function, which may distort the relative percentages in comparison to fully optimizedcode.The main difference between our SAT solver and the best generic SAT solvers is that we don’t use a preprocessor tologically simplify the clause sets. In our experiments, we found the generic preprocessing techniques to be too slow for thevery large clause sets obtained from planning, to the extent that they hamper efficient planning. Preprocessing can reducethe size of the search space exponentially, but for the kind of very large SAT problems experimented with in Section 6.6 andthe relatively short runtimes (30 minutes), the exponential reductions don’t materialize. We will comment on the relativeefficiency of our SAT solver with respect to generic SAT solvers in Section 6.4.5.4. Top-level planning procedureThe top-level procedure of our planner solves SAT instances corresponding to the planning problem for different planlengths. The planner implements a number of alternative strategies.The traditional sequential strategy, first presented by Kautz and Selman [1], solves the SAT problem for horizon length1 first, and if the formula is unsatisfiable, it continues with horizon lengths 2, 3 and so on. This procedure correspondsto breadth-first search, in which all action sequences of length n − 1 are considered before proceeding with sequences oflength n. It is often very ineffective because of the hardness of the unsatisfiable formulas corresponding to horizon lengthsbelow the shortest plan [18].In all of the experiments reported later (unless otherwise stated), we use a more effective strategy formalized as algo-rithm B by Rintanen [18], with γ = 0.9. The algorithm interleaves the solution of several horizon lengths, and its importantproperty is that the satisfiability test for a formula for horizon length n can be started (and completed) before the tests ofunsatisfiable formulas for lengths < n have been completed. This way the planner does not get stuck with very hard un-satisfiable formulas. Rintanen’s algorithm B allocates CPU to formulas Φ0, Φ1, Φ2, . . . representing different horizon lengthsaccording to a geometric series: formula Φn gets CPU proportional to γ n where γ is a constant satisfying 0 < γ < 1. TheSAT problem for the shortest active horizon length gets 1 − γ per cent of the CPU: with γ = 0.9 this is 10 per cent andwith γ = 0.5 it is 50 per cent. Conceptually the algorithm considers an infinite number of horizon lengths, but to makethe algorithm practical, our planner is solving, at any given time, the SAT problems of at most 20 horizon lengths. As someinstances are shown unsatisfiable, the solver is started for longer horizon lengths. Our planners consider horizon lengths 0,5, 10 and so on.much faster, and it is never slower by more than a factor ofRintanen [18] has shown that algorithm B can be – in comparison to the traditional sequential procedure – arbitrarily11−γ .Other top-level algorithms exist, including Rintanen’s algorithm A [18,34] which equally splits CPU to a fixed numberof SAT solving processes, and Streeter and Smith’s algorithms [35] which perform a form of a binary search to identify thesatisfiable formula with the shortest horizon length. Streeter and Smith’s algorithms require as input an upper bound onthe horizon length, which is generally available in scheduling problems but not in planning. Rintanen’s algorithm A is oftencomparable to algorithm B, but overall appears somewhat worse.5.5. Conjunctive conditional effectsOur planner accepts the general (non-temporal) PDDL language [36]. The heuristics can be extended to cover the fulllanguage, with conditional effects and disjunctive conditions [37]. In the experiments reported later, we include problemswith conditional effects, but no disjunction. The extension to the heuristic required to handle conditional effects is simple,and the further extension to cover disjunction is more complicated [37].A formula isconjunctive if it is a conjunction of one or more literals and constants (cid:16) or ⊥. An action is conjunctive,if its precondition is conjunctive and for every conditional effect φ (cid:3) l the condition φ is conjunctive. The effect l of theconditional effect is made true if and only if the condition φ is true when taking the action.Instead of considering literals to be achieved by actions, we consider them to be achieved by conditional effects φ (cid:3) lof actions, with (cid:16) (cid:3) l for handling unconditional effects. When translating a planning problem into a propositional formula,we introduce a propositional variable for every conditional effect (effects φ (cid:3) l1 and φ (cid:3) l2 of one action may use the samepropositional variable, because these conditional effects must always take place together).For example, the action (cid:3)φ, {x (cid:3) y, z (cid:3) w}(cid:4) is translated into a formula with the two auxiliary variables u1 and u2 forthe two conditional effects as follows.a@t → φ@ta@t ∧ x@t → u1@tu1@t → y@(t + 1)u1@t → x@tu1@t → a@t56J. Rintanen / Artificial Intelligence 193 (2012) 45–86a@t ∧ z@t → u2@tu2@t → w@(t + 1)u2@t → z@tu2@t → a@tWith the ui variables the frame axioms(cid:3)(cid:4)y@t ∧ ¬ y@(t + 1)→ u1@t ∨ · · ·can be trivially turned to clauses.The propositional variables for the conditional effects are handled in our heuristic exactly like the propositional variablesfor actions.6. EvaluationIn the experimental part of this work, we make a comparison between the traditional CDCL heuristics such as VSIDS andthe new heuristics proposed in this work, and between our SAT-based planners and planners that use other search methods,including explicit state-space search [8] and stochastic search in the space of plans [38].Our planner with VSIDS as the decision heuristic, corresponding to our earlier work [12], has already been shown todramatically outperform planners with the BLACKBOX architecture [39] on the standard benchmark sets, so we don’t includethese planners in the comparison.3As the goal of the work is to show that the new heuristics are competitive for the standard benchmarks from theplanning competition, the main focus of the comparison to other planners and to SAT-based planning with generic heuristicsis with the best configuration of our new heuristics (agw), as determined in Section 6.6.1. This is the planner we call Mp.In Sections 6.5.1, 6.5.2 and 6.5.3 we compare Mp to M, the variant of our planner that uses the standard VSIDS decisionheuristic, with a number of problem classes for which standard SAT solvers are known to perform particularly well. InSection 6.6 we shift focus to the planning competition benchmarks, first showing that our new variable selection heuristicis outperformed by VSIDS with unsatisfiable formulas. Then we show, however, that the heuristics’ behavior with satisfiableformulas is far more critical for the planners’ performance with the planning competition benchmarks, to the extent thatthe new heuristic lifts the efficiency of SAT as a planning method to the same level with best earlier planners (Section 6.6).6.1. Test materialWe use problem instances from 3 different categories of planning problems. Next we describe these categories in moredetail, pointing out some of the limitations of each.1. We test more than 1600 problem instances from the biennial planning competitions from 1998 to 2008, and the 2011competition [41], which represent small to very large planning problems, with the largest instances having thousandsof state variables and hundreds of thousands of actions, and still often solved quickly by many planners. A detailed listof the benchmark domains is given in Table 5 on page 67. These are the problems many works on classical planningfocus on, including ones evaluating and comparing different planners.The planning competition domains represent a wide range of mostly simplified planning scenarios from transportation,autonomous systems, control of networked systems such as oil pipelines, as well as a number of less serious scenariossuch as stacking and unstacking blocks, mixing cocktails, or parking cars.The instance sets available and commonly used by the planning community could be more informative for plannerevaluation. First, for many of the domains, all or most of the planners solve all the instances quickly, often in a matterof seconds. Little or no information about the planners’ scalability and asymptotic behavior can be obtained in thesecases. Second, in the 2011 competition, for many domains the instances are relatively hard, some planners not solvingany or only few instances, and for some of the domains all instances are of roughly the same difficulty. In these caseswe only obtain qualitative information, that some planners are equally strong or (at least somewhat) stronger than someothers for instances of a given difficulty level, but it is not possible to quantify this difference further or asymptotically.2. Of combinatorially harder planning problems, which earlier have been best solved by generic SAT solvers, we usedproblems obtained through translations from hard combinatorial graph and other problems into planning [10]. We usethe problem sets made available by Bonet on his web page.3. Other classes of small but hard problems are those obtained by sampling from the space of all planning problems, witha sampling distribution experimentally determined to produce hard problems. These problems were first considered by3 None of the recent published works on planning with SAT make an experimental comparison to other search methods because of the large performancegap between BLACKBOX style planners and recent state-space search planners such as LAMA [40].J. Rintanen / Artificial Intelligence 193 (2012) 45–8657Bylander [42]. We use elaborations of Bylander’s models by Rintanen [11], as well as a newer model that only producessolvable instances [43].For the first class of problems, we use a sequence of problem instances that covers the phase transition region fromeasy to hard to easy instances, for a fixed number of state variables and a varying number of actions.For the second class of problems, we go through a sequence of different problem sizes, increasing the number of bothactions and state variables linearly while keeping the parameters affecting the relative difficulty constant.We describe the instances from each of these categories in more detail in Sections 6.6, 6.5.1 as well as 6.5.2 and 6.5.3,respectively. The main point of comparison for the other search paradigms is the benchmarks from the planning competi-tions, for which SAT earlier was not very competitive. For the combinatorially harder problems we demonstrate the trade-offrepresented by our new heuristics: the new heuristic is generally between SAT-based planning with VSIDS as implementedin our M planner, and the planners that don’t use SAT. M is in general the strongest planner with these problems.6.2. Other planners evaluatedIn addition to SAT-based planning with general-purpose heuristics, we make a comparison to planners that don’t useSAT. The most competitive planners are ones from the HSP family of planners [8], which use explicit state-space search, andthe LPG-td planner [38] which uses two search algorithms, one doing search in the space of partial plans and the otherdoing explicit state-space search.A distinction between planners is whether they – like LPG-td – use a portfolio of algorithms or only use one algorithm. Togive more depth to our evaluation, we look at the individual components of some of the earlier portfolio-based planners, aswell as consider the impact of our new planner when used as a part of a portfolio. Algorithm portfolios [44–46] have beenrecognized as an important approach to solving hard combinatorial problems when different individual algorithms havecomplementary strengths and none of the individual algorithms alone is very strong. Portfolios can be used in differentways, either choosing one algorithm based on the characteristics of the problem instance at hand, or running several of thealgorithms in parallel, or according to a schedule.The planning community has used small portfolios, typically consisting of two algorithms, and the constituent algorithmshave been selected by trial and error based on their performance with the standard benchmark sets. The first planner touse portfolios was BLACKBOX [39]. It used hand-crafted schedules which determined which SAT solvers are run in whichorder and for how long. Later, FF and LPG-td used two-algorithm portfolios, with the second algorithm run after the firstalgorithm had terminated without finding a plan, according to a termination criterion. Lots of other portfolios are possible,obtained by combining any collection of two or more search algorithms. Some of them are discussed in Section 6.7.In our experimental study, we compare our SAT-based planners to the following planners.1. HSP is the original heuristic state-space search planner by Bonet and Geffner [17,8]. It implements a number of searchalgorithms and heuristics based on delete relaxations.HSP restricts to the STRIPS subset of (non-temporal) PDDL without disjunctive conditions or conditional effects.We used HSP version 2.0 with forward search (explicit state-space search), the additive sum heuristic, and the best-firstsearch algorithm. We used the -w 5.0 option as suggested by Bonet and Geffner, to make the search more greedy.2. FF [47] is a planner that uses a 2-algorithm portfolio, adding an incomplete local search phase before a HSP-stylecomplete search. The first phase does a hill-climbing search with the generation of successor states restricted to a subsetgenerated by helpful actions to minimize the time spent evaluating the heuristic value of states, and with exhaustivebreadth-first search to escape plateaus and local minima. FF’s first phase also uses a goal agenda mechanism which iscritical for solving many of the Blocks World instances, some Airport instances, but otherwise has little or no impact.The second phase is essentially HSP with a heuristic similarly based on delete relaxations but with a different methodfor counting the actions required to reach the goals, and with a similar performance. The second phase is started afterthe first phase cannot escape a local minimum.FF’s parser did not parse half of the instances of the 2008 TRUCK domain because of a stack overflow caused by arecursive grammar rule, but these instances are already beyond FF’s reach, so this issue does not affect the results ofthe experiments.3. LPG-td [38] is a 2-algorithm portfolio similarly to FF. Its first stage is stochastic local search in the space of partial plans.The second stage is FF’s HSP-style best-first search. Of the algorithms we test, the first phase of LPG-td is the only onethat uses neither SAT nor explicit state-space search, and its heuristics are radically different from the ones used by theother planners.Similarly to HSP, LPG-td is restricted to STRIPS.We ran LPG-td with the default settings and a preference for low runtimes rather than small plans. When testing thefirst phase only with the -nobestfirst option, we changed the -restarts setting from the low default value to1000 to make use of all of the available 1800 seconds rather than giving up too early. The LGP-td binary that wasavailable to us limited to 10 000 actions, not allowing to run the planner with a number of the largest instances,in particular those of LOGISTICS, which the planner would probably have solved quickly. Similarly, a hard limit on thenumber of goal literals in the binary we had prevented LGP-td from solving a number of VISITALL instances it otherwisesolved quickly.58J. Rintanen / Artificial Intelligence 193 (2012) 45–86LPG-td incorrectly claims the unsolvability of 5 instances of the PARCPRINTER domain, which it otherwise solves easily.4. YAHSP [48] uses FF’s heuristic and a best-first search algorithm with preference to actions that are helpful according tothe FF definition. YAHSP also introduces shortcuts to the search space obtained from prefixes of relaxed plans computedas a part of the heuristic. Unlike FF and LPG-td, YAHSP consists of one phase only. Similarly to HSP and LPG-td, YAHSPonly supports STRIPS.We ran the planner with its default settings. Equality is incorrectly implemented in YAHSP’s front-end, requiring smallmodifications in the TPP and SCANALYZER domain files: See Section 6.6 for details.5. LAMA [40] combines FF’s heuristic with another heuristic (landmarks), and it has a scheme for preferring successorstates reached by helpful actions that differs from YAHSP’s. Unlike the other planners, LAMA’s preprocessor constructsa many-valued representation from the Boolean PDDL representation, and thus has a more compact higher-level rep-resentation to work with than the other planners. LAMA has one phase only, and a main difference to YAHSP is – inaddition to the use of an aggregate of heuristics – the lack of the shortcut mechanism. The purpose of LAMA’s landmarkheuristic is to improve the quality of plans and it has little impact on its performance and scalability otherwise [40].LAMA, similarly to M, Mp and FF, supports the PDDL language with conditional effects (ADL).We ran two variants of LAMA, the 2008 competition version and the newer (unpublished) 2011 competition version,which we respectively call LAMA08 and LAMA11. Both planners were run otherwise with default settings, but tunedto find plans faster rather than to find good plans, as advised by LAMA’s authors. Some issues with the front-end ofLAMA08 were fixed by replacing the front-end with a newer version from the Fast Downward system, following MalteHelmert’s instructions. LAMA08 incorrectly reports 6 AIRPORT/ADL instances unsolvable.These planners are the winners of the non-optimal classical planning tracks of the 2000, 2002, 2008, and 2011 compe-titions (FF, LPG-td, LAMA08, LAMA11), and a runner-up from the 2004 competition (YAHSP). We did not include winningplanners from the 2004 and 2006 competitions. LAMA08 is a successor of the 2004 winner FD and it is implemented in thesame general framework. The 2006 winner SGPlan uses specialized solution methods for several of the standard benchmarkdomains. Overall, the planners we use are frequently used in experimental comparisons of planning algorithms.6.3. Test equipment and settingAll the experiments were run in workstations with Intel Core i7 3930K CPUs running at 4.2 GHz with 32 GB of mainmemory and a 12 MB L3 cache, under Linux Mint. All planners were run in a single core with the other five cores busy, sothat access to the shared L3 cache was not exclusive during the runs. We had the binaries of YAHSP and LPG-td only for the32-bit x86 instruction set, which meant that these planners could use at most 4 GB of memory. However, these plannersterminated because of a memory overflow only in very few cases. We observed with the other planners for which we coulduse both 32-bit and 64-bit versions that the 32-bit version is often 20 per cent faster, most likely because of smaller memoryuse, due to the use of 4-byte instead of 8-byte pointers. We compiled M, Mp, HSP, FF and LAMA from the source files to usethe full amd64 instruction set that allows addressing memory past the 4 GB bound. The memory limitations were relevantonly for some of the planning competition benchmarks that are experimented with in Section 6.6. With them, LAMA usedmore than 4 GB of memory for 61 instances, including 20 with over 8 GB. LAMA solved 7 of the instances requiring over4 GB of memory, and 6 of the ones requiring over 8 GB. For our planners M and Mp, the consideration of long horizonlengths for instances with very high numbers of actions (hundreds of thousands and more) meant allocating large amountsof memory, and we stopped considering longer horizons as soon as 10 GB of memory had been allocated. This affectedabout a dozen of problem instances. Of instances solved by Mp in 30 minutes, over 4 GB of memory was used for 71 andover 8 GB for 23.For most of the experiments we used a 1800 second time limit per instance. The 1800 second time limit was chosen toget a good understanding of the relative behavior of the planners on a relatively long time horizon, but also to allow theexperiments to be carried out in a reasonable amount of time. As we will see later, all of the planners solved few instancesbetween the 10 and 30 minute marks, and performance differences that showed up past the 3 minute mark are of minorimportance. This suggests that the 30 minute time limit is more than sufficient to differentiate between the planners. Thereported runtimes include all standard phases of a planner, starting from parsing the PDDL description of the benchmarkand ending in outputting a plan.We ran each planner with each problem instance once. The randomization from Section 4.3 affects the runtimes ofour planner on different runs, but not much: different complete runs of all instances solved two instances more or less,depending on whether the runtimes were slightly below or slightly above the time limit. Of the other planners, we ranLPG-td with the random seed 12345 and did not try other seeds. The rest of the planners don’t use randomization or usepseudorandom generators with a fixed seed number.6.4. Confirmation of the efficiency of our SAT solver implementationTo show that the quality of the implementation of our SAT solver and the VSIDS heuristic matches the state-of-the-art in SAT solving, we compare our SAT solver to the winners of the application/industrial track in the 2007 and 2011J. Rintanen / Artificial Intelligence 193 (2012) 45–8659Fig. 6. Number of instances solved by different SAT solvers.SAT competitions, RSAT [33]4 and Lingeling. The runtimes for solving the planning competition problems (see Section 6.6)are given in Fig. 6. We translated the test problems into DIMACS CNF for horizon lengths 0, 5, 10, 15, 20, . . . , 1305 andsolved them with a 180 second time limit per instance,6 and then calculated the corresponding Algorithm B runtimes withγ = 0.9. The Lingeling and RSAT runtimes exclude the construction of the CNF formulas by our planner’s front-end, and forthis reason the curves are not completely accurate. The times also exclude the writing and reading of DIMACS CNF files,With these problem instances, our SAT solver with VSIDS as the decision heuristic outperforms RSAT with all timeoutlimits until 1800 seconds, and it outperforms Lingeling for timeout limits until about 500 seconds. With timeout limits past500 seconds Lingeling solves as many instances as M. A main factor in the runtime differences is preprocessing: for manylarge SAT instances that our planners solve almost instantaneously, RSAT and Lingeling spend considerable time with thepreprocessing before starting the search phase. Otherwise the efficiency of our CDCL implementation is almost at the samelevel as Lingeling and RSAT, in terms of the number of decisions and conflicts per second. Because our SAT solver does nopreprocessing and Lingeling strongly relies on it, these solvers’ behaviors substantially differ. Lingeling’s runtimes are oftenmuch higher than M’s, up to two or three orders of magnitude, but in some cases the preprocessing pays off and Lingelingscales up better, solving more instances.A peculiarity of SAT problems obtained by translation from the standard planning benchmark problems from the planningcompetitions, in contrast to SAT problems representing many other applications, is their extremely large size and the factthat these problems can still often be solved quickly. The largest SAT problems Lingeling solves (within the time boundsexplained earlier) are instance 41 of AIRPORT (417 476 propositional variables, 92.9 million clauses) and instance 26 ofTRUCKS (926 857 propositional variables, 11.3 million clauses).Our planner solves instance 49 of AIRPORT (13 840 actions and 14 770 state variables) with a completed unsatisfiabilitytest for horizon 65, with 1.12 million propositional variables and 108.23 million clauses, and a plan for horizon 85, with 1.46million propositional variables and 141.54 million clauses. The planner also solves instance 33 of SATELLITE (989 250 actionsand 5185 state variables), with a plan found for horizon 20, with 19.89 million propositional variables and 69.99 millionclauses, backtrack-free in 14.50 seconds excluding translation into SAT and including search effort for shorter horizons.These are extreme cases. More typical SAT instances have less than 2 million propositional variables and a couple of millionclauses.As we will see in Sections 6.5.2 and 6.5.3, all existing planners have difficulties solving much smaller problems that havea more complex structure, with only some dozens of actions and state variables. For these problems, the SAT instances havesome thousands of clauses and propositional variables.6.5. Comparison of planners with combinatorially hard problemsDifferent approaches to planning and state-space search have different strengths. When the state space can be easilycompletely enumerated and the number of states is at most some millions, blind explicit state-space search is generally thestrongest approach. The SAT approach is more sensitive to the length of the plans, and cannot always take advantage of thesmall cardinality of the state space. One strength of SAT has been in solving hard combinatorial planning problems, with4 We used RSAT 3.0 from 2008, without the SATeLite preprocessor.5 For the blocks world problems we used horizon lengths up to 200.6 This is sufficient to determine the planners’ runtimes up to 1800 seconds with γ = 0.9.60J. Rintanen / Artificial Intelligence 193 (2012) 45–86Table 2Number of Porco et al. [10] instances solved by different planners in 300 seconds.DomaincliquecoloringHamiltoniank-colorabilitymatchingSATtotalInstances6002802004801602001920Mp6164821226941439M19366711118078599LAMA08371651143539291FF424525401153HSP2353854020140YAHSP611854113330279state spaces beyond the reach of explicit state-space search, and with a structure too complex to be captured by existingheuristics.In this section we evaluate the impact of our new heuristics on the solution of such planning problems. We considertranslations of hard combinatorial search problems into planning as proposed by Porco et al. [10], as well as hard instancesgenerated according to problem parameters that have been empirically determined to be hard for existing algorithms [11].6.5.1. Graph problemsSome of the hardest planning problems are those that include hard combinatorial problems as subproblems. Althoughmany hard combinatorial problems appear implicitly or explicitly as subproblems in many planning problems of practicalrelevance, it is also interesting to study these problems in isolation. Porco et al. [10] have presented a method for generatingtranslations of NP-complete problems to planning, and demonstrated it with several graph problems, including Clique, 3-Coloring, Hamiltonian Circuit, k-Colorability, Matching and SAT. According to Porco et al. [10], our planner M with a general-purpose SAT solver as the search method is the strongest with these problems, but they do not quantify this statementfurther.We ran the planners with a 300 second time limit, and summarize the results in Table 2.7 Unlike Porco et al., whoseexperiments had most of the instances solved by M in 1800 seconds, we did not use the known plan length lower andupper bounds and could not therefore distinguish “no” answers from timeouts, leading to M solving less than half of theinstances, and only ones with a “yes” answer. Similarly to the planning problems that involve solving hard unsatisfiableformulas (see Section 6.6.2), VSIDS is stronger than our new heuristics. For some problems the differences seem minor, butwe suspect that major differences would be apparent with instances with negative answers (testing of unsatisfiability), assuggested by the results of Section 6.6.2.Both SAT-based planners perform considerably better than LAMA, FF, HSP and YAHSP. As half of the problems containednegative preconditions and other features not handled by HSP or YAHSP, we eliminated the unsupported features beforerunning HSP and YAHSP. We do not include data for LPG-td because all instances it solves are due to its second phasewhich is borrowed from FF.6.5.2. Solubility phase transitionThe discovery of the relation between computational difficulty and phase transitions, the relatively abrupt transition fromsolvable to unsolvable problem instances as a parameter is changed [49,50], was one of the great advances in understandingthe difficulty and structure of hard combinatorial problems such as SAT. The hardest instances of a problem are typically inthe parameter range that covers the phase transition region, and instances outside the region are typically easy. Essentially,the phase transition region divides the problem instances to the easy under-constrained, the hard critically constrained, andthe easy over-constrained, Phase transitions exist in all kinds of constraint-satisfaction, resource-allocation and planningproblems, but in their purest form they have been investigated in the form of models of sampling from the space of allproblem instances.In planning, phase transitions and easy-hard-easy patterns were first observed and investigated by Bylander [42]. Theunder-constrained instances are those with lots of actions and consequently also lots of alternative plans (which Bylandershowed to be easily solvable by a simple hill-climbing search), the over-constrained are those with few actions and no plans(which Bylander showed to have no plans by a simple syntactic test), and the critically constrained those in between, with asmall number of plans which are difficult to find. The parameter values corresponding to the critically constrained problemscan be understood in terms of the graph density in random graph models, defined as the ratio of arcs to nodes, and theemergence of the giant component [51] as the density is increased [11]. The critically constrained instances in Bylander’sand related models are significantly harder than the planning competition benchmarks (Section 6.6) of the same size: someinstances with only 20 state variables are hard, and many with only 40 state variables are very hard [11].In our experiments, we used model A [11] to generate 4500 instances that covers the easy-hard-easy transition in thephase transition region. The instances have 40 state variables, the actions have 3 preconditions and 2 effects, and there is7 We give the results for LAMA08, which performed substantially better than LAMA11.J. Rintanen / Artificial Intelligence 193 (2012) 45–8661Fig. 7. Percentage of instances solved in the phase transition region.only one goal state. We test different actions-to-variables ratios from 1.75 to 7.75, corresponding to 70 to 310 actions witha step of 15 actions. For each ratio we generate 300 instances.The results are shown in Fig. 7. As these problem instances are already quite difficult, we don’t know which of the hardestinstances have plans. Hence our comparison concerns the relative performance of the planners, how many of the instancesfor each actions-to-variables ratio each planner can solve, and what the median runtimes are. Most of the instances belowratio 2.0 (corresponding to 80 actions) are trivially found unsolvable, as there are not enough actions to reach the goals,and this is detected either by a simple syntactic analysis or with a small amount of search. Practically all of the instancesabove ratio 4.0 (corresponding to 160 actions) are trivially solvable: there are lots of alternative plans, and almost anysearch that makes progress towards the goals will almost immediately reach them. The hardest instances are between theseratios. M performs most solidly. Mp, LAMA and HSP solve a moderate percentage fewer instances than M, but there is no bigdifference between them, and the percentages of solved instances goes up to 100 when the number of actions reaches about160. The most visibly divergent behavior is by FF, which does not solve many of the very easy instances in 5 minutes. Thereason for this is the hill-climbing search in FF’s first phase, in which pruning with “helpful” actions eliminates too manyactions to be able to reach the goals, but which also does not give up and let the HSP-style second phase continue becausethe local minima are too large to search through exhaustively [12]. YAHSP and LAMA, which also use helpful actions, havea substantially better performance due to their use of helpful actions only for tie-breaking without categorically eliminatingall non-helpful from consideration.6.5.3. Action sequencingAnother class of hard planning problems, similar in flavor to the phase transition problems above, varies the density ofthe state transition graph without disconnecting the initial node from the goal node [43]. In these problems, the solubilityof an instance is guaranteed by construction: first generate an execution (a state sequence) with a fixed number of statevariables changing between two consecutive states, and then for each pair of consecutive states generate an action that isexecutable in the first state and that modifies it to obtain the second state. The selection of the preconditions determinesthe difficulty of the instances in terms of the density of the graph and the flexibility in which the actions can be ordered.We experimented with instances that have N state variables, 2 state variables changing their value between two consec-utive states in the sample execution, N2 actions with 3 effects and 2 preconditions in each (with one of the effects havingno effect in the sample execution), N goal literals which determine the goal state uniquely, and the parameter π = 4 de-termining the difficulty level. We chose π close to what appears to be the most difficult region of instances with a givenN [43]. Fig. 8 gives the median runtimes as N is increased from 10 to 400, together with 95 per cent confidence intervals,and Fig. 9 gives the percentages of solved instances. The new heuristic fares worse than the VSIDS heuristic, but better thanLPG-td and the planners that use explicit state-space search. The curve depicting the performance of Mp seems slightly lesssteep than those of HSP, LPG-td, FF, LAMA and YAHSP, and the performance difference between 80 and 100 variables is twoorders of magnitude and appears to be increasing. The other planners all have roughly the same performance. Except forsome of the smallest instances, FF always immediately switches from its local search algorithm to the systematic HSP-stylesearch. Similarly, the additional techniques YAHSP and LAMA employ don’t substantially help with these problems, and alsotheir performance is close to HSP’s. The gap between M and Mp is first similar to the gap between Mp and the rest ofthe planners, about two orders of magnitude in terms of median runtimes, but then grows quickly as runtimes of M growsignificantly slower.62J. Rintanen / Artificial Intelligence 193 (2012) 45–86Fig. 8. Scalability with problems representing action sequencing.Fig. 9. Scalability with problems representing action sequencing.6.6. Comparison of planners with competition benchmarksMuch of the experimentation with algorithms for the classical planning problem has focused on the benchmark problemsused in the planning competitions. Next we present the results for these problems.We included almost all domains used in the competitions from 1998 until 2011 in our experimental comparison, as wellas most instances. The excluded domains and others handled exceptionally are the following.• If a domain was used in more than one competition, we used the instances from the competition that had the harderinstances. If the instances were different but there was no difference in hardness, we used the newer instances. Thedomains used in multiple competitions are listed in Table 3.• We excluded the 2000 SCHEDULE domain from the comparison because of grounding issues, the overall simple structureof the domain, and the very high number of instances (500). First, none of the planners except LAMA ground the domainquickly. Second, after grounding by LAMA’s front-end, Mp and LAMA solve every one of the 500 instances in seconds,but only after spending up to several minutes with preprocessing. The planner that solved almost all of the groundedinstances in seconds including preprocessing is YAHSP. Also LPG-td’s first phase did very well and would have solvedalmost all of the series quite quickly had it not had an internal limit of 10 000 ground actions.• Some of the planners were very slow to ground the 1998 LOGISTICS instances, so we grounded them with FF’s front-end before running the planners. FF did not parse files with more than about 100 000 ground actions due to a parserrestriction, and LAMA was slow to compute invariants from the grounded representation. Since both of these plannerscould ground the instances quickly, we used the original ungrounded input with them.• Of the STRIPS domains, 2011 TIDYBOT contains negative preconditions, which are not supported by HSP. We ran HSPwith a modified version of TIDYBOT with positive preconditions only, by using the standard reduction which introducesJ. Rintanen / Artificial Intelligence 193 (2012) 45–8663Table 3Instances excluded from the comparison.Excluded instancesCovered by2000 LOGISTICS2002 ROVERS2002 FREECELL2002 SATELLITE2006 OPENSTACKS2006 PIPES/TANKAGE2008 ELEVATOR2008 OPENSTACKS2008 PARC2008 PEGSOL2008 SCANALYZER2008 SOKOBAN2008 WOODWORKING1998 LOGISTICS2006 ROVERS2000 FREECELL2004 SATELLITE2011 OPENSTACKS2004 PIPES/TANKAGE2011 ELEVATOR2011 OPENSTACKS2011 PARC2011 PEGSOL2011 SCANALYZER2011 SOKOBAN2011 WOODWORKINGJustificationharderincludes the oldharderharderharderexactly the sameharderharderequally hardequally hardequally hardharderharderTable 4Impact of different features on the planner’s performance.--?a-?-g?ag???-11881201 (+13)1213 (+25)1225 (+37)??m1376 (+188)1385 (+197)1374 (+186)1404 (+216)??w1383 (+195)1399 (+211)1399 (+211)1416 (+228)a state variable ˆx for every state variable x that occurs negatively in a precondition and forces ˆx and x to have oppositetruth-values.• For the 1998 MPRIME domain, we use a corrected version that adds a missing equality test in the drink action.• 1998 ASSEMBLY/ADL uses a syntactic feature in the schematic actions that is not implemented by all of the plannerfront-ends. We grounded all instances of this domain before running the planners.• The implementation of equality in YAHSP does not conform to the PDDL definition. To run YAHSP correctly, we addedthe :equality keyword to the PDDL requirements list in the 2006 TPP and the 2011 SCANALYZER domain files. Thisforced YAHSP instantiate schema variables with all object combinations, including ones in which more than variable areinstantiated with the same object.6.6.1. Comparison of different configurations of our plannerThe impact of the heuristics from Section 4 on the performance of the variable selection scheme is illustrated in Table 4.The baseline --- planner solves 1188 of the 1646 planning competition instances from Section 6.6 in 30 minutes. Forother configurations (as described in Table 1), we show the improvement obtained as the difference between the numberof solved instances and 1188. The goal-ordering heuristic from Section 4.1 and the action choice heuristic from Section 4.2lead to a minor improvement over a fixed goal ordering and an arbitrary selection of actions. The replacement of strictbackward chaining depth-first search with the less directional form of search from Section 4.3 is a substantial improvement,without which the performance would be slightly below the level of VSIDS.6.6.2. Comparison to VSIDS with a focus on unsatisfiable formulasWe compare the new heuristic to the VSIDS heuristic. Almost all of the currently strongest implementations of the CDCLalgorithm use some variant of VSIDS or a related heuristic.To compare heuristics in terms of both satisfiable and unsatisfiable formulas, with emphasis on the unsatisfiable onesthat are required for proving the minimality of the horizon length, we set up our planners to use the BLACKBOX sequentialstrategy which goes through horizon lengths 0, 1, 2, 3 and so on, until it finds a satisfiable formula. For many problemclasses, including the planning competition problems, the runtimes of the planners in this configuration are very stronglydominated by the unsatisfiable formulas. The results for these problems are summarized in Fig. 10. The plot shows thenumber of problem instances that are solved (finding a plan) in n seconds or less when using VSIDS and when usingthe new heuristic. The solver with VSIDS solves about 10 per cent more instances when 1800 seconds is spent solvingeach problem instance. With the sequential strategy, usually almost all of the computation effort is spent solving the lastunsatisfiable formulas right before the first satisfiable one. However, as we will see later, VSIDS is weaker than the newheuristic with satisfiable formulas, which are far more important when finding plans.6.6.3. Comparison to VSIDS in terms of plan sizes and runtimesIn Figs. 11 and 12 we compare the solution times and plan sizes for VSIDS and the new heuristic, as implementedin our planners M and Mp respectively, with parallel solution strategies that don’t require completing the SAT solving forunsatisfiable formulas. Each dot in these figures represents one problem instance, and the location of the dot on the X-axis64J. Rintanen / Artificial Intelligence 193 (2012) 45–86Fig. 10. Number of instances solved in a given time with the sequential strategy.Fig. 11. Runtimes with the new heuristic (Mp) and with VSIDS (M).depicts the runtime or the plan size with our planner with the VSIDS heuristic, and its location on the Y-axis that of ourplanner with the new heuristic. Hence any dot on the diagonal means that the planners perform equally well, and dotsbelow and right mean that the runtime or the plan size is higher with VSIDS than with the new heuristic.Fig. 11 shows that for a vast majority of the problem instances the new heuristic outperforms VSIDS, often by 1 or 2orders of magnitude. VSIDS is sometimes faster, but only in about two dozen cases more than by a factor of 10. There isoverall a high variation in the runtimes of the CDCL algorithm for a given instance due to the arbitrariness of some of thebranching decisions, and for this reason one would in general see a weaker algorithm outperform an overall stronger onein a small number of cases, exactly as we have observed here. Plans with VSIDS are on average a bit longer than with thenew heuristic, as indicated by Fig. 12, but the differences are relatively small. The longer plans are mostly due to redundantactions that don’t contribute to any of the goals or preconditions in the plan, and which could be eliminated by a simplepost-processing step.6.6.4. Comparison to other search algorithmsWe first compare our planners to what could be viewed as the baseline search algorithms in the different approaches,including the planners and planner components that use the standard best-first search algorithm with a heuristic but noadditional pruning, shortcut or preference mechanisms. These are HSP and the component algorithms of FF and LPG-td.Then we follow with the rest of the planners, including FF and LPG-td themselves as well as LAMA and YAHSP that enhanceJ. Rintanen / Artificial Intelligence 193 (2012) 45–8665Fig. 12. Plan sizes with the new heuristic (Mp) and with VSIDS (M).Fig. 13. Number of STRIPS instances solved by different algorithms.the baseline HSP-style search with additional techniques. Finally, we have a look at the impact of our planners in the bigpicture of planning by considering algorithm portfolios that can be built from the individual planners.The planners or planner components we compare to and that are based on only one search algorithm and one heuristicare HSP, the two phases of FF [47], and the first phase of LPG-td [38]. The runtimes for the first phase of FF are withoutthe goal agenda mechanism, as this mechanism is orthogonal to the other features of the planner and it could be equallyused in any other planner. The goal agenda increases the number of instances solved in 1800 seconds by 77, being criticalfor Blocks World but having no impact for most other domains.Fig. 13 illustrates the performance of these planners or planner components. All are outperformed by our baseline SAT-based planner M from 2006 [12]. A remarkable fact is that M has an outstanding performance although it uses a generic SATheuristic which is completely unaware of planning. Explicit state-space search similarly without a heuristic would performextremely poorly with these problems because there are far too many states to go through exhaustively.6.6.5. Comparison to other plannersNext we make a comparison between our planners and FF and LPG-td, which consist of the components evaluated inthe previous section, as well as LAMA08, LAMA11 and YAHSP, which consist of one phase only, but employ additionaltechniques on top of the basic heuristic search algorithm. A diagram depicting the performance of M, Mp, LAMA and FF66J. Rintanen / Artificial Intelligence 193 (2012) 45–86Fig. 14. Number of instances solved by different planners.Fig. 15. Number of STRIPS instances solved by different planners.with all instances is given in Fig. 14. For the subclass of STRIPS instances, and including also HSP, YAHSP and LPG-td whichonly support STRIPS, a diagram is given in Fig. 15.The curves in all cases are similar: all planners solve a large fraction of the problem instances in seconds, and thenumber of solved instances increases slowly as the time limit is increased past a couple of minutes. We also calculatea score, as the sum of the percentages of instances solved for each domain in 30 minutes, and estimate the statisticalsignificance of the scores by calculating confidence intervals. The confidence intervals are calculated by a bootstrappingprocedure, hypothesizing that the planning competition domains (and instances) are randomly sampled from some largerpool of similar domains. For Mp we give the 95 per cent confidence interval upper and lower bounds, and for the otherplanners we calculate the intervals as the difference to the Mp score as obtained with the bootstrap calculation. Accordingto this calculation, the difference between Mp and M is “significant”, and the difference to FF is also “significant”, but onlywith a small margin. Differences between Mp and LAMA08/LAMA11 are not “significant” according to this calculation: whendrawing samples of domains from the hypothetical domain pool, Mp would often get a score that is higher than that ofLAMA11, and LAMA11 would often get a higher score than Mp.Our new heuristic is an improvement over VSIDS in almost all domains. With many of the easiest domains and instancesthe improvement is however modest, as there is not much room to improve and the runtimes are often dominated by thepreprocessing phase shared by the planners.There are only four domains where the new heuristic is not an improvement over VSIDS. With many of the instances ofOPTICAL-TELEGRAPH and TRUCKS (both STRIPS and ADL), the new heuristic is more effective than VSIDS, but for a numberof instances VSIDS finds a plan within the 30 minute time bound while the new heuristic does not. With BLOCKSWORLDthe VSIDS heuristic scales up clearly better due to its ability to quickly shift to long horizon lengths by completing unsatis-fiability tests faster. With CYBERSECURITY, VSIDS is often 15 to 50 per cent faster, and equally often slower. However, bothplanners solve all instances of CYBERSECURITY in well under one minute.J. Rintanen / Artificial Intelligence 193 (2012) 45–8667Table 5Number of problems solved in 1800 seconds by domain.MpM1998-GRID1998-GRIPPER1998-LOGISTICS1998-MOVIE1998-MPRIME1998-MYSTERY2000-BLOCKS2000-FREECELL2002-DEPOTS2002-DRIVERLOG2002-ZENO2004-AIRPORT2004-OPTICAL-TELEGRAPH2004-PHILOSOPHERS2004-PIPESWORLD-TANKAGE2004-PIPESWORLD-NOTANKAGE2004-PSR-SMALL2004-SATELLITE2006-PATHWAYS2006-ROVERS2006-STORAGE2006-TPP2006-TRUCKS2008-CYBER-SECURITY2011-BARMAN2011-ELEVATORS2011-FLOORTILE2011-NOMYSTERY2011-OPENSTACKS2011-PARCPRINTER2011-PARKING2011-PEGSOL2011-SCANALYZER2011-SOKOBAN2011-TIDYBOT2011-TRANSPORT2011-VISITALL2011-WOODWORKING1998-ASSEMBLY-ADL2000-ELEVATOR-SIMPLE2000-SCHEDULE-ADL2002-SATELLITE-ADL2004-AIRPORT-ADL2004-OPTICAL-TELEGRAPH-ADL2004-PHILOSOPHERS-ADL2006-TRUCKS-ADL2008-OPENSTACKS-ADLtotalweighted scoreconfidence interval lowconfidence interval high520303020191026022202050142950505036304030303030202020202020202020202020202024150150205048482930520303020196345222020501429384150353040303021301020201702002020217402024150150204939481618320303018188232221918481429112050353040253022300120170200191302002023150150204741482215164647141639.0634.8242.79130434.36−7.86−1.982008520293020195459182019383123844503128402130829172021318122019201314162016241491342031192317301332LAMA201152030302014955922202038141441445036284020301529202061820202020201916197202315013820451141430141437.97−6.094.1440.48−3.336.36FF520303019168060221620391314223643362040182811402054202082020171594424150134203017141130123834.11−9.69−0.12Overall, the number of cases in which VSIDS is stronger is much smaller than of those where the opposite holds: forseveral domains the new heuristic dramatically outperforms VSIDS, and for most of the rest the runtimes are a clear im-provement over VSIDS. As we have seen earlier, with a number of other types of planning problems than the ones from theplanning competitions, especially smaller and combinatorially harder ones, CDCL with VSIDS continues to be the strongestsearch method, and the improvements over VSIDS are with the type of problems used in the planning competitions.The new planner often compares well with LAMA11 [40], the winner of the non-optimal non-temporal track of the 2011planning competition.8 Fig. 16 illustrates the relative performance of LAMA11 and our planner Mp with all of the probleminstances in terms of runtime, and Fig. 17 in terms of plan size. Diagrams comparing runtimes and plan sizes for eachdomain separately are given in Appendix A. In dozens of cases, the strengths of LAMA and Mp are quite complementary,one planner outperforming the other by two or more orders of magnitude in runtime. Also, both planners in some cases8 Note that the evaluation criterion in the competition was the quality of the plans generated, whereas in our comparison we are only counting thenumber of instances solved. In the 2011 competition, the problem instances were selected so that most of the participating planners could solve them.68J. Rintanen / Artificial Intelligence 193 (2012) 45–86Fig. 16. Runtimes with Mp and LAMA for each problem instance.Fig. 17. Plan sizes with Mp and LAMA for each problem instance.produce much longer plans than the other planner, Mp more so, but for a vast majority of problem instances the plan sizesare close to each other. Of the planning competition instances that are solved by both Mp and LAMA11, the average lengthof plans found by Mp is 81.72 and of those found by LAMA11 is 72.93.Earlier, the strength of SAT-based planning has been perceived to be in small but combinatorially hard planning problems,a perception which is to some extent confirmed by the experiments in Sections 6.5.1, 6.5.2, and 6.5.3. However, with thenewest planners and concerning the planning competition benchmarks, this is less clearly the case. Fig. 18 depict the ratioof the runtimes of LAMA11 and Mp on all of the planning competition instances solved by both planners, plotted againstthe numbers of actions in the plans found by LAMA11. Instances that LAMA11 solves faster than Mp are below the linecorresponding to the X-axis at 1, and instances it solves slower are above the line. The number of instances above the lineis roughly equal to the number of dots below the line. Although for some domains LAMA’s relative performance improvesas the difficulty in terms of the number of action in plans increases, as can be seen from the cloud of dots at the areaJ. Rintanen / Artificial Intelligence 193 (2012) 45–8669Fig. 18. Relative performance of LAMA11 and Mp with increasing plan size.between (10, 1) and (50, 0.1), this trend is not generally very clear, and there are also several domains for which Mp’srelative performance over LAMA11 improves. A plot against the number of state variables or number of ground actions inthe instance looks similar. It seems fair to say that with the newest planners, the strengths of SAT-based planners are nolonger limited to small and hard instances, but also cover many problems that are large and easy (relative to their size).For some of the domains there are partial explanations for the performance differences to LAMA11. The formalizationsof some of the domains are particularly unfavorable to search directions other than forward search (explicit state-spacesearch). A typical issue is incrementing a counter c from i to i + 1 where i is in some range l (cid:4) i (cid:4) u. This incrementcan be represented as u − l − 1 STRIPS actions with the precondition c = i for l (cid:4) i < u and the effect c := i + 1, witheach counter value represented as a separate state variable. With forward search this representation is unproblematic asthe old value of the counter is always known: only one of the actions, with the precondition matching the current valuec = i can be chosen. But with backward search and SAT, for actions in the middle of the plan, selecting an action alwaysnecessarily commits to one value of the counter. The problem is that the previous and the next actions in the plan shouldhave compatible values, but at the time of selecting this action it is generally not known what and where these actions willbe, often leading to poor action choices that are essentially bad guesses about the values of the counter. Domains with thistype of counter increments and decrements are 2000 FREECELL, 2011 BARMAN, 2011 TRANSPORT and 2011 OPENSTACKS,with counters representing container or vehicle capacities and the availability of other resources. With BARMAN, a minormodification of the action description, involving conditional effects, turns the domain from 10 solved to 19 out of 20 solved.With TRANSPORT, the same modification increases the number from 4 to 13. A better representation of the increments thanthe one used in these modifications at the PDDL level would be possible at the SAT level, leading to substantially smallerSAT instances. More generally, the problem with these four domains is the low abstraction level offered by PDDL/STRIPS,which forces representation decisions at the modeling time which may be good for some search methods and bad for others.LPG-td, which also does not use explicit state-space search (forward search) in its first phase, scales poorly with three ofthese domains, but not with OPENSTACKS. LPG-td solves OPENSTACKS efficiently due to its ability to increase the horizonlength quickly.Another domain with which our planners perform poorly, and which differs from all other domains, is 2011 VISITALL.The plans in this domain are extremely long, with thousands of actions, with no possibility to parallelize them. Our planner’sstrategy to consider horizon lengths 0, 5, 10, 15, and so on, the restriction to at most 20 simultaneous horizon lengths, andthe difficulty to prove non-trivial lower bounds for horizon lengths, mean that the planner never proceeds further than acouple of hundred plan steps, and never finds any plans. If we force the planner to consider horizon lengths 1000, 2000,and so on, the new heuristic (but not VSIDS) finds plans for the first instances of VISITALL quickly with little or no search.Very long horizons remain problematic to SAT-based planners because of the high memory requirements that follow fromthe need to represent all actions and state variables for every time point.There might seem to be a discrepancy between the performance differences of FF and M in Table 5 and in our earlierarticle [12], with the new results showing that the difference between M and FF is small, whereas the 2006 article seemedto suggest a far bigger difference. One factor in the difference is improvements in implementations of SAT solvers since2006. In 2006, we used the Siege SAT solver [52], which is dramatically outperformed by newer solvers and our own solver.Second, M considers only every fifth horizon length, 0, 5, 10, 15 and so on, whereas in the 2006 paper we considered allhorizon lengths, 0, 1, 2, 3, and so on, and in some cases did not go far enough to discover the easiest satisfiable formulas.70J. Rintanen / Artificial Intelligence 193 (2012) 45–86Table 6Number of instances solved in 1800 seconds by 2-planner portfolios.MpMLAMA08LAMA11FFMp14161436153815611507M14361293154115561468LAMA08LAMA111538154113321471146115611556147114141448Table 7Number of STRIPS instances solved in 1800 seconds by 2-algorithm portfolios.MpMHSPFF-1FF-2LPG-TD-1Mp902920966942954941M920781878872894831HSP966878665788724812FF-1942872788503752739Table 8Number of STRIPS instances solved in 1800 seconds by 2-planner portfolios.MpMHSPFF-1FF-2LPG-TD-1LAMA08LAMA11FFLPG-TDYAHSPMp902920966942954941101010439919601023M920781878872894831100710319448781015HSP966878665788724812935999847844946FF-1FF-2LPG-td-1LAMA08LAMA119428727885037527399079798078299129548947247526488199219778078209129418318127398196129601007879744980101010079359079219608851003973985982104310319999799771007100397998810081037FF-2954894724752648819FF991944847807807879973988808880969FF15071468146114481238LPG-td-1941831812739819612LPG-tdYAHSP9608788448298207449851008880766988102310159469129129809821037969988892And, finally, the data given in the 2006 paper did not include those problems that were very quickly solved by our planner,giving an overly negative impression of its performance.6.7. Impact of the new heuristic on portfoliosThere is the obvious question about the performance of our planner as a component of an algorithm portfolio. Weconsider portfolios that consist of two planners run in parallel, each planner getting 50 per cent of the CPU, and a planis returned as soon as one of the planners finds one. Other ways of combining planners are possible, including sequentialcomposition with a fixed amount of time allocated to each planner. An advantage of parallel composition is that it issymmetric with respect to the components, so that if one of the components delivers a solution quickly, the parallel portfoliowill do it as well.We have Tables 6, 7, and 8 illustrating the 2-planner portfolios that can be constructed by parallel composition. Table 6lists portfolios for planners that support the PDDL language with conditional effects. Table 7 lists portfolios for the baselinesearch algorithms for each approach (SAT, explicit state-space search, LPG-td), with performance data restricted to the STRIPSinstances, and Table 8 lists all planners and planner components, with data similarly restricted to the STRIPS instances.For each portfolio, the tables show the number of problem instances solved in 30 minutes. The diagonal represents theplanner run alone, getting 100 percent of the CPU for 30 minutes. For each row we highlight the column with the highestnumber of solved instances.M and Mp are relatively stronger, and complement the other planners better, when considering the full set of instances,including ones in the general PDDL language with conditional effects. When restricted to STRIPS instances, LAMA11 isgenerally the best complement, although M and Mp are in several cases close to LAMA11.The strongest portfolio is that of Mp and LAMA11, both with the set of all instances and with the STRIPS subset. WithSTRIPS instances, several other portfolios are very close, including LAMA11-M, LAMA11-YAHSP, Mp-YAHSP, M-YAHSP andLAMA11-LPG-td. Overall, the differences between the planners in terms of the planning competition instances are far smallerthan with the other classes of problems in Sections 6.5.1, 6.5.2 and 6.5.3.J. Rintanen / Artificial Intelligence 193 (2012) 45–86717. Related work7.1. Planning with SAT and constraint satisfactionAll earlier SAT-based planners used generic SAT solvers, with VSIDS and similar heuristics, and with the breadth-first-style sequential solving of SAT instances for different horizon lengths. All the performance differences in earlier plannerscame from the SAT solver used and from differences in the encodings, primarily the size the encodings and the use ofadditional constraints to prune the search spaces.The best-known early planner that used SAT is BLACKBOX by Kautz and Selman [39]. Rintanen et al. [12] demonstratethat their ∀-step semantics encoding is often substantially faster than the BLACKBOX encoding, sometimes by a factor of20 and more. Both encodings use the same definition of parallel plans. Results of Sideris and Dimopoulos [53] indicate thatnewer planners in the BLACKBOX family implement encodings that are not faster than BLACKBOX’s and are sometimes twiceas slow, due to weaker unit propagations. Robinson et al. [54] propose a factored encoding of ∀-step plans and demonstratesubstantial speed-ups over some of the encodings from the BLACKBOX family. Other recent works claim improvementsover Kautz and Selman style encodings [55,56], but only demonstrate moderate improvements and make no comparison toencodings by Rintanen et al. or Robinson et al.The more relaxed notion of parallel plans used in our planner, the ∃-step semantics [12,24], allows shorter horizons andsmaller formulas than ∀-step plans, and therefore leads to substantial efficiency improvements. This and parallelized searchstrategies [57] often mean further one, two or more orders of magnitudes of speed-up over other SAT-based planners.7.2. Planning with partially ordered representations: Graphplan, LPG, CPTThe Graphplan algorithm [13] uses backward search constrained by the planning graph structure which represents ap-proximate (upper bound) reachability information. The action selection of GraphPlan’s search may resemble our actionselection: given a subgoal l at time t, the choice of an action to reach l is restricted to actions in the planning graph atlevel t − 1. This same constraint on action selection shows up in any extraction of action sequences from exact distanceinformation, for example in BDD-based planning [58] and related model-checking methods, and the data structures repre-senting the distances (the planning graph or the BDDs) are not used as a heuristic as in our work: when the action choicefor achieving l is not restricted by the contents of the planning graph (which is usually the case), Graphplan will choosean arbitrary action with l as an effect. Another major difference is of course that our heuristic leverages on the inferencesand learned clauses of the CDCL algorithm. This is the main reason why our heuristic, despite its extreme simplicity, is aseffective as substantially more complex heuristics used with explicit state-space search.The LPG planner [38] does stochastic local search in the space of incomplete plans with parallel actions similar to theSAT-based approach. LPG’s choice of actions to be added in the current incomplete plan is based on the impact of the actionon violations of constraints describing the solutions. A main difference between LPG and SAT-based planning is that LPG,similarly to local-search algorithms for SAT, does not use general logical inference, but only a restricted form for propagationof values of non-changing facts from a time point to its predecessors or successors.Vidal and Geffner [59] present the CPT planner which covers both classical and temporal planning. It uses a constraint-based model and can be viewed as an instance of the partial-order causal link (POCL) framework [60]. CPT’s partial plansare partial valuations of the variables expressing the times the actions take place. As in the POCL framework, planningproceeds by identifying flaws which suggest possible violations of the constraints in the current partial plan, and thenposting additional constraints to eliminate the flaw. As in LPG, the heuristics in CPT evaluate the different ways of removingthe flaws in terms of the distances between plan elements related to the flaws in question.7.3. Planning with state-space searchSystematic algorithms for heuristic search [61] have long been a leading approach to problem solving in AI, but itsuse in planning (which is problem solving with a generic high-level input language) was limited until Bonet et al. [17,8] demonstrated the power of these algorithms and automatically derived heuristics in the HSP planner. Research quicklyfocused on explicit state-space search guided by heuristics derived from declarative problem descriptions in a generic,problem-independent manner.The HSP family of planners have to evaluate all of the possible successor states in order to choose one which is likelyto lead toward the goal states. In contrast, our work has demonstrated that in the CDCL framework, the current partialvaluation gives reliable heuristic information about which actions to add to the current partial plan, without evaluating allaction candidates separately, simply by reading the next action (decision variable) from the current partial valuation. Whileour heuristics are simpler, the inferences and learning of the CDCL framework are more complex than the explicit state-space framework, representing a different trade-off in resource use. Interestingly, the number of states evaluated per secondby planners like LAMA is typically within one order of magnitude from the number of decisions (action selections) in Mpor generic VSIDS-based CDCL implementations. Table 9 gives, for four problem instances for which both Mp and LAMA hadsimilar and relatively high search times, the numbers of state expansions and action selections per second. LAMA’s numbersof states generated, but not evaluated, per second are considerably higher. Of course, because of the fundamentally different72J. Rintanen / Artificial Intelligence 193 (2012) 45–86Table 9Rates of state evaluations and generations for LAMA11 and of action selections (decisions) Mp.Instance2004 AIRPORT 462004 PIPES 362004 SATELLITE 362006 TRUCKS 122011 ELEVATOR 17LAMA11time117.3088.08150.56162.5283.02eval54 8221404917 3131 669 39524 254per sec467.37159.50114.9910 271.94292.15generatedper sec249 76171329935 689 16837 026 9522 101 1042129.258098.3123 7042.83227 830.1625 308.41Mptime113.8161.5110.3463.3169.04decs40 31239 96316 752139 02784 347per sec352.20649.701620.122195.971221.71problem representations used by Mp and LAMA, and the fact that a decision (action selection) in the CDCL context couldbe viewed as a lower level operation than a state evaluation in explicit state-space search, these numbers are not directlycomparable.There is a resemblance between our variable selection scheme and the best supporters and minimal paths of Lipovetzkyand Geffner [62], in both cases directly going back to the preference for shortest possible action sequences. Our variableselection scheme chooses one of the earliest possible actions (with respect to the current partial valuation of the CDCL algo-rithm) that can make a given (sub)goal true, whereas the minimal paths are sequences of actions constructed by backwardchaining so that an action supporting the preconditions of a later action are best supporters in the sense that their valueaccording to the hmax heuristic is the lowest. Unlike in our work, the restriction to best supporters is a pruning technique,and not a heuristic, and it leads to incompleteness in Lipovetzky and Geffner’s framework [62].7.4. Domain-specific heuristics for SAT solvingNot much is known about using problem-specific heuristics in SAT solving or the workings of SAT solvers when solvingplanning problems. Beame et al. [27] demonstrate the utility of a problem-specific variable selection heuristic for a clause-learning algorithm solving a combinatorial problem (pebbling formulas), leading to improvements in finding resolutionrefutations with CDCL.Our decision heuristic focuses on action variables, and only assigns fact variables at the last stages to complete theassignment that is already known to represent a plan. Theoretical results indicate that the efficiency of CDCL is sometimesdecreased if variable assignments are restricted to a subset of the variables only, even if those variables are sufficient fordetermining satisfiability and unsatisfiability [63,64]. However, these results, and all other known restrictions on SAT solvingefficiency (in a given proof system), only apply to unsatisfiability proofs, which are of limited importance when finding aplan without having to prove the optimality of the plan.8. Conclusions and future workThe contribution of this paper is a simple yet powerful variable selection strategy for clause-learning SAT solvers thatsolve AI planning problems, as well as an empirical demonstration that the strategy outperforms VSIDS for benchmarksfrom the planning competitions. With smaller but combinatorially harder problems VSIDS continues to be the strongestheuristic. A main additional benefit over VSIDS is that the variable selection strategy is understandable in terms of theplanning problem. This makes it particularly promising because the features that make it strong are largely complementaryto the important features of VSIDS, suggests ways to combine them. This is a focus of future work.Our heuristics ignore many aspects of action selection that have traditionally been considered important, especially inearly works on planning. One such issue is interference between different subgoals, caused by conflicts between the actionsfulfilling them. With some problems with which our planner did not perform very well we observed such interferenceissues. Handling action selection and subgoal interactions in a more informed fashion is one avenue to still more effectiveheuristics.The main ideas in this work are quite general and could be easily adapted to other applications of SAT and constraint-satisfaction to reachability, for example in LTL model-checking [4] and diagnosis [9], as well as to other forms of planning,for example planning with more complex models of time and with continuous state variables (hybrid systems), by usingSAT modulo Theories (SMT) solvers [65–68], and planning with nondeterministic actions and partial observability by usingquantified Boolean formulas [69,70] or stochastic satisfiability [71].AcknowledgementsWe thank Hector Geffner and Patrik Haslum for comments and suggestions on early versions of this paper, and BlaiBonet for providing us with updated versions of the HSP 2.0 planner. We also thank the reviewers for valuable commentsand suggestions that helped increase the breadth and depth of the experimental evaluation.J. Rintanen / Artificial Intelligence 193 (2012) 45–8673Appendix A. Comparisons with planning competition domainsThe diagrams in the next pages compare the runtimes and plan sizes of two planners instance by instance for each of thedomains used in the planning competitions between 1998 and 2011. Some of the diagrams have fewer dots than indicatedby Table 5. This is due to more than one instance having exactly the same runtimes for both planners, typically when theruntimes are close to 0 seconds.A.1. Comparison of Mp and LAMA runtimes with STRIPS benchmarksFor this runtime comparison, we have only included the search times of both planner. The relatively long preprocessingtimes of LAMA11 and Mp are ignored, because both spend a lot of time finding invariants but by using radically differentalgorithms for this task. LAMA’s preprocessor is generally slower but it scales up somewhat better than that of Mp to largeinstances.74J. Rintanen / Artificial Intelligence 193 (2012) 45–86J. Rintanen / Artificial Intelligence 193 (2012) 45–867576J. Rintanen / Artificial Intelligence 193 (2012) 45–86A.2. Comparison of Mp and LAMA runtimes with ADL benchmarksA.3. Comparison of Mp and LAMA plan sizes with STRIPS benchmarksJ. Rintanen / Artificial Intelligence 193 (2012) 45–867778J. Rintanen / Artificial Intelligence 193 (2012) 45–86J. Rintanen / Artificial Intelligence 193 (2012) 45–867980J. Rintanen / Artificial Intelligence 193 (2012) 45–86A.4. Comparison of Mp and LAMA plan sizes with ADL benchmarksA.5. Comparison of Mp and M runtimes with STRIPS benchmarksJ. Rintanen / Artificial Intelligence 193 (2012) 45–868182J. Rintanen / Artificial Intelligence 193 (2012) 45–86J. Rintanen / Artificial Intelligence 193 (2012) 45–868384J. Rintanen / Artificial Intelligence 193 (2012) 45–86A.6. Comparison of Mp and M runtimes with ADL benchmarksJ. Rintanen / Artificial Intelligence 193 (2012) 45–8685References[1] H. Kautz, B. Selman, Planning as satisfiability, in: B. Neumann (Ed.), Proceedings of the 10th European Conference on Artificial Intelligence, John Wiley& Sons, 1992, pp. 359–363.[2] S.A. Cook, The complexity of theorem proving procedures, in: Proceedings of the Third Annual ACM Symposium on Theory of Computing, pp. 151–158.[3] H. Kautz, B. Selman, Pushing the envelope: planning, propositional logic, and stochastic search, in: Proceedings of the 13th National Conference onArtificial Intelligence and the 8th Innovative Applications of Artificial Intelligence Conference, AAAI Press, 1996, pp. 1194–1201.[4] A. Biere, A. Cimatti, E.M. Clarke, Y. Zhu, Symbolic model checking without BDDs, in: W.R. Cleaveland (Ed.), Tools and Algorithms for the Constructionand Analysis of Systems, Proceedings of 5th International Conference, TACAS’99, in: Lecture Notes in Computer Science, vol. 1579, Springer-Verlag,1999, pp. 193–207.[5] J.P. Marques-Silva, K.A. Sakallah, GRASP: a search algorithm for propositional satisfiability, IEEE Transactions on Computers 48 (1999) 506–521.[6] R.J. Bayardo Jr., R.C. Schrag, Using CSP look-back techniques to solve real-world SAT instances, in: Proceedings of the 14th National Conference onArtificial Intelligence (AAAI-97) and 9th Innovative Applications of Artificial Intelligence Conference (IAAI-97), pp. 203–208.[7] M.W. Moskewicz, C.F. Madigan, Y. Zhao, L. Zhang, S. Malik, Chaff: engineering an efficient SAT solver, in: Proceedings of the 38th ACM/IEEE DesignAutomation Conference (DAC’01), ACM Press, 2001, pp. 530–535.[8] B. Bonet, H. Geffner, Planning as heuristic search, Artificial Intelligence 129 (2001) 5–33.[9] A. Grastien, Anbulagan, J. Rintanen, E. Kelareva, Diagnosis of discrete-event systems using satisfiability algorithms, in: Proceedings of the 22nd AAAIConference on Artificial Intelligence (AAAI-07), AAAI Press, 2007, pp. 305–310.[10] A. Porco, A. Machado, B. Bonet, Automatic polytime reductions of NP problems into a fragment of STRIPS, in: ICAPS 2011. Proceedings of the Twenty-First International Conference on Automated Planning and Scheduling, pp. 178–185.[11] J. Rintanen, Phase transitions in classical planning: an experimental study, in: D. Dubois, C.A. Welty, M.-A. Williams (Eds.), Principles of KnowledgeRepresentation and Reasoning: Proceedings of the Ninth International Conference (KR 2004), AAAI Press, 2004, pp. 710–719.[12] J. Rintanen, K. Heljanko, I. Niemelä, Planning as satisfiability: parallel plans and algorithms for plan search, Artificial Intelligence 170 (2006) 1031–1080.[13] A.L. Blum, M.L. Furst, Fast planning through planning graph analysis, Artificial Intelligence 90 (1997) 281–300.[14] B. Selman, H.A. Kautz, B. Cohen, Noise strategies for improving local search, in: Proceedings of the 19th National Conference on Artificial Intelligence(AAAI-2004) and the 16th Conference on Innovative Applications of Artificial Intelligence (IAAI-2004), AAAI Press, 1994, pp. 337–343.[15] B. Selman, H.A. Kautz, B. Cohen, Local search strategies for satisfiability testing, in: DIMACS Series in Discrete Mathematics and Theoretical ComputerScience, vol. 25, 1996, pp. 521–531.[16] J.M. Crawford, L.D. Auton, Experimental results on the crossover point in random 3-SAT, Artificial Intelligence 81 (1996) 31–57.[17] B. Bonet, G. Loerincs, H. Geffner, A robust and fast action selection mechanism for planning, in: Proceedings of the 14th National Conference onArtificial Intelligence (AAAI-97) and 9th Innovative Applications of Artificial Intelligence Conference (IAAI-97), AAAI Press, 1997, pp. 714–719.[18] J. Rintanen, Evaluation strategies for planning as satisfiability, in: R. López de Mántaras, L. Saitta (Eds.), ECAI 2004. Proceedings of the 16th EuropeanConference on Artificial Intelligence, IOS Press, 2004, pp. 682–687.[19] J. Rintanen, K. Heljanko, I. Niemelä, Parallel encodings of classical planning as satisfiability, in: J.J. Alferes, J. Leite (Eds.), Logics in Artificial Intelligence:9th European Conference, JELIA 2004. Proceedings, Lisbon, Portugal, September 27–30, 2004, in: Lecture Notes in Computer Science, vol. 3229, Springer-Verlag, 2004, pp. 307–319.[20] C.M. Li, Anbulagan, Heuristics based on unit propagation for satisfiability problems, in: M. Pollack (Ed.), Proceedings of the 15th International JointConference on Artificial Intelligence, Morgan Kaufmann Publishers, 1997, pp. 366–371.[21] J. Rintanen, A planning algorithm not based on directional search, in: A.G. Cohn, L.K. Schubert, S.C. Shapiro (Eds.), Principles of Knowledge Representa-tion and Reasoning: Proceedings of the Sixth International Conference (KR’98), Morgan Kaufmann Publishers, 1998, pp. 617–624.[22] M. Davis, G. Logemann, D. Loveland, A machine program for theorem proving, Communications of the ACM 5 (1962) 394–397.[23] J. Rintanen, Heuristics for planning with SAT, in: D. Cohen (Ed.), Principles and Practice of Constraint Programming – CP 2010, 16th InternationalConference, CP 2010, Proceedings, St. Andrews, Scotland, September 2010, in: Lecture Notes in Computer Science, vol. 6308, Springer-Verlag, 2010,pp. 414–428.[24] M. Wehrle, J. Rintanen, Planning as satisfiability with relaxed ∃-step plans, in: M. Orgun, J. Thornton (Eds.), PAI 2007: Advances in Artificial Intelligence:20th Australian Joint Conference on Artificial Intelligence, Proceedings, Surfers Paradise, Gold Coast, Australia, December 2–6, 2007, in: Lecture Notesin Computer Science, vol. 4830, 2007, pp. 244–253.[25] S. Ogata, T. Tsuchiya, T. Kikuno, SAT-based verification of safe Petri nets, in: F. Wang (Ed.), Automated Technology for Verification and Analysis: SecondInternational Conference ATVA 2004, Proceedings, Taipei, Taiwan, ROC, October 31–November 3, 2004, in: Lecture Notes in Computer Science, vol. 3299,Springer-Verlag, 2004, pp. 79–92.[26] A. Gerevini, L. Schubert, Inferring state constraints for domain-independent planning, in: Proceedings of the 15th National Conference on ArtificialIntelligence (AAAI-98) and the 10th Conference on Innovative Applications of Artificial Intelligence (IAAI-98), AAAI Press, 1998, pp. 905–912.[27] P. Beame, H. Kautz, A. Sabharwal, Towards understanding and harnessing the potential of clause learning, Journal of Artificial Intelligence Research 22(2004) 319–351.[28] D.G. Mitchell, A SAT solver primer, EATCS Bulletin 85 (2005) 112–133.[29] C.P. Gomes, B. Selman, N. Crato, H. Kautz, Heavy-tailed phenomena in satisfiability and constraint satisfaction problems, Journal of Automated Reason-ing 24 (2000) 67–100.[30] C.P. Gomes, B. Selman, H. Kautz, Boosting combinatorial search through randomization, in: Proceedings of the 14th National Conference on ArtificialIntelligence (AAAI-97) and 9th Innovative Applications of Artificial Intelligence Conference (IAAI-97), AAAI Press, 1998, pp. 431–437.[31] J. Rintanen, Regression for classical and nondeterministic planning, in: M. Ghallab, C.D. Spyropoulos, N. Fakotakis (Eds.), ECAI 2008. Proceedings of the18th European Conference on Artificial Intelligence, IOS Press, 2008, pp. 568–571.[32] J. Rintanen, Engineering efficient planners with SAT, in: ECAI 2012. Proceedings of the 20th European Conference on Artificial Intelligence, IOS Press,2012, pp. 684–689.[33] K. Pipatsrisawat, A. Darwiche, A lightweight component caching scheme for satisfiability solvers, in: J. Marques-Silva, K.A. Sakallah (Eds.), Proceedingsof the 8th International Conference on Theory and Applications of Satisfiability Testing (SAT-2007), in: Lecture Notes in Computer Science, vol. 4501,Springer-Verlag, 2007, pp. 294–299.[34] E. Zarpas, Simple yet efficient improvements of SAT based bounded model checking, in: A.J. Hu, A.K. Martin (Eds.), Formal Methods in Computer-AidedDesign: 5th International Conference, FMCAD 2004, Proceedings, Austin, Texas, USA, November 15–17, 2004, in: Lecture Notes in Computer Science,vol. 3312, Springer-Verlag, 2004, pp. 174–185.[35] M. Streeter, S.F. Smith, Using decision procedures efficiently for optimization, in: M. Boddy, M. Fox, S. Thiébaux (Eds.), ICAPS 2007. Proceedings of theSeventeenth International Conference on Automated Planning and Scheduling, pp. 312–319.[36] D. McDermott, The planning domain definition language, Technical Report CVC TR-98-003/DCS TR-1165, Yale Center for Computational Vision andControl, Yale University, 1998.[37] J. Rintanen, Heuristics for planning with SAT and expressive action definitions, in: ICAPS 2011. Proceedings of the Twenty-First International Conferenceon Automated Planning and Scheduling, AAAI Press, 2011, pp. 210–217.86J. Rintanen / Artificial Intelligence 193 (2012) 45–86[38] A. Gerevini, I. Serina, Planning as propositional CSP: from Walksat to local search techniques for action graphs, Constraints Journal 8 (2003) 389–413.[39] H. Kautz, B. Selman, Unifying SAT-based and graph-based planning, in: T. Dean (Ed.), Proceedings of the 16th International Joint Conference on ArtificialIntelligence, Morgan Kaufmann Publishers, 1999, pp. 318–325.[40] S. Richter, M. Westphal, The LAMA planner: guiding cost-based anytime planning with landmarks, Journal of Artificial Intelligence Research 39 (2010)127–177.[41] ICAPS, http://www.icaps-conference.org/, 2010.[42] T. Bylander, A probabilistic analysis of propositional STRIPS planning, Artificial Intelligence 81 (1996) 241–271.[43] J. Rintanen, Generation of hard solvable planning problems, Technical Report TR-CS-12-03, Research School of Computer Science, The Australian Na-tional University, 2012.[44] B.A. Huberman, R.M. Lukose, T. Hogg, An economics approach to hard computational problems, Science 275 (1997) 51–54.[45] C.P. Gomes, B. Selman, Algorithm portfolio design: theory vs. practice, in: Proceedings of the Thirteenth Conference on Uncertainty in Artificial Intelli-gence (UAI-97), Morgan Kaufmann Publishers, 1997, pp. 190–197.[46] C.P. Gomes, B. Selman, Algorithm portfolios, Journal of Artificial Intelligence Research 126 (2001) 43–62.[47] J. Hoffmann, B. Nebel, The FF planning system: fast plan generation through heuristic search, Journal of Artificial Intelligence Research 14 (2001)253–302.[48] V. Vidal, A lookahead strategy for heuristic search planning, in: S. Zilberstein, J. Koehler, S. Koenig (Eds.), ICAPS 2004. Proceedings of the FourteenthInternational Conference on Automated Planning and Scheduling, AAAI Press, 2004, pp. 150–160.[49] P. Cheeseman, B. Kanefsky, W.M. Taylor, Where the really hard problems are, in: J. Mylopoulos (Ed.), Proceedings of the 12th International JointConference on Artificial Intelligence, Morgan Kaufmann Publishers, 1991, pp. 331–337.[50] D. Mitchell, B. Selman, H. Levesque, Hard and easy distributions of SAT problems, in: W. Swartout (Ed.), Proceedings of the 10th National Conferenceon Artificial Intelligence, The MIT Press, 1992, pp. 459–465.[51] B. Bollobás, Random Graphs, Academic Press, 1985.[52] L. Ryan, Efficient algorithms for clause-learning SAT solvers, Master’s thesis, Simon Fraser University, 2003.[53] A. Sideris, Y. Dimopoulos, Constraint propagation in propositional planning, in: ICAPS 2010. Proceedings of the Twentieth International Conference onAutomated Planning and Scheduling, AAAI Press, 2010, pp. 153–160.[54] N. Robinson, C. Gretton, D.-N. Pham, A. Sattar, SAT-based parallel planning using a split representation of actions, in: A. Gerevini, A. Howe, A. Cesta,I. Refanidis (Eds.), ICAPS 2009. Proceedings of the Nineteenth International Conference on Automated Planning and Scheduling, AAAI Press, 2009,pp. 281–288.[55] K. Ray, M.L. Ginsberg, The complexity of optimal planning and a more efficient method for finding solutions, in: J. Rintanen, B. Nebel, J.C. Beck, E.Hansen (Eds.), ICAPS 2008. Proceedings of the Eighteenth International Conference on Automated Planning and Scheduling, pp. 280–287.[56] R. Huang, Y. Chen, W. Zhang, A novel transition based encoding scheme for planning as satisfiability, in: Proceedings of the 24th AAAI Conference onArtificial Intelligence (AAAI-10), pp. 89–94.[57] J. Rintanen, Planning and SAT, in: A. Biere, M.J.H. Heule, H. van Maaren, T. Walsh (Eds.), Handbook of Satisfiability, in: Frontiers in Artificial Intelligenceand Applications, vol. 185, IOS Press, 2009, pp. 483–504.[58] A. Cimatti, E. Giunchiglia, F. Giunchiglia, P. Traverso, Planning via model checking: a decision procedure for AR, in: S. Steel, R. Alami (Eds.), RecentAdvances in AI Planning. Fourth European Conference on Planning (ECP’97), in: Lecture Notes in Computer Science, vol. 1348, Springer-Verlag, 1997,pp. 130–142.[59] V. Vidal, H. Geffner, Branching and pruning: an optimal temporal POCL planner based on constraint programming, Artificial Intelligence 170 (2006)298–335.[60] D.A. McAllester, D. Rosenblitt, Systematic nonlinear planning, in: Proceedings of the 9th National Conference on Artificial Intelligence, vol. 2, AAAIPress/The MIT Press, 1991, pp. 634–639.[61] J. Pearl, Heuristics: Intelligent Search Strategies for Computer Problem Solving, Addison-Wesley Publishing Company, 1984.[62] N. Lipovetzky, H. Geffner, Inference and decomposition in planning using causal consistent chains, in: A. Gerevini, A. Howe, A. Cesta, I. Refanidis (Eds.),ICAPS 2009. Proceedings of the Nineteenth International Conference on Automated Planning and Scheduling, pp. 217–224.[63] A. Haken, The intractability of resolution, Theoretical Computer Science 39 (1985) 297–308.[64] M. Järvisalo, T. Junttila, Limitations of restricted branching in clause learning, Constraints Journal 14 (2009) 325–356.[65] M. Bozzano, R. Bruttomesso, A. Cimatti, T. Junttila, P. van Rossum, S. Schulz, R. Sebastiani, The MathSAT 3 system, in: Automated Deduction – CADE-20,in: Lecture Notes in Computer Science, vol. 3632, Springer-Verlag, 2005, pp. 315–321.[66] G. Audemard, A. Cimatti, A. Kornilowicz, R. Sebastiani, Bounded model checking for timed systems, in: Formal Techniques for Networked and Dis-tributed Systems – FORTE 2002, in: Lecture Notes in Computer Science, vol. 2529, Springer-Verlag, 2002, pp. 243–259.[67] N. Giorgetti, G.J. Pappas, A. Bemporad, Bounded model checking of hybrid dynamical systems, in: Proceedings of the 44th IEEE Conference on Decisionand Control, and the European Control Conference 2005, IEEE, 2005, pp. 672–677.[68] G. Audemard, M. Bozzano, A. Cimatti, R. Sebastiani, Verifying industrial hybrid systems with MathSAT, Electronic Notes in Theoretical Computer Sci-ence 119 (2005) 17–32.[69] J. Rintanen, Constructing conditional plans by a theorem-prover, Journal of Artificial Intelligence Research 10 (1999) 323–352.[70] J. Rintanen, Asymptotically optimal encodings of conformant planning in QBF, in: Proceedings of the 22nd AAAI Conference on Artificial Intelligence(AAAI-07), AAAI Press, 2007, pp. 1045–1050.[71] S.M. Majercik, M.L. Littman, Contingent planning under uncertainty via stochastic satisfiability, Artificial Intelligence 147 (2003) 119–162.