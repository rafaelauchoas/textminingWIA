Artificial Intelligence 198 (2013) 1–51Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintProbability and timeMarco Zaffalon a,∗, Enrique Miranda ba Istituto Dalle Molle di Studi sull’Intelligenza Artificiale (IDSIA), Galleria 2, 6928 Manno (Lugano), Switzerlandb University of Oviedo, Department of Statistics and Operations Research, C – Calvo Sotelo, s/n, 33007 Oviedo, Spaina r t i c l ei n f oa b s t r a c tArticle history:Received 18 November 2011Received in revised form 17 December 2012Accepted 23 February 2013Available online 26 February 2013Keywords:Temporal reasoningImprecise probabilitiesConditioningLower previsionsSets of desirable gamblesCoherenceConglomerabilityProbabilistic reasoning is often attributed a temporal meaning,in which conditioningis regarded as a normative rule to compute future beliefs out of current beliefs andobservations. However, the well-established ‘updating interpretation’ of conditioning is notconcerned with beliefs that evolve in time, and in particular with future beliefs. On theother hand, a temporal justification of conditioning was proposed already by De Moivre andBayes, by requiring that current and future beliefs be consistent. We reconsider the latterapproach while dealing with a generalised version of the problem, using a behaviouraltheory of imprecise probability in the form of coherent lower previsions as well as ofcoherent sets of desirable gambles, and letting the possibility space be finite or infinite. Weobtain that using conditioning is normative, in the imprecise case, only if one establishesfuture behavioural commitments at the same time of current beliefs. In this case it isalso normative that present beliefs be conglomerable, which is a result that touches on along-term controversy at the foundations of probability. In the remaining case, where onecommits to some future behaviour after establishing present beliefs, we characterise theseveral possibilities to define consistent future assessments; this shows in particular thattemporal consistency does not preclude changes of mind. And yet, our analysis does notsupport that rationality requires consistency in general, even though pursuing consistencymakes sense and is useful, at least as a way to guide and evaluate the assessment process.These considerations narrow down in the special case of precise probability, because thisformalism cannot distinguish the two different situations illustrated above: it turns out thatthe only consistent rule is conditioning and moreover that it is not rational to be willing tostick to precise probability while using a rule different from conditioning to compute futurebeliefs; rationality requires in addition the disintegrability of the present-time probability.© 2013 Elsevier B.V. All rights reserved.1. Introduction1.1. What has time to do with probability?We are interested in probability understood in the subjective tradition: as an uncertainty formalism that allows you1to express beliefs and do rational reasoning. Conditioning is an important component to reason with probability. In fact,the computation of conditional beliefs (i.e., expectations or probabilities) is taken by some researchers as ‘the’ procedureto obtain future rational beliefs out of current beliefs and observations, as if the Bayesian calculus—and Bayes’ rule inparticular—had captured the essence of the reasoning process itself through time.* Corresponding author.E-mail addresses: zaffalon@idsia.ch (M. Zaffalon), mirandaenrique@uniovi.es (E. Miranda).1 We follow Good, de Finetti and Walley in referring to ‘you’ as the subject that holds some probabilistic assessments.0004-3702/$ – see front matter © 2013 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2013.02.0052M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–51Is this view justified? To see whether this is the case, it is useful to go back at the foundations of probability. As ithas been well documented by Shafer [54,55], De Moivre and Bayes provided, already in the 18th century, an argument forthe temporal use of conditioning: it relies on constructing two bets, at present and future times, that jointly yield you asure loss if you do not use conditioning to compute your future beliefs. This is, in other words, a (Dutch) book argumentapplied through time. The approach is not uncontroversial2 and it may well clash with one’s intuition: in fact, from thetemporal-book argument it follows that once you have established your initial beliefs, your future rational behaviour willbe ‘mechanically’ determined. Should this be the case, should you not be allowed to change your mind?Nowadays, well-established approaches to probability seem to have taken a more cautious approach to defining the roleof conditioning; this caution de facto corresponds to eliminating time from the picture. The so-called updating interpretationof conditioning reads as follows: “your expectation of a gamble (i.e., a bounded random variable) f : Ω → R, conditional onevent B from a partition B of the possibility space Ω , represents yourcurrent beliefs about f under the assumption that Boccurs and that you obtain no other relevant information about Ω ”. The crucial word in the previous phrase is ‘current’: itmeans that under the updating interpretation, conditional beliefs are beliefs that you hold now; moreover, there is nothingin that phrase that relates your current conditional beliefs with the behaviour you will adopt once, and if, B occurs. Inthis view, Bayes’ rule loses its temporal flavor and reveals a simpler nature, that of a consistency requirement between yourcurrent conditional and unconditional beliefs: in fact, Bayes’ rule can be made to follow from the traditional book argument,the one that is applied to beliefs held at the same point in time.Yet, part of the literature has kept on exploring the relationship between probability and time, in the spirit of De Moivreand Bayes’ original intuition: this is the case, for instance, of the philosophical work on ‘dynamic coherence’ started inthe seventies with Teller (who credited David Lewis for having originated the argument, see [62, Note 1 to Section 1.3])and that continued in the eighties with a number of papers [2,3,58–60]; Shafer’s work, we have already mentioned, wasalso concerned to some degree with temporal considerations [54,55]. More recent work by Shafer et al. [56] stresses suchan aspect even more: among other things, it shows that Walley’s generalisation of Bayes’ rule to sets of probabilities [67,Section 6.4] is temporally consistent in a game-theoretic sense [57].Some other tightly connected approach is the statistical work on ‘temporal coherence’ by Goldstein [21–24], and therelated one in philosophy by van Fraassen [65,66]. In our view the aim here is different, however, as the focus does notappear to be on relating present and future behaviour, but rather on widening present beliefs so as to encompass also beliefsabout future beliefs. The field of ‘belief revision’, originated in the work of Gärdenfors and colleagues [1,18], attempts alsoto deal with temporal considerations in probability, besides logic. Its connection with the temporal-book idea is weaker,though.1.2. ContributionsWe aim at making a thorough analysis about the extent to which De Moivre and Bayes’ intuition can be made to providea firm foundation for a temporal interpretation of probabilistic reasoning. To this end, we consider a framework madeof two time points: now, and a future one determined by the occurrence of an event B ∈ B. Accordingly, we considertwo uncertainty models: one that you hold at present time, that is, your current beliefs (we also call them your currentcommitments3), and another one that you will hold after B occurs. We call the latter your future commitments.Our approach to the problem initially makes no assumptions on the relationship between current and future commit-ments. We do not even force the analysis to focus on conditional beliefs: present beliefs are allowed to be generically madeboth of conditional and unconditional information. Rather, we let the relationship between current and future assessmentsemerge by itself by characterising what it means that current and future commitments are consistent. This will also revealwhether and when it is actually rational (or normative) for you to be self-consistent in time.We shall pursue our aims within the framework of imprecise probability, and in particular start our work using Walley’sbehavioural theory of coherent lower previsions [67]: this is an extension of de Finetti’s theory [12] to sets of probabilitiesthat is close to robust Bayesianism. De Finetti’s theory is based on the concept of a (linear) prevision, which is anothername for an expectation functional; a coherent lower prevision is a lower envelope of linear previsions, which is in one-to-one correspondence with a closed and convex set of finitely additive probabilities. These tools enable us to deal uniformlywith precise and imprecise probability, as well as with any cardinality of the possibility space Ω —which is then allowed tobe infinite. Section 2 provides an introduction to the theory that is conceived to make the work as self-contained as it ispossible in a research paper. It also discusses the alternative representation of coherent lower previsions in terms of a setof desirable gambles: this is the set of gambles that you find desirable (i.e., that you would accept if they were offered toyou) as a logical consequence of your probabilistic assessments. This helps us to convey the intuition behind the conceptsand the results we present. Section 3 describes our temporal framework in detail, and introduces your uncertainty modelsin the form of two coherent lower previsions for your present and future commitments, respectively.The core of our work starts in Section 4. We define a number of consistency notions for your current and future lowerprevisions, and show that each of these notions is appropriate in a different scenario, depending on the time when your2 See also philosopher Levi’s fierce opposition to the idea of the temporal-book argument in his ‘demons of decision’ [36].3 Probabilistic assessments can be interpreted as commitments to engage in special types of bets.M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–513future commitments are declared. For each of these notions, we give a number of characterisations, and establish a connec-tion with other notions from the theory of coherent lower previsions.One of the most interesting is the equivalence between one of our consistency notions and the conglomerability of yourpresent beliefs. Loosely speaking, the notion of conglomerability is what allows us, in precise probability, to represent aprevision (i.e., an expectation) as an infinite mixture of conditional previsions. This notion was originally introduced byde Finetti in 1930 [9,11] as a property that a finitely additive—but not countably additive—probability may not satisfy. Sincethen, the debate concerning whether or not conglomerability should be a rationality requirement in probability has neverhad an end (e.g, see [67, Section 6.8], [45, Section 3.4], but also [27,28,48,49,53]). Here we explicitly relate conglomerabilityto temporal considerations; and it is this very connection that allows us to make a clear point: that conglomerability shouldin fact be a rationality requirement when present and future commitments are established together (and moreover thatfuture commitments should be equal to present conditional beliefs). Let us stress that we achieve this without strengtheningthe assumptions commonly employed in these cases,4 like those in de Finetti’s theory, but rather just coupling them withtemporal considerations.When present and future commitments are established at different times, the situation is more open: there are manyways to define future commitments that are consistent with current beliefs (and hence may be constrained by them to someextent). This means, in particular, that in the imprecise framework changing mind is compatible with temporal consistency.On the other hand, we do not see the possibility to argue in general that it should be normative for you to be consistentin time. The situation changes if we restrict the attention to the special case of precise probability, as in Section 4.5, andespecially if we assume in addition that conditioning events have positive probability. We argue that in this case rationalityrequires that your present probability be disintegrable (disintegrability is a special case of conglomerability, see [14]) andthat future commitments be defined by Bayes’ rule. Stated differently, it appears to be a specificity of the Bayesian setup todisallow you to change your mind in order to keep consistency, and hence to regard future beliefs as predetermined onceyou have established your present beliefs. The framework is less rigid in case we allow conditioning events to be assignedzero probability.Although we can say much about the consistency of your uncertainty models when these are represented by means ofcoherent lower previsions, there are situations when these are not expressive enough; this is for instance the case whenwe want to condition on sets of probability zero, as it is common in infinite spaces, or if we want to give a meaning togambles with prevision equal to zero, which is important when we wish to model preferences. A more informative modelfor those cases are just sets of desirable gambles, when we use them in their full generality. We review the model in thislight in Section 5, and discuss in addition how desirable gambles can be regarded as a particularly natural and powerfulgeneralisation of propositional logic to uncertainty.In Section 6 we take desirable gambles as our primitive model (from which one can actually derive coherent lowerprevisions, in case), and show how the consistency notions we have introduced in Section 4 can be extended to such ageneralised setup, and which are the properties that hold in this case. In particular, we consider the important specialcase where your present beliefs are constructed in a hierarchical way through marginal extension [40,43,67], which is ageneralisation of the law of iterated expectations to imprecise probability. We reconsider also the Bayesian case in the lightof desirability: thanks to the notion of precision that is tailored to sets of desirable gambles, we show that in this caseconditioning is the only rational rule to compute future commitments even when the probability of a conditioning event iszero.In Section 7 we comment on the connections between our work and some related approaches: dynamic coherence;Jeffreys’ rule and probability kinematics; the work by Goldstein and van Fraassen; Shafer et al.’s game-theoretic reinterpre-tation of the theory of coherent lower previsions; belief revision.In Section 8 we discuss at some length our updated point of view on these matters after the analysis we have done.Some additional technical results are given in Appendix A.2. Coherent lower previsions2.1. An introduction to the theoryLet us denote by Ω the possibility space, that is, the set of possible outcomes of an experiment, intended in a broadsense. Let us make this more concrete with the help of a running example that will be developed throughout the text.Example 1 (Running example). You are a physician confronted with a situation of uncertainty originated by two differentviruses causing flu: the usual seasonal virus (i.e., virus s) and a more serious atypical variant (virus a). Your experience tells4 Technically speaking, this has to do with a finitary feature of these uncertainty representations, including the ones we use in this paper, according towhich it is never assumed that you should be willing to accept infinitely many gambles that are desirable to you, in case they are offered to you. It iscontroversial that the opposite should be assumed (e.g., de Finetti does not find it rationally justified while Walley does), and in addition it is a very strongassumption: one that makes it trivial to derive conglomerability, so that the latter is deprived of its own meaning—which lies entirely in the assumption—,and even that probabilities should be σ -additive. But σ -additivity leads us into measurability problems, which we are instead dispensed of in case we staywith finitely additive models.4M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–51you something about the likelihood of each of these two viruses on a person; there is also a blood test (with positive ornegative outcomes) that allows you to discriminate the viruses to some good degree. However, the information in these twocases may be uncertain, and this may render impossible the task of modelling it by means of precise probabilities. For thetime being, we shall only model this problem by the variables V and T , for virus and test, with possible values {a, s} and{p, n}, respectively. The possibility space in this example is just the product space Ω := {(a, p), (a, n), (s, p), (s, n)}. We shalluse the convention to denote by V = v and T = t, for generic values (v, t) ∈ Ω , the events {(v, p), (v, n)} and {(a, t), (s, t)},respectively.In this paper we let Ω be general in the sense that we do not impose any restriction on its cardinality. We call a gambleany bounded function from Ω to the real numbers. A gamble is interpreted as an uncertain reward that depends on theunknown outcome of the experiment; we assume that the rewards are expressed in a utility scale that is linear for you.We denote by L(Ω) the set of all gambles on Ω . L+(Ω) denotes the set of positive gambles on Ω : that is, all gamblesf such that f (ω) (cid:2) 0 for all ω ∈ Ω and f (ω) > 0 for some ω ∈ Ω ; we rewrite this notation for short as f (cid:2) 0 (similarly,the negative gambles { f (cid:3) 0} are such that f (ω) (cid:3) 0 for all ω ∈ Ω and f (ω) < 0 for some ω ∈ Ω ). We shall often use thesymbol B to denote a subset B of Ω , as well as to denote the indicator function IB of subset B; this means for instancethat B f shall denote the gamble given by(cid:2)B f (ω) =f (ω)0if ω ∈ B,otherwise.(1)L(B) denotes the set of all gambles on B, and L+(B) is its subset of positive gambles. Sometimes we shall also use theshorter notation L to refer to the set of all gambles on a certain possibility space, when this is clear from the context orwhen we want to establish some result for a generic possibility space. We shall also use the short notation L+It is also convenient to introduce the following notation: when f ∈ L(Ω) and B is an element of a partition B of Ω ,f B ∈ L(B). More generally speaking, we shall use subscript B forwe shall denote by f B the restriction of f to B. Hence,gambles in L(B). On the other hand, if f B is a gamble on B, we shall denote by B f B its extension to a gamble on Ω , givenby Eq. (1). Thus, f =(cid:3).B∈B B f B .Operations on gambles are understood point-wise. We shall focus in particular on the multiplication of a gamble f witha constant λ, giving rise to gamble λ f , and on the sum of two gambles f and g, giving rise to gamble f + g. Constantgambles are denoted by the corresponding real value: the distinction between the two cases will be clear from the context;for example, if α is a real number, then f + α denotes the sum of f and the gamble constant on α. Also, when a gamble isconstant on the elements of a partition B of Ω , we call it B-measurable. Comparisons of gambles, such as f (cid:2) g, are to beintended point-wise too (although f (cid:2) 0 is an exception to this rule as it is different from f > 0).The theory of coherent lower previsions generalises probability theory (in the sense of de Finetti [12]) to the case wherebeliefs are specified imprecisely via sets of (finitely additive) probabilities. To see this, we need to define expectation, whichde Finetti calls prevision. We focus in particular on lower and upper previsions, which arise naturally when your set of beliefsis consistent with a range of previsions; in addition we directly focus on the conditional case, and discuss the unconditionalone as a special case.Definition 1 (Coherent conditional lower previsions). Let B be a partition of Ω , and for every B ∈ B let P (·|B) be a real-valuedfunctional on L(Ω). Then P ( f |B) is called the lower prevision of f conditional on B. The B-measurable gamble P ( f |B) :=(cid:3)B∈B B P ( f |B) is called the lower prevision of f conditional on B. The functional P (·|B) : L(Ω) → L(Ω) is called a separatelycoherent conditional lower prevision when the following conditions hold for every f , g ∈ L, B ∈ B and λ > 0:(SC1) P ( f |B) (cid:2) infω∈B f (ω);(SC2) P (λ f |B) = λP ( f |B);(SC3) P ( f + g|B) (cid:2) P ( f |B) + P (g|B).In that case P (·|B) is called a coherent lower prevision.The behavioural interpretation of the conditional lower prevision P ( f |B) is that of your current supremum price forbuying gamble f under the assumption that ω ∈ B. When the focus is on selling rather than buying gambles, we cometo conditional upper previsions: P ( f |B) is your current infimum price to sell gamble f under the assumption that ω ∈ B.P (·|B) and the functional P (·|B) are then defined analogously to the case of lower previsions, and are called coherentand, respectively, separately coherent conditional upper previsions. The definition of conditional lower and upper previsionsmakes it clear that the following conjugacy relationship holds: P ( f |B) = −P (− f |B) for all f ∈ L and B ∈ B; this allows usto focus our development on conditional lower previsions only. The occasional use we do of conditional upper previsionswill be mostly motivated by mathematical convenience.As we have mentioned already, coherent lower previsions represent lower expectation functionals (note that they areapplied to gambles, that is, to bounded random variables). In fact, it is important to be aware right from the beginning thatthe theory of imprecise probability we have just started to describe, regards expectation as the primitive concept ratherM. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–515than probability. The idea is that you model your uncertainty by providing conditional and unconditional coherent lowerprevisions. Accordingly, when we speak of ‘beliefs’, we technically mean the uncertainty model, which in this case are lowerprevisions.5Of course, you may still want to model your uncertainty using probabilities; this is possible by providing your lowerprevisions of the indicator functions. Thus, in this theory, an event A ⊆ Ω is represented by gamble I A , and your lowerprobability for A is just the lower prevision P (I A). This can be written more simply as P ( A), thanks to the convention thatallows us to use A, besides I A , to denote the indicator function of set A.Example 2 (Running example). Assume for instance that you have imprecise information about the likelihood of the twodifferent types of flu depending on the outcome of the test. You may know for instance that if the test is positive, theatypical virus is at least three times as likely as the seasonal one, while if the test is negative, the seasonal virus is at leastfour times as likely as the atypical one. This leads to the probabilistic assessmentsP (V = a|T = p) (cid:2) 3P (V = s|T = p) and P (V = s|T = n) (cid:2) 4P (V = a|T = n).These assessments can equivalently be represented by the following lower and upper conditional probabilities:P (V = a|T = p) = 0.75 and P (V = a|T = n) = 0.2,which, in turn, determine the following coherent conditional lower previsions:(cid:4)P ( f |T = p) = min(cid:4)P ( f |T = n) = min(cid:5)f (a, p), 0.75 f (a, p) + 0.25 f (s, p)(cid:5)f (s, n), 0.8 f (s, n) + 0.2 f (a, n),,where fis any gamble on the product space {(a, p), (s, p), (a, n), (s, n)}.However, modelling uncertainty only with probabilities (that is, specifying buying and selling prices only for indicatorfunctions) limits expressiveness in the imprecise case: it is well known that lower probabilities do not determine coherentlower previsions in general, in the sense that there may be more than one coherent lower prevision that is consistent withthe specified probabilities (see, e.g., [67, Section 2.7.3]). Therefore, to take full advantage of the theory, it is necessary tomove from events to the richer language of gambles.Precise probability is obtained when conditional lower and upper previsions coincide:Definition 2 (Conditional linear previsions). If for a coherent lower prevision it holds that P ( f |B) = P ( f |B) for all f ∈ L, thenwe denote the common value by P ( f |B) and call it the linear prevision of f conditional on B. When this holds for all B ∈ B,we define P (·|B) in analogy with the case of conditional lower previsions, and call it a conditional linear prevision.Example 3 (Running example). In case you had precise information, stating that if the test is positive, the atypical virus isexactly three times as likely as the seasonal one, while if the test is negative, the seasonal virus is exactly four times aslikely as the atypical one, we would end up with the conditional linear prevision P (V |T ) given byP ( f |T = p) = 0.75 f (a, p) + 0.25 f (s, p) and P ( f |T = n) = 0.8 f (s, n) + 0.2 f (a, n)for any gamble f on {(a, p), (s, p), (a, n), (s, n)}.The case of (unconditional) lower and linear previsions follows as a special case from the above definitions by consideringthe trivial partition {Ω}. In that case we simplify the notation by writing P := P (·|{Ω}) as well as P := P (·|{Ω}).A linear prevision P is in one-to-one correspondence with the finitely additive probability that is its restriction to (indi-cator functions of) events. A coherent lower prevision P is in one-to-one correspondence with the credal set6 M(P ) of linearprevisions given by M(P ) := {P : P ( f ) (cid:2) P ( f ) ∀ f ∈ L}. This shows that P is in correspondence with a set of finitely addi-tive probabilities; in addition, P corresponds to the lower envelope of the previsions in M(P ): P ( f ) = inf{P ( f ): P ∈ M(P )}for every f ∈ L. These relationships immediately extend to the conditional case.In this paper we are going to work with beliefs established at different points in time. When these beliefs are representedby means of lower previsions, we may end up with an unconditional coherent lower prevision P and with a separatelycoherent conditional lower prevision P (·|B). The consistency between an unconditional and a conditional lower prevision inWalley’s theory is verified by means of a notion of (joint) coherence. In order to define it, it is convenient to consider somespecial gambles: given a separately coherent conditional lower prevision P (·|B) and a gamble f ∈ L, we let5 Later, when we introduce a more general theory than coherent lower previsions in Section 5, it will be a set of gambles that you desire, i.e., which youare prepared to accept.∗6 By a credal set we mean a set of linear previsions that is closed in the weak∗topology and convex. The weaktopology is the smallest topology forwhich all the evaluation functionals given by f (P ) := P ( f ), where f ∈ L, are continuous.6M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–51G( f |B) := B(cid:6)(cid:7)f − P ( f |B)and G( f |B) := f − P ( f |B) =(cid:8)B∈BG( f |B).Definition 3 (Coherence for lower previsions). Let P be a coherent lower prevision on L, B a partition of Ω and P (·|B) aseparately coherent conditional lower prevision on L. We say that P , P (·|B) are coherent when they satisfy the followingconditions:GBR. P (G( f |B)) = 0 for every f ∈ L, B ∈ B [Generalised Bayes rule];CNG. P (G( f |B)) (cid:2) 0 for every f ∈ L [Conglomerability].Condition GBR is called generalised Bayes rule because it amounts to applying Bayes’ rule to all the elements of a credalset—if that is possible—in order to obtain the conditional credal set. Therefore it becomes Bayes’ rule in the precise case.Condition CNG refers to the conglomerability of an unconditional lower prevision with a conditional one, and is tightlyrelated to de Finetti’s original formulation of conglomerability [9] (a related definition of conglomerability, in this case ofa single coherent lower prevision, is provided in Definition 5 later on). Note moreover that CNG follows from GBR and thecoherence of P when the partition B is finite. Together, GBR and CNG can also be given a behavioural interpretation [67,Chapter 6]: they mean that a finite combination of gambles whose desirability follows from the lower previsions P , P (·|B)should still be desirable, and moreover that a gamble you have not deemed desirable should not become desirable byconsidering the implications of the assessments in P , P (·|B).Example 4 (Running example). Assume for instance that you have unconditional information, stating that the prevalence ofthe atypical virus in that region is of at most 5%, while that of the seasonal virus is of at least 95%. This corresponds to theprobabilistic assessmentsP (a) (cid:3) 0.05 and P (s) (cid:2) 0.95;if we consider the set of probabilities on {(a, p), (s, p), (a, n), (s, n)} that are compatible with this information, we end upwith the coherent lower prevision P given byP ( f ) = min(cid:4)(cid:4)min(cid:5)f (s, n), f (s, p), 0.95 min(cid:4)(cid:5)f (s, n), f (s, p)(cid:4)+ 0.05 min(cid:5)(cid:5)f (a, n), f (a, p)(2)for any gamble f . To see if this lower prevision satisfies coherence with respect to the conditional model from Example 2,note that given the gamble f := I(a,p), it holds thatP ( f |T = p) = 0.75, whence G( f |T = p) = 0.25I(a,p) − 0.75I(s,p),and this means that(cid:6)(cid:7)G( f |T = p)P= min{−0.75, 0.05 · 0 − 0.95 · 0.75} = −0.75 < 0.Therefore, the two lower previsions are not coherent, because they do not satisfy GBR. Note that in this specific example GBRis equivalent to coherence, because condition CNG follows from it since the partition is finite.Generalised Bayes rule enables us to define the least-committal extension of a coherent lower prevision to the conditionalcase:Definition 4 (Conditional natural extension for lower previsions). Let P be a coherent lower prevision on L. The natural extensionof P conditional on B ∈ B is given by(cid:2)E( f |B) :=sup{μ: P (B( f − μ)) (cid:2) 0}infω∈B f (ω)if P (B) > 0,otherwise.(3)This is a separately coherent conditional lower prevision determined through generalised Bayes rule when the condi-tioning event has positive lower probability: in that case, E( f |B) is the only value for which GBR is satisfied with respectto P ; and it is vacuous, which means completely uninformative, in the remaining case. In fact, when the conditioning eventhas zero lower probability there may be many conditional lower previsions satisfying generalised Bayes rule with P [67,Section 6.10]; the vacuous one corresponds to the smallest [67, Theorem 8.1.6]. The conditional natural extension E(·|B) isalways coherent with P when B is finite.Example 5 (Running example). If we consider the coherent lower prevision P from Example 4, then it satisfies P (V =a) = 0 and P (V = s) = 0.95. Hence, the conditional natural extension P (T |V = a) is vacuous: we have P ( f |V = a) =min{ f (a, p), f (a, n)}. On the other hand, P ( f |V = s) is determined by the generalised Bayes rule, which in this case pro-duces a vacuous model too:M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–517(cid:4)P (T |V = s) = min(cid:5)f (s, p), f (s, n);this is because if we consider any μ > min{ f (s, p), f (s, n)}, then(cid:6)(cid:7)Is( f − μ)P(cid:4)= min(cid:5)f (s, n), f (s, p)− μ < 0,and therefore GBR is not satisfied.When the conditioning partition B is infinite, a lower prevision need not be coherent with its conditional natural exten-sion; the latter is rather a lower bound of any conditional lower prevision that is coherent with the unconditional model.Hence, the acceptable buying prices encoded by the conditional natural extension should be acceptable under any coher-ent extension to the conditional case. On the other hand, the coherence of a coherent lower prevision with its conditionalnatural extension is characterised by the notion of conglomerability:Definition 5 (Conglomerability for lower previsions). A coherent lower prevision P is called B-conglomerable when there is aseparately coherent conditional lower prevision P (·|B) such that P , P (·|B) are coherent.In this paper we always focus on a single partition B of Ω ; for this reason we shall often say simply that a lowerprevision is conglomerable rather than B-conglomerable. In particular, P is conglomerable if and only if it is coherent withits conditional natural extension E(·|B) given by Eq. (3) [67, Theorem 6.8.2]. Moreover, P is always conglomerable whenP (B) = 0 for every B ∈ B, or when the partition B is finite.A related notion is that of disintegrability:Definition 6 (Disintegrability). A linear prevision P is called B-disintegrable (or just disintegrable) when there is a linearconditional prevision P (·|B) such that P , P (·|B) are coherent.Given a linear prevision P and a conditional linear prevision P (·|B), conditions GBR and CNG together are equivalentto the equality P = P (P (·|B)). Trivially, if a linear prevision P is disintegrable, then it is also conglomerable. However,the converse is not true: there are linear previsions P satisfying conditions GBR and CNG with respect to a conditionallower prevision P (·|B) but not with respect to any conditional linear prevision P (·|B) (for an example, see [14] and [67,Example 6.6.10]).There is also a weaker consistency notion for lower previsions that is called avoiding sure loss:Definition 7 (Avoiding sure loss for lower previsions). Let P be a coherent lower prevision on L, B a partition of Ω and P (·|B)a separately coherent conditional lower prevision on L. We say that P , P (·|B) avoid sure loss when for every f , g ∈ L, itholds thatASL. sup[G( f ) + G(g|B)] (cid:2) 0.The behavioural interpretation of this condition is that by accepting a finite combination of gambles whose desirabilityfollows from the definition of P , P (·|B) you should never be subject to a sure loss. If P , P (·|B) are coherent then they alsoavoid sure loss; both conditions are equivalent when P , P (·|B) are linear (unconditional and conditional) previsions.Example 6 (Running example). Consider again the unconditional and conditional lower previsions P , P (V |T ) from Example 4.We already saw there that they are not coherent. To see that they avoid sure loss, note that for any gamble fit followsfrom Eq. (2) that P ( f ) (cid:3) min{ f (s, n), f (s, p)}, whence G( f )(s, n) (cid:2) 0 and G( f )(s, p) (cid:2) 0. Since on the other hand it alsofollows from the definition of P (V |T ) that P (g|T = n) (cid:3) g(s, n) for any gamble g, we deduce that(cid:9)(cid:10)G( f ) + G(g|T )(s, n) (cid:2) 0for any pair of gambles f , g. As a consequence, P , P (V |T ) avoid sure loss.In particular, if we apply condition ASL to an unconditional lower prevision P on L, it turns out that P avoids sureloss if and only if its associated credal set M(P ) is non-empty. This holds in particular when P is coherent, although bothconditions are not equivalent.2.2. Correspondence with a set of gamblesA coherent lower prevision can be expressed equivalently by determining the set of gambles whose acceptability itencompasses.Given a coherent lower prevision P on L, its associated set of gambles is given by8M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–51(cid:4)(cid:5).R := L+ ∪f ∈ L: P ( f ) > 0(4)f ∈ L, as your supremum acceptable buying prices for the gambles f ∈ L, then the set RIf we interpret the values P ( f ),represents those that you are sure to find acceptable: those non-zero gambles that may only make you subject to a gain(L+) and those for which you are disposed to pay a positive amount in order to buy them ({ f ∈ L: P ( f ) > 0}).Similarly, given a conditional lower prevision P (·|B) on L(Ω), its associated set of gambles is given by(cid:6)(cid:4)R|B :=f ∈ L: f = B f and(cid:7)(cid:5).Note also that we can recover P (·|B) from R|B by means ofμ: B( f − μ) ∈ R|Bor P ( f |B) > 0P ( f |B) = supB f ∈ L+(cid:5).(cid:4)(5)(6)In this paper, we shall make a connection between a number of notions of temporal consistency for coherent lowerprevisions and associated properties of the sets of desirable gambles they induce. In particular, we shall use the following:Definition 8 (Coherence for gambles). A subset R ⊆ L is called coherent when it satisfies the following conditions:D1. L+ ⊆ R [Accepting Partial Gains];D2. 0 /∈ R [Avoiding Null Gain];D3.D4.f ∈ R, λ > 0 ⇒ λ f ∈ R [Positive Homogeneity];f , g ∈ R ⇒ f + g ∈ R [Additivity],and it is said to avoid partial loss when it is included in a coherent set.Coherence means that you should be willing to accept a transaction represented by a finite number of desirable gam-bles (D4), and to make a linear change in the utility scale without affecting the desirability of the gambles (D3). Moreover, itimplies that a non-zero gamble that can never give you a negative reward should be desirable (D1), while a gamble that cannever give you a positive reward should not (D2). Avoiding partial loss suffices to extend your assessments while ‘correcting’them into coherent ones. Geometrically, a coherent set is a convex cone, that is, a set closed with respect to finite positivelinear combinations (as from D3–D4). The smallest, and hence the least committal, of the coherent cones that include R, iscalled its natural extension:Definition 9 (Natural extension for gambles). If a set R avoids partial loss, then the intersection of all its coherent supersets,denoted by ER, is coherent and it is called its natural extension.Then R is coherent if and only if it coincides with its natural extension. An example of a coherent set is the one inducedby a coherent lower prevision, as in (4).Remark 1. Note that ER does not contain any gamble g (cid:3) 0. The case g = 0 is excluded by D2. In the case g (cid:3) 0, we shouldhave that 0 = −g + g ∈ ER, by D1 and D4, and this contradicts D2 again.On the other hand, it is not difficult to show that given two coherent sets of gambles R1, R2, their union R1 ∪ R2avoids partial loss if and only if the set(cid:4)R1 ⊕ R2 :=f + g: f ∈ R1 ∪ {0}, g ∈ R2 ∪ {0}, f (cid:10)= 0 or g (cid:10)= 0(cid:5)satisfies D2, and it is coherent if and only if R1 ∪ R2 = R1 ⊕ R2 (see Proposition 8 in Section 6 and Lemma 3in Appendix A).Axioms D1–D4 show that the coherence notion we have introduced is equivalent to that proposed by Peter Williams in[68]; in particular, it should not be confused with the strongest definition proposed by Walley in [67, Appendix F1]. Walley’sdefinition includes in addition a requirement of conglomerability as expressed by axiom D5 below:7Definition 10 (Conglomerability for gambles). Given a set of desirable gambles R that satisfies D1–D4 and a partition B of Ω ,R is called B-conglomerable (or just conglomerable) when it also satisfies:D5.f ∈ L \ {0}, B f ∈ R ∪ {0} ∀B ∈ B ⇒ f ∈ R,where B fis given by Eq. (1), and of course f =(cid:3)B∈B B f .7 However, Walley requires axiom D5 to hold for all the partitions of Ω ; this is called ‘full conglomerability’. In contradistinction, our axiom D5 is onlyused with respect to the single partition B. This is called ‘partial conglomerability’ and bears no implications on the much stronger requirement of fullconglomerability. Therefore, whenever we talk of conglomerability in this paper, we mean partial conglomerability.M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–519Conglomerability follows from D4 in case the partition is finite; hence Williams’ and Walley’s coherence notions areequivalent in that case (and in particular when Ω is finite). The treatment of the infinite case is a controversial matter:Walley claims that conglomerability should be imposed as a rationality requirement [67, Section 6.9.8] while other authors,such as de Finetti [9,11], reject this idea. This question is important, especially because conglomerability can be related to σ -additivity: this means that what de Finetti rejects, by rejecting conglomerability, is that σ -additivity should be a rationalityrequirement; to him, rationality only constrains us to stay with finitely additive probabilities.Conglomerability can be used to define a special type of natural extension [43]:Definition 11 (Conglomerable natural extension for gambles). Given a set of desirable gambles R and a partition B of Ω , theB-conglomerable natural extension of R, if it exists, is the smallest set F that contains R and satisfies D1–D5.Let us move on now to consider conditioning for a set of desirable gambles. Conditioning is made with respect to anelement B of a partition B of Ω .Definition 12 (Conditioning for gambles). Given a coherent set of desirable gambles R and a partition B of Ω , we definebeliefs conditional on an element B of B as the setR|B := { f ∈ L: f = B f ∈ R}.(7)Sometimes we need to represent this set through gambles defined on L(B); then we use the equivalent representationgiven by R|B := { f B ∈ L(B): B f B ∈ R|B }.One interesting property is that this conditional set of gambles induces the conditional natural extension of P , given byEq. (3). If we define(cid:4)(cid:5)(cid:4)(cid:5)P ( f |B) := supμ: B( f − μ) ∈ R(8)where R is the set of gambles induced by P through (4) and R|B is derived from R by means of (7), then we have thefollowing:= supμ: B( f − μ) ∈ R|B,Lemma 1. Let P be a coherent lower prevision on L, and let P (·|B) be the conditional lower prevision it induces by means of Eq. (8).Then:(a) P , P (·|B) satisfy GBR.(b) P (·|B) coincides with the conditional natural extension E(·|B) of P .Proof.(a) Consider a gamble f on Ω and B ∈ B. From Eq. (8), for every δ > 0 the gamble B( f − P ( f |B) + δ) ∈ R, whenceP (B( f − P ( f |B) + δ)) (cid:2) 0 by Eq. (4). Since this holds for every δ > 0 we deduce that P (G( f |B)) (cid:2) 0. On the other hand,if P (G( f |B)) > 0, then there is some δ > 0 such that P (B( f − P ( f |B) − δ)) > 0, whence B( f − P ( f |B) − δ) ∈ R and asa consequence P ( f |B) (cid:2) P ( f |B) + δ, a contradiction.(b) Taking point (a) into account, now we must show only that P ( f |B) = infB f whenever P (B) = 0. We have thatP ( f |B) = supμ: B( f − μ) ∈ R(cid:4)(cid:5)= sup= sup(cid:4)μ: B( f − μ) (cid:2) 0 or P(cid:4)μ: B( f − μ) (cid:2) 0(cid:5)= infBf ,(cid:6)(cid:7)B( f − μ)> 0(cid:5)because of Eq. (4), and because P (B( f − μ)) (cid:3) P (B(supB f − μ)) = P (B)(supB f − μ) = 0, taking into account thatμ (cid:3) P ( f |B) (cid:3) supB f . (cid:2)The definition of conditioning for a set of desirable gambles is simply based on restricting the attention to the desirablegambles that are zero outside B. This corresponds to the so-called contingent interpretation of conditioning: we can think ofit as a way of modelling your present attitudes towards gambles that are called off if the outcome ω ∈ Ω of the experiment,for which you are accepting gambles, does not belong to B. On the other hand, the updating interpretation of conditioningunderstands set R|B as the gambles you are disposed to accept now if you assume that B occurs and that you obtain noother relevant information about Ω . Walley discusses the agreement of the contingent and the updating interpretations in[67, Section 6.1.5].A question of particular importance is that the updating interpretation makes no claim whatsoever concerning the gam-bles you will be committed to accept once (and if) B actually obtains. Since this is a frequent source of confusion insubjective probability, let us stress once again that conditional beliefs refer only to your current beliefs and bear no implica-tions (in absence of further conditions or justifications) on the future. To enforce this distinction, in the following we shall10M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–51Fig. 1. The temporal setup. Current beliefs are always established now. Future commitments can be established in three different periods: now; afterwardsbut before B occurs; after B occurs. Future commitments are never effective before B occurs.use the terminology conditional beliefs to talk of (current) updated beliefs, and future commitments for the probability modelyou will endorse after B actually obtains. See Section 3 for a more detailed discussion.3. Introducing the temporal setup3.1. On the relationship of probability with timeLet us recall that you are interested in the outcome of an experiment that is known to belong to the set Ω . Section 2described, among other things, how to model your uncertainty about Ω through a coherent lower prevision P . This lowerprevision has to be intended as commitments on your side: by providing P , you commit yourself to accept any gamble youare offered from the set R originated by P through Eq. (4). This implies also that you will not accept the zero gamble, be-cause of D2, nor any gamble − f ∈ −R, for you are committed to accept f and f − f = 0. On the other hand, establishing Rhas no implications on the gambles in L \ (R ∪ −R ∪ {0}): in the actual transactions with an opponent, you could actuallyaccept some of them and reject some others, or just be undecided. In other words, we acknowledge that your uncertaintymodel may be only an incomplete representation of your beliefs, rather than an exhaustive one. This means, in particular, thatyour actual behaviour might even be consistent with a lower prevision that is more (but never less) precise than P . Thereare many reasons why this may happen; see [67, Section 2.10.3] for a discussion about this point.It is important to clearly understand the relationship of all this with time. In fact, Section 2 was entirely focused on asingle point in time—which we conventionally take to be the present moment. In particular, that section assumes that youare providing your beliefs about Ω now and makes no claims about the dynamics of your beliefs through time. This is thecase even when one considers conditional assessments, which still refer, by definition, to beliefs at present time. In thissetup, there is no link, let alone a formal one, between your present and future commitments.If we want to relate your present commitments to your future ones, we need to explicitly introduce time in the processof defining your assessments. This is what we set out to do. To this end, we consider an additional time point, besides now,that is determined by the outcome of a further experiment. The latter experiment will yield an element B of a partition Bof Ω , thus informing you that the outcome ω ∈ Ω of the former experiment—the one you are really after—actually belongsto B.The situation then is going to be the following. At present time you define your current beliefs P ; from this moment tothe future time point when B occurs, an opponent may offer you a (finite) number of gambles and you will be committed toaccept all those that belong to R, the set associated to P . On the other hand, you will also establish some other assessmentsin the form of a lower prevision P B : this represents your future commitments, which only become effective after B isobserved. The idea here is that from the occurrence of B onwards, you will be committed to accept gambles from the setof desirable gambles RB associated to P B , and no longer from R. We consider three possible time periods when you candecide to establish your future commitments, as shown in Fig. 1: now, later but before B, after B.In practice there are a number of reasons why you might want to define P B in different time periods. For example, youmight exclude that the availability of extra time to reflect on P could lead you to modify your current conditional beliefs.In this case you might want to set your future commitments equal to your conditional beliefs, and you would do it now. Orit could be the case that at the time when you establish your present beliefs you do not even know which are the possibleevents to observe in the future, that is, you do not know what the partition B is going to be. Imagine that you come toknow the form of B some time later and before B occurs. You will probably use some of the remaining time to specificallyimprove on your assessments concerned with your beliefs conditional on the events of B, and possibly commit to them (forthe future) before B occurs. Finally, it could well be the case that you know both B and B only after the latter occurs. Inthis case you will specifically focus only on beliefs that depend on the occurrence of such a specific B.Needless to say, your future commitments P B express your beliefs about Ω at the time point when you establish them.Therefore, in case you establish them before B occurs, they cannot in general be regarded as your beliefs after B. This isthe reason why we call them future commitments rather than future beliefs. Still, they are commitments: for you are awarethat in the moment when you decide to establish (i.e., declare) them, you are committing yourself to accept gambles, afterM. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–5111B occurs, from the set of desirable gambles RB induced by P B . Note moreover that the beliefs represented by P B willobviously take into account that the commitments they express will become effective after B occurs, and therefore theywill only focus on the case where the outcome ω ∈ Ω of the original experiment belongs to B; in other words, they arebeliefs about the set B ⊆ Ω .A few additional remarks are in order:• In this paper we are interested in the case of two time points, as indicated above; we are not considering extensions tomultiple future time points. Accordingly, we assume that the present time coincides with the beginning of the processof establishing commitments, in the sense that P represents the first commitments you have made about Ω .• Let us point out more clearly something that is already implied by the above discussion: after the present moment,when your current lower prevision P is established, you are no longer allowed to modify or drop it until event Boccurs. This means that the commitments it encodes actually constrain your behaviour up to the occurrence of B.• We are making no assumptions about the process that leads you to define the future lower prevision P B ; you candefine it arbitrarily. In particular, we are not assuming that it coincides with the conditional natural extension E(·|B)of P , that is, your present conditional beliefs. However, we shall assume that your future commitments are known,instead of being random variables, as is the case for the related approaches by Goldstein and van Fraassen we shalldiscuss in Section 7.3. Moreover, we are assuming that they are indeed commitments: once they are established, yourbehaviour after B is going to be constrained by P B (it is not necessarily going to be fully determined by P B , since weare not assuming that P B is an exhaustive model). This appears to be in line with recent work by Shafer et al. [56], andless so with respect to older work by Shafer.8• In order to avoid confusion, let us also point out that your future commitments P B are beliefs (at the time when youestablish them) about B: they are not, and should not be interpreted as, beliefs about your future beliefs.• On the other hand, we assume that after the definition of P , you will not receive new information relevant to Ω otherthan B (and the related partition B); hence, we are dealing with a case of exact information, in the words of Shafer etal. [55].9 This setup resembles the one commonly adopted in probability when defining the updating interpretation ofconditioning: that a subject, in the process of assessing his conditional beliefs, assumes to get to know B and nothingelse new about Ω . However, there are also differences with our setup. One that is especially clear arises if you define P Bafter B occurs: in that case it will not be only an assumption for you that B is the only new information observed, itwill arguably be a matter of fact. Another difference is indeed that your future commitments can be established laterthan now (check Fig. 1), while conditional beliefs are always established at present time. A final difference is that inthe traditional updating interpretation there is no statement claiming that your future behaviour should be constrainedby your conditional beliefs: in fact, this is one of the key points of this paper, that is, distinguishing clearly your futurecommitments, those that will actually constrain your behaviour in the future, from your current conditional beliefs.• The previous point assumes that your state of information stays the same from now to the occurrence of B. Whatthen justifies a possible difference between E(·|B) and P B is just the availability of additional time: having more timeallows you in general to rework your original assessments E(·|B) by examining the available evidence more carefullyso as to come up with model P B . In fact, in this paper we aim at taking into account also the situations where yourinitial beliefs P may have been specified only roughly, for instance for lack of time or other resources; in this case,the availability of additional time to define P B may well change much your future commitments from your currentconditional beliefs.10 Note moreover that despite the above reworking process may be made in time in an incrementalway through different stages, we only consider the final stage where you decide that the model P B is definitive andhence declare it (i.e., establish it). For it is only then that you will commit yourself to accept gambles, after B occurs,from RB . (We comment on this point and the previous one to some further extent in the concluding Section 8.)• Finally, we assume that you value gambles according to a linear utility scale throughout. This implies that the timewhen you accept some gamble does not affect its value for you. We need this assumption to be able to comparegambles accepted at different times, as in the following discussion.Letting time enter the picture of belief assessment raises a new kind of consistency problem about your commitmentsthat is not present otherwise: it may happen that despite both your present and future commitments are coherent whentaken on their own, they may lead to some form of inconsistency when considered together. For instance, even if each ofthe sets of gambles R and RB , respectively induced by P and P B , are coherent, this cannot prevent you from establishing8 In fact, we have to say that it is not entirely clear to us yet how much Shafer was actually discussing a temporal setting rather than the updatinginterpretation in his early works on the subject. For instance, in the third last paragraph in [55, p. 266], Shafer seems to support the updating interpretation,while in other parts of the paper he seems to be concerned with temporal questions.9 This is also related to the problem of observability within subjective probability. See [67, Sections 6.1 and 6.11] and [12,21] for some additional dis-cussion. Very briefly, the question is that conditioning is well defined under the updating interpretation, if the conditioning event is the outcome of anexperiment, and hence it belongs to a partition of Ω . Overlooking this subtlety may lead into troubles by neglecting the role of the process by which onemakes observations. All this is related to the condition of coarsening at random (see [8,20,55,71]).10 One could argue then that E(·|B) and P B should coincide when they are established together. Our choice is to leave you freedom also in this case tochoose P B as you wish, so as to make a treatment uniform with all the other cases; only later we shall discuss how rationality will require in this case toset P B equal to E(·|B) (as well as to make P conglomerable; see Section 4.4 and in particular Theorem 2(c)).12M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–51that for a certain f ∈ L(Ω), and ε0 > ε1 > 0, the gamble B( f − ε0) is desirable now and that after B occurs, the gambleB(ε1 − f ) becomes desirable; these assessments (considered also that B represents the event that occurs) imply that youare actually exposing yourself to the possibility of accepting the gamble f − ε0 + ε1 − f = ε1 − ε0 < 0, that is, to a sureloss. Note that you can undergo such a loss only by combining commitments related to different times: the reason is that,although at each time point you are coherent, at the moment we are missing some notion, or requirement, of consistencyof your commitments through time. The rest of this paper will be devoted to introduce and discuss some notions of timeconsistency.3.2. Basic toolsWe start introducing some basic tools, in terms of the sets of desirable gambles associated to your current and futurecommitments, that we need for the following mathematical development:• R is the coherent set of gambles induced by the coherent lower prevision P that represents your current beliefs bymeans of Eq. (4). For each B ∈ B, your beliefs conditional on B as induced by R are given by the set R|B determinedby Eq. (7).• RB is the set of desirable gambles that represents your future commitments in case B ∈ B obtains, and that is inducedby the lower prevision P B by means of Eq. (5).11The specification of future commitments can be more or less informative depending on the period when they are es-tablished. If they are established after B occurs, then there will be only a single set RB . But if you establish them beforeB occurs, then you will have to specify a lower prevision P B for every B ∈ B, given that at that time you will not knowwhich B is going to obtain; correspondingly, there will be a set RB for every B ∈ B.Let us analyse the latter case more in detail. Expressing all those sets commits you to accept any gamble in RB providedthat (and hence after) B occurs, and this for every B ∈ B. What we claim now is that this actually implies more: thatyou are committed to accept any gamble f such that B f belongs to RB for any B ∈ B. In fact, when the sets RB , B ∈ B,have been established, an opponent might offer you the following agreement: that he will give you gamble B fin case Boccurs, and this for all B ∈ B. By the very definition of the sets RB , B ∈ B, you will have to accept this agreement. But theagreement just says that you will accept B f after any B occurs, so that eventually you will be rewarded with f (ω) whateverω ∈ Ω will come true. It is important to realise that this kind of acceptance of f does not imply that you will be involvedin transactions made by infinitely many gambles: you will eventually accept the single gamble B f related to the only eventB that will obtain.These considerations lead us to define your future commitments in a way that everything that can happen in the future,and hence also all the agreements that you would accept, is properly represented. We can do this by a single set of gambles:F B :=(cid:4)(cid:2)=f ∈ L(Ω): B f ∈ RB ∪ {0} ∀B ∈ B(cid:8)f ∈ L(Ω): f =B g: B g ∈ RB ∪ {0}(cid:5)\ {0}(cid:11)\ {0}.(9)(10)B∈Bf to B is equal to zero, because in this way RB isIn Eqs. (9)–(10) we allow that for each set B ∈ B the restriction ofcorrectly included in F Bfor all B ∈ B. Saying this differently, letting each of these restrictions to possibly equal zero allowsus to represent also the agreements (you would accept) stating that you will be given a gamble from a certain RB in case Bhappens, and nothing otherwise. Finally, observe that we exclude the zero gamble from F B. This is harmless, just becauseit represents a trivial transaction, and at the same time it allows us to make F Bcomply with axiom D2.12 In fact, F Bsatisfies a much stronger property:Proposition 1. F Bis the conglomerable natural extension of(cid:12)B∈B RB .Proof. Let us show that F Bsatisfies D1–D5.h ∈ F B.D1. Consider h (cid:2) 0. Then for every B ∈ B, it holds that Bh (cid:2) 0, and as a consequence it belongs to RB ∪ {0}. Hence,11 Although Eq. (5) induces a set of desirable gambles from a conditional lower prevision P (·|B), nothing prevents us from applying it to P B , given thatP B formally acts like a conditional lower prevision—only its interpretation is different. Note also that to maintain a consistent notation here we denote theinduced set by RB rather than by R|B as in Eq. (5).12 A more subtle issue is that when we create gambles in a piece-wise way along the elements of a partition as in F B, we can give rise to unboundedgambles even if each set RB contains only bounded ones: for instance, consider a countable partition B with elements B1, B 2, . . . , Bk, . . . , and select thepositive constant gamble k in RBk for all k ∈ N. We rule out situations of this type by requiring in (9) that f belongs to L(Ω), which is a set made ofbounded gambles by definition. The reason is that currently the theories of coherent sets of desirable gambles, as well as of coherent lower previsions, aredeveloped only for the case of bounded gambles (with the notable exception of [63]). Such a choice is not restrictive for the subsequent analysis since wewere already assuming that beliefs be expressed only with reference to bounded gambles.M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–5113Fig. 2. We can represent the establishment of commitments through time by a tree. At the root there are present beliefs R. Later, depending on the eventthat occurs, a certain set RB represents the commitments, such as B g, that are effective since then. F Brepresents the totality of what can happen in thefuture, without assuming to know the specific event B that will occur.D2. We know that 0 /∈ F BD3. Consider h ∈ F Bby definition.and λ > 0. Then for every B ∈ B the gamble Bh belongs to RB ∪ {0}, whence λ(Bh) = B(λh) alsobelongs to RB ∪ {0} and as a consequence λh ∈ F B.(cid:11) ∈ F BD4. Consider h, hThis implies that h + his equal to zero, there must be some B ∈ B such that Bh (cid:10)= 0 and Bhcontradiction with the coherence of RB . Hence, h + h(cid:11) ∈ F B ∪ {0}. To see that h + h. Then for every B ∈ B it holds that Bh, Bh(cid:11) ∈ F B.(cid:11) (cid:10)= 0, assume ex-absurdo that h + h(cid:11) ∈ RB ∪ {0}, whence B(h + h(cid:11) ∈ RB ∪ {0}.(cid:11)) = Bh + Bh(cid:11) = 0. Since neither of these gambles(cid:11) = 0, a(cid:11) ∈ RB and Bh + Bh(cid:11) = −Bh. But then Bh, BhD5. Consider 0 (cid:10)= h ∈ L such that Bh ∈ F B ∪ {0} for all B ∈ B. Then it follows from Eq. (9) that Bh ∈ RB ∪ {0} for everyB ∈ B, whence h ∈ F B.On the other hand, any superset F ofB∈B RB satisfying D1–D5 should include any gamble f (cid:10)= 0 for which B f ∈RB ∪ {0} for every B ∈ B, because then B f ∈f ∈ F . We(cid:12)conclude that F BB∈B RB ∪ {0} for every B and applying D5 it follows thatB∈B RB satisfying D1–D5, i.e., its conglomerable natural extension. (cid:2)is the smallest superset of(cid:12)(cid:12)This result tells us in particular that F Bis conglomerable. But remember that we are still not assuming that, at a certainmoment in time, an infinite sum of desirable gambles is desirable to you: the commitments expressed by the sumB∈B B gwill become effective only after a certain B occurs, so that in the end you will only make the single transaction representedby B g.(cid:3)(cid:11)(cid:11)(cid:11)(cid:11)(cid:11), BAnother way to look at this is that the above infinite sum does not involve gambles representing commitments that youhold simultaneously, given that the different sets RB are exclusive: you will never hold commitments RBtogether within B. This can be seen also from Fig. 2. Therefore F BRBis not a set of commitments thatyou will hold at some point in time; it is rather a formal tool that we use to represent everything that can happen in thefuture based on the commitments that you have established (separately) relative to the occurrence of different events., for two different events BThe situation is different in the case of conditional beliefs. Consider a gamble g :=B∈B B g such that B g ∈ R|B for allB ∈ B, where R|B is induced from R by means of Eq. (7). Then for every B ∈ B, you are willing to accept B g now (and notB∈B B g: in fact, all the gambles B g belong toafter B occurs). But this does not mean that you are now willing to acceptR and hence express commitments that you hold altogether at the same point in time; and you are allowed to combineonly a finite number of them through the finitary axiom D4. As a consequence, an opponent may have you at most acceptis a finite subset of B. But this will not be able to represent gamble g in general.a gamble like gAs a consequence, R is not going to be closed with respect to D5 in general.B∈B(cid:11) B g B , where B(cid:11)(cid:11) :=(cid:3)(cid:3)(cid:3)(cid:11)We see then that the mechanisms that allow us to combine gambles through sums are very different in the case wherewe focus on a set of beliefs maintained at the same point in time (R) or on a set summarising sets of commitments relativeto different future events that will occur (F B). And it is particularly revealing in our view to see that the conglomerabilityof F Bis a feature that arises spontaneously without being imposed on the set. Note in particular that without using infinitesums in F Bwe would not be able to represent all the possible future scenarios: for instance, the scenario where you willaccept some B g (cid:10)= 0 after B occurs, and this for all B ∈ B, can be represented only through the infinite sumB∈B B gbecause by making it finite some elements B g (actually infinitely many of them) should equal zero. The set that arises ifwe use only finite sums is in fact different from F B, as the following corollary shows:(cid:3)Corollary 1. The natural extension of(cid:2)E B :=f ∈ L(Ω): f = h +(cid:12)B∈B RB is given byB g: B g ∈ RB ∪ {0}, h (cid:2) 0, B(cid:11) ⊆ B s.t. |B(cid:11)| < ∞\ {0}.(11)(cid:11)(cid:8)B∈B(cid:11)14M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–51Proof. It is enough to show that E Bthat any coherent superset ofProposition 1. On the other hand, given a gamble in (11), if we rewriteB∈B RB must include E Bis the smallest coherent superset of(cid:12)follows with a reasoning analogous to that used w.r.t. F Bis trivial, andin(cid:12)(cid:12)B∈B RB . ThatB∈B RB ⊆ E B(cid:8)(cid:8)h +B g =B(g + h) +B∈B(cid:11)B∈B(cid:11)(cid:8)BhB /∈B(cid:11)we see, through (10), that E B ⊆ F Bgambles from E Bcannot yield zero as 0 /∈ F B. (cid:2). Then the axioms D1–D4 are trivial to verify, considered in particular that sums ofObserve in particular that the natural extension E BOn the other hand, since in Section 4 we shall focus primarily on coherent lower previsions, we shall need also a way toaggregate the several models of future commitments directly through lower previsions. In this case we have a prevision P Bon L(B) for all B ∈ B. We summarise them by means of the functional P B given bysatisfies D1–D4 and not D5 in general.P B( f ) :=(cid:8)B P B ( f B ),B∈Bwhich mathematically acts as a separately coherent conditional lower prevision on L(Ω). However, since, strictly speaking,it is not a conditional lower prevision (which, by definition, represents current beliefs), we shall use for it the terminologyof separately coherent future lower prevision.Let us remark that although the sets R, F Bwill be used already in Section 4, as a way to easily convey a behaviouralinterpretation of the results we shall pursue, it is from Section 6 onwards that these sets will actually play a primary rolein the development, because we shall take them as our primitive models, not only as models derived from coherent lowerprevisions. This will allow us to establish results similar in spirit to the first part of the paper but in a much more generalway.4. Temporal consistencyRemember that we distinguish different time periods for the definition of your future commitments. In this section westart by focusing on the intermediate period, where you define them before B occurs, but also after having established yourcurrent beliefs. In this situation, the relevant models in terms of lower previsions are an unconditional lower prevision P onL(Ω) that represents your present beliefs, and the separately coherent future lower prevision P B on L(Ω) that summarisesyour future commitments.4.1. Temporal consistencyWe are ready to define our first notion of consistency across your current and future commitments. To this end, letbe the conglomerableR, RB (B ∈ B) be the sets of gambles associated to P , P B by means of Eqs. (4), (5) and let F Bnatural extension of(cid:12)B∈B RB .Theorem 1. The following statements are equivalent:avoids partial loss.(a) R ∪ F B(b) P , P B avoid sure loss.(c) P ( f − P B( f )) (cid:2) 0 for every f ∈ L.(d) P B( f ) (cid:2) 0 ⇒ P ( f ) (cid:2) 0 for every f ∈ L.(e) P ( f ) (cid:2) inf P B( f ) for every f ∈ L.Proof. Let us make a circular proof.(a) ⇒ (b) Assume ex-absurdo that P , P B do not avoid sure loss. Then from ASL we deduce that there are gambles f , g suchthat sup[G( f ) + GB(g)] < 0, whence there is some δ > 0 such that sup[G( f ) + GB(g) + δ] < 0. SinceG( f ) + δ2= f −(cid:13)(cid:14)P ( f ) − δ2(cid:13)(cid:13)∈ R and(cid:14)(cid:14)G B (g B ) + Bδ2= Bg −P B (g) − δ2∈ RB ∀B ∈ B ⇒ GB(g) + δ2∈ F B,we deduce that the gamble G( f ) + GB(g) + δ belongs to the natural extension of R ∪ F B(because the natural ex-tension is closed w.r.t. sums of gambles). But since such a gamble is negative, we deduce that the natural extension isincoherent, a contradiction with (a). As a consequence, P , P B avoid sure loss.M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–5115(b) ⇒ (c) This follows from [67, Theorem 6.3.5].(c) ⇒ (d) Because if P B( f ) (cid:2) 0 then P ( f ) (cid:2) P ( f − P B( f )) (cid:2) 0.(d) ⇒ (e) Taking into account that, since P is a coherent lower prevision, P ( f − inf P B( f )) = P ( f ) − inf P B( f ), and P B( f −inf P B( f )) (cid:2) 0 because P B is separately coherent.(e) ⇒ (a) Use Remark 1, and assume there are gambles f ∈ R, g ∈ F Bbecausein that case we would have g (cid:3) 0, a contradiction with the coherence of F Bimplies that P B(g) (cid:2) 0,whence, applying (e), P (g) (cid:2) 0. Using the conjugacy between upper and lower previsions, together with f (cid:3) −g, wededuce that P (−g) (cid:3) 0, and the monotonicity of P implies then that P ( f ) (cid:3) 0. But since f /∈ L+, we deduce fromEq. (4) that f cannot belong to the set of gambles R, a contradiction. Hence, R ∪ F Bavoids partial loss. (cid:2)such that f + g (cid:3) 0. Note that f /∈ L+. Then g ∈ F BThis result generalises [67, Theorem 6.3.5(1) and (3)], where the implications (b) ⇒ (e) and (b) ⇒ (c) were obtained.13From it, we establish the following:Definition 13 (Temporal consistency). We say that your current and future commitments P , P B are temporally consistent whenany of the equivalent conditions of Theorem 1 holds.The rationale behind this definition should be clear: if you failed temporal consistency, an opponent could create acombination of current and future transactions that will have the overall effect of making you desire, and then accept, agamble that is strictly smaller than 0. For example, assume that there are gambles f and g such that ASL fails, becausethere is some δ > 0 such that(cid:9)(cid:10)G( f ) + GB(g)sup(cid:3) −δ < 0.Then the definition of P means that you should be disposed to buy the gamble f for the price P ( f ) − δthat you should accept the gamble G( f ) + δg at the price P B (g) − δmatter which is the B you observe, you should accept the gamble G( f ) + GB(g) + 2δδ3 irrespective of the actual B that will occur. This is an inconsistency.3 , or, equivalently,3 ; on the other hand, for any B ∈ B, you should be disposed to buy the gamble3 ). But this means that no3 , which will produce a loss of at least3 after observing B, or equivalently, to accept the gamble B(g − P B (g) + δExample 7 (Running example). Consider again the situation depicted in Example 1: take the variables V := ‘virus type’(seasonal, atypical) and T := ‘test result’ (positive, negative). Assume you model your current beliefs about the two vari-ables by means of the coherent lower prevision P from Example 4, and that, at some later time, but before you know theresults of the test, you set your future commitments equal to the separately coherent conditional lower prevision P (V |T )from Example 2. Since we have showed in Example 6 that these two lower previsions avoid sure loss, we conclude thatyour assessments are temporally consistent: they cannot be exploited together in order to make you subject to a sure loss.This is easy to see if we consider their associated sets of gambles by means of Eqs. (4) and (5): we have that(cid:5)f (a, n), f (a, p)(cid:4)f : f (s, n) > 0, f (s, p) > 0 and 0.95 min(cid:5)f (s, n), f (s, p)(cid:4)+ 0.05 minR := L+ ∪> 0(cid:4)(cid:5),and(cid:2)(cid:13)RB :=f : f (a, n) = f (s, n) = 0 and(cid:2)f (a, p) > max(cid:13)RBc :=f : f (a, p) = f (s, p) = 0 andf (s, n) > max(cid:2)(cid:11)(cid:14)(cid:11)0, − f (s, p)(cid:2)30, − f (a, n)4or f (a, p) = 0 < f (s, p)(cid:11),(cid:14)(cid:11)or f (s, n) = 0 < f (a, n),where we are using B to denote the event T = p.Then note that if the sum of a gamble fmust be f (s, n) = g(s, n) = 0, from which f ∈ L+in R with a gamble g ∈ F Band therefore g (cid:3) 0, a contradiction. Hence, R ∪ F Bavoids partial loss.were negative or zero, we would deduce that itTheorem 1 also allows us to relate the conditional beliefs we can derive from your set of current beliefs and your futurecommitments. Let R|B be the set of conditional beliefs derived from R by means of Eq. (7), and let E(·|B) be its associatedlower prevision (the conditional natural extension of P , from Lemma 1), given by Eq. (6). Since RB ⊆ F B, then we candeduce from Theorem 1 thatE( f |B) (cid:3) P B ( f B ) ∀ f ∈ L(Ω).(12)13 But note that Walley was not concerned with temporal considerations as we are; his results deal with a pair of unconditional and conditional lowerprevisions that are both established at present time. Therefore the aims and the interpretation of the results in the two cases are very different.16M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–51Indeed, if (12) does not hold, then you are willing now to pay E( f |B) − δ/2, for any δ > 0, to get f under the assumptionf at price P B ( f B ) + δ/2; the result of these twothat B happens, while after B actually happens, you are willing to selltransactions is B( f − E( f |B) + δ/2) − B f + P B ( f B ) + δ/2 = P B ( f B ) − E( f |B) + δ, which is negative provided that we chooseδ < E( f |B) − P B ( f B ).We can use Theorem 1 also to see, intuitively, that you do not need to modify your current beliefs in order to achievetemporal consistency: given any set of current beliefs, you can create temporally consistent future commitments. This is animportant feature of temporal consistency, because it means that you can use it also after having established (and hencehaving ‘fixed’) the present beliefs. The next remark makes the point more precisely.B (cid:3) P B, then if P , P B satisfyRemark 2. If your commitments become more imprecise, in the sense that P 1temporal consistency then so do P 1, P 1B. A related comment is made in [67, Proposition 2.6.3(a)]. Furthermore, temporallyconsistent models always exist (for instance the vacuous ones); and we can always find a future model that satisfies tem-poral consistency with respect to your current beliefs by making it imprecise enough: if we take the vacuous P B, then it istemporally consistent with any initial coherent lower prevision P . This shows on the one hand that temporal consistency isweaker than conglomerability: even if we start with a conglomerable, precise prevision, a conditional lower prevision thatis temporally consistent with it is not necessarily precise. On the other hand, even if there are coherent lower previsionsthat are not conglomerable, they are always temporally consistent with respect to the vacuous P B. We shall come back tothe connection with conglomerability in Section 4.4.(cid:3) P and P 14.1.1. Correcting temporal inconsistencyAn interesting side problem is to determine whether you can modify your (not yet established) commitments whentemporal consistency is not satisfied, so as to obtain a temporally consistent model and with a correction that is as small aspossible. In other words, we would like to define an analogue of the notion of natural extension for temporally consistentmodels, in the sense of being the closest model that satisfies temporal consistency. Since we have already remarked that amodel that is included in a temporally consistent model satisfies again temporal consistency, the correction should be doneby making the model more imprecise. That is, you should define the temporally consistent extension as the greatest (thatis, more informative) model that is temporally consistent and is included in your assessments.If your current and future commitments are temporally inconsistent, it follows from the definition of avoiding sureloss that there is no linear prevision P satisfying P (G( f )) (cid:2) 0 and P (GB( f )) (cid:2) 0 for every gamble f . This means that ifwe consider the credal sets M1 := {P : P (G( f )) (cid:2) 0 ∀ f } and M2 := {P : P (GB( f )) (cid:2) 0 ∀ f }, their intersection is empty.Equivalently, this means that the lower prevision Q := max{P 1, P 2}, where P 1, P 2 are the lower previsions associated toM1, M2, incurs a sure loss. Therefore, one possibility for correcting your inconsistent assessments would be to find the‘closest’ lower prevision that is dominated by Q and avoids sure loss (so that it is associated to a non-empty credal set).However, such a prevision does not exist in general, as we proceed to show:Proposition 2. Let P be a coherent lower prevision incurring sure loss. Then there is no greatest lower prevision that avoids sure lossand is dominated by P .Proof. First of all, we can assume without loss of generality that P ( f ) ∈ [inf f , sup f ] for every f : otherwise, it suffices toconsider the lower prevision Pgiven by(cid:11)(cid:11)P( f ) :=⎧⎨⎩inf fsup fP ( f )if P ( f ) < inf f ,if P ( f ) > sup f ,otherwise.(cid:11)(cid:11)(cid:11))), byThen for any credal set M we can consider the lower previsions P 1means of which we can make a correspondence between the lower previsions that are dominated by P and avoid sure lossand those that are dominated by Pand avoid sure loss. Hence, if we show that there is not a greatest lower prevision thatand avoids sure loss, we shall immediately deduce that there is not a greatest lower prevision that isis dominated by Pdominated by P and avoids sure loss either.:= inf(M ∪ M(P )) and P 2:= inf(M ∪ M(PAssume now that there is a lower prevision Q (cid:3) P that avoids sure loss and such that for any other lower prevision(cid:11) (cid:3) Q . Since Q avoids sure loss and P does not, there must be some gamble(cid:11) (cid:3) P that avoids sure loss it holds that QQf such that Q ( f ) < P ( f ). Let P be a linear prevision satisfying P ( f ) = P ( f ) (such a prevision always exists because(cid:11) (cid:3) P .inf f (cid:3) P ( f ) (cid:3) sup f ), and let us define QHowever, Qis not dominated by Q . This is a contradiction. (cid:2)(cid:11) := min{P , P }. Then P ∈ M(Q(cid:11)(cid:11)( f ) = P ( f ) > Q ( f ), and as a consequence Qavoids sure loss, and moreover Q(cid:11)), so Q(cid:11)Hence, it is not possible to find the closest temporally consistent model to some temporally inconsistent assessments;interestingly, it may be possible to do so if you fix your current beliefs P and look for the greatest model of future com-mitments that is dominated by P B and is temporally consistent with P . This is easier to establish if we work with sets ofdesirable gambles, as we shall see in Section 6.1.M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–51174.2. Strong temporal consistencyTemporal consistency means that it should not be possible to combine your current and future commitments in orderto make you subject to a sure loss, but it does not impose any actual restriction on how these future commitments shouldbe defined. When we require that they are determined by your current beliefs, we obtain a strengthening of temporalconsistency that we shall call strong temporal consistency:Definition 14 (Strong temporal consistency). We say that a coherent lower prevision P and a separately coherent future lowerprevision P B are strongly temporally consistent when they are temporally consistent and moreover P B coincides with theconditional natural extension E(·|B) of P , given by Eq. (3).Taking into account the comments about temporal consistency in Section 4.1, the behavioural interpretation of thiscondition is that one should not be able to exploit your current and future commitments in order to make you subject toa sure loss, when moreover your future commitments are determined by your current ones by means of natural extension.This shall be clearer when we discuss the definition of strong temporal consistency in terms of sets of gambles in Section 6.2.We begin by noting that strong temporal consistency is related to the property of conglomerability, in the sense that ifyou set your future commitments equal to present conditional beliefs, then strong temporal consistency holds automaticallyif P is conglomerable.Proposition 3. Let P be a coherent lower prevision and let E(·|B) denote its conditional natural extension. Then each of the followingstatements implies the next:(a) P is conglomerable.(b) P , E(·|B) have dominating coherent lower previsions Q , Q (·|B).(c) P , E(·|B) are temporally consistent.Proof.(a) ⇒ (b) If P is conglomerable then it is coherent with its conditional natural extension E(·|B), so the thesis holds trivially.(b) ⇒ (c) If Q (cid:2) P and Q (·|B) (cid:2) E(·|B), and Q , Q (·|B) are coherent, then Q is conglomerable, whence it is coherent withits conditional natural extension, which must also dominate E(·|B) because Q (cid:2) P . Taking into account Remark 2,we deduce that P , E(·|B) are temporally consistent. (cid:2)On the other hand, we may note then that if the coherent lower prevision P that represents your current beliefs doesnot satisfy temporal consistency with its conditional natural extension E(·|B), neither does any dominating coherent lowerprevision Q (cid:2) P : for if there are gambles f , g such that(cid:9)(cid:10)f − P ( f ) + g − E(g|B)sup< 0,then we also have(cid:9)(cid:10)f − Q ( f ) + g − Q (g|B)sup< 0,taking into account that the conditional natural extension Q (·|B) of Q dominates that of P . This shows that failure ofstrong temporal consistency cannot be corrected by making your assessments more precise.Example 8 (Running example). If in our running example we make your future commitments equal to the ones derivedfrom P by means of natural extension, we obtain the vacuous conditional lower prevision E(V |T ) from Example 5. Sinceits associated set of gambles is F |B = L+, it trivially avoids partial loss with the set R induced by P . Hence, P , E(V |T ) arestrongly temporally consistent. This could be deduced immediately from Proposition 3: since the partition {T = p, T = n} isfinite, the coherent lower prevision P is trivially conglomerable, and therefore it is temporally consistent with its conditionalnatural extension.One particular case where P always avoids sure loss with its conditional natural extension is when you build it by meansof the marginal extension. This is a generalisation of the law of total probability for the imprecise case that is useful in acontext of hierarchical information. Consider a separately coherent conditional lower prevision P (·|B) on L, and let P bea coherent lower prevision defined on the set K ⊆ L of B-measurable gambles. Then the marginal extension of P , P (·|B):= P (P (·|B)), and it can be checked [67, Theorem 6.7.2] that this lower prevision isis the lower prevision given by P 1coherent with P (·|B).Proposition 4. Under the above conditions, the marginal extension P 1 of P , P (·|B) is temporally consistent with its conditional naturalextension.18M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–51Proof. The result follows from Proposition 3 once we show that the conditional natural extension E(·|B) of P 1 is dominatedby P (·|B). Given B ∈ B, if P 1(B) = 0 then E(·|B) is vacuous and is trivially dominated by P (·|B); and if P 1(B) > 0 thenE(·|B) is uniquely determined from P 1 using GBR , and as a consequence it must coincide with P (·|B), because P 1, P (·|B)are coherent. (cid:2)On the other hand, the equality E(·|B) = P B between the conditional natural extension of P and the separately coherentfuture lower prevision is made up of two inequalities: E(·|B) (cid:3) P B and E(·|B) (cid:2) P B. The first of these inequalities meansthat your future commitments should take into account (i.e., be at least as precise as) the implications of the current beliefsby conditional natural extension. This suggests that strong temporal consistency can naturally be turned into a weakerconsistency notion based on such an inclusion.Definition 15 (Strong backward temporal consistency). We say that your current and future commitments are strongly backwardtemporally consistent if they are temporally consistent and E(·|B) (cid:3) P B.The inequality E(·|B) (cid:3) P B is related to a proposal that Walley did in [67, Section 6.1.2].14 The rationale, paraphrasinghis words, is that your conditional assessments E(·|B) should be ‘reliable’, in the sense that when you establish them, youshould inspect all the evidence carefully; if you do so, when you later come to know B, you might do some extra effortand make your assessments more precise, but there should be no possibility that you change your mind so as to make yourassessments become more imprecise. It is interesting then to see that Walley’s proposal can be thought of as a consistencyrequirement of current commitments onto future ones. We can see thus strong temporal consistency as a limit case ofstrong backwards temporal consistency: it would be the least-committal (i.e., the most imprecise) model for which strongbackward temporal consistency is satisfied.But note that strong backward temporal consistency is stronger than Walley’s proposal because we are requiring inaddition that P , P B avoid sure loss, and this does not follow from the inequality E(·|B) (cid:3) P B and the fact that P , E(·|B)avoid sure loss: use [67, Example 6.6.10] for an example of a linear prevision P whose conditional natural extension isvacuous (and which therefore trivially satisfies temporal consistency) but that is temporally inconsistent with any precisefuture commitments.4.3. Event-wise (strong) temporal consistencyIn the previous sections we have focused on a setup where future commitments are established after present beliefs andbefore event B occurs. Now we move on to consider the simplest case to characterise, that where future commitments areestablished after the occurrence of B.In this situation, having got to know exactly which element in the partition B has obtained, you will obviously focus onthe lower prevision P B associated to that B, which is defined on L(B), or, equivalently, on the subset of L(Ω) given bythose gambles that are zero outside B. Characterising consistency is then very similar to what we have already done before,with the additional requirement to focus on the only set B that is available.Proposition 5. Let P be the coherent lower prevision modelling your current beliefs and let P B be your coherent lower previsionon L(B), or equivalently on K := { f ∈ L(Ω): f = B f }, that models your beliefs after knowing that B occurs. Let R, RB be theirassociated sets of gambles by Eqs. (4) and (5). Then the following are equivalent:(a) The lower prevision P 1 given by(cid:2)P 1( f ) :=max{P ( f ), P B ( f )}P ( f )if f ∈ K,otherwise,avoids sure loss.(b) R ∪ RB avoids partial loss.(c) E( f |B) (cid:3) P B ( f ) for every f ∈ K, where E(·|B) denotes the conditional natural extension of P .Proof.(a) ⇒ (b) Since both R, RB are convex cones of gambles, we can deduce from Remark 1 that R ∪ RB incurs partial loss ifand only if there are gambles f ∈ R, g ∈ RB such that f + g (cid:3) 0. We can assume without loss of generality thatnone of these gambles is positive, or we would contradict the coherence of either R or RB . As a consequence, itmust be P ( f ) > 0 and P B (g) > 0, whence14 A notion related to strong backwards temporal consistency can be found in [26]; there are, however, a few differences with our framework: the authorsof [26] consider only the observation of an event, instead of a partition; they also consider a non-linear utility function, whereas we assume your utilityscale is linear; and their basic model is not established in terms of lower and upper previsions.M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–5119(cid:9)(cid:10)f − P 1( f ) + g − P 1(g)sup< sup[ f + g] (cid:3) 0,which implies that P 1 incurs sure loss, a contradiction.2(b) ⇒ (a) Assume ex-absurdo that there are two gambles f , g such that sup[ f − P 1( f ) + g − P 1(g)] < 0; then there is someδ > 0 such that f − P 1( f ) + g − P 1(g) + δ < 0. Since both P and P B are coherent on their respective domains,we can assume without loss of generality that f ∈ K and P 1( f ) = P B ( f ) and that P 1(g) = P (g). Hence, givenf 1 := f − P 1( f ) + B δ=2 > 0, whence g1 ∈ R. But then f 1 + g1 belongs to the natural extension ofg − P (g) + δR ∪ RB and it is smaller than or equal to 0. Hence, R ∪ RB incurs partial loss, a contradiction.2 , whence f 1 ∈ RB . Similarly, given g1 := g − P 1(g) + δ∈ K, it holds that P B ( f 1) = δ2 , it holds that P (g1) = δ(b) ⇒ (c) Assume ex-absurdo that there is a gamble f ∈ K such that E( f |B) > P B ( f ). Then from Lemma 1 there is some2 ) belongs to RB , we would deduce that −B δδ > 0 such that B( f − P B ( f ) − δ) ∈ R; since B(P B ( f ) − f + δbelongs to the natural extension of R ∪ RB , a contradiction.(c) ⇒ (b) If R ∪ RB incurs partial loss, then there are gambles f ∈ R, g ∈ RB such that f + g (cid:3) 0. Since Bc g = 0, it followsthat Bc f (cid:3) 0. Thus, B f = f − Bc f ∈ R. Since g cannot be positive because this would contradict the coherenceof R, we deduce that P B (g) > 0, from which we have the following contradiction:220 (cid:2) P B (B f + g) (cid:2) P B (B f ) + P B (g) (cid:2) E( f |B) + P B (g) > 0.Here the first inequality follows from f + g (cid:3) 0 and the monotonicity of coherent upper previsions, the secondone follows from the coherence of P B and the third one from (c). (cid:2)Definition 16 (Event-wise temporal consistency). We say that your present and future commitments are event-wise temporallyconsistent when any of the equivalent conditions in Proposition 5 holds.Hence, by event-wise temporal consistency you establish your future commitments after observing which element B ofthe partition happens, while making sure that your present and future commitments cannot be exploited in order to makeyou subject to a sure loss.15 As a consequence of Theorem 1 and Proposition 5, if your current and future commitmentsare temporally consistent, then they are also event-wise temporally consistent for every B ∈ B. The converse does not holdin general: if your future commitments coincide with the conditional natural extension E(·|B) of P , then we always haveevent-wise temporal consistency for every B ∈ B, but not necessarily temporal consistency. An explicit case is shown inExample 11 later on.A consequence of the above proposition is that inequality (12), which we derived from temporal consistency, is actuallyequivalent to event-wise temporal consistency. This shows that violations of event-wise temporal consistency should bevery rare if only present beliefs were assessed using some minimal care.Example 9 (Running example). Consider again the unconditional lower prevision P that represents your current beliefs, andassume that you postpone the assessment of your future commitments until the test has been made, and that this turnsout to be positive. Then temporal consistency should only be verified by means of P , P (V |T = p), since it makes no senseanymore to take into account the assessments in P (V |T = n). Since we already showed in Example 7 that P , P (V |T ) aretemporally consistent, and therefore R ∪ F Bavoids partial loss, so does its subset R ∪ RB , where B denotes the eventT = p. Hence, we also have event-wise temporal consistency.We can extend the similarity to temporal consistency further up to strong temporal consistency, in an obvious way:Definition 17 (Event-wise strong temporal consistency). We say that your present and future commitments are event-wisestrongly temporally consistent if P B= E(·|B).The underlying idea is, as usual, that you set future commitments equal to conditional beliefs. The additional requirementthat conditional beliefs and future commitments jointly avoid sure loss is automatically satisfied in the present case, takinginto account Proposition 5.The (event-wise) consistencies we have introduced in this section are the weakest in this paper. This is due to thelimited availability of information about your future commitments. On the other hand, note that the other notions, suchas (strong) temporal consistency, are not only a separate replication of event-wise temporal consistency for all the possibleevents B ∈ B: they also consider the joint effect on your current beliefs of future commitments related to different events Bthrough the inborn conglomerability of set F Binduced by P B. This is the key to the increased consistency power of thosenotions that can rely on F B.15 One might want to consider modifying the definition in the following way: given that future commitments are established after B occurs, at that timeyou might know exactly which subset R(cid:11)of the desirable gambles R associated to P have been offered to you, and hence accepted, in that first stage (seealso Section 3.1); then it might make sense to consider a (weaker) definition of temporal consistency that involves (the natural extension of) R(cid:11)ratherthan R. The essence of the rationale behind the definition would not change, however, nor would the technical development change in any substantialway.20M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–514.4. Temporal coherenceWe finally focus on the case where you define your future commitments now, at the same time of your present beliefs.The peculiar feature of this case is that the assessments of present and future commitments can influence each other (thisshould be contrasted with strong temporal consistency, for instance, where it is only possible that future commitmentsare affected by present beliefs, which are established in advance and cannot be modified during the assessment of futurecommitments). This allows us to give much more stringent conditions than it was possible before, and actually allows usalso to establish them as rationality requirements.The first condition that becomes immediately tenable as a rationality requirement is that future commitments coincidewith the conditional beliefs derived from P , which, from Lemma 1, are given by(cid:5)(cid:4)(cid:5)E( f |B) = supμ: B( f − μ) ∈ R= sup(cid:4)μ: B( f − μ) ∈ R|B,where R is the set of gambles induced by P through (4) and R|B is derived from R by means of (7). The lower previsionE(·|B) represents your beliefs now under the assumption that B occurs. Given that by assumption you are also establishingnow the model P B , this should just lead you to make P B equal to E(·|B). For this reason, we stick to the equality P B =E(·|B) in this section.16 This is also equivalent to the equality F B = F |B, where(cid:4)F |B :=f ∈ L: B f ∈ R|B ∪ {0} ∀B ∈ B(cid:5)denotes the conglomerable natural extension of\ {0}(cid:12)B∈B R|B . Note that F B = F |Bif and only if RB = R|B for all B ∈ B.Proposition 6. Let P , P B be a coherent lower prevision and a separately coherent future lower prevision on L that represent yourcurrent and future commitments, respectively. Let R, RB (B ∈ B) be the sets of desirable gambles they induce by means of Eqs. (4)and (5), and let F BB∈B RB . On the other hand, let R|B be the set of conditional gamblesinduced by R by means of (7), let F |BB∈B R|B and let E(·|B) be the conditional lowerprevision induced by F |Bbe the conglomerable natural extension ofbe the conglomerable natural extension of. Then(cid:12)(cid:12)F B = F |B ⇔ P B = E(·|B).Proof. Since F Bshow that R|B = RB . Recall thatinduces P B, the direct implication is trivial, so it suffices to prove the converse one. Fix B ∈ B, and let us(cid:4)RB =f : f = B f , f (cid:2) 0 or P B ( f B ) > 0(cid:5)andR|B = { f : f = B f , B f ∈ R} =(cid:4)f : f = B f , f (cid:2) 0 or P (B f ) > 0(cid:5).We skip the trivial case f (cid:2) 0. Let us show that in the remaining case it holds that E( f |B) > 0 if and only if P (B f ) > 0,from which the thesis follows immediately. E( f |B) > 0 implies that there is δ > 0 s.t. B( f − δ) ∈ R. This means thatP (B( f − δ)) > 0, taking into account that we have excluded the case B f (cid:2) 0, whence P (B f ) > 0. Conversely, P (B f ) > 0implies that there is δ > 0 s.t. P (B f − δ) > 0, whence P (B( f − δ)) > 0. This means that B( f − δ) ∈ R or, in other words,that E( f |B) > 0. (cid:2)The next condition that does appear tenable too as a rationality requirement is that also your current and future com-mitments cohere. If this were not the case, then some of the beliefs you are expressing at the same point in time (now)would clash with each other. As we mentioned in Section 2, P and E(·|B) need not be coherent, because they need notsatisfy CNG. The next theorem gives insights on this important question.Theorem 2. Let P be a coherent lower prevision on L representing your current beliefs, and E(·|B) be its conditional natural extension.Let R be the set of gambles associated to P , and F |BB∈B R|B . Then the following areequivalent:the conglomerable natural extension of(cid:12)is coherent.(a) R ∪ F |B(b) P , E(·|B) are coherent.(c) R is conglomerable.16 When discussing these questions in the more general framework of desirability in Section 6.4, we shall see that the equality of future commitments toconditional beliefs formally follows from a coherence condition.M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–5121Proof. The equivalence of (b) and (c) follows from [43, Theorem 3] and the definition of conglomerability. We proceed toprove the equivalence of (a) and (b).(a) ⇒ (b) Assume that R ∪ F |Bis coherent, and let us show that in that caseP ( f ) (cid:2) 0 ∀ f ∈ F |B.(13), [43, Proposition 10] implies that R = F |B = L+then we can consider a gamble g ∈ R \ F |B, and therefore (13). This means that P (g) (cid:2) 0 andThere are two possibilities: if R ⊆ F |Bholds. On the other hand, if R (cid:4) F |Bmoreover that there is some B ∈ B such that B g /∈ R|B ∪ {0}.Assume ex-absurdo that (13) does not hold, and take f ∈ F |BR|Bcontradiction. As a consequence, f 1 ∈ F |B(cid:11) ∪ {0} for every B, and therefore λ f 1 ∈ F |BP ( f 1) = P ( f − B f ) (cid:3) P ( f ) + P (−B f ) = P ( f ) − P (B f ) < 0,f 1 ∈(cid:11) ∈ B, and moreover it cannot be f 1 = 0 or we should have f = B f ∈ R and P ( f ) (cid:2) 0, asuch that P ( f ) < 0. Define f 1 := Bc f . Then B(cid:11)for all λ > 0. Moreover,because P ( f ) < 0 and P (B f ) (cid:2) 0 taking into account that B f ∈ R|B ∪ {0}. Define h := λ f 1 + g; h belongs to thenatural extension of R ∪ F |B. Then it holds thatBh = B(λ f 1 + g) = B g /∈ R|B ∪ {0} ⇒ h /∈ F |B,andP (h) = P (λ f 1 + g) (cid:3) P (λ f 1) + P (g) = λP ( f 1) + P (g) < 0 for λ > − P (g)P ( f 1).Hence, for λ big enough P (h) < 0, whence h does not belong to R either. As a consequence, R ∪ F |Bfrom its natural extension and therefore it is not a coherent set, a contradiction.We conclude that Eq. (13) holds, and applying now [43, Theorem 2], we deduce that F |B ⊆ R. Hence, R is con-glomerable, and since the second and the third statements are equivalent we deduce that P , E(·|B) are coherent.such thatf + g /∈ R ∪ F |B; since this gamble does not belong to R, we deduce that P ( f + g) (cid:3) 0. We can assume withoutloss of generality that neither of these gambles is positive, or we should contradict the coherence of either R orF |Bimplies that E(g|B) (cid:2) 0, whenceg (cid:2) g − E(g|B). As a consequence,f ∈ R implies that P ( f ) > 0. On the other hand, g ∈ F |Bis not coherent. Then there are gambles f ∈ R, g ∈ F |B. From Eq. (4),is different0 (cid:2) P ( f + g) (cid:2) P ( f ) + P (g) ⇒ 0 > −P ( f ) (cid:2) P (g) (cid:2) Pwhence P , E(·|B) do not satisfy CNG and therefore are not coherent. (cid:2)(cid:6)(cid:7)g − E(g|B),(b) ⇒ (a) Conversely, assume ex-absurdo that R ∪ F |BIn the light of Proposition 6, we see that Theorem 2 yields a truly bright outcome: that, provided that F B = F |B,the coherence of the union of your sets of current and future commitments is equivalent to the conglomerability of Ror, equivalently, to the conglomerability of P . It is striking in particular that a very simple, natural, and especially finitaryrequirement such as the coherence of R ∪ F |B, which is also the straightforward way to strengthen strong temporal con-sistency, eventually shows itself to coincide with F |B ⊆ R. We remark that the use of Walley’s results in the proof of thistheorem is necessary for the equivalence between the second and the third items, but not for the equivalence with the firstitem, which is the main finding of the theorem, and which allows us to justify conglomerability in a finitary way: in ourknowledge, this is achieved here for the first time.This gives rise to the following rationality condition:Definition 18 (Temporal coherence). Let P , P B be the coherent lower previsions representing your current and future com-mitments. We say that they are temporally coherent when P B coincides with the conditional natural extension of P andwhen moreover any of the conditions in Theorem 2 holds.The conglomerability of an imprecise probability model does not imply that the model is equivalent to a set of conglom-erable precise models; an example can be found in [67, Section 6.6.9]. This means, in particular, that even when it is rationalfor you to hold conglomerable beliefs, it is not necessary that your imprecise probability model be made up of countablyadditive linear previsions. On the other hand, when your beliefs are precise, then our results entail a tight connection ofyour model with disintegrability. This will be discussed in Section 4.5.Example 10 (Running example). In the situation of our running example, since the partition {T = p, T = n} is finite, thecoherent lower prevision P representing your current beliefs is trivially conglomerable, and as a consequence it is coherentwith its conditional natural extension E(V |T ), which tells how you should assess your future commitments if you establishthem at the time of your present beliefs, and hence have no time to refine the assessment P . We conclude that P , E(V |T )are temporally coherent.22M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–514.5. The precise caseIn this section we discuss the important special case where your present and future commitments are precise. Hence,we focus on the case where your present beliefs are specified via a linear prevision P on L, and we assume that also yourfuture commitments for any B ∈ B are given by a linear prevision, which we denote by P B and that is defined on L(B).From these we induce the future linear prevision P B given, for any f ∈ L, by P B( f ) :=(cid:3)B B P B ( f B ).We start by focusing on temporal consistency:Corollary 2. Let P and P B represent your present and future commitments, respectively. Then temporal consistency holds if and only ifP ( f ) = P(cid:6)(cid:7)P B( f )∀ f ∈ L.17(14)Proof. This is an immediate consequence of Theorem 1. (cid:2)If P (B) > 0, then it is a consequence of coherence [67, Section 6.4.1] that the conditional natural extension on B isprecise and is given by Bayes’ rule:E( f |B) = P (B f )P (B).Moreover, we see from Eq. (12) that temporal consistency implies thatP B ( f ) (cid:3) E( f |B) (cid:3) P B ( f )andE( f |B) (cid:3) P B ( f ) (cid:3) E( f |B) ∀ f ∈ L.This means that when unconditional beliefs as well as future commitments are precise, we obtain the interesting additionalresult that P B ( f ) = P ( f |B), and as a consequenceP (B) > 0 ⇒ P B ( f ) = P (B f )P (B)∀ f ∈ L.(15)Loosely speaking, we can rephrase this by saying that for a Bayesian who wants to be consistent in time, there is onlyone way to compute future commitments: Bayes’ rule (but remember we are under the constraint of the positivity ofprobabilities). It is useful to notice that this result, which we have obtained from temporal consistency, actually follows fromevent-wise temporal consistency. This shows that (15) follows under the weakest consistency notion we have introduced inthis paper, and that in the precise case our notion of temporal consistency gives rise to conditional reasoning.18This is not the only thing that we can say when your current and future commitments are precise. A key observationis that in such a setting the notions of avoiding sure loss and coherence are equivalent: taking into account Theorem 2,this points to a relationship between temporal consistency and conglomerability. Such a relationship was sensed already byWalley. This is relatively clear in [67, Example 6.8.5], where Walley argues that there may be a (temporal) sure loss whenconditional beliefs are used as future commitments.19 A similar point was made also in an analogous example by Seidenfeld[51, Section 2.2], who used it to argue that Goldstein’s proposal of generalising de Finetti’s ideas to a temporal setting, thatwe shall detail in Section 7.3, was incompatible with Bayes’ rule when beliefs are modelled by a finitely additive probability.Below we report Walley’s example in our language for completeness:20Example 11. Let B := {{n, −n}: n ∈ N}, Θ := {+, −}, and Ω := Θ × B. Ω represents the set of non-zero integers: to seethis, identify the integer n with the pair (sign(n), |n|). B ∈ B represents the observation of a certain absolute value, whileΘ represents a hypothesis about the sign of an integer. Your current beliefs are represented by a probability P defined as−n, P ({−n}|{−}) := 0, and P ({+}) := P ({−}) := 1/2. It turns out that for all B ∈ B, itfollows: for all n ∈ N, P ({n}|{+}) := 2holds that P (B) > 0 and P ({+}|B) = 1, so that also P ({+}|B) = 1.Now, consistently with (15), assume that you use Bayes’ rule to define your future commitments on Θ : P B := E(·|B). It(cid:10)= 1 = P (P B({+})), which contradicts (14). And in fact, this would allow an opponent to buy eventfollows that P ({+}) = 1217 Note how this formula resembles very closely Goldstein’s formalisation of his notion of temporal coherence in [21]. See Section 7.3 for details.18 Other justifications of Bayesian updating as a temporal rule can be found in [26,44,56,69]. See also Section 7.19 But Walley was not fully explicit in claiming that conditional beliefs would be taken as the definition of future commitments (more generally speaking,he seldom talks of future commitments in his book). Overlooking this subtlety can make Walley’s argumentation easily misunderstood: in fact, if one takesthose as conditional (non-future) commitments, then there is no loss, as instead the example is supposed to show.20 This example is a specific instance of the question discussed right after Definition 13.M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–5123{+} from you now at price 12 and, after B occurs (whatever B it is), sell you {+} at price 1, thus making a sure gain. Wededuce that if you want to preserve temporal consistency as well as the possibility to use Bayes’ rule to define your futurecommitments, it is necessary that P be disintegrable.In order to fully clarify this matter, it is useful to establish the following result, which holds irrespective of whetheror not future commitments match conditional beliefs (that is, irrespective of whether or not P B is the conditional naturalextension of P ):Theorem 3. Assume your current and future commitments are linear previsions P , P B, and let R, F Binduce by means of Eqs. (4), (5) and (9). Then:be the sets of gambles theyR ∪ F Bcoherent ⇔ R ∪ F Bavoids partial loss ⇔ P , P B coherent.Proof. That the first condition implies the second is trivial; the second implies that P , P B avoid sure loss by Theorem 1,and since they are linear this means that they are coherent.Conversely, assume that P , P B are coherent, and let us show that R ∪ F Bis coherent. It suffices to show that R ∪ F Bfor every f ∈ R,. Consider such f , g. We can assume without loss of generality that neither of these gambles is positive, becauseimplies thatequals its natural extension. Since both R, F Bg ∈ F Bthe result holds trivially in that case. Using Eq. (4), we deduce that P ( f ) > 0. On the other hand, g ∈ F BP B(g) (cid:2) 0, whenceare coherent, this holds if and only iff + g ∈ R ∪ F BP ( f + g) = P ( f ) + P (g) = P ( f ) + P(cid:6)(cid:7)P B(g)> 0;the second equality follows from Corollary 2, taking into account that the coherence of P , P B implies that they are tempo-rally consistent; for the inequality use that the coherence of P implies that P (P B(g)) (cid:2) 0. As a consequence,f + g has apositive prevision, and therefore it belongs to R. We conclude that R ∪ F Bis coherent. (cid:2)We can finally analyse in more detail the implications of the precise setting. We focus on the special case where P (B) > 0for all B ∈ B. Then Eq. (15) and Theorem 3 imply that:Corollary 3. If P (B) > 0 for all B ∈ B and PBis derived from P by means of Bayes’ rule, then the following conditions are equivalent:BB(a) P , P(b) P , P(c) P , P(d) P is disintegrable.are temporally consistent.are strongly temporally consistent.are temporally coherent.BThe above equivalences do not involve event-wise temporal consistency because it considers only the occurrence of asingle event B. On the other hand, one can argue that event-wise temporal consistency is not the notion to apply in thepresent case, and more generally that it does not make sense to declare future commitments after present beliefs: in fact,since there is no choice other than using Bayes’ rule to define future commitments, why should Bayesians want to postponethis task? They know from the very beginning that by setting future commitments different from conditional beliefs, theywould expose themselves to incur a loss (remember also that we are assuming that you receive no new information about Ωuntil B obtains). Being Bayesian together with conceding—right now—that future commitments might differ from conditionalbeliefs appears irrational. Stated differently, temporal coherence appears to be a rationality requirement in the presentcase.21Example 12 (Running example). Assume that in our running example we have precise information, stating that the prevalenceof the seasonal and the atypical virus is 95% and 5%, respectively, and that the probability that the test is positive is of 60%and 90% in each of these cases. This corresponds to the assessmentsP (V = s) = 0.95,P (V = a) = 0.05,P (T = p|V = s) = 0.6,P (T = p|V = a) = 0.9from which, applying the law of total probability, we obtain the joint modelP (s, p) = 0.57,P (s, n) = 0.38,P (a, p) = 0.045,P (a, n) = 0.005.21 However, note that if one decided to use the modification of event-wise temporal consistency sketched in note 15, it might happen that the set ofactually made (current) transactions R(cid:11)is strictly smaller than R and hence that its natural extension may not be a precise probabilistic model. In thatcase, Bayes’ rule would not necessarily be the unique consistent rule to use even though all probabilities were positive.24M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–51What our results tell us is that, in order to achieve temporal coherence (or temporal consistency, or strong temporal consis-tency) your future model P (V |T ) should be determined by Bayes’ rule, so that:P (V = a|T = p) = 0.073 and P (V = a|T = n) = 0.013,and since there is no freedom in how to establish your future commitments in this precise case, it makes no sense topostpone this task until the test has been performed.Remark 3. Let us consider now what happens in the more general situation where it may be that P (B) = 0 for someB ∈ B. In this case, the natural extension E(·|B) of P conditional on B is vacuous, and therefore differs from P B (whichwe require to be precise). The connection between the different consistency notions is weaker then. Moreover, event-wisetemporal consistency, as well as declaring future commitments after present beliefs, cannot be ruled out: present beliefs donot constrain future commitments when P (B) = 0. See Proposition 19 in Section 6.5 for additional insights on this case.Our discussion so far does not exhaust all the possibilities to express precise assessments. For instance, when Ω iscontinuous, it is common to hold precise beliefs in the form of a linear prevision P that assigns zero probability to all thesubsets of Ω while having precise, and hence non-vacuous, conditional beliefs P (·|B). In this case, the model of present(unconditional and conditional) beliefs is not only made of P , simply because P (·|B) cannot be derived from it. In termsof desirable gambles, this means that your conditional beliefs cannot be derived from the set of gambles R associated toP by means of (4). However, it is still possible to deal with questions of temporal consistency under these types of preciseassessments by considering other sets of desirable gambles different from R; how this can be done is the purpose of thenext sections (see in particular Section 5.2).5. Coherent sets of gamblesSo far, we have assumed that your assessments are modelled by means of (unconditional and conditional) lower previ-sions. These lower previsions encode your commitments to accept certain gambles. In our previous sections, we consideredthe sets R, F Bdetermined by P , P B using Eqs. (4), (5) and (9), and showed that the different consistency notions for P , P Bcan be given a behavioural interpretation in terms of these sets.However, as we shall argue in this section, in certain situations there are other sets of desirable gambles that are alsorelated to P , P B and that may be more informative than the ones considered in Section 4. Because of this, it may be usefulto model your assessments using directly the sets of commitments you are willing to accept. In order to make this clear,we shall introduce next a number of aspects of the theory of sets of desirable gambles, and detail their connection with themodels of lower previsions.5.1. Almost- and strict desirabilityIn the treatment done so far, we have focused on the sets of gambles induced by coherent lower previsions. One of themost important things to realise now is that coherent lower previsions induce, through (4), only a special case of coherentsets of desirable gambles, which can be characterised as follows:Definition 19 (Strictly desirable gambles). R is called a set of strictly desirable gambles when it is coherent and moreoversatisfies the following condition:D0. For every f ∈ R \ L+there is some δ > 0 such that f − δ ∈ R.D0 is a condition of openness: a set of strictly desirable gambles is a convex cone that, excluding the region L+ ⊆ Rfrom consideration, coincides with its interior. In the following we shall say that the set is open, thus neglecting the case ofL+, with an abuse of terminology. We shall adopt the notation R for a set of strictly desirable gambles in case we need todistinguish it from different types of sets.Given a set R of strictly desirable gambles, we can induce a coherent lower prevision from it in a way similar to whatwe have already done in (6) for the conditional case:P ( f ) := sup{μ: f − μ ∈ R}.(16)It can be checked that Eqs. (4) and (16) commute; as a consequence, there is a one-to-one correspondence between coherentlower previsions and sets of strictly desirable gambles; something similar applies to the conditional case (Eqs. (5) and (6)).This correspondence extends also towards the notion of conglomerability we have given in Definitions 5 and 10: a coherentlower prevision P is conglomerable if and only if its associated set of strictly desirable gambles R is conglomerable.At the other extreme of the coherent open sets of desirable gambles, there are the closed sets of desirable gambles.These are cones whose interior is a set of strictly desirable gambles, and which include the border of the cone. These closedcones are called sets of almost-desirable gambles, and are characterised as follows:Definition 20 (Almost-desirable gambles). R is called almost-desirable when it satisfies axiomM. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–5125(cid:11)D0.f + ε ∈ R ∀ε > 0 ⇒ f ∈ R,the following modified versions of axioms D1 and D2:(cid:11)D1(cid:11)D2. inf f > 0 ⇒ f ∈ R,. sup f < 0 ⇒ f /∈ R,as well as axioms D3 and D4.(cid:11)D0is a closure condition, which means that the uniform limit of a decreasing sequence of gambles in R also belongs(cid:11)guarantee that R includes the gambles that are strictly positive and excludes those that areto R; axioms D1strictly negative, when these gambles are at the same time bounded away from zero. Note that a set of almost-desirablegambles is not coherent because axioms D0(cid:11)A coherent lower prevision P on L induces a set of almost-desirable gambles byimply that 0 ∈ R, thus violating D2.(cid:11)and D2(cid:11)–D1(cid:4)(cid:5)R :=f ∈ L: P ( f ) (cid:2) 0.(17)If we denote by R the strictly desirable set induced by P through (4), we obtain that R corresponds to the closure of R inthe topology of uniform convergence [41, Proposition 4], so any almost-desirable gamble can be seen as the uniform limitof a sequence of strictly desirable gambles. For this reason, we shall also denote by R a set of almost-desirable gambles.In this paper almost-desirability is useful to provide the definition of avoiding sure loss in the case of gambles:Definition 21 (Avoiding sure loss for gambles). We say that a set of gambles R avoids sure loss when it is included in a set ofalmost-desirable gambles.Since any set of almost-desirable gambles that includes R must also include its natural extension ER because of ax-, D3 and D4, we deduce that R avoids sure loss if and only if ER is included in a set of almost-desirable(cid:11), D1(cid:11)ioms D0gambles. Moreover,R avoids sure loss ⇔ E R is a set of almost-desirable gambles,where E R denotes the closure of ER in the topology of uniform convergence. To see the direct implication, note that any setof almost-desirable gambles that includes R must include E R because of the axioms of almost-desirability, and moreover(cid:11)E R is a set of almost-desirable gambles if and only if it satisfies D2, so if E R is not a set of almost-desirable gambles noneof its supersets can be.(cid:11)Moreover, it can be checked that if E R violates D2then also ER does it, and from this we deduce the existence ofa positive linear combination f of gambles in R such that sup f < 0. This allows us to get some intuition about thisdefinition: we say that R avoids sure loss when it is not possible that a positive linear combination of gambles in R resultsin a gamble that produces a loss of at least some ε > 0, no matter the outcome of the experiment.A set of gambles that avoids partial loss avoids in particular sure loss, because the closure of any coherent set of desirablegambles is a set of almost-desirable gambles; however, the converse does not hold in general, since a set of almost-desirablegambles, such as { f (cid:2) 0}, may incur a partial loss. Note moreover than a coherent set of desirable gambles avoids inparticular partial and sure loss.We conclude by noting that, in a similar way to coherent lower previsions, a coherent set of desirable gambles R is alsoassociated to a credal set:(cid:4)M(R) :=P : P ( f ) (cid:2) 0 ∀ f ∈ R(cid:5),and it can be checked that this credal set coincides with M(P ), where P is the coherent lower prevision induced by R byEq. (16).5.2. Introducing general desirabilityFrom now on we consider the general case of coherent sets of desirable gambles, i.e., those sets that satisfy axioms D1–D4 without being necessarily strictly desirable. In the present section we introduce such a general case and discuss why itis important to focus on it.We start by noticing that, as opposed to the case of strict desirability, the correspondence between coherent lowerprevisions and coherent sets of gambles is one-to-many: in fact, any coherent set of desirable gambles R inducing P bymeans of Eq. (16) satisfiesR ⊆ R (cid:5) R,(18)26M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–51where R is the set of strictly desirable gambles that induces P and R is the topological closure of R (as well as of R).In fact, R is also the set of almost-desirable gambles induced by P by means of Eq. (17). In other words, all the infinitelymany coherent sets of gambles R that satisfy the inclusion (18) are going to induce P . Such an inclusion highlights oncemore that the difference between all these sets lies only in their topological border, given that R and R share the sameinterior.Remember that in the case of strict desirability a gamble f /∈ L+belongs to R if and only if P ( f ) > 0. For a generalcoherent set of desirable gambles R, it may hold instead that both f ∈ R and P ( f ) = 0. This has important consequencesfor the conditional case. To see this, note that we can obtain a separately coherent conditional lower prevision from acoherent set of desirable gambles in the following way:P ( f |B) := sup(cid:4)μ: B( f − μ) ∈ R(cid:5),(19)which generalises and subsumes both (6) and (16). Now, whenever P (B) = 0 for an event B ∈ B, we must have alsoP (B g) (cid:3) 0 for any gamble g ∈ L (cf. [43, Lemma 1]), so that there is no gamble g such that B g ∈ R; by applying (19)to R, we see then that the supremum μ such that B( f − μ) ∈ R is μ = infB f . This means that if we apply Eq. (19) toa set of strictly desirable gambles, the lower prevision of any gamble f conditional on B, with P (B) = 0, is necessarilyvacuous. Note how this is consistent with (3) (in fact, the lower prevision conditional on B obtained through R is just theconditional natural extension of P , as we can see from Lemma 1), and that this means in particular that a set of strictlydesirable gambles is completely uninformative about any conditional inference when P (B) = 0.This need not be the case for general desirability, as an immediate consequence of the property that allows bothP (B f ) = 0 and B f ∈ R to hold. The implications of such a property are very broad, perhaps broader that one might expectat first: in fact, it has been shown in [43, Theorem 25(i)] (and stated also in [67, Appendix F4]) that whenever P is (jointly)coherent with a conditional lower prevision P (·|B), then there is a coherent set R that induces them both. Joint coherenceis particularly easy to characterise when we deal with a finite possibility space Ω and all the conditioning events havepositive upper probability: in that case, a coherent lower prevision P and a separately coherent conditional lower previsionP (·|B) are jointly coherent if and only if P (·|B) ∈ [E(·|B), R(·|B)] for all B ∈ B, where E(·|B) is the conditional naturalextension given by Eq. (3) andR( f |B) := sup(cid:4)μ: P(cid:6)(cid:7)B( f − μ)(cid:5)(cid:2) 0is called the regular extension (see [39, Section 4.3]).22 This implies that whenever E(·|B) (cid:10)= R(·|B),23 there are infinitelymany separately coherent conditional lower previsions P (·|B) that are jointly coherent with P . For each of those, we canfind a coherent set of desirable gambles R that induces both P and P (·|B). This shows that even if the difference betweendesirability and strict desirability is only in the topological border of the involved sets, the border actually makes all thedifference when it comes to making inferences in the conditional case with P (B) = 0.Moreover, note that the case P (B) = 0 is particularly important in applications. For instance, consider the case where Ωis the bi-dimensional set of real numbers R2. In a case like this, it is common practice in precise probability to expressuncertainty through a density function that assigns zero probability to every pair (ω1, ω2) ∈ Ω ; at the same time, theinferences conditional on the observation of ω2 ∈ R are obtained through the conditional density, and hence are not vacuous.This prevents the conditional and unconditional models from being represented through a coherent set of strictly desirablegambles, because this would be incompatible with the non-vacuity of the conditional inferences. The models can instead beinduced by a single coherent set of desirable gambles, because the pair P , P (·|B), corresponding to the unconditional andthe conditional density, are jointly coherent (see [67, Section 7.7.2]).Even though these situations cannot be represented using a single set of strictly desirable gambles, or, which is equiv-alent, using a single coherent lower prevision, one could still try to use a collection of coherent lower previsions torepresent your current beliefs, such as a jointly coherent pair P , P (·|B) for your present unconditional and conditionalbeliefs, respectively—where P (·|B) would not need to coincide with the conditional natural extension E(·|B) of P . But thiswould technically complicate much the analysis we are pursuing in this paper compared to using desirability, taking intoaccount that we should also need to use a further separately coherent lower prevision for your future commitments. Per-haps more important, it has been shown that even collections of separately coherent conditional lower previsions are notas expressive as coherent sets of desirable gambles; this is the case also when we consider finite spaces of possibilities, asshown by the following example based on [41, Example 10].Example 13. Two people express their beliefs about a fair coin using coherent sets of desirable gambles. The possibility spaceΩ := {h, t}, represents the two possible outcomes of tossing the coin, i.e., heads and tails. For the first person, the desirablegambles f are characterised by f (h) + f (t) > 0; for the second person, a gamble fis desirable if either f (h) + f (t) > 0 orf (h) = − f (t) < 0. Call R1 and R2 the set of desirable gambles for the first and the second person, respectively. It can be22 Conditioning a set of mass functions by regular extension corresponds to applying Bayes’ rule to each mass function that assigns positive probability tothe conditioning event B. If there is no such mass function, then the regular extension yields the set of all the mass functions, i.e., the vacuous model.23 This may happen only when P (B) > P (B) = 0; when P (B) > 0 both are equal to the unique value for which GBR is satisfied.M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–51272verified that both sets are coherent. Moreover, they originate the same conditional and unconditional lower previsions. Inthe unconditional case we obtain P ( f ) = f (h)+ f (t); this corresponds, correctly, to assigning 0.5 probability to both heads andtails. In the conditional case, we again correctly obtain that each person would assign probability 1 to either heads or tailsassuming that one of them indeed occurs: P ( f |{h}) = f (h), P ( f |{t}) = f (t). This exhausts the conditional and unconditionallower previsions that we can obtain from R1 and R2, given that Ω has only two elements. It follows that R1 and R2 areindistinguishable as far as probabilistic statements are concerned. But now consider the gamble f := (−1, 1), which yields aloss of 1 unit of utility if the coin lands heads and a gain of 1 unit otherwise: whereas f is not desirable for the first person,it is actually so for the second. This distinction of the two persons’ behaviour cannot be achieved through probabilities—andin fact gamble f lies in the border of each of the two sets. This shows, in addition, that the relationship between collectionsof separately coherent conditional lower previsions and coherent sets of desirable gambles is also one-to-many.In summary, the focus on general desirability allows us be truly general and at the same time it does not overcomplicatethe technical development. On the other hand, we can find yet another reason to focus on desirability, as opposed tocoherent lower previsions, in that it allows us to naturally regard coherent sets of desirable gambles as a logic24 (this ishelpful, among other things, to discuss the relationship of the present work with the field of belief revision, see Section 7.5).5.3. Basic consistency notions for general desirabilityAssume that you check L for desirability: this means that at some point you will isolate the subset R of gambles in Lthat you desire. Set R is a belief model that can be regarded as a generalisation of a set of sentences in propositional logic,where L has the role of the language. Notice how in propositional logic the sentences represent what is certain to you,while R only represents what you deem desirable; this change of perspective is the passage from which uncertainty comesinto play.The desirability analog of the deductive closure operator in logic is the mechanism that allows us to obtain the gamblesin L whose desirability is implied by those in R. To see how this mechanism works, consider first that since gamblesexpress rewards in units of a linear utility, then any positive linear combination of a finite number of desirable gambles isdesirable too. Let us call this the ‘posi’ of a set:posi(R) :=λ j f j: f j ∈ R, λ j > 0, r (cid:2) 1;(cid:19)(cid:18)r(cid:8)j=1posi(R) is the smallest convex cone25 that includes R. Moreover, any gamble in L+increase the utility without ever decreasing it (whence L+mechanism we are after simply works as follows:is desirable as well, given that it mayplays the role of the tautologies in logic). In other words, theER := posi(cid:6)R ∪ L+(cid:7),where ER is then the analog of the deductive closure in propositional logic (and in fact ER can be shown to satisfy Tarski’saxioms26 for the finitary consequence operator;27 for a description of these axioms, see [61, Chapter 5§1], Axioms 2–4).The reason why we use ER is first of all to check that R is a rational set of assessments, which means that it does notlead to the zero gamble being desirable:Definition 22 (Avoiding partial loss for gambles). We say that R avoids partial loss if 0 /∈ ER.The name of this condition is due to the fact that once a set avoids partial loss, then no gamble g (cid:3) 0 can belong to it[41, Corollary 2]. This notion of avoiding partial loss is equivalent to the existence of a coherent superset of R (as statedin Definition 8), and in fact in that case ER is nothing else but the natural extension of R in Definition 9. In propositionallogic the analog of avoiding partial loss is the notion of a consistent set of sentences; and when in propositional logic wesay that a set of sentences is consistent and logically closed, or a theory, in desirability we say that set R is coherent: thisis equivalent to having 0 /∈ R = ER.In logic, a special role is taken by complete theories: in a complete theory, for every sentence in the language it holds thateither the sentence or its negation is in the theory. In desirability, the situation is very much alike: we say that a coherentset of gambles R is complete, or maximal, if for every non-zero gamble f ∈ L, either f ∈ R or − f ∈ R. Geometrically, amaximal set corresponds to a cone degenerated into a hyperplane. Maximal sets are tightly related to precise probability,24 Joining probability and logic is the focus of some recent work by Howson [27,28], who, interestingly, discusses also the question of conglomerability(but not desirability).25 A set R is a convex cone if posi(R) = R.26 Yet, note that Tarski’s axiom 1 restricts the treatment to sets that are at most countable. This restriction does not apply to L nor to the logicalformalism of coherent sets of desirable gambles.27 This is actually a more formal rewording of the claim, we repeat in a few places throughout the paper, that our setup is finitary.28M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–51because deriving a lower prevision from a maximal set by means of Eq. (16) yields a linear prevision; more generallyspeaking, linear previsions are in one-to-one correspondence with the interiors of maximal sets.As a side note, let us point out that the relationship between desirability and logic that we have only sketched here,is discussed in much greater detail in [6, Section 5] (which is partly based on a former work in a similar spirit [44]).One interesting point made in that paper, among others, is that propositional logic can formally be embedded in the logicoriginated by coherent lower previsions, and that linear previsions correspond to complete logical theories. This shows ina definite sense how imprecision in probability, as well as in desirability, is what allows us to move away from completetheories into the much more expressive and used field of general logical theories.5.4. Advanced consistency notions for general desirabilityIn this section we consider the notion of coherence relative to a subset Q of L, which generalises the previous notion ofcoherence. The reason why this generalisation is introduced, is that it is not always realistic to expect that you can checkall the gambles in L for desirability; you will often focus on a subset Q of them, and identify in R the subset of gamblesin Q that you find desirable. To define coherence in this setting, we first extend R into posi(R ∪ L+) =: ER and checkthat 0 /∈ ER, because otherwise R would have no coherent extension to L. In case 0 /∈ ER, we proceed to define coherencein a very natural way: we say that you are coherent if the restriction of the natural extension ER to Q recreates R. Thismeans that not only you rationally defined R, but that you were also fully aware of the desirability implications of yourassessments within the set Q that you examined. This is made precise below:Definition 23 (Coherence relative to a subset of L). Say that R is coherent relative to Q if R avoids partial loss and Q ∩ ER ⊆ R(and hence Q ∩ ER = R). In case Q coincides with L then we simply say that R is coherent.This definition is indeed equivalent to axioms D1–D4 when Q = L [41, Proposition 2]. It can be understood as a moreprimitive definition of coherence, which shows perhaps more intuitively what is the rationale behind those axioms. Part ofthe beauty of this definition is in that it joins simplicity with generality: in fact, from this single definition one can derivenot only all the theory of coherent sets of desirable gambles but also all the theory of coherent lower previsions (exceptfor the part that requires conglomerability in addition, as in the case of Walley’s), as well as de Finetti’s theory as a specialcase—by imposing the extra axiom of completeness.Definition 23 has been developed for the case where you examine a single set Q ⊆ L of gambles and isolate out of itthe set R of gambles that are desirable to you. However, for the aims of this paper, we need to consider also a slightlymore general setup. The motivation is that we need to deal with a pair of sets of desirable gambles: one for your presentbeliefs and one for your future commitments. These two sets are the result of two different assessment procedures, and wemight want the two models to cohere with each other in some sense.To address this problem it is convenient for the moment to represent the situation abstractly, without reference to thetemporal setting of this paper. In this representation, you first examine set Q1 ⊆ L and declare that the coherent subsetR1 ⊆ Q1 is desirable; then you examine set Q2 ⊆ L and declare that the coherent subset R2 ⊆ Q2 is desirable. In otherwords, such a situation is characterised by a collection {(R1, Q1), (R2, Q2)} of assessed models, and the problem now ishow to define the overall coherence of the collection. A basic requirement is that each model (Ri, Qi), i = 1, 2, is coherentaccording to Definition 23. To define then the actual coherence of the collection, we can proceed in two ways. One possibilityis to replay the ideas at the basis of the traditional notion of coherence straightforwardly:Definition 24 (Coherence of a collection). Let R := R1 ∪ R2, and Q := Q1 ∪ Q2. Say that the collection is coherent if R iscoherent relative to Q.However, there is another avenue that we can take. The idea is that the logical implications of the sets R1, R2, shouldnot force any gamble in Q1 \ R1, nor any gamble in Q2 \ R2, to become desirable:Definition 25 (Strong coherence of a collection). Let R := R1 ∪ R2 and ER := posi(R ∪ L+). Say that the collection is stronglycoherent if R avoids partial loss and ER ∩ Qi ⊆ Ri for i = 1, 2.In other words, what we require here is that the logical implications of the collection, expressed by ER, cohere with eachmodel (Qi, Ri), i = 1, 2, separately. The next proposition shows that strong coherence is indeed stronger than coherence. Itis related to ideas underlying [41, Theorem 11, points (1) and (3)].Proposition 7. Let Ri be a set of desirable gambles coherent relative to Qi , for i = 1, 2. Let ER be the natural extension of R :=R1 ∪ R2, and let Q := Q1 ∪ Q2. Then the following are equivalent:(a) The collection is coherent and R ∩ Qi ⊆ Ri for i = 1, 2.(b) The collection is strongly coherent.Proof.M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–5129(a) ⇒ (b) Since R is coherent relative to Q, then it avoids partial loss. Moreover, ER ∩ Q ⊆ R implies that ER ∩ Q ∩ Qi ⊆R ∩ Qi or, in other words, that ER ∩ Qi ⊆ R ∩ Qi ⊆ Ri , applying the assumption.(b) ⇒ (a) By hypothesis, R avoids partial loss. In addition, we know that ER ∩ Qi ⊆ Ri for i = 1, 2. By taking the union oneach side of the inclusion for i = 1, 2, we see that ER ∩ Q ⊆ R. (cid:2)A case of special interest for this paper is that where Q1 = Q2 = L. In this case we see immediately that strong co-herence amounts to having R1 = R2, taking into account that both R1 and R2 are assumed to be coherent sets.28 Thisequality can be represented through the pair of inclusions R1 ⊆ R2 and R1 ⊇ R2. If we look at the definition of strongcoherence, we see that the former inclusion states that R2 must not be inconsistent with the logical implications of R1,and the latter, that R1 must not be inconsistent with the logical implications of R2. In other words, strong coherence canbe regarded as a bidirectional requirement of coherence. We formalise the unidirectional requirement as follows:Definition 26 (One-way strong coherence). Let R1, R2 be two coherent sets of desirable gambles. We say that R2 stronglycoheres with R1 when R1 ⊆ R2.One-way strong coherence implies the coherence of the collection {(R1, L), (R2, L)}, since that is equivalent to thecoherence of R1 ∪ R2.The unidirectional requirement of strong coherence is an important notion for this paper. The underlying reason, whichwill become clear in the following sections, is that our temporal setup creates additional constraints with respect to theabstract representation above. These constraints are related to the existence of a temporal order of the models for whichwe might consider a requirement of strong coherence (such as your present and future commitments); and this order maybe compatible only with a unidirectional consistency notion, as it is the case, for instance, of strong temporal consistency inSection 6.2. In these cases, one-way strong coherence is the strongest consistency requirement that is possible to consider.On the other hand, there are cases where the question of the order is less constraining, such as in the case of strongtemporal coherence in Section 6.4, and then it is possible to apply also bidirectional strong coherence.6. Temporal consistency notions for coherent sets of gamblesAssume now that you assess your current and future commitments directly in terms of sets of desirable gambles. Let usconsider thus that your current beliefs are a coherent set R of desirable gambles. Your future commitments, that becomeeffective after a certain B ∈ B occurs, are instead represented by means of a coherent set RB of desirable gambles withrespect to L(B), or, equivalently, by means of the set RB ⊆ L it determines through RB := {B f :f ∈ RB }. Note that RBis coherent relative to the set { f ∈ L(Ω):f = B f }. In case you establish your future commitments for all B ∈ B, then wecombine all the sets RB into their conglomerable natural extension F B, as in Proposition1 .In this section, we shall investigate how the different consistency notions from Section 4 can be established when yourassessments are modelled by means of the above sets.6.1. Temporal consistencyIn this first case the relevant sets are R and F B. The following definition is a straightforward extension to sets ofdesirable gambles of what we have already studied in Section 4:Definition 27 (Temporal consistency for gambles). We say that your current and future commitments are temporally consistentif R ∪ F Bavoids partial loss.Once again, the rationale behind this definition is that if you failed temporal consistency, an opponent could create acombination of current and future transactions that will have the overall effect of making you desire, and then accept, agamble g (cid:3) 0. For example, assume that f − ε belongs to R for some ε > 0, and that at the same time −B f belongsto RB for all B ∈ B. Then an opponent might decide now to sell you f at price ε immediately, and to ask you for B fafter B happens. This will earn him a gain of ε irrespective of the actual B that will occur: that is, he will make you incur asure loss (in time). As a side remark, observe that when Ω is infinite, this specific example is prevented from happeningunder Definition 27 just because that definition is based on F B: we could not achieve this by using finite combinations ofelements from sets RB , B ∈ B.Let us give some insight about the definition we have just introduced.Proposition 8. Let R, R1 be coherent sets of desirable gambles. Then28 It can be checked that this holds as soon as Q1 = Q2; note, however, that this does not mean that the sets Q1, Q2 uniquely determine R1, R2.30M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–51(a) R ∪ R1 avoids partial loss if and only if f ∈ R1 ⇒ − f /∈ R.(b) As a consequence, the following conditions are equivalent:(b.1) Your current and future commitments are temporally consistent.(b.2) The following implication holds:f ∈ F B ⇒ − f /∈ R.(b.3) posi(R ∪ F B) is coherent.Proof.(20)(a) Let R(cid:11) := R ∪ R1, and call ER(cid:11) its natural extension. Given that both R and R1 are coherent, we obtain thatER(cid:11) = posi(cid:7)(cid:6)R(cid:11)=(cid:18)n(cid:8)i=1λi f i: n (cid:2) 1, λi > 0, f i ∈ R(cid:11)(cid:19)(cid:4)=f + g: f ∈ R ∪ {0}, g ∈ R1 ∪ {0}, f (cid:10)= 0 or g (cid:10)= 0(cid:5).Now, R(cid:11)avoids partial loss if and only if 0 /∈ ER(cid:11) . Note that this last condition holds if and only if f ∈ R1 ⇒ − f /∈ R.The direct implication is trivial. For the converse, 0 ∈ ER(cid:11) requires that there are f ∈ R, g ∈ R1 so that f = −g, because0 /∈ R(cid:11)since both R and R1 are coherent.(b) This follows from (a) and [41, Proposition 3(d)]. (cid:2)This proposition provides an interpretation of temporal consistency: for this condition to hold, if you commit yourself toaccept some gamble in the future, you should not accept the opposite gamble now. This is related to the ideas of Goldsteinand van Fraassen we shall discuss in Section 7.3.29Remark 4. Similarly to Remark 2, temporal consistency holds automatically when you make your sets of temporally consis-tent commitments more imprecise, in the sense that if you consider two sets of current beliefs R1 ⊆ R and two sets offuture commitments F B1 are temporally con-1sistent. The interpretation here is that, since temporal consistency means that the convex cone generated by your currentand future commitments does not produce partial losses, if you become more cautious (that is, more imprecise) in yourassessments and remove some gambles from your sets of current and future commitments you will obtain a smaller convexcone, which as a consequence will not produce partial losses either.are temporally consistent, then trivially also R1 and F Band R, F B⊆ F BThe set R of current beliefs induces a coherent lower prevision P by means of Eq. (19); similarly, for every B ∈ B the setRB induces a lower prevision P B by means of Eq. (19); as a consequence, the set F Binduces a separately coherent futurelower prevision P B. The sets of strictly desirable gambles associated to these two lower previsions are included in R, F B,respectively. Then it is easy to deduce from Theorem 1 the following:Theorem 4. Let us denote by P , P B the lower previsions induced by R, F Brespectively. Then the following conditions are equivalent:(a) R ∪ F Bavoids sure loss.(b) M(R) ∩ M(F B) (cid:10)= ∅.(c) P , P B are temporally consistent.As a consequence, if R, F Bare temporally consistent, so are the lower previsions P , P B they induce.Proof. Let us make a circular proof.(a) ⇒ (b) Assume that R ∪ F Bavoids sure loss. This means that it is included in some set D of almost-desirable gambles,and as a consequence the lower prevision Q given by Q ( f ) := sup{μ: f − μ ∈ D} is coherent [67, Theorem 3.8.1].Moreover, D = { f : Q ( f ) (cid:2) 0} whence, given P ∈ M(Q ), it holds that P ( f ) (cid:2) 0 for every f ∈ R ∪ F B, i.e.,P ∈ M(R) ∩ M(F B).(b) ⇒ (c) Consider P ∈ M(R) ∩ M(F B), and assume ex-absurdo that P , P B do not avoid sure loss. Then there are gamblesf , g such that sup[G( f ) + GB(g)] < 0, whence there is some δ > 0 such that sup[G( f ) + GB(g) + δ] < 0. Since29 Interestingly, the first point in the proposition relates also to propositional logic, where it is said that a set of sentences is consistent when it is not thecase that a proposition and its negation both belong to that set.M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–5131G( f ) + δ2= f −(cid:14)(cid:13)(cid:13)P ( f ) − δ2(cid:13)∈ R ⊆ R and(cid:14)(cid:14)G B (g) + Bδ2= Bg −P B (g) − δ2∈ RB ⊆ RB ∀B ∈ B ⇒ GB(g) + δ2∈ F B,we deduce that P (G( f ) + GB(g) + δ) (cid:2) 0. But on the other hand the coherence of P implies that P (G( f ) +GB(g) + δ) (cid:3) sup[G( f ) + GB(g) + δ] < 0, a contradiction. Hence, P , P B avoid sure loss.(c) ⇒ (a) If P , P B are temporally consistent then it follows from Theorem 1 that given their associated sets of strictlydesirable gambles R1, RB1 avoids sureloss, which means that it is included in a set of almost desirable gambles D. But this set D must include theunion R1 ∪ F B. It follows that R ∪ F Bavoids sure loss.1 avoids partial loss. As a consequence, R1 ∪ F B1 , and as a consequence it also includes R ∪ F B1 , B ∈ B, the union R1 ∪ F B1 of the closures of R1, F BFor the second part it suffices to use that R, F Bmust include the sets of strictly desirable gambles induced by P , P B,are temporally consistent so are these sets of strictly desirable gambles. The result followsand as a consequence if R, F Bthen from Theorem 1. (cid:2)Let us show that the implication in the second part of this theorem is not an equivalence:Example 14. Let Ω := {1, 2, 3, 4}, B := {1, 2} and B := {B, Bc}. Let your current beliefs be given by(cid:4)R :=f ∈ L(Ω):(cid:6)f (1) + f (2) + f (3) + f (4) > 0(cid:7)(cid:6)orf (1) + f (2) + f (3) + f (4) = 0, f (1) > 0(cid:7)(cid:5)and let your future commitments be given byRB :=RBc :=(cid:4)(cid:5)f ∈ L(Ω): f = B f , f (1) + f (2) > 0 or f (1) = − f (2) < 0,(cid:4)f ∈ L(Ω): f = Bc f , f (3) + f (4) > 0 or f (3) = − f (4) < 0(cid:5).It can be checked that all the above sets of (present and future) commitments are coherent. Then since the partition Bis finite we have F B = E Band this set is equal to(cid:4)f ∈ L(Ω):(cid:6)f (1) + f (2) > 0 or f (1) = − f (2) (cid:3) 0(cid:7)(cid:6)andf (3) + f (4) > 0 or f (3) = − f (4) (cid:3) 0(cid:7)(cid:5)\ {0}.Moreover, R ∪ F B(−1, 1, −1, 1) belongs to F Bdoes not avoid partialloss, because the gamble (1, −1, 1, −1) belongs to R and its opposite, meaning that their sum 0 belongs to posi(R ∪ F B).On the other hand, R induces the linear prevision P given byP ( f ) := f (1) + f (2) + f (3) + f (4)4∀ f ∈ L,and F Binduces the conditional linear prevision P B given byP B ( f ) := f (1) + f (2)2,P Bc ( f ) := f (3) + f (4)2;P , P B satisfy GBR because P B is derived from P by means of Bayes’ rule, and, taking into account that B is finite, also CNG.Hence, P , P B are coherent, and as a consequence also temporally consistent.In particular, we deduce from this example and Theorem 1 that we may have temporally inconsistent R, F Bwhile thelower previsions P , P B they induce satisfy any of the equivalent conditions from that result, and in particular where theirassociated sets of strictly desirable gambles are temporally consistent.When we consider the sets of strictly desirable gambles induced by your current and future lower previsions, thenTheorem 1 gives us also the opportunity to discuss an interesting side point concerned with the definition of F B. Rememberin Eq. (9) to possibly equal zero (as we have argued right after that equation). Now we canthat we have allowed each B fshow that, as long as we focus on coherent lower previsions (and only then), it is immaterial whether we allow each B f toequal zero or not:Proposition 9. Let R, RB be the sets of strictly desirable gambles induced by P , P B , B ∈ B, and let us define F := { f : B f ∈ RB ∀B ∈B} ⊆ F Bavoids partial loss ⇔ R ∪ F avoids partial loss.. Then R ∪ F BProof. The direct implication follows trivially from the inclusion F ⊆ F B. To see the converse, note that the conditionallower previsions induced by F and F Bcoincide, because of the one-to-one correspondence between coherent lower pre-visions and sets of strictly desirable gambles in Eqs. (16) and (4). Let us prove that if R ∪ F avoids partial loss then the32M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–51lower previsions P , P B they induce avoid sure loss; the result will follow then from Theorem 1. Assume ex-absurdo thatP , P B incur a sure loss. Then there are gambles f , g such that sup[G( f ) + GB(g)] < 0, whence there is some δ > 0 suchthat G( f ) + GB(g) + δ < 0. SinceG( f ) + δ2= f −(cid:14)(cid:13)(cid:13)P ( f ) − δ2(cid:13)∈ R and(cid:14)(cid:14)G B (g) + Bδ2= Bg −P B (g) − δ2∈ RB ∀B ∈ B ⇒ GB(g) + δ2∈ F,we deduce that the gamble G( f ) + GB(g) + δ < 0 belongs to posi(R ∪ F ), and as a consequence this set incurs a partialloss. This is a contradiction. As a consequence, P , P B avoid sure loss and therefore R ∪ F Bavoids partial loss. (cid:2)On the other hand, we can also show that the equivalence established in Proposition 9 is only an implication when thesets of gambles are not strictly desirable:Example 15. Let us consider the space and sets of Example 14, but considering instead RBc := { f ∈ L(Ω):f = Bc f , f (3) +f (4) > 0}. Then R ∪ F B. However, for every g ∈ F it holdsthat g(1) + g(2) + g(3) + g(4) (cid:2) g(3) + g(4) > 0, whence F ⊆ R and as a consequence R ∪ F is coherent and in particularavoids partial loss.incurs partial loss, because f := (1, −1, 0, 0) ∈ R and − f ∈ F BWe turn now to the problem of correcting temporally inconsistent assessments. As we discussed in Section 4.1.1, whenyour current and future commitments are temporally inconsistent it may be interesting to determine the closest model thatsatisfies temporal consistency.Taking into account the negative result we obtained for the case of lower previsions (see Proposition 2), we shall takehere a different route: we shall start from temporally inconsistent R, F B, but shall study instead which is the greatestcoherent subset of F Bthat is temporally consistent with R. Taking into account Proposition 8, a set is temporally consistentwith R if and only if it is included in (−R)c . Hence, we shall look for the greatest coherent subset of R1 := (−R)c ∩ F B,where ‘greatest’ means that every coherent subset of R1 is included in it.Proposition 10.(a) The greatest coherent subset of R1, if it exists, is always equal to R1.(b) If R is a maximal set of gambles, then R1 is coherent.Proof.(a) It suffices to show that for every gamble fthat the natural extension of { f } is given byin R1 there is a coherent subset of R1 that includes f . To see this, noteE{ f } := {g = λ f + h: λ (cid:2) 0, h (cid:2) 0} \ {0}.This is included in F Bbecause the latter is a coherent set of gambles that includes f . To see that it is also included in(−R)c , assume that there is some λ (cid:2) 0 and some h (cid:2) 0 such that λ f + h is non-zero and does not belong to (−R)c .This means that λ f + h ∈ −R, or, equivalently, that −λ f − h ∈ R. Since this is a coherent set, we deduce that also−λ f ∈ R, and consequently so does − f . But we are assuming that f ∈ R1 ⊆ (−R)c , whence − f /∈ R, a contradiction.(b) If R is a maximal set of gambles,(−R)c = { f : f /∈ −R} = { f : − f /∈ R} = R ∪ {0},whence R1 = R ∩ F Bis coherent because it is the intersection of two coherent sets. (cid:2)Statement (b) of this proposition cannot be extended to the case where R is not maximal:Example 16. Consider Ω := {1, 2, 3, 4}, and let your current beliefs be given by(cid:5)f (1), f (3)(cid:4)f : minR := L+ ∪> 0(cid:4)(cid:5).Let your future commitments be the same as in Example 14. Then R and F Binstanceare not temporally consistent, because forf := (1, −2, 1, −2) ∈ R and − f := (−1, 2, −1, 2) ∈ F B;M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–5133to see that in this case R1 = (−R)c ∩ F Bis not coherent, consider the gambles h1 := (1, 0, −2, 3) and h2 := (−2, 3, 1, 0).Then h1, h2 ∈ F B. On the other hand, h1 ∈ (−R)c because −h1 = (−1, 0, 2, −3) /∈ R, and h2 ∈ (−R)cbecause −h2 = (2, −3, −1, 0) /∈ R. However, h1 + h2 = (−1, 3, −1, 3) /∈ (−R)c because −h1 − h2 ∈ R. Hence, h1, h2 ∈ R1 buth1 + h2 /∈ R1, and therefore this set is not coherent., whence h1 + h2 ∈ F BThis means that, although there may not be an optimal way of correcting inconsistent assessments when you modifyboth your sets of commitments at the same time (see Proposition 2), such an optimal correction may be possible when youfix your set of current beliefs and modify only the set of future commitments, i.e., when you look for the greatest set F B1of future commitments such that R ∪ F B1 avoids partial loss. This second scenario is actually something that well fits thecurrent setup where future commitments are defined after current beliefs.In a similar vein as Proposition 10, we can in addition establish the following:Corollary 4. Assume your current beliefs are determined by a linear prevision P , and that they are temporally inconsistent with theseparately coherent future lower prevision P B. Then if P (B) > 0 for every B ∈ B there is a greatest lower prevision P(cid:3) P B that istemporally consistent with respect to P .B1Proof. If P (B) > 0 for every B, then it follows from Corollary 3 that the only linear conditional prevision that satisfiestemporal consistency with P is the E(·|B) determined from P by means of Bayes’ rule. Then Proposition 5 implies that anyB(cid:11)B that is temporally consistent with P must be dominated by E(·|B). Hence, the greatest P1 that is dominated by P BPand satisfies temporal consistency with P is simply P:= min{P B, E(·|B)} (taking into account also Remark 2). (cid:2)B1Hence, an optimal correction is always possible when your current beliefs are precise and all the conditioning eventshave positive probability. More generally, it is not clear whether we can do an optimal correction whenever your currentbeliefs are precise, because the implication between the temporal consistency of gambles and that of the previsions theyinduce is not an equivalence, as we showed in Example 14.6.2. Strong temporal consistencyIf you express your assessments by means of sets of desirable gambles, the idea of strong temporal consistency meansstrongly cohere (cf. Definition 26) with theB∈B R|B :that (i) R ∪ F Bconditional information embedded in R, and which we can represent by the conglomerable natural extension ofavoids partial loss; and (ii) the future commitments F B(cid:12)(cid:4)(cid:5)F |B :=f ∈ L: B f ∈ R|B ∪ {0} ∀B ∈ Bwhere the sets R|B are derived from R by means of Eq. (7).\ {0},Definition 28 (Strong temporal consistency for gambles). Your current and future commitments are said to be strongly temporallyconsistent if they are temporally consistent and F B = F |B.Remember that at the time when F Bis established, in the present setting there is no possibility to revise R, given that itrepresents commitments that are effective at that time. Therefore it is only possible for you to make future commitments notinconsistent with present beliefs (and not vice versa). We express this using one-way strong coherence through F |B ⊆ F B.The equality that we have in Definition 28 follows then by focusing on the least-committal future model that stronglycoheres with F |B. If we instead do not focus on such a least-committal model, we obtain a weaker consistency condition:Definition 29 (Strong backward temporal consistency for gambles). We say that your current and future commitments arestrongly backward temporally consistent if they are temporally consistent and F |B ⊆ F B.The latter could in particular be a more realistic consistency condition than the former as it seems unreasonable to expectthat future commitments always match conditional beliefs: why should this be the case given that you have additional timeto refine your conditional beliefs into future commitments? It may instead be more reasonable to expect that in a numberof cases future commitments are more precise than conditional beliefs, as in Definition 29, just because of the extra timeyou can devote to assess them.(or R ⊆ F BRemark 5. One might wonder whether the rationale behind Definitions 28–29 should rather be applied to R and F B,leading to R = F B). This approach is not viable in the temporal setup we are dealing with again for thereason that present beliefs cannot be modified at the time of establishing F B: in fact, considered the special structureof F Bwould be that R is also defined similarly through sums of gambles definedpiece-wise on different elements of the partition B. But this would mean that R is built using only conditional informationso that for every f ∈ R and every B ∈ B it holds that B f ∈ R ∪ {0}, and as a consequence R ⊆ F |B. This is clearly not, the only possibility to have R ⊆ F B34M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–51going to be the case in general, and therefore this approach is not applicable. Notice, however, that in case R ⊆ F |BDefinition 29 represents indeed a strong coherence requirement between R and F Bdefinitions focus on F |B, then, so that the fact that the previousis not restrictive.In the remainder of this section, we explore some of the implications of strong temporal consistency. Let us start bygiving an equivalent formulation of this notion:Proposition 11. Assume that RB = R|B for all B ∈ B, and consider f ∈ L. Then (20) can be rewritten equivalently as follows:B f ∈ R ∪ {0} ∀B ∈ B ⇒ − f /∈ R.(21)If in addition R is maximal, then strong temporal consistency is equivalent to the conglomerability of R.Proof. Let us show that (20) implies (21). We skip the trivial case f = 0. For a B ∈ B s.t. B f ∈ R, we have that B f ∈B∈B: B f (cid:10)=0 B f ∈ F BR|B = RB . Applying the definition of F Band hence − f /∈ R, using (20).We consider now the converse implication. Take f ∈ F BB∈B B f , with B f ∈ RB ∪ {0} = R|B ∪ {0}, whenceB f ∈ R ∪ {0} for all B ∈ B. Applying (21), we see that − f /∈ R.For the second part, note that Eq. (21) together with the maximality of R imply that F |B ⊆ R, i.e., that R is conglomer-able; and conversely, if R is conglomerable, then B f ∈ R ∪ {0} for all B ∈ B implies that f ∈ R ∪ {0}, whence by coherence− f /∈ R and Eq. (21) holds. (cid:2)in (9), we obtain that f =. Then f =(cid:3)(cid:3)Expression (21) allows us also to clarify an important point:Proposition 12. Your set R of current beliefs fails (21) if and only if every coherent set R(cid:11) ⊇ R fails (21).Proof. For the direct implication, consider − f ∈ R s.t. B f ∈ R ∪ {0} ∀B ∈ B. Assume ex-absurdo that there is a coherentset R(cid:11) ⊇ R that satisfies (21). Then B f ∈ R(cid:11) ∪ {0} ∀B ∈ B, so that − f /∈ R(cid:11) ⊇ R. This is a contradiction. The converseimplication is trivial. (cid:2)In other words, the only possible coherent extension of R that satisfies (21) is R itself. This means that if R fails (21),there is no such an extension; and on the other hand, if it satisfies (21), we do not need to compute the extension, aswe have it already. This should be compared with the conglomerable natural extension of R, which may be different fromR, and can in particular be difficult to compute, as illustrated in [43]. The situation is analogous if we work with lowerprevisions rather than sets of desirable gambles. This property can in fact be regarded as a particular case of Remark 4,when you assume that your future commitments coincide with your conditional beliefs.6.2.1. MET-beliefsWe next consider the important special case in which your current beliefs have been constructed by the marginal ex-tension theorem (see [40,67], and especially [43, Proposition 29]). We call them MET-beliefs. This corresponds to a situationof hierarchical information, where in addition to the conditional information on each element of the partition we have un-conditional information expressed in terms of a set of desirable gambles that are constant on the different elements of thepartition (recall that such gambles are called B-measurable). In order to aggregate these pieces of information into a jointmodel, we consider two avenues.Let R0 be a set coherent relative to the set of B-measurable gambles (and hence it is a set of B-measurable gamblesitself) and for every B ∈ B let R|B be a coherent set of desirable gambles with respect to L(B). Then the conglomerablenatural extension of R0 ∪(cid:2)B∈B R|B is given by(cid:12)(cid:11)R :=h +B g B : h ∈ R0 ∪ {0}, g B ∈ R|B ∪ {0}\ {0}.(22)B∈BThis set can be expressed equivalently asR =(cid:4)h + g: h ∈ R0 ∪ {0}, g ∈ F |B ∪ {0}(cid:5)\ {0}.Moreover, it holds that R|B is the conditional set of gambles derived from R by Eq. (7): consider a gamble f ∈ L suchthat f = B f ∈ R. Then we can write B f = h1 + h2, for some h1 ∈ R0 ∪ {0}, h2 ∈ F |B ∪ {0}, h1 + h2 (cid:10)= 0. We skip the trivialcase made of Bh1 = 0. Since the gamble h1 is B-measurable, Bh1 is constant on some real number. If this constant ish1 (cid:2) 0, or we should contradict the coherence of R0. But in thatnegative, then there must be some Bcase since B. As a consequence, we musthave Bh1 (cid:2) 0. Whence, if Bh2 ∈ R|B , then f ∈ R|B because f = B f (cid:2) Bh2 ∈ R|B ; otherwise, if Bh2 = 0, then fis equal tothe positive constant Bh1, so that f ∈ R|B .h2 (cid:3) 0, a contradiction with the definition of F |B(cid:11)(h1 + h2) = 0 we should have B(cid:11) (cid:10)= B such that B(cid:11)(cid:11)(cid:8)M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–5135(23)In the second case, we consider the natural extension of R0 ∪(cid:12)conglomerable as we consider finite sums only. By considering the natural extension E |BB∈B R|B is given by:natural extension of R0 ∪(cid:5)(cid:4)h + g: h ∈ R0 ∪ {0}, g ∈ E |B ∪ {0}is a subset of F |BNote that E |B\ {0}.R :=, and as a consequence this set is included in that defined by (22).(cid:12)B∈B R|B . In that case, your beliefs are not necessarily30(cid:12)B∈B R|B in (11), then theofReasoning as before, we deduce that this set also induces the conditional assessments R|B , B ∈ B: it is trivial thatf = B f ∈ R}; to see the converse inclusion, note that the set of conditional assessments induced by (23)R|B ⊆ { f ∈ L:must be included in that induced by (22), which we have showed to be given by R|B , B ∈ B.In summary, when your current beliefs are constructed by means of the marginal extension theorem, we can also takeinto account conglomerability (and then we end up with the set R in Eq. (22)) or not (and then we end up with the set Rin (23)). Let us show that R satisfies strong temporal consistency in each of these two cases.Proposition 13. Let R be defined either by (22) or by (23), and consider f ∈ L. ThenB f /∈ R ∀B ∈ B ⇒ f /∈ R.As a consequence, in either case R satisfies strong temporal consistency with its conditional beliefs.Proof. We focus on the case that R is defined by (22); the remaining case is analogous. Assume ex-absurdo that there issome f ∈ R such that B f /∈ R for every B ∈ B. Then,B∈B B g B for some h ∈ R0 ∪ {0} and g B ∈ R|B ∪ {0}, B ∈ B.Consider any element B ∈ B; we see that B f = Bh B + B g B , where h B is a constant and g B ∈ R|B ∪ {0}.Now, for any B ∈ B it cannot be h B > 0, because since B g B ∈ R ∪ {0} we should deduce that B f = Bh B + B g B ∈ R, acontradiction. As a consequence, it must be h (cid:3) 0. On the one hand, it cannot be h (cid:3) 0 or we contradict h ∈ R0. On theB: B f (cid:10)=0 B g B , whence B f = B g B for every B, and since B f /∈ R by hypothesis we deduceother hand, h = 0 means that f =that B g B = 0 for every B. This means that f = 0 /∈ R.Let us move now to the second part. Take f ∈ L such that B f ∈ R ∪ {0} for all B ∈ B. Then B(− f ) /∈ R for all B ∈ B. Thef = h +(cid:3)(cid:3)thesis follows applying the first part of the result and Proposition 11. (cid:2)This means that in the case of MET-beliefs, strong temporal consistency is automatically secured if future commitmentsequal conditional beliefs, irrespective of whether current beliefs are conglomerable or not. This last case seems to be partic-ularly interesting. To see this more clearly, recall that we have showed that the set R induces the conditional assessmentsR|B for B ∈ B irrespective of whether it is defined by Eqs. (22) or (23). If R is defined by Eq. (22) we deduce that F |B ⊆ R,and as a consequence R is conglomerable, which implies in particular that it satisfies (21). When R is defined by (23), sinceit determines the same conditional assessments, we deduce that it also satisfies (21): if it did not, we should have somegamble f ∈ F |Bsuch that − f ∈ R, and this would contradict the conglomerability of the coherent set of gambles definedby (22).Note also that this does not contradict Proposition 11, because if R is defined by (23) and it is not conglomerable, thenit cannot be maximal, because it is strictly included in the conglomerable coherent set defined by (22).Proposition 13 gives us also an opportunity to simplify the initial notion of (i.e., non-strong) temporal consistency incase of MET-beliefs:Proposition 14. If your current beliefs are given by (22), then temporal consistency holds if and only iff ∈ F B ⇒ − f /∈ F |B.(24)In case they are given by (23) and temporal consistency holds, then condition (24) holds.Proof. Let us show that under (22) temporal consistency is implied by (24). Take f ∈ F BB∈B: B f (cid:10)=0 B f , andfor every B such that B f (cid:10)= 0 it holds that B f ∈ RB ⊆ F B, whence −B f /∈ R|B and as aconsequence B(− f ) /∈ R for all B. Proposition 13 then establishes the necessity of (20). Now, observing that the set in (23)is included in the set in (22), we obtain that necessity holds also under (23). Finally, that temporal consistency implies (24)is trivial under (22) because in that case F |B ⊆ R. (cid:2). We have by (24) that B(− f ) /∈ F |B. Then f =(cid:3)The characterisation of temporal consistency established in Proposition 14 does not hold when your current beliefs arenot constructed by marginal extension:30 They are conglomerable if B is finite, as in this case the sets in (22) and (23) coincide.36M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–51Example 17. Consider Ω := {1, 2, 3, 4}, B := {1, 2}, B := {B, Bc} and let us consider the linear previsions P 1, P 2 on L deter-mined by(cid:6)(cid:6)(cid:6)(cid:6)(cid:7)(cid:7)(cid:7)(cid:7)P 1{1}{4}:= 0.25,Let P := min{P 1, P 2} and define your future commitments for any gamble f by:= 0.25,:= 0.75,{2}{3}P 2P 2P 1:= 0.75.P B ( f ) := 0.5P 1( f |B) + 0.5P 2( f |B) = 0.5 f (1) + 0.5 f (2),+ 0.5P 2P Bc ( f ) := 0.5P 1= 0.5 f (3) + 0.5 f (4).(cid:20)(cid:20)Bc(cid:20)(cid:20)Bc(cid:7)(cid:6)(cid:6)(cid:7)ffLet R be the set of strictly desirable gambles associated to P , and RB , RBc the sets of strictly desirable gambles associ-ated to P B , P Bc . Note that by definition F |Bis included in R, because the partition B is finite, so in this case temporalconsistency implies Eq. (24). Let us show that they are not equivalent.Given the gamble g := 2I{2,3} − I{1,4} it holds thatP B (g) = −0.5 + 2 · 0.5 = 0.5 > 0,P Bc (g) = 0.5 · 2 − 0.5 = 0.5 > 0,whence g ∈ F B; however, P 1(−g) = P 2(−g) = −2 · 0.25 + 1 · 0.75 = 0.25, whenceP (−g) = min{0.25, 0.25} = 0.25 > 0 ⇒ −g ∈ R.are not temporally consistent. To see that Eq. (24) holds, note that if a gamble f belongs to F BThus, R and F Bthen eitherf B or f Bc (or both) is non-zero. Assume for instance that f B is non-zero; the remaining cases are established similarly. Itholds that f B ∈ RB , whence:• either f B (cid:2) 0, and then − f B (cid:3) 0 /∈ R|B ;• or f B (cid:6) 0, and then it must be P B ( f ) = 0.5 f (1) + 0.5 f (2) > 0; if − f B ∈ R|B , then P (−B f B ) = min{−0.75 f (1),−0.25 f (2)} (cid:2) 0, which means that max{ f (1), f (2)} (cid:3) 0 and which contradicts f (1) + f (2) > 0. We conclude thatin this case − f B /∈ R|B either.Thus, when R is not established by marginal extension (24) is not equivalent to temporal consistency.It is possible to simplify further the expression of temporal consistency under MET-beliefs:Proposition 15. Eq. (24) holds if and only if R|B ∪ RB avoids partial loss for all B ∈ B.Proof. Let us focus on the direct implication. Take B ∈ B. Since both R|B and RB are coherent with respect to L(B), we canapply Proposition 8 to conclude that R|B ∪ RB avoids partial loss if and only if g B ∈ RB implies −g B /∈ R|B . Then considerg B ∈ RB , so that B g B ∈ F B, whence −g B /∈ R|B . Consider the converse implication. Take f ∈ F B,(cid:3)B∈B: B g B (cid:10)=0 B g B , with g B ∈ RB for all B. The assumption implies that for all B, −g B /∈ R|B . This implies thatso that f =(cid:3). By (24), B(−g B ) /∈ F |BB∈B: B g B (cid:10)=0 B(−g B ) = − f /∈ F |B. (cid:2)6.3. Event-wise temporal consistencyIf your assessments are expressed by means of coherent sets of gambles, we can also consider a notion of event-wisetemporal consistency, whose rationale is the same as that behind temporal consistency:Definition 30 (Event-wise temporal consistency for gambles). We say that your present and future commitments are event-wisetemporally consistent if R ∪ RB avoids partial loss.As discussed in Section 4.3, this notion is interesting when your future commitments are established after you haveobserved the element B of the partition B. It follows immediately from Proposition 5 that if R ∪ RB avoids sure loss thenthe lower previsions they induce satisfy the corresponding notion of event-wise temporal consistency we have introducedin Section 4.3. A reformulation of event-wise temporal consistency follows immediately in a way similar to the more generalcase of temporal consistency:Proposition 16. The following statements are equivalent:(a) Your present and future commitments satisfy event-wise temporal consistency.(b) R|B ∪ RB avoids partial loss.M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–5137(c) Define RB(cid:11) := { f ∈ L+: f = B(cid:11)f } for all B(cid:11) (cid:10)= B, B(cid:11) ∈ B, and let F Bbe given by (9). Then R ∪ F Bavoids partial loss.Proof. Since R|B ⊆ R and RB ⊆ F B, we deduce that (a) implies (b) and that (c) implies (a). Let us show then that (b)implies (c). Let f ∈ F B, it holds that B f ∈ RB ∪ {0}, Bc f (cid:2) 0. Assume ex-absurdo that − f = −B f −Bc f ∈ R. In this case Bc f (cid:10)= 0, because otherwise −B f = − f ∈ R|B , contradicting our assumptions. As a consequence,Bc f (cid:2) 0 so that R includes the gamble (−B f − Bc f ) + Bc f = −B f ∈ R|B , again contradicting the assumptions. (cid:2). By definition of F BThis proposition makes it clear that event-wise temporal consistency relates only to your beliefs conditional on B, asfar as your current beliefs are concerned. In other words, we can think of event-wise temporal consistency as a weakeningof temporal consistency that focuses only on the subset R|B of R. In a similar way, one can also extend the notion ofevent-wise strong temporal consistency to sets of desirable gambles.6.4. Strong temporal coherenceIf your current and future commitments are established at the same time, then these assessments can affect each other.Moreover, just because the commitments are established at the same time, it would be irrational in particular that con-ditional and future commitments do not cohere with each other. Using strong coherence in Definition 25, we deduce thatF B = F |Bis a rationality requirement in the present setting.For similar reasons, it would be also irrational that the full set of present beliefs R does not cohere with future commit-ments. To this end, the strongest coherence condition that we can apply is one-way strong coherence in the form F |B ⊆ R.This inequality makes sense just because the two sets are established at the same time, so that future commitments canactually affect present beliefs. It is instead not reasonable to impose in addition the opposite inclusion unless it is alreadythe case that you specify R only through conditional information (see Remark 5).We can also see with a simple example why the condition F |B ⊆ R does intuitively make sense. Consider this case:B∈B B g, with B g ∈ R|B ∪ {0} for all B ∈ B, such that g ∈ F |B \ R. As we have discussed inassume that there is g :=Section 3.2, g represents an agreement about the future that you would accept now, and it implies that you will be rewardedby g(ω), whatever ω ∈ Ω comes true. But when you know that accepting the agreement has the same implications for youof accepting g, then this should make you see that g /∈ R is not compatible with your other assessments. This should leadyou to resolve the incoherence, either by making g belong to R or by removing g from F |B. In other words, you shouldagree that it is rational for you that F |B ⊆ R.(cid:3)We are thus led to the following:Definition 31 (Strong temporal coherence). We say that your current and future commitments are strongly temporally coherentif F B = F |B ⊆ R.Strong temporal coherence is a strengthening of strong temporal consistency: it is enough to observe that under strongtemporal coherence R ∪ F |B = R is coherent, and hence it avoids partial loss. More importantly, strong temporal coherenceis equivalent to the conglomerability of R, provided that F B = F |B.As we have already said, it appears to be the first time that conglomerability is obtained out of finitary considerationsas in this case. Walley, for instance, has repeatedly argued in favour of conglomerability [67, Section 6.8.4], but the supportthat he gave to it appears eventually to go back to the idea that one should allow countably many transactions to be made(see, for instance, the penultimate paragraph in page 320 of Walley’s book [67], or note 13 to Section 6.9 in the same book;other argumentations in [67, Section 6.8.4] are based on the use of the so-called ‘conglomerative principle’, which lies at thebasis of his notion of coherence, and which involves the sum of infinitely many gambles). In contrast, our setup is finitary inthat respect: all the coherence conditions we deal with are eventually based on the natural extension, which involves onlyfinitely many transactions; and moreover, even though F Bis defined through sums that may be infinite, the transactionsrelated to elements of F Balways involve finitely many gambles. And yet, as we have shown, a coherence condition togetherwith the availability of future commitments can make it.We should be careful in establishing the scope of our claim that conglomerability should be taken as a rationality re-quirement. The notion of conglomerability is important and it has been the subject of much controversy since its earlydefinition by de Finetti [9]: the controversy concerns precisely whether or not it is rational to impose conglomerability.Our standpoint is the following: conglomerability should be regarded as a rationality requirement when present beliefsand future commitments are established at the same point in time, for the reasons discussed above. We do not claim thatconglomerability should be imposed more generally than this. In particular, we do not see reasons to impose conglomer-ability in the setups where your future commitments are established after your present beliefs.31 For similar reasons, we donot support requiring conglomerability in probabilistic models whenever these are not used to constrain future behaviour:31 However, in some of those cases it may be rational to impose disintegrability when working with precise models, see Section 4.5 (in particular thediscussion after Theorem 3).38M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–51for example, when a model is used only in the unconditional case, or when it is used in the conditional case under thecontingent interpretation.Despite our claim lives within the special frame indicated above, it should not be overlooked that its scope remains quitewide. For example, it is a common statistical practice to interpret conditional beliefs as future commitments, as if it were asort of ‘default’ case; and in that case, our claim applies. This implies that by taking such a practice seriously, in statisticsone should always work with conglomerable models. This is straightforward to do when the partition B is finite (and this isobviously the case for finite Ω ), because conglomerability holds automatically in that case, as a consequence of axiom D4,or by the super-additivity of coherent lower previsions. In other words, in this case, we have the remarkable result thatstrong temporal coherence is equivalent to F B = F |B, that is, the equality of future commitments with conditional beliefs.On the other hand, statistics is very often concerned with infinite partitions and in this case working with conglomerablemodels can be mathematically very involved. This has recently become even clearer [43]; more work is needed to addressthis problem. Alternatively, one might want to question the default case mentioned above. Some discussion in this sensecan be found for instance in [67, Section 6.11.1] (see also Section 8). This could lead one, in some statistical problems, toprefer temporal consistency (or even event-wise temporal consistency) to strong temporal coherence.Strong temporal coherence implies that R ∪ F |Bis coherent. This gives us some motivation to study the next coherencecondition:Definition 32 (Temporal coherence for gambles). We say that your current and future commitments are temporally coherent ifF B = F |Band R ∪ F |Bis coherent.Temporal coherence is different from strong temporal consistency because it may happen that R ∪ F |Bavoids partialloss but it is not coherent, as shown in [43, Example 7]. On the other hand, temporal coherence is also different from strongtemporal coherence because we may have R (cid:5) F |B, as in [43, Example 2]; however, when R is a set of strictly desirablegambles, both conditions are equivalent, as we can see from Theorem 2.In the case of lower previsions, temporal coherence and the corresponding notion for lower previsions coincide: remem-ber, from Proposition 6, that F B = F |Bmeans that your future commitments must be specified by E(·|B), the conditionalnatural extension of P ; this, together with Theorem 2, shows that if you express your current and future commitments bymeans of lower previsions, they are temporally coherent if and only if the sets of strictly desirable gambles they induce are.More generally speaking, we can show that temporal coherence leads to some surprising facts. To this end, observethat temporal coherence holds trivially when either R ⊆ F |Bor F |B ⊆ R. It is useful to understand whether there arepossibilities other than these in order to comply with temporal coherence. The situation is established in the followinglemma:Lemma 2. Let R be a coherent set of desirable gambles and let F |Bbe the set of conditional gambles it induces. ThenR, F |Btemporally coherent ⇒ R ⊆ F |Bor F |B ⊆ R.Proof. Assume ex-absurdo that R, F |Bf ∈ F |B \ R, whence P ( f ) < 0. Take on the other hand g ∈ R \ F |Bit does not belong to F |Bthere is some B ∈ B such that B g /∈ R|B ∪ {0}.(cid:11)Let us consider the gamble f 1 := Bc f . Then Bshould have f = B f ∈ R, a contradiction. As a consequence, f 1 ∈ F |Bf 1 ∈ R|B(cid:11) ∪ {0} for every Bare temporally coherent and that R (cid:4) F |Band F |B (cid:4) R. Then there is a gamble. Then since g ∈ R we deduce that P (g) (cid:2) 0, and since(cid:11) ∈ B, and moreover it cannot be f 1 = 0 or we, and therefore λ f 1 ∈ F |Bfor all λ > 0. Moreover,P ( f 1) = P ( f − B f ) (cid:3) P ( f ) + P (−B f ) = P ( f ) − P (B f ) < 0,because P ( f ) < 0 and P (B f ) (cid:2) 0 taking into account that B f ∈ R|B ∪ {0}. Define h := λ f 1 + g ∈ posi(R ∪ F |B). Then it holdsthatBh = B(λ f 1 + g) = B g /∈ R|B ∪ {0} ⇒ h /∈ F |B,andP (h) = P (λ f 1 + g) (cid:3) P (λ f 1) + P (g) = λP ( f 1) + P (g) < 0 for λ > − P (g)P ( f 1).Hence, for λ big enough P (h) < 0, whence h does not belong to R either. As a consequence, posi(R ∪ F |B) (cid:10)= R ∪ F |Btherefore R, F |Bare not temporally coherent, a contradiction. (cid:2)andThis result holds for any coherent set of desirable gambles R, not necessarily strictly desirable ones. Remarkably, whenR is a coherent set of strictly desirable gambles the inclusion F B ⊆ R is equivalent to the inclusion F B ⊆ R, i.e., to theconglomerability of R [43, Theorem 2]. We see then that in the case of strict desirability the notion of temporal coherencecoincides with strong temporal coherence, taking into account that in such a special case R ⊆ F |Bholds trivially only whenM. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–5139R = L+of strict desirability was indeed already proved in Theorem 2.so that the first inclusion is sufficient to describe all the cases. The fact that those two notions coincide in the caseWe shall next argue that temporal coherence is not a suitable notion for the more general framework where you defineyour commitments through sets of (not necessarily strictly) desirable gambles. This is the case because strong temporalcoherence is indeed stronger than temporal coherence when R is not a set of strictly desirable gambles; temporal coherenceis rather an intermediate notion between the conglomerability of R and that of R (the latter being the set of strictlydesirable gambles associated to R).Theorem 5. Let R be a coherent set of gambles, and let F |Bbe its associated conditional set of gambles. ThenR conglomerable ⇒ R ∪ F |Bcoherent ⇒ R conglomerable.is included in R, whence R ∪ F |B = R isProof. To see the first implication, note that if R is conglomerable then F |Bcoherent.To see the second implication, assume that R ∪ F |Bis coherent. Then, taking into account Lemma 2, we have twopossibilities:• the first is that R ⊆ F |B; then for every f ∈ R and every B ∈ B, it holds that B f ∈ R ∪ {0}. Let P be the coherentlower prevision induced by R. Then for every k > 0 it holds thatP (IB − kIBc ) (cid:2) P (B) + P (−kIBc ) = P (B) − k P(cid:6)(cid:7),Bcand this is positive for k small enough provided that P (B) > 0. But in that case we should have a gamble f := IB − kIBc(cid:11) (cid:10)= B, a contradiction. Hence, it must be P (B) = 0 for every B, whence P isin R such that Btrivially conglomerable and as a consequence R is conglomerable by [43, Theorem 3].f /∈ R ∪ {0} for any B• The second possibility is that F |B ⊆ R; in that case applying [43, Theorem 2] we deduce that R is conglomerable. (cid:2)(cid:11)The converse implications in the above result do not hold in general:Example 18. To see that temporal coherence does not imply conglomerability, note that it may happen that R is a propersubset of F |Bis coherent, but this set wouldnot be included in R and therefore the latter would not be conglomerable. An example of such a situation can be found in[43, Example 2].; in that case, temporal coherence would hold trivially because R ∪ F |B = F |BTo see that the conglomerability of R does not imply temporal coherence, consider the set N of positive natural numbers,Ω := N, Bn := {2n − 1, 2n}, B := {Bn: n ∈ N} and P a finitely additive probability satisfying P ({n}) = 0 for every n, P (Iodd) =0.25. Consider R := R1 ∪ R2, for R1 := { f : P ( f ) > 0} and R2 := { f : P ( f ) = 0, ∃n f ∈ N s.t. f In f → (cid:2) 0,n f (n) > 0},where n f → denotes the set {n ∈ N: n (cid:2) n f }.Then R includes any gamble f ∈ L+. If P ( f ) > 0, thenf ∈ R1; if P ( f ) = 0, then f ∈ R2, taking n f = 1 and using that f (cid:10)= 0. Applying (18), it follows that R lies between the setof strictly desirable gambles and that of almost-desirable gambles associated to P .: it follows from the coherence of P that P ( f ) (cid:2) 0 ∀ f ∈ L+Both R1 and R2 are cones that do not include the zero gamble, so to see that the zero gamble does not belong toposi(R) it suffices to see that it cannot be expressed as the sum of a gamble of R1 with a gamble from R2. But if we takef ∈ R1, g ∈ R2, we have that P ( f + g) = P ( f ) + P (g) > 0, so it cannot be f + g = 0. Hence, posi(R) is a coherent set ofgambles inducing P .Since P (Bn) = 0 for every n, we deduce that P is trivially conglomerable and as a consequence R is conglomerable.. However, P ( f ) =incurs partial loss and as a consequence it is notHowever, given the gamble f := 2Iodd − Ieven, it holds that Bn f ∈ R for every n ∈ N, whence f ∈ F |B−0.25 < 0, whence − f ∈ R. Hence, 0 ∈ posi(R ∪ F |B), whence R ∪ F |Bcoherent.(cid:3)In other words, in the general case, temporal coherence no longer implies that F |B ⊆ R. This means that it is no longersuited to prevent you from incurring the (second) kind of irrationality across your current and future commitments that wehave illustrated at the beginning of this section. In the case of general desirability it is then necessary to impose the notionof (one-way) strong temporal coherence.A geometrical interpretation of temporal coherence can help us to better see the specific features, and weaknesses forthe case of general desirability, of such a notion. In particular, Corollary 6 in Appendix A implies that for temporal coherenceit is necessary that(cid:6)M(R) ∪ Mis convex.F |B(25)(cid:7)It follows from this that the lower prevision corresponding to the credal set M(R) ∩ M(F |B) must agree withmax{P , P (·|B)} (see Proposition 20 in Appendix A). This condition is sufficient only when both R and F |Bare sets of40M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–51strictly desirable gambles; however, F |Bwill never be a set of strictly desirable gambles as soon as we have an infinitenumber of sets {Bn}n in B such that RBn is different from L+(Bn), even if all these are sets of strictly desirable gambles:n ) for every n, and then their sumfor, in that case, we could select a gamble f Bnf would belong to F B\ L+(Bn) such that P (Bn f Bn ) ∈ (0, 1even if f − ε does not belong to F |Bfor any ε > 0.∈ RBnThat condition (25) is a very peculiar one to comply with, can also be seen if we exclude the cases where one of thetwo sets is included in the other, which we have identified at the beginning of this section as the two possible one-waystrong coherence conditions applied to R and F B. The remaining case is characterised by two convex sets that partiallyoverlap32 and whose union is naturally convex too. This situation is quite constraining, as it can easily be verified withsimple examples in the three-dimensional space. As a side remark, note how the difference in the respective necessaryconditions makes it clear that temporal coherence is much more of a stringent condition than strong temporal consistency.Moreover, it is difficult to find a ‘temporal’ meaning to condition (25) in the case just discussed. In our view, thisappears to be saying that temporal coherence is meaningful when it coincides with a strong coherence condition, and thatit is hardly so otherwise. In summary, we regard strong temporal coherence as the essential notion of coherence for thecase where you establish your present and future commitments at the same time.6.5. The precise caseThe above notions can also be applied to sets of gambles inducing precise conditional and unconditional previsions.When these sets of gambles are strictly desirable, we can establish a tight relationship with disintegrability:Proposition 17. Assume that R is a set of strictly desirable gambles that induces the linear prevision P . Assume, in addition, that yourfuture commitments F Binduce a linear future prevision P B. Then:R, F Btemporally consistent ⇒ P disintegrable ⇒ R, F |Btemporally consistent.As a consequence, if in addition F B = F |Bthen R, F Bare temporally consistent if and only if P is disintegrable.1 , where F BProof. The first implication follows from Theorem 3, taking into account that if R, F Bare temporally consistent so areR, F B1 is the conglomerable natural extension of the strictly desirable gambles associated to P B. The secondfollows from Theorem 2, taking into account that the disintegrability of P implies its conglomerability, and from [43, Theo-rem 3]. The second statement is an immediate consequence of the first. (cid:2)More in general, we can apply the notions of temporal consistency and coherence to sets of gambles that are notnecessarily strictly desirable. In that case, we can establish the following:Proposition 18. Let R, F BP , P B. Then:be coherent sets of desirable gambles such that they induce linear unconditional and future previsionsR ∪ F Bcoherent ⇒ R ∪ F Bavoids partial loss ⇒ P , P B coherent.Proof. That the first condition implies the second is trivial; the second implies that R ∪ F BTheorem 4 P , P B avoid sure loss, and since they are linear this means that they are coherent. (cid:2)avoids sure loss, whence byHowever, the above implications are not equivalences: on the one hand, the sets of current and future commitments inExample 14 induce coherent linear previsions but their union incurs partial loss. To see that the avoiding partial loss ofR ∪ F Bdoes not imply its coherence, consider the following example:(cid:4)Example 19. Consider Ω := {1, 2, 3, 4}, B := {1, 2}, B := {B, Bc}, and the set R of current beliefs given by(cid:5)f ∈ L(Ω): f (1) + f (2) + f (3) + f (4) > 0∪f ∈ L(Ω): f (1) + f (2) + f (3) + f (4) = 0, min(cid:5)f (1), f (3)> 0(cid:4)(cid:4)(cid:5)and let your future commitments be given byRB :=RBc :=(cid:4)(cid:5)f ∈ L(Ω): f = B f , f (1) + f (2) > 0 or f (1) = − f (2) < 0(cid:4)f ∈ L(Ω): f = Bc f , f (3) + f (4) > 0(cid:5).,32 They overlap because temporal coherence implies temporal consistency, and for the latter to hold it is necessary that M(R) ∩ M(F |B) (cid:10)= ∅ (seeTheorem 4(b)).M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–5141Then R induces the linear prevision associated to the uniform distribution on Ω , and F BP B derived from R by means of Bayes’ rule. To see that R ∪ F B(cid:5)f ∈ L(Ω): f (1) + f (2) + f (3) + f (4) > 0(cid:5)f ∈ L(Ω): f (1) + f (2) + f (3) + f (4) = 0, f (3) (cid:2) 0R ∪ F B ⊆(cid:4)\ {0},∪(cid:4)avoids partial loss, note thatinduces the conditional previsionand that the set on the right-hand side is coherent. To see on the other hand that R ∪ F Bf := (1, −3, 1, 1) ∈ R and g := (−1, 1, 0, 0) ∈ F B, their sum is f + g = (0, −2, 1, 1), which does not belong to R ∪ F Bis not coherent, note that given.A straightforward deduction could then be that the precise case differs from the case of desirable gambles to that of pre-visions, which was discussed in Section 4.5. This is particularly evident from the fact that the implications in Proposition 18were equivalences in Theorem 3. But this conclusion is based on the precision (or linearity) of the previsions that can bederived from a set of desirable gambles. This is not the precision of the set itself: the latter is rather the completeness, ormaximality, of the set. By assuming that the involved sets are maximal, and considering the setting of event-wise temporalconsistency, we obtain a very interesting outcome:Proposition 19. Let your current and future commitments R, RB be event-wise temporally consistent. Assume in addition that Rand RB := { f B ∈ L(B): B f B ∈ RB } are both maximal. Then it holds that RB = R|B .33Proof. First, note that if R is maximal, then so is R|B : indeed, if there is f B (cid:10)= 0 such that f B /∈ R|B , then B f B /∈ R; themaximality of R implies that −B f B ∈ R and hence − f B ∈ R|B .Now, assume ex-absurdo that RB (cid:10)= R|B , and in particular that there is a non-zero gamble f = B f such that f ∈ RB andf /∈ R|B . Since R|B is maximal, − f ∈ R|B ⊆ R and this contradicts that R∪RB avoids partial loss. It follows that RB ⊂ R|B .Then there is a non-zero gamble f = B f such that f ∈ R|B ⊆ R and f /∈ RB . But since RB is maximal, − f ∈ RB and wecontradict again that R ∪ RB avoids partial loss. We deduce that under event-wise temporal consistency, it holds thatRB = R|B . (cid:2)This tells us that, once we use the proper condition of precision for desirable gambles, future commitments should beequal to conditional beliefs even under the weakest consistency notion of this paper. This leads us to replay the reasoningin Section 4.5: since conditioning is the only (event-wise) temporally consistent rule in the case of maximal sets, whyshould one postpone the task of assessing future commitments? Being maximal (i.e., Bayesian) together with conceding—right now—that future commitments might differ from conditional beliefs appears irrational. As a consequence, we obtainthat strong temporal coherence becomes a rationality requirement whenever we stick to using maximal sets. This meansthat in the case of maximal sets it holds that: (i) conditioning is the only rule to compute future commitments; (ii) andthat R must be conglomerable. Moreover, taking into account Proposition 11, we obtain a result similar to Corollary 3—yetwithout assuming that probabilities be positive:Corollary 5. Let R be a maximal set of desirable gambles representing your current beliefs, and let F B = F |Bconditions are equivalent:. Then the following(a) R, F B(b) R, F B(c) R, F B(d) R is conglomerable.are temporally consistent.are strongly temporally consistent.are strongly temporally coherent.7. Relationship with other approachesIn this section, we consider a number of other approaches that relate probability and time, and discuss their connectionwith the work we have carried out in this paper.7.1. Dynamic coherenceThis paper is related to the work on dynamic coherence carried out by Skyrms [58–60] and Armendt [2,3], among others,and with a strong influence from Ramsey’s work [47] (see also [17,30] for other references on this topic). These authorsjustify the rationality of a temporal updating principle by means of the impossibility of building a book against it, and inthis way they support Bayes’ rule of conditioning, as well as Jeffrey’s and van Fraassen’s rules we shall discuss later on. They33 Strictly speaking, the notion of maximality does not hold for the sets R|B and RB , because we can add gambles to them keeping their coherence; itapplies instead to their counterparts R|B and RB ; it is this simple technical reason that makes us introduce the latter sets in the propostion.42M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–51distinguish between two concepts of coherence: the static or synchronic one, where your present and future commitmentsare all established at the same time, and where coherence can be justified using de Finetti’s or Ramsey’s arguments; andthe dynamic or diachronic one, where your present and future commitments are established at different times. In this case,the use of a book argument (i.e., of a finite combination of acceptable gambles that yields a sure loss) has been criticised byMaher [38] and Levi [36,37], among others (see [3] for a response to some of these criticisms). A diachronic book argumentwas first proposed by David Lewis in order to justify Bayesian updating, as reported by Teller [62, note 1 to Section 1.3].That dynamic coherence is closely related in spirit to the present work is clear if we reconsider the ideas behind temporalconsistency and coherence: in the first, we have considered that your future commitments are established later than presentbeliefs, and as a consequence we are considering a diachronic argument, in the above language; in the second, instead, weassume that your present and future commitments are established together, and hence we are in the synchronic framework.On the other hand, our work is more general than dynamic coherence in three ways: first, we are allowing for an im-precise model of your assessments, which allows us to apply our results in cases of uncertain or indeterminate information;second, in our formalisation we are allowing for infinite partitions of the set of outcomes, and as a consequence we haverelated our approach to the notions of conglomerability and disintegrability; and finally, we have moved away from the lan-guage of previsions (or probabilities) into the richer language of sets of desirable gambles. This has implications, for instance,for the type of losses we need to consider, which are partial rather than sure as in the traditional book approach. Moreover,it has implications in that we are not led to conclude in general that rationality requires computing future commitments byconditioning (we comment on this to a wider extent in Section 8).7.2. Probability kinematicsAn interesting and useful approach to compute future commitments was provided by Richard Jeffrey in his celebratedtheory of probability kinematics [29,31] (see also [13]). Jeffrey’s rule is defined in the following way.Consider a countable partition B := {Bn: n ∈ N} of the set of outcomes Ω of the experiment, each of them with positiveprobability, and let P 0 be your current probability model. Suppose you are interested in an event A ⊆ Ω , and that afterdefining P 0, you receive some evidence that leads you to revise your probabilities P 0(Bn) (n ∈ N) into new (or posterior)probabilities P 1(Bn), without changing your conditional probabilities: that is, P 0( A|Bn) = P 1( A|Bn) for all n. In this caseyour probabilities are said to satisfy probability kinematics, and your posterior probability for A should be defined asP 1( A) :=(cid:8)nP 0( A|Bn)P 1(Bn).Jeffrey’s rule is useful when the new evidence represents an uncertain observation about B, rather than coinciding with anevent of such a partition. If in particular your unconditional commitments do not change in time, i.e., if P 1(Bn) = P 0(Bn)for all n, we recover the law of total probability, and therefore this can be regarded as generalising Bayesian updating (andin particular the idea of using Bayes’ rule to compute future commitments). Remark also on the assumption of positivity ofunconditional probabilities, which is formally related to our comments in Section 4.5.Jeffrey’s approach is dual to ours, in the following sense: while we allow future commitments to differ from the con-ditional ones and the unconditional beliefs are determined only at the present time, Jeffrey requires that the conditionalprobabilities should not change in time, but allows the unconditional ones to be modified in the light of new evidence. Still,in [2] and [58], it has been argued in favour of probability kinematics by means of dynamic coherence.7.3. The temporal sure thing and reflection principlesTwo very related approaches to the work carried out in this paper are due to Goldstein [21–23] and van Fraassen [65,66].Goldstein [21,23] required your current and future beliefs to satisfy the temporal sure thing principle:“Suppose that you have a sure preference for A over B at (future) time t. Then you should not have a strict preferencefor B over A now”.In our language, the temporal sure preference principle states that if you knew that fis desirable to you in the future,then you should not desire − f now, which is in clear connection with Eq. (20) in Proposition 8 (it is not exactly the samebecause the underlying notion we are concerned with is avoiding partial loss, which is stronger than the book-equivalentidea of avoiding sure loss).Now, if we denote by P 0 your current probability model and by P 1(·|B) your future probability model conditional onthe observation of some evidence, the temporal sure thing principle implies [21, Section 3] that your current model shouldsatisfyP 0( f ) = P 0(cid:6)(cid:7)P 1( f |B)for every gamble f .Around the time of Goldstein’s initial proposal, van Fraassen [65, p. 244] established his reflection principle:(26)M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–5143“My current probability for an event A, conditional that at some later time I assign A probability r, should also be equalto r,”which can be expressed mathematically also as(cid:7)(cid:6)P oA|P 1( A) = r= r.(27)Van Fraassen also allows for vague assessments in [66], determining then a general reflection principle:“My current opinion about event E must lie in the range spanned by the possible opinions I may come to have about Eat some later time t, as far as my present opinion is concerned.”This general principle yields Eq. (27) in the particular case of precise probabilities.Both these approaches are related, like ours, to the impossibility of building a book against you using your currentand future commitments.34 However, their focus is on the current beliefs, and future beliefs are treated as some uncertainquantity. This is very clear by the way van Fraassen ends his principle: ‘as far as my present opinion is concerned’ (for similarreasons, van Fraassen says in [65] that we may speak of a Dutch strategy instead of a Dutch book). In other words, all theseprinciples determine how your current beliefs should be related to the future ones, if you knew them. On the contrary, ourfocus is on a time where your current and future commitments have already been established, so the latter do not act asuncertain objects for us. Hence, even if their formula of time consistency (26) looks basically identical to our Eq. (14), thetwo of them are saying very different things. In particular, since Goldstein and van Fraassen regard future commitmentsas uncertain quantities, claims about them are made through expectations. Stated differently, Eq. (26) is actually concernedwith a consistency property of current beliefs alone, that cannot prevent you from incurring a temporal sure loss. In contrast,endorsing Eq. (14) does prevent you from incurring a sure loss. For this to be possible, however, future commitments mustbe known, as we indeed assume in this paper.Another difference between our work and Goldstein’s is related to conglomerability. In fact, Goldstein maintains thathis approach does not imply the conglomerability of present beliefs and in fact he supports finitely additive models. Thisclaim has originated some controversy. We can find Walley, for instance, deducing that Eq. (26) does lead to the conglom-erability of present beliefs (see [67, note 11 to Section 6.5]); and other researchers who have criticised Goldstein’s temporalsure preference principle as incompatible with finite additivity, that is, non-conglomerable models (see [32, Section 2.3];Goldstein’s reply is in [24], and renewed criticism is in [33]). On the other hand, our notion of strong temporal coherenceleads to conglomerability; more generally speaking, in the case of precise probability the relationship of our approach todisintegrability is very tight even under much weaker notions than strong temporal coherence.7.4. The work of Shafer, Gillet and ScherlIn an interesting paper [56], Shafer, Gillet and Scherl use a dynamic approach to justify Walley’s updating rule as atemporal rule.35 This work has some points in common with the work we have carried out here, such as, for instance, thedistinction of different time periods for the establishment of future commitments. On the other hand, their approach isbased on Shafer and Vovk’s [57] two-player reinterpretation of de Finetti’s and Walley’s subjective approach to probability.The idea is to consider the process of assessing subjective probabilities as a game between two players: House, whichdetermines the probabilities of certain events, and Gambler, the one that determines the stakes at which he is disposed tobet on the different events. A third player, called Reality, can be used to determine what are the events that actually happenin the end. In our language you play the role of House while Gambler is an opponent of yours. Shafer, Gillet and Scherluse two different approaches to establish the consistency of your assessments: the first relates to the common idea of thebook, that is, to avoiding losses; the second is more peculiar to Shafer and Vovk’s game-theoretic probability and is calledCournot’s principle. According to the latter, and loosely speaking, the probabilities can be seen as consistent when it is notpossible for Gambler to exploit them in order to become infinitely rich without risking bankruptcy. It is a principle thatrelates to a long-run interpretation of probability and that allows the authors to draw stronger conclusions than those theyachieve by the book-based consistency.One of the aims in [56] is to see how probabilities should be temporally updated. The authors consider both the precise(in Section 1) and the imprecise (in Section 2) cases, and also distinguish the case where you have exact information [55],which means that all you know in the future is the event B ∈ B that is observed (and that coincides with our case inthis paper), or when you can have additional information besides B. They show that under some conditions, which roughly34 See also [22,66] for other justifications of these principles.35 Shafer, Gillet and Scherl appear to regard Walley’s updating interpretation of conditioning as defining a temporal setting—one that prescribes computingfuture beliefs out of present ones by conditioning—, and then try to justify it accordingly (this was already pointed out in [7, footnote 10 in p. 1408]). Inour view, Walley’s updating interpretation of conditioning is instead only concerned with your current beliefs under the assumption that event B occurs.The justification of this interpretation of updating is already in Walley’s theory, and it follows in particular from the axioms D1–D4 of desirability throughhis ‘updating principle’.44M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–51coincide with our strong temporal coherence setup, updating beliefs by means of Walley’s GBR is consistent in their sense;then they try to make the case also for information that is not exact (Section 2.4) and conclude that a particular case oftemporal consistency must be satisfied.With respect to that work, there are a few novelties in our paper:• While in [56] it is assumed that updating is made by means of GBR and afterwards it is justified that this is consistentunder some conditions, in our paper we make no assumptions about how the future commitments are established; inparticular, we show that there are several other possibilities satisfying temporal consistency, and that even when youestablish your future commitments in advance, as in the case of temporal coherence, there are other possible rulescompatible with our consistency notions (such as the regular extension).• Our treatment allows for infinite partitions of future events, whereas only finite partitions are considered in [56]. Thisis what has allowed us to deal with the notion of conglomerability.• Moreover, in [56] it is assumed that all the conditional events have positive lower probability, which is not the case inthis paper.Remark 6. It is also interesting to consider a more subtle difference between the two approaches. In [56, Section 1.6]the authors claim that Bayes’ rule cannot be derived in the precise case when future commitments are established aftercurrent beliefs. This seems to follow from the impossibility of Gambler to know the future prices at the time when presentcommitments are effective: in fact, to make you undergo a loss, Gambler must design two bets, one for present and onefor future commitments, that act jointly to that end. On the other hand, in the analogous case in our paper (temporal, orevent-wise temporal, consistency), we instead do derive Bayes’ rule—provided that probabilities are positive. This is the casebecause we do not stress as much as in [56] the operational nature of the game: for us it is enough that an inconsistencyis possible in order to exclude the corresponding rule; we do not enforce that there should be an actual protocol by whichan opponent could exploit it. Notice, however, that also Shafer, Gillet and Scherl eventually rule out those inconsistencies(in Section 1.7) and derive Bayes’ rule, by invoking Cournot’s principle.7.5. Belief revisionIt is also interesting to comment on the connection between our approach and the work on belief revision developedamong others by Gärdenfors in [18] (see also [1]). Roughly speaking, belief revision refers to the general process by whichyou modify your belief model to keep it up to date with the information you access (in particular, belief revision has beengiven a temporal interpretation by means of temporal logic [5] or dynamic doxastic logic [50,64]). For more information onthis topic, we recommend Peppas’ gentle introduction to the field [46] and also the web site http://www.beliefrevision.org/.In Gärdenfors’ view, three basic procedures are relevant when changes in a belief model are concerned: expansion,where you add a new element to your belief set that is consistent with it; contraction, where you remove one elementfrom the belief set; and revision, where you add a new element to your belief set that is inconsistent with the latter. Inany of these cases, the modifications in your belief set should be made so that it remains logically consistent: this means,as a consequence, that when belief revision is performed, some elements of the belief set must be removed in order tomaintain consistency. Moreover, the underlying rationale is that the removal of some elements should be made so as tomake a minimal change to the preexisting belief set. This gives rise to a number of axioms, first introduced by Alchourrón,Gärdenfors and Makinson in [1], producing the so-called AGM models.The AGM axioms have been originally put forward in a logical context, where knowledge is represented by sentencesfrom a certain language L. There have been attempts to extend them to probability (even in the seminal book by Gärden-fors), but many of these attempts seem to have faced the limitations of not being able to fully deal with probability as alogic. This can be overcome by representing probability through desirable gambles, which, as we have argued already, hasa very direct connection with logic. In particular, de Cooman shows in [6] how some of the AGM axioms can be extendedvery naturally to an imprecise probability scenario by using desirability. Some earlier work on the same line of researchwas made by Moral and Wilson [44] (other work connecting imprecise probability and belief revision has been carried out,among others, by Dubois and Prade in the framework of possibility measures [15,16]).Regarding the work in this paper, at the moment we do not see a direct relationship with belief revision.36 Althoughwe have considered two sets of assessments established at (possibly) different points in time, the problem we have studiedis that of characterising consistency across the two sets, and this is not a problem of belief revision. In particular, for themost part we are not interested nor give guidelines as to how to modify your set of current beliefs in the light of the eventB: we just concentrate on characterising all the possible temporally consistent, or coherent, changes; as a consequence, weare certainly not focused in particular on minimal changes. This point is probably what marks the most significant difference36 A distinction was made by Katsuno and Mendelzon [34] between belief revision and belief updating: the latter applies when you have additionalevidence that transforms your set of possible worlds, and in that case traditional techniques of belief revision are no longer applicable. The approach wefollow in this paper cannot be easily linked to Katsuno and Mendelzon’s work either: see [56, Section 4.3] for a related discussion in the context of Shaferet al.’s approach, which is very similar in spirit to ours.M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–5145from belief revision (at least from the one originally formulated by Gärdenfors). As we understand it, the rationale of doing aminimal change originates from the underlying idea that the original belief set is correct, or stable, before accessing the newinformation; therefore it should be preserved as much as possible while incorporating new information. Our setup is insteadconceived to accommodate also situations where your current beliefs may have been roughly specified, for instance for lackof time, and thus can be (and it is actually desirable that they are) subject even to big changes if there is additional time totake the available evidence more carefully into consideration. More generally speaking, even the founding idea of ‘rationalchange’ in belief revision does not seem to directly apply to our setup: in our setup every change may be reasonable insome situation,37 sometimes even changes that are not temporally consistent, simply because current beliefs may have beeninaccurately specified.Note, moreover, that even if present and future commitments satisfy the appropriate consistency notion for the situation(temporal consistency, temporal coherence or event-wise temporal consistency, depending on when the future commitmentsare established), we are not concerned with the task of enlarging the set of beliefs so as to accommodate both: the idea israther to drop the current beliefs in favour of the future commitments.The only place where we appear to be closer to a belief revision problem is when we briefly study how to modifyyour assessments when temporal consistency is violated (Sections 4.1.1 and 6.1), and that could be seen as a procedure ofbelief contraction. However, our approach is slightly different from belief contraction, for a number of reasons: instead ofmodifying the union of the set of current and future commitments in order to remove the inconsistent gambles, we see thatit is more productive to investigate how the set of future commitments can be contracted in order to obtain consistencywith the set of current beliefs (the reason why this second problem is interesting in our approach is that in the case oftemporal consistency, current beliefs cannot be modified after they are established and before event B occurs). We showthat there is not in general an optimal way of doing so, which in our context means that there is not a greatest subset ofthe future commitments satisfying temporal consistency. This links to the well-known fact within the belief revision theorythat contraction is not always possible under the assumption of a minimal change, for which a number of solutions havebeen proposed (see [46] for information and references). However, and perhaps surprisingly, we do show that in the case ofmaximal (i.e., precise) desirability assessments, there may exist an optimal correction (see in particular Proposition 10 andCorollary 4).Another special trait of our work is the structure of the set F Bof future commitments. We recall that this is not aset of commitments that you hold at some point in time; it is rather a summary of different sets of commitments RBthat become effective depending on the element B ∈ B that comes true (see Section 3.1). This is another difference withrespect to belief revision, where the set that is produced after the changes is a new set of beliefs. And yet F Bis reallya fundamental concept in order to define appropriate consistency notions across present and future commitments: it isthe very structure of F Bthat allows us to properly define the losses (to avoid) whenever the partition B is infinite; it ismoreover the structure of F Bthat has allowed us to find a finitary justification for the notion of conglomerability.On the other hand, and despite the differences that we currently see between belief revision and our work, we find thatmany aspects of their relationship are still unclear; moreover, we are aware that we may well have missed contributions inthe vast literature of belief revision that might have changed our mind about some of the aspects we have been commentingon. For these reasons, we think it would be useful to study more deeply the interplay of the ideas in this work and in theliterature of belief revision.8. Concluding remarks and future outlooksIn this section we would like to discuss what we think we have understood after the analysis we have carried out in thispaper. We recall that our focus has been on developing mathematical tools to characterise whether or not your probabilisticassessments are consistent in time. We have restricted the attention in particular to the simplest situation made of twotime points: now, and a subsequent point that depends on the observation of an event B in a partition B of the possibilityspace Ω . We have represented your current beliefs by a set of desirable gambles R (or by the special case made of acoherent lower prevision P ). We have assumed, in addition, that after B occurs, you will hold new commitments, thusdropping R, and that these ‘future commitments’ are known. Moreover, we have found it useful to consider three timeperiods when you might establish your future commitments: now, later but before B occurs, after B occurs.The case where you establish your future commitments now, together with your current beliefs, is the one closest inspirit to the traditional probabilistic, and statistical, setup. We have argued that in this case rationality should lead youto apply a strong temporal coherence condition. From this, we have deduced that your model of present beliefs should beconglomerable. This result is meaningful because it provides for the first time, in our knowledge, a justification of conglom-erability obtained through considerations of temporal coherence, where the coherence notion is—in a definite sense—finitary.This has been surprising to ourselves in the first place, because conglomerability is a non-finitary concept. Most importantly,such a feature of our approach seems to provide new elements to settle the 83-years-long, and still on-going, controversyabout whether or not conglomerability should be imposed on probabilistic models.37 Provided that we are not focusing on strong temporal coherence or on precise beliefs, as rationality imposes very tight constraints in these cases.46M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–51Another important question affected by strong temporal coherence is that of the choice of the ‘rule to update beliefs’under imprecise probability. Here we should clearly distinguish two situations. If by updating beliefs we mean the traditionalupdating interpretation of conditioning—the one that is not really concerned with future commitments—, then the questionwas already thoroughly analysed and discussed by Walley: the only updating rule supported by (non-temporal) coherencearguments is conditioning.38 This means using the generalised Bayes rule in case the conditioning event has positive lowerprobability (and hence Bayes’ rule in the precise case). When this is not the case, the choice is wider but it can still beformulated as conditioning a coherent set of desirable gambles (see Definition 12). If, on the other hand, by updating beliefswe mean a temporal setting that involves future commitments established at present time, then we can use the analysis inthis paper to deduce that also in this case there is only one choice: again, that of conditioning.39Let us remark once again that these results are obtained in the specific case where you establish your future commit-ments now, together with present beliefs, and that you are in fact committed to them, in the sense that they will constrainyour future behaviour. When could this be the case in practice? Most probably this would happen when you create yourpresent uncertainty model carefully, that is, doing your best effort to examine the available evidence and formalise yourcurrent beliefs. In this situation, you would probably exclude that the availability of extra time to reason could lead you tochange significantly your uncertainty model in absence of new information (remember that in this paper we assume thatthe only new information you will receive about Ω is B). As a consequence, you would commit yourself, already at presenttime, to have your future behaviour constrained by conditional beliefs. This will give you the opportunity to strengthen yourmodel of present beliefs through the implications of conglomerability.This situation is relatively close to the traditional view of some fields of research. For instance, in the case of knowledge-based systems, you ideally do your best effort to model domain knowledge by a, possibly imprecise, probabilistic model;once the system is built and successfully tested, then it supports decisions by making inferences through conditioning.Another example can be statistics: a model is carefully built via (again, possibly imprecise) prior and likelihood, and futureactions are chosen to be constrained by the posterior inferences. It is for these reasons that we think that strong temporalcoherence has something to say in particular for the traditional probabilistic and statistical setup: it appears that there youshould use conglomerable models and make inferences by conditioning them.On the other hand, it will not always be possible for you to create a model with full care. This will be the case alsoin the previous fields of research, whose description above has been partly idealised, and will be definitely so if we focuson reasoning and decisions in daily life: for it is relatively uncommon that at any time you have an accurate model of theevidence around you that is stable and not subject to revision in absence of information. Usually, the process by whichyou form beliefs is very dynamic: you start with a rough model of the evidence, whose accuracy is constrained by timelimitations or by lack of other resources; then the availability of extra time usually helps you to rework your model andmake it more stable. This process is reactivated whenever you can and think it is worth (and of course also when youaccess new information). Note how this setup seems to be more in the scope of artificial intelligence than the previous one.The scenario in which you establish your future commitments at present time appears to be just too narrow for this case:why should you commit yourself now to constrain your future behaviour by conditional beliefs when you may well doubtthat they actually reflect a careful analysis of the evidence at hand? Most probably, you will instead establish your futurecommitments at some later time (note that nothing prevents you from realising later that conditional beliefs were insteadaccurate enough and can be taken as future commitments). This is precisely where the more flexible framework of temporalconsistency enters the picture.In particular, our results on temporal consistency (by this we also mean, for short, event-wise temporal consistency inwhat follows) can be used as a guidance in the process of belief assessment so as to maintain consistency between presentand future commitments: this will prevent an opponent from making you incur a (sure or partial) loss. Nevertheless, in ourview this cannot be given the status of a rationality requirement, in the sense that temporal consistency cannot be imposedin general on probabilistic models: for it is always possible that your original model R was too inaccurately specified, sothat you might want to reconsider part of the assessments of R in the passage to future commitments, even though thiswill create an inconsistency between the two models.40Stated differently, even though we think that it should be desirable for you to be self-consistent in time, we find itunreasonable to impose it on you in general. In fact, the lesson we draw from the analysis in this paper is another: thecrucial point is not that you should force yourself later to define future commitments that are consistent with your presentbeliefs; it is rather on adopting a procedure to assess beliefs that gives you some minimal quality guarantees throughout.Remember, in fact, that temporal consistency is a relatively weak notion (see, e.g., Theorem 4(b)): that your future commit-ments conflict with your present beliefs implies that somewhere in the process of assessing your beliefs there has been a38 Some caution, or additional considerations, should be used in case you were strongly focused on the Gamma-maximin criterion as a way to solvedecision-theoretic problems (see, e.g., [4,25], and especially the criticism to Gamma-maximin in [52]).39 These outcomes should not be over-interpreted: for an uncertainty model constrains rather than determines your behaviour in general (see the discus-sion in Section 3.1). On the other hand, these constraints can be very weak on some occasions, especially when generalised Bayes rule is used to computeconditional inferences from credal sets. In these cases it could be useful to rely on uncertainty models more informative than sets of probabilities, such ascoherent sets of desirable gambles and the related conditioning (see Section 5.2). This would be also a way not to compromise the possibility to achievestrong temporal coherence.40 This will be even more the case in a setup where it is allowed, unlike in this paper, to receive information about Ω besides B, and which might evennot be representable as a subset of Ω .M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–5147very serious flaw. This means that if you implement that process using some minimal care, you will automatically minimisethe possibility to be temporally inconsistent. Quality can be achieved by relying on the tools that we have developed tocheck temporal consistency: for they make you aware when you contradict the beliefs you stated first (but still allowingyou to do so), so that any change of beliefs is well reflected on. Moreover, you achieve quality by tuning the strength ofyour judgements relative to the evidence at hand as well as to the depth by which you have analysed it. The good newsis that this is not too difficult to do in an imprecise probability setting: it is enough to make your assessments the moreimprecise the weaker your knowledge (it goes without saying that you should also aim at making them the more precisethe stronger your knowledge, if you want your models to be useful).The situation could instead be quite difficult if you wanted to stick to precise probability: for there are states of weakknowledge that cannot be represented by precise models (ignorance is one case, and there are many others that are lessextreme). In these cases, the formalism you have chosen will de facto oblige you to make stronger judgements than thoseyou actually support; this, together with the fact that temporal consistency becomes a very rigid notion in the precise case(most often41 allowing only for conditioning in order to create future commitments), will make it quite likely for you toincur a temporal loss. In this case you would behave like a person that is used to make bold claims even when the evidencedoes not support them, and that is obliged to retract them at some later time. The central question here, and somewhatloosely speaking, is that precise probability is too narrow of a framework to allow strong temporal coherence and temporalconsistency to be distinguished: these two notions nearly collapse into a single one.A summary of the discussion up to this point is that our research in this paper indicates that there are two behaviouralprobabilistic theories of uncertainty that should be considered when the focus in on temporal considerations. Referring tothe most general mathematical model in this paper, one is that of coherent sets of desirable gambles with an additionalaxiom that accounts for the conglomerability of the model (that is, the theory based on axioms D1–D5;42 see [42] for thecase of lower previsions); this should be used in the case of strong temporal coherence. In the remaining cases, the theoryshould be the one based on axioms D1–D4 and complemented by considerations of temporal consistency. Both theoriesoffer opportunities and challenges. In the first case, a definite challenge is to make the theory of practical use in general,because the conglomerability axiom is non-finitary, and this means, in a logical language, that the deductive closure (whichin that case is the conglomerable natural extension) cannot be computed in any finitary way.43 In the second case, thetheory is mathematically much easier to deal with and, on the other hand, it is largely there to be developed with regardto considerations of temporal consistency: for example, a vast number of possibilities open up here to define temporallyconsistent updating rules.We would like to conclude this paper by signalling some of the most prominent open problems stemming from ourwork; an important one, in our view, is the extension of the notions of (strong) temporal consistency and strong temporalcoherence to several steps in the future, which would allow us to link our work to stochastic processes. We think that ifwe can represent these steps by means of hierarchical information, the treatment should be similar to that of the marginalextension theorem we have considered in Section 6.2.1, using the general version of this result established in [40]. Inthis sense, it would be interesting to investigate the connections with the notion of cut-conglomerability considered by deCooman and Hermans in [7].On the other hand, we may also consider the case where information cannot be represented in a hierarchical way, forinstance when we consider several different partitions, not necessarily nested, at the same point in time. We believe that inthat case temporal consistency and strong temporal coherence will probably be related to the notions of weak and strongcoherence by Walley [67, Chapter 7]. This would probably entail the generalisation of the results in Appendix A to severalsets of desirable gambles, which leads us to believe that the notions will become much more stringent.Another interesting open problem would be to investigate in more detail the relationships of our work with the ap-proaches summarised in Section 7. In particular, it would be useful to detail the relationships between our approach andbelief revision, studying how the set of current beliefs should be contracted or revised taking into account the (possiblyinconsistent) information included in the set of future commitments. We think this could be particularly useful in the caseyou access information that is not exact. In fact, let us recall that in this work we have restricted the attention to the caseof exact information, where B is the only new information you access about the possibility space Ω . We have done so inthe attempt to focus on a clearly defined setting, isolating the core of the temporal questions from other types of difficultproblems, and because the case of exact information is particularly important in traditional probability. Now that the basictemporal questions have been analysed, it would be possible to try a generalisation to the case of inexact information. Weregard this as a very important research avenue for the future. Part of the results in this paper will probably continue tohold in such a generalised setup; the challenge will be to merge them with a model of the process by which information isaccessed.41 Remember the possible exceptions discussed in Remark 3, note 21 and Remark 6.42 We remark once again that axiom D5 is defined relative to the fixed partition B and bears no implications on full conglomerability.43 But remember that for finite spaces of possibilities D5 boils down to a finitary axiom that follows automatically from D4.48M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–51AcknowledgementsThis work was supported by the Swiss NSF grants Nos. 200020_134759/1, 200020_137680/1, by the Hasler foundationgrant No. 10030, and by the Spanish project MTM2010-17844. We would like to thank Gert de Cooman for initial stimulatingdiscussion and the anonymous reviewers for comments that helped us to improve the presentation of the paper.Appendix A. On the coherence of the union of two sets of desirable gamblesIn this technical appendix, we provide some insight about the coherence of the union of two coherent sets of desirablegambles. This is used in Section 6.4 to discuss the inadequacy of temporal coherence in the case of sets of desirable gambles.Nevertheless, the results we provide here have some interest on their own, and this is particularly the case of the summarymade at the end of this appendix in Corollary 6.We start with a simple observation, which is also related to Remark 1.Lemma 3. Given two coherent sets of desirable gambles R1, R2, their union R1 ∪ R2 is coherent if and only iff ∈ R1, g ∈ R2 ⇒ f + g ∈ R1 ∪ R2.(A.1)Proof. It is trivial that R1 ∪ R2 satisfies D1–D3, given that both R1, R2 are coherent. Therefore R1 ∪ R2 is coherent ifand only if it satisfies D4. But D4 holds trivially in case f and g are taken from the same set; whence D4 is equivalentto (A.1). (cid:2)On the other hand, note that given coherent sets R1, R2, it holds that(cid:6)M(cid:7)posi(R1 ∪ R2)= M(R1 ∪ R2) = M(R1) ∩ M(R2).Hence, when R1 ∪ R2 avoids partial loss, then the natural extension of R1 ∪ R2 is in correspondence with the credal setM(R1) ∩ M(R2). Note that this credal set can generally have extreme points that belong to neither M(R1) nor M(R2).However, when R1 ∪ R2 is coherent we can go one step further.Proposition 20. Let P 1, P 2, defined on L, be the coherent lower previsions derived from the respective coherent sets of desirablegambles R1, R2. Assume that R1 ∪ R2 avoids partial loss. Then(cid:4)R1 ∪ R2 coherent ⇒ P ( f ) = max(cid:5)P 1( f ), P 2( f )∀ f ∈ L,(A.2)where P is the coherent lower prevision derived from posi(R1 ∪ R2) by (16). If moreover R1, R2 are coherent sets of strictly desirablegambles, then the converse also holds.Proof. For the first statement, consider that for any gamble fit holds that(cid:4)P ( f ) = sup(cid:5)μ: f − μ ∈ posi(R1 ∪ R2)because posi(R1 ∪ R2) = R1 ∪ R2 when the latter is coherent.(cid:4)= sup{μ: f − μ ∈ R1 ∪ R2} = max(cid:5),P 1( f ), P 2( f )To see that the converse holds when R1, R2 are coherent sets of strictly desirable gambles, it suffices to show thatEq. (A.2) implies (A.1). Take f ∈ R1, g ∈ R2. If both of them are positive gambles, then so is f + g, whence f + g ∈R1 ∩ R2 ⊆ R1 ∪ R2.On the other hand, if for instance f has a negative part, then we deduce from the definition of strictly desirable gamblesthat P 1( f ) > 0, whence also P ( f ) (cid:2) P 1( f ) > 0. On the other hand, it holds that P (g) (cid:2) P 2(g) (cid:2) 0, and using the coherenceof P we deduce thatP ( f + g) (cid:2) P ( f ) + P (g) > 0.As a consequence, either P 1( f + g) > 0 or P 2( f + g) > 0, and therefore f + g ∈ R1 ∪ R2. Applying Lemma 3 we deducethat R1 ∪ R2 is coherent. (cid:2)Theorem 6. Consider two credal sets M1, M2. The following are equivalent:(a) M1 ∪ M2 is convex.(b) For every P 1 ∈ M1, P 2 ∈ M2 there is some α ∈ [0, 1] such that the linear prevision α P 1 + (1 − α)P 2 belongs to M1 ∩ M2.(c) The lower envelope of M1 ∩ M2 is the maximum of the lower envelopes P 1, P 2 of M1, M2.M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–5149Proof.(a) ⇒ (b) Consider P 1 ∈ M1, P 2 ∈ M2, and let us defineA1 :=A2 :=(cid:4)α ∈ [0, 1]: α P 1 + (1 − α)P 2 ∈ M1(cid:4)α ∈ [0, 1]: α P 1 + (1 − α)P 2 ∈ M2(cid:5)(cid:5),.Since M1 ∪ M2 is convex, we deduce that A1 ∪ A2 = [0, 1]. Moreover, both these sets are non-empty, because0 ∈ A2 and 1 ∈ A1. Let x1 be the infimum of A1 and let x2 be the supremum of A2. Then x1, x2 are a minimumand a maximum, respectively, because M1, M2 are closed sets. Moreover, given 1 (cid:2) z > x1, then also z ∈ A1,because(cid:6)z P 1 + (1 − z)P 2 = α P 1 + (1 − α)x1 P 1 + (1 − x1)P 2(cid:7)for α := z − x11 − x1.Similarly, given z < x2 then also z ∈ A2. Thus, A1 = [x1, 1], A2 = [0, x2] and A1 ∪ A2 = [0, 1], whence x2 (cid:2) x1. Thisimplies that for every α ∈ [x1, x2] it holds that α P 1 + (1 − α)P 2 ∈ M1 ∩ M2.(b) ⇒ (a) Take P 1 ∈ M1, P 2 ∈ M2. Then there is some α ∈ [0, 1] such that α P 1 + (1 − α)P 2 ∈ M1 ∩ M2. Since M1 isconvex, we deduce that for every x > α it holds that(cid:6)xP 1 + (1 − x)P 2 = λP 1 + (1 − λ)α P 1 + (1 − α)P 2(cid:7)∈ M1 where λ := x − α1 − α,and similarly for every y < α it holds that y P 1 + (1 − y)P 2 ∈ M2. Hence, γ P 1 + (1 − γ )P 2 ∈ M1 ∪ M2 for everyγ ∈ [0, 1]. We conclude that M1 ∪ M2 is convex.(b) ⇒ (c) Let us consider a gamble f ∈ L. Then there are linear previsions P 1 ∈ M1, P 2 ∈ M2 such that P 1( f ) = P 1( f )and P 2( f ) = P 2( f ). Applying (b), there is some α ∈ [0, 1] such that α P 1 + (1 − α)P 2 ∈ M1 ∩ M2, whenceP ( f ) := minP ∈M1∩M2(cid:4)P ( f ) (cid:3) α P 1( f ) + (1 − α)P 2( f ) = α P 1( f ) + (1 − α)P 2( f ) (cid:3) max(cid:5),P 1( f ), P 2( f )and since the converse inequality always holds we deduce the equality P ( f ) = max{P 1( f ), P 2( f )}. Since we cando this for every f , we deduce that (c) holds.(c) ⇒ (b) Assume ex-absurdo that (b) does not hold. Then there are P 1 ∈ M1, P 2 ∈ M2 such that α P 1 + (1 − α)P 2 doesnot belong to M1 ∩ M2 for every α ∈ [0, 1]. Since both M1 ∩ M2 and V := {α P 1 + (1 − α)P 2: α ∈ [0, 1]}are compact convex sets of linear previsions, we can apply [67, Appendix E3] to conclude that there is somecontinuous linear functional Λ, λ ∈ R and δ > 0 such that Λ(P ) (cid:3) λ−δ for every P ∈ V and Λ(P ) (cid:2) λ+δ for everyP ∈ M1 ∩ M2. Since from [67, Appendix D3] continuous linear functionals are always evaluation functionals,there is some gamble f such that P ( f ) (cid:3) λ − δ for every P ∈ V . In particular, P 1( f ), P 2( f ) (cid:3) λ − δ, whencemax{P 1( f ), P 2( f )} (cid:3) λ − δ, whileminP ∈M1∩M2P ( f ) (cid:2) λ + δ,a contradiction with (c). (cid:2)We are finally ready to report the most important result for a geometrical interpretation of the coherence of R1 ∪ R2.Corollary 6. Consider two coherent sets of desirable gambles, R1 and R2, such that R1 ∪ R2 avoids partial loss. Then for R1 ∪ R2 tobe coherent it is necessary that M(R1) ∪ M(R2) be convex. This condition is also sufficient if R1 and R2 are sets of strictly desirablegambles.Proof. Necessity and sufficiency follow from Proposition 20 and Theorem 6. (cid:2)References[1] C. Alchourrón, P. Gärdenfors, D. Makinson, On the logic of theory change: partial meet contraction and revision functions, Journal of SymbolicLogic 50 (2) (1985) 510–530.[2] B. Armendt, Is there a Dutch book argument for probability kinematics? Philosophy of Science 47 (1980) 583–588.[3] B. Armendt, Dutch strategies for diachronic rules: when believers see the sure loss coming, in: PSA: Proceedings of the biennial meeting of thePhilosophy of Science Association, vol. 1, 1992, pp. 217–229.[4] T. Augustin, On the suboptimality of the generalized Bayes rule and robust Bayesian procedures from the decision theoretic point of view — a caution-ary note on updating imprecise priors, in: J.-M. Bernard, T. Seidenfeld, M. Zaffalon (Eds.), ISIPTA ’03, Proceedings of the Third International Symposiumon Imprecise Probabilities and Their Applications, in: Proceedings in Informatics, vol. 18, Carleton Scientific, 2003, pp. 31–45.[5] G. Bonanno, Axiomatic characterization of the AGM theory of belief revision in a temporal logic, Artificial Intelligence 171 (2–3) (2007) 144–160.[6] G. de Cooman, Belief models: an order-theoretic investigation, Annals of Mathematics and Artificial Intelligence 45 (2005) 5–34.50M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–51[7] G. De Cooman, F. Hermans, Imprecise probability trees: bridging two theories of imprecise probability, Artificial Intelligence 172 (11) (2008) 1400–1427.[8] G. de Cooman, M. Zaffalon, Updating beliefs with incomplete observations, Artificial Intelligence 159 (1–2) (2004) 75–125.[9] B. de Finetti, Sulla proprietà conglomerativa delle probabilità subordinate, Rendiconti del Reale Instituto Lombardo 63 (1930) 414–418.[10] B. de Finetti, Teoria delle Probabilità, Einaudi, Turin, 1970.[11] B. de Finetti, Probability, Induction and Statistics, Wiley, London, 1972.[12] B. de Finetti, Theory of Probability: A Critical Introductory Treatment, John Wiley & Sons, Chichester, 1974–1975, English translation of [10], twovolumes.[13] P. Diaconis, S.L. Zabell, Updating subjective probability, Journal of the American Statistical Association 77 (380) (1982) 822–830.[14] L.E. Dubins, Finitely additive conditional probabilities, conglomerability and disintegrations, The Annals of Probability 3 (1975) 88–99.[15] D. Dubois, H. Prade, Evidence, knowledge and belief functions, International Journal of Approximate Reasoning 6 (3) (1992) 295–319.[16] D. Dubois, H. Prade, A survey of belief revision and updating rules in various uncertainty models, International Journal of Intelligent Systems 9 (1994)61–100.[17] H. Gaifman, A theory of higher order probabilities, in: B. Skyrms, W. Harper (Eds.), Causation, Chance, and Credence, Kluwer, 1988, pp. 191–219.[18] P. Gärdenfors, Knowledge in Flux – Modeling the Dynamics of Epistemic States, MIT Press, Cambridge, MA, 1988.[19] P. Gärdenfors, N.-E. Sahlin, Decision, Probability, and Utility, Cambridge University Press, Cambridge, 1988.[20] R. Gill, M. Van der Laan, J. Robins, Coarsening at random: characterisations, conjectures and counter-examples, in: D.-Y. Lin (Ed.), Proceedings of thefirst Seattle Conference on Biostatistics, Springer, 1997, pp. 255–294.[21] M. Goldstein, The prevision of a prevision, Journal of the American Statistical Association 87 (1983) 817–819.[22] M. Goldstein, Temporal coherence, in: J.M. Bernardo, M.H. DeGroot, D.V. Lindley, A.F.M. Smith (Eds.), Bayesian Statistics, vol. 2, North-Holland, Amster-dam, 1985, pp. 231–248, with discussion.[23] M. Goldstein, Prior inferences for posterior judgments, in: M.L. Chiara, K. Doets, D. Mundici, J.F.A.K. van Benthem (Eds.), Structures and Norms inScience, Kluwer, Dordrecht, 1997, pp. 57–71.[24] M. Goldstein, Avoiding foregone conclusions: geometric and foundational analysis of paradoxes of finite additivity, Journal of Statistical Planning andInference 94 (2001) 73–87.[25] P.D. Grünwald, J. Halpern, Making decisions using sets of probabilities: updating, time consistency, and calibration, Journal of Artificial IntelligenceResearch 42 (2011) 393–426.[26] E. Hanany, P. Klibanoff, Updating preferences with multiple priors, Theoretical Economics 2 (2007) 261–298.[27] C. Howson, Can logic be combined with probability? Probably, Journal of Applied Logic 7 (2009) 177–187.[28] C. Howson, Bayesianism as a pure logic of inference, in: P.S. Bandyopadhyay, M.R. Forster (Eds.), Handbook of the Philosophy of Science, in: Philosophyof Statistics, vol. 7, Elsevier, 2011, pp. 441–471.[29] R. Jeffrey, The Logic of Decision, McGraw–Hill, 1965.[30] R. Jeffrey, Conditioning, kinematics, and exchangeability, in: B. Skyrms, W. Harper (Eds.), Causation, Chance and Credence, Kluwer, 1988, pp. 221–255.[31] R. Jeffrey, Subjective Probability (The Real Thing), Cambridge University Press, 2004.[32] J.B. Kadane, M.J. Schervish, T. Seidenfeld, Reasoning to a foregone conclusion, Journal of the American Statistical Association 91 (435) (1996) 1228–1235.[33] J.B. Kadane, M.J. Schervish, T. Seidenfeld, Goldstein’s dilemma: require countable additivity or abandon “prevision of prevision”, Journal of StatisticalPlanning and Inference 94 (2001) 89–91.[34] H. Katsuno, A. Mendelson, On the difference between updating a knowledge base and revising it, in: Proceedings of the 2nd International Conferenceon Principles of Knowledge Representation and Reasoning, Morgan Kauffman, 1991, pp. 387–394.[35] H.E. Kyburg Jr., H.E. Smokler (Eds.), Studies in Subjective Probability, Wiley, New York, 1964, second edition (with new material) 1980.[36] I. Levi, The demons of decision, The Monist 70 (1987) 193–211.[37] I. Levi, Money pumps and diachronic books, Philosophy of Science 69 (3) (2002) 235–247.[38] P. Maher, Diachronic rationality, Philosophy of Science 59 (1992) 120–141.[39] E. Miranda, Updating coherent lower previsions on finite spaces, Fuzzy Sets and Systems 160 (9) (2009) 1286–1307.[40] E. Miranda, G. de Cooman, Marginal extension in the theory of coherent lower previsions, International Journal of Approximate Reasoning 46 (1) (2007)188–225.[41] E. Miranda, M. Zaffalon, Notes on desirability and conditional lower previsions, Annals of Mathematics and Artificial Intelligence 60 (3–4) (2010)251–309.[42] E. Miranda, M. Zaffalon, Conglomerable coherent lower previsions, in: R. Kruse, M.R. Berthold, C. Moewes, M.A. Gil, P. Grzegorzewski, O. Hryniewicz(Eds.), Advances in Intelligent Systems and Computing, in: Synergies of Soft Computing and Statistics for Intelligent Data Analysis, vol. 190, Springer,Berlin Heidelberg, 2012, pp. 419–427.[43] E. Miranda, M. Zaffalon, G. de Cooman, Conglomerable natural extension, International Journal of Approximate Reasoning 53 (8) (2012) 1200–1227.[44] S. Moral, N. Wilson, Revision rules for convex sets of probabilities, in: G. Coletti, D. Dubois, R. Scozzafava (Eds.), Mathematical Models for HandlingPartial Knowledge in Artificial Intelligence, Plenum Press, New York, 1995, pp. 113–128.[45] R. Pelessoni, P. Vicig, Williams coherence and beyond, International Journal of Approximate Reasoning 50 (4) (2009) 612–626.[46] P. Peppas, Belief revision, in: V. Lifschitz, F. van Harmelen, B. Porter (Eds.), Handbook of Knowledge Representation, Elsevier, 2008, pp. 317–359.[47] F.P. Ramsey, Truth and probability, in: R.B. Braithwaite (Ed.), The Foundations of Mathematics and other Logical Essays, Kegan, Paul, Trench, Trubner &Co., London, 1926, pp. 156–198, 1931, Chapter VII, reprinted in [35] and [19].[48] M.J. Schervisch, T. Seidenfeld, J.B. Kadane, The extent of non-conglomerability of finitely additive probabilities, Zeitschrift fur Wahrscheinlichkeitstheorieund verwandte Gebiete 66 (1984) 205–226.[49] M.J. Schervisch, T. Seidenfeld, J.B. Kadane, On the equivalence between conglomerability and disintegrability for unbounded random variables, Sankhya,2010, submitted for publication.[50] K. Segerberg, Two traditions in the logic of belief: bringing them together, in: H. Ohlbach, U. Reyle (Eds.), Logic, Language and Reasoning, Kluwer, 1999,pp. 135–147.[51] T. Seidenfeld, When normal and extensive form decisions differ, in: D. Prawitz, B. Skyrms, D. Westerståhl (Eds.), Logic, Methodology and Philosophy ofScience IX, Elsevier, 1994, pp. 451–463.[52] T. Seidenfeld, A contrast between two decision rules for use with (convex) sets of probabilities: Gamma-maximin versus E-admissibility, Syn-these 140 (1–2) (2004) 69–88.[53] T. Seidenfeld, M.J. Schervisch, J.B. Kadane, Non-conglomerability for finite-valued finitely additive probability, Sankhya 60 (3) (1998) 476–491.[54] G. Shafer, Bayes’s two arguments for the rule of conditioning, The Annals of Statistics 10 (1982) 1075–1089.[55] G. Shafer, Conditional probability, International Statistical Review 53 (1985) 261–277.[56] G. Shafer, P.R. Gillett, R.B. Scherl, A new understanding of subjective probability and its generalization to lower and upper prevision, InternationalJournal of Approximate Reasoning 33 (2003) 1–49.[57] G. Shafer, V. Vovk, Probability and Finance: It’s Only a Game! Wiley, New York, 2001.M. Zaffalon, E. Miranda / Artificial Intelligence 198 (2013) 1–5151[58] B. Skyrms, Dynamic coherence and probability kinematics, Philosophy of Science 54 (1987) 1–20.[59] B. Skyrms, The Dynamics of Rational Deliberation, Harvard University Press, 1990.[60] B. Skyrms, A mistake in dynamic coherence arguments? Philosophy of Science 60 (2) (1993) 320–328.[61] A. Tarski, Logic, Semantics, Metamathematics. Papers from 1923 to 1938, Oxford University Press, 1956, translated by J.H. Woodger.[62] P. Teller, Conditionalization and observation, Synthese (1973) 212–258.[63] M. Troffaes, Conditional lower previsions for unbounded random quantities, in: J. Lawry, E. Miranda, A. Bugarin, S. Li, M.A. Gil, P. Grzegiorzewski,O. Hryniewicz (Eds.), Soft Methods in Integrated Uncertainty Modelling, Springer, 2006, pp. 201–210.[64] H. van Ditmarsch, Prolegomena of dynamic logic for belief revision, Synthese 147 (2005) 229–275.[65] B.C. Van Fraassen, Belief and the will, Journal of Philosophy 81 (1984) 235–256.[66] B.C. Van Fraassen, Belief and the problem of Ulysses and the sirens, Philosophical Studies 77 (1995) 7–37.[67] P. Walley, Statistical Reasoning with Imprecise Probabilities, Chapman and Hall, London, 1991.[68] P.M. Williams, Notes on conditional previsions, Technical report, School of Mathematical and Physical Science, University of Sussex, UK, 1975, reprintedin [70].[69] P.M. Williams, Bayesian conditionalisation and the principle of minimum information, British Journal for the Philosophy of Science 31 (1980) 131–144.[70] P.M. Williams, Notes on conditional previsions, International Journal of Approximate Reasoning 44 (2007) 366–383, revised journal version of [68].[71] M. Zaffalon, E. Miranda, Conservative inference rule for uncertain reasoning under incompleteness, Journal of Artificial Intelligence Research 34 (2009)757–821.