Artificial Intelligence 259 (2018) 110–146Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintThe complexity and generality of learning answer set programsMark Law∗, Alessandra Russo, Krysia BrodaDepartment of Computing, Imperial College London, SW7 2AZ, United Kingdoma r t i c l e i n f oa b s t r a c tArticle history:Received 2 September 2016Received in revised form 20 February 2018Accepted 15 March 2018Available online 21 March 2018Keywords:Non-monotonic logic-based learningAnswer Set ProgrammingComplexity of non-monotonic learningTraditionally most of the work in the field of Inductive Logic Programming (ILP) has ad-dressed the problem of learning Prolog programs. On the other hand, Answer Set Program-ming is increasingly being used as a powerful language for knowledge representation and reasoning, and is also gaining increasing attention in industry. Consequently, the research activity in ILP has widened to the area of Answer Set Programming, witnessing the pro-posal of several new learning frameworks that have extended ILP to learning answer set programs. In this paper, we investigate the theoretical properties of these existing frame-works for learning programs under the answer set semantics. Specifically, we present a detailed analysis of the computational complexity of each of these frameworks with re-spect to the two decision problems of deciding whether a hypothesis is a solution of a learning task and deciding whether a learning task has any solutions. We introduce a new notion of generality of a learning framework, which enables us to define a framework to be more general than another in terms of being able to distinguish one ASP hypothesis solution from a set of incorrect ASP programs. Based on this notion, we formally prove a generality relation over the set of existing frameworks for learning programs under answer set se-mantics. In particular, we show that our recently proposed framework, Context-dependent Learning from Ordered Answer Sets, is more general than brave induction, induction of stable models, and cautious induction, and maintains the same complexity as cautious induction, which has the highest complexity of these frameworks.© 2018 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).1. IntroductionOver the last two decades there has been a growing interest in Inductive Logic Programming (ILP) [1], where the goal is to learn a logic program called a hypothesis, which together with a given background knowledge base, explains a set of examples. The main advantage that ILP has over traditional statistical machine learning approaches is that the learned hypotheses can be easily expressed in plain English and explained to a human user, so facilitating a closer interaction be-tween humans and machines. Traditional ILP frameworks have focused on learning definite logic programs [1–6] and normal logic programs [7,8]. On the other hand, Answer Set Programming [9] is a powerful language for knowledge representation and reasoning. ASP is closely related to other declarative paradigms such as SAT, SMT and Constraint Programming, which have each been used for inductive reasoning [10–12]. Compared with these other paradigms, due to its non-monotonicity, ASP is particularly suited for common-sense reasoning [13–15]. Because of its expressiveness and efficient solving, ASP is * Corresponding author at: Department of Computing, Huxley Building, 180 Queen’s Gate, Imperial College London, London, SW7 2AZ, United Kingdom.E-mail address: mark.law09 @imperial .ac .uk (M. Law).https://doi.org/10.1016/j.artint.2018.03.0050004-3702/© 2018 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).M. Law et al. / Artificial Intelligence 259 (2018) 110–146111also increasingly gaining attention in industry [16]; for example, in decision support systems [17], in e-tourism [18] and in product configuration [19]. Consequently, the scope of ILP has recently been extended to learning answer set programs from examples of partial solutions of a given problem, with the intention being to provide algorithms that support automated learning of complex declarative knowledge. Learning ASP programs allows us to learn a variety of declarative non-monotonic, common-sense theories, including for instance Event Calculus [20] theories [21] and theories for scheduling problems and agents’ preference models, both from real user data [22] and from synthetic data [23,24].Learning ASP programs has several advantages when compared to learning Prolog programs. Firstly, when learning Prolog programs, the goal directed SLDNF procedure of Prolog must be taken into account. Specifically, when learning programs with negation, it must be ensured that the programs are stratified, or otherwise the learned program may loop under certain queries. As ASP is declarative, no such consideration need be taken into account when learning ASP programs. A second, more fundamental advantage of learning ASP programs, is that the theory learned can be expressed using extra types of rules that are not available in Prolog, such as choice rules and weak constraints. Learning choice rules allows us to learn non-deterministic concepts; for instance, we may learn that a coin may non-deterministically land on either heads or tails, but never both. This could be achieved by learning the simple choice rule 1{heads, tails}1. Learning choice rules is different from probabilistic ILP settings such as [25–27] where, in similar coins problems the focus would be on learning the probabilities of the two outcomes of are coin. Learning weak constraints enables a natural extension of ILP to preference learning [23], which has resulted to be effective in problem domains such as learning preference models for scheduling [23]and for urban mobility [24].Several algorithms, aimed at learning under the answer set semantics, and different frameworks for learning ASP pro-grams have been recently introduced in the literature. [28] presented the notions of brave induction (I L P b) and cautious induction (I L P c ), based respectively on the well established notions of entailment under the answer set semantics [13,29]of brave entailment (when an atom is true in at least one answer set) and cautious entailment (when and an atom is true in all answer sets). In brave induction, at least one answer set must cover the examples, whereas in cautious induction, every answer set must cover the examples. Brave induction is actually a special case of an earlier learning framework, called in-duction of stable models (I L P sm) [30], in which examples are partial interpretations. A hypothesis is a solution of an induction of stable models task if for each of the example partial interpretations, there is an answer set of the hypothesis combined with the background knowledge, that covers that partial interpretation. Brave induction is equivalent to induction of stable models with exactly one (partial interpretation) example.Each of the above frameworks for learning ASP programs is unable to learn some types of ASP programs [31]; for exam-ple, brave induction alone cannot learn programs containing hard constraints. In [31], we presented a learning framework, called Learning from Answer Sets (I L P L A S ), which unifies brave and cautious induction and is able to learn ASP programs containing normal rules, choice rules and hard constraints. In spite of the increased expressivity, none of the above ap-proaches can learn weak constraints, which are able to capture preference learning. Informally, learning weak constraints consists on identifying conditions for ordering answer sets. The learning task in this case would require examples of or-derings over partial interpretations. To tackle this aspect of learning ASP programs, we have extended the Learning from Answer Sets framework to Learning from Ordered Answer Sets (I L P L O A S ) [23] and demonstrated that our algorithm1 is able to learn preferences in a scheduling domain. More recently, we have extended the I L P L O A S framework to I L P contextL O A S , with context-dependent examples, which come together with extra contextual information [24].In this paper, we explore both the expressive power and the computational complexity of each framework. The former is important, as it allows us to identify the class of problems that each framework can solve, whereas the latter gives an indication of the price paid for using each framework. We characterise the expressive power of a framework in terms of new notions called one-to-one-distinguishability, one-to-many-distinguishability and many-to-many-distinguishability. The intuition of one-to-one-distinguishability is that, given some fixed background knowledge B and sufficient examples, the framework should be able to distinguish a target hypotheses H 1 from another, unwanted, hypotheses H 2. This means that there should be at least one task T (of the given framework) with background knowledge B, such that H 1 is a solution 1(F )) as the set of of T , and H2 is not. We characterise the one-to-one-distinguishability class of a framework F (written D1tuples (cid:3)B, H1, H2(cid:4) for such B’s, H1’s and H2’s, and state that a framework F1 is more D11 -general than another F2 if F2’s one-to-one-distinguishability class is a strict subset of F1’s one-to-one-distinguishability class.One-to-many-distinguishability relates to the task of finding a single target hypothesis from within a set of possi-ble hypotheses. It upgrades the notion of one-to-one-distinguishability classes to one-to-many-distinguishability classes. These are tuples of the form (cid:3)B, H, S(cid:4) for which a framework has at least one task that includes H and none of the (unwanted) hypotheses in S as an inductive solution. Many-to-many-distinguishability upgrades this notion to many-to-many-distinguishability classes. These contain tuples of the form (cid:3)B, S 1, S2(cid:4), where S1 is a set of target hypotheses, for which a framework must have a task that accepts each hypothesis in S 1 and no hypothesis in S2 as inductive solution. We show that, under these three measures, I L P contextis more general than I L P L O A S , which is more general than I L P L A S . We L O A Salso show that I L P L A S is more general than both I L P sm and I L P c . Although I L P sm is equally D11 -general to I L P b, we show that I L P sm is more general than I L P b under the one-to-many and many-to-many generality measures.1 Our ILASP system for solving I L P L O A S tasks is available for download from [32].112M. Law et al. / Artificial Intelligence 259 (2018) 110–146Despite the different generalities of I L P c , I L P L A S , I L P L O A S and I L P contextL O A S , we show that the computational complexity of all four frameworks is the same, both for the decision problem of verifying that a given hypothesis is a solution of a given learning task, and for the problem of deciding whether a given learning task has any solutions. Similarly, we also show that I L P sm and I L P b have the same computational complexities for both decision problems, despite the former being more general than the latter under two of our generality measures.We begin, in Section 2, by reviewing the background material necessary for the rest of the paper. In Section 3 we recall the definitions of each of the learning frameworks and in Sections 4 and 5 we prove the complexities and generalities (respectively) of each learning framework. We conclude the paper with a discussion of the related and future work.2. Background2.1. Answer Set ProgrammingIn this section we introduce the concepts needed in the paper. Given any atoms h, h1, . . . ,h k, b1, . . . ,b n, c1, . . . ,c m, h :- b1, . . . ,b n, not c1, . . . , not cm is called a normal rule, with h as the head and b1, . . . ,b n, not c1, . . . ,not c m (col-lectively) as the body (“not” represents negation as failure); a rule :- b1, . . . ,b n, not c1, . . . ,not c m, with an empty head, is a hard constraint; a choice rule is a rule l{h1, . . . ,h k}u ← b1, . . . ,b n, not c1, . . . ,not c m (where l and u are integers) and its head is called an aggregate. A rule R is safe if each variable in R occurs in at least one positive literal in the body of R. In this paper we will use ASP ch to denote the set of choice programs P , which are programs composed of safe normal rules, choice rules, and hard constraints. Given a rule R, we will write head(R) to denote the head of R, body(R) to denote −(R)) to denote the atoms that occur positively (resp. negatively) in the body of R. the body of R and bodyGiven a program P , we will also write Atoms(P ) to denote the atoms in P . We will also extend this notation to fragments of a program.(resp. bodyThe Herbrand Base of any program P ∈ ASP ch, denoted H B P , is the set of variable free (ground) atoms that can be formed from predicates and constants in P . The subsets of H B P are called the (Herbrand) interpretations of P . A ground aggregate l{h1, . . . ,h k}u is satisfied by an interpretation I iff l ≤ |I ∩ {h1, . . . ,h k}| ≤ u.+As we restrict our programs to sets of normal rules, (hard) constraints and choice rules, we can use the simplified definitions of the reduct for choice rules presented in [33]. Given a program P and an Herbrand interpretation I ⊆ H B P , the reduct P Iis constructed from ground(P ) (the set of ground instances of rules in P ) in 4 steps: firstly, remove rules whose bodies contain the negation of an atom in I ; secondly, remove all negative literals from the remaining rules; thirdly, replace the head of any hard constraint, or any choice rule whose head is not satisfied by I with ⊥ (where ⊥ /∈ H B P ); and finally, replace any remaining choice rule l{h1, . . . ,h m}u:- b1, . . . ,b n with the set of rules {hi:- b1, . . . ,b n | hi ∈I ∩ {h1, . . . , hm}}. Any I ⊆ H B P is an answer set of P if it is the minimal model of the reduct P I . Throughout the paper we denote the set of answer sets of a program P with A S(P ).We say a program P bravely entails an atom a (written P |=b a) if there is at least one answer set A of P such that a ∈ A. Similarly, P cautiously entails a (written P |=c a) if for every answer set A of P , a ∈ A.Unlike hard constraints in ASP, weak constraints do not affect what is, or is not, an answer set of a program P . Hence the above definitions also apply to programs with weak constraints. Weak constraints create an ordering over A S(P ) specifying which answer sets are “preferred” to others. A weak constraint is of the form :∼ b1, . . . ,b n,not c1, . . . ,not c m.[w@l, t1, . . . ,t k] where b1, . . . ,b n, c1, . . . ,c m are atoms, w and l are terms specifying the weightand the level, and t1, . . . , tk are terms. A weak constraint W is safe if every variable in W occurs in at least one positive literal in the body of W . At each priority level l, the aim is to discard any answer set which does not min-imise the sum of the weights of the ground weak constraints with level l whose bodies are true. The higher levels are minimised first. The terms t1, . . . ,t k specify which ground weak constraints should be considered unique [34]. For any program P and an interpretation A, weak(P , A) is the set of tuples (w, l, t1, . . . ,t k) for which there is some :∼ b1, . . . ,b n, not c1, . . . ,not c m.[w@l, t1, . . . ,t k] in ground(P ) such that A satisfies b1, . . . ,b n, not c1, . . . ,not c m. =For each level l, the score of the interpretation A is the sum of the weights of tuples with level l, formally P l(cid:2)Aand (w,l,t1,...,tk)∈weak(P , A) w. For A1, A2 ∈ A S(P ), A1 dominates A2 (written A1 (cid:12)P A2) iff ∃l such that P l. An answer set A ∈ A S(P ) is optimal if it is not dominated by any A2 ∈ A S(P ).< P lA2A1∀m > l, P mA1= P mA2Example 1. Let P be the program {0{p(1), p(2), p(3)}1.}. P has 8 answer sets, which are the various combinations of making each of the three p atoms true or false. Consider the two weak constraints :∼ p(X).[1@1] and :∼ p(X).[1@1, X]. The first weak constraint states that if any of the p atoms is true then a penalty of one must be paid. This penalty is only paid once, regardless whether 1, 2 or 3 of the p atoms are true. Conversely, the second weak constraint says that a penalty of 1 must be paid for each of the p atoms that is true. In both cases, ∅ is the only optimal answer set; however, in the first case, none of the remaining answer sets dominate each other, whereas in the second case, the answer sets with only one patom dominate those with 2 p atoms, which in turn each dominate the single answer set with 3 p atoms.Note that the definition of weak constraints used in this paper is in line with the recent ASP standard established in [34]. The syntax of some previous definitions of weak constraints such as [13] do not include the terms t1, . . . ,t k and considered M. Law et al. / Artificial Intelligence 259 (2018) 110–146113every ground instance of every weak constraint individually. This semantics can be achieved using the notion of weak con-straints in [34]. Any weak constraint :∼ body.[w : l]2 can be mapped to the weak constraint :∼ body.[w@l, V1, . . . ,V n], where V1, . . . , Vn is the set of all variables that occur in body. If there are multiple weak constraints, to exactly preserve the semantics of [13], a unique term must be added to each weak constraint. For example, {:∼ p(X).[1 : 1]; :∼ q(X).[1 : 1]}would become {:∼ p(X).[1@1, X, 1]; :∼ q(X).[1@1, X, 2]}. With this additional term, W eak(P , {p(a), q(a)}) (where P is the program containing the two weak constraints) would be equal to {(1, 1, a, 1), (1, 1, a, 2)}, leading to a score of 2 at level 1; without the additional term, W eak(P , {p(a), q(a)}) would equal {(1, 1, a)}, leading to a score of 1 at level 1.Unless otherwise stated, when we refer to an ASP program in this paper, we mean a program consisting of a finite set of normal rules, choice rules, hard and weak constraints.We now introduce some extra notation which will be useful in later sections. Given a set of interpretations S, the set ord(P , S) captures the ordering of the interpretations given by the weak constraints in P . It generalises the dom-inates relation; so it not only includes (cid:3) A1, A2, <(cid:4) if A1 (cid:12)P A2, but it also includes tuples for other binary compari-son operators. Formally, (cid:3) A1, A2, <(cid:4) ∈ ord(P , S) if A1, A2 ∈ S and A1 (cid:12)P A2; (cid:3) A1, A2, >(cid:4) ∈ ord(P , S) if A1, A2 ∈ S and A2 (cid:12)P A1; (cid:3) A1, A2, ≤(cid:4) ∈ ord(P , S) if A1, A2 ∈ S and A2 (cid:2)P A1; (cid:3) A1, A2, ≥(cid:4) ∈ ord(P , S) if A1, A2 ∈ S and A1 (cid:2)P A2; (cid:3) A1, A2, =(cid:4) ∈ ord(P , S) if A1, A2 ∈ S, A1 (cid:2)P A2 and A2 (cid:2)P A1; (cid:3) A1, A2, (cid:17)=(cid:4) ∈ ord(P , S) if A1, A2 ∈ S and A1 (cid:12)P A2 or A2 (cid:12)P A1. Given an ASP program, we write ord(P ) as a shorthand for ord(P , A S(P )). Two ASP programs P and Q are strongly equivalent (written P ≡s Q ) if for every ASP program R, A S(P ∪ R) = A S(Q ∪ R).We now recall the splitting set theorem from [35], which we use in the proofs throughout the paper. This theorem relies on the notions of a splitting set and the partial evaluation of a logic program. Given a program P , a set U ⊆ H B P is a splitting set of P if and only if for every rule R ∈ ground(P ) such that Atoms(head(R)) ∩ U (cid:17)= ∅, Atoms(R) ⊆ U . Given a ground rule R and a set of atoms U , we write R\U to denote the rule R with all (positive or negative) occurrences of atoms in U removed from the body of R. Given a program P a splitting set U of P and a set X ⊆ U , the partial evaluation of P+(R) ∩ U ) ⊆with respect to U and X , written eU (P , X), is the program {R\U | R ∈ ground(P ), Atoms(head(R)) ∩ U = ∅, (bodyX, body−(R) ∩ X = ∅}.Theorem 1. Given any ground ASP program P , and splitting set U of P , A S(P ) = { X ∪ Y | X ∈ A S({R ∈ P | Atoms(head(R)) ∩ U (cid:17)=∅}), Y ∈ A S(eU (P , X))}.The intuition behind the splitting set theorem is that if a set of atoms U is known to split the program P , then we can find the answer sets of the subprogram that defines the atoms in U first. For each of these answer sets X , we can partially evaluate P using X and solve this partially evaluated program for answer sets. The splitting set theorem then guarantees that for each answer set Y of the partially evaluated program, X ∪ Y is an answer set of P . Furthermore, every answer set of P can be constructed in this way.2.2. Complexity theoryWe assume the reader is familiar with the fundamental concepts of complexity, such as Turing machines and reductions; for a detailed explanation, see [36].Many of the decision problems for ASP are known to be complete for classes in the polynomial hierarchy [37]. The classes of the polynomial hierarchy are defined as follows: P is the class of all problems which can be solved in polynomial = (cid:4)Ptime by a Deterministic Turing Machine (DTM); (cid:2)Pis the class of all problems which can be k+100= N P (cid:2)Psolved by a DTM in polynomial time with a (cid:2)Pis the class of all problems which can be solved by a non-deterministic Turing Machine in polynomial time with a (cid:2)Pk oracle; finally, (cid:3)Pis the class of all problems whose complement can be solved by a non-deterministic Turing Machine in polynomial time with a (cid:2)P1 and (cid:3)P1are N P and co-N P (respectively), where N P is the class of problems which can be solved by a non-deterministic Turing machine in polynomial time and co-N P is the class of problems whose complement is an N P problem.= (cid:3)P0k oracle; (cid:2)Pk oracle. (cid:2)P= co-N P (cid:2)P= P ; (cid:4)P= P (cid:2)PD P is the class of problems D that can be mapped to a pair of problems D1 and D2 such that D1 ∈ N P , D2 ∈ co-N P , and for each instance I of D, I answers “yes” if and only if both of the mapped instances I1 and I2 (of D1 and D2, respectively) answer “yes”. It is well known [36] that the following inclusions hold: P ⊆ N P ⊆ D P ⊆ (cid:4)P2 and P ⊆2co-N P ⊆ D P ⊆ (cid:4)P2⊆ (cid:3)P2 .⊆ (cid:2)Pk+1k+1kkk3. Learning frameworksIn this section, we give the definitions of the six learning frameworks we analyse in this paper. The first three – brave induction, cautious induction and induction of stable models – are not our own. We reformulate, but preserve the meaning of, the original definitions for easier comparison with our own.2 In [13] “:” was used for the same purpose as “@”.114M. Law et al. / Artificial Intelligence 259 (2018) 110–146It is common in ILP for a task to have a hypothesis space (the set of all rules which can appear in hypotheses). The purpose of the hypothesis space is two-fold: firstly, it allows the task to be restricted to those solutions which are in some way interesting; secondly, it aids the computational search for inductive solutions. Tasks for brave and cautious induction and for induction of stable models were originally presented with no hypothesis space [28,30] as they were mainly considered theoretically without the specifications of efficient algorithmic computations. The only publicly available algorithms for brave induction [38,39] make use of a hypothesis space defined by mode declarations [40]. In this paper, we “upgrade” each of brave induction, cautious induction and induction of stable models with a hypothesis space S M .3.1. Notation and terminologyAn ILP learning framework F defines what a learning task of F is and what an inductive solution is for a given learning task of F . For each framework a task is a tuple (cid:3)B, S M , E(cid:4), where B is an ASP program called the background knowledge, S Mis a set of ASP rules called the hypothesis space, and E is a tuple called the examples. The structure of E depends on the type of ILP framework. Each of the papers [28], [30], [31] and [23] presented learning frameworks with different languages for B and S M ; for example, induction of stable models was presented only for normal logic programs. It would be unfair to say that induction from stable models is not general enough to learn programs with choice rules, simply because they were not considered in the original paper (in fact, induction from stable models is general enough to learn some programs with choice rules). For a fair comparison we therefore assume in this paper that every learning framework has a background knowledge B and hypothesis space S M that consist of normal rules, choice rules, hard constraints and weak constraints.Given a framework F and a learning task T F = (cid:3)B, S M , E(cid:4) of F , a hypothesis is any subset of the hypothesis space S M . In Section 5, we consider tasks with unrestricted hypothesis spaces (written (cid:3)B, E(cid:4)), in which case any ASP program can be called a hypothesis. An inductive solution is a hypothesis that, together with the background knowledge B, satisfies some conditions on E (given by the particular learning framework F ). We write I L P F (T F ) to denote the set of all inductive solutions of T F . Throughout the paper, we use the term covers to apply to any kind of example: i.e. given a F task (cid:3)B, S M , E(cid:4), we say that a hypothesis H covers an example e (any element of any component of E), if it meets the particular conditions that the framework F puts on H and e.3.2. Framework definitionsBrave induction (I L P b), first presented in [28], defines an inductive task in which all examples are ground atoms that should be covered in at least one answer set, i.e. entailed under brave entailment in ASP. The original definition did not consider atoms which should not be present in an answer set, namely negative examples. The two publicly available algo-rithms that realise brave induction, on the other hand, do allow for negative examples. We therefore upgrade the definition in this paper to allow negative examples3 as follows.−(cid:4)(cid:4), where B is an ASP program called the back-Definition 1. A brave induction (I L P b) task T b is a tuple (cid:3)B, S M , (cid:3)E−are sets of ground atoms called the positive and negative ground knowledge, S M is the hypothesis space and Eexamples (respectively). A hypothesis H ⊆ S M is said to be an inductive solution of T b (written H ∈ I L P b(T b)) if and only if ∃ A ∈ A S(B ∪ H) such that E+ ⊆ A and E− ∩ A = ∅.and E+, E+Cautious induction (I L P c ) was also first presented in [28]. It defines an inductive task where all of the examples should be covered in every answer set (i.e. entailed under cautious entailment in ASP) and that B ∪ H should be satisfiable (have at least one answer set). Similarly to brave induction, the original definition did not consider negative examples, but in Definition 2 we upgrade the framework to include negative examples.−(cid:4)(cid:4), where B is an ASP program called the back-Definition 2. A cautious induction (I L P c ) task T c is a tuple (cid:3)B, S M , (cid:3)E−are sets of ground atoms called the positive and negative ground knowledge, S M is the hypothesis space and Eexamples (respectively). A hypothesis H ⊆ S M is said to be an inductive solution of T c (written H ∈ I L P c(T c)) if and only if A S(B ∪ H) (cid:17)= ∅ and ∀ A ∈ A S(B ∪ H), E+ ⊆ A and E− ∩ A = ∅.and E+, E+Brave induction alone can only reason about what should be true (or false) in a single answer set of B ∪ H . It cannot specify other brave tasks such as enforcing that two atoms are both bravely entailed, but not necessarily in the same answer set. Induction of stable models [30] (I L P sm), on the other hand, generalises the notion of brave induction as shown in Definition 4. The following terminology is first introduced.Definition 3. A partial interpretation e is a pair of sets of ground atoms (cid:3)einc, eexc(cid:4). An interpretation I is said to extend e iff einc ⊆ I and eexc ∩ I = ∅.3 Note that in I L P b a negative example ei can be easily simulated by adding a rule ai:- not ei to the background knowledge and giving ai as a positive example (where ai is a new atom (unique to ei) which does not appear anywhere in the original task).M. Law et al. / Artificial Intelligence 259 (2018) 110–146115Definition 4. An induction of stable models (I L P sm ) task T sm is a tuple (cid:3)B, S M , (cid:3)E(cid:4)(cid:4), where B is an ASP program called the background knowledge, S M is the hypothesis space and E is a set of partial interpretations called the examples. A hypothesis H is said to be an inductive solution of T sm (written H ∈ I L P sm(T sm)) if and only if H ⊆ S M and ∀e ∈ E, ∃ A ∈ A S(B ∪ H)such that A extends e.Note that a brave induction task can be thought of as a special case of induction of stable models, with exactly one (partial interpretation) example.We now consider the Learning from Answer Sets framework introduced in [31]. This is the first framework capable of unifying the concepts of brave and cautious induction. The idea is to use examples of partial interpretations which should or should not be extended by answer sets of B ∪ H .Definition 5. A Learning from Answer Sets task is a tuple T = (cid:3)B, S M , (cid:3)Eand Eground knowledge, S M is the hypothesis space and Epositive and negative examples. A hypothesis H ⊆ S M is an inductive solution of T (written H ∈ I L P L A S (T )) if and only if:−(cid:4)(cid:4) where B is an ASP program called the back-are sets of partial interpretations called, respectively, the +, E+−1. ∀e2. ∀e+ ∈ E− ∈ E+ ∃ A ∈ A S(B ∪ H) such that A extends e+− (cid:3) A ∈ A S(B ∪ H) such that A extends e−Note that this definition combines properties of both the brave and cautious semantics: the positive examples must each be bravely entailed, whereas the negation of each negative example must be cautiously entailed.Example 2. Consider an I L P L A S learning task whose background knowledge B contains definitions of the structure of a4x4 Sudoku board; i.e. definitions of cell, same_row, same_col and same_block (where same_row, same_col and same_block are true only for two different cells in the same row, column or block).⎧⎪⎪⎪⎪⎪⎪⎪⎪⎪⎨⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩B =cell((1, 1)). cell((1, 2)). . . . cell((4, 4)).same_row((X1, Y), (X2, Y)):- cell((X1, Y)), cell((X2, Y)), X1 (cid:17)= X2.same_col((X, Y1), (X, Y2)):- cell((X, Y1)), cell((X, Y2)), Y1 (cid:17)= Y2.block((1, 1), 1). block((1, 2), 1). block((2, 1), 1). block((2, 2), 1).block((3, 1), 2). block((3, 2), 2). block((4, 1), 2). block((4, 2), 2).block((1, 3), 3). block((1, 4), 3). block((2, 3), 3). block((2, 4), 3).block((3, 3), 4). block((3, 4), 4). block((4, 3), 4). block((4, 4), 4).same_block(C1, C2):- block(C1, B), block(C2, B), C1 (cid:17)= C2.⎫⎪⎪⎪⎪⎪⎪⎪⎪⎪⎬⎪⎪⎪⎪⎪⎪⎪⎪⎪⎭For the purposes of this example, we will consider only a small hypothesis space S M but in practice this would be much ⎧larger.4S M =+ =E− =E⎫(cid:10)⎪⎪⎪⎪⎪⎨⎪⎪⎪⎪⎪⎩0{value(C, 1), value(C, 2), value(C, 3), value(C, 4)}1:- cell(C).1{value(C, 1), value(C, 2), value(C, 3), value(C, 4)}1:- cell(C).1{value(C, 1), value(C, 2), value(C, 3), value(C, 4)}2:- cell(C).:- same_row(C1, C2), value(C1, V), value(C2, V).:- same_col(C1, C2), value(C1, V), value(C2, V).:- same_block(C1, C2), value(C1, V), value(C2, V).(cid:3){value((1, 1), 1)}, ∅(cid:4)⎧(cid:3){value((1, 1), 1), value((1, 3), 1)}, ∅(cid:4)⎪⎪⎪⎨(cid:3){value((1, 1), 1), value((3, 1), 1)}, ∅(cid:4)(cid:3){value((1, 1), 1), value((2, 2), 1)}, ∅(cid:4)⎪⎪⎪⎩(cid:3){value((1, 1), 1), value((1, 1), 2)}, ∅(cid:4)(cid:3)∅, {value((1, 1), 1), value((1, 1), 2), value((1, 1), 3), value((1, 1), 4)}(cid:4)⎪⎪⎪⎪⎪⎬⎪⎪⎪⎪⎪⎭(cid:11)⎫⎪⎪⎪⎬⎪⎪⎪⎭We need to be able to say that there should be at least one answer set that assigns a value to a cell, or otherwise the empty hypothesis would be sufficient. This is captured by our positive example which causes at least one of the choice rules to be part of a solution in order to be covered. Our first three negative examples require the three constraints to be also included in a solution. Without each one of these negative examples, at least one constraint could be left out of the solution. The fourth negative example means that the upper bound of the counting aggregate in the choice rule must be 1, as otherwise there would be answer sets in which cell (1, 1) was assigned to both 1 and 2. Finally, the fifth negative 4 A larger version of this learning task with a hypothesis space with 542 rules can be found in the manual for our learning algorithm, ILASP [41].116M. Law et al. / Artificial Intelligence 259 (2018) 110–146example forces that the lower bound of the choice rule should be 1 as otherwise there would be answer sets in which (1, 1) was not assigned to any of the values between 1 and 4. Hence, one possible inductive solution is:⎧⎪⎪⎨H =⎪⎪⎩1{value(C, 1), value(C, 2), value(C, 3), value(C, 4)}1:- cell(C).:- same_row(C1, C2), value(C1, V), value(C2, V).:- same_col(C1, C2), value(C1, V), value(C2, V).:- same_block(C1, C2), value(C1, V), value(C2, V).⎫⎪⎪⎬⎪⎪⎭The only other solutions within the hypothesis space S M are those that contain H and also extra redundant choice rules, such as 0{value(C, 1), value(C, 2), value(C, 3), value(C, 4)}1:- cell(C).Note that we need I L P L A S ’s combination of brave and cautious induction to separate the correct hypothesis from the incorrect hypotheses.+, E• If we instead use brave induction, whichever examples we use, if H is a solution, then any of the choice , containing only the choice rule −(cid:4) such that H ∈− ∩ A = ∅. As A S(B ∪ H) ⊂rules on their own is also a solution. For instance, consider the hypothesis H0{value(C, 1), value(C, 2), value(C, 3), value(C, 4)}1:- cell(C). For any examples (cid:3)EI L P b((cid:3)B, (cid:3)EA S(B ∪ H−(cid:4)(cid:4)), there must be an answer set A of B ∪ H such that E(cid:20)), any such answer set is also an answer set of B ∪ His also a solution of the task.+ ⊆ A and E; and hence, H• If we use cautious induction, we have to give examples which are either true in every answer set, or false in every answer set. Therefore, we could not give any examples about the value predicate – for each atom value(x, y) (where x and y range from 1 to 4), there is at least one answer set of B ∪ H that contains value(x, y) and at least one that does not; this means that if value(x, y) is given as either a positive or negative example, H will not be a solution of the task.This means that for any I L P c task T c such that H is a solution, any subset of the hypothesis space S M is also a solution of T c .+, E(cid:20)(cid:20)(cid:20)Note that none of the learning frameworks we have considered so far (I L P L A S included) can incentivise learning a weak constraint. This is because the frameworks only have examples of what should be in some, all or none of the answer sets of B ∪ H . Any solution H containing a weak constraint W will have the same answer sets with W removed and H\{W }would therefore be a shorter (more optimal5) solution. The notion of ordering examples is needed to incentivise learning weak constraints, in order to enforce which answer sets of B ∪ H should dominate other answer sets.Definition 6. An ordering example is a tuple o = (cid:3)e1, e2, op(cid:4) where e1 and e2 are partial interpretations and op is a binary comparison operator (<, >, =, ≤, ≥ or (cid:17)=). An ASP program P bravely respects o iff ∃ A1, A2 ∈ A S(P ) such that all of the following conditions hold: (i) A1 extends e1; (ii) A2 extends e2; and (iii) (cid:3) A1, A2, op(cid:4) ∈ ord(P ). P cautiously respects o iff (cid:3) A1, A2 ∈ A S(P ) such that all of the following conditions hold: (i) A1 extends e1; (ii) A2 extends e2; and (iii) (cid:3) A1, A2, op(cid:4) /∈ord(P ).Note that Definition 6 generalises our initial definition of ordering examples given in [23], where ordering examples had only the operator <, and we could not express examples of pairs of answer sets which were equally preferred. In Section 5we show that this extension allows us to learn a wider class of programs. We now define the notion of Learning from Ordered Answer Sets (I L P L O A S ).Definition 7. A Learning from Ordered Answer Sets task is a tuple T = (cid:3)B, S M , (cid:3)Ecalled the background knowledge, S M is the hypothesis space, Etively, positive and negative examples, and O b and O c are sets of ordering examples over Eorderings. A hypothesis H ⊆ S M is an inductive solution of T (written H ∈ I L P L O A S (T )) if and only if:−, O b, O c(cid:4)(cid:4) where B is an ASP program, are sets of partial interpretations called, respec-called brave and cautious and E+, E+−+1. H ∈ I L P L A S ((cid:3)B, S M , (cid:3)E2. ∀o ∈ O b B ∪ H bravely respects o3. ∀o ∈ O c B ∪ H cautiously respects o−(cid:4)(cid:4))+, ENote that the orderings are only over positive examples. We chose to make this restriction as there does not appear to be any scenario where a hypothesis would need to respect orderings which are not extended by any pair of answer sets of B ∪ H .Example 3. Consider the I L P L O A S task T = (cid:3)B, S M , (cid:3)Efollows:+, E−, O b, O c(cid:4)(cid:4) where the individual components of the task are as 5 It is common practice in ILP to search for the optimal (shortest) solution(s).M. Law et al. / Artificial Intelligence 259 (2018) 110–146117(cid:11)+1 , e• B = {0{p, q}2.}• S M is unrestricted (i.e. S M is the set of all normal rules, choice rules and hard and weak constraints).(cid:10)+ =• Ee− = ∅• E(cid:10)• O b =(cid:10)• O c =where e(cid:11)++2 , <(cid:4)(cid:3)e1 , e(cid:11)++1 , =(cid:4)(cid:3)e1 , e= (cid:3){p}, ∅(cid:4) and e= (cid:3)∅, {p}(cid:4)+2+2+1The positive examples of this task are already satisfied by the background knowledge, which has the answer sets ∅, {p}, {q} and {p, q}. As there are no negative examples, it remains to find a set of weak constraints such that there is at least one answer set which contains p which is preferred to at least one answer set which does not contain p and all answer sets which contain p are equally optimal.One such hypothesis is the single weak constraint :∼ not p.[1@1].The frameworks discussed so far have examples which can only express the properties of a learned hypothesis H together with a fixed background knowledge B. These properties are on the answer sets of B ∪ H (and the ordering of these answer sets). In [24], we presented a new learning framework that uses context-dependent examples. Each example comes with its own context, which is an ASP ch program C . Examples then express properties of B ∪ H ∪ C , meaning that by using multiple examples (with different contexts), we can express that B ∪ H ∪ C1 should have some properties and that B ∪ H ∪ C2 should have different properties.Definition 8. A context-dependent partial interpretation (CDPI) is a pair (cid:3)e, C(cid:4), where e is a partial interpretation and C is an ASP ch program, called a context. A context-dependent ordering example (CDOE) o is a tuple (cid:3)(cid:3)e1, C1(cid:4), (cid:3)e2, C2(cid:4), op(cid:4), where the first two elements are CDPIs and op is a binary comparison operator (<, >, =, ≤, ≥ or (cid:17)=). P is said to bravely respect o if ∃ A1 ∈ A S(P ∪ C1), ∃ A2 ∈ A S(P ∪ C2) such that A1 extends e1, A2 extends e2 and (cid:3) A1, A2, op(cid:4) ∈ ord(P , A S(P ∪ C1) ∪ A S(P ∪C2)). A program P is said to cautiously respect o if ∀ A1 ∈ A S(P ∪ C1), ∀ A2 ∈ A S(P ∪ C2) such that A1 extends e1 and A2extends e2, (cid:3) A1, A2, op(cid:4) ∈ ord(P , A S(P ∪ C1) ∪ A S(P ∪ C2)).When examples are given with empty contexts, they are equivalent to examples in I L P L O A S . Note also that contexts do not contain weak constraints. In fact, the operator (cid:12)P defines the ordering over two answer sets based on the weak constraints in one program P . So, given a CDOE (cid:3)(cid:3)e1, C1(cid:4), (cid:3)e2, C2(cid:4)(cid:4) such that C1 and C2 contain different weak constraints, it is not clear which program to consider for computing the ordering of answer sets – i.e. whether they should be checked against the weak constraints in P , P ∪ C1, P ∪ C2 or P ∪ C1 ∪ C2.We now present a formal definition of the I L P contextL O A Sframework.−, O b, O c(cid:4)(cid:4)Definition 9. A Context-dependent Learning from Ordered Answer Sets (I L P contextwhere B is an ASP program called the background knowledge, S M is the set of rules allowed in the hypotheses (the are finite sets of CDPIs called, respectively, positive and negative examples, and O b and O chypothesis space), E+called, respectively, brave and cautious context-dependent orderings. A hypothesis H ⊆ S Mare finite sets of CDOEs over Eis an inductive solution of T (written H ∈ I L P contextL O A S ) task is a tuple T = (cid:3)B, S M , (cid:3)Eand E+, EL O A S (T )) if and only if:−+++, ∃ A ∈ A S(B ∪ C ∪ H) st A extends e, (cid:3) A ∈ A S(B ∪ C ∪ H) st A extends e+, C(cid:4) ∈ E−, C(cid:4) ∈ E1. ∀(cid:3)e2. ∀(cid:3)e3. ∀o ∈ O b, B ∪ H bravely respects o4. ∀o ∈ O c , B ∪ H cautiously respects o−−In [24], we showed that context-dependent examples could be used to simplify the encoding of certain tasks, by splitting the background knowledge into contexts that were only relevant to particular examples. Although any I L P contexttask can L O A Sbe transformed into an I L P L O A S task, in general this requires parts of the examples to be encoded in the background knowledge. Example 4 shows such a transformation.Example 4. Consider a simple scenario where we have a machine that has a single configuration parameter a, which is allowed to take any natural number as its value. A user is allowed to input another natural number b, and if a > b, the machine should beep.Two example scenarios could be encoded as the context-dependent positive examples (cid:3)(cid:3){beep}, ∅(cid:4), {value(a, 3).value(b, 2).}(cid:4), and (cid:3)(cid:3)∅, {beep}(cid:4), {value(a, 4). value(b, 20).}(cid:4). A task containing these examples and an empty back-ground knowledge requires an inductive solution that when combined with the context of the first example would have at least one answer set containing beep, and when combined with the second example would have at least one answer set not containing beep. If we were expressing the same task in I L P L O A S the above two scenarios would be represented considering the background knowledge:118M. Law et al. / Artificial Intelligence 259 (2018) 110–146Table 1A summary of the available systems for learning under the answer set se-mantics.FrameworkSystemsI L P bI L P smI L P cI L P L A SI L P L O A SI L P contextL O A SXHAIL [42], ASPAL [38] and RASPAL [43]ILASP [32]ILASP [32]ILASP [32]Table 2A summary of the complexity of the various learning frameworks.FrameworkComplexity of verificationComplexity of deciding satisfiabilityI L P bI L P smI L P cI L P L A SI L P L O A SI L P contextL O A SN P -completeN P -completeD P -completeD P -completeD P -completeD P -completeN P -completeN P -complete(cid:2)P2 -complete(cid:2)P2 -complete(cid:2)P2 -complete(cid:2)P2 -complete(cid:10)B =1{value(a, 3), value(a, 4)}1.1{value(b, 2), value(b, 20)}1.(cid:11)The context-dependent examples could then be mapped to the non context-dependent examples (cid:3){value(a, 3),value(b, 2), beep}, ∅(cid:4) and (cid:3){value(a, 4), value(b, 20)}, {beep}(cid:4). In fact, in [24], we show that there is a general map-ping from I L P contextto I L P L O A S . This mapping, just as the simplified mapping here, depends on encoding the examples L O A Sin the background knowledge, which abuses the purpose of the background knowledge. The contexts in context-dependent examples allow us instead to separate information that is truly background knowledge, which applies in all scenarios, from information that is part of a particular example.3.3. Systems for learning under the answer set semanticsThe current publicly available systems for ILP can be categorised according to the 6 frameworks presented in this section (Table 1). It should be noted that although there are no systems which directly solve I L P c or I L P sm tasks, both can be simply translated into I L P L A S tasks, and can therefore be solved by the ILASP system.The ILED [21] system is an incremental extension of XHAIL, that is specifically targeted at learning Event Calculus [20]theories. The underlying mechanism is based on brave induction, but each of its examples are in terms of two sequential time points.4. ComplexityIn this section, we discuss the complexity of each of the learning frameworks presented in Section 3 with respect to two decision problems: verification, deciding whether a given hypothesis H is an inductive solution of a task T ; and satisfiability, deciding whether a learning task T has any inductive solutions. A summary of the results is shown in Table 2. To aid readability, the proofs of the propositions stated in this section are given in appendix. All complexities discussed in this section are for propositional versions of the frameworks (both the background knowledge and hypothesis space of each learning task is ground).4.1. Learning from answer sets with stratified summing aggregatesAs there are existing results on the complexity of solving aggregate stratified programs, it is useful to introduce a new learning framework I L P sL A S , which is a generalization of I L P L A S , that allows summing aggregates in the bodies of rules, as long as they are stratified. The existing results on the complexity of these programs then allow us to prove the complexity of I L P sL A S . Hence, as we can show that I L P L O A S reduces to I L P sL A S , this is helpful in proving the complexity of I L P L O A S .A summing aggregate s is of the form l#sum{a1 = w1, . . . ,a n = wn}u, where l, u and w1, . . . , wn are integers and ≤ u, where W S is the set {wi |a1, . . . , an are atoms. s is satisfied by an interpretation I if and only if l ≤i ∈ [0..n], ai ∈ I}. We now recall the definition of aggregate stratification from [44]. We slightly simplify the definition by considering only propositional programs without disjunction.wi∈W S w i(cid:12)(cid:2)(cid:13)Definition 10. A propositional logic program P , in which aggregates occur only in bodies of rules, is stratified on an aggregateagg if there is a level mapping (cid:22) (cid:22) from Atoms(P ) to ordinals, such that for each rule R ∈ P , the following holds:M. Law et al. / Artificial Intelligence 259 (2018) 110–1461191. ∀b ∈ Atoms(body(R)) : ||b|| ≤ ||head(R)||2. If agg ∈ body(R), then ∀b ∈ Atoms(agg) : ||b|| < ||head(R)||P is said to be aggregate stratified if it is stratified on every aggregate in P .The intuition is that aggregate stratification forbids recursion through aggregates. In general aggregate stratified programs have a lower complexity than non-aggregate stratified programs. Aggregate stratification has nothing to do with negation as failure, and therefore, whether a program is aggregate stratified is unrelated to whether it is stratified in the usual sense. Note that constraints and choice rules can be added in to any aggregate stratified program without breaking stratification so long as no atoms in the head of the choice rule are on a lower level than any atom in the body. This is illustrated by the following example.Example 5. Any constraint :- b1, . . . ,b n, not c1, . . . ,not c m can be rewritten as s:- b1, . . . ,b n, not c1, . . . ,not c m,not s where s is a new atom. s can then be mapped to a higher level than any other atom.A choice rule l{h1, . . . ,h o}u:- b1, . . . ,b n, not c1, . . . , not cm can be rewritten as:h1:- b1, . . . ,b n, not c1, . . . , not cm, not h(cid:20)1.h(cid:20)1:- b1, . . . ,b n, not c1, . . . , not cm, not h1.. . .ho:- b1, . . . ,b n, not c1, . . . , not cm, not h(cid:20)o.h(cid:20)o:- b1, . . . ,b n, not c1, . . . , not cm, not ho.s:- b1, . . . , bn, not c1, . . . ,not c m, {h1, . . . , hn}l − 1, not s.s(cid:20):- b1, . . . ,b n, not c1, . . . ,not c m, u + 1{h1, . . . ,h n}, not s(cid:20).o, s, s(cid:20)1, . . . ,h (cid:20)are all new atoms. s and s(cid:20)where h(cid:20)i can be given the same level as hi (if they did not occur in the previous program then they should be given a new level one below s and s(cid:20)). Provided the previous program was aggregate stratified, then this new one is too. To avoid constantly using this mapping, we will refer to programs with choice rules and constraints as also being aggregate stratified.can both be given a new highest level and each h(cid:20)Lemma 1. [44] Deciding whether an aggregate stratified propositional program without disjunction cautiously entails an atom is co-N P -complete.Corollary 1. Deciding whether an aggregate stratified propositional program without disjunction bravely entails an atom is N P -complete.Proof. We first show that deciding whether an aggregate stratified propositional program without disjunction bravely en-tails an atom is in N P . We do this by showing that there is a polynomial reduction from this problem to the complement of the problem in Lemma 1 (which by definition of co-N P must be in N P ). The complement of the problem in Lemma 1 is de-ciding whether a non disjunctive aggregate stratified program does not cautiously entail an atom. Take any non-disjunctive aggregate stratified program P and any atom a and let neg_a be an atom that does not occur in P . P |=b a if and only if P ∪ {neg_a:- not a.} (cid:17)|=c neg_a. So the decision problem is in N P .It remains to show that deciding whether an aggregate stratified propositional program without disjunction bravely entails an atom is N P -hard. We do this by showing that any problem in N P can be reduced in polynomial time to deciding the satisfiability of an aggregate stratified propositional program without disjunction.Consider an arbitrary N P problem D. The complement of D, ¯D, must be in co-N P (by definition of co-N P ). Hence, by Lemma 1, there is a polynomial reduction from ¯D to deciding whether an aggregate stratified propositional program without disjunction cautiously entails an atom. We define the polynomial reduction from D to deciding whether an aggregate stratified propositional program without disjunction bravely entails an atom as follows: for any instance I of D, let P and a be the program and atom given by the polynomial reduction from the complement of I to deciding cautious entailment; (cid:20)as the program P ∪ {neg_a:- not a.} (where neg_a is a new atom). I returns true if and only if P (cid:17)|=c a if and define P(cid:20) |=b neg_a. Hence, as Pis still aggregate stratified (the new atom neg_a can be put in the top strata), this is a only if Ppolynomial reduction from D to deciding whether an aggregate stratified propositional program without disjunction bravely entails an atom. Hence, the decision problem is N P -hard. (cid:2)(cid:20)We can now introduce our extra learning task, Learning from Answer Sets with Stratified Aggregates (I L P sL A S ). It is the same as Learning from Answer Sets, except for allowing summing aggregates in the bodies of the rules in B and S M , as long as 120M. Law et al. / Artificial Intelligence 259 (2018) 110–146Fig. 1. Chains of polynomial reductions where each arrow denotes that there is a polynomial reduction from one framework to another.B ∪ S M is aggregate stratified. Note that the condition of B ∪ S M being aggregate stratified implies that for any hypothesis H ⊆ S M , B ∪ H is aggregate stratified.4.2. Relationships between the learning tasksIn this section we prove for both decision problems that I L P b and I L P sm both reduce to each other polynomially. We also show that for both decision problems there is a chain of polynomial reductions from I L P c to I L P L A S to I L P contextto L O A SI L P L O A S to I L P sL A S . This chain of reductions is then used in proving that all four tasks share the same complexity for both decision problems. By proving that I L P c is O-hard and I L P sL A S is in O for some complexity class O, we prove that all four tasks are O-complete. Similarly as I L P b and I L P sm both reduce polynomially to each other for both decision problems, if for one of the problems I L P b is O-complete for some class then so is I L P sm. The chains of reductions are shown in Fig. 1.Proposition 1 shows that the complexity of I L P b and I L P sm coincide for both decision problems.Proposition 1.1. Deciding both verification and satisfiability for I L P b reduces polynomially to the corresponding I L P sm decision problem.2. Deciding both verification and satisfiability for I L P sm reduces polynomially to the corresponding I L P b decision problem.Proposition 2 shows that there is a chain of polynomial reductions from I L P c to I L P L A S to I L P L O A S to I L P contextL O A SL A S for both decision problems.I L P sto Proposition 2.1. Deciding both verification and satisfiability for I L P c reduces polynomially to the corresponding I L P L A S decision problem.2. Deciding both verification and satisfiability for I L P L A S reduces polynomially to the corresponding I L P context3. Deciding both verification and satisfiability for I L P contextL O A S4. Deciding both verification and satisfiability for I L P L O A S reduces polynomially to the corresponding I L P sL O A S decision problem.reduces polynomially to the corresponding I L P L O A S decision problem.L A S decision problem.4.3. Complexity of deciding verification and satisfiability for each frameworkFor each of the learning frameworks, we prove the complexity of deciding verification and satisfiability. We start with the I L P b and I L P sm frameworks, for which both decision problems are N P -complete.Proposition 3. Verifying whether a given H is an inductive solution of a general I L P b task is N P -complete.Corollary 2. Verifying whether a given H is an inductive solution of a general I L P sm task is N P -complete.Proposition 4. Deciding the satisfiability of a general I L P b task is N P -complete.Corollary 3. Deciding the satisfiability of a general I L P sm task is N P -complete.We have now proven the complexity of deciding verification and satisfiability for I L P b and I L P sm, proving the corre-sponding entries in Table 2. It remains to show the complexities for I L P c , I L P L A S , I L P L O A S and I L P contextL O A S .reduces to I L P sAs we have shown that I L P c reduces to I L P L A S which, in turn, reduces to I L P L O A S , which reduces to I L P contextL O A S and that I L P contextL A S (all in polynomial time), to prove the complexity of verifying a hypothesis for each framework, L O A Sit suffices to show that I L P c is D P -hard (thus also proving the hardness for each of the other frameworks) and that I L P sL A Sis a member of D P (thus proving membership for the other frameworks). This shows that each framework is both a member of D P and also D P -hard, and therefore must be D P -complete.Proposition 5. Deciding verification for I L P sL A S is a member of D P .M. Law et al. / Artificial Intelligence 259 (2018) 110–146121Proposition 6. Deciding verification for I L P c is D P -hard.We can now prove the complexity of deciding verification for I L P c , I L P L A S and I L P L O A S . This proves the corresponding entries in Table 2.Theorem 2. Deciding whether a given H is a solution of any I L P c , I L P L A S , I L P L O A S or I L P contextL O A Stask is D P -complete in each case.Proof. By Proposition 6, deciding the verification for I L P c is D P -hard. By Proposition 2, deciding the verification for I L P creduces to deciding verification for I L P L A S which, in turn, reduces to deciding verification for I L P contextL O A S , which reduces to deciding satisfiability for I L P L O A S , which again reduces to deciding verification for I L P sL A S and by Proposition 5, deciding verification for I L P sL A S is a member of D P . Deciding verification for each of these learning frameworks must therefore be both a member of D P and must be D P -hard. Hence, deciding verification for each framework is D P -complete. (cid:2)Similarly, to show that deciding satisfiability is (cid:2)P2 -complete for each framework, we only need to show that I L P sL A S is a member of (cid:2)P2 and I L P c is (cid:2)P2 -hard.Proposition 7. Deciding satisfiability for I L P sL A S is in (cid:2)P2 .Proposition 8. Deciding satisfiability for I L P c is (cid:2)P2 -hard.We can now prove the complexity of deciding satisfiability for I L P c , I L P L A S and I L P L O A S . This proves the remaining entries in Table 2.Theorem 3. Deciding the satisfiability of any I L P c, I L P L A S , I L P L O A S or I L P contextL O A Stask is (cid:2)P2 -complete in each case.Proof. (similar to the proof of Theorem 2) By Proposition 8, deciding satisfiability for I L P c is (cid:2)P2 -hard. By Proposition 2, deciding satisfiability for I L P c reduces to deciding satisfiability for I L P L A S which, in turn, reduces to deciding satisfiability for I L P contextL A S . By Proposition 7, deciding satisfiability for I L P s2 . Deciding satisfiability for each of these learning frameworks is therefore both a member of (cid:2)PL O A S , which reduces to deciding satisfiability for I L P L O A S , which again reduces to deciding satisfiability of I L P s2 -hard. Hence, deciding satisfiability for each framework is (cid:2)P2 -complete. (cid:2)L A S is in (cid:2)P2 and is (cid:2)P4.4. Considering noisy examplesAlthough the frameworks considered in this paper were originally presented under the assumption that all examples were perfectly labeled (i.e. there is no noise in the examples), some of the systems for solving these tasks do consider noise when searching for an optimal solution.A common approach, used by both XHAIL [42] and ILASP [32] is to penalise hypotheses for the examples they do not cover. In ILASP, some examples can be labeled together with a penalty that must be paid if a hypothesis does not cover the example. Any example that is not labeled with a penalty must be covered by any inductive solution. Given a set of examples E, the score of a hypothesis H is said to be |H| + p(H, E), where |H| is the length of the hypothesis, and p(H, E)is the sum of the weights of all examples that are not covered by H . As a hypothesis is an inductive solution if and only if it covers all the examples that are labeled with a penalty, that were not labeled with an explicit penalty, the two decision problems of verification and satisfiability can be reduced to the corresponding decisions for non-noisy tasks (by simply removing any example with a penalty).5. GeneralityIn this section, we present a new notion of the generality of a learning framework. The aim is to get a sense of which class of ASP programs a framework is capable of learning, if given sufficient examples. Language biases tend, in general, to impose their own restrictions on the classes of program that can be learned. They are primarily used to aid the performance of the computation, rather than to capture intrinsic properties of a learning framework. In this section we will therefore consider learning tasks with unrestricted hypothesis spaces: hypotheses can be constructed from any set of (first order) normal rules, choice rules and hard and weak constraints. We assume each learning framework F to have a task consisting of a pair (cid:3)B, EF (cid:4), where B is the (first order ASP) background knowledge and EF is a tuple consisting of the examples for this framework; for example E L A S = (cid:3)Eare sets of partial interpretations.−(cid:4) where Eand E+, EAllowing an unrestricted hypothesis space raises the question of whether a learning framework is general enough to define tasks that lead to a particular set of hypotheses as the inductive solutions. On a first instance, we could say that a framework F is general enough to learn a hypothesis H if there is at least one task T F in this framework such that H is an inductive solution of T F . However, as shown in Example 6, such a “loose notion” of generality may lead to the trivial learning framework, whose learning tasks have no examples, as the most general framework possible.−+122M. Law et al. / Artificial Intelligence 259 (2018) 110–146Example 6. Consider the trivial learning framework I L P (cid:23) whose learning tasks are pairs (cid:3)B, E(cid:23)(cid:4), where E(cid:23) is the empty tuple and B is an ASP program. I L P (cid:23)((cid:3)B, E(cid:23)(cid:4)) is then the set of all ASP programs, i.e., every ASP program is a solution of every I L P (cid:23) task. Although for every hypothesis H , given any background knowledge B there is clearly a set of examples E(cid:23) such that H ∈ I L P (cid:23)((cid:3)B, E(cid:23)(cid:4)), every other possible hypothesis is also a solution of this same task, making it impossible to distinguish any hypothesis from another.It is clearly not sufficient to say that a framework is general enough to learn some target hypothesis (denoted from now on as H T ) if we can find at least one learning task with H T as a solution. What this definition lacks is a way to express that H T is a solution of a task T , but that some other (unwanted) hypothesis is not a solution of T . To capture this property of a learning framework we should be able to say that a task T can distinguish a hypothesis H T from the unwanted hypothesis. Pairs of target and unwanted hypotheses, which can be distinguished from each other, are an interesting starting point when considering generality of a learning framework. But this again might not be the only property of generality. Frameworks, (cid:20)2, such as brave induction, can distinguish the target hypothesis H T from two (or more) unwanted hypotheses, e.g., Hin two separate learning tasks, but they may not have a single learning task capable of accepting H T as inductive solution but neither H(cid:20)2. Consider for instance the following example.(cid:20)1 and H(cid:20)1 nor HExample 7. Imagine the scenario where we are observing a coin being tossed several times. Obviously there are two out-comes, and we would like to learn an ASP program whose answer sets correspond to these two different outcomes. Consider the background knowledge B to be empty, and the atoms heads and tails to be true when the coin lands on heads or tails respectively. Our target hypothesis H T is an ASP program such that A S(B ∪ H) = {{heads}, {tails}}. One such hypothesis could be the program H T = {1{heads, tails}1.}. Consider now the two hypotheses H= {heads.} and = {tails.}, which correspond to the coin always landing on heads or tails respectively. Neither of these hypothe-Hsis correctly represent the behaviour of the coin, so they are unwanted hypotheses. There is one answer set, {heads}, of (cid:20)B ∪ H2 separately with the tasks (cid:3)B, (cid:3){tails}, ∅(cid:4)(cid:4) and (cid:3)B, (cid:3){heads}, ∅(cid:4)(cid:4), respectively. But there is, however, no learning task for I L P b for which H T is an inductive solution and neither H(cid:20)1 and one answer set, {tails}, of B ∪ H(cid:20)2. I L P b can distinguish H T from H(cid:20)1 and from H(cid:20)2(cid:20)1(cid:20)1 nor H(cid:20)2 is.A more general notion of generality of learning framework can be considered, which looks at distinguishing a target hy-pothesis H T from a set of unwanted hypotheses S. In Section 5.2 we introduce the notion of one-to-many-distinguishability class of a learning framework. This corresponds to the class of pairs of single hypothesis H T ’s and set S’s of hypotheses for which a learning framework has at least one task that distinguishes H T from each hypothesis in S. Informally, this notion expresses the generality of a framework in finding a single target hypothesis in the presence of many unwanted hypotheses. In Section 5.3, we extend one-to-many-distinguishability class of a learning framework to many-to-many-distinguishability, which in turns captures the notion of distinguishing a set of target hypotheses S 1 from another set of unwanted hypothe-ses S2, with a single task.In the remainder of this section we explore these three new measures of generality, expressed as three different learning problems. One-to-one-distinguishability determines the hypotheses that a framework is general enough to learn, while ruling out another unwanted hypothesis; one-to-many-distinguishability determines the hypotheses that can be learned from within a space of unwanted hypotheses; and finally, many-to-many-distinguishability determines exactly which sets of hypotheses can be learned. We will prove properties of our three classes of generalities making use of a definition of strong reduction from one framework to another. Strong reduction is different from the concept of reduction presented in [45]. Definitions 11 and 12 present, respectively, a reformulation of the notion of reduction introduced in [45] and of our new concept of strong reduction.Definition 11. A framework F1 reduces to F2 (written F1 →r F2) if for every F1 task T F1 there is an F2 task T F2 such that I L P F1 (T F1 ) = I L P F2 (T F2 ). A framework F1 is at least as r-general as F2 if F2 →r F1; and F1 is more r-general than F2if F2 →r F1 and F1 (cid:4)r F2.−(cid:4)(cid:4) maps to the Example 8. Consider the I L P b and I L P c learning frameworks. I L P b →r I L P c , as any I L P b task (cid:3)B, (cid:3)E−}, (cid:3)∅, ∅(cid:4)(cid:4). I L P c does not, however, reduce to I L P b. Consider, for I L P c task (cid:3)B ∪ {:- not e. | e ∈ E−(cid:4)(cid:4) such that I L P b(T b) = I L P c(T c). instance, the I L P c task T c = (cid:3)∅, (cid:3){p}, ∅(cid:4)(cid:4) and assume that there is a task T b = (cid:3)B, (cid:3)EThe hypothesis H1 = {p.} ∈ I L P c(T c), and, given the assumption, H 1 is also in I L P b(T b). But consider now the hypothesis −(cid:4), then so does B ∪ H2. Thus, H2 = {0{p}1.}. Since A S(B ∪ H1) ⊆ A S(B ∪ H2), if B ∪ H1 has an answer set extending (cid:3)Eif H1 ∈ I L P b(T b) then H2 ∈ I L P b(T b). But, although H2 ∈ I L P b(T b), it is easy to see that H2 /∈ I L P c(T c), so making I L P b(T b)not equal to I L P c(T c). Hence, I L P c does not reduce to I L P b , and I L P c is more r-general than I L P b.+} ∪ {:- e. | e ∈ E+, E+, E+, EWe discuss the relationship between reductions and our own measures of generality in Section 6. Our notion of strong reduction differs from the above notion of reduction, in the fact that the reduced task must have the same background knowledge as the original task.M. Law et al. / Artificial Intelligence 259 (2018) 110–146123Definition 12. A framework F1 strongly reduces to F2 (written F1 →sr F2) if for every F1 task T F1F2 = (cid:3)B, EF2and F1 is more sr-general than F2 if F2 →sr F1 and F1 (cid:4)sr F2.(cid:4) there is an (cid:4) task T F2 such that I L P F1 (T F1 ) = I L P F2 (T F2 ). A framework F1 is at least as sr-general as F2 if F2 →sr F1; = (cid:3)B, EF1Proposition 9 shows the strong reduction relations between the frameworks considered in this paper. Note that although I L P c is more r-general than I L P b (as shown in Example 8), it is not more sr-general than I L P b . This is because without changing the background knowledge, I L P c cannot represent the same I L P b tasks.Proposition 9.1. I L P b →sr I L P sm →sr I L P L A S →sr I L P L O A S →sr I L P contextL O A S2. I L P c →sr I L P L A SProof.1. For any I L P b task T b = (cid:3)B, (cid:3)E+, E−(cid:4)(cid:4), I L P b(T b) = I L P sm((cid:3)B, (cid:3){(cid:3)E+, E−(cid:4)}(cid:4)(cid:4))For any I L P sm task T sm = (cid:3)B, (cid:3){e1, . . . , en}(cid:4)(cid:4), I L P sm(T sm) = I L P L A S ((cid:3)B, (cid:3){e1, . . . , en}, ∅(cid:4)(cid:4))−, ∅, ∅(cid:4)(cid:4))For any I L P L A S task T L A S = (cid:3)B, (cid:3)EFor any partial interpretation e, let c(e) be the CDPI (cid:3)e, ∅(cid:4). For any I L P L O A S task T L O A S = (cid:3)B, (cid:3)EI L P L O A S (T L O A S ) = I L P contextO c}(cid:4)(cid:4))−, O b, O c(cid:4)(cid:4), −}, {(cid:3)c(e1), c(e2)(cid:4) | (cid:3)e1, e2(cid:4) ∈ O b}, {(cid:3)c(e1), c(e2)(cid:4) | (cid:3)e1, e2(cid:4) ∈−(cid:4)(cid:4), I L P L A S (T L A S ) = I L P L O A S ((cid:3)B, (cid:3)E+}, {c(e) | e ∈ E+, E+, E+, E−n2. For any I L P c task T c = (cid:3)B, (cid:3){e},∅(cid:4), . . . , (cid:3){e}, ∅(cid:4)}(cid:4)(cid:4)). Note that the empty I L P L A S positive example enforces that there is at least one answer set, and both the I L P c positive and negative examples are mapped to I L P L A S negative examples which enforce in the case of positive (resp. negative) examples that they are not false (resp. not true) in any answer set, and hence true (resp. false) in every answer set. (cid:2)}(cid:4)(cid:4), I L P c(T c) = I L P L A S ((cid:3)B, (cid:3){(cid:3)∅, ∅(cid:4)}, {(cid:3)∅, {e}(cid:4), . . . ,(cid:3)∅, {e}(cid:4), (cid:3){e}, {e+m−1L O A S ((cid:3)B, (cid:3){c(e) | e ∈ E−1 , . . . , e+1 , . . . , e+m−n+15.1. DistinguishabilityA one-to-one-distinguishability class captures those pairs of hypotheses H 1 and H2 that can be distinguished from each other with respect to a given possible background knowledge.Definition 13. The one-to-one-distinguishability class of a learning framework F (denoted D11(F )) is the set of tuples (cid:3)B, H1, H2(cid:4) of ASP programs for which there is at least one task T F = (cid:3)B, EF (cid:4) such that H1 ∈ F (T F ) and H2 /∈ F (T F ). For each (cid:3)B, H1, H2(cid:4) ∈ D11(F ), T F is said to distinguish H1 from H2 with respect to B. Given two frameworks F1 and F2, we say that F1 is at least as (resp. more) D11 -general as (resp. than) F2 if D11(F1) (resp. D11(F2) ⊆ D11(F 2) ⊂ D11(F 1)).Note that the one-to-one-distinguishability relationship is not symmetric; i.e. there are pairs of hypotheses H 1 and H2such that, given a background knowledge B, H 1 can be distinguished from H 2, but H2 can not be distinguished from H 1. This is illustrated by Example 9.Example 9. Consider a background knowledge B that defines the concepts of cell, same_block, same_row and same_column for a 4x4 Sudoku grid.Let H1 be the incomplete description of the Sudoku rules:1 { value(C, 1), value(C, 2), value(C, 3), value(C, 4) } 1 :- cell(C).:- value(C1, V), value(C2, V), same_row(C1, C2).:- value(C1, V), value(C2, V), same_col(C1, C2).Also let H2 be the complete description of the Sudoku rules:1 { value(C, 1), value(C, 2), value(C, 3), value(C, 4) } 1 :- cell(C).:- value(C1, V), value(C2, V), same_row(C1, C2).:- value(C1, V), value(C2, V), same_col(C1, C2).:- value(C1, V), value(C2, V), same_block(C1, C2).I L P b can distinguish H1 from H2 with respect to B. This can be seen using the task (cid:3)B, (cid:3){value((1, 1), 1),value((2, 2), 1)}, ∅(cid:4)(cid:4). On the other hand, I L P b cannot distinguish H2 from H1. Whatever examples are given in a learning − ∩ A = ∅, where A is an answer set of B ∪ H 2. But answer sets task to learn H2, it must be the case that Eof B ∪ H2 are also answer sets of B ∪ H1. So A is also an answer set of B ∪ H 1, which implies that H1 satisfies the same examples and is a solution of the same learning task.+ ⊆ A and E124M. Law et al. / Artificial Intelligence 259 (2018) 110–146Table 3A summary of the sufficient and necessary conditions in each learning framework for a hypothesis H1 to be distinguishable from another hypothesis H2 with respect to a background knowledge B.Framework FI L P (cid:23)I L P bI L P smI L P cI L P L A SI L P L O A SI L P contextL O A S1(F)Sufficient/necessary condition for (cid:3)B, H1, H2(cid:4) to be in D1⊥A S(B ∪ H1) (cid:2) A S(B ∪ H2)A S(B ∪ H1) (cid:2) A S(B ∪ H2)A S(B ∪ H1) (cid:17)= ∅ ∧ ( A S(B ∪ H2) = ∅ ∨ (Ec(B ∪ H1) (cid:2) Ec(B ∪ H2)))A S(B ∪ H1) (cid:17)= A S(B ∪ H2)( A S(B ∪ H1) (cid:17)= A S(B ∪ H2)) ∨ (ord(B ∪ H1) (cid:17)= ord(B ∪ H2))(B ∪ H1 (cid:17)≡s B ∪ H2) ∨ (∃C ∈ ASP ch st ord(B ∪ H1 ∪ C) (cid:17)= ord(B ∪ H2 ∪ C))In fact, Proposition 10 generalises Example 9 showing that I L P b cannot distinguish any program containing a constraint from the same program without the constraint.Proposition 10. I L P b cannot distinguish any hypothesis H which contains a constraint C from H\{C}, with respect to any background knowledge.Proof. Assume for contradiction that there is a hypothesis H = H(cid:3)B, (cid:3)E−(cid:4)(cid:4) such that H ∈ I L P b(T b) and H(cid:20) /∈ I L P b(T b).+, E(cid:20) ∪ C where C is a constraint and an I L P b task T b =⇒ ∃ A ∈ A S(B ∪ H) such that E+ ⊆ A and E− ∩ A = ∅. But as C is a constraint A S(B ∪ H) ⊆ A S(B ∪ H(cid:20)) and so A ∈(cid:20)).A S(B ∪ H⇒ ∃ A ∈ A S(B ∪ H⇒ H(cid:20) ∈ I L P b(T b). Contradiction! (cid:2)(cid:20)) such that E+ ⊆ A and E− ∩ A = ∅.One useful property is that if there is a strong reduction from one framework F1 to another framework F2 then 1 -general than F1, even in the case when there is no 1(F1) ⊆ D11(F2). Note that F2 is not guaranteed to be more D1D1reduction from F2 to F1.Proposition 11. For any two frameworks F1 and F2: F1 →sr F2 ⇒ D11(F1) ⊆ D11(F2).Proof. Assume that F1 →sr F2. Take any (cid:3)B, H1, H2(cid:4) ∈ D11(F1). There must be some task T F1 , with background knowledge B, such that H1 ∈ I L P F1 (T F1 ) and H2 /∈ I L P F1 (T F1 ). Hence, as F1 →sr F2, there must be some task T F2 , with background knowledge B, such that H1 ∈ I L P F2 (T F2 ) and H2 /∈ I L P F2 (T F2 ). So (cid:3)B, H1, H2(cid:4) ∈ D11(F2). Hence, D11(F1) ⊆ D11(F2). (cid:2)As there are clear strong reductions (shown by Proposition 9), an ordering of the one-to-one-distinguishability classes of the frameworks emerges (shown in Corollary 4).Corollary 4.1. D12. D11(I L P b) ⊆ D11(I L P c) ⊆ D11(I L P sm) ⊆ D11(I L P L A S )1(I L P L A S ) ⊆ D11(I L P L O A S ) ⊆ D11(I L P contextL O A S )While this does give us information about the ordering of the power of the frameworks to distinguish between hy-potheses, it does not tell us, for example, what the relationship is between the distinguishability classes of I L P b and I L P c . It does not tell us which of the ⊆’s are strict (in fact, D11(I L P sm), but the rest are strict subset re-lations). For each framework, Table 3 shows the necessary and sufficient condition needed to be able to distinguish hypotheses. In the case of the cautious induction framework, the condition makes use of a new notation. Given a program P , Eb(P ) = {i1 ∧ . . . ∧ im ∧ not e1 ∧ . . . ∧ not en|∃ A ∈ A S(P ) st i1, . . . ,i m ∈ A and e1, . . . ,e n /∈ A}, i.e. Eb(P ) denotes the set of conjunctions of literals that are true in at least one answer set of P . Similarly, we use Ec(P ) to denote the set of conjunctions of literals that are true in every answer set of P . The following property holds.1 (I L P b) = D1Proposition 12. For any programs P 1 and P 2, Eb(P 1) ⊆ Eb(P 2) if and only if A S(P 1) ⊆ A S(P 2).Propositions 13 to 18 prove the one-to-one-distinguishability classes of I L P b, I L P sm, I L P c , I L P L A S , I L P L O A S and L O A S , showing also the sufficient and necessary conditions for distinguishability presented in Table 3. To aid readability, I L P contextthe proofs are in the appendix rather than the main paper.(cid:10)(cid:14)(cid:11)(cid:14) A S(B ∪ H1) (cid:5) A S(B ∪ H2)(cid:3)B, H1, H2(cid:4).Proposition 13. D11(I L P b) =M. Law et al. / Artificial Intelligence 259 (2018) 110–146125Interestingly, although I L P sm (cid:4)sr I L P b, D11(I L P sm). This is shown by Proposition 14. The reason for this is that if I L P sm can distinguish one hypothesis H 1 from another hypothesis H 2 then, there must be some task T sm such that H1 is a solution of T sm and H2 is not. This means that H1 must cover all of the examples of T sm and there must be at least one (partial interpretation) example of T sm which is not covered by H2. This partial interpretation example can be given as the set of positive and negative examples in an I L P b task. This I L P b task will then distinguish H 1 from H2.1(I L P b) = D1Proposition 14. D11(I L P b) = D11(I L P sm).To better compare the conditions for I L P b and I L P c , we can express the necessary and sufficient condition of I L P b in terms of the notion Eb(P ). Specifically, in I L P b for one hypothesis H1 to be distinguishable from another hypothesis H 2(with respect to a background knowledge B) it is both necessary and sufficient for Eb(B ∪ H1) to contain at least one conjunction that is not in Eb(B ∪ H2). This is because the extra conjunction can be used to generate a set of examples that are covered by H1 but not H2. This is demonstrated by Example 10.Example 10. Consider again the programs B = ∅, H 1 = {1{heads, tails}1.} and H2 = {heads.}. Eb(B ∪ H1) contains the conjunction not heads ∧ tails, whereas Eb(B ∪ H2) does not. This conjunction can be mapped into the positive example tails and the negative example heads, which B ∪ H 1 covers, but B ∪ H2 does not – i.e. the task (cid:3)B, (cid:3){tails}, {heads}(cid:4)(cid:4)distinguishes H1 from H2.So, as the one-to-one-distinguishability condition for I L P b could also be expressed as Eb(B ∪ H1) (cid:5) Eb(B ∪ H2), it might be expected that the one-to-one-distinguishability condition for I L P c would be that Ec(B ∪ H1) (cid:5) Ec(B ∪ H2). Indeed this would be the case, if it were not for the extra condition that I L P c imposes on any inductive solution: that is, any inductive solution H must be such that B ∪ H is satisfiable. Although this extra condition may seem unnecessary at first sight, its importance becomes clear when considering distinguishability. Without this extra condition, no hypothesis would be distinguishable from the hypothesis given by the empty constraint “:- .” – i.e. there would be no hypothesis H such that (cid:3)B, H, {:- .}(cid:4) ∈ D11(I L P c) (for any B). This is because there cannot be any answer set of B ∪ {:- .} that does not cover the examples (as there are no answer sets). As I L P c has the extra condition that B ∪ H must be satisfiable, its distinguishability condition is slightly more complicated than Ec(B ∪ H1) (cid:5) Ec(B ∪ H2), as shown in Proposition 15.Proposition 15. D11(I L P c) =(cid:15)(cid:14)(cid:14)(cid:14)(cid:3)B, H1, H2(cid:4)(cid:14)A S(B ∪ H1) (cid:17)= ∅∧( A S(B ∪ H2) = ∅ ∨ Ec(B ∪ H2) (cid:5) Ec(B ∪ H1))(cid:16).We now prove the one-to-one-distinguishability classes of our own frameworks, I L P L A S and I L P L O A S . D11(I L P L A S ) con-1(I L P c) as I L P L A S can distinguish any two hypotheses which, combined with the background tains both D11(I L P b) and D1knowledge, have different answer sets.Proposition 16. D11(I L P L A S ) = {(cid:3)B, H1, H2(cid:4)| A S(B ∪ H1) (cid:17)= A S(B ∪ H2)} .As shown in Theorem 4, I L P L O A S is more D11 -general than I L P L A S . This is because I L P L O A S is able to use its ordering examples to distinguish any two hypotheses that, when combined with the background knowledge, order their answer sets differently, even if the two programs have the same answer sets.(cid:15)(cid:16)Proposition 17. D11(I L P L O A S ) =(cid:14)(cid:14)(cid:14)(cid:3)B, H1, H2(cid:4)(cid:14)A S(B ∪ H1) (cid:17)= A S(B ∪ H2) orord(B ∪ H1) (cid:17)= ord(B ∪ H2).Note that we assume I L P L O A S to be able to give ordering examples with any of the binary ordering operators. The slightly more restrictive version of I L P L O A S , presented in [23] where the operator is only the <, has a smaller one-to-one-distinguishability class. This is shown in Example 11.Example 11. Consider the heads and tails problem again, where B =(cid:10)1{heads, tails}1.(cid:11), and two potential hypotheses:• H1 = ∅• H2 = {:∼ heads.[1@1]}A S(B ∪ H1) = A S(B ∪ H2) = {{heads}, {tails}}. If we consider the restricted I L P L O A S where only the operator < is used to express ordering over the examples, H 2 can be distinguished from H 1, but not H1 from H2. This is because all answer sets of B ∪ H1 are equally optimal – neither (cid:3){tails}, {heads}, <(cid:4) nor (cid:3){heads}, {tails}, <(cid:4) is in ord(B ∪ H 1). In contrast, if we allow the use of any of the binary ordering operators, we can consider a task with the ordering example (cid:3){tails}, {heads}, =(cid:4) and be able to distinguish H 1 from H2. The learned hypothesis H1 has no weak constraints, so 126M. Law et al. / Artificial Intelligence 259 (2018) 110–146the two answer sets are equally optimal and the ordering example is respected by H 1, whereas H2 prefers {tails} to {heads}.I L P L O A S can distinguish any two hypotheses that, when combined with a fixed background knowledge, behave dif-ferently. It cannot distinguish hypotheses that are different but behave the same with respect to the background knowl-edge. This means that there are some hypotheses that are not strongly equivalent (when combined with the background knowledge), but I L P L O A S cannot distinguish one from the other. We now show that I L P contextcan distinguish between L O A Sany two hypotheses, H1 and H2, that, when combined with the background knowledge, are not strongly equivalent, or there is at least one program C ∈ ASP ch (consisting of normal rules, choice rules and hard constraints), such that ord(B ∪ H1 ∪ C) (cid:17)= ord(B, ∪H2 ∪ C).Proposition 18.D11(I L P contextL O A S ) =(cid:15)(cid:3)B, H1, H2(cid:4)(cid:14)(cid:14)(cid:14)(cid:14)B ∪ H1 (cid:17)≡s B ∪ H2 or∃C ∈ ASP ch such that ord(B ∪ H1 ∪ C) (cid:17)= ord(B ∪ H2 ∪ C)(cid:16)Now that we have proven the distinguishability classes for each learning framework, we can strengthen the statement of Corollary 4 and more precisely state the relationship between the distinguishability classes of the frameworks. Apart from the case of I L P b and I L P sm, each of the subset relations in Corollary 4 are in fact strict subsets.Theorem 4. Consider the learning frameworks I L P b, I L P c , I L P sm, I L P L A S , I L P L O A S and I L P contextL O A S .1. D12. D11(I L P b) = D11(I L P c) ⊂ D11(I L P sm) ⊂ D11(I L P L A S )1(I L P L A S ) ⊂ D11(I L P L O A S ) ⊂ D11(I L P contextL O A S )Proof.1(I L P b) = D11(I L P context1. The fact that D11(I L P sm) was shown in Proposition 14. By Corollary 4, D11(I L P sm) ⊆ D11(I L P L O A S ) ⊆ D11(I L P contextL O A S )L O A S ); hence, it remains to show that D1D1D1• Consider the tuple (cid:3)B, H1, H2(cid:4), where B = ∅, H1 = {p.} and H2 = {1{p, q}1}. A S(B ∪ H1) ⊂ A S(B ∪ H2), hence 1(I L P sm). It does, however, (cid:3)B, H1, H2(cid:4) does not satisfy the condition, given in Table 3, necessary for it to be in D1satisfy the condition for it to be in D11(I L P L A S ) (cid:17)= D11(I L P sm) (cid:17)= D1• Consider the tuple (cid:3)B, H1, H2(cid:4), where B = {1{p, q}1}, H1 = ∅ and H2 = {:∼ p.[1@1]}. A S(B ∪ H1) = A S(B ∪ H2)1(I L P L O A S ) but is not in and ord(B ∪ H1) (cid:17)= ord(B ∪ H2). Hence, by the conditions in Table 3, (cid:3)B, H1, H2(cid:4) is in D1D11(I L P L O A S ).1(I L P L A S ). Therefore, D1• Consider the tuple (cid:3)B, H1, H2(cid:4), where B = ∅, H1 = ∅ and H2 = {p:-q.}. Also consider the program P = {q.}. A S(B ∪H1) = A S(B ∪ H2) and ord(B ∪ H1) = ord(B ∪ H2), but A S(B ∪ H1 ∪ P ) (cid:17)= A S(B ∪ H2 ∪ P ); this shows that B ∪ H1 (cid:17)≡sB ∪ H2. Hence, by the conditions in Table 3, (cid:3)B, H1, H2(cid:4) is in D11(I L P L O A S ). Therefore, D1L O A S ) but is not in D11(I L P L A S ) (cid:17)= D11(I L P context1(I L P L A S ). Hence, D11(I L P sm) (cid:17)= D11(I L P L A S ).1(I L P L A S ) ⊆1(I L P L O A S ) (cid:17)=2. By Corollary 4, D11(I L P L A S ). Consider the tuple (cid:3)B, H1, H2(cid:4), where B = {p:- not p}, H1 = ∅ and H2 = {p.}. A S(B ∪ H1) = ∅ and A S(B ∪ H1) (cid:17)= A S(B ∪ H2). By the conditions in Table 3, (cid:3)B, H1, H2(cid:4) is in D11(I L P L A S ). Hence, it remains to show that D11(I L P c) (cid:17)= D11(I L P L A S ) but is not in D11(I L P c). Hence, D11(I L P L A S ). (cid:2)1(I L P c) (cid:17)= D11(I L P L O A S ) (cid:17)= D11(I L P contextL O A S ).1(I L P c) ⊆ D15.2. The one-to-many-distinguishability class of a learning frameworkIn practice an ILP task has a search space of possible hypotheses, and it is important to know the cases in which one particular hypothesis can be distinguished from the rest. In what follows, we analyse the conditions under which a learning framework can distinguish an hypothesis from a set of other hypotheses. As mentioned at the beginning of Section 5, this corresponds to the new notion we call the one-to-many-distinguishability class of a learning framework, which is a generalisation of the notion of the one-to-one-distinguishability class described above.Definition 14. The one-to-many-distinguishability class of a learning framework F (denoted D1m(F )) is the set of all tu-ples (cid:3)B, H, {H1, . . . , Hn}(cid:4) such that there is a task T F which distinguishes H from each H i with respect to B. Given two frameworks F1 and F2, we say that F1 is at least as (resp. more) D1m(F1) (resp. D1m-general than F2 if D1m(F2) ⊆ D1m(F 2) ⊂ D1m(F 1)).The one-to-many-distinguishability class tells us the circumstances in which a framework is general enough to distinguish some target hypothesis from a set of unwanted hypotheses. Note that, although the tuples in a one-to-M. Law et al. / Artificial Intelligence 259 (2018) 110–146127many-distinguishability class that have a singleton set as third argument correspond to the tuples in a one-to-one-m-general than F2 then F1 is distinguishability class of that framework, it is not always the case that if F1 is more D1also more D11 -general than F2. For example, we will see that I L P sm is more D1m-general than I L P b, but we have already 1 -general. Proposition 19 shows, however, that if F1 is at shown in Proposition 14 that the I L P b and I L P sm are equally D11 -general as F2.least as D1m-general as F2 then F1 is at least as D1Proposition 19. For any two frameworks F1 and F2 such that F1 is at least as D1(i.e. D1m(F1) ⇒ D1m(F2) ⊆ D11(F2) ⊆ D11(F1)).m-general as F2, F1 is at least as D11 -general as F2Proof. Assume that F1 is at least as D1D11 -general as F2, we must show that (cid:3)B, H1, H2(cid:4) ∈ D1As (cid:3)B, H1, H2(cid:4) ∈ D1and hence, (cid:3)B, H1, H2(cid:4) ∈ D11(F2), (cid:3)B, H1, {H2}(cid:4) ∈ D11(F1). (cid:2)1(F1).m-general as F2 and let (cid:3)B, H1, H2(cid:4) ∈ D11(F2). To show that F1 is at least as m(F2); hence, as F1 is at least as D1m-general as F2, (cid:3)B, H1, {H2}(cid:4) ∈ D1m(F1); We have already seen that if there is a strong reduction from F1 to F2 then F2 is at least as D11 -general as F1. 1 -generality, however, a strong reduction m-general than F1, even in the case that there is no strong reduction from m-generality. Similarly to D1Proposition 20 shows that a similar result holds for D1from F1 to F2 does not imply that F2 is more D1F2 to F1.Proposition 20. For any two frameworks F1 and F2: F1 →sr F2 ⇒ D1m(F1) ⊆ D1m(F2).Proof. Assume that F1 →sr F2. Take any (cid:3)B, H, S(cid:4) ∈ D1m(F1). There must be some task T F1 , with background knowledge B, such that H ∈ I L P F1 (T F1 ) and S ∩ I L P F1 (T F1 ) = ∅. Hence, as F1 →sr F2, there must be some F2 task T F2 , with background knowledge B, such that H ∈ I L P F2 (T F2 ) and S ∩ I L P F2 (T F2 ) = ∅. So (cid:3)B, H, S(cid:4) ∈ D1m(F2). Hence, D1m(F1) ⊆ D1m(F2). (cid:2)Due to the strong reductions shown in Proposition 9, an ordering of the one-to-many-distinguishability classes of the frameworks emerges (shown in Corollary 5).Corollary 5.1. D12. D1m(I L P b) ⊆ D1m(I L P c) ⊆ D1m(I L P sm) ⊆ D1m(I L P L A S )m(I L P L A S ) ⊆ D1m(I L P L O A S ) ⊆ D1m(I L P contextL O A S )This time, we will see that each of the ⊆’s in Corollary 5 can be upgraded to a strict ⊂. Rather than proving the one-to-many-distinguishability classes from scratch, we now present a useful result. For some frameworks, the one-to-one-distinguishability class of a learning framework can be used to construct the one-to-many-distinguishability class. This is the case when the framework has closed one-to-many-distinguishability (formalised by Definition 15). Proposition 21 and Corollary 6 show how the one-to-many-distinguishability class of a framework can be constructed using its one-to-one-distinguishability class if it has closed one-to-many-distinguishability.Definition 15. Given any learning framework F , the closure of the one-to-many-distinguishability class, written D1the set {(cid:3)B, H, S1 ∪ . . . ∪ Sn(cid:4) | (cid:3)B, H, S1(cid:4), . . . , (cid:3)B, H, Sn(cid:4) ∈ D1and only if D1m(F ), is m(F )}. We say that F has closed one-to-many-distinguishability if m(F ) = D1m(F ).Proposition 21. For any learning framework F , D1Corollary 6. For any learning framework F , D1holds if and only if F has closed one-to-many-distinguishability.m(F ) ⊆m(F ) =(cid:10)(cid:10)(cid:14)(cid:14)(cid:3)B, H, H1(cid:4), . . . ,(cid:3) B, H, Hn(cid:4) ∈ D1(cid:3)B, H, {H1, . . . , Hn}(cid:4)(cid:14)(cid:14)(cid:3)B, H, H1(cid:4), . . . ,(cid:3) B, H, Hn(cid:4) ∈ D1(cid:3)B, H, {H1, . . . , Hn}(cid:4)(cid:11)1(F )(cid:11)1(F ).. The equality Note that not all learning frameworks have closed one-to-many-distinguishability; for instance, Example 12 shows that brave induction does not. We will show that induction of stable models, on the other hand, does have closed one-to-many-distinguishability.Example 12. I L P b does not have closed one-to-many-distinguishability. We can see this by reconsidering the programs B = ∅, H = {1{heads, tails}1.}, H1 = {heads.} and H2 = {tails.}. (cid:3)B, H, {H1}(cid:4) ∈ D1m(I L P b) ((cid:3)B, (cid:3){tails}, ∅(cid:4)(cid:4) distin-guishes H from H1 wrt the background knowledge B). Similarly (cid:3)B, H, {H 2}(cid:4) ∈ D1m(I L P b) ((cid:3)B, (cid:3){heads}, ∅(cid:4)(cid:4) distinguishes Hfrom H2 wrt the background knowledge B). If I L P b had closed one-to-many-distinguishability then (cid:3)B, H, {H 1, H2}(cid:4) would 128M. Law et al. / Artificial Intelligence 259 (2018) 110–146be in D1(cid:3)B, H, {H1, H2}(cid:4) /∈ D1{H1, H2} ∩ I L P b(T b) = ∅.m(I L P b); hence, to show that I L P b does not have closed one-to-many-distinguishability it is sufficient to show that −(cid:4)(cid:4) such that H ∈ I L P b(T b) and m(I L P b). Hence it remains to show that there is no task T b = (cid:3)B, (cid:3)E+, EAssume for contradiction that there is such a task T b . As H ∈ I L P b(T b) and A S(B ∪ H) = {{heads}, {tails}}, E− ⊂ {heads, tails} (neither can be equal to {heads, tails} or H would not be a solution).{heads, tails} and E+ ⊂Case 1: E+ = ∅Case a: E− = ∅Case b: E− = {heads}Then H1 and H2 would be inductive solutions. This is a contradiction as {H 1, H2} ∩ I L P b(T b) = ∅.Then H2 would be an inductive solution of T b . Contradiction.Case c: E− = {tails}Then H1 would be an inductive solution of T b . Contradiction.Case 2: E+ = {heads}−Case 3: E+ = {tails}heads /∈ Ebe an inductive solution (regardless of what else is in Eas otherwise the task would have no solutions (and we know that H is a solution). In this case H 1 would ). Contradiction.−Similarly to above case, tails /∈ Einductive solution (regardless of what else is in E−−). Contradiction.as otherwise the task would have no solutions. In this case H 2 would be an Hence, there is no such task T b = (cid:3)B, (cid:3)Eclosed one-to-many-distinguishability.+, E−(cid:4)(cid:4) such that H ∈ I L P b(T b) and {H1, H2} ∩ I L P b(T b) = ∅. I L P b does not have In contrast to I L P b , I L P sm (which we will see does have closed one-to-many-distinguishability), can distinguish H from H1 and H2 with the task (cid:3)B, (cid:3){(cid:3){heads}, ∅(cid:4), (cid:3){tails}, ∅(cid:4)}(cid:4)(cid:4). Note that this is a combination of the two brave tasks which distinguish H from H1 and from H2. We will show that the ability to combine tasks in this way is a sufficient condition for a framework to have closed one-to-many-distinguishability. Proposition 22 shows the one-to-many-distinguishability class of I L P b.Proposition 22. D1m(I L P b) =(cid:10)(cid:14)(cid:11)(cid:14) A S(B ∪ H) (cid:5) A S(B ∪ h1) ∪ . . . ∪ A S(B ∪ hm)(cid:3)B, H, {h1, . . . , hm}(cid:4).Proof.1. Let B, H, h1, . . . , hm be ASP programs such that A S(B ∪ H) (cid:5) A S(B ∪ h1) ∪ . . . ∪ A S(B ∪ hm). This implies that there is an interpretation A that is an answer set of B ∪ H but not an answer set of any of the programs B ∪ h1, . . . , B ∪ hm. Let Lbe the set of atoms which occur in at least one answer set of at least one of the programs B ∪ H, B ∪ h1, . . . B ∪ hm; then B ∪ H has an answer set that extends (cid:3) A, L\ A(cid:4), but none of B ∪ h1, . . . B ∪ hm do. So the task (cid:3)B, (cid:3) A, L\ A(cid:4)(cid:4) distinguishes H from h1 to hm. Hence, (cid:3)B, H, {h1, . . . , hm}(cid:4) ∈ D12. Assume (cid:3)B, H, {h1, . . . , hm}(cid:4) ∈ D1set extending (cid:3)Eis not an answer set of any of B ∪ h1, . . . , B ∪ hm. Therefore A S(B ∪ H) (cid:5) A S(B ∪ h1) ∪ . . . ∪ A S(B ∪ hm). (cid:2)−(cid:4)(cid:4) such that B ∪ H has an answer −(cid:4) and none of B ∪ h1, . . . , B ∪ hm do. Hence, there must be at least one answer set of B ∪ H , which m(I L P b). Then there is an I L P b task T b = (cid:3)B, (cid:3)Em(I L P b).+, E+, EFor a framework F to have closed one-to-many-distinguishability it is sufficient (but not necessary) that for every two Ftasks, there is a third F task whose solutions are exactly those hypotheses which are solutions to both of the original two tasks. This is formalised and proved in Lemma 2. This condition is not necessary in general, but it holds for the frameworks considered in this paper that have closed one-to-many-distinguishability.Lemma 2. For any learning framework F to have closed one-to-many-distinguishability, it is sufficient that for every pair of learn-F ) =ing tasks T 1I L P F (T 1F (cid:4) it is possible to construct a new learning task T 3F (cid:4) such that I L P F (T 3F = (cid:3)B, E 1F ) ∩ I L P F (T 2F (cid:4) and T 2F ).F = (cid:3)B, E 2F = (cid:3)B, E 3Proof. Assume that for every pair of learning tasks T 1learning task T 3that F has closed one-to-many-distinguishability, we must show that (cid:3)B, H, S 1 ∪ . . . ∪ Sn(cid:4) ∈ D1showing (by mathematical induction) that for each k ∈ [1..n], (cid:3)B, H, S1 ∪ . . . ∪ Sk(cid:4) ∈ D1F (cid:4) such that I L P F (T 3F (cid:4) it is possible to construct a new m(F ). To prove m(F ). We prove this by F ). Let (cid:3)B, H, S1(cid:4), . . . , (cid:3)B, H, Sn(cid:4) ∈ D1F ) = I L P F (T 1F ) ∩ I L P F (T 2F (cid:4) and T 2F = (cid:3)B, E 1F = (cid:3)B, E 2F = (cid:3)B, E 3m(F ).Base Case: k = 1. (cid:3)B, H, S1(cid:4) ∈ D1Inductive Hypothesis: Assume that for some 0 ≤ k < n, (cid:3)B, H, S1 ∪ . . . ∪ Sk(cid:4) ∈ D1Inductive Step: We must show that (cid:3)B, H, S1 ∪ . . . ∪ Sk+1(cid:4) ∈ D1m(F ) by the initial assumptions.m(F ).m(F ).M. Law et al. / Artificial Intelligence 259 (2018) 110–146129As (cid:3)B, H, S1 ∪ . . . ∪ Sk(cid:4) ∈ D1and (S1 ∪ . . . ∪ Sk) ∩ I L P F (T 1H ∈ I L P F (T 2I L P F (T 3fore, H ∈ I L P F (T 3F ) = I L P F (T 1F ) ∩ I L P F (T 2F ) and Sk+1 ∩ I L P F (T 2m(F ) (by the inductive hypothesis), there must be a learning task T 1F such that H ∈ I L P F (T 1F ) = ∅. As (cid:3)B, H, Sk+1(cid:4) ∈ D1F ) = ∅. By our initial assumption, there is a learning task T 3F ), (S1 ∪ . . . ∪ Sk) ∩ I L P F (T 3m(F ), there must also be a learning task T 2F = (cid:3)B, E 3F ) = ∅ and Sk+1 ∩ I L P F (T 3F ). So, H ∈ I L P F (T 3F )F such that F (cid:4) such that F ) = ∅. There-F ) and (S1 ∪ . . . ∪ Sk+1) ∩ I L P F (T 3F ) = ∅. Hence, (cid:3)B, H, S1 ∪ . . . ∪ Sk+1(cid:4) ∈ D1m(F ). (cid:2)Proposition 23. I L P c , I L P sm, I L P L A S , I L P L O A S and I L P contextL O A S all have closed one-to-many-distinguishability.Theorem 5. Given two frameworks F1 and F2, D1m(F1) ⊆ D1m(F2) if and only if D11(F1) ⊆ D11(F2).Proof. D1m(F1) ⊆ D1⎧⎨m(F2)(cid:14)(cid:14)(cid:14)(cid:14)(cid:3)B, H, {H1, . . . , Hn}(cid:4)(cid:14)(cid:14)⇔⎩⎧⎨⎩(cid:14)(cid:14)(cid:14)(cid:14)(cid:3)B, H, {H1, . . . , Hn}(cid:4)(cid:14)(cid:14)⊆⎫⎬⎭(cid:3)B, H, H1(cid:4) ∈ D11(F1). . .(cid:3)B, H, Hn(cid:4) ∈ D11(F1)(cid:3)B, H, H1(cid:4) ∈ D1. . .(cid:3)B, H, Hn(cid:4) ∈ D11(F2)1(F2)⎫⎬⎭ (by Proposition 21)⇔ D11(F1) ⊆ D11(F2). (cid:2)Corollary 7. Given two frameworks F1 and F2 with closed one-to-many-distinguishability: D1D11(F1) ⊂ D11(F2).m(F1) ⊂ D1m(F2) if and only if Theorem 6. Consider the learning frameworks I L P b, I L P c , I L P sm, I L P L A S , I L P L O A S and I L P contextL O A S .1. D12. D1m(I L P b) ⊂ D1m(I L P c) ⊂ D1m(I L P sm) ⊂ D1m(I L P L A S )m(I L P L A S ) ⊂ D1m(I L P L O A S ) ⊂ D1m(I L P contextL O A S )Proof. Firstly, as shown in Example 12, D1D1follow from Corollary 7 and Proposition 23. (cid:2)m(I L P sm); and hence as I L P sm has closed one-to-many-distinguishability, D1m(I L P b) is a strict subset of D1m(I L P b). Hence, by Theorem 5, D1m(I L P b) ⊂m(I L P sm). The other results all m(I L P b) ⊂ D1Even if two frameworks F1 and F2 both have closed one-to-many-distinguishability, it might not be the case that their combination has closed one-to-many-distinguishability. Example 13 shows, for example, that this is not the case for I L P smand I L P c . We define first what we mean by combination framework constructed from two given frameworks.Definition 16. Given two frameworks F1 and F2, the combination framework comb(F1, F2) allows any task (cid:3)B, (cid:3)1, E 1(cid:4)(cid:4), where (cid:3)B, E 1(cid:4) is an F1 task, and any task (cid:3)B, (cid:3)2, E 2(cid:4)(cid:4), where (cid:3)B, E 2(cid:4) is an F2 task.(cid:15)Given any comb(F1, F2) task T = (cid:3)B, (cid:3)x, E(cid:4)(cid:4): I L P comb(F1,F2)(T ) =I L P F1 ((cid:3)B, E(cid:4))I L P F2 ((cid:3)B, E(cid:4))if x = 1if x = 21(I L P c). Hence by Definition 16 they must be in D11(I L P c) (using the task (cid:3)B, (cid:3)∅, {q}(cid:4)(cid:4)). This shows that both (cid:3)B, H, H 1(cid:4) and (cid:3)B, H, H2(cid:4) are in D1Example 13. Consider the frameworks I L P sm and I L P c (both of which have closed one-to-many-distinguishability). Consider the programs B = ∅, H = {0{p}1.} , H1 = ∅, H2 = {0{p, q}1.}. (cid:3)B, H, H1(cid:4) ∈ D11(I L P sm) (using the task (cid:3)B, (cid:3){(cid:3){p}, ∅(cid:4)}(cid:4)(cid:4)), and (cid:3)B, H, H2(cid:4) ∈ D11(I L P sm) ∪D11(comb(I L P sm, I L P c)). But using the distinguishability conditions proven in the previous section, it can be seen that neither framework can distinguish H from both H 1 and H2. Therefore, (cid:3)B, H, {H1, H2}(cid:4) /∈ D1m(I L P L A S ). This is because D1m(I L P c)) and has closed one-to-many-distinguishability, so must also contain (cid:3)B, H, {H 1, H2}(cid:4).m(I L P L A S ) contains both (cid:3)B, H, {H1}(cid:4) and (cid:3)B, H, {H2}(cid:4) (as it contains both D1m(comb(I L P sm, I L P c)). This also means that D1m(I L P c) is a strict subset of D1m(I L P sm) and D1m(I L P sm) ∪ D15.3. The many-to-many-distinguishability class of a learning frameworkSo far, we have considered two main classes to define how general a learning framework is. Firstly, we discussed the (cid:20)(cid:4) such that the framework can distinguish H from one-to-one-distinguishability class, which is made up of tuples (cid:3)B, H, Hwith respect to B. We showed that this has limitations and cannot separate I L P b and I L P sm even though I L P b is clearly Ha special case of I L P sm. This motivated upgrading the notion of a one-to-one-distinguishability class, changing the third (cid:20)130M. Law et al. / Artificial Intelligence 259 (2018) 110–146element of each tuple from a single hypothesis to a set of hypotheses to give the notion of a one-to-many-distinguishability class.This naturally leads to the question of whether it is possible to upgrade generality classes by allowing the second element of the tuple to also be a set of hypotheses. Each tuple would then be of the form (cid:3)B, S 1, S2(cid:4), where B is a background knowledge, and S1 and S2 are sets of hypotheses. For each tuple in this new class, a framework would be required to have at least one task T with the background knowledge B such that every hypothesis in S 1 is an inductive solution of T , and no hypothesis in S2 is an inductive solution of T . Definition 17 formalises this many-to-many-distinguishability class.Definition 17. The many-to-many-distinguishability class of a learning framework F (denoted Dmm(F )) is the set of all tuples (cid:3)B, S1, S2(cid:4), where B is a program and S1 and S2 are sets of hypotheses for which there is a task T F , with background knowledge B, such that S1 ⊆ I L P F (T F ) and S2 ∩ I L P F (T F ). Given two frameworks, F1 and F2, we say that F1 is at least as (resp. more) Dmm -general than F2 if and only if Dmm(F1) (resp. Dmm (F2) ⊆ Dmm(F2) ⊂ Dmm(F1)).We have already seen that for any two frameworks, F1 and F2, F1 →sr F2 ⇒ D1We have also seen that for D1F1 these subset relations are not necessarily strict. Proposition 24 and Corollary 8 show that Dmstrong reductions.1(F2). m-generality, even if there is no corresponding strong reduction from F2 to m -generality is equivalent to 1 -generality and D1m(F2) ⇒ D1m(F1) ⊆ D11(F1) ⊆ D1Proposition 24. For any two learning frameworks F1 and F2, F1 →sr F2 ⇔ Dmm(F1) ⊆ Dmm(F2).Proof.m(F2).2. Assume that Dm1. Assume that F1 →sr F2. Let (cid:3)B, S1, S2(cid:4) be an arbitrary element of Dmm(F1), there is a task T F1with background knowledge B such that S1 ⊆ I L P F1 (T F1 ) and S2 ∩ I L P F1 (T F1 ) = ∅. Hence, as F1 →sr F2, there is an F2 task T F2 with background knowledge B such that S1 ⊆ I L P F2 (T F2 ) and S2 ∩ I L P F2 (T F2 ) = ∅. Hence (cid:3)B, S1, S2(cid:4) ∈Dmm (F1). By definition of Dmm (F1) ⊆ Dmm(F2). Let T F1 be an arbitrary F1 task. We must show that there is a F2 task with the same background knowledge and the same inductive solutions. Let B be the background knowledge of T F1 , S1 = I L P F1 (T F1 )and S2 be the (possibly infinite) set of ASP programs which are not in S1. (cid:3)B, S1, S2(cid:4) ∈ Dmm(F1); and hence, (cid:3)B, S1, S2(cid:4) ∈Dmm(F2). Therefore, there must be at least one task T F2 with the background knowledge B such that I L P F2 (T F2 ) = S1. Hence, F1 →sr F2. (cid:2)Corollary 8. For any two learning frameworks F1 and F2, F1 is more Dmm -general than F2 if and only if F2 →sr F1 and F1 (cid:4)sr F2.Proposition 25. For any two frameworks F1 and F2: Dmm(F1) ⊆ Dmm(F2) ⇒ D1m(F1) ⊆ D1m(F2).Proof. Assume that DmDmm(F2). Hence, (cid:3)B, H, S(cid:4) ∈ D1m(F1) ⊆ Dmm(F2). (cid:2)m(F2) and let (cid:3)B, H, S(cid:4) ∈ D1m(F1). Then (cid:3)B, {H}, S(cid:4) ∈ Dmm(F1), and so (cid:3)B, {H}, S(cid:4) ∈Theorem 7 shows that one framework being more D1m-general than another implies that it is also more Dmm -general if there is a strong reduction from the second framework to the first.Theorem 7. For any two frameworks F1 and F2, if F1 is more D1than F2.m-general than F2 and F2 →sr F1 then F1 is more Dmm -general Proof. Assume that F1 is more D1as F2. It remains to show that F2 is not at least as DmDmD1m -general as F1. Then by Proposition 25, F2 is at least as D1m-general than F2. (cid:2)m-general than F2 and that F2 →sr F1. By Proposition 24, F1 is at least as Dmm -general m -general as F1. Assume for contradiction that F2 is at least as m-general as F1, contradicting the fact that F1 is more Corollary 9. Consider the learning frameworks I L P b, I L P c , I L P sm, I L P L A S , I L P L O A S and I L P contextL O A S .1. Dm2. Dmm(I L P b) ⊂ Dmm(I L P c) ⊂ Dmm(I L P sm) ⊂ Dmm(I L P L A S )m(I L P L A S ) ⊂ Dmm(I L P L O A S ) ⊂ Dmm(I L P contextL O A S )Proof. Each result follows directly from Theorem 6, Theorem 7 and Proposition 9. (cid:2)Note that although for each pair of frameworks discussed in this paper, one being more D1m -general than another implies that it is also more Dmm -general, this result does not hold in general. Example 14 shows such a pair of frameworks.M. Law et al. / Artificial Intelligence 259 (2018) 110–146131PropertyF1 and F2 have equal D1Table 4A summary of the relationships between the different measures of generality in this paper.Consequences of propertyF1 and F2 have equal D11) F1 and F2 have equal D12) F1 and F2 have equal D1Either F1D1F1 and F2 have equal Dm1 -general than F2F1 is more D1is more D1m -generalitym-generalitym-generality1 -generality1 -generalitym-generalitym-general than F2 or F1 and F2 have incomparable F1 is more D1m-general than F2F1 is more Dmm -general than F2F1 is at least as D1F1 is at least as Dmm-general as F2m -general as F2F1 and F2 have different D11 -generalityF1 and F2 have different D1m-generalityF1 and F2 have incomparable D11 -generalityF1 and F2 have incomparable D1m-generalitym -general than F2 or F1 and F2 have incomparable m -generality1 -general as F21 -general as F21 -general as F2m-general as F21) Either F1 is more DmDm2) F1 is at least as D11) F1 is at least as D12) F1 is at least as D1F1 is at least as D11) F1 is at least as D12) F1 is at least as D11) F1 and F2 have different D12) F1 and F2 have different DmF1 and F2 have different Dm1) F1 and F2 have incomparable D12) F1 and F2 have incomparable DmF1 and F2 have incomparable Dm1 -general as F2m-general as F2m-generalitym -generalitym -generalitym-generalitym -generalitym -generalityExample 14. Consider a new learning framework I L P d that takes as examples a pair of sets of atoms Esuch that a hypothesis H is an inductive solution of a task if B ∪ H has exactly one answer set and this answer set contains all of 1(I L P c). This can be seen as follows: the Eassume that (cid:3)B, H, H−1(I L P d). Then there is a task Td = (cid:3)B, (cid:3)E’s. The one-to-one-distinguishability class D1’s and none of the E(cid:20)(cid:4) ∈ D1−(cid:4)(cid:4) such that H ∈ I L P d(Td) but H1(I L P d) ⊆ D1(cid:20) /∈ I L P d(Td).and E+, E++−Case 1: A S(B ∪ HLet T c = (cid:3)B, (cid:3)EA S(B ∪ HCase 2: B ∪ H(cid:20)) = ∅+, E(cid:20)(cid:4) ∈ D1(cid:20)) = ∅, H(cid:20)has exactly one answer set, and this answer set does not cover the examples.−(cid:4)(cid:4). As B ∪ H has exactly one answer set, and this answer set covers the examples, H ∈ I L P c(T c). As (cid:20) /∈ I L P c(T c). Hence, (cid:3)B, H, H1(I L P c).+, E−(cid:4)(cid:4). As B ∪ H has exactly one answer set, and this answer set covers the examples, H ∈ I L P c(T c). As has an answer set that does not cover the examples, H(cid:20) /∈ I L P c(T c). Hence, (cid:3)B, H, H(cid:20)(cid:4) ∈ D11(I L P c).Let T c = (cid:3)B, (cid:3)E(cid:20)B ∪ HCase 3: B ∪ H(cid:20)has multiple answer sets.There must be at least one answer set A∗set). There must either be an atom a ∈ Abut is in the unique answer set of B ∪ H . In the first case, let Eand EHof B ∪ Hthat is not in the unique answer set of B ∪ H , or an atom a that is not in Athat is not an answer set of B ∪ H (as B ∪ H only has one answer ∗, −= {a}c(cid:4)(cid:4). H ∈ I L P c(T c) as the only answer set of B ∪ H covers the examples, whereas has at least one answer set that does not cover the examples. Hence, (cid:3)B, H, H= {a}. In the second case, let E= ∅. Then let T c = (cid:3)B, (cid:3)E(cid:20) /∈ I L P c(T c) as B ∪ H= ∅ and E(cid:20)(cid:4) ∈ D1+c , E+c+c−c−c(cid:20)∗(cid:20)1(I L P c).I L P c1(I L P c) as D11(I L P d) is a strict subset of D1(cid:20)(cid:4) where B ∪ H has multiple answer In fact, D1sets. As I L P c is closed under one-to-many-distinguishability, and all one-to-many-distinguishability classes are subsets of their own closure, this means that I L P c is more D11(I L P d) has no elements (cid:3)B, H, Hm-general than I L P d (by Theorem 5).is not, however, more Dmm -general than I L P d. Take, for instance, the tuple t = (cid:3)∅, {{heads.}, {tails.}},{{1{heads, tails}1.}}(cid:4). The empty set of examples are sufficient for I L P d to distinguish both hypotheses containing facts from the choice rule (as the choice rule has multiple answer sets). However, there is no I L P c task such that both facts are solutions, but the choice rule is not. Hence, t ∈ Dmm(I L P d) but t /∈ Dmm -general m -general as I L P c either, the two have incomparable Dmas I L P d. In fact, as I L P d is not as Dmm(I L P c); and so, I L P c is not at least as Dmm -generalities.Example 14 shows that Dmm -generality may not be able to compare two frameworks even when there is a clear m-generality relation between the two. In the next section, we discuss relationships between, and the relative merits D1of using, each measure of generality.132M. Law et al. / Artificial Intelligence 259 (2018) 110–1465.4. DiscussionTable 4 summarises the relationships between the different measures of generality presented in this paper. It shows that equal one-to-one-distinguishability is weaker than equal one-to-many-distinguishability, which is weaker than equal many-to-many-distinguishability. This can be seen from the first section of the table, as equal many-to-many-distinguishability implies equal one-to-many-distinguishability, which implies equal one-to-one-distinguishability, but the converse implica-tions do not hold in general. On the other hand different one-to-one-distinguishability is stronger than different one-to-many-distinguishability, which in turn is stronger than different many-to-many-distinguishability. This means that many-to-many-distinguishability (resp. one-to-many-distinguishability) will be able to “separate” frameworks that one-to-many-distinguishability (resp. one-to-one-distinguishability) can not; but, there are more frameworks that are incomparable under many-to-many-distinguishability (resp. one-to-many-distinguishability) than one-to-many-distinguishability (resp. one-to-one-distinguishability).The different notions of generalities will never be inconsistent, in the sense that one will never say that F1 is more general than F2, while the other says that F2 is more general than F1. It is useful, however, to explain the tasks that the different measures of generality correspond to.1. One-to-one-distinguishability describes how general a framework is at distinguishing one hypothesis from another.2. One-to-many-distinguishability describes how general a framework is at the task of identifying one target hypothesis within a space of unwanted hypotheses.3. Many-to-many-distinguishability describes how general a framework is for the task of identifying a set of target hy-potheses – for any background knowledge B and set of hypotheses S, there is a task T F with background knowledge B such that I L P F (T F ) = S if and only if (cid:3)B, S, ¯S(cid:4) ∈ Dmm(F ), where ¯S is the (infinite) set of hypotheses which are not in S.In practice, as ILP usually addresses the task of finding a single target hypothesis from a space of other hypotheses, one-to-many-distinguishability is likely to be the most useful measure; however, one-to-one-distinguishability classes are useful for finding the one-to-many-distinguishability classes of frameworks, and many-to-many-distinguishability is interesting as a theoretical property.5.4.1. More general learning frameworksWe have shown in this section that I L P contextL O A Sis more general (under every measure) than any of the other tasks pre-sented for learning under the answer set semantics. The obvious question is whether it is possible to go further and define more general learning tasks.The most D1m-generality.1 -general learning task possible would be able to distinguish between any two different ASP programs H 1and H2 with respect to any background knowledge B. This would require the learning task to distinguish between programs which are strongly equivalent, such as {p. q:- p.} and {p:- q. q.}. We would argue that this level of one-to-one-distinguishability is unnecessary as in ILP, we aim to learn programs whose output explains the examples. As two strongly equivalent programs will always have the same output, even when combined with additional programs providing “context”, we can not see any reason for going further under D1L O A S has closed one-to-many-distinguishability, the same argument can be made for D11 -generality. As I L P contextOne outstanding question is whether it is worth going any further under Dmm -generality. Note that it is possible to define the notion of the closure of many-to-many-distinguishability classes; however, none of the frameworks considered in this paper have closed many-to-many-distinguishability. It is unclear whether having closed many-to-many-distinguishability is a desirable property for a framework. Closed one-to-many-distinguishability means that a framework can distinguish a target hypothesis H from any set of hypotheses S such that it can distinguish H from each element of S: this means that the sets of examples that distinguish H from each element of S can be combined to form a single set of examples, ruling out each element of S. For a framework to have closed many-to-many-distinguishability, however, given two (or more) target hypotheses h1, h2 that can be distinguished from an undesirable hypothesis h3 , it would need to be able to find a task which distinguished both h1 and h2 from h3. For example, as both (cid:3)∅, {heads.}, {1{heads, tails}1.}(cid:4)and (cid:3)∅, {tails.}, {1{heads, tails}1.}(cid:4) are in D11(I L P L A S ), for I L P L A S to have closed many-to-many-distinguishability it would need to be able to find a task with an empty background knowledge that distinguishes both {heads.} and {tails.}from {1{heads, tails}1.}. It is difficult to imagine a scenario, however, where we should learn either the hypothesis that a coin is always heads or always tails, when the choice rule is not a desirable hypothesis.5.4.2. The generality of noisy frameworksAs discussed in Section 4.4 some learning systems are able to solve tasks where examples are potentially noisy – in this case, not all examples should necessarily be covered, and there is a trade off between maximising coverage and not over-fitting the examples. One method, used by the XHAIL [42] and ILASP [32] systems is to penalise a hypothesis for each example that is not covered. Examples are given a positive integer penalty, which must be paid if the example is not covered.M. Law et al. / Artificial Intelligence 259 (2018) 110–146133The three measures of generality presented in this section could be extended to cover the noisy tasks. For instance, in the case of one-to-one-distinguishability we could define the “noisy” one-to-one-distinguishability class of a learning framework as the set of tuples (cid:3)B, H1, H2(cid:4), for which there is a set of examples E such that p(H 1, E) < p(H2, E), where p(H, E) is the total penalty paid by a hypothesis H (together with the background knowledge B) over the examples E. In fact, we now show that this extended notion of one-to-one-distinguishability class would be equivalent to the standard “non-noisy” one-to-one-distinguishability class.(cid:20)) < p(H2, E(cid:20)), where E(cid:20)As all penalties are positive, p(H 1, E) < p(H2, E) implies that p(H1, Ethe set of all examples in (cid:20)(cid:20), but H2 does not. This E that are covered by H . Hence, there is a set of examples Emeans that any (cid:3)B, H1, H2(cid:4) that would be in the “noisy” one-to-one-distinguishability class is in the standard “non-noisy” one-to-one-distinguishability class. Similarly for any tuple (cid:3)B, H 1, H2(cid:4) in the standard one-to-one-distinguishability class, there is a set of examples E such that H 1 covers every example in E, and H 2 does not; hence p(H1, E) < p(H2, E), and so (cid:3)B, H1, H2(cid:4) would be in the “noisy” one-to-one-distinguishability class.such that H1 every example in EA similar argument holds for the one-to-many-distinguishability class; however, it is worth noting that it does not hold true for the many-to-many-distinguishability class. If we upgrade the many-to-many-distinguishability class in the same way then there are some tuples which are in the “noisy” many-to-many-distinguishability class for a framework, but not in the standard many-to-many-distinguishability class. Take for instance the example discussed in the previous section: (cid:3)∅, {{heads.}, {tails.}}, {1{heads, tails}1.}(cid:4) is not in Dmm(I L P L A S ). However, if we consider the I L P L A S examples E = (cid:3)∅, {(cid:3){heads}, ∅(cid:4), (cid:3){tails}, ∅(cid:4)(cid:4), then p({heads.}, E) = 1, p({tails.}, E) = 1 and p({1{heads, tails}1.}, E) = 2, meaning that (cid:3)∅, {{heads.}, {tails.}}, {1{heads, tails}1.}(cid:4) would be in the “noisy” Dmm(I L P L A S ).6. Related workThe complexity of I L P b and I L P c for verification and satisfiability were investigated in [28]. However, in that work, the results on satisfiability are for deciding whether or not a task has any solutions with no restrictions on the hypothesis space. This means that for both I L P b and I L P c deciding whether a task is satisfiable is equivalent to checking whether there is a model of B in which the examples are covered (a simpler decision problem). For this reason, the complexity of satisfiability for I L P c in [28] was N P -complete, rather than (cid:2)P2 -complete. The complexities given of verification of a hypothesis given in [28] are also different from the ones in this paper, as they consider a different language for B ∪ H . They consider disjunctive logic programs, whereas we investigated the complexity of learning programs without disjunction. The reason we chose not to consider disjunctive logic programs is that the systems available for ILP under the answer set semantics do not allow disjunction. For example, the systems for I L P b [38,39] do not allow disjunction, and allowing disjunction would raise the complexity beyond the complexity of the tasks that are actually solved in practice by the existing systems.As discussed in Section 5, the generality of a learning framework has been investigated before. In [45], the author defined generality in terms of reductions – one framework F1 was said to be more general than another framework F2 if and only if F2 →r F1 and F1 (cid:4)r F2. We showed in Section 5 that our final notion of generality (many-to-many-distinguishability) coincides with a similar notion of strong reductions. The difference with strong reductions, as compared to the reductions in [45], is that strong reductions do not allow the background knowledge to be modified as part of the reduction. We showed in Example 8 that I L P b reduces to I L P c , but I L P b does not strongly reduce to I L P c . This is because any reduction from I L P b to I L P c must encode the examples in the background knowledge, which we would argue abuses the purpose of the background knowledge.Aside from the differences in strong reductions and reductions, we discussed in Section 5 that one-to-many-distinguishability is more relevant when comparing the generalities of frameworks with respect to the task of finding a single hypothesis within a space of hypotheses. The reductions of [45] are closer to the notion of many-to-many-distinguishability, because they compare the set of solutions.One key advantage to using our three notions of generality, rather than strong reductions or reductions, is for comparing the relative generalities of frameworks that do not strongly reduce to one another. For instance, we have seen that I L P band I L P c are incomparable under D-generality, but we can still reason that I L P b is never D-general enough to distinguish a hypothesis containing a constraint from the same hypothesis without the constraint. On the other hand, I L P c may be D-general enough to do so (for example, I L P c can distinguish {:- p.} from ∅ with respect to the background knowledge {0{p}1.}, with the task (cid:3){0{p}1.}, (cid:3)∅, {p}(cid:4)(cid:4)).6.1. Other learning frameworksTraditional ILP aims to learn Prolog style logic programs, often restricted to learning definite programs (with no negation as failure). For the shared subset of the languages learned by these ILP frameworks and the ASP frameworks (definite rules, not including lists), a definite learning task can be expressed as either a brave, or as a cautious task with the same examples as the definite task, and hypothesis space restricted to definite logic programs. As these frameworks do not support features such as choice rules or constraints or negation, and ASP frameworks do not support lists, a comparison of the generality is not very informative. A review of early efforts to extend ILP to learn normal logic programs was presented in [8]. The techniques discussed in [8] that operate under the stable model (or answer set) semantics require that all examples are covered in all stable models (or answer sets). This corresponds to cautious induction.134M. Law et al. / Artificial Intelligence 259 (2018) 110–146We have already discussed most of the other frameworks for ILP which work under the answer set semantics and shown in sections 4 and 5 how the complexity and generality of these frameworks compare to our own frameworks. In particular, we have shown that although the complexities of our three learning frameworks (I L P L A S , I L P L O A S and I L P contextL O A S ) are the same as cautious induction, there are some learning problems which can be represented in learning from answer sets that cannot be represented in either brave or cautious induction. One example of this is the learning of the rules of Sudoku. This is because brave induction cannot incentivise learning the constraints in the rules of Sudoku, and there are no useful examples that can be given to a cautious learner about the values of cells, since no cell has the same value in every valid Sudoku board.Another early work on learning frameworks under the answer set semantics is Induction from Answer Sets [46]. In the paper, two learning algorithms I A S pos and I A Sneg are presented. The task of I A S pos is to learn a hypothesis that cautiously entails a set of examples. This corresponds to the task of cautious induction. I A Sneg on the other hand aims to find a hypothesis that does not cautiously entail each of a set of examples (i.e. there should be at least one answer set that does not contain each example). This is (in some sense reversed) brave induction. As shown in the paper, in general the I A S posand I A Sneg procedures are cannot be combined in general to compute a correct hypothesis.Another framework, under the supported model semantics rather than the answer set semantics, is Learning from Inter-pretation Transitions (LFIT) [47]. In LFIT, the examples are pairs of interpretations (cid:3)I, J (cid:4) where Jis the set of immediate consequences of I given B ∪ H . In [24], we presented a mapping from any LFIT task to an I L P contexttask. This shows that the complexity of deciding both satisfiability and verification for LFIT is at most (cid:2)P2 -complete. The generality, on the other hand would be different to the tasks we have considered, since there are programs that are strongly equivalent under the answer sets semantics that have different supported models. Example 15 demonstrates a pair of such programs, and an example that learning from interpretations could use to distinguish between them.L A SExample 15. Consider the programs P 1 and P 2.P 1 = {p:- p.}P 2 = ∅P 1 and P 2 are strongly equivalent under the answer set semantics. However, P 1 has the supported model {p}, whereas P 2does not. LFIT can distinguish P 1 from P 2 (with respect to an empty background knowledge) with the example (cid:3){p}, {p}(cid:4).Example 15 shows that I L P contextL O A S has a distinguishability class which does not contain LFIT’s distinguishability class. Conversely, LFIT cannot have a distinguishability class which contains D11(I L P contextL O A S ), as it cannot distinguish hypotheses containing weak constraints from the same hypotheses without the weak constraints. In fact, it does not even contain D11(I L P L A S ), as shown in Example 16.Example 16. Consider the programs P 1 and P 2.(cid:10)(cid:15)P 1 =P 2 =(cid:11)p.p:- p.p:- not p.(cid:16)is the set {p}. This means that no For both programs P 1 and P 2, the immediate consequences of any interpretation Iexample could possibly distinguish P 1 from P 2 with respect to an empty background knowledge. Under the answer set semantics, however, P 1 has one answer set {p}, but P 2 has no answer sets. I L P L A S can therefore distinguish P 1 from P 2(with respect to the empty background knowledge), with the positive example (cid:3){p}, ∅(cid:4).I L P L A S , I L P L O A S and I L P contexthave different distinguishability classes to LFIT, but none is either more or less L O A SD11 -general than LFIT. This is an interesting observation, as it demonstrates that even when two frameworks are incom-parable under our measures of generality, we can still reason about their individual distinguishability classes and discuss hypotheses which one framework is powerful enough to distinguish between and another is not. For instance, I L P L A S can-not distinguish between any two hypotheses that are strongly equivalent under the answer set semantics, but Example 15shows that there are some cases where I L P L F I T can.6.2. Relation to probabilistic ILPOne of the advantages to learning ASP programs rather than Prolog programs is that ASP allows the modeling of non-determinism, either through unstratified negation or through choice rules. The latter can be seen in the coin examples throughout the paper, where we have shown that our I L P L A S framework can learn that a coin can be either heads or tails, but not both.M. Law et al. / Artificial Intelligence 259 (2018) 110–146135Another method for achieving non-determinism in ILP is by adding probabilities. Probabilistic Inductive Logic Program-ming [48] is a combination of ILP with probabilistic reasoning. Its aim is to learn a logic program that is annotated with probabilities. The task of PILP is often divided into structure learning, where the underlying logic program is learned, and parameter estimation or weight learning, where the probabilities are learned. A key difference between I L P L A S and PILP is that while both aim to learn programs which are non-deterministic, I L P L A S aims to learn programs whose answer sets capture the set of possibilities, whereas PILP aims to learn a probability distribution over these possibilities.Although there has been significant progress in the field of PILP [25,49–51,26] for learning annotated Prolog programs, PILP under the answer set semantics is still relatively young, and thus, there are few approaches. PrASP [52,53,27] considers the problem of weight learning, and in fact uses a similar example of learning about coins. This example illustrates the difference between weight learning and standard ILP. In ILP our task is to learn that there are exactly two possibilities (heads and tails); whereas in weight learning, the goal is to estimate probabilities of each possibility. PROBXHAIL [54]does attempt to combine structure learning and weight learning, but can only learn definite logic programs.While the coin example used in this paper may be viewed as inherently probabilistic, there are situations in practice where we may wish to learn non-deterministic programs without considering probability; for instance, in policy learning. A policy may well permit many valid actions in a given scenario, and impose some constraints on these actions. The task is to learn a program whose answer sets reflect the set of valid options, rather than to estimate the probability of each action being taken.7. ConclusionIn this paper we have investigated the complexity and generality of the state of the art frameworks for learning answer set programs. We have shown, for the two decision problems of verification that a hypothesis is an inductive solution of a task and deciding whether a given task is satisfiable, that brave induction (I L P b ) and induction of stable models (I L P sm) have the same complexities, and that cautious induction (I L P c ), learning from answer sets (I L P L A S ), learning from ordered answer sets (I L P L O A S ) and context dependent learning from ordered answer sets (I L P contextL O A S ) also have the same complexities as each other, but higher than I L P b and I L P sm. Studying the complexity of decision problems for the learning frameworks is important, as it gives a sense of the price paid for choosing a particular framework. In contrast, generality is important, as it shows the advantages of choosing one framework over another, by specifying which hypotheses can be learned by each framework. When using ILP in practice, a trade off must be made between the complexity and generality of the framework. The generality classes presented in this paper can inform this decision, as it is likely to be influenced by the class of programs that must be learned.1 -generality, D1m-generality and DmWe have introduced three new measures of generality (D1m -generality), and shown that, both under our own measures of generality, and by using the concept of strong reductions, there is an ordering of the generalities of the frameworks considered in this paper. Although I L P c , I L P L A S , I L P L O A S and I L P contextL O A S have the same computational complexities, I L P c is less general than I L P L A S , which is less general than I L P L O A S , which is less general than I L P contextL O A S , under each measure of generality. This ordering could have been seen using strong reductions, but our measures go further. They allow us to reason about why one framework is more D11 -general than another, for example, by studying the class of tuples which are in one framework’s distinguishability class, but not the others. They also allow us to discuss the generalities of frameworks which are incomparable under strong reductions; for example, there is no strong reduction from I L P c to I L P b, or from I L P b to I L P c . Our measures allow us to show, however, that I L P b is not D11 -general enough to distinguish a hypothesis containing a constraint from the same program without the constraint, but in some cases I L P c is D11 -general enough to do so.In this paper, most of the results we have presented have addressed non-noisy learning frameworks. In general our ILASP systems do support noise, by allowing examples to be labeled with a penalty. In this case, ILASP searches for a hypothesis that minimises the sum |H| + p(H, E), where p(H, E) is the sum of all examples in a set E that are not covered by a hypothesis H . Such a hypothesis is called an optimal solution. For the two decision problems of verification and satisfiability, we have shown that the complexity results are unaffected. In current work we are investigating whether the complexities of the non-noisy frameworks and the noisy frameworks differ for the decision problem of verifying that a hypothesis is an optimal solution of a given task. In future work, we also hope to “upgrade” the propositional complexity results presented in this paper to apply to the learning of first order answer set programs.AcknowledgementsThis research is partially funded by the EPSRC project EP/K033522/1 “Privacy Dynamics” and by an EPSRC Doctoral Training Account EP/L504786/1.136M. Law et al. / Artificial Intelligence 259 (2018) 110–146Appendix A. ProofsA.1. Proofs from Section 4In this section, we present the proofs that were omitted from Section 4. In some of the proofs, we make use of predicate symbols to avoid continually introducing new atoms and to aid readability. As this section is restricted to propositional programs, any first order atom should be interpreted as a new propositional atom.Proposition 1.1. Deciding both verification and satisfiability for I L P b reduces polynomially to the corresponding I L P sm decision problem.2. Deciding both verification and satisfiability for I L P sm reduces polynomially to the corresponding I L P b decision problem.Proof.1. Let T b = (cid:3)B, S M , (cid:3)E+, E−(cid:4)(cid:4) be any arbitrary I L P b task.+, E−(cid:4)}(cid:4)(cid:4). ∀H , H ∈ I L P sm(T sm) if and only if H ∈ I L P b(T b) and hence deciding Consider the task T sm = (cid:3)B, S M , (cid:3){(cid:3)Everification for I L P b reduces polynomially to deciding verification for I L P sm. Similarly, as I L P sm(T sm) = I L P b(T b), T smis satisfiable if and only if T b is satisfiable; hence, deciding satisfiability for I L P b reduces to deciding satisfiability for I L P sm.2. Let T sm = (cid:3)B, S M , (cid:3)E(cid:4)(cid:4) be any arbitrary I L P sm task.Let n = |E|, where E = {e1, . . . , en}.For each integer i from 1 to n, let f i be a function which maps each atom a in B ∪ S M to a new atom ai. We also extend this notation to work on sets of atoms and rules (and parts of rules) by replacing each atom a in the set or rule with f i(a).For each rule R ∈ S M , define a new atom in_hR.Consider the task T b = (cid:3)Bb, Sbwith the atom a appended to the body).−(cid:4)(cid:4) where the components of the task are as follows (append(R, a) is the rule RM , (cid:3)E+, E(cid:17)⎧⎨⎩append( f 1(R), in_hR),. . . ,append( fn(R), in_hR)⎫⎬R ∈ S M⎭(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)Bb =f 1(R),. . . ,fn(R)SbM=in_hR+ =E− =Efi(inc)fi(exc)⎧⎨⎩(cid:10)⎧⎨⎩⎧⎨⎩⎫⎬⎭(cid:11)R ∈ B(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)R ∈ S M(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)ei ∈ E,ei = (cid:3)einc, eexciiinc ∈ einciei ∈ E,ei = (cid:3)einc, eexciiexc ∈ eexci⎫⎬⎭⎫⎬⎭(cid:4),(cid:4),For any solution H of T b, define g(H) to be {R | in_hR ∈ H}. We now show that I L P sm(T sm) = {g(HAssume H ∈ I L P sm(T sm)⇔ H ⊆ S M and ∀ei ∈ E, ∃ A ∈ A S(B ∪ H) such that A extends ei .⇔ H ⊆ S M and ∀ei ∈ E, ∃ A ∈ A S( f i(B ∪ H)) such that A extends (cid:3){ f i(inc) | inc ∈ einc⇔ H ⊆ S M and ∃ A ∈ A S({ f i(B ∪ H) | 1 ≤ i ≤ n}) such that A extends (cid:3)E+, E}, { f i(exc) | exc ∈ eexc−(cid:4) (as the atoms in each sub program are }(cid:4).ii(cid:20)) | H(cid:20) ∈ I L P b(T b)}.disjoint).⇔ H ⊆ S M and ∃ A ∈ A S(Bb ∪ {in_hR | R ∈ H}) such that A extends (cid:3)E+, E−(cid:4) (by the splitting set theorem, using {in_hR | R ∈ H} as a splitting set).(cid:20) ⊆ SbM such that g(H(cid:20) ∈ I L P b(T b) such that g(H(cid:20)) = H and ∃ A ∈ A S(Bb ∪ H⇔ ∃H⇔ ∃H⇔ H ∈ {g(H∀H , H ∈ I L P sm(T sm) if and only if g(H) ∈ I L P b(T b) and hence deciding verification for I L P sm reduces polynomially to deciding verification for I L P b. Similarly, as I L P sm(T sm) = {g(H) | H ∈ I L P b(T b)}, T sm is satisfiable if and only if T b is satisfiable; hence, deciding satisfiability for I L P b reduces to deciding satisfiability for I L P sm. (cid:2)(cid:20)) such that A extends (cid:3)E(cid:20) ∈ I L P b(T b)}(cid:20)) = H(cid:20)) | H+, E−(cid:4)Proposition 2.1. Deciding both verification and satisfiability for I L P c reduces polynomially to the corresponding I L P L A S decision problem.2. Deciding both verification and satisfiability for I L P L A S reduces polynomially to the corresponding I L P contextL O A S decision problem.M. Law et al. / Artificial Intelligence 259 (2018) 110–1461373. Deciding both verification and satisfiability for I L P contextL O A S4. Deciding both verification and satisfiability for I L P L O A S reduces polynomially to the corresponding I L P sreduces polynomially to the corresponding I L P L O A S decision problem.L A S decision problem.Proof.1. Let T c be any I L P c task (cid:3)B, S M , (cid:3)E+, E−(cid:4)(cid:4).+ ∈ E+}(cid:4) | e+} ∪ {(cid:3){e−}, ∅(cid:4) | eConsider the I L P L A S task T L A S = (cid:3)B, S M , (cid:3){(cid:3)∅, ∅(cid:4)}, {(cid:3)∅, {eBy the definition of I L P L A S , H ∈ I L P L A S if and only if H ⊆ S M ; ∃ A ∈ A S(B ∪ H) such that A extends (cid:3)∅, ∅(cid:4); ∀e−, ∅(cid:4).(cid:3) A ∈ A S(B ∪ H) such that A extends (cid:3)∅, e− ∀ A ∈ A S(B ∪ H)This is true if and only if H ⊆ S M , B ∪ H is satisfiable, ∀e− /∈ A. This is the definition of H being a member of I L P c(T c); hence, I L P c(T c) = I L P L A S (T L A S ).eAs I L P c(T c) = I L P L A S (T L A S ), T c is satisfiable if and only if T L A S is satisfiable. Hence deciding the satisfiability of an I L P ctask can be reduced to deciding the satisfiability of an I L P L A S task in polynomial time. Similarly, for any hypothesis H , H ∈ I L P c(T c) if and only if H ∈ I L P L A S (T L A S ); and so deciding verification for I L P c reduces polynomially to deciding verification for I L P L A S ., (cid:3) A ∈ A S(B ∪ H) such that A extends (cid:3)e+ ∀ A ∈ A S(B ∪ H), e+(cid:4); and finally, ∀e+ ∈ A and ∀e+ ∈ E+ ∈ E− ∈ E− ∈ E, +−− ∈ E−}(cid:4)(cid:4).2. Let T L A S be any I L P L A S task (cid:3)B, S M , (cid:3)E+, E−(cid:4)(cid:4). Consider the I L P L O A S task T L O A S = (cid:3)B, S M , (cid:3)E+, E−, ∅, ∅(cid:4)(cid:4).I L P L A S (T L A S ) = I L P L O A S (T L O A S ) and hence, T L A S is satisfiable if and only if T L O A S is satisfiable. Hence deciding the satisfiability of I L P L A S reduces polynomially to deciding satisfiability for I L P L O A S . Similarly, for any hypothesis H , H ∈ I L P L A S (T L A S ) if and only if H ∈ I L P L O A S (T L O A S ); and so deciding verification for I L P L A S reduces polynomially to deciding verification for I L P L O A S .3. In [24], we presented a mapping from any I L P contextL O A Stask to an I L P L O A S task. The correctness of this mapping is proven in Theorem 1 of [24]. Given any I L P contexttask, we can decide its satisfiability by using this mapping and checking the L O A Ssatisfiability of the resulting I L P L O A S task. Similarly, given any hypothesis and I L P contexttask, we can verify that the L O A Shypothesis is an inductive solution of the task by using the mapping. Hence, both satisfiability and verification for I L P contextL O A Sreduce to satisfiability and verification (respectively), for I L P L O A S .+, E4. We do this by translating an arbitrary I L P L O A S task T L O A S = (cid:3)B, S M , (cid:3)Ethis, we define several new atoms used in our meta representation.For i ∈ {1, 2}, let f i be a function which maps each atom a in B ∪ S M to a new atom ai. We also extend this notation to work on sets of atoms and rules (and parts of rules) by replacing each atom a in the set or rule with f i(a).For each rule R ∈ S M , define a new atom in_h R .For each weak constraint W ∈ B ∪ S M let id1(W ) and id2(W ) be two new (propositional) atoms and let wt(W ) be the weight of W and priorit y(W ) be the priority level of W .For any two terms t1 and t2, dominates(t1, t2) is defined as below.L A S task. Before we do −, O b, O c(cid:4)(cid:4) to an I L P sdominates(t1, t2) =⎧⎪⎪⎪⎪⎪⎪⎪⎪⎪⎨⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩dom_lv(t1, t2, l):-#sum{id1(W1) = wt(W1), . . . ,id 1(Wn) = wt(Wn),id2(W1) = −wt(W1), . . . ,id 2(Wn) = −wt(Wn)} < 0.non_dom_lv(t1, t2, l):-#sum{id1(W1) = wt(W1), . . . ,id 1(Wn) = wt(Wn),id2(W1) = −wt(W1), . . . ,id 2(Wn) = −wt(Wn)} > 0.dom(t1, t2):- dom_lv(t1, t2, l),not non_bef(t1, t2, l).(cid:15)l is a priority level in B ∪ S M ,W 1 . . . W n are the weakconstraints in B ∪ S M with level l⎫⎪⎪⎪⎪⎪⎪⎪⎪⎪⎬⎪⎪⎪⎪⎪⎪⎪⎪⎪⎭(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)(cid:16)(cid:14)(cid:14)(cid:14)(cid:14)∪L A S(cid:20), S= (cid:3)Bnon_bef(t1, t2, l1):- non_dom_lv(t1, t2, l2).l1, l2 are levels in B ∪ S M ,l1 < l2−(cid:20)(cid:4)(cid:4) where the individual components are defined below. For the positive and Consider the task T s(cid:20)negative examples, it is a simple reification so that the examples relate to the new BM . The brave orderings are mapped to positive examples which can only be covered by a hypothesis H if B ∪ H bravely respects the ordering (cid:20)represent two answer sets of M , the f 1 and f 2 in a single answer set of Bexample. For any hypothesis HB ∪ H where H is the hypothesis in S M corresponding to H. Similarly, cautious orderings are mapped to negative (cid:20)examples, such that there is an answer set of Bwhich extends the example if there is a pair of answer sets of the corresponding B ∪ H which are ordered incorrectly (i.e. if B ∪ H does not cautiously respect the ordering).(cid:20)M , (cid:3)Eand S(cid:20) ∪ H(cid:20) ∪ H+(cid:20), E(cid:20) ∈ S(cid:20)(cid:20)(cid:20)(cid:20) = { f i(R)|R ∈ B, R is not a weak constraint, i ∈ {1, 2}}B∪ {idi(W ):- f i(body(W )).|W is a weak constraint in B, i ∈ {1, 2}}∪ {append( f i(R), in_h R )|R ∈ S M , R is not a weak constraint }∪ {idi(W ):- append( f i(body(W )), in_hW ).|W is a weak constraint in S M , i ∈ {1, 2}}138M. Law et al. / Artificial Intelligence 259 (2018) 110–146∪ dominates(1, 2) ∪ dominates(2, 1)∪ {dom:- dom(1, 2). dom:- dom(2, 1).}= {in_h R |R ∈ S M }(cid:14)(cid:14)e+ ∈ E+)(cid:10)(cid:11)+f 1(e(cid:20)M+(cid:20) =SE(cid:18)∪∪∪∪∪∪−(cid:20) =E∪∪∪∪∪∪(cid:18)(cid:18)(cid:18)(cid:18)(cid:18)(cid:10)(cid:18)(cid:18)(cid:18)(cid:18)(cid:18)(cid:18)(cid:3) f 1(einc1 ) ∪ f 2(einc2 ) ∪ {dom(1, 2)}, f 1(eexc(cid:3) f 1(einc1 ) ∪ f 2(einc2 ), f 1(eexc1 ) ∪ f 2(eexc(cid:3) f 1(einc1 ) ∪ f 2(einc2 ) ∪ {dom}, f 1(eexc1 ) ∪ f 2(eexc(cid:3) f 1(einc1 ) ∪ f 2(einc2 ) ∪ {dom(2, 1)}, f 1(eexc(cid:3) f 1(einc1 ) ∪ f 2(einc2 ), f 1(eexc1 ) ∪ f 2(eexc1 ) ∪ f 2(einc(cid:3) f 1(einc2 ), f 1(eexc(cid:14)(cid:11)(cid:14)e−− ∈ E−)f 1(e1 ) ∪ f 2(eexc(cid:3) f 1(einc1 ) ∪ f 2(einc2 ), f 1(eexc1 ) ∪ f 2(eexc(cid:3) f 1(einc1 ) ∪ f 2(einc2 ) ∪ {dom(2, 1)}, f 1(eexc(cid:3) f 1(einc1 ) ∪ f 2(einc2 ), f 1(eexc1 ) ∪ f 2(eexc(cid:3) f 1(einc1 ) ∪ f 2(einc2 ), f 1(eexc1 ) ∪ f 2(eexc2 )(cid:4)1 ) ∪ f 2(eexc(cid:14)(cid:14)(cid:14)(cid:3)(cid:3)einc(cid:14)(cid:14)(cid:14)(cid:3)(cid:3)einc2 ) ∪ {dom(2, 1)}(cid:4)(cid:14)(cid:14)(cid:14)(cid:3)(cid:3)einc1 , eexc(cid:14)(cid:14)(cid:14)(cid:3)(cid:3)einc(cid:14)(cid:14)(cid:14)(cid:3)(cid:3)einc2 ) ∪ {dom(1, 2)}(cid:4)1 ) ∪ f 2(eexc2 )(cid:4)2 )(cid:4)1(cid:14)(cid:14)(cid:14)(cid:3)(cid:3)einc2 ) ∪ {dom}(cid:4)2 )(cid:4)(cid:14)(cid:14)2 ) ∪ {dom(1, 2)}(cid:4)(cid:14)(cid:3)(cid:3)einc(cid:14)(cid:14)(cid:14)(cid:3)(cid:3)einc1 ) ∪ f 2(eexc(cid:14)(cid:14)(cid:14)(cid:3)(cid:3)einc2 ) ∪ {dom}(cid:4)1 , eexc(cid:14)(cid:14)(cid:14)(cid:3)(cid:3)einc2 ) ∪ {dom(2, 1)}(cid:4)(cid:14)(cid:14)(cid:14)(cid:3)(cid:3)einc1 ) ∪ f 2(eexc2 )(cid:4)1(cid:3) f 1(einc1 ) ∪ f 2(einc2 ) ∪ {dom(1, 2)}, f 1(eexc(cid:3) f 1(einc1 ) ∪ f 2(einc2 ) ∪ {dom}, f 1(eexc1 ) ∪ f 2(eexc2 )(cid:4)1 , eexc11 , eexc1(cid:4), (cid:3)einc2 , eexc2(cid:4), (cid:3)einc2 , eexc2(cid:4), >(cid:4) ∈ O b(cid:4), ≥(cid:4) ∈ O b(cid:19)(cid:4), (cid:3)einc2 , eexc2(cid:4), (cid:17)=(cid:4) ∈ O b1 , eexc11 , eexc1(cid:4), (cid:3)einc2 , eexc2(cid:4), (cid:3)einc2 , eexc2(cid:4), <(cid:4) ∈ O b(cid:4), ≤(cid:4) ∈ O b(cid:19)1 , eexc1(cid:4), (cid:3)einc2 , eexc2(cid:4), =(cid:4) ∈ O b1 , eexc11 , eexc1(cid:4), (cid:3)einc2 , eexc2(cid:4), (cid:3)einc2 , eexc2(cid:4), >(cid:4) ∈ O c(cid:4), ≥(cid:4) ∈ O c(cid:19)(cid:4), (cid:3)einc2 , eexc2(cid:4), (cid:17)=(cid:4) ∈ O c1 , eexc11 , eexc1(cid:4), (cid:3)einc2 , eexc2(cid:4), (cid:3)einc2 , eexc2(cid:4), <(cid:4) ∈ O c(cid:4), ≤(cid:4) ∈ O c(cid:19)(cid:4), (cid:3)einc2 , eexc2(cid:4), =(cid:4) ∈ O c(cid:14)(cid:14)(cid:14)(cid:3)(cid:3)einc11 , eexc(cid:20) ∈ S(cid:20)M :(cid:19)(cid:19)(cid:19)(cid:19)(cid:19)(cid:19)(cid:19)(cid:19)By using the splitting set theorem [35], it can be shown that for any H⎛⎞A S(B(cid:20) ∪ H(cid:20)) =A ∈ A S⎝⎧⎨⎩ A(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)f 1( A1) ∪ f 2( A2)∪dominates(1, 2) ∪ dominates(2, 1)∪{dom:- dom(1, 2). dom:- dom(2, 1).}⎠ , A1, A2 ∈ A S(B ∪ H)⎫⎬⎭(cid:20)(cid:20)(cid:20)(cid:10)A+(cid:20)(cid:20)) =(cid:20) ∈ S(cid:20) ∪ H(cid:20) ∪ H, where Acorrespond to the is mapped to an example in Eis A augmented with dom and dom(1, 2) when (cid:20)M , let H be the corresponding hypothesis in S M . The answer sets of Bensuring that at least one of the pairs of answer sets’ . Note that as each answer set of B ∪ H must be the first element of one of these pairs at Hence, as the rules in dominates(t1, t2) describe exactly the behaviour of the weak constraints in B ∪ H for two answer sets (with dom(t1, t2) being true if and only if the first answer set dominates the second):(cid:14)(cid:11)(cid:14) A = f 1( A1) ∪ f 2( A2), A1, A2 ∈ A S(B ∪ H)A S(BA1 dominates A2 and dom and dom(2, 1) when A2 dominates A1.For any hypothesis Hpairs of answer sets of B ∪ H .++ ∈ EEach positive example e+first answer set covers eleast once, this is true if and only if B ∪ H covers each positive example.− ∈ ESimilarly each negative example eis mapped to an example in Esets’ first answer set covers eEach brave ordering example (cid:3)e1, e2, op(cid:4) ∈ O b is mapped to a positive example ensuring that there is a pair of answer sets (cid:3) A1, A2(cid:4) of B ∪ H such that A1 covers e1, A2 covers e2 and (cid:3) A1, A2, op(cid:4) ∈ ord(B ∪ H). This is true if and only if B ∪ H bravely respects the ordering example.Each cautious ordering example (cid:3)e1, e2, op(cid:4) ∈ O c is mapped to a negative example ensuring that there is no pair of answer sets (cid:3) A1, A2(cid:4) of B ∪ H such that A1 covers e1, A2 covers e2 and (cid:3) A1, A2, op(cid:4) /∈ ord(B ∪ H). This is true if and only if B ∪ H cautiously respects the ordering example.(cid:20), SHence, HI L P L O A S ((cid:3)B, S M , (cid:3)EThis means that we can check the satisfiability of any I L P L O A S task (and similarly verify a solution) by mapping the task to an I L P sAs this mapping is polynomial in size of the original task, this means that verification and satisfiability for I L P L O A Seach reduces polynomially to the corresponding decision problem for I L P s. This is true if and only if B ∪ H does not cover any negative examples.is an inductive solution of I L P s−, O b, O c(cid:4)(cid:4)).−(cid:20) (cid:4)(cid:4)) if and only if H is an inductive solution of L A S task as above. Note that this is a well defined I L P sL A S task as B contains only stratified aggregates.ensuring that none of the pairs of answer L A S ((cid:3)B(cid:20)M , (cid:3)E+, E, E−(cid:20)+(cid:20)−−(cid:20)L A S . (cid:2)Proposition 3. Verifying whether a given H is an inductive solution of a general I L P b task is N P -complete.M. Law et al. / Artificial Intelligence 259 (2018) 110–146139+} ∪ {:- e−. | e−(cid:4)(cid:4). For any H ⊆ S M , H ∈ I L P b(T b) if and only if B ∪ H ∪ {:- not e+. |Proof. Let T b be any I L P b task (cid:3)B, S M , (cid:3)E−} is satisfiable. As deciding the satisfiability of this program is N P -complete (B ∪ H contains + ∈ Eeonly normal rules, choice rules and constraints), and the program can be constructed in polynomial time, this means that deciding verification for I L P b is in N P .− ∈ E+, EIt remains to show that deciding verification is N P -hard. We do this by showing that deciding satisfiability for any ASP program P containing normal rules, choice rules and constraints can be reduced polynomially to deciding verification for an I L P b task. Consider the I L P b task T b = (cid:3)P , ∅, (cid:3)∅, ∅(cid:4)(cid:4). Let H = ∅. H ∈ I L P b(T b) if and only if there is an answer set of P ∪ H , and hence, if and only if P is satisfiable. (cid:2)Proposition 4. Deciding the satisfiability of a general I L P b task is N P -complete.+, EProof. First we will show that deciding the satisfiability of a general I L P b task is in N P . We do this by mapping an arbitrary −(cid:4)(cid:4) to an ASP program whose answer sets can be mapped to the solutions of T . This program will task T = (cid:3)B, S M , (cid:3)Ebe satisfiable if and only if T is satisfiable and as the program is aggregate stratified, checking whether the program is satisfiable is in N P . Hence, if we can construct such a program then we will have proved that deciding satisfiability for I L P b is in N P .For each R i ∈ S M we define a new atom in_hRi . Also, let meta(R i) be the rule R i with the additional atom in_hRiadded to the body.We define the meta encoding Tmeta as follows:Tmeta = B ∪ {meta(R i) | R i ∈ S M } ∪ { 0{in_hR1 , . . . ,in _hR|SM| }|SM|. }∪ {:- not e. | e ∈ E+} ∪ {:- e. | e ∈ E−}For any answer set A, let M−1( A) = {R i | R i ∈ S M , in_hRi ∈ A}.A ∈ A S(Tmeta) if and only if ( A\{in_hRi | R i ∈ S M }) ∈ A S(B ∪ M−1( A) ∪ {:- not e. | e ∈ Ecan be seen by using the splitting set theorem, with {in_hRi | R i ∈ S M } as the splitting set.)+} ∪ {:- e. | e ∈ E−}). (This Hence A ∈ A S(Tmeta) if and only if ∃H ⊆ S M such that H = M−1( A), ( A\{in_hRi | R i ∈ S M }) ∈ A S(B ∪ H) and A respects Hence Tmeta is satisfiable if and only if ∃H ⊆ S M such that ∃ A ∈ A S(B ∪ H) such that A respects the examples. This is the examples.the case if and only if T is satisfiable.It remains to show that deciding the satisfiability of a general I L P b task is N P -hard. Deciding the satisfiability of a normal logic program is N P -hard, so demonstrating that a deciding the satisfiability of a normal program P can be mapped to a I L P b task is sufficient.Let P be any normal logic program. Let T be the I L P b task (cid:3)P , ∅, (cid:3)∅, ∅(cid:4)(cid:4). T is satisfiable if and only if ∃H ⊆ ∅ such that ∃ A ∈ A S(P ∪ H) such that ∅ ⊆ A and A ∩ ∅ = ∅. This is true if and only if P is satisfiable.Hence, deciding the satisfiability of a general I L P b task is N P -complete. (cid:2)Proposition 5. Deciding verification for I L P sL A S is a member of D P .Proof. Checking whether H is an inductive solution of an I L P sT to two aggregate stratified ASP programs Pand Pcautiously an atom.and P−−+L A S task T = (cid:3)B, S M , (cid:3)E+, E, such that H ∈ I L P L A S (T ) if and only if P−(cid:4)(cid:4) can be achieved by mapping bravely entails an atom +1. Let n be the integer |E+|.For any integer i ∈ [1, n], let f i be a function mapping the atoms a in B ∪ H to new atoms ai . We extend the notation to allow f i to act on ASP programs (substituting all atoms in the program).Let Pbe the program:covered(i):- fi(einc), . . . ,f i(eincm), . . . ,not f i(eexc).1o),not fi(eexc1(cid:16)(cid:14)(cid:14)(cid:14)(cid:14)ei = (cid:3){einc1 , . . . , eincm}, {eexc1 , . . . , eexco}(cid:4) ∈ E+(cid:16)+(cid:15)(cid:15)f i(B ∪ H) ∪+can be split into n sub programs P 1 . . . P n where each program P i contains the rules containing the atoms generated Pby f i , plus the rule for covered(i).As the atoms in each sub program are disjoint from the atoms of all other subprograms, A S(PA S(P 1), . . . , An ∈ A S(P n)}. (This follows from applying the splitting set theorem n − 1 times).For each i ∈ [1, n], P i |=b covered(i) if and only if ∃ A ∈ B ∪ H such that A extends ei (where eitive example). Hence Pexamples are covered. Therefore, checking whether all the positive examples are covered is in N P by Corollary 1.As checking that H ⊆ S M can be done in polynomial time, this means that checking both that H ∈ S M and all the positive examples are covered is in N P .is the ith posi-+ ∪ {covered:- covered(1), . . . , covered(n).} |=b covered if and only if all the positive +) = { A1 ∪ . . . ∪ An | A1 ∈140M. Law et al. / Artificial Intelligence 259 (2018) 110–1462. Let P−be the program:(cid:17) (cid:15)B ∪ H ∪ {covered:- not neg_violated.}neg_violated:- einc, . . . ,e inc,o .1, . . . ,not e excnot eexcm1− |=c covered if and only if (cid:3) A ∈ A S(B ∪ H) such that ∃ePnegative examples are covered is in co-N P by Lemma 1.(cid:14)(cid:14)(cid:14)(cid:14)(cid:3){einc1 , . . . , eincm}, {eexc1 , . . . , eexco(cid:16)}(cid:4) ∈ E−− ∈ E−such that A extends e−. Hence checking that all Hence as H ∈ I L P sL A S (T ) if and only if H ⊆ S M , all the positive examples are covered and all the negative examples are L A S (T ) can be reduced to checking one problem in N P and another problem in co-N P . This covered, verifying that H ∈ I L P smeans that verifying a hypothesis is a solution of an I L P sL A S task is in D P . (cid:2)Proposition 6. Deciding verification for I L P c is D P -hard.Proof. To prove that verification that a hypothesis is a solution of an I L P c task is D P -hard, we must prove that any problem in D P can be reduced to the verification task.Let D be any arbitrary decision problem which is in D P .By the definition of D P , this is the case if and only if there exist two decision problems D1 and D2 such that D1 is in N P , D2 is in co-N P and D returns yes if and only if both D1 and D2 return yes.By Lemma 1 and Corollary 1, this is the case if and only if there are two programs P 1 and P 2 and two atoms a1 and a2 such that both P 1 |=b a1 and P 2 |=c a2 if and only if D returns yes. Without loss of generality we can assume that the atoms in P 1 (together with a1) are disjoint from the atoms in P 2 (together with a2).+, E−(cid:4)(cid:4), where the individual components of the task are defined as follows:Take T c to be the I L P c task (cid:3)B, S M , (cid:3)E• B = P 1 ∪ append(P 2, a3) ∪ {:- not a1. 0{a3}1. a2:- not a3.} (where we assume a3 to be a new atom and append(P , a) to add the atom a to the body of all rules in P )• S M = ∅• E• E+ = {a2}− = ∅∅ ∈ I L P c(T c) if and only if (P 1 ∪ {:- not a1.}) is satisfiable and append(P 2, a3) ∪ {0{a3}1. a2:- not a3.} |=c a2. This is the case as the two subprograms P 1 ∪ {:- not a1.} and append(P 2, a3) ∪ {0{a3}1. a2:- not a3.} are disjoint, and the latter is guaranteed to be satisfiable (it will always have the answer set {a2}).Hence ∅ ∈ I L P c(T c) if and only if P 1 |=b a1, and P 2 |=c a2. But this is the case if and only if D returns yes.Hence any problem in D P can be reduced to verifying that a hypothesis is an inductive solution of an I L P c task.Hence verification for I L P c is D P -hard. (cid:2)Proposition 7. Deciding satisfiability for I L P sL A S is in (cid:2)P2 .Proof. Given an I L P sN P oracle could check satisfiability of T in polynomial time.L A S task T = (cid:3)B, S M , (cid:3)E+, E−(cid:4)(cid:4), we show that a non-deterministic Turing Machine with access to an A non-deterministic Turing Machine can have |S M | choices to make (corresponding to selecting each rule as part of the hypothesis). This hypothesis can then be verified in polynomial time using an N P oracle, with two queries similar to the N P query and (the complement of) the co-N P query in Proposition 5, answering yes if and only if the first query returned yes and the second query returned no.Such a Turing Machine would terminate answering yes if and only if the task is satisfiable (as there is a path through the Turing Machine which answers yes if and only if there is an hypothesis in S M which is an inductive solution of the task).Hence, deciding the existence of a solution for an I L P sL A S task is in (cid:2)P2 . (cid:2)Proposition 8. Deciding satisfiability for I L P c is (cid:2)P2 -hard.Proof. We show this by reducing a known (cid:2)Pdisjunctive logic program [55]) to an I L P c task.2 -complete problem (deciding the existence of an answer set for a ground Take any ground disjunctive logic program P . We will define an I L P c task T (P ) which has a solution if and only if Phas an answer set.Let Atoms be the set of atoms in P . Let Pbe the program constructed by replacing each negative literal not a with the literal not in_as(a) (where in_as is a new predicate) and replacing each head h1 ∨ . . . ∨ hm with the counting aggregate 1{h1, . . . , hm}m (empty heads are mapped to 1{}0 - this is equivalent to ⊥).(cid:20)M. Law et al. / Artificial Intelligence 259 (2018) 110–146141We define the learning task T (P ) as follows (not_minimal is a new atom):(cid:15)B = P(cid:20) ∪:- a, not in_as(a).not_minimal:- not a, in_as(a).S M = {in_as(a) | a ∈ Atoms}+ = ∅− = {not_minimal}EE(cid:16)(cid:14)(cid:14)(cid:14)(cid:14)a ∈ AtomsThis task has a solution if there exists an H ⊆ S M such that B ∪ H is satisfiable and no answer set of B ∪ H contains not_minimal.⇔ ∃H ⊆ S M st∃ A ∈ A S⎛⎝⎧⎨⎩1{h1, . . . ,h m}m:- b1, . . . , bn(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)1{h1, . . . ,h m}m:- b1, . . . ,b n,not in_as(c1), . . . ,not in _as(co).{in_as(c1), . . . , in_as(co)} ∩ H = ∅∈ P(cid:20),⎞⎠⎫⎬⎭such that A ⊆ {a | in_as(a) ∈ H} and no answer set of B ∪ H contains not_minimal.⇔ ∃H ⊆ S M st ∃ A ∈ A S⎛⎝⎧⎨⎩1{h1, . . . ,h m}m:- b1, . . . ,b n(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)1{h1, . . . , hm}m:- b1, . . . ,b n,not in_as(c1), . . . ,not in _as(co).{in_as(c1), . . . , in_as(co)} ∩ H = ∅∈ P(cid:20),⎞⎠⎫⎬⎭such that A = {a | in_as(a) ∈ H} and there is no strict subset of A which is also an answer set (or there would be an answer set of B ∪ H which contains not_minimal).⇔ ∃H ⊆ S M st {a | in_as(a) ∈ H} is a minimal model of⎧⎨⎩h1 ∨ . . . ∨ hm:- b1, . . . ,b n1{h1, . . . ,h m}m:- b1, . . . , bn,not in_as(c1), . . . , not in_as(co).{in_as(c1), . . . , in_as(co)} ∩ H = ∅∈ P(cid:20),⎫⎬⎭⇔ ∃H ⊆ S M st {a | in_as(a) ∈ H} is a minimal model of⎧⎨⎩h1 ∨ . . . ∨ hm:- b1, . . . ,b nh1 ∨ . . . ∨ hm:- b1, . . . , bn,not c1, . . . ,not c o.∈ P ,{in_as(c1), . . . , in_as(co)} ∩ H = ∅⇔ ∃ A ⊆ Atoms st A is a minimal model of⎧⎨⎩h1 ∨ . . . ∨ hm:- b1, . . . ,b nh1 ∨ . . . ∨ hm:- b1, . . . , bn,not c1, . . . ,not c o.{c1, . . . , co} ∩ A = ∅∈ P ,⎫⎬⎭⎫⎬⎭(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)(cid:14)⇔ ∃ A ⊆ Atoms such that A is a minimal model of P A⇔ ∃ A ⊆ Atoms such that A an answer set of P .⇔ P is satisfiable.Hence, deciding whether a disjunctive logic program is satisfiable can in general be mapped to the decision problem of checking the existence of solutions of a learning from answer sets task.Therefore, deciding the existence of solutions of a ground I L P c task is (cid:2)P2 -hard. (cid:2)A.2. Proofs from Section 5Proposition 12. For any programs P 1 and P 2, Eb(P 1) ⊆ Eb(P 2) if and only if A S(P 1) ⊆ A S(P 2).Proof.• Assume that A S(P 1) ⊆ A S(P 2)⇔ ∀ A ∈ A S(P 1), A ∈ A S(P 2).Assume c = i1 ∧ . . . ∧ im, ∧not e1, . . . ,not e n ∈ Eb(P 1). Then there must be an answer set A of P 1 which contains all of the i’s and none of the e’s. Hence, there is also such an answer set of P 2 which contains all of the i’s and none of the e’s. Hence, c ∈ Eb(P 2).142M. Law et al. / Artificial Intelligence 259 (2018) 110–146• Conversely, assume that Eb(P 1) ⊆ Eb(P 2). Let A ∈ A S(P 1), we must show that A ∈ A S(P 2).∪ H B P 2 .Let L be the set H B P 1As A ∈ A S(P 1), c = i1 ∧ . . . ∧ im, ∧not e1, . . . ,not e n ∈ Eb(P 1), where the i’s are the set of atoms in A and the e’s are the set of atoms in L\ A. As c ∈ Eb(P 1), c ∈ Eb(P 2) and hence there is an answer set Aof P 2 which contains each i ∈ A but no atom e ∈ L\ A, and hence as H B P 2(cid:10)(cid:20) = A. Hence A ∈ A S(P 2). (cid:2)⊆ L, A(cid:20)Proposition 13. D11(I L P b) =(cid:14)(cid:11)(cid:14) A S(B ∪ H1) (cid:5) A S(B ∪ H2)(cid:3)B, H1, H2(cid:4).Proof. We prove this by showing that D1(cid:14)(cid:11)(cid:10)(cid:14) A S(B ∪ H1) (cid:5) A S(B ∪ H2)(cid:3)B, H1, H2(cid:4)1(I L P b) =by Proposition 12.(cid:10)(cid:14)(cid:11)(cid:14)Eb(B ∪ H1) (cid:5) Eb(B ∪ H2)(cid:3)B, H1, H2(cid:4), which is equal to the set • We first show that if (cid:3)B, H1, H2(cid:4) ∈ D11(I L P b) then there must be a conjunction in Eb(B ∪ H1) that is not in Eb(B ∪ H2).1(I L P b), there is an I L P b task T = (cid:3)B, (cid:3){i1, . . . , im}, {e1, . . . , en}(cid:4)(cid:4) such that H1 ∈ I L P b(T ) and H2 /∈As (cid:3)B, H1, H2(cid:4) ∈ D1I L P b(T ).Hence, there must be an answer set of B ∪ H 1 such that {i1, . . . , im} ⊆ A and {e1, . . . , em} ∩ A = ∅, but no such answer set of B ∪ H2.Hence the conjunction c = i1 ∧ . . . ∧ im ∧ not e1 ∧ . . . ∧ not en ∈ Eb(B ∪ H1) but c /∈ Eb(B ∪ H2).• Next we show that if there exists a conjunction c = i1 ∧ . . . ∧ im ∧ not e1 ∧ . . . ∧ not en such that c ∈ Eb(B ∪ H1) but c /∈ Eb(B ∪ H2), then (cid:3)B, H1, H2(cid:4) ∈ D1Assume that there is such a conjunction c. Then B ∪ H 1 has an answer set that extends (cid:3){i1, . . . , im}, {e1, . . . , en}(cid:4) and B ∪ H2 does not. Hence H1 ∈ I L P b((cid:3)B, (cid:3){i1, . . . , im}, {e1, . . . , en}(cid:4)(cid:4)) but H2 /∈ I L P b((cid:3)B, (cid:3){i1, . . . , im}, {e1, . . . , en}(cid:4)(cid:4)). So (cid:3)B, H1, H2(cid:4) ∈ D11(I L P b).1(I L P b). (cid:2)Proposition 14. D11(I L P b) = D11(I L P sm).Proof.• First we show that D11(I L P b) ⊆ D11(I L P sm). Assume (cid:3)B, H1, H2(cid:4) ∈ D1such that H1 ∈ I L P b(T b) and H2 /∈ I L P b(T b). Let T sm = (cid:3)B, {(cid:3)E(cid:3)B, H1, H2(cid:4) ∈ D11(I L P sm).1(I L P b). Then there is a task T b = (cid:3)B, (cid:3)E−(cid:4)(cid:4)−(cid:4)}(cid:4). H1 ∈ I L P sm(T sm) but H2 /∈ I L P sm(T sm). Hence, +, E+, E1(I L P b) ⊇ D1• Next we show that D1−n. . . ,(cid:3) E+(cid:3)Ei , Eswer set of B ∪ H2. Hence, letting T b = (cid:3)B, (cid:3)E(cid:4),(cid:4)}(cid:4) such that H1 ∈ I L P sm(T sm) and H2 /∈ I L P sm(T sm). There must be at least one partial interpretation ∩ A = ∅ and there is no such an-1(I L P b). (cid:2)(cid:4) such that there is an answer set A of B ∪ H 1 such that E(cid:4)(cid:4), H1 ∈ I L P b(T b) but H2 /∈ I L P b(T b). So (cid:3)B, H1, H2(cid:4) ∈ D11(I L P sm). There must be a task T sm = (cid:3)B, {(cid:3)E1(I L P sm). Assume (cid:3)B, H1, H2(cid:4) ∈ D1⊆ A and E+n , E−i+i , E−i−i+i+1 , E−1Proposition 15. D11(I L P c) =(cid:15)(cid:14)(cid:14)(cid:14)(cid:3)B, H1, H2(cid:4)(cid:14)A S(B ∪ H1) (cid:17)= ∅∧( A S(B ∪ H2) = ∅ ∨ Ec(B ∪ H2) (cid:5) Ec(B ∪ H1))(cid:16).Proof.• First we show that for any (cid:3)B, H 1, H2(cid:4) ∈ D11(I L P c), A S(B ∪ H1) (cid:17)= ∅ and either A S(B ∪ H2) = ∅ or Ec(B ∪ H1) (cid:5) Ec(B ∪H2).Let (cid:3)B, H1, H2(cid:4) be an arbitrary element of D1Ec(B ∪ H2). We must show that A S(B ∪ H2) = ∅. As (cid:3)B, H1, H2(cid:4) ∈ D1and H2 /∈ I L P c(T c).−} ∈ Ec(B ∪As H1 ∈ I L P c(T c), ∀ A ∈ A S(B ∪ H1) : EH1); hence by our initial assumption that Ec(B ∪ H1) ⊆ Ec(B ∪ H2), the conjunction is also in Ec(B ∪ H2); hence, ∀ A ∈ A S(B ∪ H2), E1(I L P c). As H1 ∈ I L P c(T c), A S(B ∪ H1) (cid:17)= ∅. Assume that Ec(B ∪ H1) ⊆−(cid:4)(cid:4) such that H1 ∈ I L P c(T c)− ∩ A = ∅. But as H2 /∈ I L P c(T c) this means that A S(B ∪ H2) = ∅.− ∩ A (cid:17)= ∅, hence the conjunction E1(I L P c), ∃T c = (cid:3)B, (cid:3)E+ ⊆ A and E+ ⊆ A and E+ ∧ {not e− ∈ E− | e+, E• We now show that for any B, H 1 and H2, if A S(B ∪ H1) (cid:17)= ∅ ∧ ( A S(B ∪ H2) = ∅ ∨ Ec(B ∪ H1) (cid:5) Ec(B ∪ H2), then (cid:3)B, H1, H2(cid:4) ∈ D1Case 1: A S(B ∪ H1) (cid:17)= ∅ ∧ A S(B ∪ H2) = ∅.1(I L P c).Consider the task T c = (cid:3)B, (cid:3)∅, ∅(cid:4)(cid:4). H1 ∈ I L P c(T c) as A S(B ∪ H1) (cid:17)= ∅ and ∀ A ∈ A S(B ∪ H1), ∅ ⊆ A and A ∩ ∅ = ∅. H2 /∈ I L P c(T c) as A S(B ∪ H2) = ∅.Case 2: A S(B ∪ H1) (cid:17)= ∅ ∧ ∃(c = i1 ∧ . . . ∧ im ∧ not e1 ∧ . . . ∧ en) ∈ Ec(B ∪ H1) such that c /∈ Ec(B ∪ H2).Consider the task T c = (cid:3)B, (cid:3){i1, . . . , im}, {e1, . . . , en}(cid:4)(cid:4). H1 ∈ I L P c(T c), but H2 /∈ I L P c(T c). (cid:2)Proposition 16. D11(I L P L A S ) = {(cid:3)B, H1, H2(cid:4)| A S(B ∪ H1) (cid:17)= A S(B ∪ H2)}Proof.M. Law et al. / Artificial Intelligence 259 (2018) 110–146143• We first show that D1I L P L A S task T = (cid:3)B, (cid:3)ECase 1: ∃e ∈ E+As H1 ∈ I L P L A S (T ), ∃ AH1) (cid:17)= A S(B ∪ H2).As H1 ∈ I L P L A S (T ), ∀ AH1) (cid:17)= A S(B ∪ H2).• It remains to show that D11(I L P L A S ) ⊆ {(cid:3)B, H1, H2(cid:4)| A S(B ∪ H1) (cid:17)= A S(B ∪ H2)}. For any (cid:3)B, H1, H2(cid:4) ∈ D1+, E−(cid:4)(cid:4) such that H1 ∈ I L P L A S (T ) and H2 /∈ I L P L A S (T ).1(I L P L A S ) there is an such that ∀ A ∈ A S(B ∪ H2), A does not extend e.(cid:20) ∈ A S(B ∪ H1) such that A(cid:20)extends e. Hence as A(cid:20)cannot be in A S(B ∪ H2), A S(B ∪Case 2: ∃e ∈ E−, ∃ A ∈ A S(B ∪ H2) such that A extends e.(cid:20) ∈ A S(B ∪ H1), A(cid:20)does not extend e. Hence A cannot be in A S(B ∪ H 1) and so A S(B ∪1(I L P L A S ) ⊇ {(cid:3)B, H1, H2(cid:4)| A S(B ∪ H1) (cid:17)= A S(B ∪ H2)}. Take B, H1, H2 to be any ASP programs such that A S(B ∪ H1) (cid:17)= A S(B ∪ H2)Let L be the set of atoms which appear in answer sets of B ∪ H 1 and B ∪ H2.Case 1: ∃ A ∈ A S(B ∪ H1) such that A /∈ A S(B ∪ H2)Let e A = (cid:3) A, L\ A(cid:4). A is the only interpretation in A S(B ∪ H 1) or A S(B ∪ H2) which extends e A (as e A is completely defined over the atoms in L). Hence, there is an answer set of B ∪ H 1 which extends e A , but no such answer set of B ∪ H2.Hence, H1 ∈ I L P L A S ((cid:3)B, (cid:3){e A}, ∅(cid:4)(cid:4)), but H2 /∈ I L P L A S ((cid:3)B, (cid:3){e A}, ∅(cid:4)(cid:4)). So (cid:3)B, H1, H2(cid:4) ∈ D11(I L P L A S ).Case 2: ∃ A ∈ A S(B ∪ H2) such that A /∈ A S(B ∪ H1)Let e A = (cid:3) A, L\ A(cid:4). A is the only interpretation in A S(B ∪ H 1) or A S(B ∪ H2) which extends e A . Hence, there is no answer set of B ∪ H1 which extends e A , but there is such an answer set of B ∪ H 2.Hence, H1 ∈ I L P L A S ((cid:3)B, (cid:3)∅, {e A}(cid:4)(cid:4)), but H2 /∈ I L P L A S ((cid:3)B, (cid:3)∅, {e A}(cid:4)(cid:4)). So (cid:3)B, H1, H2(cid:4) ∈ D11(I L P L A S ). (cid:2)Proposition 17. D11(I L P L O A S ) =(cid:15)(cid:14)(cid:14)(cid:14)(cid:3)B, H1, H2(cid:4)(cid:14)A S(B ∪ H1) (cid:17)= A S(B ∪ H2) orord(B ∪ H1) (cid:17)= ord(B ∪ H2)(cid:16).Proof.(cid:3)B, H1, H2(cid:4) ∈ D1H2 /∈ I L P L O A S (T ).Case 1: ∃e ∈ E+As H1 ∈ I L P L O A S (T ), ∃ AH1) (cid:17)= A S(B ∪ H2).As H1 ∈ I L P L O A S (T ), ∀ AH1) (cid:17)= A S(B ∪ H2).• We first show that D11(I L P L O A S ) ⊆ {(cid:3)B, H1, H2(cid:4)| A S(B ∪ H1) (cid:17)= A S(B ∪ H2) or ord(B ∪ H1) (cid:17)= ord(B ∪ H2)}. For any −, O b, O c(cid:4)(cid:4) such that H1 ∈ I L P L O A S (T ) and task T = (cid:3)B, (cid:3)E1(I L P L O A S ) there is an I L P L O A S+, Esuch that ∀ A ∈ A S(B ∪ H2), A does not extend e.(cid:20) ∈ A S(B ∪ H1) such that A(cid:20)extends e. Hence as A(cid:20)cannot be in A S(B ∪ H2), A S(B ∪Case 2: ∃e ∈ E−, ∃ A ∈ A S(B ∪ H2) such that A extends e.(cid:20) ∈ A S(B ∪ H1), A(cid:20)does not extend e. Hence, A cannot be in A S(B ∪ H 1) and so A S(B ∪Case 3: ∃(cid:3)e1, e2, op(cid:4) ∈ O b which is covered by H1 but not H2.Assume A S(B ∪ H1) = A S(B ∪ H2). ∃ A1, A2 ∈ A S(B ∪ H1) such that A1 extends e1, A2 extends e2 and (cid:3) A1, A2, op(cid:4) ∈ ord(B ∪ H1) as H1 covers the ordering example. (cid:3) A1, A2, op(cid:4) /∈ ord(B ∪ H2) as H2 does not cover the ordering example; and hence, ord(B ∪ H 1) (cid:17)= ord(B ∪ H2).Case 4: ∃(cid:3)e1, e2, op(cid:4) ∈ O c which is covered by H1 but not H2.Assume A S(B ∪ H1) = A S(B ∪ H2). ∃ A1, A2 ∈ A S(B ∪ H2) such that A1 extends e1, A2 extends e2 and (cid:3) A1, A2, op(cid:4) /∈ ord(B ∪ H2) as H2 does not cover the ordering example. (cid:3) A1, A2, op(cid:4) ∈ ord(B ∪ H1) as H1 does cover the ordering example; and hence, ord(B ∪ H 1) (cid:17)= ord(B ∪ H2).Hence, in all cases, either A S(B ∪ H 1) (cid:17)= A S(B ∪ H2 or ord(B ∪ H1) (cid:17)= ord(B ∪ H2).• It remains to show that D11(I L P L O A S ) ⊇ {(cid:3)B, H1, H2(cid:4)| A S(B ∪ H1) (cid:17)= A S(B ∪ H2) or ord(B ∪ H1) (cid:17)= ord(B ∪ H2)}. Take B, H1, H2 to be any ASP programs such that A S(B ∪ H 1) (cid:17)= A S(B ∪ H2) or ord(B ∪ H1) (cid:17)= ord(B ∪ H2).Let L be the set of literals which appear in answer sets of B ∪ H 1 and B ∪ H2.Case 1: A S(B ∪ H1) (cid:17)= A S(B ∪ H2)(cid:3)B, H1, H2(cid:4) ∈ D1H1 ∈ I L P L A S (T L A S ) and H2 /∈ I L P L A S (T L A S ). Let T L O A S = (cid:3)B, (cid:3)EI L P L O A S (T L O A S ).1(I L P L A S ) (by Proposition 16). Hence, there is an I L P L A S task T L A S = (cid:3)B, (cid:3)E+, E−(cid:4)(cid:4) such that −, ∅, ∅(cid:4)(cid:4). H1 ∈ I L P L O A S (T L O A S ) and H2 /∈+, ECase 2: A S(B ∪ H1) = A S(B ∪ H2) but ord(B ∪ H1) (cid:17)= ord(B ∪ H2)∃ A1, A2 ∈ A S(B ∪ H1) (which is equal to A S(B ∪ H2)) such that there is a binary operator op such that (cid:3) A1, A2, op(cid:4) ∈ ord(B ∪ H1) but (cid:3) A1, A2, op(cid:4) /∈ ord(B ∪ H2).6 Let e1 = (cid:3) A1, L\ A1(cid:4) and e2 = (cid:3) A2, L\ A2(cid:4) (where L is 6 Note that there is no need to consider the case where there is a tuple (cid:3) A1, A2, op(cid:4) ∈ ord(B ∪ H2) such that (cid:3) A1, A2, op(cid:4) /∈ ord(B ∪ H1), as in this case (cid:3) A1, A2, op−1(cid:4) /∈ ord(B ∪ H2) (where <−1 is ≥, >−1 is ≤, =−1 is (cid:17)=, ≥−1 is <, ≤−1 is > and (cid:17)=−1 is =).−1(cid:4) ∈ ord(B ∪ H1) and (cid:3) A1, A2, op144M. Law et al. / Artificial Intelligence 259 (2018) 110–146the set of atoms in the answer sets of B ∪ H 1). Consider the I L P L O A S task T L O A S = (cid:3)B, (cid:3){e1, e2}, ∅, {(cid:3)e1, e2, op(cid:4)},∅(cid:4)(cid:4). H1 ∈ I L P L O A S (T L O A S ) and H2 /∈ I L P L O A S (T L O A S ).Hence, in both cases (cid:3)B, H1, H2(cid:4) ∈ D11(I L P L O A S ). (cid:2)Proposition 18. D11(I L P contextL O A S ) =(cid:15)(cid:14)(cid:14)(cid:14)(cid:3)B, H1, H2(cid:4)(cid:14)B ∪ H1 (cid:17)≡s B ∪ H2 or∃C ∈ ASP ch such that ord(B ∪ H1 ∪ C) (cid:17)= ord(B ∪ H2 ∪ C)(cid:16).Proof.• We first show that D11(I L P contextL O A S ) ⊆L O A S ) there is an I L P contextL O A S1(I L P context(cid:14)(cid:15)(cid:14)(cid:14)(cid:3)B, H1, H2(cid:4)(cid:14)B ∪ H1 (cid:17)≡s B ∪ H2 or∃C ∈ ASP ch st ord(B ∪ H1 ∪ C) (cid:17)= ord(B ∪ H2 ∪ C)task T = (cid:3)B, (cid:3)E+, E−, O b, O c(cid:4)(cid:4) such that H1 ∈ I L P contextL O A S (T ) and (cid:16). For any(cid:3)B, H1, H2(cid:4) ∈ D1H2 /∈ I L P contextL O A S (T ).Case 1: ∃(cid:3)e, C(cid:4) ∈ E+−such that ∀ A ∈ A S(B ∪ H2 ∪ C), A does not extend e.(cid:20) ∈ A S(B ∪ H1 ∪ C) such that AL O A S (T ), ∃ AAs H1 ∈ I L P contextA S(B ∪ H1 ∪ C) (cid:17)= A S(B ∪ H2 ∪ C). Hence, B ∪ H1 (cid:17)≡s B ∪ H2.(cid:20)Case 2: ∃(cid:3)e, C(cid:4) ∈ E, ∃ A ∈ A S(B ∪ H2 ∪ C) such that A extends e.(cid:20) ∈ A S(B ∪ H1 ∪ C), AL O A S (T ), ∀ AAs H1 ∈ I L P contextso A S(B ∪ H1 ∪ C) (cid:17)= A S(B ∪ H2 ∪ C). Hence, B ∪ H1 (cid:17)≡s B ∪ H2.Case 3: ∃(cid:3)(cid:3)e1, C1(cid:4), (cid:3)e2, C2(cid:4), op(cid:4) ∈ O b which is covered by H1 but not H2.(cid:20)extends e. Hence, as A(cid:20)cannot be in A S(B ∪ H2 ∪ C), does not extend e. Hence, A cannot be in A S(B ∪ H 1 ∪ C) and Assume that B ∪ H1 ≡s B ∪ H2.Let S be the set A S(B ∪ H1 ∪ C1) ∪ A S(B ∪ H1 ∪ C2) (which is equal to the set A S(B ∪ H 2 ∪ C1) ∪ A S(B ∪ H2 ∪ C2)as B ∪ H1 ≡s B ∪ H2). ∃ A1 ∈ A S(B ∪ H1 ∪ C1), A2 ∈ A S(B ∪ H1 ∪ C2) such that A1 extends e1, A2 extends e2 and (cid:3) A1, A2, op(cid:4) ∈ ord(B ∪ H1, S) as H1 covers the ordering example. (cid:3) A1, A2, op(cid:4) /∈ ord(B ∪ H2, S) as H2 does not cover the ordering example.Let C be the ASP ch program append(C1, a1) ∪ append(C2, a2) ∪ {1{a1, a2}1.} (where a1 and a2 are new atoms and append(P , a) appends the atom a to the body of each rule in P ). A S(B ∪ H 1 ∪ C) = { A ∪ {a1} | A ∈A S(B ∪ H1 ∪ C1)} ∪ { A ∪ {a2} | A ∈ A S(B ∪ H1 ∪ C2)}, and hence, t = (cid:3) A1 ∪ {a1}, A2 ∪ {a2}, op(cid:4) ∈ ord(B ∪ H1 ∪ C), but t /∈ ord(B ∪ H2 ∪ C).Hence, ∃C ∈ ASP ch such that ord(B ∪ H1 ∪ C) (cid:17)= ord(B ∪ H2 ∪ C).Case 4: ∃(cid:3)e1, e2, op(cid:4) ∈ O c which is covered by H1 but not H2.Assume that B ∪ H1 ≡s B ∪ H2.Let S be the set A S(B ∪ H1 ∪ C1) ∪ A S(B ∪ H1 ∪ C2) (which is equal to the set A S(B ∪ H 2 ∪ C1) ∪ A S(B ∪ H2 ∪ C2)as B ∪ H1 ≡s B ∪ H2). ∃ A1 ∈ A S(B ∪ H1 ∪ C1), A2 ∈ A S(B ∪ H1 ∪ C2) such that A1 extends e1, A2 extends e2and (cid:3) A1, A2, op(cid:4) /∈ ord(B ∪ H2, S) as H2 does not cover the ordering example. (cid:3) A1, A2, op(cid:4) ∈ ord(B ∪ H1, S) as H1 does cover the ordering example.Let C be the ASP ch program append(C1, a1) ∪ append(C2, a2) ∪ {1{a1, a2}1.} (where a1 and a2 are new atoms and append(P , a) appends the atom a to the body of each rule in P ). A S(B ∪ H 1 ∪ C) = { A ∪ {a1} | A ∈A S(B ∪ H1 ∪ C1)} ∪ { A ∪ {a2} | A ∈ A S(B ∪ H1 ∪ C2)}, and hence, t = (cid:3) A1 ∪ {a1}, A2 ∪ {a2}, op(cid:4) ∈ ord(B ∪ H1 ∪ C), but t /∈ ord(B ∪ H2 ∪ C).Hence, ∃C ∈ ASP ch such that ord(B ∪ H1 ∪ C) (cid:17)= ord(B ∪ H2 ∪ C).Hence, in all cases, either B ∪ H 1 ≡s B ∪ H2 or ∃C ∈ ASP ch such that ord(B ∪ H1 ∪ C) (cid:17)= ord(B ∪ H2 ∪ C).• It remains to show that D11(I L P L O A S ) ⊇ {(cid:3)B, H1, H2(cid:4)| A S(B ∪ H1) (cid:17)= A S(B ∪ H2) or ord(B ∪ H1) (cid:17)= ord(B ∪ H2)}. Take B, H1, H2 to be any ASP programs such that A S(B ∪ H 1) (cid:17)= A S(B ∪ H2) or ord(B ∪ H1) (cid:17)= ord(B ∪ H2).Case 1: B ∪ H1 (cid:17)≡s B ∪ H2There must be a program C such that A S(B ∪ H 1 ∪ C) (cid:17)= A S(B ∪ H2 ∪ C).Case i: ∃ A ∈ A S(B ∪ H1 ∪ C) such that A /∈ A S(B ∪ H2 ∪ C).Let L be the set of atoms in the answer sets of B ∪ H 1 ∪ C and B ∪ H2 ∪ C and let e A be the partial interpretation (cid:3) A, L\ A(cid:4). Then B ∪ H 1 ∪ C has an answer set that extends e A , but B ∪ H2 ∪ C does not, and hence, H1 ∈ I L P contextL O A S ((cid:3)B, S M , (cid:3){(cid:3)e A, C(cid:4)}, ∅, ∅, ∅(cid:4)(cid:4)) but H2 is not.Case ii: ∃ A ∈ A S(B ∪ H2 ∪ C) such that A /∈ A S(B ∪ H1 ∪ C).Let L be the set of atoms in the answer sets of B ∪ H 1 ∪ C and B ∪ H2 ∪ C and let e A be the partial interpretation (cid:3) A, L\ A(cid:4). Then B ∪ H 2 ∪ C has an answer set that extends e A , but B ∪ H1 ∪ C does not, and hence, H1 ∈ I L P contextL O A S ((cid:3)B, S M , (cid:3)∅, {(cid:3)e A, C(cid:4)}, ∅, ∅(cid:4)(cid:4)) but H2 is not.Case 2: B ∪ H1 ≡s B ∪ H2 but ∃C ∈ ASP ch such that ord(B ∪ H1 ∪ C) (cid:17)= ord(B ∪ H2 ∪ C)∃ A1, A2 ∈ A S(B ∪ H1 ∪ C) (which is equal to A S(B ∪ H2 ∪ C)) such that there is a binary operator op such that (cid:3) A1, A2, op(cid:4) ∈ ord(B ∪ H1 ∪ C) but (cid:3) A1, A2, op(cid:4) /∈ ord(B ∪ H2 ∪ C). Let e1 = (cid:3) A1, L\ A1(cid:4) and e2 = (cid:3) A2, L\ A2(cid:4)(where L is the set of atoms in the answer sets of B ∪ H 1 ∪ C ). Consider the I L P context=L O A S(cid:3)B, (cid:3){e1, e2}, ∅, {(cid:3)(cid:3)e1, C(cid:4), (cid:3)e2, C(cid:4), op(cid:4)}, ∅(cid:4)(cid:4). H1 ∈ I L P contextL O A S ).L O A S ) and H2 /∈ I L P contextL O A S (T contextL O A S (T contexttask T contextL O A SHence, in both cases (cid:3)B, H1, H2(cid:4) ∈ D11(I L P contextL O A S ). (cid:2)Proposition 19. For any learning framework F , D1m(F ) =(cid:14)(cid:10)(cid:14)(cid:3)B, H, H1(cid:4), . . . ,(cid:3) B, H, Hn(cid:4) ∈ D1(cid:3)B, H, {H1, . . . , Hn}(cid:4)(cid:11)1(F ).M. Law et al. / Artificial Intelligence 259 (2018) 110–146145Proof.• We first show (cid:3)B, H, S(cid:4) ∈ D1this, we need to show that ∀HTake an arbitrary Hsubset SHence, as H(cid:20) ⊆ S such that H(cid:20), (cid:3)B, H, H• We now show that D1(cid:20) ∈ S{H1, . . . , Hn}(cid:4) ∈hence, (cid:3)B, H, {H i}(cid:4) ∈ D1m(F ) ⊆m(F ). We must show that (cid:3)B, H, S(cid:4) ∈(cid:14)(cid:11)(cid:14)(cid:3)B, H, H1(cid:4), . . . ,(cid:3) B, H, Hn(cid:4) ∈ D11(F )(cid:3)B, H, {H1, . . . , Hn}(cid:4)(cid:14)(cid:14)(cid:3)B, H, H1(cid:4), . . . , (cid:3)B, H, Hn(cid:4) ∈ D1(cid:3)B, H, {H1, . . . , Hn}(cid:4)that D1. Take an arbitrary(cid:11)1(F ). To do (cid:10)(cid:10)(cid:20) ∈ S, (cid:3)B, H, H(cid:20)(cid:4) ∈ D11(F ).(cid:20) ∈ S. It remains to show that (cid:3)B, H, H(cid:20)(cid:4) ∈ D11(F ). By definition of D1(cid:20)(cid:4) ∈ D1(cid:20) ∈ S(cid:20)and (cid:3)B, H, S(cid:20)(cid:4) ∈ D11(F ).(cid:10)m(F ) ⊇(cid:14)(cid:10)(cid:14)(cid:3)B, H, H1(cid:4), . . . ,(cid:3) B, H, Hn(cid:4) ∈ D1(cid:3)B, H, {H1, . . . , Hn}(cid:4)(cid:14)(cid:14)(cid:3)B, H, H1(cid:4), . . . , (cid:3)B, H, Hn(cid:4) ∈ D1(cid:3)B, H, {H1, . . . , Hn}(cid:4)(cid:11)1(F )m(F ), (cid:3)B, H, {H1, . . . , Hn}(cid:4) ∈ D1m(F ). Hence, by definition of D1(cid:11)1(F )m(F ). Hence, ∃T F such that H ∈ I L P F (T F ) and S. Take an arbitrary (cid:3)B, H,1(F ), and . For each i ∈ [1..n], (cid:3)B, H, H i(cid:4) ∈ D1m(F ). (cid:2)m(F ), there must be some (cid:20) ∩ I L P F (T F ) = ∅. Proposition 20. I L P c , I L P sm, I L P L A S , I L P L O A S and I L P contextL O A S all have closed one-to-many-distinguishability.Proof.1. Consider any two I L P c tasks, T 1cH ∈ I L P c(T 1−∪ EE2Hence, by Lemma 2, I L P c has closed one-to-many-distinguishability.∩ A = ∅. This is the case if and only if (E+= (cid:3)B, (cid:3)E1+c ) if and only if A S(B ∪ H) is non-empty and ∀ A ∈ A S(B ∪ H): E1+2 ) ⊆ A, and (E+∪ E2 , E+∩ A = ∅ and ⊆ A, E2−2 ) ∩ A = ∅ which holds if an only if H ∈ I L P c(T 3c ).−−∪ E12⊆ A, Ec ) ∩ I L P c(T 2(cid:4)(cid:4) and T 2c(cid:4)(cid:4). Let T 3c= (cid:3)B, (cid:3)E= (cid:3)B, (cid:3)E+2 , E+1 , E(cid:4)(cid:4).−1∪ E−2+1−1−12. For any tasks T 1sm1, . . . e1n}(cid:4) and T 2sm= (cid:3)B, {e21, . . . e2m}(cid:4), let T 3sm= (cid:3)B, {e11, . . . e1n, e21, . . . , e2m}(cid:4). I L P sm(T 3sm) == (cid:3)B, {e1sm).= (cid:3)B, (cid:3)EL A S ).sm) ∩ I L P sm(T 2I L P sm(T 1Hence, by Lemma 2, I L P sm has closed one-to-many-distinguishability.−1(cid:4)(cid:4) and T 23. For any tasks T 1= (cid:3)B, (cid:3)E+1 , E(cid:4)(cid:4), let T 3+2 , E−2L A SL A S∪ O bL A S ) ∩ I L P L A S (T 24. For any tasks T 1I L P L A S (T 1Hence, by Lemma 2, I L P L A S has closed one-to-many-distinguishability.+−= (cid:3)B, (cid:3)E(cid:4)(cid:4) and T 21 , O b2 , E−L O A S ) ∩ I L P L O A S (T 2L O A S ) = I L P L O A S (T 12 , O bEHence, by Lemma 2, I L P L O A S has closed one-to-many-distinguishability.−−+= (cid:3)B, (cid:3)E2 , O b2, O c1 , O b2 , EL O A S ) ∩ I L P contextL O A S (T 2contextL O A S has closed one-to-many-distinguishability. (cid:2)−2, O c2 , O bE1Hence, by Lemma 2, I L P context1, O cL O A S ) = I L P contextL O A S (T 3context5. For any tasks T 1contextL O A S∪ O c∪ O b2= (cid:3)B, (cid:3)E(cid:4)(cid:4). I L P L O A S (T 3+= (cid:3)B, (cid:3)E1 , E(cid:4)(cid:4). I L P context(cid:4)(cid:4) and T 2contextL O A S−2 , O bL O A S ).L O A S (T 1contextL O A S∪ O c22, O c2, O c1, O c+1 , EL O A S121111= (cid:3)B, (cid:3)E+1∪ E+2 , E−1∪ E−2(cid:4)(cid:4). I L P L A S (T 3L A S ) =L A S(cid:4)(cid:4), let T 3L O A S= (cid:3)B, (cid:3)E+1∪ E+2 , E−1∪(cid:4)(cid:4), let T 3context2L O A SL O A S ).= (cid:3)B, (cid:3)E+1∪ E+2 , E−1∪References[1] S. Muggleton, Inductive logic programming, New Gener. Comput. 8 (4) (1991) 295–318.[2] O. Ray, K. Broda, A. Russo, A hybrid abductive inductive proof procedure, Log. J. IGPL 12 (5) (2004) 371–397.[3] S. Muggleton, L. De Raedt, D. Poole, I. Bratko, P. Flach, K. Inoue, A. Srinivasan, ILP turns 20, Mach. Learn. 86 (1) (2012) 3–23.[4] S. Muggleton, D. Lin, Meta-interpretive learning of higher-order dyadic datalog: predicate invention revisited, in: Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence, AAAI Press, 2013, pp. 1551–1557.[5] A. Srinivasan, The Aleph Manual, Machine Learning at the Computing Laboratory, Oxford University, 2000.[6] H. Blockeel, L. De Raedt, Top-down induction of first-order logical decision trees, Artif. Intell. 101 (1) (1998) 285–297.[7] D. Corapi, A. Russo, E. Lupu, Inductive logic programming as abductive search, in: ICLP (Technical Communications), 2010, pp. 54–63.[8] C. Sakama, Nonmonotomic inductive logic programming, in: International Conference on Logic Programming and Nonmonotonic Reasoning, Springer, [9] M. Gelfond, V. Lifschitz, The stable model semantics for logic programming, in: ICLP/SLP, vol. 88, 1988, pp. 1070–1080.[10] S. Kolb, Learning constraints and optimization criteria, in: Proceedings of the First Workshop on Declarative Learning Based Programming, 2016.[11] C. Jordan, Ł. Kaiser, Machine learning with guarantees using descriptive complexity and smt solvers, preprint, arXiv:1609 .02664.[12] M. Sebag, C. Rouveirol, Constraint inductive logic programming.[13] T. Eiter, G. Ianni, T. Krennwallner, Answer set programming: a primer, in: Reasoning Web. Semantic Technologies for Information Systems, Springer, [14] E.T. Mueller, Commonsense Reasoning: An Event Calculus Based Approach, Morgan Kaufmann, 2014.[15] M. Gelfond, Y. Kahl, Knowledge Representation, Reasoning, and the Design of Intelligent Agents: The Answer-Set Programming Approach, Cambridge 2001, pp. 62–80.2009, pp. 40–110.University Press, 2014.[16] E. Erdem, M. Gelfond, N. Leone, Applications of answer set programming, AI Mag. 37 (3) (2016) 53–68.[17] M. Nogueira, M. Balduccini, M. Gelfond, R. Watson, M. Barry, An a-prolog decision support system for the space shuttle, in: International Symposium on Practical Aspects of Declarative Languages, Springer, 2001, pp. 169–183.[18] F. Ricca, A. Dimasi, G. Grasso, S.M. Ielpa, S. Iiritano, M. Manna, N. Leone, A logic-based system for e-tourism, Fundam. Inform. 105 (1–2) (2010) 35–55.[19] T. Soininen, I. Niemelä, Developing a declarative rule language for applications in product configuration, in: International Symposium on Practical Aspects of Declarative Languages, Springer, 1999, pp. 305–319.[20] R. Kowalski, M. Sergot, A logic-based calculus of events, New Gener. Comput. 4 (1) (1986) 67–95.146M. Law et al. / Artificial Intelligence 259 (2018) 110–146[21] N. Katzouris, A. Artikis, G. Paliouras, Incremental learning of event definitions with inductive logic programming, J. Mach. Learn. Res. 100 (2–3) (2015) 555–585.[22] D. Athakravi, Inductive Logic Programming Using Bounded Hypothesis Space, Ph.D. thesis, Imperial College London, 2015.[23] M. Law, A. Russo, K. Broda, Learning weak constraints in answer set programming, Theory Pract. Log. Program. 15 (4–5) (2015) 511–525.[24] M. Law, A. Russo, K. Broda, Iterative learning of answer set programs from context dependent examples, Theory Pract. Log. Program. 16 (5–6) (2016) 834–848.[25] L. De Raedt, A. Kimmig, H. Toivonen, Problog: a probabilistic prolog and its application in link discovery, in: IJCAI, vol. 7, 2007, pp. 2462–2467.[26] F. Riguzzi, E. Bellodi, R. Zese, A history of probabilistic inductive logic programming, Front. Robot. AI 1 (2014) 6.[27] M. Nickles, PrASP report, preprint, arXiv:1612 .09591.[28] C. Sakama, K. Inoue, Brave induction: a logical framework for learning from incomplete information, J. Mach. Learn. Res. 76 (1) (2009) 3–35.[29] M. Alviano, W. Faber, N. Leone, S. Perri, G. Pfeifer, G. Terracina, The disjunctive datalog system DLV, in: Datalog Reloaded, Springer, 2011, pp. 282–301.[30] R.P. Otero, Induction of stable models, in: Inductive Logic Programming, Springer, 2001, pp. 193–205.[31] M. Law, A. Russo, K. Broda, Inductive learning of answer set programs, in: Logics in Artificial Intelligence (JELIA 2014), Springer, 2014.[32] M. Law, A. Russo, K. Broda, The ILASP system for learning answer set programs, https://www.doc .ic .ac .uk /~ml1909 /ILASP, 2015.[33] M. Law, A. Russo, K. Broda, Simplified Reduct for Choice Rules in ASP, Tech. Rep. DTR2015-2, Imperial College of Science, Technology and Medicine, Department of Computing, 2015.[34] F. Calimeri, W. Faber, M. Gebser, G. Ianni, R. Kaminski, T. Krennwallner, N. Leone, F. Ricca, T. Schaub, ASP-Core-2 input language format, https://www.mat .unical .it /aspcomp2013 /files /ASP-CORE -2 .0 .pdf, 2013.[35] V. Lifschitz, H. Turner, Splitting a logic program, in: ICLP, vol. 94, 1994, pp. 23–37.[36] C.H. Papadimitriou, Computational Complexity, John Wiley and Sons Ltd., 2003.[37] L.J. Stockmeyer, The polynomial-time hierarchy, Theor. Comput. Sci. 3 (1) (1976) 1–22.[38] D. Corapi, A. Russo, E. Lupu, Inductive logic programming in answer set programming, in: Inductive Logic Programming, Springer, 2012, pp. 91–97.[39] O. Ray, Nonmonotonic abductive inductive learning, J. Appl. Log. 7 (3) (2009) 329–340.[40] S. Muggleton, Inverse entailment and progol, New Gener. Comput. 13 (3–4) (1995) 245–286.[41] M. Law, A. Russo, K. Broda, Inductive learning of answer set programs v2.6.0.[42] S. Bragaglia, O. Ray, Nonmonotonic learning in large biological networks, in: Inductive Logic Programming, Springer, 2015, pp. 33–48.[43] D. Athakravi, D. Corapi, K. Broda, A. Russo, Learning through hypothesis refinement using answer set programming, in: International Conference on Inductive Logic Programming, Springer, 2013, pp. 31–46.[44] W. Faber, G. Pfeifer, N. Leone, Semantics and complexity of recursive aggregates in answer set programming, Artif. Intell. 175 (1) (2011) 278–298.[45] L. De Raedt, Logical settings for concept-learning, Artif. Intell. 95 (1) (1997) 187–201.[46] C. Sakama, Induction from answer sets in nonmonotonic logic programs, ACM Trans. Comput. Log. 6 (2) (2005) 203–231.[47] K. Inoue, T. Ribeiro, C. Sakama, Learning from interpretation transition, J. Mach. Learn. Res. 94 (1) (2014) 51–79.[48] L. De Raedt, K. Kersting, Probabilistic inductive logic programming, in: International Conference on Algorithmic Learning Theory, Springer, 2004, pp. 19–36.[49] L. De Raedt, I. Thon, Probabilistic rule learning, in: International Conference on Inductive Logic Programming, Springer, 2010, pp. 47–58.[50] E. Bellodi, F. Riguzzi, Structure learning of probabilistic logic programs by searching the clause space, Theory Pract. Log. Program. 15 (02) (2015) 169–212.Artificial Intelligence, 2016.[51] F. Riguzzi, E. Bellodi, R. Zese, G. Cota, E. Lamma, Scaling structure learning of probabilistic logic programs by MapReduce, in: European Conference on [52] M. Nickles, A. Mileo, Probabilistic inductive logic programming based on answer set programming, preprint, arXiv:1405 .0720.[53] M. Nickles, A. Mileo, A system for probabilistic inductive answer set programming, in: International Conference on Scalable Uncertainty Management, Springer International Publishing, 2015, pp. 99–105.[54] S. Dragiev, A. Russo, K. Broda, M. Law PROBXHAIL, An abductive-inductive algorithm for probabilistic inductive logic programming.[55] T. Eiter, G. Gottlob, On the computational cost of disjunctive logic programming: propositional case, Ann. Math. Artif. Intell. 15 (3–4) (1995) 289–323.