Artificial Intelligence 262 (2018) 279–300Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintTogether we know how to achieve: An epistemic logic of know-howPavel Naumov a, Jia Tao b,∗a Claremont McKenna College, Claremont, CA, USAb Lafayette College, Easton, PA, USAa r t i c l e i n f oa b s t r a c tThe existence of a coalition strategy to achieve a goal does not necessarily mean that the coalition has enough information to know how to follow the strategy. Neither does it mean that the coalition knows that such a strategy exists. The article studies an interplay between the distributed knowledge, coalition strategies, and coalition “know-how” strategies. The main technical result is a sound and complete trimodal logical system that describes the properties of this interplay.© 2018 Elsevier B.V. All rights reserved.Article history:Received 26 May 2017Received in revised form 24 May 2018Accepted 12 June 2018Available online 21 June 2018Keywords:StrategyGame theoryKnowledgeFormal epistemologyLogicAxiomatizationCompletenessImperfect information1. IntroductionAn agent a comes to a fork in a road. There is a sign that says that one of the two roads leads to prosperity, another to death. The agent must take the fork, but she does not know which road leads where. Does the agent have a strategy to get to prosperity? On one hand, since one of the roads leads to prosperity, such a strategy clearly exists. We denote this fact by modal formula Sa p, where statement p is a claim of future prosperity. Furthermore, agent a knows that such a strategy exists. We write this as KaSa p. Yet, the agent does not know what the strategy is and, thus, does not know how to use the strategy. We denote this by ¬Ha p, where know-how modality Ha expresses the fact that agent a knows how to achieve the goal based on the information available to her. In this article we study the interplay between modality K, representing knowledge, modality S, representing the existence of a strategy, and modality H, representing the existence of a know-how strategy. Our main result is a complete trimodal axiomatic system capturing properties of this interplay.1.1. Epistemic transition systemsIn this article we use epistemic transition systems to capture knowledge and strategic behavior. Informally, epistemic transition system is a directed labeled graph supplemented by an indistinguishability relation on vertices. For instance, our motivational example above can be captured by epistemic transition system T 1 depicted in Fig. 1. In this system state w* Corresponding author.E-mail addresses: Pavel.Naumov@ClaremontMcKenna.edu (P. Naumov), taoj@lafayette.edu (J. Tao).https://doi.org/10.1016/j.artint.2018.06.0070004-3702/© 2018 Elsevier B.V. All rights reserved.280P. Naumov, J. Tao / Artificial Intelligence 262 (2018) 279–300Fig. 1. Epistemic transition system T 1.Fig. 2. Epistemic transition system T 2.Fig. 3. Epistemic transition system T 3.(cid:3)represents death. The original state is u, but it is indistinguishable by the agent arepresents the prosperity and state wfrom state v. Arrows on the diagram represent possible transitions between the states. Labels on the arrows represent the choices that the agents make during the transition. For example, if in state u agent chooses left (L) road, she will transition to the prosperity state w and if she chooses right (R) road, she will transition to the death state w. In another epistemic state v, these roads lead the other way around. States u and v are not distinguishable by agent a, which is shown by the dashed line between these two states. In state u as well as state v the agent has a strategy to transition to the state of prosperity: u (cid:2) Sa p and v (cid:2) Sa p. In the case of state u this strategy is L, in the case of state v the strategy is R. Since the agent cannot distinguish states u and v, in both of these states she does not have a know-how strategy to reach prosperity: u (cid:2) Ha p and v (cid:2) Ha p. At the same time, since formula Sa p is satisfied in all states indistinguishable to agent a from state u, we can claim that u (cid:2) KaSa p and, similarly, v (cid:2) KaSa p.As our second example, let us consider the epistemic transition system T 2 obtained from T 1 by swapping labels on transitions from v to w and from v to w, see Fig. 2. Although in system T 2 agent a still cannot distinguish states u and v, she has a know-how strategy from either of these states to reach state w. We write this as u (cid:2) Ha p and v (cid:2) Ha p. The strategy is to choose L. This strategy is know-how because it does not require to make different choices in the states that the agent cannot distinguish.(cid:3)(cid:3)1.2. Imperfect recallFor the next example, we consider a transition system T 3 obtained from system T 1 by adding a new epistemic state s. (See Fig. 3.) From state s, agent a can choose label L to reach state u or choose label R to reach state v. Since proposition q is satisfied in state u, agent a has a know-how strategy to transition from state s to a state (namely, state u) where q is satisfied. Therefore, s (cid:2) Haq.A more interesting question is whether s (cid:2) HaHa p is true. In other words, does agent a know how to transition from state s to a state in which she knows how to transition to another state in which p is satisfied? One might think that such a strategy indeed exists: in state s agent a chooses label L to transition to state u. Since there is no transition labeled by L that leads from state s to state v, upon ending the first transition the agent would know that she is in state u, where she needs to choose label L to transition to state w. This argument, however, is based on the assumption that agent a has a perfect recall. Namely, agent a in state u remembers the choice that she made in the previous state. We assume that the agents do not have a perfect recall and that an epistemic state description captures whatever memories the agent has in this state. In other words, in this article we assume that the only knowledge that an agent possesses is the knowledge captured by P. Naumov, J. Tao / Artificial Intelligence 262 (2018) 279–300281Fig. 4. Epistemic transition system T 4.Fig. 5. Epistemic transition system T 5.the indistinguishability relation on the epistemic states. Given this assumption, upon reaching the state u (indistinguishable from state v) agent a knows that there exists a choice that she can make to transition to state in which p is satisfied: s (cid:2) HaSa p. However, she does not know which choice (L or R) it is: s (cid:2) HaHa p.1.3. Multiagent settingSo far, we have assumed that only agent a has an influence on which transition the system takes. In transition system T 4depicted in Fig. 4, we introduce another agent b and assume both agents a and b have influence on the transitions. In each state, the system takes the transition labeled D by default unless there is a consensus of agents a and b to take the transition labeled C. In such a setting, each agent has a strategy to transition system from state u into state w by voting D, but neither of them alone has a strategy to transition from state u to state wbecause such a transition requires the consensus of both agents. Thus, u (cid:2) Sa p ∧ Sb p ∧ ¬Saq ∧ ¬Sbq. Additionally, both agents know how to transition the system from state u into state w, they just need to vote D. Therefore, u (cid:2) Ha p ∧ Hb p.In Fig. 5, we show a more complicated transition system obtained from T 1 by renaming label L to D and renaming label R to C. Same as in transition system T 4, we assume that there are two agents a and b voting on the system transition. We also assume that agent a cannot distinguish states u and v while agent b can. By default, the system takes the transition labeled D unless there is a consensus to take transition labeled C. As a result, agent a has a strategy (namely, vote D) in state u to transition system to state w, but because agent a cannot distinguish state u from state v, not only does she not know how to do this, but she is not aware that such a strategy exists: u (cid:2) Sa p ∧ ¬Ha p ∧ ¬KaSa p. Agent b, however, not only has a strategy to transition the system from state u to state w, but also knows how to achieve this: u (cid:2) Hb p.(cid:3)1.4. CoalitionsWe have talked about strategies, know-hows, and knowledge of individual agents. In this article we consider knowledge, strategies, and know-how strategies of coalitions. There are several forms of group knowledge that have been studied before. The two most popular of them are common knowledge and distributed knowledge [1]. Different contexts call for different forms of group knowledge.As illustrated in the famous Two Generals’ Problem [2,3] where communication channels between the agents are unreli-able, establishing a common knowledge between agents might be essential for having a strategy.In some settings, the distinction between common and distributed knowledge is insignificant. For example, if members of a political fraction get together to share all their information and to develop a common strategy, then the distributed knowledge of the members becomes the common knowledge of the fraction during the in-person meeting.Finally, in some other situations the distributed knowledge makes more sense than the common knowledge. For example, if a panel of experts is formed to develop a strategy, then this panel achieves the best result if it relies on the combined knowledge of its members rather than on their common knowledge.In this article we focus on distributed coalition knowledge and distributed-know-how strategies. We leave the common knowledge for the future research. Establishing distributed knowledge though communication between agents might affect what is known by individual agents [4], but the communication between agents is out of the scope of this paper.To illustrate how distributed knowledge of coalitions interacts with strategies and know-hows, consider epistemic tran-sition system T 6 depicted in Fig. 6. In this system, agents a and b cannot distinguish states u and v while agents b and ccannot distinguish states v and u. In every state, each of agents a, b and c votes either L or R, and the system transitions according to the majority vote. In such a setting, any coalition of two agents can fully control the transitions of the system.For example, by both voting L, agents a and b form a coalition {a, b} that forces the system to transition from state u to state w no matter how agent c votes. Since proposition p is satisfied in state w, we write u (cid:2) S{a,b} p, or simply u (cid:2) Sa,b p. Similarly, coalition {a, b} can vote R to force the system to transition from state v to state w. Therefore, coalition {a, b}(cid:3)282P. Naumov, J. Tao / Artificial Intelligence 262 (2018) 279–300Fig. 6. Epistemic transition system T 6.Fig. 7. Epistemic transition system T 7.has strategies to achieve p in states u and v, but the strategies are different. Since they cannot distinguish states u and v, agents a and b know that they have a strategy to achieve p, but they do not know how to achieve p. In our notations, v (cid:2) Sa,b p ∧ Ka,bSa,b p ∧ ¬Ha,b p.On the other hand, although agents b and c cannot distinguish states v and u, by both voting R in either of states v and , they form a coalition {b, c} that forces the system to transition to state w where p is satisfied. Therefore, in any of states , they not only have a strategy to achieve p, but also know that they have such a strategy, and more importantly, uv and uthey know how to achieve p, that is, v (cid:2) Hb,c p.(cid:3)(cid:3)(cid:3)1.5. Nondeterministic transitionsIn all the examples that we have discussed so far, given any state in a system, agents’ votes uniquely determine the transition of the system. Our framework also allows nondeterministic transitions. Consider transition system T 7 depicted in Fig. 7. In this system, there are two agents a and b who can vote either C or D. If both agents vote C, then the system takes one of the consensus transitions labeled with C. Otherwise, the system takes the transition labeled with D. Note that there are two consensus transitions starting from state u. Therefore, even if both agents vote C, they do not have a strategy to achieve p, i.e., u (cid:2) Sa,b p. However, they can achieve p ∨ q. Moreover, since all agents can distinguish all states, we have u (cid:2) Ha,b(p ∨ q).1.6. Universal principlesIn the examples above we focused on specific properties that were either satisfied or not satisfied in particular states of epistemic transition systems T 1 through T 7. In this article, we study properties that are satisfied in all states of all epistemic transition systems. Our main result is a sound and complete axiomatization of all such properties. We finish the introduction with an informal discussion of these properties.Properties of single modalities Knowledge modality KC satisfies the axioms of epistemic logic S5 with distributed knowledge. Both strategic modality SC and know-how modality HC satisfy cooperation properties [5,6]:SC (ϕ → ψ) → (SDϕ → SC∪D ψ), where C ∩ D = ∅,HC (ϕ → ψ) → (HDϕ → HC∪D ψ), where C ∩ D = ∅.They also satisfy monotonicity propertiesSC ϕ → SDϕ, where C ⊆ D,HC ϕ → HDϕ, where C ⊆ D.(1)(2)The two monotonicity properties are not among the axioms of our logical system because, as we show in Lemma 5 and Lemma 3, they are derivable.Properties of interplay Note that w (cid:2) HC ϕ means that coalition C has the same strategy to achieve ϕ in all epistemic states indistinguishable by the coalition from state w. Hence, the following principle is universally true:HC ϕ → KC HC ϕ.(3)P. Naumov, J. Tao / Artificial Intelligence 262 (2018) 279–300283Fig. 8. Epistemic transition system T 8.Similarly, w (cid:2) ¬HC ϕ means that coalition C does not have the same strategy to achieve ϕ in all epistemic states indistin-guishable by the coalition from state w. Thus,¬HC ϕ → KC ¬HC ϕ.(4)We call properties (3) and (4) strategic positive introspection and strategic negative introspection, respectively. The strategic negative introspection is one of our axioms. Just as how the positive introspection principle follows from the rest of the axioms in S5 (see Lemma 14), the strategic positive introspection principle is also derivable (see Lemma 1).Whenever a coalition knows how to achieve something, there should exist a strategy for the coalition to achieve. In our notation,HC ϕ → SC ϕ.(5)We call this formula strategic truth property and it is one of the axioms of our logical system.The last two axioms of our logical system deal with empty coalitions. First of all, if formula K∅ϕ is satisfied in an epistemic state of our transition system, then formula ϕ must be satisfied in every state of this system. Thus, even empty coalition has a trivial strategy to achieve ϕ:K∅ϕ → H∅ϕ.(6)We call this property empty coalition principle. In this article we assume that an epistemic transition system never halts. That is, in every state of the system no matter what the outcome of the vote is, there is always a next state for this vote. This restriction on the transition systems yields property¬SC ⊥that we call nontermination principle.(7)Let us now turn to the most interesting and perhaps most unexpected property of interplay. Note that S∅ϕ means that an empty coalition has a strategy to achieve ϕ. Since the empty coalition has no members, nobody has to vote in a particular way. Statement ϕ is guaranteed to happen anyway. Thus, statement S∅ϕ simply means that statement ϕ is unavoidably satisfied after any single transition.For example, consider an epistemic transition system depicted in Fig. 8. As in some of our earlier examples, this system has agents a and b who vote either C or D. If both agents vote C, then the system takes one of the consensus transitions labeled with C. Otherwise, the system takes the default transition labeled with D. Note that in state v it is guaranteed that statement p will happen after a single transition. Thus, v (cid:2) S∅ p. At the same time, neither agent a nor agent b knows about this because they cannot distinguish state v from states u and urespectively. Thus, v (cid:2) ¬KaS∅ p ∧ ¬KbS∅ p.In the same transition system T 8, agents a and b together can distinguish state v from states u and u. Thus, v (cid:2) Ka,bS∅ p. In general, statement KC S∅ϕ means that not only ϕ is unavoidable, but coalition C knows about it. Thus, coalition C has a know-how strategy to achieve ϕ:(cid:3)(cid:3)KC S∅ϕ → HC ϕ.In fact, the coalition would achieve the result no matter which strategy it uses. Coalition C can even use a strategy that simultaneously achieves another result in addition to ϕ:KC S∅ϕ ∧ HC ψ → HC (ϕ ∧ ψ).In our logical system we use an equivalent form of the above principle that is stated using only implication:HC (ϕ → ψ) → (KC S∅ϕ → HC ψ).(8)We call this property epistemic determinicity principle. Properties (1), (2), (4), (5), (6), (7), and (8), together with axioms of epistemic logic S5 with distributed knowledge and propositional tautologies constitute the axioms of our sound and complete logical system.284P. Naumov, J. Tao / Artificial Intelligence 262 (2018) 279–3001.7. Literature reviewLogics of coalition power were developed by Marc Pauly [5,6], who also proved the completeness of the basic logic of coalition power. Pauly’s approach has been widely studied in the literature [7–13]. An alternative logical system was proposed by More and Naumov [14].Alur, Henzinger, and Kupferman introduced Alternating-Time Temporal Logic (ATL) that combines temporal and coalition modalities [15]. Van der Hoek and Wooldridge proposed to combine ATL with epistemic modality to form Alternating-Time Temporal Epistemic Logic [16]. Goranko and van Drimmelen [17] gave a complete axiomatization of ATL. Decidability and model checking problems for ATL-like systems has also been widely studied [18–20].Ågotnes and Alechina proposed a complete logical system that combines the coalition power and epistemic modali-ties [21]. Since this system does not have epistemic requirements on strategies, it does not contain any axioms describing the interplay of these modalities. In the extended version of this work they added a complete axiomatization of an interplay between knowledge and know-how modalities [22].Know-how strategies were studied before under different names. While Jamroga and Ågotnes talked about “knowledge to identify and execute a strategy” [23], Jamroga and van der Hoek discussed “difference between an agent knowing that he has a suitable strategy and knowing the strategy itself” [24]. Van Benthem called such strategies “uniform” [25]. Wang gave a complete axiomatization of “knowing how” as a binary modality [26,27], but his logical system does not include the knowledge modality.In [28], we investigated coalition strategies to enforce a condition indefinitely. Such strategies are similar to “goal main-tenance” strategies in Pauly’s “extended coalition logic” [5, p. 80]. We focused on “executable” and “verifiable” strategies. Using the language of the current article, executability means that a coalition remains “in the know-how” throughout the execution of the strategy. Verifiability means that the coalition can verify that the enforced condition remains true. In the notations of the current article, the existence of a verifiable strategy could be expressed as SC KC ϕ. In [28], we provided a complete logical system that describes the interplay between the modality representing the existence of an “executable” and “verifiable” coalition strategy to enforce and the modality representing knowledge. This system can prove principles similar to the strategic positive introspection (3) and the strategic negative introspection (4) mentioned above. A similar complete logical system in a single-agent setting for strategies to achieve a goal in multiple steps rather than to maintain a goal is developed by Fervari, Herzig, Li, and Wang [29]. In a more recent work, we described the interplay between modalities K and H in the perfect recall setting in [30]. Properties of second-order know-how, when a coalition knows how another coalition can do it, are discussed in [31].In the current article, we combine know-how modality H with strategic modality S and epistemic modality K. In other words, we combine two separate logical systems given in [22]: one for knowledge and coalition power modalities and the other for knowledge and know-how modalities, into a single logical system. While doing this, we generalize the setting from the individual knowledge to the distributive knowledge and discover a new axiom, epistemic determinicity principle, not present in [22]. The proof of the completeness theorem in the current article is significantly more challenging than those in [22,28,29]. It employs new techniques that construct pairs of maximal consistent sets in “harmony” and in “complete harmony”. See Section 6.3 and Section 6.4 for details. An extended abstract of this article, without proofs, appeared as [32].1.8. OutlineThis article is organized as follows. In Section 2 we introduce formal syntax and semantics of our logical system. In Section 3 we list axioms and inference rules of the system. Section 4 provides examples of formal proofs in our logical systems. Proofs of the soundness and the completeness are given in Section 5 and Section 6 respectively. Section 7 concludes the article.The key part of the proof of the completeness is the construction of a pair of sets in complete harmony. We discuss the intuition behind this construction and introduce the notion of harmony in Section 6.3. The notion of complete harmony is introduced in Section 6.4.2. Syntax and semanticsIn this section we present the formal syntax and semantics of our logical system given a fixed finite set of agents A. Epistemic transition system could be thought of as a Kripke model of modal logic S5 with distributed knowledge to which we add transitions controlled by a vote aggregation mechanism. Examples of vote aggregation mechanisms that we have considered in the introduction are the consensus/default mechanism and the majority vote mechanism. Unlike the introduc-tory examples, in the general definition below we assume that at different states the mechanism might use different rules for vote aggregation. The only restriction on the mechanism that we introduce is that there should be at least one possible transition that the system can take no matter what the votes are. In other words, we assume that the system can never halt.For any set of votes V , by Vwe mean the set of all functions from set A to set V . Alternatively, the set VAAcould be thought of as a set of tuples of elements of V indexed by elements of A.Definition 1. A tuple (W , {∼a}a∈A, V , M, π ) is called an epistemic transition system, whereP. Naumov, J. Tao / Artificial Intelligence 262 (2018) 279–3002851. W is a set of epistemic states,2. ∼a is an indistinguishability equivalence relation on W for each a ∈ A,3. V is a nonempty set called “domain of choices”,4. M ⊆ W × V(w, s, w(cid:3)) ∈ M,A × W is an aggregation mechanism where for each w ∈ W and each s ∈ VA, there is w(cid:3) ∈ W such that 5. π is a function that maps propositional variables into subsets of W .Epistemic transition systems are very similar to concurrent game structures, the semantics of ATL [15], with two notable differences. First, in concurrent game structures, the domain of choices depends on the state and on the agent. On the other hand, we assume a uniform domain of choices for all states and all agents. This difference is insignificant because all domains of choices in a concurrent game structure could be replaced with their union if the aggregation mechanism is modified to interpret the additional choices as alternative names for the original choices. Second, unlike the transition function in the concurrent game structures, our aggregation mechanism allows to capture nondeterministic transitions. This difference is significant because restricting semantics to only deterministic transitions would require additional axioms. For example, property SAϕ ∨ SA¬ϕ, where A is the coalition of all agents, is universally true in deterministic epistemic transition systems, but is not true in some nondeterministic systems.Definition 2. A coalition is a subset of A.Note that a coalition is always finite due to our assumption that the set of all agents A is finite. Informally, we say that two epistemic states are indistinguishable by a coalition C if they are indistinguishable by every member of the coalition. Formally, coalition indistinguishability is defined as follows:Definition 3. For any epistemic states w 1, w 2 ∈ W and any coalition C , let w 1 ∼C w 2 if w 1 ∼a w 2 for each agent a ∈ C .Corollary 1. Relation ∼C is an equivalence relation on the set of states W for each coalition C .By a strategy profile {sa}a∈C of a coalition C we mean a tuple that specifies vote sa ∈ V of each member a ∈ C . Since such a tuple can also be viewed as a function from set C to set V , we denote the set of all strategy profiles of a coalition Cby V C :Definition 4. Any tuple {sa}a∈C ∈ V C is called a strategy profile of coalition C .In addition to a fixed finite set of agents A we also assume a fixed countable set of propositional variables. We use the assumption that this set is countable in the proof of Lemma 21. The language (cid:5) of our formal logical system is specified in the next definition.Definition 5. Let (cid:5) be the minimal set of formulae such that1. p ∈ (cid:5) for each propositional variable p,2. ¬ϕ, ϕ → ψ ∈ (cid:5) for all formulae ϕ, ψ ∈ (cid:5),3. KC ϕ, SC ϕ, HC ϕ ∈ (cid:5) for each coalition C and each ϕ ∈ (cid:5).In other words, language (cid:5) is defined by the following grammar:ϕ := p | ¬ϕ | ϕ → ϕ | KC ϕ | SC ϕ | HC ϕ.By ⊥ we denote the negation of a tautology. For example, we can assume that ⊥ is ¬(p → p) for some fixed proposi-tional variable p.According to Definition 1, a mechanism specifies the transition that a system might take for any strategy profile of the set of all agents A. It is sometimes convenient to consider transitions that are consistent with a given strategy profile s of a given coalition C ⊆ A. We write w →s u if a transition from state w to state u is consistent with strategy profile s. The formal definition is below.Definition 6. For any epistemic states w, u ∈ W , any coalition C , and any strategy profile s = {sa}a∈C ∈ V C , we write w →s uif (w, s(cid:3), u) ∈ M for some strategy profile s= sa for each a ∈ C .such that s}a∈A ∈ V(cid:3) = {sA(cid:3)a(cid:3)a286P. Naumov, J. Tao / Artificial Intelligence 262 (2018) 279–300Corollary 2. Let s be the unique strategy profile of the empty coalition ∅, if there are a coalition C and a strategy profile sC such that w →s(cid:3) u, then w →s u.(cid:3)of coalition The next definition is the key definition of this article. It formally specifies the meaning of the three modalities in our logical system.Definition 7. For any epistemic state w ∈ W of a transition system (W , {∼a}a∈A, V , M, π ) and any formula ϕ ∈ (cid:5), let relation w (cid:2) ϕ be defined as follows1. w (cid:2) p if w ∈ π (p) where p is a propositional variable,2. w (cid:2) ¬ϕ if w (cid:2) ϕ,3. w (cid:2) ϕ → ψ if w (cid:2) ϕ or w (cid:2) ψ ,(cid:3) (cid:2) ϕ for each w4. w (cid:2) KC ϕ if w5. w (cid:2) SC ϕ if there is a strategy profile s ∈ V C such that w →s w(cid:3)6. w (cid:2) HC ϕ if there is a strategy profile s ∈ V C such that w ∼C w(cid:3) ∈ W such that w ∼C w,(cid:3)(cid:3)implies wand w(cid:3) →s w(cid:3) (cid:2) ϕ for every wimply w(cid:3) ∈ W ,(cid:3)(cid:3) (cid:2) ϕ for all w(cid:3)(cid:3)(cid:3), w(cid:3)(cid:3) ∈ W .Note that item 6 of this definition is requiring the strategy s to work in all states w. That is, the strategy s should work in all states indistinguishable from the current state w by the whole coalition. Informally, it means that we require the whole coalition C to know distributively that strategy s will succeed. Alternatively, one might require this to be known to each individual member of this coalition C . In the latter case, item 6 of Definition 7 would be stated assuch that w ∼C w(cid:3)(cid:3)(cid:3)6.w (cid:2) HC ϕ when there is a strategy profile s ∈ V C such that for each a ∈ C , each wand w, then w(cid:3)(cid:3) (cid:2) ϕ.(cid:3) →s w(cid:3)(cid:3)(cid:3) ∈ W and each w(cid:3)(cid:3) ∈ W , if w ∼a w(cid:3)This alternative, individual knowledge-based, definition of coalition know-how is used in logic ATL[33]. Yet another al-ternative [28,29] is to require that after execution of know-how strategy to achieve ϕ the coalition would know that ϕ is indeed true:∗(cid:3)(cid:3)6.w (cid:2) HC ϕ if there is a strategy profile s ∈ V C such that w ∼C ww(cid:3)(cid:3)(cid:3) ∈ W .(cid:3)(cid:3), w(cid:3), w(cid:3), w(cid:3) →s w(cid:3)(cid:3), and w(cid:3)(cid:3) ∼C w(cid:3)(cid:3)(cid:3)imply w(cid:3)(cid:3)(cid:3) (cid:2) ϕ for all This definition yields axiom HC ϕ → HC KC ϕ, which is present in [28,29]. In our current setting, this axiom is not valid. However, it would be valid under the assumption of perfect recall by nonempty coalitions [30].3. AxiomsIn additional to propositional tautologies in language (cid:5), our logical system consists of the following axioms.1. Truth: KC ϕ → ϕ,2. Negative Introspection: ¬KC ϕ → KC ¬KC ϕ,3. Distributivity: KC (ϕ → ψ) → (KC ϕ → KC ψ),4. Monotonicity: KC ϕ → KDϕ, if C ⊆ D,5. Cooperation: SC (ϕ → ψ) → (SDϕ → SC∪D ψ), where C ∩ D = ∅.6. Strategic Negative Introspection: ¬HC ϕ → KC ¬HC ϕ,7. Epistemic Cooperation: HC (ϕ → ψ) → (HDϕ → HC∪D ψ), where C ∩ D = ∅,8. Strategic Truth: HC ϕ → SC ϕ,9. Epistemic Determinicity: HC (ϕ → ψ) → (KC S∅ϕ → HC ψ),10. Empty Coalition: K∅ϕ → H∅ϕ,11. Nontermination: ¬SC ⊥.We have discussed the informal meaning of these axioms in the introduction. In Section 5 we formally prove the soundness of these axioms with respect to the semantics from Definition 7.We write (cid:13) ϕ if formula ϕ is provable from the axioms of our logical system using Necessitation, Strategic Necessitation, and Modus Ponens inference rules:ϕKC ϕϕHC ϕϕ,ϕ → ψψ.We write X (cid:13) ϕ if formula ϕ is provable from the theorems of our logical system and a set of additional axioms X using only Modus Ponens inference rule.P. Naumov, J. Tao / Artificial Intelligence 262 (2018) 279–3002874. Derivation examplesIn this section we give examples of formal derivations in our logical system. In Lemma 1 we prove the strategic pos-itive introspection principle (3) discussed in the introduction. The proof is similar to the proof of the epistemic positive introspection principle in Lemma 14.Lemma 1. (cid:13) HC ϕ → KC HC ϕ.Proof. Note that formula ¬HC ϕ → KC ¬HC ϕ is an instance of Strategic Negative Introspection axiom. Thus, (cid:13) ¬KC ¬HC ϕ →HC ϕ by the law of contrapositive in the propositional logic. Hence, (cid:13) KC (¬KC ¬HC ϕ → HC ϕ) by Necessitation inference rule. Thus, by Distributivity axiom and Modus Ponens inference rule,(cid:13) KC ¬KC ¬HC ϕ → KC HC ϕ.(9)At the same time, KC ¬HC ϕ → ¬HC ϕ is an instance of Truth axiom. Thus, (cid:13) HC ϕ → ¬KC ¬HC ϕ by contraposition. Hence, taking into account the following instance of Negative Introspection axiom ¬KC ¬HC ϕ → KC ¬KC ¬HC ϕ, one can conclude that (cid:13) HC ϕ → KC ¬KC ¬HC ϕ. The latter, together with statement (9), implies the statement of the lemma by the laws of propositional reasoning. (cid:2)In the next example, we show that the existence of a know-how strategy by a coalition implies that the coalition has a distributed knowledge of the existence of a strategy.Lemma 2. (cid:13) HC ϕ → KC SC ϕ.Proof. By Strategic Truth axiom, (cid:13) HC ϕ → SC ϕ. Hence, (cid:13) KC (HC ϕ → SC ϕ) by Necessitation inference rule. Thus, (cid:13)KC HC ϕ → KC SC ϕ by Distributivity axiom and Modus Ponens inference rule. At the same time, (cid:13) HC ϕ → KC HC ϕ by Lemma 1. Therefore, (cid:13) HC ϕ → KC SC ϕ by the laws of propositional reasoning. (cid:2)The next lemma shows that the existence of a know-how strategy by a sub-coalition implies the existence of a know-how strategy by the entire coalition.Lemma 3. (cid:13) HC ϕ → HDϕ, where C ⊆ D.Proof. Note that ϕ → ϕ is a propositional tautology. Thus, (cid:13) ϕ → ϕ. Hence, (cid:13) HD\C (ϕ → ϕ) by Strategic Necessitation inference rule. At the same time, by Epistemic Cooperation axiom, (cid:13) HD\C (ϕ → ϕ) → (HC ϕ → HDϕ) due to the assumption C ⊆ D. Therefore, (cid:13) HC ϕ → HDϕ by Modus Ponens inference rule. (cid:2)Although our logical system has three modalities, the system contains necessitation inference rules only for two of them. The lemma below shows that the necessitation rule for the third modality is derivable.Lemma 4. For each finite C ⊆ A, inference rule ϕSC ϕis derivable in our logical system.Proof. Assumption (cid:13) ϕ implies (cid:13) HC ϕ by Strategic Necessitation inference rule. Hence, (cid:13) SC ϕ by Strategic Truth axiom and Modus Ponens inference rule. (cid:2)The next result is a counterpart of Lemma 3. It states that the existence of a strategy by a sub-coalition implies the existence of a strategy by the entire coalition.Lemma 5. (cid:13) SC ϕ → SDϕ, where C ⊆ D.Proof. Note that ϕ → ϕ is a propositional tautology. Thus, (cid:13) ϕ → ϕ. Hence, (cid:13) SD\C (ϕ → ϕ) by Lemma 4. At the same time, by Cooperation axiom, (cid:13) SD\C (ϕ → ϕ) → (SC ϕ → SDϕ) due to the assumption C ⊆ D. Therefore, (cid:13) SC ϕ → SDϕ by Modus Ponens inference rule. (cid:2)5. SoundnessIn this section we prove the soundness of our logical system. The proof of the soundness of multiagent S5 axioms and inference rules is standard. Below we show the soundness of each of the remaining axioms and the Strategic Necessitation inference rule as a separate lemma. The soundness theorem for the whole logical system is stated at the end of this section as Theorem 1.288P. Naumov, J. Tao / Artificial Intelligence 262 (2018) 279–300Lemma 6. If w (cid:2) SC (ϕ → ψ), w (cid:2) SDϕ, and C ∩ D = ∅, then w (cid:2) SC∪D ψ .Proof. Suppose that w (cid:2) SC (ϕ → ψ). Then, by Definition 7, there is a strategy profile s1 = {s1aϕ → ψ for each w(cid:3) (cid:2) ϕ for each wsuch that w(cid:2)s1 w(cid:3) ∈ W where w →. Similarly, assumption w (cid:2) SDϕ implies that there is a strategy s2 = {s2a. Let strategy profile s = {sa}a∈C∪D be defined as follows:(cid:3) ∈ W where w →s2 w(cid:3)(cid:3)}a∈C ∈ V C such that w(cid:3) (cid:2)}a∈D ∈ V Dsa =s1a ,s2a ,if a ∈ C,if a ∈ D.Strategy profile s is well-defined due to the assumption C ∩ D = ∅ of the lemma.Consider any epistemic state wassumption w →s wof strategies s1 and s2. Therefore, w(cid:3)(cid:3) ∈ W such that w →s w(cid:3)s1 w(cid:3) (cid:2) ψ by Definition 7. (cid:2), by Definition 6, implies that w →(cid:3). By Definition 7, it suffices to show that wand w →(cid:3) (cid:2) ϕ → ψ and w(cid:3) (cid:2) ψ . Indeed, (cid:3) (cid:2) ϕ by the choice . Thus, w(cid:3)s2 wLemma 7. If w (cid:2) ¬HC ϕ, then w (cid:2) KC ¬HC ϕ.Proof. Consider any epistemic state u ∈ W such that w ∼C u. By Definition 7, it suffices to show that u (cid:2) HC ϕ. Assume (cid:3)(cid:3) ∈ Wthe opposite. Thus, u (cid:2) HC ϕ. Then, again by Definition 7, there is a strategy profile s ∈ V C where u(cid:3)such that u ∼C uand (cid:3)(cid:3)(cid:3) →s uu. Therefore, w (cid:2) HC ϕ, by Definition 7. The latter contradicts the assumption of the lemma. (cid:2)(cid:3), u(cid:3)(cid:3) (cid:2) ϕ for all u(cid:3)(cid:3) ∈ W such that w ∼C u. Recall that w ∼C u. Thus, by Corollary 1, u(cid:3)(cid:3) (cid:2) ϕ for all u(cid:3) →s uand u(cid:3), u(cid:3)(cid:3)(cid:3)Lemma 8. If w (cid:2) HC (ϕ → ψ), w (cid:2) HDϕ, and C ∩ D = ∅, then w (cid:2) HC∪D ψ .(cid:3)(cid:3) (cid:2) ϕ → ψ for all epistemic states w}a∈C ∈ V C such that Proof. Suppose that w (cid:2) HC (ϕ → ψ). Thus, by Definition 7, there is a strategy profile s1 = {s1a. Similarly, assumption w (cid:2) HDϕ implies that wthere is a strategy s2 = {s2. Let strategy profile s2 was = {sa}a∈C∪D be defined as follows:(cid:3)(cid:3)s1 wwhere w ∼D w}a∈D ∈ V D such that w(cid:3)(cid:3) (cid:2) ϕ for all wwhere w ∼C wand w(cid:3), w(cid:3) →(cid:3)(cid:3)and w(cid:3), w(cid:3) →(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:2)sa =s1a ,s2a ,if a ∈ C,if a ∈ D.Strategy profile s is well-defined due to the assumption C ∩ D = ∅ of the lemma.Consider any epistemic states w(cid:3), w(cid:3)(cid:3) ∈ W such that w ∼C∪D w(cid:3)(cid:3) (cid:2) ψ . Indeed, by Definition 3 assumption w ∼C∪D w(cid:3)(cid:3)that wDefinition 6, assumption wof strategies s1 and s2. Therefore, w(cid:3) →s wimplies that w(cid:3)(cid:3) (cid:2) ψ by Definition 7. (cid:2)s1 w(cid:3) →(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3) →s wand wimplies that w ∼C w. Thus, ws2 w(cid:3) →(cid:3)(cid:3)(cid:3)and w. By Definition 7, it suffices to show and w ∼D w. At the same time, by (cid:3)(cid:3) (cid:2) ϕ by the choice (cid:3)(cid:3) (cid:2) ϕ → ψ and w(cid:3)Lemma 9. If w (cid:2) HC ϕ, then w (cid:2) SC ϕ.Proof. Suppose that w (cid:2) HC ϕ. Thus, by Definition 7, there is a strategy profile s ∈ V C such that w(cid:3)(cid:3)states wwhere w →s w. Therefore, w (cid:2) SC ϕ by Definition 7. (cid:2). By Corollary 1, w ∼C w. Hence, w(cid:3)(cid:3) ∈ W , where w ∼C w(cid:3) →s wand w(cid:3), w(cid:3)(cid:3)(cid:3)(cid:3)(cid:3) (cid:2) ϕ for each epistemic state w(cid:3)(cid:3) (cid:2) ϕ for all epistemic (cid:3)(cid:3) ∈ W , Lemma 10. If w (cid:2) HC (ϕ → ψ) and w (cid:2) KC S∅ϕ, then w (cid:2) HC ψ .Proof. Suppose that w (cid:2) HC (ϕ → ψ). Thus, by Definition 7, there is a strategy profile s ∈ V C such that wepistemic states wand w(cid:3)(cid:3) ∈ W where w ∼C w(cid:3), wConsider any epistemic states w(cid:2) ψ .Indeed, by Definition 7, the assumption w (cid:2) KC S∅ϕ together with w ∼C w∈ W such that w ∼C w(cid:3)0 and w(cid:3) →s w(cid:3)0, w→s ww(cid:3)(cid:3)0(cid:3)(cid:3)0(cid:3)0(cid:3)(cid:3).(cid:3)tion 7, there is a strategy profile sto Corollary 2 and wFinally, by Definition 7, statements wof empty coalition ∅ such that w(cid:3)(cid:3) (cid:2) ϕ for each w(cid:3)(cid:3)(cid:3)(cid:3)0. By the choice of strategy profile s, statements w ∼C w(cid:3)(cid:3)(cid:2) ψ . (cid:2)0(cid:2) ϕ imply that w(cid:2) ϕ → ψ and w→s w(cid:3)(cid:3)0(cid:3)(cid:3)0(cid:3)0(cid:3)(cid:3)(cid:3)0. By Definition 7, it suffices to show that (cid:3)(cid:3)(cid:2) S∅ϕ. Hence, by Defini-0 imply that w0(cid:3)(cid:3)(cid:3)(cid:2) ϕ due →s(cid:3) w. Thus, wwhere w00(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:2) ϕ → ψ . →s w0 imply w0 and w00(cid:3)(cid:3)(cid:3)(cid:3) (cid:2) ϕ → ψ for all Lemma 11. If w (cid:2) K∅ϕ, then w (cid:2) H∅ϕ.Proof. Let s = {sa}a∈∅ be the empty strategy profile. Consider any epistemic states wwtion w (cid:2) K∅ϕ and Definition 7. (cid:2). By Definition 7, it suffices to show that w(cid:3)(cid:3) (cid:2) ϕ. Indeed w ∼∅ w(cid:3) →s w(cid:3)(cid:3)(cid:3)(cid:3)by Definition 3. Therefore, w(cid:3), w(cid:3)(cid:3) ∈ W such that w ∼∅ w(cid:3)and (cid:3)(cid:3) (cid:2) ϕ by assump-Lemma 12. w (cid:2) SC ⊥.P. Naumov, J. Tao / Artificial Intelligence 262 (2018) 279–300289Proof. Suppose that w (cid:2) SC ⊥. Thus, by Definition 7, there is a strategy profile s = {sa}a∈A ∈ V C such that u (cid:2) ⊥ for each u ∈ W where w →s u.Note that by Definition 1, the domain of choices V is not empty. Thus, strategy profile s can be extended to a strategy profile s(cid:3) = {s(cid:3)a}a∈A ∈ VAsuch that s= sa for each a ∈ C .(cid:3)aBy Definition 1, there must exist a state w(cid:3) (cid:2) ⊥ by the choice of strategy s, which contradicts Definition 7. (cid:2)(cid:3) ∈ W such that (w, s(cid:3), ww(cid:3)) ∈ M. Hence, w →s w(cid:3)by Definition 6. Therefore, Lemma 13. If w (cid:2) ϕ for any epistemic state w ∈ W of an epistemic transition system (W , {∼a}a∈A, V , M, π ), then w (cid:2) SC ϕ for every epistemic state w ∈ W .Proof. By Definition 1, set V is not empty. Let v ∈ V . Consider strategy profile s = {sa}a∈C of coalition C such that sa = v for (cid:3) ∈ W due to the assumption of the lemma. Therefore, w (cid:2) SC ϕ by Definition 7. (cid:2)each s ∈ C . Note that w(cid:3) (cid:2) ϕ for each wTaken together, the lemmas above imply the soundness theorem for our logical system stated below.Theorem 1. If (cid:13) ϕ, then w (cid:2) ϕ for each epistemic state w ∈ W of each epistemic transition system (W , {∼a}a∈A, V , M, π ). (cid:2)6. CompletenessThis section is dedicated to the proof of the following completeness theorem for our logical system.Theorem 2 (completeness). If w (cid:2) ϕ for each epistemic state w of each epistemic transition system, then (cid:13) ϕ.6.1. Positive introspectionThe proof of Theorem 2 is divided into several parts. In this section we prove the positive introspection principle for distributed knowledge modality from the rest of modality K axioms in our logical system. This is a well-known result that we reproduce to keep the presentation self-sufficient. The positive introspection principle is used later in the proof of the completeness.Lemma 14. (cid:13) KC ϕ → KC KC ϕ.Proof. Formula ¬KC ϕ → KC ¬KC ϕ is an instance of Negative Introspection axiom. Thus, (cid:13) ¬KC ¬KC ϕ → KC ϕ by the law of contrapositive in the propositional logic. Hence, (cid:13) KC (¬KC ¬KC ϕ → KC ϕ) by Necessitation inference rule. Thus, by Distribu-tivity axiom and Modus Ponens inference rule,(cid:13) KC ¬KC ¬KC ϕ → KC KC ϕ.(10)At the same time, KC ¬KC ϕ → ¬KC ϕ is an instance of Truth axiom. Thus, (cid:13) KC ϕ → ¬KC ¬KC ϕ by contraposition. Hence, taking into account the following instance of Negative Introspection axiom ¬KC ¬KC ϕ → KC ¬KC ¬KC ϕ, one can conclude that (cid:13) KC ϕ → KC ¬KC ¬KC ϕ. The latter, together with statement (10), implies the statement of the lemma by the laws of propositional reasoning. (cid:2)6.2. Consistent sets of formulaeAs usual, we call a set X ⊆ (cid:5) consistent if X (cid:4) ⊥. We refer to set X as maximal consistent if it is maximal among consistent subsets of (cid:5). The proof of the completeness consists in constructing a canonical model in which states are maximal consistent sets. This is a standard technique in modal logic that we modified significantly to work in the setting of our logical system. The standard way to apply this technique to a modal operator (cid:2) is to create a “child” state wsuch that ¬ψ ∈ wfor each “parent” state w where ¬(cid:2)ψ ∈ w. In the simplest case when (cid:2) is a distributed knowledge modality KC , the standard technique requires no modification and the construction of a “child” state is based on the following lemma:(cid:3)(cid:3)Lemma 15. For any consistent set of formulae X , any formula ¬KC ψ ∈ X , and any formulae KC ϕ1, . . . , KC ϕn ∈ X , the set of formulae {¬ψ, ϕ1, . . . , ϕn} is consistent.Proof. Assume the opposite. Then, ϕ1, . . . , ϕn (cid:13) ψ . Thus, by the deduction theorem for propositional logic applied n times,(cid:13) ϕ1 → (ϕ2 → . . . (ϕn → ψ) . . . ).290P. Naumov, J. Tao / Artificial Intelligence 262 (2018) 279–300Hence, by Necessitation inference rule,(cid:13) KC (ϕ1 → (ϕ2 → . . . (ϕn → ψ) . . . )).By Distributivity axiom and Modus Ponens inference rule,KC ϕ1 (cid:13) KC (ϕ2 → . . . (ϕn → ψ) . . . ).By repeating the last step (n − 1) times,KC ϕ1, . . . , KC ϕn (cid:13) KC ψ.Hence, X (cid:13) KC ψ by the choice of formula KC ϕ1, . . . , KC ϕn, which contradicts the consistency of the set X due to the assumption ¬KC ψ ∈ X . (cid:2)If (cid:2) is the modality SC , then the standard technique needs to be modified. Namely, while ¬SC ψ ∈ w means that coalition C can not achieve goal ψ , its pairwise disjoint sub-coalitions D1, . . . , Dn ⊆ C might still achieve their own goals ϕ1, . . . , ϕn. An equivalent of Lemma 15 for modality SC is the following statement.Lemma 16. For any consistent set of formulae X , and any subsets D1, . . . , Dn of a coalition C , any formula ¬SC ψ ∈ X , and any SD1 ϕ1, . . . , SDn ϕn ∈ X , if D i ∩ D j = ∅ for all integers i, j ≤ n such that i (cid:15)= j, then the set of formulae {¬ψ, ϕ1, . . . , ϕn} is consistent.Proof. Suppose that ϕ1, ϕ2, . . . , ϕn (cid:13) ψ . Hence, by the deduction theorem for propositional logic applied n times,(cid:13) ϕ1 → (ϕ2 → (. . . (ϕn → ψ) . . . )).Then, (cid:13) S∅(ϕ1 → (ϕ2 → (. . . (ϕn → ψ) . . . ))) by Lemma 4. Hence, by Cooperation axiom and Modus Ponens inference rule,(cid:13) SD1ϕ1 → S∅∪D1 (ϕ2 → (. . . (ϕn → ψ) . . . )).In other words,(cid:13) SD1ϕ1 → SD1 (ϕ2 → (. . . (ϕn → ψ) . . . )).Then, by Modus Ponens inference rule,SD1ϕ1 (cid:13) SD1 (ϕ2 → (. . . (ϕn → ψ) . . . )).By Cooperation axiom and Modus Ponens inference rule,SD1ϕ1 (cid:13) SD2ϕ2 → SD1∪D2 (. . . (ϕn → ψ) . . . ).Again, by Modus Ponens inference rule,SD1ϕ1, SD2ϕ2 (cid:13) SD1∪D2 (. . . (ϕn → ψ) . . . ).By repeating the previous steps n − 2 times,SD1ϕ1, SD2ϕ2, . . . , SDn ϕn (cid:13) SD1∪D2∪···∪Dn ψ.Recall that SD1 ϕ1, SD2 ϕ2, . . . , SDn ϕn ∈ X by the assumption of the lemma. Thus, X (cid:13) SD1∪D2∪···∪Dn ψ . Therefore, X (cid:13) SC ψby Lemma 5. Since the set X is consistent, the latter contradicts the assumption ¬SC ψ ∈ X of the lemma. (cid:2)6.3. HarmonyIf (cid:2) is the modality HC , then the standard technique needs even more significant modification. Namely, as it follows from Definition 7, assumption ¬HC ψ ∈ w requires us, for each strategy profile of coalition C , to create not a single child of parent w, but two different children referred in Definition 7 as states wis a state of the system indistinguishable from state w by coalition C . Child wand coalition C cannot prevent the system to transition from w(cid:3)is a state such that ¬ψ ∈ w, see Fig. 9. Child wand w(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)One might think that states w. It appears, however, that such an approach does not work because it does not guarantee that ¬ψ ∈ w. To solve the issue, we con-as maximal consistent sets of formulae, it struct states wsimultaneously. While constructing states wis important to maintain two relations between sets wthat we call “to be in harmony” and “to be in complete and wharmony”. In this section we define harmony relation and prove its basic properties. The next section is dedicated to the complete harmony relation.could be constructed in order: first state wand then state w(cid:3)(cid:3)and wand w(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)to w(cid:3).and w(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)P. Naumov, J. Tao / Artificial Intelligence 262 (2018) 279–300291Fig. 9. States w(cid:3)(cid:3)and ware maximal consistent sets of formulae in complete harmony.Even though according to Definition 5 the language of our logical system only includes propositional connectives ¬ and →, other connectives, including conjunction ∧, can be defined in the standard way. By ∧Y we mean the conjunction of a finite set of formulae Y . If set Y is a singleton, then ∧Y represents the single element of set Y . If set Y is empty, then ∧Yis defined to be any propositional tautology.Definition 8. Pair ( X, Y ) of sets of formulae is in harmony if X (cid:4) S∅¬ ∧ Y(cid:3)for each finite set Y(cid:3) ⊆ Y .Lemma 17. If pair ( X, Y ) is in harmony, then set X is consistent.Proof. If set X is not consistent, then any formula can be derived from it. In particular, X (cid:13) S∅¬ ∧ ∅. Therefore, pair ( X, Y )is not in harmony by Definition 8. (cid:2)Lemma 18. If pair ( X, Y ) is in harmony, then set Y is consistent.Proof. Suppose that Y is inconsistent. Then, there is a finite set YThus, X (cid:13) S∅¬ ∧ Y. Therefore, by Definition 8, pair ( X, Y ) is not in harmony. (cid:2)(cid:3)(cid:3) ⊆ Y such that (cid:13) ¬ ∧ Y(cid:3). Hence, (cid:13) S∅¬ ∧ Y(cid:3)by Lemma 4. Lemma 19. For any ϕ ∈ (cid:5), if pair ( X, Y ) is in harmony, then either pair ( X ∪ {¬S∅ϕ}, Y ) or pair ( X, Y ∪ {ϕ}) is in harmony.Proof. Suppose that neither pair ( X ∪ {¬S∅ϕ}, Y ) nor pair ( X, Y ∪ {ϕ}) is in harmony. Then, by Definition 8, there are finite sets Y 1 ⊆ Y and Y 2 ⊆ Y ∪ {ϕ} such thatX, ¬S∅ϕ (cid:13) S∅¬ ∧ Y 1andX (cid:13) S∅¬ ∧ Y 2.(11)(12)Formula ¬ ∧ Y 1 → ¬((∧Y 1) ∧ (∧(Y 2 \ {ϕ}))) is a propositional tautology. Thus, (cid:13) S∅(¬ ∧ Y 1 → ¬((∧Y 1) ∧ (∧(Y 2 \ {ϕ}))))by Lemma 4. Then, by Cooperation axiom, statement (11), and Modus Ponens inference rule, X, ¬S∅ϕ (cid:13) S∅∪∅¬((∧Y 1) ∧(∧(Y 2 \ {ϕ}))). In other words,X, ¬S∅ϕ (cid:13) S∅¬((∧Y 1) ∧ (∧(Y 2 \ {ϕ}))).(13)Finally, formula ¬ ∧ Y 2 → (ϕ → ¬((∧Y 1) ∧ (∧(Y 2 \ {ϕ})))) is also a propositional tautology. Thus, by Lemma 4,(cid:13) S∅(¬ ∧ Y 2 → (ϕ → ¬((∧Y 1) ∧ (∧(Y 2 \ {ϕ}))))).Then, by Cooperation axiom, statement (12), and Modus Ponens inference rule, X (cid:13) S∅(ϕ → ¬((∧Y 1) ∧ (∧(Y 2 \ {ϕ})))). Thus, by Cooperation axiom and Modus Ponens inference rule,X (cid:13) S∅ϕ → S∅¬((∧Y 1) ∧ (∧(Y 2 \ {ϕ}))).By Modus Ponens inference rule,X, S∅ϕ (cid:13) S∅¬((∧Y 1) ∧ (∧(Y 2 \ {ϕ}))).Hence, X (cid:13) S∅¬((∧Y 1) ∧ (∧(Y 2 \ {ϕ}))) by statement (13) and the laws of propositional reasoning. Recall that Y 1 and Y 2 \ {ϕ} are subsets of Y . Therefore, pair ( X, Y ) is not in harmony by Definition 8. (cid:2)The next lemma is an equivalent of Lemma 15 and Lemma 16 for modality HC . The lemma is stated in terms of an arbitrary function f : C → (cid:5). This lemma will be used in the proof of Lemma 30 for a specific function definable only in the context of the proof of Lemma 30.292P. Naumov, J. Tao / Artificial Intelligence 262 (2018) 279–300Lemma 20. For any consistent set of formulae X , any formula ¬HC ψ ∈ X , and any function f : C → (cid:5), pair (Y , Z ) is in harmony, whereY = {ϕ | KC ϕ ∈ X}, andZ = {¬ψ} ∪ {χ | ∃D ⊆ C (HDχ ∈ X ∧ ∀a ∈ D ( f (a) = χ ))}.Proof. Suppose that pair (Y , Z ) is not in harmony. Thus, by Definition 8, there is a finite ZSince a derivation uses only finitely many assumptions, there are formulae K C ϕ1, KC ϕ2 . . . , KC ϕn ∈ X such that(cid:3) ⊆ Z such that Y (cid:13) S∅¬ ∧ Z(cid:3). ϕ1, ϕ2 . . . , ϕn (cid:13) S∅¬ ∧ Z(cid:3).Then, by the deduction theorem for propositional logic applied n times,(cid:13) ϕ1 → (ϕ2 → (· · · → (ϕn → S∅¬ ∧ Z(cid:3)) . . . )).Hence, by Necessitation inference rule,(cid:13) KC (ϕ1 → (ϕ2 → (· · · → (ϕn → S∅¬ ∧ Z(cid:3)) . . . ))).Then, by Distributivity axiom and Modus Ponens inference rule,(cid:13) KC ϕ1 → KC (ϕ2 → (· · · → (ϕn → S∅¬ ∧ Z(cid:3)) . . . )).Thus, by Modus Ponens inference rule,KC ϕ1 (cid:13) KC (ϕ2 → (· · · → (ϕn → S∅¬ ∧ Z(cid:3)) . . . )).By repeating the previous two steps (n − 1) times,KC ϕ1, KC ϕ2 . . . , KC ϕn (cid:13) KC S∅¬ ∧ Z(cid:3).Hence, by the choice of formulae K C ϕ1, KC ϕ2, . . . , KC ϕn,X (cid:13) KC S∅¬ ∧ Z(cid:3).(14)(cid:3)Since set ZD1, . . . , Dn ⊆ C ,is a subset of set Z , by the choice of set Z , there must exist formulae HD1 χ1, . . . , HDn χn ∈ X such that ∀i ≤ n ∀a ∈ D i ( f (a) = χi),and the following formula is a tautology, even if ¬ψ /∈ Z(cid:3):χ1 → (χ2 → . . . (χn → (¬ψ → ∧ Z(cid:3))) . . . ).Without loss of generality, we can assume that formulae χ1, . . . , χn are pairwise distinct.Claim 1. D i ∩ D j = ∅ for each i, j ≤ n such that i (cid:15)= j.(15)(16)Proof of Claim. Suppose the opposite. Then, there is a ∈ D i ∩ D j . Thus, χi = f (a) = χ j by statement (15). This contradicts the assumption that formulae χ1, . . . , χn are pairwise distinct. (cid:2)Since formula (16) is a propositional tautology, by the law of contrapositive, the following formula is also a propositional tautology:χ1 → (χ2 → . . . (χn → (¬ ∧ Z(cid:3) → ψ)) . . . ).Thus, by Strategic Necessitation inference rule,(cid:13) H∅(χ1 → (χ2 → . . . (χn → (¬ ∧ Z(cid:3) → ψ)) . . . )).Hence, by Epistemic Cooperation axiom and Modus Ponens inference rule,(cid:13) HD1χ1 → H∅∪D1 (χ2 → . . . (χn → (¬ ∧ Z(cid:3) → ψ)) . . . ).Then, by Modus Ponens inference rule,P. Naumov, J. Tao / Artificial Intelligence 262 (2018) 279–300293HD1χ1 (cid:13) HD1 (χ2 → . . . (χn → (¬ ∧ Z(cid:3) → ψ)) . . . ).By Epistemic Cooperation axiom, Claim 1, and Modus Ponens inference rule,HD1χ1 (cid:13) HD2χ2 → HD1∪D2 (. . . (χn → (¬ ∧ Z(cid:3) → ψ)) . . . ).By Modus Ponens inference rule,HD1χ1, HD2χ2 (cid:13) HD1∪D2 (. . . (χn → (¬ ∧ ZBy repeating the previous two steps (n − 2) times,(cid:3) → ψ)) . . . ).HD1χ1, HD2χ2, . . . , HDn χn (cid:13) HD1∪D2∪···∪Dn (¬ ∧ Z(cid:3) → ψ).Recall that HD1 χ1, HD2 χ2, . . . , HDn χn ∈ X by the choice of HD1 χ1, . . . , HDn χn. Thus, X (cid:13) HD1∪D2∪···∪Dn (¬ ∧ Zbecause D1, . . . , Dn ⊆ C , by Lemma 3, X (cid:13) HC (¬ ∧ Zment (14). Since the set X is consistent, this contradicts the assumption ¬HC ψ ∈ X of the lemma. (cid:2)(cid:3) → ψ). Hence, (cid:3) → ψ). Then, X (cid:13) HC ψ by Epistemic Determinicity axiom and state-6.4. Complete harmonyDefinition 9. A pair in harmony ( X, Y ) is in complete harmony if for each ϕ ∈ (cid:5) either ¬S∅ϕ ∈ X or ϕ ∈ Y .Lemma 21. For each pair in harmony ( X, Y ), there is a pair in complete harmony ( X(cid:3), Y(cid:3)) such that X ⊆ X(cid:3)and Y ⊆ Y(cid:3).Proof. Recall that the set of agent A is finite and the set of propositional variables is countable. Thus, the set of all formulae (cid:5) is also countable. Let ϕ1, ϕ2, . . . be an enumeration of all formulae in (cid:5). We define two chains of sets X1 ⊆ X2 ⊆ . . . and Y 1 ⊆ Y 2 ⊆ . . . such that pair ( Xn, Yn) is in harmony for each n ≥ 1. These two chains are defined recursively as follows:1. X1 = X and Y 1 = Y ,2. if pair ( Xn, Yn) is in harmony, then, by Lemma 19, either pair ( Xn ∪ {¬S∅ϕn}, Yn) or pair ( Xn, Yn ∪ {ϕn}) is in harmony. Let ( Xn+1, Yn+1) be ( Xn ∪ {¬S∅ϕn}, Yn) in the former case and ( Xn, Yn ∪ {ϕn}) in the latter case.(cid:3)(cid:3)(cid:3) =Let Xn Xn and YWe next show that pair ( X(cid:3) (cid:13) S∅¬ ∧ Ysuch that X(cid:3)(cid:3)(cid:3) =n Yn. Note that X = X1 ⊆ X(cid:3)and Y = Y 1 ⊆ Y(cid:3).(cid:3), Y(cid:3)) is in harmony. Suppose the opposite. Then, by Definition 8, there is a finite set Y. Since a deduction uses only finitely many assumptions, there must exist n1 ≥ 1 such that(cid:3)(cid:3) ⊆ Y(cid:3)(cid:13) S∅¬ ∧ Y(cid:3)(cid:3).Xn1(17)(cid:3)(cid:3) →(cid:3)(cid:3) → S∅¬ ∧ Yn by (cid:13) S∅¬ ∧ Yn due to statement (17). Thus, Xn (cid:13) S∅¬ ∧ Yn, ⊆ Xn. Then, pair ( Xn, Yn) is not in harmony, which contradicts the choice of pair ( Xn, Yn). Therefore, pair (cid:3)(cid:3)At the same time, since set Y¬ ∧ Yn is a tautology because YCooperation axiom and Modus Ponens inference rule. Hence, Xn1because Xn1( Xis finite, there must exist n2 ≥ 1 such that Y(cid:3)(cid:3) ⊆ Yn2(cid:3)(cid:3) ⊆ Yn2 . Let n = max{n1, n2}. Note that ¬ ∧ Y(cid:3)(cid:3) → ¬ ∧ Yn) by Lemma 4. Then, (cid:13) S∅¬ ∧ Y⊆ Yn. Thus, (cid:13) S∅(¬ ∧ Yis an enu-meration of all formulae in (cid:5), there must exist k ≥ 1 such that ϕ = ϕk. Then, by the choice of pair ( Xk+1, Yk+1), either ¬S∅ϕ = ¬S∅ϕk ∈ Xk+1 ⊆ X. Therefore, pair ( X(cid:3)) is in complete harmony. Indeed, consider any ϕ ∈ (cid:5). Since ϕ1, ϕ2, . . .(cid:3)) is in complete harmony. (cid:2)or ϕ = ϕk ∈ Yk+1 ⊆ Y(cid:3)) is in harmony.(cid:3), YWe finally show that pair ( X(cid:3), Y(cid:3), Y(cid:3)(cid:3)6.5. Canonical epistemic transition systemIn this section we fix a maximal consistent set of formulae X0 and define a canonical epistemic transition system E T S( X0) = (W , {∼a}a∈A, V , M, π ).The standard technique for proving the completeness of S5 modal logic consists in defining states of a Kripke model as maximal consistent sets of formulae and specifying that relation s1 ∼a s2 holds if sets s1 and s2 have the same formulae of the form Kaϕ. This approach, however, does not work directly in the case of distributed knowledge version of S5. Indeed, in the latter case, if s1 ∼a s2 and s1 ∼b s2, then we need sets s1 and s2 to share not only formulae of the form Kaϕ and of the form Kbϕ, but also of the form K{a,b}ϕ. A naïve way to achieve this is to require states s1 and s2 to share formulae of form K{a,b}ϕ each time when need s1 ∼a s2 and s1 ∼b s2 both to be true. To achieve this, we define a canonical model, called the canonical epistemic transition system, as a graph whose nodes are labeled with maximal consistent sets and whose edges are labeled with coalitions. If nodes s1 and s2 are connected by an edge labeled with coalition C , then we require maximal consistent sets associated with nodes s1 and s2 to share all formulae of the form KD ϕ, where D ⊆ C . In fact, as we will see later, it suffices just to share formulae of the form KC ϕ.Note, however, that the graph construction does not solve our problems completely. Indeed, let us suppose that the graph, see Fig. 10, in addition to nodes s1 and s2, has nodes u and v such that edges (s1, u) and (u, s2) are labeled with 294P. Naumov, J. Tao / Artificial Intelligence 262 (2018) 279–300Fig. 10. The graph construction.Fig. 11. A fragment of the canonical epistemic transition system.single-element coalition {a} and edges (s1, v) and (v, s2) are labeled with single-element coalition {b}. Thus, on one hand sets s1 and s2 share Kaϕ formulae (through set u) and Kbϕ formulae (through state v), but they do not, generally speaking, share formulae of the form K{a,b}ϕ. On the other hand, we need them to share formulae K{a,b}ϕ because s1 ∼a s2 and s1 ∼b s2. More generally, such a situation happens if the graph has two distinctive paths between nodes s1 and s2: edges along one path are labeled with coalitions containing agent a and edges along the other path are labeled with coalitions containing agent b. To avoid this situation, it suffices to guarantee that the canonical models use trees instead of arbitrary graphs. We achieve this by adopting the “unravelling” technique [34].Although in the informal discussion above we talked about states as the nodes of the tree, in the “unravelling” construc-tion it is mathematically more elegant to assume that states are paths that lead to the node from the root of the tree. For the sake of simplicity, we still like to informally think about states as the nodes. For example, see Fig. 11, we talk about state X2 rather than state X0, {a, c}, X1, {a}, X2.Definition 10. The set of epistemic states W consists of all finite sequences X0, C1, X1, C2, . . . , Cn, Xn, such that1. n ≥ 0,2. Xi is a maximal consistent subset of (cid:5) for each i ≥ 1,3. Ci is a coalition for each i ≥ 1,4. {ϕ | KCi ϕ ∈ Xi−1} ⊆ Xi for each i ≥ 1.We say that two nodes of the tree are indistinguishable to an agent a if every edge along the unique path connect-ing these two nodes is labeled with a coalition containing agent a. For example, in Fig. 11, nodes X3 (technically, state X0, {a, b, c}, X3) and node X2 are indistinguishable to agent a because a ∈ {a, b, c}. At the same time, nodes X3 and X4 are distinguishable to agent a because edge between nodes X1 and X4 is not labeled with a. However, nodes X3 and X4 are indistinguishable to agent c.Definition 11. For any state w = X0, C1, X1, C2, . . . , Cn, Xn and any state wthere is an integer k such that(cid:3) = X0, C(cid:3)1, X(cid:3)1, C(cid:3)2, . . . , C(cid:3)m, X(cid:3)m, let w ∼a w(cid:3)if 1. 0 ≤ k ≤ min{n, m},(cid:3)i for each i such that 1 ≤ i ≤ k,2. Xi = X(cid:3)3. Ci = Ci for each i such that 1 ≤ i ≤ k,4. a ∈ Ci for each i such that k < i ≤ n,(cid:3)i for each i such that k < i ≤ m.5. a ∈ CLemma 22. Relation ∼a is an equivalence relation on set W for each a ∈ A.Proof. Relation “connected by a path labeled with agent a” is a reflexive, symmetric, and transitive relation on nodes of an arbitrary labeled graph. (cid:2)For any state w = X0, C1, X1, C2, . . . , Cn, Xn, by hd(w) we denote the set Xn. The abbreviation hd stands for “head”.Lemma 23. For any w = X0, C1, X1, C2, . . . , Cn, Xn ∈ W and any integer k ≤ n, if KC ϕ ∈ Xn and C ⊆ Ci for each integer i such that k < i ≤ n, then KC ϕ ∈ Xk.P. Naumov, J. Tao / Artificial Intelligence 262 (2018) 279–300295Proof. Suppose that there is k ≤ n such that KC ϕ /∈ Xk. Let m be the maximal such k. Note that m < n due to the assumption KC ϕ ∈ Xn of the lemma. Thus, m < m + 1 ≤ n.Assumption KC ϕ /∈ Xm implies ¬KC ϕ ∈ Xm due to the maximality of the set Xm. Hence, Xm (cid:13) KC ¬KC ϕ by Negative ¬KC ϕ by the Monotonicity axiom and the assumption C ⊆ Cm+1 of the lemma (recall ¬KC ϕ ∈ Xm due to the maximality of the set Xm. Hence, ¬KC ϕ ∈ Xm+1 by Definition 10. Thus, Introspection axiom. Thus, Xm (cid:13) KCm+1that m + 1 ≤ n). Then, KCm+1KC ϕ /∈ Xm+1 due to the consistency of the set Xm+1, which is a contradiction with the choice of integer m. (cid:2)Lemma 24. For any w = X0, C1, X1, C2, . . . , Cn, Xn ∈ W and any integer k ≤ n, if KC ϕ ∈ Xk and C ⊆ Ci for each integer i such that k < i ≤ n, then ϕ ∈ Xn.Proof. We prove the lemma by induction on the distance between n and k. In the base case n = k. Then the assumption KC ϕ ∈ Xn implies Xn (cid:13) ϕ by Truth axiom. Therefore, ϕ ∈ Xn due to the maximality of set Xn.Suppose that k < n. Assumption KC ϕ ∈ Xk implies Xk (cid:13) KC KC ϕ by Lemma 14. Thus, Xk (cid:13) KCk+1 KC ϕ by the Monotonicity axiom, the condition k < n of the inductive step, and the assumption C ⊆ Ck+1 of the lemma. Then, KCk+1 KC ϕ ∈ Xk by the maximality of set Xk. Hence, KC ϕ ∈ Xk+1 by Definition 10. Therefore, ϕ ∈ Xn by the induction hypothesis. (cid:2)Lemma 25. If KC ϕ ∈ hd(w) and w ∼C w(cid:3), then ϕ ∈ hd(w(cid:3)).Proof. The statement follows from Lemma 23, Lemma 24, and Definition 11 because there is a unique path between any two nodes in a tree. (cid:2)At the beginning of Section 6.2, we discussed that if a parent node contains a modal formula ¬(cid:2)ψ , then it must have a child node containing formula ¬ψ . Lemma 15 in Section 6.2 provides a foundation for constructing such a child node for modality KC . The proof of the next lemma describes the construction of the child node for this modality.Lemma 26. If KC ϕ /∈ hd(w), then there is an epistemic state w(cid:3) ∈ W such that w ∼C w(cid:3)and ϕ /∈ hd(w(cid:3)).Proof. Assumption KC ϕ /∈ hd(w) implies that ¬KC ϕ ∈ hd(w) due to the maximality of the set hd(w). Thus, by Lemma 15, set Y 0 = {¬ϕ} ∪ {ψ | KC ψ ∈ hd(w)} is consistent. Let Y be a maximal consistent extension of set Y 0 and wbe sequence (cid:3) ∈ Ww, C, Y . In other words, sequence wdue to Definition 10 and the choice of set Y 0. Furthermore, w ∼C wby Definition 11. To finish the proof, we need to show (cid:3)) due to the consistency of the set that ϕ /∈ hd(w(cid:3)). (cid:2)hd(w(cid:3)(cid:3)) by the choice of Y 0. Therefore, ϕ /∈ hd(wis an extension of sequence w by two additional elements: C and Y . Note that w(cid:3)). Indeed, ¬ϕ ∈ Y 0 ⊆ Y = hd(w(cid:3)(cid:3)In the next two definitions we specify the domain of votes and the vote aggregation mechanism of the canonical transi-tion system. Informally, a vote (ϕ, w) of each agent consists of two components: the actual vote ϕ and a key w. The actual vote ϕ is a formula from (cid:5) in support of what the agent votes. Recall that the agent does not know in which exact state the system is, she only knows the equivalence class of this state with respect to the indistinguishability relation. The key wis the agent’s guess of the epistemic state where the system is. Informally, agent’s vote has more power to force the formula to be satisfied in the next state if she guesses the current state correctly.Although each agent is free to vote for any formula she likes, the vote aggregation mechanism would grant agent’s wish only under certain circumstances. Namely, if the system is in state w and set hd(w) contains formula SC ϕ, then the mechanism guarantees that formula ϕ is satisfied in the next state as long as each member of coalition C votes for formula ϕ and correctly guesses the current epistemic state. In other words, in order for formula ϕ to be guaranteed in the next state all members of the coalition C must cast vote (ϕ, w). This means that if SC ϕ ∈ hd(w), then coalition C has a strategy to force ϕ in the next state. Since the strategy requires each member of the coalition to guess correctly the current state, such a strategy is not a know-how strategy.The vote aggregation mechanism is more forgiving if the epistemic state w contains formula HC ϕ. In this case the mechanism guarantees that formula ϕ is satisfied in the next state if all members of the coalition vote for formula ϕ; it does not matter if they guess the current state correctly or not. This means that if HC ϕ ∈ hd(w), then coalition C has a know-how strategy to force ϕ in the next state. The strategy consists in each member of the coalition voting for formula ϕand specifying an arbitrary epistemic state as the key.Formal definitions of the domain of choices and of the vote aggregation mechanism in the canonical epistemic transition system are given below.Definition 12. The domain of choices V is (cid:5) × W .For any pair u = (x, y), let pr1(u) = x and pr2(u) = y.296P. Naumov, J. Tao / Artificial Intelligence 262 (2018) 279–300Definition 13. The mechanism M of the canonical model is the set of all tuples (w, {sa}a∈A, wϕ ∈ (cid:5) and each coalition C ,(cid:3)) such that for each formula 1. if SC ϕ ∈ hd(w) and sa = (ϕ, w) for each a ∈ C , then ϕ ∈ hd(w2. if HC ϕ ∈ hd(w) and pr1(sa) = ϕ for each a ∈ C , then ϕ ∈ hd(w(cid:3)), and(cid:3)).The next two lemmas prove that the vote aggregation mechanism specified in Definition 13 acts as discussed in the informal description given earlier.Lemma 27. Let w, ww →s w(cid:3)and sa = (ϕ, w) for each a ∈ C , then ϕ ∈ hd(w(cid:3)).(cid:3) ∈ W be epistemic states, SC ϕ ∈ hd(w) be a formula, and s = {sa}a∈C be a strategy profile of coalition C . If Proof. Suppose that w →s wa ∈ C and (w, s(cid:3)) ∈ M. Therefore, ϕ ∈ hd(w. Thus, by Definition 6, there is a strategy profile s(cid:3) = {s(cid:3)) by Definition 13 and the assumption sa = (ϕ, w) for each a ∈ C . (cid:2)such that s}a∈A ∈ V(cid:3), w(cid:3)a(cid:3)a(cid:3)A= sa for each Lemma 28. Let w, w(cid:3)(cid:3)(cid:3) →s ww ∼C w, w(cid:3)(cid:3)(cid:3) ∈ W be epistemic states, HC ϕ ∈ hd(w) be a formula, and s = {sa}a∈C be a strategy profile of coalition C . If (cid:3), w, and pr1(sa) = ϕ for each a ∈ C , then ϕ ∈ hd(w(cid:3)(cid:3)).Proof. Suppose that HC ϕ ∈ hd(w). Thus, hd(w) (cid:13) KC HC ϕ by Lemma 1. Hence, KC HC ϕ ∈ hd(w) due to the maximality of the set hd(w). Thus, HC ϕ ∈ hd(wimplies (cid:3)), that there is a strategy profile spr1(s. By Definition 6, assumption w(cid:3), w(cid:3)) by Lemma 25 and the assumption w ∼C w(cid:3), s(cid:3)(cid:3)) by Definition 13. (cid:2)(cid:3)a) = pr1(sa) = ϕ for each a ∈ C , and (w}a∈A such that s(cid:3), w(cid:3)(cid:3)) ∈ M. Since HC ϕ ∈ hd(w= sa for each a ∈ C and (w(cid:3)(cid:3)) ∈ M, we have ϕ ∈ hd(w(cid:3) →s w(cid:3) = {s(cid:3), s(cid:3)a(cid:3)a(cid:3)(cid:3)(cid:3)The lemma below provides a construction of a child node for modality SC . Although the proof follows the outline of the proof of Lemma 26 for modality KC , it is significantly more involved because of the need to show that a transition from a parent node to a child node satisfies the constraints of the vote aggregation mechanism from Definition 13.Lemma 29. For any epistemic state w ∈ W , any formula ¬SC ψ ∈ hd(w), and any strategy profile s = {sa}a∈C ∈ V C , there is a state w(cid:3) ∈ W such that w →s wand ψ /∈ hd(w(cid:3)).(cid:3)Proof. Let Y 0 be the following set of formulae{¬ψ} ∪ {ϕ | ∃D ⊆ C(SDϕ ∈ hd(w) ∧ ∀a ∈ D(pr1(sa) = ϕ))}.We first show that set Y 0 is consistent. Suppose the opposite. Thus, there must exist formulae ϕ1, . . . , ϕn ∈ Y 0 and subsets D1, . . . , Dn ⊆ C such that (i) SD i ϕi ∈ hd(w) for each integer i ≤ n, (ii) pr1(sa) = ϕi for each i ≤ n and each a ∈ D i , and (iii) set {¬ψ, ϕ1, . . . , ϕn} is inconsistent. Without loss of generality we can assume that formulae ϕ1, . . . , ϕn are pairwise distinct.Claim 2. Sets D i and D j are disjoint for each i (cid:15)= j.Proof of Claim. Assume that d ∈ D i ∩ D j , then pr1(sd) = ϕi and pr1(sd) = ϕ j . Hence, ϕi = ϕ j , which contradicts the assump-tion that formulae ϕ1, . . . , ϕn are pairwise distinct. Therefore, sets D i and D j are disjoint for each i (cid:15)= j. (cid:2)By Lemma 16, it follows from Claim 2 that set Y 0 is consistent. Let Y be any maximal consistent extension of Y 0 and wbe the sequence w, ∅, Y . In other words, wis an extension of sequence w by two additional elements: ∅ and Y .(cid:3)(cid:3)Claim 3. w(cid:3) ∈ W .Proof of Claim. By Definition 10, it suffices to show that, for each formula ϕ ∈ (cid:5), if K∅ϕ ∈ hd(w), then ϕ ∈ Y . Indeed, suppose that K∅ϕ ∈ hd(w). Thus, hd(w) (cid:13) H∅ϕ by Empty Coalition axiom. Hence, hd(w) (cid:13) S∅ϕ by Strategic Truth axiom. Then, S∅ϕ ∈ hd(w) due to the maximality of set hd(w). Therefore, ϕ ∈ Y 0 ⊆ Y by the choice of sets Y 0 and Y . (cid:2)Let (cid:19) be any propositional tautology. For example, (cid:19) could be formula ψ → ψ . Define strategy profile s(cid:3) = {s(cid:3)a}a∈A as follows(cid:2)(cid:3)sa=sa,((cid:19), w),if a ∈ C,otherwise.(18)Claim 4. For any formula ϕ ∈ (cid:5) and any D ⊆ A, if SDϕ ∈ hd(w) and s(cid:3)a= (ϕ, w) for each a ∈ D, then ϕ ∈ hd(w(cid:3)).P. Naumov, J. Tao / Artificial Intelligence 262 (2018) 279–300297Proof of Claim. Consider any formula ϕ ∈ (cid:5) and any set D ⊆ A such that SD ϕ ∈ hd(w) and sa ∈ D. We need to show that ϕ ∈ hd(wCase 1: D ⊆ C . In this case, sa = sset Y 0.Case 2: There is a0 ∈ D such that a0 /∈ C . Then, sset D. Thus, ((cid:19), w) = (ϕ, w). Hence, formula ϕ is the tautology (cid:19). Therefore, ϕ ∈ hd(w= ((cid:19), w) by definition (18). Note that s= (ϕ, w) for each a ∈ D by definition (18). Thus, ϕ ∈ Y 0 ⊆ Y = hd(w(cid:3)) because set hd(w(cid:3)).(cid:3)a0(cid:3)a0(cid:3)a(cid:3)a= (ϕ, w) for each agent (cid:3)) by the choice of = (ϕ, w) by the choice of the (cid:3)) is maximal. (cid:2)Claim 5. For any formula ϕ ∈ (cid:5) and any D ⊆ A, if HDϕ ∈ hd(w) and pr1(s(cid:3)a) = ϕ for each a ∈ D, then ϕ ∈ hd(w(cid:3)).Proof of Claim. Consider any formula ϕ ∈ (cid:5) and any set D ⊆ A such that HD ϕ ∈ hd(w) and pr1(sa ∈ D. We need to show that ϕ ∈ hd(w(cid:3)Case 1: D ⊆ C . In this case, pr1(sa) = pr1(sa) = ϕ for each agent a ∈ D by definition (18) and the choice of set D. Thus, (cid:3)) by the choice of set Y 0.ϕ ∈ Y 0 ⊆ Y = hd(wCase 2: There is agent a0 ∈ D such that a0 /∈ C . Then, sset D. Thus, (cid:19) = ϕ. Hence, formula ϕ is the tautology (cid:19). Therefore, ϕ ∈ hd(w= ((cid:19), w) by definition (18). Note that pr1(s) = ϕ by the choice of (cid:3)) because set hd(w(cid:3)) is maximal. (cid:2)(cid:3)a) = ϕ for each agent (cid:3)).(cid:3)a0(cid:3)a0By Definition 13, Claim 4 and Claim 5 together imply that (w, snition (18). To finish the proof of the lemma, note that ψ /∈ hd(whd(w(cid:3)). (cid:2)(cid:3), w(cid:3)) ∈ M. Hence, w →s w(cid:3)(cid:3)) because set hd(wby Definition 6 and defi-(cid:3)) is consistent and ¬ψ ∈ Y 0 ⊆ Y =The next lemma shows the construction of a child node for modality HC . The proof is similar to the proof of Lemma 29except that, instead of constructing a single child node, we construct two sibling nodes that are in complete harmony. The intuition was discussed at the beginning of Section 6.3.Lemma 30. For any state w ∈ W , any formula ¬HC ψ ∈ hd(w), and any strategy profile s = {sa}a∈C ∈ V C , there are epistemic states w(cid:3)(cid:3) ∈ W such that ψ /∈ hd(w, and w(cid:3)(cid:3)), w ∼C w(cid:3) →s w(cid:3), w(cid:3)(cid:3).(cid:3)Proof. By Definition 12, for each a ∈ C , vote sa is a pair. LetY = {ϕ | KC ϕ ∈ hd(w)}, andZ = {¬ψ} ∪ {ϕ | ∃D ⊆ C (HDϕ ∈ hd(w) ∧ ∀a ∈ D (pr1(sa) = ϕ))}.By Lemma 20 where f (x) = pr1(sx), pair (Y , Z ) is in harmony. By Lemma 21, there is a pair (Ysuch that Y ⊆ Yand Z ⊆ Zconsistent extensions of sets Y. By Lemma 17 and Lemma 18, sets Y(cid:3)(cid:3), Zare consistent. Let Y, respectively.and Zand Z(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)) in complete harmony (cid:3)(cid:3)be maximal and Z(cid:3)(cid:3)Recall that set A is finite. Thus, set C ⊆ A is also finite. Let integer n be the cardinality of set C . Consider (n + 1)sequences w 1, w 2, . . . , wn+1, where sequence wk is an extension of sequence w that adds 2k additional elements:(cid:3)(cid:3)(cid:3)(cid:3)w 1 = w, C, Yw 2 = w, C, Yw 3 = w, C, Y. . .wn+1 = w, C, Y(cid:3)(cid:3), C, Y, C, Y(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3), C, Y(cid:3)(cid:3), . . . , C, Y(cid:3)(cid:3)(cid:4)(cid:7)(cid:5)(cid:6)2(n+1) elements.Claim 6. wk ∈ W for each k ≤ n + 1.Proof of Claim. We prove the claim by induction on integer k.Base Case: By Definition 10, it suffices to show that if KC ϕ ∈ hd(w), then ϕ ∈ hd(w 1). Indeed, if KC ϕ ∈ hd(w), then ϕ ∈ Y by the choice of set Y . Therefore, ϕ ∈ Y ⊆ YInduction Step: By Definition 10, it suffices to show that if KC ϕ ∈ hd(wk), then ϕ ∈ hd(wk+1) for each k ≥ 1. In other words, we need to prove that if KC ϕ ∈ Y, which follows from Truth axiom and the maximality of set Y(cid:3)(cid:3) = hd(w 1)., then ϕ ∈ Y(cid:3) ⊆ Y. (cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)By the pigeonhole principle, there is i0 ≤ n such that pr2(sa) (cid:15)= w i0 for all a ∈ C . Let w(cid:3)be epistemic state w i0 . Thus,(cid:3)pr2(sa) (cid:15)= wfor each a ∈ C.be the sequence w, ∅, ZLet w(cid:3)(cid:3)(cid:3)(cid:3)ments: ∅ and Z(cid:3)(cid:3). Finally, let strategy profile s. In other words, sequence w(cid:3)a(cid:3) = {s}a∈A be defined as follows(cid:3)(cid:3)is an extension of sequence w by two additional ele-(19)298(cid:2)(cid:3)sa=sa,((cid:19), w(cid:3)),if a ∈ C,otherwise.Claim 7. w(cid:3)(cid:3) ∈ W .P. Naumov, J. Tao / Artificial Intelligence 262 (2018) 279–300(20)(cid:3)(cid:3)) for each formula ϕ ∈ (cid:5). Indeed, Proof of Claim. By Definition 10, it suffices to show that if K∅ϕ ∈ hd(w), then ϕ ∈ hd(wby Empty Coalition axiom, assumption K∅ϕ ∈ hd(w) implies that hd(w) (cid:13) H∅ϕ. Hence, H∅ϕ ∈ hd(w) by the maximality of the set hd(w). Thus, ϕ ∈ Z by the choice of set Z . Therefore, ϕ ∈ Z ⊆ Z(cid:3)(cid:3) = hd(w(cid:3)(cid:3)). (cid:2)(cid:3) ⊆ ZClaim 8. w ∼C w(cid:3).Proof of Claim. By Definition 11, w ∼C w i for each integer i ≤ n + 1. In particular, w ∼C w i0(cid:3)= w. (cid:2)Claim 9. ψ /∈ hd(w(cid:3)(cid:3)).Proof of Claim. Note that ¬ψ ∈ Z by the choice of set Z . Thus, ¬ψ ∈ Z ⊆ Zthe consistency of the set hd(w(cid:3)(cid:3)). (cid:2)(cid:3) ⊆ Z(cid:3)(cid:3) = hd(w(cid:3)(cid:3)). Therefore, ψ /∈ hd(w(cid:3)(cid:3)) due to Claim 10. Let ϕ be a formula in (cid:5) and D be a subset of A. If SDϕ ∈ hd(w(cid:3)) and s(cid:3)a= (ϕ, w(cid:3)) for each a ∈ D, then ϕ ∈ hd(w(cid:3)(cid:3)).(cid:3), Z(cid:3) ⊆ Z(cid:3)(cid:3) = hd(w(cid:3)(cid:3)). Assumption SD ϕ ∈ hd(w(cid:3)) is in complete harmony. Thus, by Definition 9, either ¬S∅ϕ ∈ YProof of Claim. Note that either set D is empty or it contains an element a0. In the latter case, element a0 either belongs or does not belong to set C .Case I: D = ∅. Recall that pair (Yϕ ∈ Zthe assumption D = ∅ of the case. Therefore, ϕ ∈ hd(w(cid:3)). Thus, Case II: there is an element a0 ∈ C ∩ D. Thus, a0 ∈ C . Hence, pr2(sa0 ) (cid:15)= w(cid:15)= (ϕ, wby inequality (19). Then, sa0(cid:3)) by definition (20). Recall that a0 ∈ C ∩ D ⊆ D. This contradicts the assumption that s(cid:3)(cid:3)(cid:3)) for each a ∈ D.= (ϕ, wsaa0(cid:3)(cid:3)) by definition (20). At the same time, s(cid:3)) by the second Case III: there is an element a0 ∈ D \ C . Thus, s= ((cid:19), w= (ϕ, wa0(cid:3)(cid:3)) due to the maximality assumption of the claim. Hence, formula ϕ is the propositional tautology (cid:19). Therefore, ϕ ∈ hd(wof the set hd(w(cid:3)(cid:3) = hd(w(cid:3)) due to the consistency of the set hd(w(cid:3)) implies that ¬S∅ϕ /∈ hd(w(cid:3)) or (cid:3)) and (cid:15)= (ϕ, w(cid:3)(cid:3)). (cid:2)(cid:3) ⊆ Y(cid:3)(cid:3)).(cid:3)a0(cid:3)Claim 11. Let ϕ be a formula in (cid:5) and D be a subset of A. If HDϕ ∈ hd(w(cid:3)) and pr1(s(cid:3)a) = ϕ for each a ∈ D, then ϕ ∈ hd(w(cid:3)(cid:3)).(cid:3) ⊆ ZProof of Claim.Case I: D ⊆ C . Suppose that pr1(s(cid:3)(cid:3)).ϕ ∈ Z ⊆ Z(cid:3)) by definition (20). At the same time, pr1(s(cid:3)Case II: D (cid:5) C . Consider any a0 ∈ D \ C . Note that s) = ϕ by the aa(cid:3)(cid:3)) due to the second assumption of the claim. Hence, formula ϕ is the propositional tautology (cid:19). Therefore, ϕ ∈ hd(wmaximality of the set hd(w(cid:3)). Thus, ϕ ∈ Z by the choice of set Z . Therefore, (cid:3)a) = ϕ for each a ∈ D and HD ϕ ∈ hd(w(cid:3)(cid:3) = hd(w= ((cid:19), w(cid:3)(cid:3)). (cid:2)(cid:3)a0Claim 10 and Claim 11, by Definition 13, imply that (w(cid:3), {s(cid:3)a}a∈A, w(cid:3)(cid:3)) ∈ M. Thus, w(cid:3) →s w(cid:3)(cid:3)by Definition 6 and defini-tion (20). This together with Claim 6, Claim 7, Claim 8, and Claim 9 completes the proof of the lemma. (cid:2)Definition 14. π (p) = {w ∈ W | p ∈ hd(w)}.This concludes the definition of tuple (W , {∼a}a∈A, V , M, π ).Lemma 31. Tuple (W , {∼a}a∈A, V , M, π ) is an epistemic transition system.Proof. By Definition 1, it suffices to show that for each w ∈ W and each s ∈ V(cid:3)) ∈ M.Recall that set A is finite. Thus, (cid:13) ¬SA⊥ by Nontermination axiom. Hence, ¬SA⊥ ∈ hd(w). By Lemma 29, there is (cid:3) ∈ W such that w →s w(cid:3)) ∈ M by Definition 6. (cid:2)(cid:3) ∈ W such that (w, s, w. Therefore, (w, s, wthere is ww(cid:3)ALemma 32. w (cid:2) ϕ iff ϕ ∈ hd(w) for each epistemic state w ∈ W and each formula ϕ ∈ (cid:5).Proof. We prove the lemma by induction on the structural complexity of formula ϕ. If formula ϕ is a propositional variable, then the required follows from Definition 7 and Definition 14. The cases of formula ϕ being a negation or an implication follow from Definition 7, and the maximality and the consistency of the set hd(w) in the standard way.P. Naumov, J. Tao / Artificial Intelligence 262 (2018) 279–300299Let formula ϕ have the form KC ψ .(⇒) Suppose that KC ψ /∈ hd(w). Then, by Lemma 26, there is wby the induction hypothesis. Therefore, w (cid:2) KC ψ by Definition 7.(⇐) Assume that KC ψ ∈ hd(w). Consider any wIndeed, ψ ∈ hd(w(cid:3)) by Lemma 25. Therefore, by the induction hypothesis, w(cid:3) ∈ W such that w ∼C w(cid:3)(cid:3) (cid:2) ψ .(cid:3) ∈ W such that w ∼C w(cid:3)and ψ /∈ hd(w(cid:3)). Hence, w(cid:3) (cid:2) ψ. By Definition 7, it suffices to show that w(cid:3) (cid:2) ψ . Let formula ϕ have the form SC ψ .(⇒) Suppose that SC ψ /∈ hd(w). Then, ¬SC ψ ∈ hd(w) due to the maximality of the set hd(w). Hence, by Lemma 29, for (cid:3)). Thus, by the induction any strategy profile s ∈ V C , there is an epistemic state w(cid:3) (cid:2) ψ . Then, w (cid:2) SC ψ by hypothesis, for any strategy profile s ∈ V C , there is a state wDefinition 7.(⇐) Assume that SC ψ ∈ hd(w). Consider strategy profile s = {sa}a∈C ∈ V C such that sa = (ψ, w) for each a ∈ C . By (cid:3)). Hence, by the induction hypothesis, for any Lemma 27, for any epistemic state wepistemic state w, then ψ ∈ hd(w(cid:3) (cid:2) ψ . Therefore, w (cid:2) SC ψ by Definition 7.(cid:3) ∈ W such that w →s w(cid:3) ∈ W such that w →s wand ψ /∈ hd(wand w(cid:3) ∈ W , if w →s w(cid:3) ∈ W , if w →s w(cid:3)(cid:3)(cid:3)(cid:3), then wFinally, let formula ϕ have the form HC ψ .(cid:3)(cid:3) (cid:2) ψ by the induction hypothesis. Therefore, w (cid:2) HC ψ by Definition 7.(⇒) Suppose that HC ψ /∈ hd(w). Then, ¬HC ψ ∈ hd(w) due to the maximality of the set hd(w). Hence, by Lemma 30, for (cid:3)(cid:3)). Thus, any strategy profile s ∈ V C , there are epistemic states ww(⇐) Assume that HC ψ ∈ hd(w). Consider a strategy profile s = {sa}a∈C ∈ V C such that sa = (ψ, w) for each a ∈ C . By (cid:3)(cid:3)). Hence, by the induction (cid:3)Lemma 28, for all epistemic states whypothesis, w(cid:3)(cid:3) ∈ W , if w ∼C w(cid:3)(cid:3) (cid:2) ψ . Therefore, w (cid:2) HC ψ by Definition 7. (cid:2)(cid:3)(cid:3) ∈ W such that w ∼C w, then ψ ∈ hd(w, and ψ /∈ hd(w(cid:3) →s w(cid:3) →s w, and w(cid:3), w(cid:3), w, w(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)6.6. Completeness: the final stepTo finish the proof of Theorem 2 stated at the beginning of Section 6, suppose that (cid:4) ϕ. Let X0 be any maximal consistent subset of set (cid:5) such that ¬ϕ ∈ X0. Consider the canonical epistemic transition system E T S( X0) defined in Section 6.5. Let w be the single-element sequence X0. Note that w ∈ W by Definition 10. Thus, w (cid:2) ¬ϕ by Lemma 32. Therefore, w (cid:2) ϕ by Definition 7.Note that Theorem 2 can be stated and proven in a slightly more general form known as string completeness theorem:Theorem 3 (strong completeness). For any (possibly infinite) set of formulae X ⊆ (cid:5) and any formula ϕ ∈ (cid:5), if X (cid:4) ϕ, then there is an epistemic state w of an epistemic transition system such that w (cid:2) χ for each formula χ ∈ X and w (cid:2) ϕ.The proof of Theorem 3 is identical to the proof of Theorem 2 except for X0 must be a maximal consistent extension of set X ∪ {¬ϕ}.7. ConclusionWe proposed a sound and complete logic system that captures an interplay between the distributed knowledge, coalition strategies, and how-to strategies. This article is an extended version of our previous conference paper [32], which contained the same results, but did not include the proofs of the soundness and the completeness. The completeness proof is signif-icantly different from standard proofs of completeness in modal logic because of the peculiarity of know-how modality H. According to item 6 of Definition 7, if w (cid:2) HC ϕ, then there are two epistemic states wand wthat satisfy curtain condi-tions (while in the case of S5 and most of other standard modal logics, only one state wis required in a similar situation). had to be constructed simultaneously because of the inter-dependency between them Furthermore, the states wimposed by Definition 7. To achieve this, we developed a new technique that we call “harmony”. This technique is one of the main contributions of this article. In our upcoming paper [31], this technique is adapted and refined for second-order know-how strategies.and w(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)In the future work we hope to explore know-how strategies of nonhomogeneous coalitions in which different members contribute differently to the goals of the coalition. For example, “incognito” members of a coalition might contribute only by sharing information, while “open” members also contribute by voting. It would also be interesting to investigate the computational complexity of this logic and alternative inference frameworks such as modal and description logics to design tableau algorithms for automated reasoning. Another direction may be the consideration of different types of coalition knowledge, such as common knowledge. Finally, one could study the interplay of knowledge and coalition power in a logic where strategies are first class citizen.AcknowledgementWe thank the reviewers for their insightful comments that greatly improved the quality of this article.300P. Naumov, J. Tao / Artificial Intelligence 262 (2018) 279–300References2008 .08 .004.[1] R. Fagin, J.Y. Halpern, Y. Moses, M.Y. Vardi, Reasoning about Knowledge, MIT Press, Cambridge, MA, 1995.[2] E.A. Akkoyunlu, K. Ekanadham, R. Huber, Some constraints and tradeoffs in the design of network communications, in: ACM SIGOPS Operating Systems Review, vol. 9, ACM, 1975, pp. 67–74.[3] J.N. Gray, Notes on data base operating systems, in: Operating Systems, Springer, 1978, pp. 393–481.[4] T. Ågotnes, Y.N. Wáng, Resolving distributed knowledge, Artif. Intell. 252 (2017) 1–21.[5] M. Pauly, Logic for Social Software, Ph.D. thesis, Institute for Logic, Language, and Computation, 2001.[6] M. Pauly, A modal logic for coalitional power in games, J. Log. Comput. 12 (1) (2002) 149–166, https://doi .org /10 .1093 /logcom /12 .1.149.[7] V. Goranko, Coalition games and alternating temporal logics, in: Proceedings of the 8th Conference on Theoretical Aspects of Rationality and Knowl-edge, Morgan Kaufmann Publishers Inc., 2001, pp. 259–272.[8] W. van der Hoek, M. Wooldridge, On the logic of cooperation and propositional control, Artif. Intell. 164 (1) (2005) 81–119.[9] S. Borgo, Coalitions in action logic, in: 20th International Joint Conference on Artificial Intelligence, 2007, pp. 1822–1827.[10] L. Sauro, J. Gerbrandy, W. van der Hoek, M. Wooldridge, Reasoning about action and cooperation, in: Proceedings of the Fifth International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS ’06, ACM, New York, NY, USA, 2006, pp. 185–192.[11] T. Ågotnes, P. Balbiani, H. van Ditmarsch, P. Seban, Group announcement logic, J. Appl. Log. 8 (1) (2010) 62–81, https://doi .org /10 .1016 /j .jal .2008 .12 .002.[12] T. Ågotnes, W. van der Hoek, M. Wooldridge, Reasoning about coalitional games, Artif. Intell. 173 (1) (2009) 45–79, https://doi .org /10 .1016 /j .artint .[13] F. Belardinelli, Reasoning about knowledge and strategies: epistemic strategy logic, in: Proceedings 2nd International Workshop on Strategic Reasoning, SR 2014, Grenoble, France, April 5–6, 2014, in: EPTCS, vol. 146, 2014, pp. 27–33.[14] S.M. More, P. Naumov, Calculus of cooperation and game-based reasoning about protocol privacy, ACM Trans. Comput. Log. 13 (3) (2012) 22:1–22:21, https://doi .org /10 .1145 /2287718 .2287722.[15] R. Alur, T.A. Henzinger, O. Kupferman, Alternating-time temporal logic, J. ACM 49 (5) (2002) 672–713, https://doi .org /10 .1145 /585265 .585270.[16] W. van der Hoek, M. Wooldridge, Cooperation, knowledge, and time: alternating-time temporal epistemic logic and its applications, Stud. Log. 75 (1) [17] V. Goranko, G. van Drimmelen, Complete axiomatization and decidability of alternating-time temporal logic, Theor. Comput. Sci. 353 (1) (2006) 93–117, (2003) 125–157, https://doi .org /10 .1023 /A :1026171312755.https://doi .org /10 .1016 /j .tcs .2005 .07.043.[18] B. Aminof, A. Murano, S. Rubin, F. Zuleger, Prompt alternating-time epistemic logics, in: KR 16, 2016, pp. 258–267.[19] R. Berthon, B. Maubert, A. Murano, S. Rubin, M.Y. Vardi, Strategy logic with imperfect information, in: 2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science (LICS), IEEE, 2017, pp. 1–12.[20] R. Berthon, B. Maubert, A. Murano, Decidability results for atl* with imperfect information and perfect recall, in: Proceedings of the 16th Conference on Autonomous Agents and MultiAgent Systems, International Foundation for Autonomous Agents and Multiagent Systems, 2017, pp. 1250–1258.[21] T. Ågotnes, N. Alechina, Epistemic coalition logic: completeness and complexity, in: Proceedings of the 11th International Conference on Autonomous Agents and Multiagent Systems (AAMAS), vol. 2, 2012, pp. 1099–1106.[22] T. Ågotnes, N. Alechina, Coalition logic with individual, distributed and common knowledge, J. Log. Comput. (2016) Exv085, https://doi .org /10 .1093 /logcom /exv085.https://doi .org /10 .3166 /jancl .17.423 -475.[23] W. Jamroga, T. Ågotnes, Constructive knowledge: what agents can achieve under imperfect information, J. Appl. Non-Class. Log. 17 (4) (2007) 423–475, [24] W. Jamroga, W. van der Hoek, Agents that know how to play, Fundam. Inform. 63 (2–3) (2004) 185–219.[25] J. van Benthem, Games in dynamic-epistemic logic, Bull. Econ. Res. 53 (4) (2001) 219–248, https://doi .org /10 .1111 /1467 -8586 .00133.[26] Y. Wang, A logic of knowing how, in: Logic, Rationality, and Interaction, Springer, 2015, pp. 392–405.[27] Y. Wang, A logic of goal-directed knowing how, Synthese, https://doi .org /10 .1007 /s11229 -016 -1272 -0.[28] P. Naumov, J. Tao, Coalition power in epistemic transition systems, in: Proceedings of the 2017 International Conference on Autonomous Agents and Multiagent Systems (AAMAS), 2017, pp. 723–731.gence, IJCAI-17, 2017, pp. 1031–1038.Systems (AAMAS), 2018, in press.[29] R. Fervari, A. Herzig, Y. Li, Y. Wang, Strategically knowing how, in: Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelli-[30] P. Naumov, J. Tao, Strategic coalitions with perfect recall, in: Proceedings of Thirty-Second AAAI Conference on Artificial Intelligence, 2018.[31] P. Naumov, J. Tao, Second-order know-how strategies, in: Proceedings of the 2018 International Conference on Autonomous Agents and Multiagent [32] P. Naumov, J. Tao, Together we know how to achieve: an epistemic logic of know-how, in: 16th Conference on Theoretical Aspects of Rationality and Knowledge (TARK), July 24–26, 2017, in: EPTCS, vol. 251, 2017, pp. 441–453.[33] P.-Y. Schobbens, Alternating-time logic with imperfect recall, Electron. Notes Theor. Comput. Sci. 85 (2) (2004) 82–93.[34] H. Sahlqvist, Completeness and correspondence in the first and second order semantics for modal logic, in: Proc. of the 3rd Scandinavian Logic Symposium, Uppsala, 1973, Stud. Logic Found. Math. 82 (1975) 110–143.