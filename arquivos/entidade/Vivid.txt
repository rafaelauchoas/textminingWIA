Artificial Intelligence 173 (2009) 1367–1405Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintVivid: A framework for heterogeneous problem solving ✩Konstantine Arkoudas, Selmer Bringsjord∗Rensselaer AI & Reasoning (RAIR) Lab, Department of Cognitive Science, Department of Computer Science, Rensselaer Polytechnic Institute (RPI), Troy, NY 12180, USAa r t i c l ei n f oa b s t r a c tArticle history:Received 30 June 2008Received in revised form 1 June 2009Accepted 9 June 2009Available online 13 June 2009Keywords:VividHeterogeneous reasoningProblem solvingDiagramsDPLsAssumption basesNamed system statesWorlds3-valued logic1. IntroductionWe introduce Vivid, a domain-independent framework for mechanized heterogeneous rea-soning that combines diagrammatic and symbolic representation and inference. The frame-work is presented in the form of a family of denotational proof languages (DPLs). Wepresent novel formal structures, called named system states, that are specifically designedfor modeling potentially underdetermined diagrams. These structures allow us to deal withincomplete information, a pervasive feature of heterogeneous problem solving. We intro-duce a notion of attribute interpretations that enables us to interpret first-order relationalsignatures into named system states, and develop a formal semantic framework based on3-valued logic. We extend the assumption-base semantics of DPLs to accommodate dia-grammatic reasoning by introducing general inference mechanisms for the valid extractionof information from diagrams, and for the incorporation of sentential information into dia-grams. A rigorous big-step operational semantics is given, on the basis of which we provethat the framework is sound. We present examples of particular instances of Vivid in orderto solve a series of problems, and discuss related work.© 2009 Elsevier B.V. All rights reserved.Diagrams have been recognized as valuable representational and reasoning tools at least since the days of Euclid. They areused extensively in a very wide range of fields. To note just a few examples, witness: free-body, energy-level and Feynmandiagrams in physics [60]; arrow diagrams in algebra and category theory [44]; Euler and Venn diagrams in elementaryset theory and logic; function graphs in calculus and analysis; planar figures in geometry; bar, chart, and pie graphs ineconomics; circuit, state, and timing diagrams in hardware design [32]; UML diagrams in software design [47]; higraphsin specification [25]; visual programming languages [15] and visual logic and specification languages [1,27,42]; transitiongraphs in model checking [11]; ER-diagrams and hypergraphs in databases [21]; semantic (as well as neural and belief)networks in AI [50]; icons and other pictorial devices in graphical user interfaces (GUIs) and information visualization[12,39,59,63]; and so on. Given such a list, and the power of diagrams that it suggests, it seems reasonable to hold thatif the capability of computers to work with diagrams intelligently can be further increased, human reasoning and problemsolving will be facilitated. The framework presented here, Vivid, is intended to purchase some of that increase.The representational power of diagrams stems primarily from the fact that they can have structural correspondenceswith the objects or situations they represent—they are analogical representations in the terminology of Sloman [54], orhomomorphic representations in the terminology of Barwise and Etchemendy [7]; also see Hayes [26]. To put it more plainly,✩This work was made possible by grants received from DARPA and DTO. We are indebted to Ron Brachman, David Musser, Martin Rinard, and to threeanonymous referees for insightful comments, objections, and suggestions.* Corresponding author.E-mail addresses: arkouk@rpi.edu (K. Arkoudas), selmer@rpi.edu (S. Bringsjord).0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2009.06.0021368K. Arkoudas, S. Bringsjord / Artificial Intelligence 173 (2009) 1367–1405a diagram resembles—or at any rate should resemble—what the diagram depicts, in contrast to sentential descriptions.1 Thiswas noticed at least as far back as the 19th century, when Peirce observed that a diagram is “naturally analogous to thething represented” [43, p. 316].Consider, for instance, the task of describing a human face. We could perhaps describe the face with a collection ofEnglish sentences, or with a set of sentences in some formal language. But such a description is likely to be long andcomplicated, and not particularly illuminating.2 A drawing or a picture of the face, on the other hand, will be much moreperspicuous, as well as significantly more compact than most sentential representations. Of course, some diagrams arebetter than others. A talented artist will produce a drawing that is a much more accurate depiction than the scrawlings ofa child. A digital picture will be even more accurate.3 So, as Hammer [24] observes, being an analogical or homomorphicrepresentation is not a distinguishing feature of diagrams in general, but rather a distinguishing feature of good diagrams.The utility of (good) diagrams is often thought to derive from the fact that diagrams are two-dimensional objects, andtherefore spatial relationships on the plane can directly reflect analogous relationships in the underlying domain, an obser-vation made a while back by Russell [49]. A classic example are maps. We can represent the streets of a city graphically,with a map, or sententially, e.g., by a collection of assertions expressing the various intersections and so forth. The graphicalrepresentation is doubtless a more intuitive and effective description because its spatial structure is similar to the actuallayout of the city. This analogical correspondence is lost in the sentential representation. As another example, consider amap of a lake and try to imagine a sentential description of it. Stenning and Lemon [57] trace this discrepancy to the factthat sentential languages derive from acoustic signals, which are one-dimensional and must therefore rely on a complexsyntax for representation, something that is not necessary in the case of diagrams.However, two-dimensionality by itself is neither a necessary nor a sufficient condition for being a diagram. For instance,as Hammer [24] points out, a representation of a picture by a two-dimensional array of numbers encoded under someencryption scheme does not count as a diagram; there is no structural similarity between the representation and thatwhich is being represented. And, by making sufficiently clever conventions, we can construct analogical one-dimensionaldiagrams. For example, the following string asserts that the stretch of road between Main Street/35th Street and Main/36this two-way, whereas that between Main/36th and Main/37th is one-way and proceeds from right to left:Main|35th <==> Main|36th <== Main|37thIt bears stressing that diagrams are helpful only when their visual structure is analogical or homomorphic with thesemantic structure of the information which they represent. In an era of Powerpoint and multimedia presentations, it isoften taken for granted that graphical displays of information are automatically clearer and more intuitive than text, simplyby virtue of being “visual.” That is emphatically not the case. The reason why Euler circles are efficacious, for instance, isprecisely because spatial enclosure is naturally analogous to the subset relation, spatial overlap to set-theoretic intersection,and spatial separation to set-theoretic disjointness [53]. In the absence of such structural similarities, diagrams can quicklydegenerate into what Tufte [59, p. 34] calls “chartjunk”: cluttered displays of lines, curves, arrows, bars, charts, and the like,that end up obscuring rather than clarifying information.4 Conversely, a diagram does not have to be visually arresting orelaborate in order to be superior to a sentential representation. It does not even have to be two-dimensional, as we notedabove, a point that is borne out by our Main Street example, or by Hammer’s example of an one-dimensional diagrammeant to express the relative distances between the Earth, Moon, and Mars when the Moon is aligned to fall betweenEarth and Mars:Earth–Moon————MarsThis diagram is one-dimensional: its syntax can be adequately modeled by sequences of symbols [24, p. 2].Some might be inclined to criticize such diagrams as inordinately simple and purely structural, hence suffering from in-sufficient “diagrammaticity,” the implication being that only visually elaborate diagrams qualify as truly diagrammatic. Thecriticism is at odds with the brute reality of ingenious human diagrammatic reasoning and problem solving. For example,consider the well-known example of the seating puzzle of Barwise and Etchemendy [6], which we discuss extensively inSection 8. The diagrams in that puzzle are indeed very simple (one-dimensional, small, and purely ASCII); but they are noless powerful for human reasoners as a result. In fact, their structural nature and simplicity, far from being defects, arepositively conducive to their representational power. Structure and simplicity are usually advantages of analogical represen-tations, not disadvantages.1 The terms “sentential” and “symbolic” will be used synonymously throughout.2 Fractals [37] might be able to yield compact representations for some complex shapes such as coastlines, etc., but the equations generating the fractalswould be no more analogical to the corresponding shapes than other symbolic descriptions.3 In the limiting case, the ultimate representation of an object is the object itself.4 Peter Norvig provides an amusing but compelling illustration of this point in his Powerpoint version of the Gettysburg address, where he turns “fourscores and seven years” into a gratuitous graph: www.norvig.com/Gettysburg/sld005.htm. More information can be found at www.norvig.com/Gettysburg/making.html.K. Arkoudas, S. Bringsjord / Artificial Intelligence 173 (2009) 1367–14051369In the next section we discuss some design desiderata. In Section 3 we present the notation that we use throughoutthis paper. Section 4 introduces the main conceptual tools used to specify and investigate the semantics of Vivid: attributestructures, attribute systems, and attribute system states. In Section 5 we develop the theoretical framework necessary fordefining and analyzing Vivid. We introduce the notion of attribute interpretations, which enables us to evaluate first-orderformulas with respect to attribute system states in accordance with a 3-valued logic. We also introduce named systemstates, thereby formalizing the idea that arbitrary names can appear inside diagrams. A number of useful results are listedhere that are needed later for our soundness theorem.5 Section 6 presents and discusses the abstract syntax and formalevaluation semantics of Vivid; our main soundness result also appears here. Section 7 discusses implementation issues. InSection 8 we present a Vivid solution to a well-known puzzle in heterogeneous problem solving, while Section 9 illustratesthe use of Vivid for reasoning about constraint problems (in this particular example, map coloring). Finally, in Section 10we discuss related work, and Section 11 concludes. A Vivid system allowing for the formulation and solution of arbitraryseating puzzles of the sort described in Section 8 has been implemented, and can be downloaded along with a number ofmachine-readable examples of heterogeneous proofs in that domain, including the solution to the puzzle of Barwise andEtchemendy.62. Some design desiderataWe begin by listing, briefly, some conditions that Vivid was designed to meet. We then proceed to discuss each in moredetail.• Combine symbolic and diagrammatic reasoning. As is well-known in AI, some systems are geared toward reasoning thatis exclusively symbolic in nature (e.g., resolution-based theorem proving). The visual counterparts to such systems arethose that only allow diagrammatic reasoning, and are therefore devoid of formulas of the sort seen in propositionaland predicate logic (e.g., traditional Venn diagrams). Vivid is intended to strike a marriage between these two extremes,by enabling heterogeneous reasoning: reasoning that has the tight step-by-step structure of formal, symbolic deduction,and yet at the same time makes productive use of diagrams.• Achieve diagrammatic generality. Most diagrammatic reasoning systems are committed to what might be called partic-ularism; i.e., they are suited to representing, and enabling reasoning over, a relatively small, fixed space of objects.One example is Peirce’s α system, which provides a diagrammatic rendition of the propositional calculus. As such, thissystem does not provide the resources for analogically representing, say, circuits, seating arrangements around a din-ner table, or arbitrary blocks-world configurations. To measure up to our goals for it, Vivid must reach an appreciablelevel of generality: It must be a framework for representing and reasoning heterogeneously over objects in arbitrarydomains.• Enable mechanization. Any particular instance of Vivid should be mechanizable. The diagrams should be readable andeditable by machine, and the reasoning carried out with them should be certifiable by machine, and, at least in prin-ciple, automatically obtainable by machine as well. It is not enough to empower reasoners to refine their intuitions tosome degree, or to merely externalize those intuitions in diagrams.• Develop meta-theory. It is a customary expectation by now that the presentation of a logical system should be accom-panied by—or at least be formulated with a rigor sufficient to allow the in-principle articulation of—meta-mathematicalresults. Such results often include soundness, completeness, decidability, and so on.2.1. Heterogeneous representation and inferenceVivid, as indicated, is motivated by the desire to rigorously marry symbolic and diagrammatic reasoning. It is not difficultto motivate such a marriage. To begin, almost all diagrams contain textual labels and various others sentential elements inthem. Such elements are crucial—if you remove all names and numbers from a city map, the map will be rendered uselessfor most practical purposes.Further, note that even when diagrams are perspicuous analogical representations, their use is not entirely withoutdrawbacks. While they often excel in depicting particular, concrete objects and situations, they are usually not as good fordescribing general, abstract structures and relationships. Spatial constraints tend to pull diagrams toward specificity, andend up limiting their generality and expressivity as a result. For instance, if we say that “two cities B and C are to the westof city A,” we make no commitment as to how B and C are positioned relative to each other, e.g., whether B is furtherwest or east of C , whether both are on the same meridian but one is north of the other, etc. But any attempt to drawthe spatial configuration expressed by the foregoing statement would have to place B and C somewhere on the plane, andwould therefore indicate a certain spatial relationship between them that was not present in the original sentence. Whilecertain clever maneuvers can be resorted to (e.g., using two diagrams in the B, C, A case), its seems safe to say that spatialconstraints tend to force diagrams to be specific, even when specificity is not intended.5 We have omitted most proofs for space reasons; they appear in a longer technical report, at kryten.mm.rpi.edu/vivid/vivid.pdf.6 The URL is kryten.mm.rpi.edu/vivid/implementation/.1370K. Arkoudas, S. Bringsjord / Artificial Intelligence 173 (2009) 1367–1405Sentential descriptions are particularly superior—and indeed often necessary—when it comes to expressing complexpropositions. It is easy enough to depict an atomic piece of information such as is conveyed by the sentence “a is square”diagrammatically: We simply draw a square and label it a. But the proposition expressed by the statement “a is not square”is more challenging. How do we draw something that is not square? Certainly drawing it as a triangle will not do, nor as acylinder or as any other particular shape. We need to stipulate a specific graphical convention for signifying that an objectis not square. Perhaps we could draw a square with a line over it, to indicate negation, but if there are other attributes inaddition to shape, say color, then would a line over a red square negate only squarehood or redness as well? What if weonly wanted to say that it is not red? Apparently, any conventions we make will be ad hoc solutions7 and can easily get outof hand. And while clever abstraction conventions can be introduced to express disjunctive information diagrammatically,sometimes with great visual clarity,8 for most domains it will be very difficult to have enough abstraction conventions tobe able to express arbitrary disjunctions. Existential and universal quantifications, being compactly expressed disjunctionsand conjunctions, are even more powerful: “There is a knight on the chessboard” represents a huge number of possiblechessboard configurations and excludes a huge number of others with just a few bits. In general, the issue is that in mostinteresting domains there are too many logical possibilities (models), while, due to physical spatial constraints, there is amuch smaller number of possible diagrams. This discrepancy results in a certain tension. On the one hand, the discrepancyworks to the cognitive advantage of diagrams, since the fewer the graphical possibilities, the clearer the diagrams. (Indeed,if we keep adding abstraction conventions in order to achieve a bijection between the class of diagrams and the class ofset-theoretic models, we will probably end up ruining whatever analogical benefit we might have had originally. That is thecase for Peirce’s visual system for propositional logic, for instance, whose diagrams stand in a bijective relationship withlogical sentences.9) On the other hand, the discrepancy can result in serious expressive limitations for diagrams.Expressive limitations can sometimes lead to incorrect conclusions, since different models might be wrongly conflated(represented by the same diagram). This is a known issue, for example, with some Euler circles [20], as a consequenceof Helly’s theorem in convex topology [17]. A simple illustration of the problem, due to Lemon and Pratt [36],10 is thefollowing: Consider four sets A, B, C , and D, any three of which have a non-empty intersection:A ∩ B ∩ C (cid:4)= ∅;A ∩ B ∩ D (cid:4)= ∅;B ∩ C ∩ D (cid:4)= ∅;A ∩ C ∩ D (cid:4)= ∅.These are four perfectly consistent premises. But any Euler diagram that tried to depict these premises would lead to theincorrect conclusion that all four sets have a non-empty intersection (i.e. that A ∩ B ∩ C ∩ D (cid:4)= ∅), which does not followfrom the premises.11 The reason is that there is no way to draw four convex regions on the plane so that any three of theregions intersect without having all four of them intersect. Again, this is a consequence of Helly’s theorem. Similar negativeresults hold for other diagrammatic ways of depicting sets and relationships between them, such as Englebretsen’s [18]linear diagrams; see Lemon [35] for a thorough discussion.The complexity of diagrammatic reasoning is another potential concern. Roughly, there are two types of diagrammaticinference. In one of them, exemplified by Euler circles, Venn diagrams, etc., inference is carried out by drawing appro-priate diagrams. We then simply read off the appropriate bits of information from the constructed picture. This type ofdiagrammatic inference is summarized (rather crudely) by the slogan “If you can draw it, it holds.”12 In the second type ofdiagrammatic reasoning, inference is carried out in a more traditional sense, by deriving new diagrams from other diagramsthat are given as premises, perhaps in tandem with given symbolic information (as in Vivid), or by extracting symbolicinformation from given diagrams. Computational complexity issues have been investigated more extensively for the formertype of diagrammatic reasoning. For example, it has been realized that results obtained in studying the complexity of topo-logical inference [23] have a direct bearing on the complexity of drawing diagrams such as Euler circles. It has been shown,e.g., that propositional reasoning with Euler sets is NP-hard, even though reasoning about the same domain can be donepolynomially using other representations [35].In our own work, diagrammatic inference is based on reasoning with incomplete information and has a strong model-theoretic flavor, proceeding essentially by model elimination. This can often make proof checking considerably more com-putationally intensive than it is in the purely sentential case, where proofs can be checked very efficiently. It would appear,7 Stenning [56] calls such conventions “abstraction tricks.” We will be referring to them as “abstraction conventions.” These are conventions intended toconvey a complex meaning by arranging various visual tokens in certain fixed patterns. An example is the use of “X” marks and linking in Venn diagrams.8 An example is the judicious use of question-marks inside diagrams, an abstraction convention that is often used in Vivid diagrams.9 Shin and Lemon [53] make a similar point about Peirce’s modification of Euler diagrams (the addition of X-sequences, etc.), writing that “the arbitrari-ness of its conventions and more confusing representations sacrificed the visual clarity which Euler’s original system enjoys.”10 Certain types of Euler circles are less restrictive than Lemon and Pratt’s account. E.g., see Fish and Stapleton [22].11 As a countermodel, take A = {1, 2, 4}, B = {2, 3, 4}, C = {1, 3, 4}, and D = {1, 2, 3}.12 For instance, to check the validity of a syllogism with a Venn diagram, all we have to do is draw a figure that represents the premises of the syllogism.When finished, the picture itself will tell us whether or not the conclusion follows; nothing further needs to be done. Hence, inference in such cases stopswith the representation of the premises. In customary reasoning, by contrast, inference only begins after the premises have been represented.K. Arkoudas, S. Bringsjord / Artificial Intelligence 173 (2009) 1367–14051371therefore, that visual inference, at least in some cases, can be significantly more expensive than corresponding sententialreasoning.13For these and other reasons, a number of researchers have concluded, as have we, that logical reasoning frameworksmust be heterogeneous or hybrid [7,41]; they must support both diagrammatic and sentential modes of representation andreasoning, allowing users to freely combine the two. In the attempt to formulate a generic framework for heterogeneousreasoning, one naturally confronts the question of what type of diagrams to use. As Barwise and Etchemendy [7] correctlyobserve, it would be impossible to construct a domain-independent framework for diagrammatic reasoning that relied ona specific type of diagrams. What makes a class of diagrams appropriate—i.e., good analogical representations—for certainproblems might make them inappropriate for others. For example, at different times electrical engineers use state diagrams,circuit diagrams, and timing diagrams to represent and reason about hardware as needed by the appropriate viewpoint athand (control, logic gates, or timing, respectively). There is no single type of diagram that is uniformly appropriate. Thisnaturally leads us to the next point.2.2. Diagrammatic generalityIn an influential survey of formal methods, Rushby [48, p. 66] wrote the following about diagrams:The problem [with expressing formal specifications in diagrammatic or tabular notations] is that while diagrams andtables may be convenient ways to explain certain types of specification, they do not lend themselves to particularlyeffective mechanized reasoning and . . . mechanically-supported analysis. Furthermore, different problem domains lendthemselves to different types of diagrams or tables . . . . It follows that a formal specification method built around aparticular diagrammatic or tabular notation may have rather restricted application, and limited mechanized support forgeneral forms of analysis.That is a valid and pressing concern. After all, formal symbolic logic would not be the success that it is if we had toinvent a completely new logical theory (and meta-theory) and build a new implementation for every different application.Thankfully, the abstract syntax, semantics, and proof theory of first-order logic are the same regardless of whether we aretalking about circuits, software, blocks worlds, or people.Contrary to the widespread perception expressed in the foregoing quote, we believe that a similar level of generalitycan be attained for heterogeneous reasoning. There is no a priori reason why diagrammatic representation and inferencehave to be unduly specialized and ad hoc, and much of our work on Vivid has been intended to overcome the narrowspecificity identified by Rushby. It turns out that much of what we do when we reason with a combination of diagrammaticand symbolic information does not depend on how the diagrams are drawn or even on what they mean in the context ofa specific application domain. In this paper we identify what is common in a great variety of instances of heterogeneousreasoning, and proceed to factor it out and extrapolate it into general formal constructs. In the resulting framework, thetype of diagrams used may vary from application to application, but the principles by which we reason with diagrammaticand symbolic information remain the same.This is not unlike the separations that are familiar from traditional symbolic logic, where the vocabulary varies fromapplication to application (e.g., we have different constant, relation, and function symbols as dictated by the problem do-main), and the interpretation of the atomic formulas that we can build from that vocabulary will also vary, but the generalprinciples by which we reason with such formulas do not change. In fact, ‘first-order logic’ denotes a framework allowingfor an infinite number of instantiations (first-order languages with different symbol sets), and proof theories for first-orderlogic are pitched in a way that is agnostic as to what particular symbols are legislated. This situation makes it possiblefor different people to use different particular symbols, and yet do so with the knowledge that parsing technology can beeasily created to distill such symbols to a fixed, underlying representation scheme that can be mechanically reasoned over.Such representation schemes are typically specified by use of meta-variables, which themselves carry no particular symboliccontent. Nonetheless, it should not be said about such schemes that they are not really symbolic because they are bereft ofparticular symbols.The situation with respect to Vivid is a close parallel. Vivid has a highly general and modular structure: A specificinstance of it is obtained by fixing a class of diagrams (this is done by providing a diagram parser), and an interpretationof the diagrams through an appropriate attribute structure. This is akin to the way in which the CLP( X ) scheme instantiatesspecific constraint logic programming languages by substituting different domains for X [29].2.3. MechanizationThe capacity to follow and to evaluate a logical train of thought is considered to be one of the hallmarks of intelligence,so we want to replicate that capacity in machines. Of course we want machines to do more—we want them to creatively13 Of course in some contexts this can be viewed as an advantage, as time is usually traded for space. Vivid deductions, for instance, are typically muchmore compact than corresponding sentential deductions.1372K. Arkoudas, S. Bringsjord / Artificial Intelligence 173 (2009) 1367–1405discover rational trains of thought. But, at the very least, we expect them to be able to inspect and assess the correctnessof a given piece of reasoning. In the symbolic realm, this is standard fare. At least in principle, sentential proofs can nowbe mechanically evaluated in a fairly routine manner. If heterogeneous reasoning is to gain wide currency, we believe itimperative that heterogeneous proofs can likewise be mechanically certified by standard and well-understood techniques.142.4. Meta-theoryLittle needs to be said about this requirement, according to which any logical system, and any broader framework oflogical systems, must be characterized precisely enough to determine, at least eventually, whether or not certain key meta-properties are possessed by the systems in question. This requirement is particularly important when logical systems areintended for use in AI. For example, it is certainly of some practical import that we know first-order logic to be sound,complete, but only semi-decidable. Of course, for a given logical system, or class of such, the development of a maturemeta-theory can take some time—but the system or class, from its inception, must allow for this development to unfold.For example, Frege’s contribution consisted in no small part in the fact that his seminal specification of first-order logicallowed Henkin, decades later, to provide the completeness theorem. Vivid is proved sound and decidable in this paper, andis poised for the development of additional meta-theoretical results.A final point to conclude this section: While Vivid has been designed to ensure satisfaction of these desiderata, otherhybrid diagrammatic-symbolic systems, including in some cases ones quite different from Vivid, could certainly satisfy themas well. In the purely symbolic case, after all, there are infinitely many logics, and even if we restrict the class of symboliclogics to those asserted by various AI experts to have certain desirable attributes, the resulting list would be exceedinglylarge, and healthy discussion, well short of consensus, will persist.15 We anticipate the parallel: A growing number ofheterogeneous logics will arrive on the AI scene, each, we trust, contextualized by the set of desiderata it satisfies; and insome cases, inevitably, that set will depart somewhat from our own.3. NotationFor any sets A and B, A \ B denotes their set-theoretic difference:A \ B = {x ∈ A | x /∈ B}.We write (a; b) for the ordered pair that has a and b as its first and second component, respectively, (a; b; c) for the triple ofa, b, and c, etc. For any n (cid:2) 0 objects x1, . . . , xn, [x1 · · · xn] is the list that has xi as its ith element. Given a list L = [x1 · · · xn]and i ∈ {1, . . . , n}, we write L(i) to denote xi . Further, for any such L and object x, we define(cid:2)Pos(x, L) =i ∈ {1, . . . , n}(cid:4)(cid:3)(cid:3) x = xi.Thus, if x does not occur in L then Pos(x, L) = ∅. If A is a set, then A∗is the set of all lists of elements of A.The empty list [ ] is a sublist of every list; no non-empty list is a sublist of []; while a list of the form L = [x1x2 · · · xn]is a sublist of a list of the form [ y1 y2 · · · ym] iff (1) x1 = y1 and [x2 · · · xn] is a sublist of [ y2 · · · ym]; or (2) x1 (cid:4)= y1 and Lis a sublist of [ y2 · · · ym]. Strings (words) over an alphabet Σ are simply lists of elements of Σ . To adhere to customarystring notation, we will usually denote the empty string by (cid:4) (instead of [ ]), and we will omit the enclosing brackets whenwriting non-empty strings, e.g. writing a b c instead of [abc].For any set A, we write Pfin( A) for the set of all finite subsets of A. When n is a positive integer, An denotes theCartesian productn(cid:5)(cid:8)(cid:6)(cid:7)A × · · · × A,i.e., the set of all lists of length n with elements drawn from A.16 Given a (partial) function f : A → B and elements x ∈ A,(cid:9) ∈ A. Morey ∈ B,precisely:f [x (cid:8)→ y] denotes that function from A to B which maps x to y and agrees with f on every other x(cid:9)f [x (cid:8)→ y] =( f \ {(x; f (x))}) ∪ {(x; y)}f ∪ {(x; y)}if f is defined for x;otherwise.For A(cid:9)(cid:9) ⊆ A, f (cid:3) A(cid:2)f (cid:3) A(cid:9) =denotes the restriction of f on A(cid:3)(cid:3) f (x) = y and x ∈ A(cid:9)(cid:4).(x; y)(cid:9), i.e.,Finally, for any relation R ⊆ A1 × · · · × An, D(R) denotes the set { A1, . . . , An}.14 Of course this is not to say that all diagram-infused problem solving does (or should) involve proofs, let alone proofs that should be encoded andchecked in Vivid.15 E.g., some feel that in light of Lindström’s Theorem, logic-based AI should not move beyond first-order logic; some feel that even first-order logic, givenits undecidability, is too expressive, and that description logics (or even just simple subsets of the propositional calculus) are best; some feel that movingat least to quantified modal logics is necessary; and so on.16 With A1 = A.K. Arkoudas, S. Bringsjord / Artificial Intelligence 173 (2009) 1367–140513734. Attribute structures and systemsVery broadly, a diagram depicts a finite number of objects, and conveys (though perhaps only partially) the values ofcertain observable attributes of these objects. Of course what counts as an object and what counts as an attribute dependson our underlying theory and on our purposes, i.e., on how we choose to look at a diagram. That is, how we parse the rawpictorial information of a diagram varies widely, depending on the application at hand. But, assuming that we have fixedwhat constitutes an object and which observable object attributes we are interested in, the upshot of diagram parsing canbe thought of as a mapping that assigns one or more values to every observable attribute of every object represented in thediagram. If exactly one value is assigned to every attribute and object, then the diagram is completely determined; there isno ambiguity or imprecision about it. Incomplete diagrammatic information is captured by assigning multiple values to asingle object and attribute; e.g., if a diagram does not completely determine the color of an object o, we might assign a setof several color values to o, say, green, red, and blue. What follows is a formal development of these intuitions.Definition 1. An attribute structure is a pair A = ({ A1, . . . , Ak}; R) consisting of a finite collection of sets A1, . . . , Ak, calledattributes; and a countable collection R of computable relations, with D(R) ⊆ { A1, . . . , Ak} for each R ∈ R.An attribute structure is thus a type of regular heterogeneous algebraic structure [38], without any operators, whosecarriers are called “attributes.” We will assume that R includes the identity relation on each attribute Ai : {(a; a) | a ∈ Ai}.We also assume that there is a unique label li attached to each attribute Ai of a structure A. A label will serve as analias for the corresponding attribute. Moreover, when the relations of A are immaterial, we identify A with its attributes.We can then write A simply as l1 : A1, . . . , lk : Ak, where li is the label of Ai . We further assume that there is a canonicaltotal ordering ≺l on the labels (attributes): l1 ≺l l2 ≺l · · · ≺l lk. The number of attributes k is the cardinality of A, denotedby |A|. An attribute can be infinite. If all attributes are finite, we say that A has a finite basis.Definition 2. Let A = ({ A1, . . . , Ak}; R) be an attribute structure. An attribute system based on A, or A-system for short,is a pair(cid:10)(cid:11)S ={s1, . . . , sn}; Aconsisting of a finite number n > 0 of objects s1, . . . , sn and A. An attribute of A may include some (perhaps all) of theobjects s1, . . . , sn. If at least one attribute in A includes some of these objects,17 S is called automorphic. We refer to theproduct n · |A| as the system’s power.When A is obvious from the context or immaterial, we drop references to it and speak simply of “systems” rather than“A-systems.” Further, we assume there is a given binary relation ≺s which totally orders the system objects: s1 ≺s s2 ≺s· · · ≺s sn. When ≺s is inconsequential, we do not bother to specify it.(cid:10)(cid:10)(cid:10)Example 1. Consider a simple system consisting of a clock c, with two attributes, hours and minutes:{c}; hours : {0, . . . , 23}, minutes : {0, . . . , 59}.(cid:11)Another system based on the same attribute structure might consist of two clocks c1 and c2, perhaps indicating New Yorkand Tokyo times, respectively:{c1, c2}; hours : {0, . . . , 23}, minutes : {0, . . . , 59}.Example 2. Consider a system comprising the nodes of a three-element linked list, each with two attributes, a data fieldconsisting of a Boolean value (t or f) and a next field consisting of another node or the null value:{n1, n2, n3}; data : Bool, next : {n1, n2, n3, null}where Bool = {t, f} and null is a special token distinct from {n1, n2, n3}. This is an automorphic system.Example 3. Consider a blocks-world system consisting of three blocks A, B, and C , and a single “position” attribute, wherea position is either a block or the floor:(cid:11)(cid:10){ A, B, C}; pos : { A, B, C, floor};and floor is distinct from A, B, and C . This system is also automorphic.17 That is, if Ai ∩ {s1, . . . , sn} (cid:4)= ∅ for some i ∈ {1, . . . , k}.(cid:11)(cid:11),1374K. Arkoudas, S. Bringsjord / Artificial Intelligence 173 (2009) 1367–1405Fig. 1. A linked list world.Definition 3. A state of a system S = ({s1, . . . , sn}, { A1, . . . , Ak}) is a set of functions σ = {δ1, . . . , δk}, where each δi is afunction from {s1, . . . , sn} to the set of all non-empty finite subsets of Ai , i.e.,(cid:13).(cid:12)Pfin( Ai) \ {∅}δi : {s1, . . . , sn} →We refer to each δi as the state’s ascription into Ai . An ascription δi is a valuation if it maps every object to a singleton,i.e., if |δi(s j)| = 1 for every j = 1, . . . , n. We may thus view a valuation as mapping every object to a unique attribute value.A world w is a state in which every ascription is a valuation.A system for an attribute structure with a finite basis has(cid:13)n| Ai | − 1k(cid:14)(cid:12)2i=1states, where n is the number of objects and k the number of attributes. To simplify notation, when δ is a valuation thatmaps an object s to a singleton {a}, we might write δ(s) = a instead of δ(s) = {a}. Thus in some cases we will treat δ(s) asan attribute value rather than a singleton comprising such a value; the context will always make this clear. Further, we willoften use the label li of an attribute Ai to denote the corresponding ascription into Ai . That is, we are overloading the labelsymbols: sometimes li will stand for the attribute Ai and sometimes, in the context of a given state, it will stand for δi , thestate’s (unique) ascription into Ai ; again, the context will always make our intentions obvious. As an additional convention,given a state σ of the form described in Definition 3, an attribute (label) li and an object s j , we write σ (li, s j) for δi(s j),i.e., the value of the ascription δi for the object s j .Example 4. Consider the single-clock system of Example 1:(cid:10){c}; hours : {0, . . . , 23}, minutes : {0, . . . , 59}.(cid:11)A state σ1 of this system is given by the following two valuations:σ1 :hours(c) = 15, minutes(c) = 47,indicating a time of 3:47 p.m. This is a particular world of the clock system. Using the aforementioned convention, we canalso write:σ1(hours, c) = 15, σ1(minutes, c) = 47.Suppose we know that it is between 2:30 a.m. and 3 a.m., but do not know exactly how many minutes past 2:30 it is.This knowledge can be captured by the following state:σ2 :hours(c) = 2, minutes(c) = {31, . . . , 59}.This state can also be expressed by writingσ2(hours, c) = 2, σ2(minutes, c) = {31, . . . , 59}.Complete lack of information about the time is represented by the state:hours(c) = {0, . . . , 23}, minutes(c) = {0, . . . , 59}.Example 5. Consider the linked-list system of Example 2. The statedata(n1) = t,data(n2) = f,data(n3) = t, next(n1) = n2, next(n2) = n3, next(n3) = nulldepicts the world shown in Fig. 1. The statedata(n1) = {t, f},data(n2) = {t, f},data(n3) = f,next(n1) = n2, next(n2) = {n1, n3}, next(n3) = nulldepicts a system in which we do not know the data fields of the first and second nodes, we know that the next field of thesecond node is either n1 or n3, and we have fixed values for the remaining nodes and attributes.K. Arkoudas, S. Bringsjord / Artificial Intelligence 173 (2009) 1367–14051375Fig. 2. A blocks world.Example 6. Consider the blocks world system of Example 3. The statepos( A) = B,pos(B) = floor,pos(C) = floordepicts the blocks world shown in Fig. 2. The statepos( A) = { A, B, C, floor},pos(B) = { A, B, C, floor},pos(C) = { A, B, C, floor}(1)signifies complete lack of information about the positions of the blocks.Here we assume that we are only interested in how the blocks are stacked, not in the left-of relation. So, in the caseof Fig. 2, if C were on the floor to the left of A and B instead of the right, we would still get the same state, (1). Ofcourse we could enrich our attribute structure to take such additional information into account, if doing so was deemedimportant. In general, most abstract representations of a diagram will discard certain bits of information conveyed by thediagram as irrelevant. Which aspects of a diagram are considered essential and which are not depends on the domain athand and on our purposes. In Venn diagrams, for instance, the sizes of the regions is immaterial. Likewise, if we have twointersecting circles A and B, it is immaterial whether A is to the left of B or vice versa. The issue, of course, is not withthe representations but with the diagrams themselves. As discussed in the introduction, diagrams tend to be overly specificand thus we usually need to ignore at least some of their aspects.18We might (rather loosely) think of system states as mental models of situations [31], representing various states ofknowledge ranging from completely specific to completely indeterminate.Using the canonical orders on attributes and system objects, l1 ≺l · · · ≺l lk and s1 ≺s · · · ≺s sn, a world w can be regardedas the unique finite string of the following form:w(l1, s1)w(l2, s1) · · · w(lk, s1) · · · w(l1, sn) · · · w(lk, sn).A string of this form describes, for each attribute, the unique attribute value that every system object has in w, in accordancewith the canonical orderings on objects and attributes: First we have the attribute values of the first object, then theattribute values of the second object, and so on. Thus the length of any such string is k · n, i.e., equal to the power of thesystem.Example 7. Assuming that data ≺l next and that n1 ≺s n2 ≺s n3, the world described in Example 5 (and shown in Fig. 1) canbe viewed as the six-element string t n2 f n3 t null.Definition 4. Consider a system S = ({s1, . . . , sn}; l1 : A1, . . . , lk : Ak). We say that a state σ (cid:9)such state σ , written σ (cid:9) (cid:13) σ , iff σ (cid:9)(li, s j) ⊆ σ (li, s j) for every i = 1, . . . , k and j = 1, . . . , n.19 We call σ (cid:9)of σ , denoted σ (cid:9) (cid:2) σ , iff σ (cid:9) (cid:13) σ and σ (cid:4)(cid:13) σ (cid:9)of S is an extension of anothera proper extension.Hence, σ (cid:9)is a proper extension of σ iff σ (cid:9) (cid:13) σ and there is at least one attribute l and object s such that σ (cid:9)(l, s) ⊂ σ (l, s).Worlds do not have any proper extensions.Consider, for instance, the system of Example 1:(cid:10){c1, c2}; hours : {0, . . . , 23}, minutes : {0, . . . , 59}(cid:11).The state(cid:9)hours(cid:9)(c1) = {13, 14},(c1) = {55},(c2) = {6, 7},minutes(cid:9)hoursminutes(cid:9)(c2) = {9, 10},(2)18 For instance, in the usual diagrammatic proof of the Pythagorean theorem, we must ignore the relative lengths of the triangle’s sides in order to ensurethat we are reasoning about an “arbitrary” triangle, even though any picture of a triangle will necessarily depict specific lengths for its sides.19 The terminology sounds somewhat counterintuitive, since an extension of a state is one that assigns fewer values to each object/attribute pair, therebyincreasing the overall information content. This is similar to the terminology of object-oriented class hierarchies, where we might say that the concepthuman is an extension of mammal to mean that the former is in fact a subset of the latter.1376K. Arkoudas, S. Bringsjord / Artificial Intelligence 173 (2009) 1367–1405is an extension (a proper one) of the statehours(c1) = {13, 14, 15},minutes(c1) = {55},hours(c2) = {6, 7},minutes(c2) = {9, 10, 11}.(3)Recalling that a world can be encoded as a string, we may view a system state σ as a language, namely as the set of allstrings w such that w (cid:13) σ . For instance, the second state described in Example 5 can be understood as the following set ofeight strings:{t n2 t n1 f null, t n2 t n3 f null, t n2 f n1 f null, t n2 f n3 f null, f n2 t n1 f null, f n2 t n3 f null, f n2 f n1 f null, f n2 f n3 f null}.Note that all such languages are finite, and therefore regular. This is important in representing system states as minimalacyclic deterministic finite automata (ADFA), which support highly efficient insertions and membership tests.Definition 5. Two system states σ1 and σ2 are disjoint iff there is no world w such that w (cid:13) σ1 and w (cid:13) σ2.Viewing σ1 and σ2 as languages, the two are disjoint iff they are set-theoretically disjoint, i.e., iff σ1 ∩ σ2 = ∅. Anytwo distinct worlds are automatically disjoint.20 Both perspectives on system states (as indexed sets of ascriptions and aslanguages) are useful, although the second one is not widely used in this paper. For instance, we might speak of a world was extending a certain state σ , w (cid:13) σ , viewing w and σ as sets of ascriptions; or we might speak of w as belonging to σ ,w ∈ σ , viewing the latter as a language and w as a string in that language.The set of all states of S is arranged in a rich partial order corresponding to the join (union) semi-lattice(cid:10)(cid:11)(cid:10)Pfin( A1) \ {∅}× · · · ×Pfin( Ak) \ {∅}(cid:11).We do not quite have a lattice, because the meet of two states might not exist. That is directly related to the proviso ofDefinition 3 that ascriptions must map system objects to non-empty sets of attribute values, and ultimately stems from theexpressive limitations of pictures. Given that incomplete information is part and parcel of our system, a join operator (cid:15) ondiagrams is fairly natural: For any attribute l and object s, we set(σ1 (cid:15) σ2)(l, s) = σ1(l, s) ∪ σ2(l, s).This is precisely the least upper bound of the two states w.r.t. the ordering (cid:13). But a meet operator (cid:16) would indicateconjunction, and conjoining diagrams with contradictory information is not pictorially meaningful. For instance, if an objects has a round shape in diagram σ1 and a square shape in σ2:σ1(shape, s) = round;σ2(shape, s) = square;then what is the shape of s in σ1 (cid:16) σ2? If we define meets as(σ1 (cid:16) σ2)(l, s) = σ1(l, s) ∩ σ2(l, s),then we would have σ1 (cid:16) σ2(shape, s) = ∅, indicating that s has no shape (!) in σ1 (cid:16) σ2. Sententially, we can easily write aformula that assertsRound(s) ∧ Square(s),but, diagrammatically, we cannot draw a square circle (but see the next paragraph). Likewise, we can very well write asentence that asserts that it is currently 5:15 a.m. and also that it is currently 11:30 p.m., but if we look at the face of aclock we will not see it displaying both times. There are no inconsistent diagrams, meaning that there is no diagram thatcan both ascribe and not ascribe a certain observable attribute to one of its elements,21 and this is, in turn, related to thefact that negation is not diagrammatically meaningful. If we had a negation operator ‘−’ on diagrams, then conjunctioncould be defined simply as σ1 (cid:16) σ2 = −(σ1 (cid:15) σ2). But negating a diagram could of course take us to the empty set if thestarting value comprised the entire attribute space.Having said this, we certainly concede that it is easy enough to diagrammatically denote (or at least suggest) inconsis-tency and negation, and, given this, to conjoin a diagram with that which so denotes. After all, in his α existential graph20 When a world is viewed as a language, it is obviously understood as a singleton.21 Optical illusions should not be confused with logical inconsistency.K. Arkoudas, S. Bringsjord / Artificial Intelligence 173 (2009) 1367–14051377system, Peirce uses p! to denote the negation of p, and following his lead, we could decide to use, say, (cid:18)• to indicate incon-sistency. But such techniques forfeit what, following others, we have adopted (Section 1) as the distinguishing mark of gooddiagrams: that they refer analogically (or homomorphically). At least by our lights, it is difficult to see how (cid:18)• , or anythingof the sort, structurally corresponds to inconsistency. Likewise, it might be said that a Venn diagram with a region at onceboth shaded and “Xed” denotes inconsistency. But this move does not produce something that resembles inconsistency; itmerely produces something that can be agreed by convention to suggest inconsistency. Note further that such a diagramis by itself perfectly consistent and hence can be represented in Vivid quite straightforwardly: It is a collection of minimalplane regions [24, p. 33], each of which has a number of observable attributes, e.g., a token such as × or ◦ (or none, indi-cating lack of information about the cardinality of the region). It is not the diagram itself that is inconsistent—again, thatwould require the simultaneous presence and absence of an observable property, which is physically impossible. Rather, itis our interpretation conventions that make us regard the diagram as depicting an inconsistency, albeit in a non-analogicalmanner.In principle, by descending to a sufficiently low level of detail, any diagram whatsoever can be represented in Vividas a system state, simply by treating the diagram as a raster image—an arbitrarily large grid of raw pixels. The objectsof the system would be the pixel locations, there would be only one attribute, intensity, and a system world would mapeach object (pixel location on the grid) to a particular intensity. Of course, reasoning with such a low-level diagrammaticrepresentation would be severely impractical because, by and large, pixels are not analogical representations (e.g., relationsbetween pixels are generally not reflective of relations between the objects of interest).5. Interpreting relational languages over system statesConsider a first-order vocabulary Σ = (C; R; V) consisting of a set of constant symbols C; a set of relation symbols R,with each R ∈ R having a unique positive arity; and a set of variables V. An attribute interpretation of Σ into an attributestructure A = ({l1 : A1, . . . , lk : Ak}; R) is a mapping I that assigns the following to each relation symbol R ∈ R of arity n:1. a relation R I ∈ R of some arity m, called the realization of R:R I ⊆ Ai1× · · · × Aim(where we might have m (cid:4)= n); and2. a list of m pairs(cid:12)(li1; j1) · · · (lim(cid:13); jm)called the profile of R and denoted by Prof (R), with 1 (cid:4) jx (cid:4) n for each x = 1, . . . , m.As will become clear soon, an attribute interpretation differs from a normal interpretation in that an atomic formula oversystem objects is compiled via profiles into an atomic formula over selected attribute values of (some of) those objects.The profile dictates which attributes of which objects will be selected. Accordingly, an atomic statement concerning sys-tem objects must be understood as an atomic statement concerning certain attribute values of those objects. Also notethat unlike regular interpretations, an attribute interpretation does not fix the referents of the constant symbols. In Vivid,a constant symbol can dynamically come to denote an object during the course of a deduction, as more information isobtained.For the remainder of this section, fix a signature Σ = (C; R; V), an attribute structure(cid:10)(cid:11)A ={l1 : A1, . . . , lk : Ak}; Rand an attribute interpretation I of Σ into A.,Suppose now that we are given an A-system S = ({s1, . . . , sn}; A). We define a constant assignment as a com-putable partial function ρ from C to {s1, . . . , sn}; while a variable assignment is a computable total function χ from Vto {s1, . . . , sn}. We write Dom(ρ) for the domain of a constant assignment ρ, i.e., the set of all and only those constantsymbols for which ρ is defined. A total constant assignment will usually be written as (cid:15)ρ, with the hat indicating that themapping is total. We require Dom(ρ) to be computable, for any ρ. Further, when ρ is finite, Dom(ρ) should be effectivelyobtainable from ρ. We say that two constant assignments ρ1 and ρ2 have a conflict iff there is some c ∈ Dom(ρ1) ∩ Dom(ρ2)such that ρ1(c) (cid:4)= ρ2(c). Therefore, if Dom(ρ1) ⊇ Dom(ρ2), then ρ1 and ρ2 have a conflict iff ρ1 (cid:4)⊇ ρ2.Formulas F over Σ are defined as usual, with a term t being either a variable or a constant symbol. We omit definitionsof standard notions such as free variable occurrences, alphabetic equivalence, etc.22 We write FV(F ) for the set of variablesthat occur free in a formula F , and CS(F ) for the set of all constant symbols that occur in F . We regard alphabeticallyequivalent formulas as identical. A sentence is a formula without any free variable occurrences. For any term t, we definetρ,χ as ρ(c) if t is a constant symbol c and as χ (v) if t is a variable v. Since ρ is a partial function, tρ,χ may be undefined.We write tρ,χ ↑ to indicate that tρ,χ is undefined, and tρ,χ ↓ to indicate that it is defined.22 Consult any textbook on mathematical logic for details.1378K. Arkoudas, S. Bringsjord / Artificial Intelligence 173 (2009) 1367–1405By a named state we mean a pair (σ ; ρ) consisting of a state σ and a constant assignment ρ. We say that a namedis an extension of σ (i.e., σ (cid:9) (cid:13) σ ) andstate (σ (cid:9); ρ(cid:9)) is an extension of a named state (σ ; ρ), written (σ (cid:9); ρ(cid:9)) (cid:13) (σ ; ρ), iff σ (cid:9)ρ(cid:9) ⊇ ρ (viewing the partial functions ρ and ρ(cid:9)as sets of ordered pairs). Note that (cid:13) is covariant on the state componentsbut contravariant on the constant assignments. We say that (σ (cid:9); ρ(cid:9)) is a proper extension of (σ ; ρ), written (σ (cid:9); ρ(cid:9)) (cid:2)(σ ; ρ), iff (σ (cid:9); ρ(cid:9)) (cid:13) (σ ; ρ) and σ (cid:9) (cid:2) σ or ρ(cid:9) ⊃ ρ. Further, (σ (cid:9); ρ(cid:9)) is a finite extension of (σ ; ρ) iff (σ (cid:9); ρ(cid:9)) (cid:13) (σ ; ρ) and∞the difference ρ(cid:9) \ ρ is finite. We write (σ (cid:9); ρ(cid:9))(cid:2) (σ ; ρ)) to indicate that (σ (cid:9); ρ(cid:9)) is a finite extension(respectively, a finite proper extension) of (σ ; ρ). A named state (σ ; ρ) is called a world iff σ is a world (every ascriptionof σ is a valuation) and ρ is total.23 As before, worlds do not have any extensions. If (σ (cid:9); ρ(cid:9)) (cid:13) (σ ; ρ) we might say that(σ (cid:9); ρ(cid:9)) is obtainable from (σ ; ρ) by thinning, or conversely, that (σ ; ρ) is obtainable from (σ (cid:9); ρ(cid:9)) by widening. By anassumption base β we mean a finite set of formulas. We write FV(β) and CS(β) to denote the set of all variables that havefree occurrences in some element of β, and the set of all constant symbols that appear in some element of β, respectively.A context is a pair γ = (β; (σ ; ρ)) consisting of an assumption base β and a named state (σ ; ρ). Note that since theidentity relation on each attribute is required to be decidable (by the computability proviso of Definition 1), the relation(σ1; ρ1) (cid:13) (σ2; ρ2) is decidable whenever at least one ρi is finite.∞(cid:13) (σ ; ρ) (or (σ (cid:9); ρ(cid:9))Lemma 1. The relation (cid:13) is a quasi-order on named states, i.e., it is reflexive and transitive.We will now show how to assign a truth value—or an unknown token—to any formula F , given an arbitrary namedstate (σ ; ρ) (of an A-system S = ({s1, . . . , sn}; A)) along with a variable assignment χ . This is done by formally defining amapping I(σ ;ρ)/χ from the set of all formulas to the three-element set{true, false, unknown}as follows.We begin by defining the truth value of a formula F not with respect to an arbitrary state σ (and assignments ρ and χ ),[F ]. We will afterwards definebut only with respect to a given world w (as well as ρ and χ ). This is denoted by V II(σ ;ρ)/χ (F ) in terms of V I[F ] for w (cid:13) σ .(w;ρ)/χ(w;ρ)/χFirst, the constants true and false are self-evaluating:V I(w;ρ)/χ[true] = true and V I(w;ρ)/χ[false] = false.Next, consider an atomic formula R(t1, . . . , tn), where R is a relation symbol of arity n and profile(cid:12)(li1; j1) · · · (lim(cid:13); jm).We have:V I(w;ρ)/χ(cid:12)(cid:13)R I (t1, . . . , tn)=⎧⎪⎨⎪⎩unknown if ∃ k ∈ {1, . . . , m} . ttrueρ,χjk↑;ρ,χif R I (w(li1 , tj1if ¬R I (w(li1 , t), . . . , w(lim , tρ,χjm), . . . , w(lim , t));ρ,χjmρ,χj1)).false(4)(5)The semantics of the remaining connectives are given in accordance with the strong 3-valued Kleene scheme, as shown inFig. 3. Conditionals F ⇒ G are treated as disjunctions ¬F ∨ G, and biconditionals F ⇔ G as conjunctions (F ⇒ G) ∧ (G ⇒ F ).Note that occurrences of symbols such as ∀ and ∃ on the right-hand sides of (5)–(10) occur as part of our metalanguageand should not be confused with object-level occurrences of these symbols in Vivid formulas. We will continue to useobject-level symbols in different capacities without explicitly calling attention to the distinction; the context will alwaysclarify the use.We now define I(σ ;ρ)/χ (F ) as follows:⎧⎨trueI(σ ;ρ)/χ (F ) =⎩false(w;ρ)/χunknown otherwise.(w;ρ)/χif V Iif V I[F ] = true for every w (cid:13) σ ;[F ] = false for every w (cid:13) σ ;(11)Example 8. Consider the signature Σ1 = (Cclock; Rclock; Vclock) where the set of constant symbols isCclock = {c1, c2, . . .}the set of variables is Vclock = {x, y, z, x1, y1, z1, . . .}, and the set of relation symbols isRclock = {PM, AM, Ahead, Behind},23 This also overloads the term “world”: sometimes it refers to a state and sometimes to a named state. Again, the context will always disambiguate theuse.K. Arkoudas, S. Bringsjord / Artificial Intelligence 173 (2009) 1367–14051379Fig. 3. Strong Kleene semantics of complex formulas with respect to individual worlds.with PM, AM unary and Ahead, Behind binary.Consider now the attribute structure(cid:10)Clock =hours : {0, . . . , 23}, minutes : {0, . . . , 59}; {R1, R2, R3, R4}(cid:11),where R1 ⊆ hours, R2 ⊆ hours,R3 ⊆ hours × minutes × hours × minutes,R4 ⊆ hours × minutes × hours × minutes,defined as follows: R1(h) ⇔ h > 11, R2(h) ⇔ h (cid:4) 11,R3(h1, m1, h2, m2) ⇔ h1 > h2 ∨ (h1 = h2 ∧ m1 > m2),andR4(h1, m1, h2, m2) ⇔ h1 (cid:4) h2 ∨ (h1 = h2 ∧ m1 (cid:4) m2).We define an interpretation I of Σ1 into this attribute structure by specifying a unique relation (in the structure) and aunique profile for each symbol in Rclock. In particular, we set PMI = R1, AMI = R2, AheadI = R3, BehindI = R4, and:;Prof (PM) =Prof (AM) =Prof (Ahead) =Prof (Behind) =(cid:13)(cid:12)(hours, 1)(cid:13)(cid:12)(hours, 1)(cid:13)(cid:12);(hours, 1), (minutes, 1), (hours, 2), (minutes, 2)(cid:13)(cid:12)(hours, 1), (minutes, 1), (hours, 2), (minutes, 2);.Example 9. Consider the system ({s1, s2}; Clock), where Clock is the attribute structure of Example 8. Let σ be the followingstate of this system:hours(s1) = {9, 13},minutes(s1) = 12,hours(s2) = 8,minutes(s2) = 27,1380K. Arkoudas, S. Bringsjord / Artificial Intelligence 173 (2009) 1367–1405and let ρ be the partial constant assignment that maps c1 to s1 and c2 to s2. There are exactly two worlds w 1 and w 2in σ , where w 1(hours, s1) = 9 and w 2(hours, s1) = 13, with w 1 and w 2 in agreement everywhere else. We claim that thesentence Ahead(c1, c2) is true in (σ ; ρ) for any variable assignment χ . Indeed, consider an arbitrary χ . Recalling theprofile of Ahead, definition (11) tells us that in order to have(cid:11)Ahead(c1, c2)= trueI(σ ;ρ)/χ(cid:10)we must haveV I(w;ρ)/χ(cid:13)(cid:12)Ahead(c1, c2)= truefor every w (cid:13) σ . It is straightforward to verify that this is the case: We have= true(cid:13)Ahead(c1, c2)V I(cid:12)(w 1;ρ)/χbecause R3(9, 12, 8, 27); and we also have= true,(cid:13)Ahead(c1, c2)V I(cid:12)(w 2;ρ)/χgiven that R3(13, 12, 8, 27).Lemma 2. If Dom(ρ) ⊇ CS(F ) then V I(w;ρ)/χ[F ] (cid:4)= unknown.Proof. A straightforward induction on the structure of F . (cid:3)(w;ρ)/χIn practice, V I[F ] is almost always true or false. By Lemma 2, there is only one way in which it can be unknown,namely, if F contains constant symbols which are not in the domain of ρ.24 Even then, the result might not be unknown.Consider, for instance, a formula such as R(c1, c2). If, as the first clause of (5) indicates, the profile of R involves only the firstargument position, then V I[R(c1, c2)] might return true or false even when c2 /∈ Dom(ρ). Alternatively, a conjunctionF 1 ∧ F 2 (or disjunction F 1 ∨ F 2) might return false (respectively, true) even if F 2 contains undefined constant symbols, etc.But certainly as long as every constant symbol that appears in the formula F is covered by ρ, the value V I[F ] willnot be unknown.(w;ρ)/χ(w;ρ)/χLemma 3. (a) If V IV I[F ] = V I(w;ρ)/χ(w;ρ)/χ(w;ρ(cid:9))/χ[F ] (cid:4)= unknown and ρ ⊆ ρ(cid:9)[F ]., then V I(w;ρ(cid:9))/χ[F ] = V I(w;ρ)/χ[F ]. (b) If Dom(ρ) ⊇ CS(F ) and ρ ⊆ ρ(cid:9)thenProof. By structural induction on F . ((b) also follows from (a) and Lemma 2.) (cid:3)Lemma 4 (Thinning preserves truth values). If (σ (cid:9); ρ(cid:9)) (cid:13) (σ ; ρ) andI(σ ;ρ)/χ (F ) (cid:4)= unknown,then I(σ (cid:9);ρ(cid:9))/χ (F ) = I(σ ;ρ)/χ (F ).The following result is readily proved by induction on the structure of F . It is the 3-valued-logic version of the standardcoincidence theorem of universal algebra and logic, which states that two variable assignments that agree on the freevariables of a formula F are indistinguishable for the purposes of determining the truth value of F .Lemma 5. If χ1(v) = χ2(v) for every variable v that has a free occurrence in F , thenI(σ ;ρ)/χ1 (F ) = I(σ ;ρ)/χ2 (F ).Lemma 6. Let R be a relation symbol of arity n and profile [(li11, . . . , n. Then:; j1) · · · (lim; jm)], and suppose that tρ,χjkis defined for every k =(cid:10)(cid:10)(cid:11)R(t1, . . . , tn)(cid:11)R(t1, . . . , tn)(cid:11)R(t1, . . . , tn)I(σ ;ρ)/χI(σ ;ρ)/χ(cid:10)I(σ ;ρ)/χ(a)(b)(c)= true= false= unknown iff(cid:11)(cid:11)(cid:10)ρ,χli1 , tj1(cid:10)ρ,χli1 , tj1(cid:10)li1 , tiff ∀a1 ∈ σiff ∀a1 ∈ σ(cid:12)∃ a1 ∈ σ(cid:10)∃ a1 ∈ σli1 , tρ,χj1(cid:11)ρ,χj1(cid:10)ρ,χlim , tjm(cid:10)ρ,χlim , tjm(cid:10)lim , t· · · ∀am ∈ σ· · · ∀am ∈ σ(cid:11)· · · ∃ am ∈ σ(cid:10)· · · ∃ am ∈ σlim , tρ,χjm(cid:11)ρ,χjm(cid:11)(cid:11). R I (a1, . . . , am);. ¬R I (a1, . . . , am);(cid:11). R I (a1, . . . , am) and(cid:13). ¬R I (a1, . . . , am).24 Since χ is always total, there is no issue of free variables of F not in the domain of χ .K. Arkoudas, S. Bringsjord / Artificial Intelligence 173 (2009) 1367–14051381The following is a direct consequence of the finite size of the ascription values, the finite number of system objects, andLemma 5.Theorem 7. I(σ ;ρ)/χ is computable for any named state (σ ; ρ) and variable assignment χ .Lemma 8. (a) I(σ ;ρ)/χ (¬F ) = true iff I(σ ;ρ)/χ (F ) = false; and (b) I(σ ;ρ)/χ (¬F ) = false iff I(σ ;ρ)/χ (F ) = true. Therefore,I(σ ;ρ)/χ (¬F ) = unknown iffI(σ ;ρ)/χ (F ) = unknown.Lemma 9. (a) I(σ ;ρ)/χ (F 1 ∧ F 2) = true iff I(σ ;ρ)/χ (F 1) = true and I(σ ;ρ)/χ (F 2) = true.(b) If I(σ ;ρ)/χ (F 1) = false or I(σ ;ρ)/χ (F 2) = false then I(σ ;ρ)/χ (F 1 ∧ F 2) = false. However, the converse is not true. In particular,we may have:I(σ ;ρ)/χ (F 1 ∧ F 2) = false,I(σ ;ρ)/χ (F 1) = unknown,I(σ ;ρ)/χ (F 2) = unknown.(c) If {I(σ ;ρ)/χ (F 1), I(σ ;ρ)/χ (F 2)} = {true, unknown} then I(σ ;ρ)/χ (F 1 ∧ F 2) = unknown.(d) If I(σ ;ρ)/χ (F 1) = unknown and I(σ ;ρ)/χ (F 2) = unknown then I(σ ;ρ)/χ (F 1 ∧ F 2) (cid:4)= true.The following result is the dual of Lemma 9.Lemma 10. (a) I(σ ;ρ)/χ (F 1 ∨ F 2) = false iff I(σ ;ρ)/χ (F 1) = false and I(σ ;ρ)/χ (F 2) = false.(b) If I(σ ;ρ)/χ (F 1) = true or I(σ ;ρ)/χ (F 2) = true then I(σ ;ρ)/χ (F 1 ∨ F 2) = true. However, the converse is not true. In particular,we may have:I(σ ;ρ)/χ (F 1 ∨ F 2) = true,I(σ ;ρ)/χ (F 2) = unknown.(c) If {I(σ ;ρ)/χ (F 1), I(σ ;ρ)/χ (F 2)} = {false, unknown} then I(σ ;ρ)/χ (F 1 ∨ F 2) = unknown.(d) If I(σ ;ρ)/χ (F 1) = unknown and I(σ ;ρ)/χ (F 2) = unknown then I(σ ;ρ)/χ (F 1 ∨ F 2) (cid:4)= false.I(σ ;ρ)/χ (F 1) = unknown,Lemma 11. (a) I(σ ;ρ)/χ (∀v . F ) = true iff I(σ ;ρ)/χ [v (cid:8)→ si ](F ) = true for every i = 1, . . . , n.(b) If I(σ ;ρ)/χ [v (cid:8)→ si ](F ) = false for some system object si , then I(σ ;ρ)/χ (∀v . F ) = false. However, the converse does not hold. Inparticular, we may have I(σ ;ρ)/χ (∀v . F ) = false even though I(σ ;ρ)/χ [v (cid:8)→ si ](F ) (cid:4)= false for every i = 1, . . . , n.The fact that universal and existential generalizations have the same logical structure as conjunctions and disjunctions,respectively, accounts for the similarity between Lemma 11 and Lemma 9, whose contents are essentially identical. Theonly ostensible difference between the two is part (c) of Lemma 9, which claims that the conjunction of true and unknowncomponents results in unknown, and which has no direct analogue in Lemma 11.25 Indeed, the counterexample in the proofof Lemma 11 depicts a situation where every instance of a universal generalization is either true or unknown and yet thegeneralization itself is false: I(σ ;ρ)/χ (∀v . F ) = false even though I(σ ;ρ)/χ [v (cid:8)→ si ](F ) (cid:4)= false for all i. The disparity here isonly apparent. The issue is that conjunctions are always binary whereas universal quantifications may have an arbitrarilylarge number of instances. In fact there is an analogue of part (c) for universal generalizations, namely: If there are onlytwo system objects s1 and s2, and I(σ ;ρ)/χ [v (cid:8)→ s1](F ) = true while I(σ ;ρ)/χ [v (cid:8)→ s2](F ) = unknown, then I(σ ;ρ)/χ (∀v . F ) =unknown. (The verification of this is an easy exercise.) But since this result has very limited applicability (only whenthere are two system objects), it is not worth stating as a lemma. Conversely, the same type of situation produced by theaforementioned counterexample would obtain for conjunctions if they were allowed to have arbitrarily many components,e.g., as in F = F 1 ∧ F 2 ∧ F 3. Then if I(σ ;ρ)/χ (F 1) = true but I(σ ;ρ)/χ (F 2) = I(σ ;ρ)/χ (F 3) = unknown, we could well haveI(σ ;ρ)/χ (F ) = false, because the two unknowns (F 2 and F 3) might result in false, which will then of course falsify the entireconjunction. Loosely speaking, every time two or more unknowns are combined conjunctively, whether in a conjunctionproper or in a universal generalization, the result might be false.The following is the analogue of the preceding lemma for existential generalizations, corresponding to Lemma 10:Lemma 12. (a) I(σ ;ρ)/χ (∃v . F ) = false iff I(σ ;ρ)/χ [v (cid:8)→ si ](F ) = false for every i = 1, . . . , n.(b) If I(σ ;ρ)/χ [v (cid:8)→ si ](F ) = true for some i ∈ {1, . . . , n}, thenI(σ ;ρ)/χ (∃v . F ) = true.However, the converse is not true. In particular, we may haveI(σ ;ρ)/χ (∃v . F ) = true25 Part (d) of Lemma 9 has a straightforward analogue in the case of Lemma 11, which was not stated explicitly in the latter because it is rather trivial.1382K. Arkoudas, S. Bringsjord / Artificial Intelligence 173 (2009) 1367–1405even thoughI(σ ;ρ)/χ [v (cid:8)→ si ](F ) (cid:4)= truefor all i ∈ {1, . . . , n}.Definition 6. A world (w; (cid:15)ρ) satisfies a formula F w.r.t. a variable assignment χ iffV I(w;(cid:15)ρ)/χ[F ] = true.We denote this by writing (w; (cid:15)ρ) |(cid:30)χ F . Likewise, we say that a world (w; (cid:15)ρ) satisfies a named state (σ ; ρ) iff (w; (cid:15)ρ) (cid:13)(σ ; ρ). This is denoted by (w; (cid:15)ρ) |(cid:30) (σ ; ρ). We say that (w; (cid:15)ρ) satisfies a context γ = (β; (σ ; ρ)) w.r.t. a given χ , written(w; (cid:15)ρ) |(cid:30)χ γ , iff (w; (cid:15)ρ) |(cid:30)χ F for every F ∈ β and (w; (cid:15)ρ) |(cid:30) (σ ; ρ). Finally, we say that a context γ entails a formula F ,written γ |(cid:30) F , iff (w; (cid:15)ρ) |(cid:30)χ γ implies (w; (cid:15)ρ) |(cid:30)χ F for all worlds (w; (cid:15)ρ) and variable assignments χ . Likewise, γ entails anamed state (σ (cid:9); ρ(cid:9)), written γ |(cid:30) (σ (cid:9); ρ(cid:9)), iff, for all worlds (w; (cid:15)ρ) and variable assignments χ , we have (w; (cid:15)ρ) |(cid:30) (σ (cid:9); ρ(cid:9))whenever (w; (cid:15)ρ) |(cid:30)χ γ .Lemma 13 (Weakening). If (β; (σ ; ρ)) |(cid:30) F then (β ∪ β(cid:9); (σ ; ρ)) |(cid:30) F ; and if (β; (σ ; ρ)) |(cid:30) (σ (cid:9); ρ(cid:9)) then(cid:10)(cid:11)(cid:9); (σ ; ρ)β ∪ β|(cid:30) (σ (cid:9); ρ(cid:9)).Lemma 14. If (β; (σ ; ρ)) |(cid:30) (σ (cid:9); ρ(cid:9)) and (β; (σ (cid:9); ρ(cid:9))) |(cid:30) F then (β; (σ ; ρ)) |(cid:30) F .Lemma 15. (β; (σ ; ρ)) |(cid:30) (σ ; ρ).Lemma 16. (β ∪ {false}; (σ ; ρ)) |(cid:30) (σ (cid:9); ρ(cid:9)).Lemma 17. If (β; (σ ; ρ)) |(cid:30) (σ (cid:9); ρ(cid:9)) and (σ (cid:9); ρ(cid:9)) (cid:13) (σ (cid:9)(cid:9); ρ(cid:9)(cid:9)) then (β; (σ ; ρ)) |(cid:30) (σ (cid:9)(cid:9); ρ(cid:9)(cid:9)).Corollary 18 (Widening is sound). If (σ ; ρ) (cid:13) (σ (cid:9); ρ(cid:9)) then (β; (σ ; ρ)) |(cid:30) (σ (cid:9); ρ(cid:9)).Definition 7. Suppose that (σ1; ρ1), . . . , (σm; ρm)(σ ; ρ) entails (σ1; ρ1), . . . , (σm; ρm) w.r.t. β, written (σ ; ρ) (cid:5)β {(σ1; ρ1), . . . , (σm; ρm)}, iff∞(cid:2) (σ ; ρ), for finite Dom(ρ), and let β be any assumption base. We say that(cid:10)(cid:11)β; (σ ; ρ)|(cid:30) (σi; ρi)for some i ∈ {1, . . . , m};i.e., iff for all worlds (w; (cid:15)ρ) and variable assignments χ , if(cid:11)β; (σ ; ρ),then there is some i ∈ {1, . . . , m} such that (w; (cid:15)ρ) |(cid:30) (σi; ρi).(w; (cid:15)ρ) |(cid:30)χ(cid:10)Theorem 19. The entailment relation of Definition 7 is decidable. That is, there is an algorithm that will take any assumption base βand any m + 1 named states (σ1; ρ1), . . . , (σm; ρm), (σ ; ρ) such that(σ1; ρ1), . . . , (σm; ρm)∞(cid:2) (σ ; ρ),for m > 0 and finite Dom(ρ), and will determine whether or not (σ ; ρ) (cid:5)β {(σ1; ρ1), . . . , (σm; ρm)}.Proof. Let F be the conjunction of all the formulas in β. Let ρ(cid:9)Dom(ρ1) ∪ · · · ∪ Dom(ρm) ∪ CS(F ) that are supersets of ρ. There are nb such assignments, where(cid:13)(cid:12)Dom(ρ1) ∪ · · · ∪ Dom(ρm) ∪ CS(F )(cid:13)(cid:12)Dom(ρ1) \ Dom(ρ)(cid:13)(cid:12)Dom(ρm) \ Dom(ρ)(cid:12)CS(F ) \ Dom(ρ)(cid:3)(cid:3)\ Dom(ρ)1, . . . , ρ(cid:9)b ==∪ · · · ∪(cid:13)(cid:3)(cid:3),(cid:3)(cid:3)(cid:3)(cid:3)∪d be all and only the constant assignments onand they can be mechanically enumerated, given that CS(F ) \ Dom(ρ) and Dom(ρi) \ Dom(ρ) are finite, i = 1, . . . , m. More-over, let ψ1, . . . , ψe be all distinct functions from FV(F ) to the set of all system objects, and let χ1, . . . , χe be arbitraryvariable assignments such that χi (cid:3) FV(F ) = ψi for every i = 1, . . . , e. Clearly, such variable assignments can also be mechan-ically generated. Now let Cbe the following decidable condition:(cid:9)∀w (cid:13) σ . ∀i ∈ {1, . . . , d} . ∀ j ∈ {1, . . . , e} . if V I(w;ρ(cid:9)i )/χ j[F ] = true then ∃ z ∈ {1, . . . , m} . (w; ρ(cid:9)i ) |(cid:30) (σz; ρz),and let C be the more general condition that appears in Definition 7:(cid:10)∀w . ∀(cid:15)ρ . ∀χ . if (w; (cid:15)ρ) |(cid:30)χthen ∃ z ∈ {1, . . . , m} . (w; (cid:15)ρ) |(cid:30) (σz; ρz),(cid:11)β; (σ ; ρ)and which quantifies over all worlds and constant and variable assignments.K. Arkoudas, S. Bringsjord / Artificial Intelligence 173 (2009) 1367–14051383In what follows we show that C(cid:9)is both necessary and sufficient for C :• C implies C(cid:9): Assume C . To show C(cid:9), pick any w (cid:13) σ , ρ(cid:9)i , and χ j , and suppose thatV I(w;ρ(cid:9)i )/χ j[F ] = true.Let (cid:15)ρ be any total constant assignment that extends ρ(cid:9)i , so that(cid:15)ρ ⊇ ρ(cid:9)i .⊇ ρ, we haveSince ρ(cid:9)i(cid:15)ρ ⊇ ρ.Further, since Dom(ρ(cid:9)i ) ⊇ CS(F ), (13), (12), and Lemma 3 yieldV I(w;(cid:15)ρ)/χ j[F ] = true,which is to say(w; (cid:15)ρ) |(cid:30)χ j β.Moreover, since w (cid:13) σ and (cid:15)ρ ⊇ ρ, we have(12)(13)(14)(15)(16)(w; (cid:15)ρ) |(cid:30) (σ ; ρ).(17)Hence, by (16) and (17), (w; (cid:15)ρ) |(cid:30)χ j (β; (σ ; ρ)). Therefore, by C , we infer that (w; (cid:15)ρ) |(cid:30) (σz; ρz) for some z ∈ {1, . . . , m},i.e.,(cid:3) Dom(ρz), since (cid:15)ρ ⊇ ρ(cid:9)i and Dom(ρ(cid:9)i ) ⊇ Dom(ρz). Therefore, (19) gives ρ(cid:9)i. To show C , consider any (w; (cid:15)ρ) and any χ such thatw (cid:13) σzand(cid:15)ρ ⊇ ρz.But (cid:15)ρ (cid:3) Dom(ρz) = ρ(cid:9)(w; ρ(cid:9)i ) |(cid:30) (σz; ρz).(cid:9)implies C : Assume C(cid:10)(w; (cid:15)ρ) |(cid:30)χi(cid:9)• C(cid:11)β; (σ ; ρ),so thatV I(w;(cid:15)ρ)/χ[F ] = trueand (w; (cid:15)ρ) (cid:13) (σ ; ρ), and henceandw (cid:13) σ(cid:15)ρ ⊇ ρ.(18)(19)⊇ ρz, and hence, by (18),(20)(21)(22)(23)We need to prove that there is some z ∈ {1, . . . , m} such that (w; (cid:15)ρ) (cid:13) (σz; ρz). Letρ(cid:9) = (cid:15)ρ (cid:3)(cid:13)(cid:12)Dom(ρ1) ∪ · · · ∪ Dom(ρm) ∪ CS(F ).Since (cid:15)ρ ⊇ ρ and ρi ⊇ ρ for every i, we conclude ρ(cid:9) ⊇ ρ, which means that we must have ρ(cid:9) = ρ(cid:9)Further, let χ j = χ (cid:3) FV(F ). By (21), Lemma 3, and Lemma 5, we inferi for some i ∈ {1, . . . , d}.V I(w;ρ(cid:9)i )/χ j[F ] = true,and hence, by Cinfer (cid:15)ρ ⊇ ρz and hence (w; (cid:15)ρ) (cid:13) (σz; ρz). (cid:3)(cid:9), (w; ρ(cid:9)i ) (cid:13) (σz; ρz) for some z ∈ {1, . . . , m}. Since ρ(cid:9)i= ρ(cid:9), that entails ρ(cid:9) ⊇ ρz, and since (cid:15)ρ ⊇ ρ(cid:9), weAlthough the above result is important for mechanizing the semantics of Vivid, its significance is primarily theoretical.In most cases it would be infeasible to decide entailment by carrying out the above procedure. The principal difficulty isthat the procedure requires iteration over all worlds w (cid:13) σ , and when the number of such worlds is very large (e.g., 1010or higher), such iteration would be wildly impractical. We have developed methods that can often decide the entailmentrelation much more efficiently, capable of providing results even in some cases where the number of worlds is astronomi-cally large. There is not enough space in this paper to describe these developments in detail, but a flavor will be given inSection 7.1384K. Arkoudas, S. Bringsjord / Artificial Intelligence 173 (2009) 1367–14056. A family of diagrammatic natural deduction languagesWe now formally define Vivid, a family of natural deduction languages in the DPL vein [4] that combine sentential anddiagrammatic reasoning. A concrete instance of Vivid is obtained by specifying a vocabulary Σ = (C, R, V), an attributestructure A = ({l1 : A1, . . . , lk : Ak}; R), and an interpretation I of Σ into A. We assume in what follows that Σ , A, andI have been fixed. The terms and formulas of the language are as described in Section 5. We write F [t/v] to denote theformula obtained from F by replacing every free occurrence of v by the term t (taking care to rename F if necessary toavoid variable capture). The following result is proved by induction on the structure of F .Lemma 20. If b ∈ {true, false},(w;ρ)/χ [v(cid:8)→s][F ] = b,V I(cid:9)and vdoes not occur in F , then(cid:13)/v](w;ρ)/χ [v(cid:9)(cid:8)→s]F [vV I(cid:12)(cid:9)= b.6.1. Abstract syntaxThere are two syntactic categories of proofs, sentential and diagrammatic. Sentential deductions are used to derive for-mulas, while diagrammatic deductions are used to derive diagrams. We will see that the two can be freely mixed, andindeed that their structures are mutually recursive. We use the letters D and (cid:12) to range over sentential and diagrammaticdeductions, respectively. The symbol D will range over the union of the two. The abstract syntax [46] of both proof typesis defined by the grammars below:D ::= RuleApp| assume F D|F by D| D; D| pick-any x D| pick-witness w for ∃ x . F D|| ex-generalize ∃ x . F from t|| observe Fspecialize ∀x1 · · · xn . F with t1, . . . , tncases by F 1, . . . , Fk: (σ1; ρ1)→D1 | · · · | (σn; ρn)→Dn(cid:12) ::= D; (cid:12)claim (σ ; ρ)(σ ; ρ) by thinning with F 1, . . . , Fn(σ ; ρ) by widening(σ ; ρ) by absurditycases by F 1, . . . , Fk: (σ1; ρ1)→(cid:12)1 | · · · | (σn; ρn)→(cid:12)ncases F 1 ∨ F 2: F 1→(cid:12)1 | F 2→(cid:12)2||||||| pick-witness w for ∃ x . F (cid:12)D ::= D|(cid:12)where the syntax of inference rule applications is as follows:true-introfalse-elimRuleApp ::= claim F||| modus-ponens F ⇒ G, F| modus-tollens F ⇒ G, ¬G| double-negation ¬ ¬F| absurd F , ¬Fleft-and F ∧G||right-and F ∧G| both F , G|left-either F , G|right-either F , Gcases F 1 ∨ F 2, F 1 ⇒ G, F 2 ⇒ G|left-iff F ⇔ G||right-iff F ⇔ G| equiv F ⇒G, G ⇒ FK. Arkoudas, S. Bringsjord / Artificial Intelligence 173 (2009) 1367–14051385The composition operator “;” associates to the right by default, so D1; D2; D3 stands forD1; (D2; D3)rather than (D1; D2); D3. Parentheses or begin–end pairs can be used to change the default grouping.We define D [t/x] as the deduction obtained from D by replacing every free occurrence of the variable x by the term t,taking care to perform α-conversion as necessary to avoid variable capture. The definition is given by structural recursion:(D1; D2) [t/x] = D1 [t/x]; D2 [t/x]((σ ; ρ) by thinning with F 1, . . . , Fn) [t/x] = (σ ; ρ) by thinning with F 1 [t/x], . . . , Fn [t/x](cases by F 1, . . . , Fk:(σ1; ρ1)→(cid:12)1 | · · · | (σn; ρn)→(cid:12)n) [t/x](cases F 1 ∨ F 2:F 1→(cid:12)1 | F 2→(cid:12)2)[t/x]==cases by F 1 [t/x], . . . , Fk [t/x]:(σ1; ρ1)→(cid:12)1 [t/x] | · · · | (σn; ρn)→(cid:12)n [t/x]cases F 1 [t/x] ∨ F 2 [t/x]:F 1 [t/x]→(cid:12)1 [t/x] | F 2 [t/x]→(cid:12)2 [t/x](pick-witness x for ∃ y . F (cid:12))[t/x] = pick-witness x for (∃ y . F ) [t/x](cid:12)(pick-witness w for ∃ y . F (cid:12))[t/x](when x (cid:4)= w)= pick-witness w for (∃ y . F ) [t/x](cid:12) [t/x](pick-any x D) [t/x] = pick-any x D(pick-any y D) [t/x](when x (cid:4)= y)= pick-any y D [t/x]We omit the defining equations for the sentential pick-witness, which is handled like the diagrammatic pick-witness;and for the remaining cases by, which is treated like the one above. The definition for the other forms is straightforwardand can be found elsewhere [4]. In all cases we assume that the deduction has been α-renamed away from the given term t.6.2. Evaluation semanticsOur formal semantics is given by rules that establish judgments of the formγ (cid:31) D (cid:4) Fandγ (cid:31) (cid:12) (cid:4) (σ ; ρ),which are read as follows:“In the context γ , deduction D ((cid:12)) derives F (respectively, (σ ; ρ)).”We refer to rules that derive judgments of the former sort as “sentential,” since they prescribe the behavior of sentential de-ductions; while rules that derive the second sort of judgment are called diagrammatic, since they prescribe the operationalmeaning of diagrammatic deductions.The semantics of most sentential deductions are straightforward generalizations of the standard DPL semantics for natu-ral deduction [4]. We illustrate here with the axiom for left-and and the rule for assume, omitting the rest:(β ∪ {F ∧ G}; (σ ; ρ)) (cid:31) left-and F ∧ G (cid:4) F(β ∪ {F }; (σ ; ρ)) (cid:31) D (cid:4) G(β; (σ ; ρ)) (cid:31) assume F D (cid:4) F ⇒ GIn addition, for convenience, we introduce the sentential formF by absurdity(24)as syntax sugar for the following sentential deduction:assume ¬Fclaim false; // This gives ¬F ⇒ false, provided that false is in the assumption base// This gives ¬falsefalse-elim;modus-tollens ¬F ⇒ false, ¬false; // This gives ¬¬Fdouble-negation ¬¬F// Finally, this produces F1386K. Arkoudas, S. Bringsjord / Artificial Intelligence 173 (2009) 1367–1405Accordingly, this desugaring ensures that the semantics of (24) are as follows:(β ∪ {false}; (σ ; ρ)) (cid:31) F by absurdity (cid:4) FSome additional syntax sugar is introduced later (p. 1395).The only new sentential forms (i.e., not present in N DL) are observe, cases by, and (cid:12); D. We will discuss the last twolater; the semantics of observe are as follows:(β; (σ ; ρ)) (cid:31) observe F (cid:4) Fprovided that I(σ ;ρ)/χ (F ) = true for all χ[Observe]This rule is used to extract sentential information from diagrams. The side condition is computable because of Lemma 7and because, by Lemma 5, we only need to be concerned with the free variables of F . In fact usually F is a sentence (it hasno free variables), and hence we only need to consider the empty variable assignment ∅.We now turn to the semantics of the various Vivid constructs for case analysis. There are four types of case reasoning inVivid:Sentential-to-sentential:In this type of reasoning we note that a disjunction F 1 ∨ F 2 holds and that a formula G followsin either case. That entitles us to conclude G. This is captured syntactically as a rule application:cases F 1 ∨ F 2, F 1 ⇒ G, F 2 ⇒ G.The semantics of such rule applications carry over from standard symbolic logic unchanged, since there is nodiagram manipulation involved:(β ∪ {F 1 ∨ F 2, F 1 ⇒ G, F 2 ⇒ G}; (σ ; ρ)) (cid:31) cases F 1 ∨ F 2, F 1 ⇒ G, F 2 ⇒ G (cid:4) GSentential-to-diagrammatic: Here we note that a disjunction F 1 ∨ F 2 holds and proceed to show that a certain diagram(σ ; ρ) follows in either case. This is captured by the syntax formcases F 1 ∨ F 2:F 1 → (cid:12)1 | F 2 → (cid:12)2,which is classified as a diagrammatic deduction (“a (cid:12)”) since the end result is a diagram. The semantics of thisform are given by rule [C2], shown in Fig. 4.Diagrammatic-to-sentential: We note that on the basis of the present diagram and some formulas F 1, . . . , Fk in the as-sumption base, k (cid:2) 0, one of n > 0 other system states (σ1; ρ1), . . . , (σn; ρn) must obtain, and proceed to showthat a formula F can be derived in every one of these n cases. This entitles us to infer F , provided of course thatthe n diagrammatic cases are indeed exhaustive. This form of reasoning is captured by the formcases by F 1, . . . , Fk: (σ1; ρ1) → D1 | · · · | (σn; ρn) → Dn.This is classified as a sentential deduction, since the end result is a formula F . Its semantics are shown in Fig. 5.The caveat that the diagrams (σ1; ρ1), . . . , (σn; ρn) form an exhaustive set of possibilities on the basis of F 1, . . . , Fkand the current diagram is formally captured by the proviso(σ ; ρ) (cid:5){F 1,...,Fk}(cid:2)(cid:4)(σ1; ρ1), . . . , (σn; ρn).When k = 0, the by keyword is omitted, and we simply writecases: (σ1; ρ1) → D1 | · · · | (σn; ρn) → Dn.Diagrammatic-to-diagrammatic: This is similar to the above mode of reasoning, except that instead of deriving a formulaF in each of the n cases, we derive a diagram. Therefore, syntactically, following each of the n cases we havediagrammatic deductions (cid:12)1, . . . , (cid:12)n (rather than sentential deductions D1, . . . , Dn as we did above), and theentire form is classified as a diagrammatic deduction, since the final conclusion is a diagram. The following syntaxform is used for such deductions:cases by F 1, . . . , Fk: (σ1; ρ1) → (cid:12)1 | · · · | (σn; ρn) → (cid:12)n.The corresponding semantics are given by rule [C1], shown in Fig. 4. Again, we might have k = 0, and in that casethe by keyword is omitted.Likewise, there are four types of deduction sequencing:1. D1; D2, where a sentential deduction D1 is composed with another sentential deduction D2. This form is classified asa sentential deduction, since the end result is a formula (the conclusion of D2). Its semantics are given by rule [D; D]of Fig. 4. They are isomorphic to the regular composition semantics of DPLs, since there is no diagram manipulationinvolved.K. Arkoudas, S. Bringsjord / Artificial Intelligence 173 (2009) 1367–14051387Fig. 4. Formal semantics of diagrammatic deductions.2. D; (cid:12), where a sentential deduction D is composed with a diagrammatic deduction. This form is classified as a diagram-matic deduction since the end result is a diagram—the conclusion of (cid:12). Its semantics are prescribed by rule [D; (cid:12)].Observe that the conclusion of D becomes available to (cid:12) (e.g., the conclusion of D could be a disjunction and (cid:12) mightbe a diagrammatic case analysis of that disjunction).3. (cid:12); D, where a diagrammatic deduction (cid:12) is composed with a sentential deduction. This form is classified as a sententialdeduction since the end result is a formula (the conclusion of D). Its semantics are given by rule [(cid:12); D]. Conclusionthreading here is also intuitive: D will be evaluated in the system state resulting from the evaluation of (cid:12). E.g., D mightbe an observe deduction that points out something that can be seen in the diagram derived by (cid:12).1388K. Arkoudas, S. Bringsjord / Artificial Intelligence 173 (2009) 1367–1405Fig. 5. Semantics of diagrammatic-to-sentential case reasoning.4. (cid:12)1; (cid:12)2, where a diagrammatic deduction (cid:12)1 is composed with another diagrammatic deduction (cid:12)2. This form isclassified as a diagrammatic deduction, since the end result is a diagram (the conclusion of (cid:12)2). Its semantics are givenby rule [(cid:12); (cid:12)]. The same principle of conclusion threading applies here: (cid:12)2 is evaluated in the system state resultingfrom the evaluation of (cid:12)1; the assumption base is threaded through unchanged.We briefly discuss the remaining rules of Fig. 4. [Thinning] is probably the most frequently used rule for heterogeneousinference in Vivid. It allows us to refine the current state by ruling out worlds that are inconsistent with the cited formulas.[Widening] can be seen as the inverse of thinning, entitling us to “lose information” by increasing rather than decreasing thenumber of possible worlds that satisfy the current state. This can be useful in getting the diagrammatic branches of a caseanalysis to be identical. [Absurdity] entitles us to infer any diagram whatsoever from a contradiction. [Diagram-Reiteration]allows us to retrieve the current diagram. [EI/(cid:12)] is a diagrammatic version of existential instantiation, whereby we unpackan existential quantification by choosing a witness and then proceed with a diagrammatic deduction.Theorem 21 (Soundness). If γ (cid:31) D (cid:4) F then γ |(cid:30) F ; and if γ (cid:31) (cid:12) (cid:4) (σ ; ρ) then γ |(cid:30) (σ ; ρ).Theorem 22 (Computability). The proof-checking problem for Vivid is decidable. That is, there is an algorithm that will take any proofD, context (β; (σ ; ρ)), and result r (proposition or diagram), and will determine whether or not (β; (σ ; ρ)) (cid:31) D (cid:4) r.Proof. A straightforward induction on the structure of D will provide a recursive definition of the requisite proof-checkingalgorithm. An inspection of the evaluation rules of the language will confirm that all of them are computable. The onlyinteresting cases are rules with side conditions involving either the function I(σ ;ρ)/χ or the entailment relation (cid:5), both ofwhich are computable (by Theorem 7 and Theorem 19, respectively). (cid:3)Example 10. Consider the Vivid language obtained by fixing the clock signature, attribute structure and interpretation ofExample 8. Now consider a system of two clocks s1 and s2, to which we will give the names c1 and c2 (recall that c1 andc2 are constant symbols of the signature, so this is a constant assignment ρ, which need only be partial). Now let σ be thestate depicted by the following picture.26{4, 5, 6}:28c15:45c2Intuitively, this state signifies that we know the precise time displayed by s2 (5:45 am). We are also sure of the minutevalue of s1 (28), but not of its hour value, which could be either 4, 5, or 6. Now suppose that we are further given thepremise Ahead(c1, c2), indicating that the time displayed by s1 is ahead of that displayed by s2.From these two pieces of information, one diagrammatic and the other sentential, we should be able to infer the follow-ing diagram, call it σ (cid:9)(which is, in fact, a world):6:28c15:45c2That is, we should be able to conclude the exact time of s1, since, given that s1 is ahead of s2, the hour displayed by itcannot possibly be 4 or 5; it must, therefore, be 6. We can do this in Vivid with the following one-line proof:(σ (cid:9); ρ) by thinning with Ahead(c1, c2).26 An exceedingly simple picture, but a picture nonetheless. This example is used here only because its simplicity makes it ideal for exposition purposes,not because it provides a compelling demonstration of the utility of diagrams in problem solving.K. Arkoudas, S. Bringsjord / Artificial Intelligence 173 (2009) 1367–14051389This deduction, when evaluated in a context of the form (β ∪ {Ahead(c1, c2)}; (σ ; ρ)), will result in the state (diagram)(σ (cid:9); ρ). More formally, we have:(cid:10)β ∪(cid:2)(cid:4)Ahead(c1, c2)(cid:11); (σ ; ρ)(cid:31) (σ (cid:9); ρ) by thinning with Ahead(c1, c2) (cid:4) (σ (cid:9); ρ)by virtue of(σ ; ρ) (cid:5){Ahead(c1,c2)} (σ (cid:9); ρ).(25)Note that ρ does not change in the resulting state.To establish (25) rigorously, we must show that for all worlds (w; (cid:15)ρ) and variable assignments χ , if(w; (cid:15)ρ) |(cid:30)χ(cid:10)(cid:2)(cid:4)Ahead(c1, c2)(cid:11); (σ ; ρ)then (w; (cid:15)ρ) |(cid:30) (σ (cid:9); ρ). That is, intuitively, if any world (w; (cid:15)ρ) consistent with the current state (σ ; ρ)—i.e., such that(w; (cid:15)ρ) (cid:13) (σ ; ρ)—satisfies the formula Ahead(c1, c2), w.r.t. any χ , then that world must be consistent with (σ (cid:9); ρ), i.e.,we must have (w; (cid:15)ρ) (cid:13) (σ (cid:9); ρ). To that end, pick any (w; (cid:15)ρ) (cid:13) (σ ; ρ) and any χ such thatV I(w;(cid:15)ρ)/χ(cid:12)(cid:13)Ahead(c1, c2)= true.(26)There are, in fact, only three worlds w (cid:13) σ :w 1:w 2:w 3:hours(s1) = {4}, minutes(s1) = {28},hours(s1) = {5}, minutes(s1) = {28},hours(s1) = {6}, minutes(s1) = {28},hours(s2) = {5}, minutes(s1) = {45};hours(s2) = {5}, minutes(s1) = {45};hours(s2) = {5}, minutes(s1) = {45}.Now (26) does not hold for w = w 1 and w = w 2, so we do not need to consider these two worlds. For the third and lastpossibility, we do have(w 3; (cid:15)ρ) |(cid:30)χ(cid:11); (σ ; ρ)(again, for arbitrary (cid:15)ρ ⊇ ρ and χ ), and the result follows because (w 3; (cid:15)ρ) (cid:13) (σ (cid:9); ρ).(cid:4)Ahead(c1, c2)(cid:10)(cid:2)7. ImplementationA quick inspection of the formal semantics of Vivid, in particular the [Observe] rule (p. 1386) and the rules for theremaining constructs (Figs. 4 and 5) reveals that there are two operations that must be implemented in order to mechanizethese semantics:1. evaluating a formula in a given named state and variable assignment; and2. deciding the entailment relation of Definition 7.From these two, the second is much more likely to become a bottleneck, since it may need to invoke the first operation(formula evaluation) a very large number of times. A naive implementation of these operations in terms of the definitionsand results given so far (specifically, in terms of Definition 11 and Theorem 19) would be unacceptably inefficient. This isprimarily because such an implementation might require, in the worst case, iteration over all worlds extending the givenstate. While such iteration may be feasible in some cases, in many other cases it will be practically impossible, as the givenstate will simply be too large.There are several avenues for arriving at more efficient implementations. One of them is to translate both diagramsand Vivid formulas into propositional-logic sentences in conjunctive normal form, model both problems as satisfiabilityquestions, and tackle them with off-the-shelf SAT solvers. The translation would be fairly straightforward, as a state isessentially a CNF sentence asserting that the value of the first attribute for the first object is v 1 or v 2 or . . .; and the value(cid:9)2 or . . .; and so on. For instance, let σ be the following state of a systemof the second attribute for the first object is vcomprising two objects s1 and s2, and two attributes, color and size:(cid:9)1 or vσcolor(s1) = {Red, Blue}size(s1) = {Small, Medium, Large}color(s2) = {Red, Blue, Green}size(s2) = {Medium, Large}This state can be represented by the CNF sentence:(Red1 ∨ Blue1) ∧ (Small1 ∨ Medium1 ∨ Large1) ∧ (Red2 ∨ Blue2 ∨ Green2) ∧ (Medium2 ∨ Large2).1390K. Arkoudas, S. Bringsjord / Artificial Intelligence 173 (2009) 1367–1405The number of boolean variables in such a straightforward translation would be linear in the sizes of the ascriptions andthe number of system objects. The translations for named states would need to be more complicated to account for con-stant assignments. Translations of Vivid formulas would have to be carried out on an individual basis, in accordance withthe definitions of the various relations in the underlying attribute structure. Formula evaluation would then become tan-tamount to implication. Countermodels found by the SAT solver would be translated back to Vivid states and displayeddiagrammatically. We have implemented such SAT-based instances of Vivid and found their performance to be adequate formost practical purposes. Alternatively, OBDDs could be used to represent both system states and Vivid formulas, althoughwe have not had any practical experience with such implementations.While such approaches are fairly straightforward and might often result in acceptable implementations, we observe thatthe problems in question have a good deal of structure that we can sometimes exploit to arrive at efficient solutions evenin cases well beyond the reach of the current state of the art of SAT solvers or OBDDs, namely, cases with many thousandsof boolean variables and millions of clauses. That is not always achievable, of course, and in some cases the specializedtechniques we have developed are outperformed by more straightforward implementations relying on generic technologies.Fortunately, it is easy to determine ahead of time whether or not the custom-made techniques will be profitable by per-forming a few simple calculations. The appropriate implementation technology can then be selected on the basis of thoseresults. We do not have enough space here to present these techniques, most of which are based on treating states aslanguages, and specifically as acyclic deterministic finite automata (ADFA); more details can be found in the longer on-line report. Here we will only give a glimpse of how the first problem can be tackled—evaluating a formula in a givenstate—without explicitly carrying out the evaluation in every world of that state, as a naive reading of Definition 11 wouldsuggest.Lemma 6 along with Lemmas 8 through 12 already point to the main idea for short-circuited formula evaluation thatavoids such iteration, but the caveats of the conjunction and disjunction lemmas (and the similar caveats for universal andexistential quantifications) mean that an evaluation technique based directly on those lemmas would not be universallyapplicable. For instance, if we are evaluating a conjunction F 1 ∧ F 2 and the short-circuited evaluation of both F 1 and F 2returns unknown, there is no specific value we can infer for the conjunction; the result could be either false or unknown.In such cases we would need to revert to exhaustive formula evaluation in every world of the given state. The simple ideabelow can avoid this problem in many cases.For any given F , ρ, and χ , the basis of F w.r.t. ρ and χ , denoted B(F , ρ, χ ), is a set of a.o. pairs (or an error token ∞).It is defined by structural recursion on F , as shown below. The third clause covers atomic formulas, for an arbitrary relationsymbol of arity n and profile Prof (R) = [(li1; j1) · · · (lim; jm)]:B(true, ρ, χ ) = ∅;B(false, ρ, χ ) = ∅;(cid:10)BR(t1, . . . , tn), ρ, χ(cid:9)(cid:11)=; tρ,χj1{(li1∞), . . . , (lim; tρ,χjm)}↓ for every i ∈ {1, . . . , m};ρ,χjiif totherwise;B(¬F , ρ, χ ) = B(F , ρ, χ );B(F 1 ∧ F 2, ρ, χ ) = B(F 1, ρ, χ ) ∪ B(F 2, ρ, χ );B(F 1 ∨ F 2, ρ, χ ) = B(F 1, ρ, χ ) ∪ B(F 2, ρ, χ );(cid:10)n(cid:20)(cid:11)F , ρ, χ [v (cid:8)→ si];BB(∀v . F , ρ, χ ) =B(∃v . F , ρ, χ ) =i=1n(cid:20)i=1(cid:10)(cid:11)F , ρ, χ [v (cid:8)→ si].BTo keep the notation simple, we have assumed that the set-theoretic union operation in the above identities is strict w.r.t.to ∞, i.e., that S1 ∪ · · · ∪ Sn = ∞ whenever S i = ∞ for some i ∈ {1, . . . , n}.For any two lists L1 and L2, and any set S of positive integers, define L1 ≡S L2 as follows:L1 ≡S L2 ⇔(cid:12)(cid:13)∀x ∈ S . L1(x) = L2(x).(27)(Note that L1 ≡∅ L2 for any lists L1 and L2.) That is, two lists L1 and L2 are identical w.r.t. a set of positions S iff they haveidentical elements in each position in S. It is easily verified that this is an equivalence relation (for fixed S). Likewise, forany two worlds w 1 and w 2, and any set S of a.o. pairs, definew 1 ≡S w 2 ⇔(cid:13)(cid:12)∀(l; s) ∈ S . w1(l, s) = w2(l, s).(28)If we think of worlds as strings, then the above definition is isomorphic to (27), with a.o. pairs playing the role of stringpositions. The following is a trivial consequence of the above definition, but useful enough to isolate as a lemma:Lemma 23. If w 1 ≡S w 2 then w 1 ≡S(cid:9) w 2 for every S(cid:9) ⊆ S.K. Arkoudas, S. Bringsjord / Artificial Intelligence 173 (2009) 1367–14051391The next result has important efficiency implications for formula evaluation. Its practical upshot is that in evaluating aformula F in a certain state σ and assignments ρ and χ , we only need to consider worlds that differ along the coordinatesin B(F , ρ, χ ). For any w (cid:13) σ , attribute values of w for a.o. pairs not in B(F , ρ, χ ) can be ignored. As will be illustrated,the resulting savings can be significant.Theorem 24. If B(F , ρ, χ ) (cid:4)= ∞ and w 1 ≡B(F ,ρ,χ ) w 2, then V I(w1;ρ)/χ[F ] = V I(w2;ρ)/χ[F ].To illustrate the utility of the above result, consider again the system of the two clocks s1 and s2 of Example 9, and letσ be the following state of that system:σ (hours, s1) = {9, 16, 17};σ (minutes, s1) = {0, 1, 2, . . . , 59};σ (hours, s2) = {5, 18};σ (minutes, s2) = {10, 11, . . . , 59}.Viewed as an ADFA, σ can be depicted as follows:This state contains 3 · 60 · 2 · 50 = 18,000 worlds. Consider now the formula F = ∀x . PM(x), asserting that every clock’s timeis p.m. This formula is true in some worlds (e.g., when hours(s1) = 17, minutes(s1) = 2, hours(s2) = 18, minutes(s2) = 39),and false in others (e.g., when hours(s1) = 9, minutes(s1) = 44, hours(s2) = 18, minutes(s2) = 4). Thus, as is readily verified,we have:(cid:10)(cid:11)∀x . PM(x)I(σ ;ρ)/χ= unknown(29)for arbitrary ρ and χ . However, if we simply tried to compute Iρ/χ [x (cid:8)→ s1](PM(x)) and Iρ/χ [x (cid:8)→ s2](PM(x)), we would obtainunknown and unknown, respectively, and therefore, by part (b) of Lemma 11, we would not be able to infer (29), becauseit would not be possible to rule out the possibility I(σ ;ρ)/χ (∀x . PM(x)) = false. Accordingly, we would need to resort tocalculatingV I(w;ρ)/χ(cid:12)(cid:13)∀x . PM(x)for every w (cid:13) σ . But that could be very inefficient. Depending on how we iterate through the space of 18,000 worlds, wemight have to evaluate ∀x . PM(x) over one hundred times before we find two worlds w i and w j such that(cid:12)(cid:13)∀x . PM(x)(cid:13)∀x . PM(x)= true and V I= false,V I(cid:12)(w i;ρ)/χ(w j;ρ)/χwhich would allow us to arrive at the answer (29).But examining all these worlds is unnecessary for a simple reason: The minutes attribute of a clock is irrelevant indetermining whether or not the clock’s time is p.m. Only the value of hours is necessary for making that judgment. Ifthat value is greater than 11, then the clock is p.m., otherwise it is not. By taking advantage of this information, which isprovided by the profile of PM, we can restrict attention only to the hours attribute of the two clocks. That is precisely whatthe basis of F enables us to do:1392K. Arkoudas, S. Bringsjord / Artificial Intelligence 173 (2009) 1367–1405Arbitrary values can be selected for the minutes attribute, say 0 for minutes(s1) and 10 for minutes(s2). We can then nar-row down the relevant space from 18,000 worlds to only 6 worlds w 1, . . . , w 6, formed by choosing a value for hours(s1)(three choices) followed by a value for hours(s2) (two choices), and keeping minutes(s1) and minutes(s2) fixed to 0 and 10,respectively:w 1(hours, s1) = 9w1(minutes, s1) = 0 w 1(hours, s2) = 5w 1(minutes, s2) = 10;w 2(hours, s1) = 9w2(minutes, s1) = 0 w 2(hours, s2) = 18 w 2(minutes, s2) = 10;w 3(minutes, s2) = 10;w 3(hours, s1) = 16 w3(minutes, s1) = 0 w 3(hours, s2) = 5w 4(hours, s1) = 16 w4(minutes, s1) = 0 w 4(hours, s2) = 18 w 4(minutes, s2) = 10;w 5(hours, s1) = 17 w5(minutes, s1) = 0 w 5(hours, s2) = 5w 5(minutes, s2) = 10;w 6(hours, s1) = 17 w6(minutes, s1) = 0 w 6(hours, s2) = 18 w 6(minutes, s2) = 10.Now ∀x . PM(x) will only need to be evaluated in four worlds (w 1–w 4) before we determine the correct answer, (29).Computing B(F , ρ, χ ) allows us to perform this type of narrowing in a systematic and sound way. Roughly, atomicformulas R(t1, . . . , tn) are restricted to appropriate a.o. pairs by utilizing the profile information of R, while the basis of acomplex formula is computed recursively (and conservatively) by joining the bases of each subformula. Since computing thebasis of a formula is very cheap (linear both in time and space), we can statically analyze every formula F that needs to beevaluated in a given state σ and assignments ρ and χ by computing B(F , ρ, χ ), picking arbitrary values for the a.o. pairswhich reflect different combinations of values forwhich are not in the basis, and constructing all and only those worlds wa.o. pairs in the basis. Theorem 24 then allows us to evaluate F only w.r.t. to such worlds w.(cid:9)(cid:9)8. Seating puzzlesWe now consider a puzzle that has become somewhat of a classic in discussions of diagrammatic reasoning. Presented(and to the best of our knowledge, devised) by Barwise and Etchemendy [6], it is typical of the sort of problems found inthe analytical section of the GRE, as well as typical of cognitive science experiments investigating spatial reasoning [14].27The puzzle can be described as follows:Five people A, B, C , D, and E are to be seated in a row of five seats. The seating arrangement must satisfy the followingthree conditions:1. A and C should flank E.2. C should be closer to the middle seat than B.3. B and D should be seated next to each other.On the basis of this information:(a) Prove that E cannot be either in the middle or on either end.(b) Can it be determined who must be seated in the middle seat?(c) Can it be determined who is to be seated on the two ends?Looking ahead, all three questions are answered with one Vivid deduction, shown in Fig. 6. Note that the Vivid system weare about to present is not hardwired to this particular puzzle, but allows for the formulation and solution of a wide varietyof seating puzzles (involving arbitrarily many seats, persons, names thereof, and combinations of constraints). We have alsodefined and implemented extensions of the system to two dimensions, involving several rows of seats and relations such asabove and below.27 The puzzle is also discussed by Shin [52], by Barwise and Etchemendy [9], and others.K. Arkoudas, S. Bringsjord / Artificial Intelligence 173 (2009) 1367–14051393Fig. 6. A Vivid deduction solving the seating puzzle of Barwise and Etchemendy [6].If we make the convention that juxtaposition indicates seating adjacency, and that the left-to-right relation in the textcorresponds to the analogous relation in the row of seats, then a seating arrangement might be graphically depicted simplyas follows:A E C B D(30)Note that this particular arrangement satisfies all three constraints. We will also make the natural convention of identifyingthe five chairs from left to right with the five integers 1, . . . , 5, so that the leftmost chair is chair 1 and the rightmost ischair 5. A questionmark over a seat indicates that we do not know who (if anyone) is to be placed in that seat. Thus, forinstance, the “diagram”? ? A ? ?(31)indicates a seating arrangement in which A is seated in chair 3, but we do not know where the others are seated (otherthan the fact that they are not in the middle).We now introduce a simple Vivid language that lets us solve problems in this domain. Intuitively, the system objectswill be persons, or more abstractly, objects to be seated; and their attribute values will be seat numbers, or more precisely,sets of seat numbers, allowing for incomplete information. Accordingly, a system state will map each such object to a set ofpositive integers representing chairs. For instance, diagram (30) corresponds to the system stateseat( A) = 1,seat(E) = 2,seat(C) = 3,seat(B) = 4,seat(D) = 5,which is a world, while diagram (31) is captured by the system state:seat( A) = 3,seat(E) = {1, 2, 4, 5},seat(C) = {1, 2, 4, 5},seat(B) = {1, 2, 4, 5},seat(D) = {1, 2, 4, 5}.(32)The vocabulary for this instance of Vivid consists of the binary symbol for identity (=), along with six relation symbols,whose intuitive semantics are as follows:1. flanking(x, y, z) ≡ x and y are flanking z.2. adjacent(x, y) ≡ x and y are seated next to each other.3. atEnd(x) ≡ x is seated at an end seat (far left or far right).4. middle(x) ≡ x is seated in the middle seat.5. closerToCenter(x, y) ≡ x is seated closer to the middle seat than y.6. sameSeat(x, y) ≡ x is assigned the same seat as y. (We will show that this holds iff x = y.)1394K. Arkoudas, S. Bringsjord / Artificial Intelligence 173 (2009) 1367–1405We let x, y, z, . . . , possibly with subscripts, serve as variables. The constant names are A, B, C, D, E, . . . , also possibly withsubscripts. The attribute structure here is parameterized over the number of seats, m > 1:(cid:10)(cid:11)ASm=seat : {1, . . . , m}; {R1, R2, R3, R4, R5, R6}, with:1. R1 ⊆ {1, . . . , m} × {1, . . . , m} × {1, . . . , m}, defined as follows: R1(i, j, k) ⇔ |i − k| = | j − k| = 1 ∧ i (cid:4)= j. This interpretsflanking via the profile [(seat, 1), (seat, 2), (seat, 3)].2. R2 ⊆ {1, . . . , m} × {1, . . . , m}, defined as R2(i, j) ⇔ |i − j| = 1. This interprets adjacent via the profile [(seat, 1), (seat, 2)].3. R3 ⊆ {1, . . . , m}, defined as R3(i) ⇔ i = 1 ∨ i = m. This interprets atEnd via the profile [(seat, 1)].4. R4 ⊆ {1, . . . , m}, defined as R4(i) ⇔ i = ! m25. R5 ⊆ {1, . . . , m} × {1, . . . , m}, defined as(cid:3)(cid:3)(cid:3)(cid:3)i −". This interprets middle via the profile [(seat, 1)].R5(i, j) ⇔(cid:22)(cid:3)(cid:3)(cid:3)(cid:3) <(cid:3)(cid:3)(cid:3)(cid:3) j −(cid:22)(cid:3)(cid:3)(cid:3)(cid:3).(cid:21)(cid:21)m + 12m + 12This interprets closerToCenter via the profile [(seat, 1), (seat, 2)].6. R6 ⊆ {1, . . . , m} × {1, . . . , m}, defined as R5(i, j) ⇔ i = j. This interprets sameSeat via the profile(cid:12)(cid:13)(seat, 1), (seat, 2).The identity symbol is interpreted by the identity relation on the set of objects.28An obvious constraint that we might wish to enforce is that distinct objects must be placed in distinct seats. This willbe captured by the sentence∀x, y . sameSeat(x, y) ⇒ x = y.For brevity, we will refer to this formula as distinct-seats.Even though diagrams in this system are particularly simple, being one-dimensional and consisting of plain text, a fewremarks on how to parse them are in order. This is a domain in which every system object needs to be labeled in order tobe uniquely identifiable, because without such labeling the identity of a system object cannot be inferred from a diagram.The reason is that an object here does not occupy a fixed place in every diagram across a given proof,29 in contrast,say, with the map-coloring puzzles of the next section, where a system object (a map region) has a unique diagrammaticlocation throughout a proof. Accordingly, in an implementation of this system the user is required to fix two parametersat the beginning of a session (i.e., prior to entering and evaluating a proof): the number of seats m, and the objects tobe seated, specified simply as distinct names c1, . . . , cn. (Note that the number of objects to be seated, n, cannot exceedthe number of seats m, although we could have n < m.) For instance, in the case of the particular puzzle discussed in thebeginning, the user would specify five chairs and the five objects A, B, C , D, and E. This lets the implementation knowthat every system state thereafter would consist of n objects s1, . . . , sn, named throughout by the constant assignmentρ = {c1 (cid:8)→ s1, . . . , cn (cid:8)→ sn}. Of course this constant assignment could be subsequently extended, if part of the probleminvolves determining the referents of certain additional names. For example, in the opening puzzle, the second questioncould be expressed by imposing the constraint middle(G), where the identity of G is initially unknown; the questioncould then be answered by proving G = C . If a system object si does not appear in a diagram (or more precisely, if thecorresponding name ci does not), then seat(si) is defined as the set of all seats that are free in that diagram, where a freeseat is indicated by the presence of a questionmark. For instance, B, C , D, and E do not appear in (31), and therefore inthe system state (32) obtained by parsing (31), the seat ascription maps the corresponding objects to the set of all chairsthat are free in that diagram, namely, {1, 2, 4, 5}. With these conventions in place, the implementation can readily parse anygiven diagram (a sequence of m tokens, each of which is either a questionmark or has exactly one of the n names placedon it, and such that no name appears more than once) into a unique named state.We now discuss the solution presented in Fig. 6. That deduction, when evaluated in a context comprising the minimal-information diagram? ? ? ? ?and an assumption base that contains the distinct-seats postulate along with the three given constraints (formalized in thislanguage as flanking( A, C, E), closerToCenter(C, B), and adjacent(B, D)), will derive the conclusion¬atEnd(E) ∧ ¬middle(E) ∧ middle(C),which we abbreviate as goal. The Vivid deduction is a faithful representation of the informal reasoning that a humanproblem-solver would use when tackling the puzzle, which is roughly as follows. Knowing that E must be between Aand C , we can distinguish three main cases:28 Strictly speaking, we should make the attribute structure automorphic if we are to formalize the realization of the identity relation symbol via a profile,but we ignore this minor technicality here in the interest of simplicity.29 For instance, an object might not appear at all in the seating arrangements during the first few steps of a proof, when we do not yet have enoughinformation to place it correctly, but might appear in the diagram subsequently, once such information is deduced.K. Arkoudas, S. Bringsjord / Artificial Intelligence 173 (2009) 1367–140513951. A E C ? ?2. ? A E C ?3. ? ? A E CBy symmetry, there are three mirror cases, obtained from the above by flipping the positions of A and C , for a total ofsix cases, as shown in Fig. 6. These six cases represent the only possibilities consistent with the flanking constraint whichdictates that E must be between A and C , assuming that distinct persons are assigned distinct seats. Moreover, from thesesix cases, onlyandA E C ? ?? ? C E A(33)(34)are consistent with the other two constraints. Each of the remaining four cases either makes it impossible for B and D to beadjacent or else fails to place C closer to the middle than B. So in those cases goal follows trivially by contradiction, whilein cases (33) and (34) goal follows by simple inspection (by applying observe). The derivation of goal explicitly answers thefirst two questions of the puzzle. For the third question, a simple glance at the proof reveals that in the only two casesthat do not involve a contradiction (namely, the top and bottom clauses in Fig. 6, i.e., cases (33) and (34)), there are no twounique persons who must be seated on the two ends; any one of A, B, and D could appear at an end.30As we pointed out, four of the six alternatives in the above case analysis are ruled out because they violate certainconstraints. Hence, in these four cases, the goal follows vacuously: We observe that the constraint does not hold, we derivea contradiction from the fact that it ought to hold, and then we derive the goal by absurdity. This situation arises frequentlyin Vivid, so it is helpful to have some syntax sugar that routinely fills in these steps without the need to spell them out.This is accomplished by the “violates F ” construct, which may appear immediately following an arrow -> in a branch of acase analysis:cases by F 1 · · · Fk : (σ1; ρ1) → D1 | · · · | (σi; ρi) → violates F | · · · | (σl; ρl) → Dl.(35)If F is in the assumption base, and if it comes out false under (σi; ρi) and the current assumption base, the phrase violatesF will derive, by way of contradiction, the conclusion that is derived by the other tail deductions D j .31 Using this convenientsyntax sugar, the solution can be expressed more succinctly as follows:cases by flanking( A, C, E), distinct-seats:A E C ? ? → observe goal? A E C ? → violates adjacent(B, D)? ? A E C → violates closer-to-center(C, B)C E A ? ? → violates closer-to-center(C, B)? C E A ? → violates adjacent(B, D)? ? C E A → observe goalBoth this shorter version of the proof and the longer one depicted in Fig. 6 are machine-readable and can be promptlyevaluated by our implementation.9. Map coloringAs another example consider map coloring, where adjacent regions in a map must receive different colors. We will referto this as the “adjacency constraint,” or AC for short. AC can be symbolically formulated as follows:∀r1, r2 . adjacent(r1, r2) ⇒ ¬sameColor(r1, r2),where r1 and r2 range over regions and adjacent and sameColor have the obvious interpretations.32 It is well known thatany planar map can be colored in a way that satisfies AC using no more than four colors [3].33 We will suppose that the30 This could be explicitly shown by appending the following sentence to the goal conjunction:(cid:10)atEnd(B) ∨ atEnd(D) ∨ atEnd( A)(cid:11).The deduction of Fig. 6 can successfully derive this stronger goal without any modification.31 Hence, at least one branch of the case analysis (σ j ; ρ j ) → D j must have a regular deduction D j as its body, i.e., not a violates clause.32 We assume for simplicity that adjacent is irreflexive.33 Provided we do not admit disconnected regions, and that adjacency means sharing a line segment (so that, for instance, sharing a single point on theplane is not sufficient to make two regions adjacent).1396K. Arkoudas, S. Bringsjord / Artificial Intelligence 173 (2009) 1367–1405Fig. 7. An initial diagram of a map to be colored.four available colors are red, green, blue, and yellow (R, G, B, Y ). This section will illustrate how rigorous reasoning aboutsuch problems can be carried out most naturally with a mixture of diagrammatic and symbolic reasoning in Vivid34; it willalso demonstrate how the assignment of names can be part of a heterogeneous deduction.Consider the map of the five regions shown in Fig. 7. A questionmark inside a region indicates that the color of thatregion is unknown; it could be any of the four possibilities. A set of colors such as {R, G} inside a region indicates that thecolor of that region must be one of the set’s elements. A single color inside a region has the obvious interpretation; e.g., thecentral region in Fig. 7 must be colored blue. A region could optionally be given a name. In the example of Fig. 7, only tworegions have names, c1 and c3. Suppose now that we are given the following two sentential constraints, in addition to theinformation depicted in the figure:¬yellow(c3);sameColor(c1, c2) ∧ c1 (cid:4)= c2.(36)(37)The intended meanings are obvious: (36) requires that c3 must not be colored yellow (hence its color must be either R,or G, or B); while (37) requires that c1 and c2 must be distinct regions assigned the same color. Note that the name c2does not appear in the diagram; it is part of the problem to figure out which region is denoted by that name. Note furtherthat while (36) could be expressed diagrammatically, by writing {R, B, G} inside c3, constraint (37) cannot be expresseddiagrammatically without considerable effort and clutter.What can we infer from the given diagram, formulas (36) and (37), and AC? First, we can deduce that the colors of thetwo regions flanking the central blue region must be in the set {R, G, Y }; they cannot be blue by (AC). Further, the color ofc3 must be either red or green; it cannot be yellow on account of (36).We can now perform a two-way case analysis:1. Suppose first that the color of c1 is red. Then, by the preceding conclusions and AC, we can conclude that c3 must begreen, while the color of the leftmost region must be yellow. Accordingly, by (37), c2 has to be the uppermost region,since all other regions have distinct colors, and it must be red.2. By contrast, suppose that c1 is green. Then by similar reasoning we can conclude that c3 must be red; the leftmostregion must be yellow; and that c2 must be the uppermost region, and it must be green.Thus we conclude that, in either case, c2 must be the uppermost region, and it must be either red or green, while the colorof the leftmost region must be yellow. The diagram representing our final conclusion and depicting all the information wehave extracted is shown in Fig. 8. Note that this is a diagrammatic conclusion that could not be expressed sententially, sinceit involves labeling the diagram (by placing c2 in the appropriate region).The above reasoning can be expressed as a heterogeneous deduction, shown in Fig. 9 and Fig. 10, where τ0 is theinitial named state shown in Fig. 7. (A detailed specification of an attribute structure, vocabulary, and interpretation will beprovided shortly, but the depicted proof should be sufficiently clear at this point even without those details.) Each step ofthe deduction depicts the propagation of one of the constraints. Formally, the Vivid proof that expresses this reasoning is asfollows:τ1 by thinning with AC;τ2 by thinning with ¬yellow(c3);cases:τ3 → beginτ5 by thinning with AC;τ7 by thinning with AC;34 Although this particular example pertains to map coloring, similar techniques are applicable to many constraint satisfaction problems. Vivid is particu-larly apt for reasoning about such problems.K. Arkoudas, S. Bringsjord / Artificial Intelligence 173 (2009) 1367–14051397Fig. 8. A diagrammatic conclusion entailed by the diagram of Fig. 7 and constraints (36) and (37).τ9 by thinning with sameColor(c1, c2) ∧ c1 (cid:4)= c2;τ11 by wideningendτ4 → beginτ6 by thinning with AC;τ8 by thinning with AC;τ10 by thinning with sameColor(c1, c2) ∧ c1 (cid:4)= c2;τ11 by wideningendIn the interest of completeness, we close with a detailed specification of a Vivid language for map coloring. Let Regionbe a universe of regions. An appropriate attribute structure for this language is:id : Region, neighbors : Pfin(Region), color : {R, B, G, Y }; {R1, R2, R3, R4, R5, R6}(cid:11)(cid:10)AR =where:1. R1 ⊆ Region × Pfin(Region), defined as follows: R1(r, S) ⇔ r ∈ S.2. R2 ⊆ {R, B, G, Y } × {R, B, G, Y }, defined as R2(c1, c2) ⇔ c1 = c2.3. R3 ⊆ {R, B, G, Y } is the “red” property, i.e., R3(c) ⇔ c = R. Likewise, R4, R5, R6 correspond to blue, green, and yellow,respectively.The vocabulary contains seven relation symbols: A binary adjacent symbol, interpreted by R 1 with profile(cid:13)(cid:12)(id, 1), (neighbors, 2);a binary sameColor symbol, interpreted by R2 with profile [(color, 1), (color, 2)]; a binary identity symbol =, interpreted bythe corresponding identity relation on the id attribute, with profile [(id, 1), (id, 2)]; and four unary relations, red, blue, green,yellow, interpreted by R3–R6, respectively, each with profile [(color, 1)].10. Related workWe have derived much inspiration from the seminal work of Barwise, Etchemendy, and others on Hyperproof [8]. Chiefamong the many contributions of Hyperproof were its emphasis on incomplete information and its ability to reason aboutambiguous (partially determined) diagrams. These choices are not only pedagogically sound, since there are many typesof problems in which students are given an incomplete sketch and are asked to fill in the gaps by way of inference; butthey are also apt design choices for visual reasoning systems in general, as often the information that agents extract from aperceived image is incomplete, either because parts of the image are visually unclear or because they are not sure how tointerpret them.Important differences between Vivid and Hyperproof include the following:1. Hyperproof is specifically built for reasoning about simple blocks worlds. Vivid, by contrast, is a domain-independentframework.2. Hyperproof’s treatment of incomplete information is ad hoc. For instance, although it is possible to signify that the sizeof a block is unknown, one cannot indicate that it is, say, large or medium but not small. Although these restrictionsare due to the limitations of the available palette of visual abstraction conventions, they are reflected in the underlyingsemantics of the system [7, Section 7.5.2]. Consequently, if a new abstraction convention is added to the system, the en-tire semantics would need to change. By contrast, Vivid’s mechanism for handling incomplete diagrammatic informationvia arbitrary sets of values is entirely general, and its semantics are decoupled from any particular set of abstractionconventions. Note carefully that this does not mean that an implementation of Vivid would not need to use abstractionconventions (it would), but only that, unlike Hyperproof, such conventions are not baked into the underlying semantics.1398K. Arkoudas, S. Bringsjord / Artificial Intelligence 173 (2009) 1367–1405Fig. 9. Diagrammatic deduction showing the solution to a map-coloring problem, part 1.K. Arkoudas, S. Bringsjord / Artificial Intelligence 173 (2009) 1367–14051399Fig. 10. Diagrammatic deduction showing the solution to a map-coloring problem, part 2.3. Vivid is based on the key DPL ideas of representing assumption scope with context-free block structure and formalizingthe denotation of a proof as a function over assumption bases. These two ideas have several advantages for formalizingreasoning [4]. More than that, a precise abstract syntax goes hand-in-hand with formal semantics, the importance ofwhich we discuss below.4. Vivid has a formal big-step evaluation semantics in the style of Kahn and Plotkin [33,45]. This is not to say thatHyperproof does not have precise semantics or that its semantics cannot be formally defined; only that it does notdraw on the same techniques from programming language theory. We stress that this is not an issue of mere stylisticdifferences in presentation. Casting a formal semantics in a style such as we have used carries significant advantages,especially in meta-theoretic investigations, where many arguments take the form of induction proofs on derivations.In general, such a semantics is an invaluable tool for reasoning about proofs in the system, and for evaluating thecorrectness of algorithms that manipulate such proofs.5. Because it is based on DPLs, Vivid is extensible from its present form as a proof-checking framework into a Turing-complete programmable system allowing the user to formulate arbitrary methods combining diagrammatic and senten-tial inference steps, in such a way that the soundness of the methods is guaranteed by the formal semantics of thelanguage. In such a framework, heterogeneous proofs such as the solution to the seating puzzle could be discovered1400K. Arkoudas, S. Bringsjord / Artificial Intelligence 173 (2009) 1367–1405automatically. It is not clear how Hyperproof could be made programmable, let alone in a way that would guaranteesoundness.The work of Konolige and Myers on reasoning with analogical representations [40] is somewhat similar in spirit to ourresearch, in that it seeks to formulate domain-independent principles for diagrammatic reasoning. However, they do notprovide any linguistic abstractions for performing such reasoning. Rather, they outline a set of data structure operations(which they call “the integration calculus”) that can be used to integrate diagrammatic inference into existing reasoningsystems, and which can be described as a programming interface. By contrast, we have introduced a precisely defined familyof languages for heterogeneous natural deduction, with novel syntax forms and formal semantics. Further, our method fordealing with what they call “structural uncertainty” (incomplete diagrammatic information) is much more general. Finally,our system is strictly more powerful in that it can perform diagrammatic case reasoning; their integration calculus does nothave that capability.Diamond [30] is a system for checking diagrammatic proofs of certain types of arithmetic theorems. The system isdesigned to reason about natural numbers, and specifically about universally quantified identities of the form ∀ · · · . s = t,where s and t are terms built from the numerals 0, 1, 2, . . . , variables, and operators such as addition, multiplication, etc.A typical example is the identity asserting that the sum of the first n odd natural numbers is n2, symbolically written asn(cid:23)i=12i − 1 = n2.(38)Diagrammatic proofs are only given for particular instances of the theorem, e.g., for (38) one might give a diagrammaticproof for n = 4, establishing that 1 + 3 + 5 + 7 = 42 = 16. A diagrammatic proof of such a concrete identity is given byrepresenting both terms (1 + 3 + 5 + 7 and 42) as diagrams, and then rewriting both diagrams to a common form. Thisclearly depends on the system’s ability to represent concrete numeric terms by suitable diagrams. This is possible andindeed intuitive for certain types of terms. E.g., 42 can be represented as a 4 × 4 square matrix of dots:and likewise for any n2. It is not so easy for other terms, however, and indeed Diamond currently cannot express somearithmetic theorems.After the user has successfully carried out several diagrammatic proofs of such concrete instances of the identity inquestion, the system uses inductive learning techniques in an attempt to automatically extrapolate a schematic proof algo-rithm capable of taking any number n and proving the identity for that particular number. If successful, the schematic proofalgorithm then needs to be proved correct in a meta-theoretic framework. This is probably the most problematic step ofthe process, as the problem is undecidable in general. As a result, even though Diamond is a proof checker and not a prooffinder, it might nevertheless fail to yield a verdict. Therefore, it might make more sense to incorporate abstraction devicesinto the diagrams in a disciplined way, and attempt from the outset to give diagrammatic proofs of the general form of thetheorem, instead of insisting on dealing with concrete diagrams only.An attempt to extend the ideas of Diamond to continuous domains led to Dr. Doodle [66], which is an interactiveproof assistant for metric space analysis, primarily intended as an educational tool. The inference rules are specified as“redraw rules,” which can be understood as visual analogues of rewrite rules. A more extensive description of the relevantideas is given by Winterstein, Bundy, Gurr, Jamnik [67], who also discuss an application of animation for representing andreasoning about quantification. This is an interesting idea (and novel, to the best of our knowledge), although, as the authorsacknowledge, it suffers from the drawback that “it is not suited to being printed (e.g., in textbooks or papers), except ascumbersome comic strips where the simplicity of the representation is lost” [67, Section 6]. Nevertheless, we do not viewthis as a serious issue, insofar as a system such as Dr. Doodle is supposed to be a computerized tool. Unlike Vivid, thesystem is not domain-general; its inference rules are restricted to real analysis. Formal analysis of this system is providedby Winterstein [65].Grover [5] is a theorem-proving system that uses diagrams to guide the proof search. The system consists of a con-ventional (sentential) automated theorem prover (ATP), &, augmented with a diagram processor. The diagram processorexamines the given diagrams and, based on the extracted information, it constructs an appropriate proof strategy for &. Thesystem has reportedly been used to obtain automatic proofs for the diamond lemma, as well as for the Schröder–Bernsteintheorem of ZF. Both are non-trivial results; the Schröder–Bernstein theorem, in particular, has a quite sophisticated senten-tial proof that is far from even the current state-of-the-art in ATP technology. According to the authors of Grover, a diagramrepresents a trail of the objects that are involved in the proof, along with key properties of and relations among such ob-jects. That is an interesting view of diagrams, but it differs markedly from the sense in which they are used in Vivid, wherethey are essentially treated as visual premises and inference rules are applied to them in the usual step-by-step fashion.Anderson and McCartney [2] present IDR, a system for representing and computing with arbitrary diagrams. A diagramis viewed as a tessellation of a finite two-dimensional planar area, with each tile having a unique triple of numbers i, j, kK. Arkoudas, S. Bringsjord / Artificial Intelligence 173 (2009) 1367–14051401associated with it, indicating a value in the CMY (Cyan, Magenta, Yellow) color scale. Apart from the spatial relationshipsbetween the tiles, the meaning of a diagram is captured mainly via tile coloring, with different colors (or shades of gray)representing different types of information. They introduce a set of operations on diagrams, each of which takes a numberof input diagrams of the same dimension and tessellation, and produces a new diagram in which the color value of a tileis a function of the color values of the corresponding tiles of the input diagrams. Among other applications, IDR has beenused to solve the n-queens problem diagrammatically, to induce correct fingerings for guitar chords, and to answer queriesconcerning cartograms of the USA. The system is more concerned with diagram computation than with inference; there areno general notions of entailment, soundness, etc. IDR is also not heterogeneous. It is exclusively diagrammatic, in that allthe available operations are applied to diagrams, not to combinations of diagrams and sentences.Barwise and Etchemendy [6] set out to “do some of the homework needed to develop a general theory of heterogeneousinference” [6, p. 33]. They provide an information-theoretic analysis of heterogeneous inference that draws heavily fromsituation theory [10]. The key idea underpinning their work is a class of mathematical structures known as infon algebras,which turn out to be Heyting algebras (complete distributive lattices). Their analysis is thoroughly abstract, in that it iscouched independently of any particular representational system and any set of syntactic constructs. Our perspective, bycontrast, is that of computer science, and particularly that of artificial intelligence and programming language theory andimplementation. Our chief objective is not to study heterogeneous inference from a purely mathematical perspective, butto actually design and build a formal framework that mechanizes such inference. That means coming up with an abstractsyntax and with formal operational semantics, proving various results about them, and demonstrating the utility of thesystem via examples. Particular attention has been paid to computational efficiency concerns, implementation issues, andachieving a modular design. These issues do not surface at all in the work of Barwise and Etchemendy [6], simply becauseit was not the objective of that work to address them. The difference is perhaps best elucidated by the following remark ofBarwise and Etchemendy [6, p. 68] on their analysis of the seating puzzle:We emphasize that we are presenting a mathematical model that shows the reasoning given above [solving the seatingpuzzle] to be valid. This is a distinct enterprise from modeling the reasoning itself [our italics]. It is analogous to a model-theoretic proof of the soundness of principles used in a piece of syntactic reasoning. Needless to say, this is not somethingthat the reasoner does in the course of the reasoning.Our focus, by contrast, has been precisely the modeling of the reasoning itself—the formal modeling of what “the reasonerdoes in the course of the reasoning.” We want reasoners to be able to communicate certain pieces of heterogeneous rea-soning to the machine succinctly and perspicuously, seamlessly integrating diagrams and sentences, in such a way that theformal machine-readable object mirrors the informal reasoning to the greatest possible extent; and we want the machineto automatically check the soundness of the reasoning. This has been our primary concern in this paper (the automaticdiscovery of such heterogeneous proofs will be our main next goal), and we believe we have achieved it, insofar, for in-stance, as the formal Vivid proof shown in Fig. 6 does mirror the informal reasoning quite closely, it has a perfectly rigoroussyntax and semantics, and it is machine-readable and machine-checkable. The same points distinguish our work from thatof Vickers [61].Swoboda and Allwein [58] propose a general framework for modeling heterogeneous systems. The examples they present(specifically, the seating arrangement and the age charts) are readily modeled in Vivid, but a meaningful comparison is dif-ficult, as it is not clear what proofs would look like in that framework (the paper does not present any heterogeneousdeductions as examples), how soundness would be ensured (no theorems are proved about the framework), or how mech-anization would be enabled.Spider diagrams [28,55] are an extension of Euler circles and Venn diagrams, used to express constraints on sets. Theyarose from work on constraint diagrams [34], which were introduced as a mechanism for the visual depiction of constraintsexpressing invariants in object-oriented models specified in UML [47]. They combine elements of Euler circles and Venndiagrams. In particular, they relax the requirement of Venn diagrams that all curves must intersect, which retains theintuitive appeal of Euler circles, while allowing for shading, which makes Euler circles more expressive. In addition, theyintroduce “spiders,” which are generalizations of Peirce’s X-sequences (linked points, which are interpreted disjunctivelyas asserting that at least one of the points lies in a non-empty region). This work differs from Vivid in several respects.First, spider diagrams are a purely diagrammatic reasoning system, whereas Vivid is a heterogeneous system that integratessentential and diagrammatic inference (a typical inference rule in Vivid, such as thinning, involves both diagrams andsentences). Second, spider diagrams, being based on Euler and Venn diagrams, are used to depict sets and relationshipsamong sets, so their graphical elements are restricted to closed plane curves and spiders. That is, of course, quite appropriatefor object-oriented design, where the main entities of interest are classes, which are naturally interpreted as sets. But thereare many cases where we wish to draw and reason about other types of diagrams, say, chess boards, where the objects ofinterest are chess pieces rather than sets; or graphs, where the objects of interests are not sets but individual nodes andthe topological relationships indicate graph-theoretic—instead of set-theoretic—relationships; or blocks worlds, where thespatial relationships of interest are on, above, and below, and potentially left-of and right-of, instead of enclosure, overlap,and separation. Such diagrams can be parsed into named system states, and once an appropriate vocabulary has beenchosen, Vivid can be used to carry out heterogeneous reasoning with them. Finally, unlike spider diagrams, the semanticsof Vivid are built on a 3-valued logic specifically designed to deal with incomplete information.1402K. Arkoudas, S. Bringsjord / Artificial Intelligence 173 (2009) 1367–1405Wang, Lee and Zeevat [62] attempt a formal analysis of the general properties of diagrams, in the setting of multi-sortedfirst-order logic. They do not present a specific axiomatic characterization of diagrams, but give a few suggestive examplesof such axioms, e.g., that the “overlaps” relation is symmetric, or that if a point x is inside a circle y, then x is not outside y.The authors acknowledge that, technically speaking, what they call a “graphical signature” is simply a multi-sorted signa-ture, and what they call a “graphical theory” is simply a multi-sorted first-order theory, but they nevertheless single outsome formal properties which, they argue, achieve a partial characterization of graphical theories, i.e., theories expressingdiagrams. These three properties are atomicity, consistency, and maximality. Atomicity means that the only properties adiagram expresses are “basic facts,” expressed by literals—atomic sentences or negations thereof. Thus, for instance, a theorythat purports to capture a diagram does not contain any quantified or any conditional sentences. We agree with the generalspirit of this condition, and indeed Vivid does not even use negations of atomic sentences in diagrams (system states). Butthere is one significant difference, namely, that Vivid allows for disjunctive information in order to accommodate incompletediagrammatic information and visual ambiguity. Consistency simply “reflects the fact that diagrams cannot convey contra-dictory graphical information” [62, p. 353]. This important point also applies to Vivid diagrams, as discussed (and qualified)previously. Finally, maximality means that “for a basic property represented by an atomic sentence P about some objectsin a diagram, either P or ¬P can be seen in the diagram” (p. 355). That is not the case for Vivid diagrams, again due tothe possibility of incomplete information. In Vivid, a “basic property” about “some objects in a diagram” might well have anunknown truth value. This also distinguishes our framework from the work of Etherington, Borgida, Brachman and Kautz[19] on “vivid knowledge bases.” We believe that the suitability of a 3-valued logic for diagrams is amply demonstratedby the examples we have presented, and by systems such as Hyperproof [8]. As the underlying framework of Wang et al.[62] is that of classical first-order logic, they do not present any new inference rules, syntax forms, or semantics specificallydesigned for heterogeneous inference. There are no algorithms presented in the paper, and few detailed remarks on howthe proposed approach would be used to mechanize diagrammatic reasoning.Qualitative spatial reasoning [16], or QSR, is another area where ideas from heterogeneous representation and inferencecould suggest some interesting new research directions. QSR is an active field of research with an impressive body of work,but so far most of that work has focused on purely symbolic formalisms, and it would be interesting to explore whetherthe combination of diagrammatic and symbolic reasoning might have anything to contribute in this area.11. ConclusionsSentential reasoning has been studied to an astonishing depth over the last century, and by now we have amassed atremendous amount of knowledge about it, both theoretical and practical. A great number of symbolic-reasoning tools suchas theorem provers, proof checkers, model finders, model checkers, planners, logic programming languages for deduction,induction, and abduction, etc., are used on a daily basis to perform all kinds of tasks, from machine learning to exploringmathematics, verifying hardware and software, finding plans for autonomous agents, performing scene understanding forrobots, and more.Progress has not been as extensive for diagrammatic reasoning, even though AI researchers have long recognized the ad-vantages of analogical representations and scientists have always used diagrams in problem solving. Indeed, as was pointedout in the introduction, visual modes of presenting information are overwhelmingly more popular (some would say trendier)than sentential ones, both in academia and in business. But in logico-mathematical domains, and particularly when it comesto formal proofs, the use of diagrams has been meager. This is partly because diagrams acquired a suspect reputation afterthe advent of the logicist era ushered in by Frege and Russell, which eventually resulted in an almost exclusive focus onsentential formalisms and stigmatized images as inherently non-rigorous and prone to mistakes. Attitudes towards diagramshave been improving over the last fifteen years (largely as a result of the seminal work of Barwise and Etchemendy), butthe stigma has not quite disappeared. There are contemporary reports of mathematicians who go so far as “actually hidingthe diagrams and visual arguments in presenting their lectures and proofs” [64, p. 281].Our work is another step towards rectifying this discrepancy and putting diagrammatic reasoning on a solid footing byintegrating it with symbolic reasoning in a heterogeneous framework. Our results demonstrate that it is possible to performperfectly rigorous reasoning with and about an exceedingly diverse range of diagrams in combination with regular symbolicreasoning. The last dozen years or so have witnessed an encouraging surge of research activity on diagrammatic reasoning,and similar demonstrations have been carried out in certain particular diagrammatic domains such as Venn diagrams andPeirce diagrams [24,51]. Our work has broader applicability, as it introduces domain-independent idioms for heterogeneousreasoning and general notions of entailment and soundness for such reasoning.Specifically, we have introduced and analyzed Vivid, a family of denotational proof languages (DPLs) that combine dia-grammatic and symbolic inference in a mechanizable framework. Vivid is based on the notion of attribute systems, and onthe use of a 3-valued logic to interpret first-order signatures into attribute structures. The design of Vivid enables highlymodular implementations by enforcing a sharp separation between the purely graphical task of diagram parsing on onehand, and the system’s syntax, semantics, and underlying diagrammatic inference procedures on the other. The latter arefixed once and for all and proven sound. To obtain a particular instance of Vivid, we need only specify a class of diagramsand an associated signature, interpret the signature via an appropriate attribute structure, and provide a diagram parser.This is somewhat analogous to the way in which the CLP scheme [29] defines a family of constraint logic programmingK. Arkoudas, S. Bringsjord / Artificial Intelligence 173 (2009) 1367–14051403languages, with a specific member of the family obtained by fixing a constraint domain and a corresponding constraintsolver and simplifier.The combination of diagrammatic and symbolic reasoning is crucial in the process of deriving new information. A typ-ical inference step in our system refines a diagram by using some sententially expressed knowledge to rule out certainpossibilities. Incomplete information plays a key role, as reasoning in Vivid proceeds largely by the gradual elimination ofuncertainty. If a diagram is completely determined, i.e., if it is a world, then it already conveys a maximal amount of infor-mation and there is not much new that can be extracted from it. That is in fact the principal limitation of Vivid at present,namely, the inability to introduce arbitrary inference rules for deriving diagrams from completely determined diagrams.This means that certain types of diagrammatic reasoning cannot presently be carried out in Vivid, e.g., various diagram-matic proofs from Euclidean geometry. Nevertheless, the capability to transform completely determined diagrams would notbe problematic to incorporate into the present framework; we plan on doing just that in the near future. While such anaddition would certainly extend the scope of Vivid, it may well be that some forms of diagrammatic reasoning will remainbeyond its reach, or, more likely, they will not be perspicuously reproducible in it. Further work and experience with thesystem will be necessary before we can probe these questions more deeply.We have not discussed how diagrams would be concretely represented within the proof text. That is an importantimplementation issue, but it concerns the interface of Vivid, not its abstract syntax or semantics. One possibility would beto give names to diagrams and then have those names appear in the proof text, but with hyperlinks. If a user clicks onsuch a link, a picture depicting the corresponding diagram would appear and the user could view or edit the diagram asnecessary. Of course, as we have already stressed, how diagrams are actually drawn depends on the domain at hand and iskept separate from other aspects of the language. While this separation of concerns results in a very modular design, onemight be concerned that ignoring diagram parsing amounts to brushing off potentially difficult problems that could arisein connection with diagrammatic reasoning. In response, it should be noted that diagram parsing is not quite the same asdiagram reasoning, in the same way that in AI parsing formulas and reasoning with them are two different tasks. Reasoningis not concerned with how to identify the structure of a diagram or a formula, but with what to do with that structure. Justas the inference rules of sentential logic operate on the abstract syntax of formulas and reasoning starts after parsing hasbeen completed, so it is with diagrams. Moreover, in very many domains diagram parsing is quite straightforward; thereare no difficult issues to be addressed. Perhaps in more complicated domains diagram parsing could present challenges.But even if a framework could not handle such domains and was instead limited to working with “simple” diagrams (andVivid has no such limitations), it could still be an exceedingly useful tool. As we pointed out in the introduction, it is notthe visual complexity of diagrams that makes them useful; diagrammatic simplicity and structure are often advantages, notdisadvantages. By not being fettered to any particular diagrammatic domain and any particular set of graphical conventions,Vivid gives users the freedom to exercise their creative imagination and invent their own simple diagrams and abstractionconventions, appropriate for their particular applications, and then use the machinery of the language to represent and solveproblems in ways that would not be possible in a sentential framework.35Two additional points should be emphasized with regard to this last remark. First, a Vivid proof in an actual computerimplementation of the language would not contain sentential descriptions of named system states; it would contain thediagrams themselves, exactly as they appear, for instance, in a picture such as that of Fig. 7. As we mentioned above,named states would appear in the proof text essentially as hyperlinks. Clicking on such a link would launch a diagrameditor, which would display the diagram and also allow the user to edit the diagram. This interface is similar to that ofHyperproof. The user sees and manipulates pictorial diagrams, not symbolic descriptions of system states. Of course, underthe hood, Vivid will parse the diagrams into system states and will apply inference rules to those, in accordance with thetheoretical framework which we have developed. Hyperproof does something similar, and indeed any other mechanizedsystem would have to do something similar. But users are shielded from all that—what they see and manipulate are thediagrams themselves. Diagrams, therefore, do not serve as mere annotations to Vivid proofs, but instead play an essentialrole in their dynamic behavior. Second, Vivid does not recast diagrammatic information into a standard formalism such asmulti-sorted first-order logic and then resort to the usual deductive mechanisms of that formalism for reasoning (which iswhat would take place in a framework such as proposed by Wang et al. [62]).36 That approach would be unfortunate froma usability perspective; for instance, any sentential solution to the seating puzzle in first-order or higher-order logic wouldbe much less natural than the heterogeneous solution shown in Fig. 6. Instead, Vivid represents diagrammatic informationby formal structures (named system states) that are tailor-made for potentially indeterminate diagrams, and then deploysnovel inference rules operating on those structures that make heterogeneous inference much more natural—all while lettingthe user graphically manipulate real diagrams.35 By drawing attention to this freedom, we should not be interpreted as assuming that the parsing of diagrams requires no ingenuity, or that suchparsing can be done without regard to the meaning of diagrams. Nonetheless, diagram parsing, as opposed to the parsing of arbitrary visual scenes, is veryoften—though admittedly not always—a matter of fairly straightforward engineering, and the utility of the freedom Vivid provides seems to us well worththe cost of setting this engineering aside as a separate problem.36 For a discussion of AI and such recasting in connection with not just diagrams, but animations, see Bringsjord and Bringsjord [13].1404K. Arkoudas, S. Bringsjord / Artificial Intelligence 173 (2009) 1367–1405References[1] J. Agusti, J. Puigsegur, D.S. Robertson, A visual syntax for logic and logic programming, Journal of Visual Languages and Computing 9 (4) (1998)399–427.[2] M. Anderson, R. McCartney, Diagram processing: Computing with diagrams, Artificial Intelligence 145 (1–2) (2003) 181–226.[3] K. Appel, W. Haken, Every Map is Four Colorable, first edn, American Mathematical Society, 1989.[4] K. Arkoudas, Denotational proof languages, PhD thesis, MIT, Department of Computer Science, Cambridge, USA, 2000, available from: http://www.cag.lcs.mit.edu/~kostas/dpls/dpl-dissertation.pdf.[5] D. Barker-Plummer, S.C. Bailin, Proofs and pictures: Proving the diamond lemma with the GROVER theorem proving system, in: Working Notes of theAAAI Spring Symposium on Reasoning with Diagrammatic Representations, American Association for Artificial Intelligence, Cambridge, MA, 1992.[6] J. Barwise, J. Etchemendy, Information, infons, and inference, in: R. Cooper, K. Mukai, J. Perry (Eds.), Situation Theory and Its Applications, vol. 1, CSLI,Stanford, CA, 1990, pp. 33–78.[7] J. Barwise, J. Etchemendy, Heterogeneous logic, in: J. Glasgow, N. Narayanan, N.H. Chandrasekaran (Eds.), Diagrammatic Reasoning, MIT Press, Cam-bridge, USA, 1995, pp. 211–234.[8] J. Barwise, J. Etchemendy, Hyperproof: For Macintosh, CSLI Publications, 1995.[9] J. Barwise, J. Etchemendy, Visual information and valid reasoning, in: G. Allwein, J. Barwise (Eds.), Logical Reasoning with Diagrams, Oxford UniversityPress, 1996, pp. 3–25.[10] J. Barwise, J. Perry, Situations and Attitudes, MIT Press, Cambridge, MA, 1983.[11] B. Bérard, M. Bidoit, A. Finkel, F. Laroussinie, A. Petit, L. Petrucci, Ph. Schnoebelen, Systems and Software Verification. Model-Checking Techniques andTools, Springer, 2001.[12] E.A. Bier, M.C. Stone, K. Pier, W. Buxton, T.D. DeRose, Toolglass and magic lenses: The see-through interface, in: Annual Conference Series, ComputerGraphics 27 (1993) 73–80.[13] S. Bringsjord, E. Bringsjord, The case against AI from imagistic expertise, Journal of Experimental and Theoretical Artificial Intelligence 8 (1996) 383–397.[14] R.M.J. Byrne, P.N. Johnson-Laird, Spatial reasoning, Journal of Memory and Language 28 (1989) 564–575.[15] S.-K. Chang (Ed.), Principles of Visual Programming Systems, Prentice Hall, New York, 1990.[16] A.G. Cohn, J. Renz, Qualitative spatial representation and reasoning, in: F. van Harmelen, V. Lifschitz, B. Porter (Eds.), Foundations of Artificial Intelli-gence, vol. 3, Elsevier, 2008, pp. 551–596.[17] H.G. Eggleston, Convexity, Cambridge University Press, 1969.[18] G. Englebretsen, Linear diagrams for syllogisms (with relationals), Notre Dame Journal of Formal Logic 33 (1) (1992) 37–69.[19] D.W. Etherington, A. Borgida, R.J. Brachman, H.A. Kautz, Vivid knowledge and tractable reasoning: Preliminary report, in: Proceedings of IJCAI-89, 10thInternational Joint Conference on Artificial Intelligence, Detroit, US, 1989, pp. 1146–1152.[20] L. Euler, Lettres à une Princesse d’Allemagne, l’Academie Imperiale des Sciences, 1768.[21] R. Fagin, A. Mendeizon, J. Ullman, A simplified universal relation assumption and its properties, ACM Transactions on Database Systems 7 (3) (1982)343–360.[22] A. Fish, G. Stapleton, Formal issues in languages based on closed curves, in: Proceedings of the International Workshop on Visual Languages andComputing, 2006.[23] M. Grigni, D. Papadias, C.H. Papadimitriou, Topological inference, in: Proceedings of the 14th International Joint Conference on Artificial Intelligence,Montreal, 1995, pp. 901–905.[24] E.M. Hammer, Logic and Visual Information, CSLI Publications, Stanford, CA, 1995.[25] D. Harel, On visual formalisms, Commun. ACM 31 (5) (1988) 514–530.[26] P.J. Hayes, Some problems and non-problems in representation theory, in: R.J. Brachman, H.J. Levesque (Eds.), Readings in Knowledge Representation,Kaufmann, Los Altos, CA, 1985, pp. 3–22.[27] M. Hirakawa, M. Tanaka, T. Ichikawa, An iconic programming system, HI–VISUAL, IEEE Transactions on Software Engineering 16 (10) (1990) 1178–1184.[28] J. Howse, F. Molina, J. Taylor, S. Kent, J. Gil, Spider diagrams: A diagrammatic reasoning system, Journal of Visual Languages and Computing 12 (3)(2001) 299–324.[29] J. Jaffar, J.-L. Lassez, Constraint logic programming, in: POPL ’87: 14th ACM Symposium on Principles of Programming Languages, ACM Press, Germany,Munich, 1987, pp. 111–119.[30] M. Jamnik, Mathematical Reasoning with Diagrams, CSLI Publications, Stanford, CA, 2001.[31] P. Johnson-Laird, Mental Models, Harvard University Press, 1983.[32] S.D. Johnson, J. Barwise, G. Allwein, Towards the rigorous use of diagrams in reasoning about hardware, in: G. Allwein, J. Barwise (Eds.), LogicalReasoning with Diagrams, Oxford University Press, 1996, pp. 201–223.[33] G. Kahn, Natural semantics, in: Proceedings of Theoretical Aspects of Computer Science, Passau, Germany, 1987.[34] S. Kent, Constraint Diagrams: Visualizing invariants in object-oriented models, in: Proceedings, Object-Oriented Programming Systems, Languages andApplications (OOPSLA ’97), 1997, pp. 327–341.[35] O. Lemon, Comparing the efficacy of visual languages, in: D. Barker-Plummer, D.I. Beaver, J. van Benthem, P.S. di Luzio (Eds.), Words, Proofs, andDiagrams, CSLI Publications, Stanford, CA, 2002, pp. 47–69.[36] O. Lemon, I. Pratt, Spatial logic and the complexity of diagrammatic reasoning, Machine Graphics and Vision 6 (1) (1997) 89–109.[37] B. Manbelbrot, The Fractal Geometry of Nature, W.H. Freeman and Company, 1982.[38] K. Meinke, J.V. Tucker, Universal algebra, in: S. Abramsky, D.M. Gabbay, T.S.E. Maibaum (Eds.), Handbook of Logic in Computer Science: Background –Mathematical Structures, vol. 1, Clarendon Press, Oxford, 1992, pp. 189–411.[39] K. Mullet, D. Sano, Designing Visual Interfaces: Communication Oriented Techniques, Prentice Hall, 1994.[40] K. Myers, K. Konolige, Reasoning with analogical representations, in: J. Glasgow, N. Narayanan, N.H. Chandrasekaran (Eds.), Diagrammatic Reasoning,MIT Press, Cambridge, USA, 1995, pp. 273–301.[41] K.L. Myers, Hybrid reasoning using universal attachment, Artificial Intelligence 67 (1994) 329–375.[42] T. Ogawa, J. Tanaka, CafePie: A visual programming system for CafeOBJ, in: Cafe: An Approach to Industrial Strength Algebraic Formal Methods, ElsevierScience, 2000, pp. 145–160.[43] C. Peirce, The Collected Papers of C.S. Peirce, Harvard University Press, 1960.[44] B.C. Pierce, Basic Category Theory for Computer Scientists, Foundations of Computing, MIT Press, Cambridge, MA, 1991.[45] G.D. Plotkin, A structural approach to operational semantics, Research Report DAIMI FN-19, Computer Science Department, Aarhus University, Aarhus,Denmark, 1981.[46] J.C. Reynolds, Theories of Programming Languages, Cambridge University Press, 1998.[47] J. Rumbaugh, I. Jacobson, G. Booch, The Unified Modeling Language Reference Manual, Addison-Wesley, 1999.[48] J.M. Rushby, Formal methods and the certification of critical systems, Research report, Computer Science Laboratory, SRI International, Menlo Park, CA,1993.K. Arkoudas, S. Bringsjord / Artificial Intelligence 173 (2009) 1367–14051405[49] B. Russell, Vagueness, Australasian Journal of Philosophy and Psychology 1 (1923) 84–92.[50] S. Russell, P. Norvig, Artificial Intelligence: A Modern Approach, Prentice Hall, Upper Saddle River, NJ, 2002.[51] S.-J. Shin, The Logical Status of Diagrams, Cambridge University Press, 1995.[52] S.-J. Shin, Heterogeneous reasoning and its logic, Bulletin of Symbolic Logic 10 (1) (2004) 86–106.[53] S.-J. Shin, O. Lemon, Diagrams, in: E.N. Zalta (Ed.), The Stanford Encyclopedia of Philosophy, Stanford University, 2003, http://plato.stanford.edu/entries/diagrams.[54] A. Sloman, Interactions between philosophy and AI: The role of intuition and non-logical reasoning in intelligence, in: Proceedings of the SecondInternational Joint Conference on Artificial Intelligence, 1971.[55] G. Stapleton, J. Howse, J. Taylor, S. Thompson, The expressiveness of spider diagrams, Journal of Logic and Computation 14 (6) (2004) 857–880.[56] K. Stenning, Seeing Reason, Oxford University Press, 2002.[57] K. Stenning, O. Lemon, Aligning logical and psychological perspectives on diagrammatic reasoning, in: Thinking with Diagrams, Kluwer, 2001.[58] N. Swoboda, G. Allwein, Modeling heterogeneous systems, in: M. Hegarty, B. Meyer, N.H. Narayanan (Eds.), Diagrams 2002, in: LNAI, vol. 2317, Springer,2002, pp. 131–145.[59] E.R. Tufte, Envisioning Information, Graphics Press, 1990.[60] M. Veltman, Diagrammatica: The Path to Feynman Rules, Cambridge Lecture Notes in Physics, vol. 4, Cambridge University Press, 1995.[61] S. Vickers, Topology via Logic, Cambridge Tracts in Theoretical Computer Science, vol. 4, Cambridge University Press, 1989.[62] D. Wang, J. Lee, H. Zeevat, Reasoning with diagrammatic representations, in: J. Glasgow, N. Narayanan, N.H. Chandrasekaran (Eds.), DiagrammaticReasoning, MIT Press, Cambridge, USA, 1995, pp. 339–393.[63] C. Ware, Information Visualization: Perception for Design, second edn, Morgan Kaufmann, 2004.[64] G.H. Wheatley, Reasoning with images in mathematical activity, in: L.D. English (Ed.), Mathematical Reasoning: Analogies, Metaphors, and Images,Lawrence Erlbaum Associates, 1997, pp. 282–312.[65] D. Winterstein, Using diagrammatic reasoning for theorem proving in a continuous domain, PhD thesis, The University of Edinburgh, Edinburgh,Scotland, 2004, available from: http://www.inf.ed.ac.uk/publications/thesis/online/IP040039.pdf.[66] D. Winterstein, A. Bundy, C.A. Gurr, Dr.doodle: A diagrammatic theorem prover, IJCAR, 2004, pp. 331–335.[67] D. Winterstein, A. Bundy, C.A. Gurr, M. Jamnik, Using animation in diagrammatic theorem proving, in: Diagrams, 2002, pp. 46–60.