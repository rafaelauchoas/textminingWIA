ELSEVIER Artificial Intelligence 87 ( 1996) 2 15-254 Artificial Intelligence Improving accuracy by combining rule-based and case-based reasoning Andrew R. Golding a,*, Paul S. Rosenbloom b a Mitsubishi Electric Research Laboratories, b Information Sciences Institute and Computer Science Department, University of Southern California, 201 Broadway, 8th Floes Cambridge, MA 02139. USA 4676 Admiralty Way, Marina de1 Rey, CA 90292, USA Received October 1994; revised November 1995 Abstract An architecture is presented reasoning. The architecture for combining that are understood rule-based and case-based reasonably well, but still imperfectly. for domains is intended It uses a set of rules, which are taken to be only approximately correct, to obtain a preliminary answer for a given problem; it then draws analogies from cases to handle exceptions to the rules. Having rules together with cases not only increases the architecture’s domain coverage, it also allows innovative ways of doing case-based reasoning: the same rules that are used for rule-based reasoning are also used by the case-based component to do case indexing and case adaptation. The architecture was applied to the task of name pronunciation, and, with minimal knowledge engineering, was found to perform almost at the level of the best commercial systems. Moreover, its accuracy was found to exceed what it could have achieved with rules or cases alone, thus demonstrating the accuracy improvement afforded by combining rule-based and case-based reasoning. 1. Intmduction to which and correctly Domains vary in the degree have been codified completely those for which no such rules are known. This paper fall between these two extremes, but closer which a set of rules domain. The rules must also be able to be run efficiently. cases both provide valuable knowledge. While they are understood, ranging in terms of a set of rules of behavior, is concerned with domains to the “well-understood” end-domains from those that to that for of the rules and that In such domains, the rules embody the understanding is known, but the rules do not cover the full complexities * Corresponding author. E-mail: golding@merI.com. 0004-3702/96/$15.00 Copyright @ 1996 Elsevier Science B.V. All rights reserved. SSD10004-3702(95)00120-4 form-illustrations in the rules the idiosyncratic has been codified over the years by experts, cases contain knowledge of the domain a more unprocessed complete with idiosyncrasies codified knowledge of cases, while by known combining The architecture to obtain a preliminary to handle exceptions that occur of actual behaviors and irregularities. Neither source subsumes is not necessarily well represented knowledge is the basis in in the domain, the other-the by any given set captured presented here for [ 20,301. correct, from cases (CBR) uses a set of rules, which arc taken to be only approximately rules. This observation rule-based answer to the rules. (RBR) 1 171 and case-based it then draws analogies for a given problem; for the architecture is not necessarily in the cases reasoning reasoning rules Having innovations the domain incorporates it also allows two novel methods to supply appropriate the architecture in CBR for CBR that are based on exploiting together with the cases not only allows First, termed prediction-based to take advan- technology. The tage of more domain knowledge. the architecture the rules are used to index the cases. The index- rules of the RBR component. indexing, hangs cases directly off the rules, using ing scheme, cues for case retrieval. This avoids having the rule antecedents indexing to analyze features; in the rules, and hence already available. The second role of the rules in CBR is for case adaptation, via a strategy of “case adaptation by factoring”. The rules are used to factor each source the case, through a process of case into rational reconstruction. The individual that the fine grained to target, despite overall dispar- relevant ones can be transferred verbatim ities between the source case to enable transfer from source is thus a way of adapting to identify a suitable vocabulary of direct and derived it takes advantage of the domain steps that were applied within steps are then sufficiently to globally dissimilar the cases. Factoring the individual structure instead, implicit To test the architecture task. it was applied engineering, the resulting to perform almost at the level of the best commercial pronunciation. With minimal knowledge was found systems, and substantially task (two versions of NETtalk). Moreover. Anapron’s what it could have achieved with rules or cases alone, improvement than other machine-learning rule-based and case-based afforded by combining better thus demonstrating reasoning. accuracy was found systems applied to this to exceed the accuracy to the problem of name ’ system, Anapron, name-pronunciation The next section presents the architecture, independent of the domain of name pronun- system. which instantiates ciation. The Anapron is then described. A set of experiments on Anapron are presented, an empirical demonstration The last two sections discuss related work. and conclude. of the improvement the architecture obtained by combining for name pronunciation, the key result being rules and cases. 2. The architecture The architecture is organized as a set of modules that can be configured according to the needs of the domain; see Fig. I The minimal configuration consists of four modules, ’ Anapron stands for Rrrulogical prmunciatlon system target cases. for a real-world A.R. Gelding, P.S. Rosenbioom/Artijciul Intelligence 87 (1996) 215-254 217 Weak theory I Problem/answer Similarity metric I Problen 4nswer Core method Fig. 1. Anatomy of the architecture. The black outer rectangle represents the overall architecture for combining RBR and CBR; the gray inner rectangle encloses the core method. Boxes represent modules of the architecture, and icons stand for knowledge structures. Links indicate dependencies between components. termed four modules the core method, shown in the diagram enclosed are the heart of the architecture-they three modules, collectively rectangle. These method for combining RBR and CBR. The remaining modules, perform various Each of these modules may be included, on a domain-by-domain make up the difference knowledge in the gray inner the implement termed the support the knowledge needed by the core method. to the basis, as needed needed by the core method and that is already available roles in acquiring in the domain. the knowledge between The sections below describe and the support followed by a discussion of design issues. For ease of exposition, examples will the core method of the architecture domain; the instantiation to name pronunciation modules, be drawn from a toy (but implemented) to Section 3. is deferred Procedure RC-Hybrid(pmhlm) (a) RBR: Use the rules to select an operator ( h 1 CBR: Look (c) Combination: Decide between that contradict for analogles to apply. the operator suggested by RBR. the operators suggested by RBR and CBR Fig. 2. Top-level procedure l’ur combming rule-based and case-based reasoning. 2.1. The cm-e ruethad from cases The core method to draw analogies of RBR and CBR. The central is the heart of the architecture; answer, and idea is expressed solving as a process of applying operators to get an approximate to the rules. This treats problem it is solved. The procedure by a combination problem exceptions The procedure problem until chooses It then looks for analogies the combination by RBR or one suggested by CBR. Underlying and line tuning with the cases is the assumption of rules applies CBR and RBR in the opposite order. it is the part that solves problems idea is to apply the rules to the target to cover in the RC-Hybrid procedure of Fig. 2. to the target It iteration. to apply via the rules. ln to actually apply-the one suggested this strategy of starting with the rules fast and accurate set that a reasonably If not, a different architecture may be called for, such as one that it selects an operator the rules and suggest alternative operators. in three steps. First that contradict step, it decides which operator applies one operator on each the operator is available. The core method gets its domain knowledge in the domain using a set of rules. It has two components: and a set of operators. The operators define the legal actions from four sources: a weak theory of the domain. a case library, a similarity metric, and a set of thresholds. The weak theory is a method for solving problems in the the rules themselves, domain. Each operator may have an associated applicability that limits the set of states in which it can be applied. The rules provide search control, specifying exactly is weak in the to apply one operator the right operator sense that it does not always suggest it did, there would in the first place. In fact, even if the weak theory be no reason to apply the architecture the architecture may be able to recover does not contuirr failures by applying in the case library, and which invents new of the weak theory (see Section 2.2.2). operators theory extension. which detects such missing operators by noticing for examples the failures in every problem-solving the right operator state. A weak (and rules) to account to apply-if to correct to apply, condition theory As an example of a weak theory, consider a toy version of a problem in auto insurance: to assess the risk of insuring a new client. Solving a problem three steps: determining whether he2 is in a hostile driving environment, his level of risk. Each step is implemented operators. For example, implemented driver-is the first step-determining by applying the attentive the client whether either in this domain consists of is an attentive driver, determining whether assessing inferences, and, based on the previous by applying one of a corresponding set of the client, c, is an attentive operator. or inattentive 2 Masculine pronouns are mtendcd in the gcnrrlc XXIX unlc\~ the context indicates otherwise A.R. Gold@. P.S. Rosenbloom/Artificiul Intelligence 87 (1996) 215-254 219 Operators attentive inattentive < endangered neutral high-risk < medium-risk low-risk c) = student If occupation( elseif sex(c) = M and age(c) < 30 then inattentive elseif age(c) 2 65 then inattentive else attentive then attentive If address2( c) = New York, NY or address2(c) = Los Angeles, CA then endangered else neutral If inattentive(c) elseif inattentive(c) else low-risk and endangered(c) then high-risk or endangered(c) then medium-risk ; ‘Student’ rule ; ‘Young driver’ rule ; ‘Old driver’ rule ; ‘Default’ rule ; ‘Hostile ; ‘Normal traffic’ rule traffic’ rule ; ‘High’ rule ; ‘Medium’ ; ‘Low’ rule rule Fig. 3. Weak theory applicability stands for a client. for the toy auto-insurance conditions that control the order example. The less-than in which represent the operators are applied. The letter c in the rules signs (<) between operators The former adds the assertion attentive(c) assertion. Applicability example, attentive The weak theory conditions and inattentive is summarized control in Fig. 3. to the state, while the latter adds the opposite for the order in which operators are applied; to apply only in the initial state. are constrained of cases, where a case consists of a problem, The next knowledge source needed by the core method collection operators by which into a client, the client’s for that client. The client the answer was derived. is the case library. It is a its answer, and the chain of In the insurance domain, a case translates that level of risk that derived as a feature vector. Fig. 4 gives an example of level of risk, and the operators is represented Name Address 1 Address2 Sex Age Occupation Car-make Car-value Answer Operators Target Case # 1 Smith Sigma Chi House Stanford, CA M 21 student Chevrolet 2,500 Johnson Sigma Chi House Stanford, CA M 19 student BMW 30,000 Case # 6 Davis Toyon Hall Stanford, CA F 22 student Toyota 3,000 medium-risk(Johnson) low-risk(Davis) inattentive, neutral, medium-risk attentive, neutral, low-risk Fig. 4. A target problem and selected cases from the insurance example. 220 A.R. (idding, I1.Y RosenDl~~on~/Art~~r~~~il Intelligence R7 (I 996) 2/S-253 Procedure Index (msc) Until (YI.FP is solved do- _- - (a) Use The rules to predict which operator (jr should apply to cask. Ler r be the rule that made Ihe prediction. (b) Compare o,, wnh the operator (I,, Ihal i< observed 10 have been applied to UI.W (c) If the IWO operators arc the same. sturc the case as a positive exemplar of rule r. else as a negative exemplar. Cd) Proceed to apply operator II<, 10 WSE. - Fig 3. Procedure for Indexing 3 case a problem and two cases in this domain. The full case library 30 cases. The structures last metric and with respect combination module are both discussed two knowledge thresholds. The similarity metric estimates how similar are to the application of a particular operator. The thresholds are used by the the rules. These in deciding whether an analogy required by the core method are the similarity should override two problems further below. in this toy example has The individual modules in the core method are presented in the following sections. 2. I. I. ldexing The purpose of the indexing module is to organize the cases to make them accessible for or against later for CBR. CBR will use the cases to critique RBR; cases are therefore viewed as evidence a rule if it illustrates a place where the rule makes a correct prediction. It constitutes evidence against a rule if it illustrates a place where the rule makes an incorrect prediction. The indexing module stores the case as a positive or negative exemplur of the rule accordingly. the rules. A case constitutes evidencefor indexing: The complete indexing procedure ic) does the actual for a case is shown in Fig. 5. It applies RBR to the the case as if it were a new problem. Step to it. to apply case as a positive or negative exemplar of each rule that was predicted to the case. It Step (d) completes one iteration of the procedure by applying an operator applies oO. the observed operator, so that when the rules make their next prediction (in step (a) ). it will be based on how the case was actually solved, not on how the rules the predicted operator, oP, would be incorrect, because would have solved then all of their subsequent predictions if the rules predict one wrong operator at the beginning, that are based on this initial wrong operator will be thrown off as well. indexed as described, they can be used as source for analogies. The indexed cases will also be used to help in judging analogical Once all of the cases have been it. Applying it stores exemplars compellingness (see Section 2. I .4). Given in the face of rule that the rules are not expected to be perfect, one may ask how this indexing the inaccuracies. Consider scheme performs is presented with a target problem, and the case library contains a source architecture to the target and has the same behavior. Will the indexing scheme problem be able as long as the rules fire the same way for the source and target problems. This is likely, is yes, regardless of rule inaccuracies, that is similar to retrieve this source? The answer the situation where A.R. Gelding, l?S. Rosenbloom/Artijicial Intelligence 87 (1996) 215-254 221 ‘Student’ rule ‘Normal traffic’ rule ‘Medium’ rule A Positive -- Negative A Positive - Negative - Johnson Johnson A Positive - Johnson Negative - Fig. 6. Results of applying PBI to client Johnson. for him. of the three rules that make a prediction Johnson is stored as a positive or negative exemplar of each if the rules handle that is both irrelevant that the source and target are similar; them is to test a property them. Thus given between between right rules, and retrieve handle these same wrong rules fire for the target problem. function, the domain. the only way for the rules to differentiate to their behavior and not shared the they will file it under If the rules it when In effect, the rules act as a hashing into behavior classes based on (weak) knowledge of it when these rules fire again for the target problem. they will file it under the wrong rules, and retrieve the source incorrectly, the source correctly, distributing exemplars just presented the rules The indexing scheme is termed prediction-based indexing (PBI) be- (EBI) features cases by it indexes should apply- cases by whatever that predicted which operators the predictions were correct. Equivalently, results in quite distinct modes of operation it can be thought of as the rules looked at in order to make their predic- there the rules [ 31; however, indexing rather than to make their own prediction of the in the two schemes. from the an- cause regardless of whether indexing to explanation-based tions. This is related are used to explain an observed outcome, outcome. This difference EBI needs to account swer using correct rule applications. that can even account for multiple nondeterministic). allowing both correct and incorrect nary rule-based set for performance. amount of work the architecture will have to do later to override wrong rule applications via CBR. the rules the rules in the forward direction, It uses the same rules as for ordi- answers and one the to minimize It prefers a theory that is as broad as possible-one answers rather than requiring one set for explaining that is as accurate as possible, PBI, on the other hand, applies rule applications. for any observed answer, and thus works backward to the same problem It prefers a theory (rendering reasoning, in the case, to the first client Example. As an illustration PBI applies sults are shown rule fires. It predicts erator specified exemplar of the ‘student’ operator, predicts neutral, positive exemplar of the ‘normal correctly predicts two operators. inattentive, Johnson of PBI, consider in the case library, Johnson, again in Fig. 6. On the first iteration, operator the attentive inattentive. Johnson rule. The indexing procedure proceeds to Johnson. On the second iteration, the toy auto-insurance example. in three iterations. The re- the rules are applied, and the ‘student’ the op- for Johnson. This differs from stored as a negative is therefore the observed traffic’ rule is made a rule based on the assertions of the previous rule. to apply the ‘normal the ‘medium’ which agrees with the operator given in the case. Johnson traffic’ rule. On the last iteration, the operator medium-risk, is therefore stored as a positive exemplar of the ‘medium’ 222 AR. GoldinK. PS. Rose~blo~~rrr/Art~c.ltrl frrtelligence X7 (I 996) 215-254 2.1.2. RBR Rule-based reasoning matches the rules against any attribute of the problem-solvin g state. including lem solving. Rule matching to step matching I-& corresponds rule is not actually applied at this point, but rather later if not overridden by CBR. that will only be applied the target problem. Rules can match assertions added by previous prob- (a) of procedure RC-Hybrid. The is taken as a provisional Example. Continuing with evaluate RC-Hybrid, the ‘student’ the risk of insuring client Smith isee Fig. 4). On the first iteration of procedure the insurance example, suppose the target problem is to rule matches and is selected as the provisional rule. 2.1.3. CBR It tries rule by looking to show that the target problem The CBR module acts as a critic of the RBR module. procedure RC-Hybrid. provisional exemplar of the rule. The negative exemplars of the rule are available the rule-this list, proposing analogies one at a time, until it runs out of exemplars, or the combination module judges one of the analogies to step (b) of is an exception of the the target problem and a negative in a list hanging off scheme. The CBR module goes down this was arranged by the indexing for an analogy between to be compelling.’ It corresponds The actual proposing of analogies takes three arguments: from source metric to-be-transferred exemplar, and the operator-to-be-transferred exemplar. The operator establishes the metric returns three arguments, the similari~ score; and the implicit or at-de. The implicit were found same outcome the features right-hand whether to be in common between is compelling the analogy that were judged by the metric a source problem, to target. Here a context two values: a numerical is done by applying for comparing a target problem, will be the operator that was applied the problems. Given the similarity metric. The and an operator- the source problem will be a negative to this these rating of the similarity, called the analogy, called the atzalogical rule that the side of the arule gives to be shared by the two problems, and the set of features the source and target problems determines the left-hand rule behind side gives the operator-to-be-transferred. The arule will be used for judging rule that any analogy makes is that a particular for the two problems. Accordingly, (see Section 2. I .4). example, the RBR module has just proposed Example. Back to the insurance dent’ rule as the provisional proposal by likening Smith above, Johnson from Johnson similarity metric. A similarity metric can, the ‘stu- this to previous negative exemplars of the rule. As was shown is one such negative exemplar. The CBR module draws an analogy the in general, be as simple or as complex as rule for Smith. The CBR module attempts to Smith, with respect operator, by applying to the inattentive to defeat ’ If there are multiple compelling analogies for different operators. this procedure will only find the first enc. The rationale is that multiple compelling analogies simply indicate multiple acceptable answers; the choice among them is immaterial. In practice, the issue of choosing among multiple compelling analogies was found to be unimportant; the current procedure already draws very few incorrect analogies (see Section 4.13). let alone incorrect analogies where an alternative compelling analogy would have been better. A.R. Gelding, KS. Rosenbloom/Arf#cial Intelligence 87 (I 996) 215-254 223 ranging features, to applying from simply counting identical a full expert system desired, feature comparison, insurance domain, a metric at the simple end of the spectrum was chosen: number of fields that match be-transferred). match For the analogy the same interval of a predefined in the two client structures Text fields are considered if the two numbers the metric yields from Johnson for measuring fall within the arule: it ignores to Smith, (and similarity. For the it counts the the operator-to- fields set of intervals. to match if they are identical. Numeric to doing a relevance-weighted If address1 (c) = Sigma Chi House and address2( c) = Stanford, CA and sex(c) = M and age(c) < 30 and occupation(c) = student then inattentive. This arule expresses The metric between Johnson and Smith returns a similarity the features shared by Johnson and Smith according score of 5, which is the number of fields (and hence also the number of conditions in the arule). to the metric, that match implements to, RBR or CBR. It does this by evaluating step (c) of RC-Hybrid: it decides which of the analogies to be compelling, then CBR wins; else score of in part on the similarity of compellingness are based If it deems one of them and thus the degree score is the degree to which the source and target problems are expected is only it also the metric the combination module does not rely on it exclusively; to an empirical verification. This is a test of how well the arule- to the similarity metric. Because the problems to which 2.1.4. Combination The combination module to listen the other modules proposed by CBR. RBR wins. Decisions the analogy. The similarity match on relevant attributes, to have the same answer, according a heuristic, however, subjects the analogy the generalization The test returns got right; and the significance of getting explained behind two results: the analogy-works for other exemplars the arule’s accuracy, of the accuracy that high an accuracy merely by chance. The calculation in more detail below. rating, which that is, the proportion of exemplars is 1 minus the probability in the case library. it of these results is Compellingness above: can now be expressed essentially the analogy must have a high similarity discussed well in the empirical verification. The conjunction compellingness. if the similarity works by spurious not also a plausible analogy A is defined more precisely as follows: An analogy between turns out not to be predictive coincidence similarity between on the available two apparently as a conjunction enables more robust judgements of the two factors score, and it must perform of similar problems will be rejected that is of an if there examples will be rejected for other examples; and an analogy its source and target. The compellingness Compelling-p(d) w similarity-score(d) and accuracy (A) >, A0 > SSo and (significance(d) 2 SO or similarity-score(d) > SS,) 224 A.K. Gelding, P.S. Kosenbloonr/Au~~crul Intelligence 87 (I 996) 215-254 for deciding when a value is high enough; from the outside, or set by the threshold setting module requires where SSo, SS,, Ao, and SO are thresholds can be provided This definition the similarity metric, and the accuracy and significance However, an escape clause-the analogies between overwhelmingly reading. for a significant the analogy accuracy disjunct to be strong on all parameters-the from the empirical verification. a way of accepting similar problems, even if there are not enough data involving SS+-provides they (Section 2.2.3). score assigned by The calculation of the accuracy and significance of an analogy will now be explained to a subset of the exemplars It does not apply in more detail. The first observation in particular, an exception class-of only rule. arule does apply on its right-hand observed Let: 0 to have been applied is that the arule may be viewed as a specialization- the provisional (both negative to the rest of the exemplars to an exemplar, side. This operator may or may not agree with the operator to the exemplar. Several definitions it will suggest the application in the case and positive) rule. It follows that the arule applies of the provisional library. When the of the operator o that is can now be made. to and that were observed to have . . that the arule applies m = number of exemplars had operator o applied, Iz = total number of exemplars M= number of exemplars of the provisional operator n applied, N = total number of exemplars of the provisional accuracy of the arule that the arule applies to, rule. p, of getting is then given by m/n. As mentioned the probability, p, a slight correction the significance that high an accuracy merely by chance. Th: is one minus of getting m out of II In calculating to be right for exemplars of p one of the exemplars-namely, that this source case does not exist; it uses m’ = m - 1 and rz’ = n - 1 therefore pretends in place of m and n. With this in mind, p can be calculated using Fisher’s exact test [ 13, p. 251: right is influenced by the fact that the arule was constructed the source case for the analogy. The calculation is needed. The probability above, p = prob(getting at least m’/n’ by chance) (1) Unfortunately, proximation reasonable can be calculated the probability of “right” exemplars Eq. (1) is computationally is therefore used. It assumes for nontrivial-sized case libraries. Under unpalatable that N is large compared this assumption, for large values of N. An ap- is to rt’, which the probabilities as if the exemplars are being drawn from an infinite population. Thus to the proportion of getting one exemplar right by chance is just equal r = M/N. The probability of in the overall population-namely, rule that were observed to have had A.R. Gelding. l?S. Rosenbloom/Artijicial Intelligence 87 (1996) 215-254 225 getting k exemplars r, and the probabilities multiply. The revised derivation of p is then: right by chance will be #--each exemplar has the same probability, p = prob(getting at least m//n’ by chance) = c m’<k<n x c m’<k<n’ prob(getting exactly k/n’ by chance) ($‘k( 1 - q-k. (2) this is compelling, the arule on the positive and negative exemplars of the provisional Johnson to four of these exemplars, again the analogy from Johnson to the ‘student’ that the arule applies the combination module Example. Consider analogy It tests rule. It happens others. Three of the four are listed as inattentive. an accuracy of 0.75. Turning are listed as inattentive. accuracy rating the similarity is 5. The thresholds values SSc = 4, SS+ = 6, Aa = 0.66, and SO = 0.50 analogy by analogy no compelling ultimately have predicted. to a similar analogies be assessed as medium inattentive are found score of the analogy from to Smith. To decide whether first runs an empirical verification. ‘student’ and three Thus m = 3 and n = 4, giving rule as a whole, 4 out of 10 exemplars of the earlier, in this domain were set to the the (see Section 2.2.3). Thus the same student in the balance of the problem risk, rather that solving, Smith will low risk as the rules alone would fraternity. Assuming than So M = 4, N = 10, and I = 0.4. The significance then works out to be 0.648 by Eq. (2). 4 Also, as mentioned is deemed compelling. The upshot is that Smith is determined to be inattentive, 2.2. The support modules required by the core method may not be readily available The knowledge structures all domains. The role of the support modules tures. Each of the three support modules deals with a particular The first, rational pairs may be available not be-but Rational each problem for the domain, to its answer. reconstruction, reconstruction these paths are needed by the core method as part of the case the path by which each answer was derived may library. from leading uses the weak theory to infer the path of operators issue in the construction. deals with the issue that while a set of problem/answer is to help construct these knowledge in struc- The second support module, may have gaps that prevent When such a gap is exposed, to add to the weak theory to bridge the gap. theory extension, deals with the issue that the weak theory through. the abovementioned theory extension proposes plausible new operators or rules reconstructions from going The third support module, threshold setting, deals with not be predefined values to use for the four thresholds the there may in the definition of analogical issue that 4 For comparison, Fisher’s exact test in Eq. ( 1) would have given 0.667; the discrepancy is noticeable because N is so small in this toy example. compellingness. training examples for itself from the case library. Threshold setting chooses values via a learning procedure that generates The support modules effectively reduce the knowledge to three: a weak theory, a set of problem/answer reconstruction knowledge three support modules. A more complete description if desired. as discussed below. The following theory extension have hooks and requirements of the architecture pairs, and a similarity metric. Rational domain the supplemental sections briefly describe to incorporate can be found in Golding [ 141. 2.2. I. Rutiorlal reconstructiot~ in pronunciation, how they pronounced Examples of problems and their answers are available in many domains-spellings patients and their diagnoses by which each answer was derived-experts and in medicine, etc. What tends to be not so widely available trouble a name, or arrived at a particular diagnosis, or came is of rather limited that wants to transfer in toto. Any system to a new problem needs some way of breaking down the answer (RR) provides a way of doing their phonetic transcriptions theorems and their proofs in mathematics, is the chain of reasoning articulating up with a proof. Unfortunately, without use; it can only be applied just part of the answer into individual this. Given a problem infers an operator sequence using a weak theory of the domain-RR that leads from the problem reconstruction module and an answer-and steps. The rational IO new problems this information, to the answer. an answer have Rational The operators must satisfy reconstruction can be viewed as a problem of search for an operator sequence. in the sequence arc drawn from a weak theory of the domain. The sequence two constraints. First, it must account for the given problem and answer: Validity: The operator sequence, when applied answer. to the problem, must produce the theory satisfies sequence is missin g one or more operators. to fill the gap. The opposite problem that no operator It may happen that the weak extension sequences. Here, RR operator sequence that even though plausible derivations. This is expressed invokes that is closest the rules are not perfect, the validity constraint; In this case, RR calls this signals theory is when there are multiple valid operator the to what the rules would have predicted. The idea is to steer RR toward they are good enough theory as a bias: the rules of the weak in a second constraint: it prefers Minimality The operator sequence must deviate minimally dicted by the rules of the weak theory. from the sequence pre- to alter this means for patching if RR cannot the weak theory: This brings up a second opportunity a valid operator sequence with zero deviation, a valid operator sequence extension option imperfect find that the rules do not predict for the problem at issue. In such cases, RR may call theory the rules such that they do predict a valid operator sequence. This is not to fix is rarely invoked, however; rules, but to supplement the primary approach of the architecture them with CBR. lead to two strategies strategy, which generates valid operator sequences and selects the one with minimal deviation; and in order of increasing the minimality-first strategy. which generates operator sequences for RR: the validity-first The two constraints above A.R. Gelding, P.S. Rosenbloom/Arfijicial Intelligence 87 (1996) 215-254 221 is the sum deviation, and selects the first valid one. The deviation of an operator sequence of the deviations of each of its operators, where a deviation metric measures the deviation of an operator. The default metric scores 0 if the operator agrees with the one predicted by the rules, and 1 otherwise. The scoring can be made more sophisticated by including domain-specific validity-first possible depends on a number of factors, including Pruning and ordering heuristics may be used in conjunction with either strategy it up. to their severity. The thereof, define a space of that is best for a given domain in the domain. to speed knowledge and minimality-first for doing RR. The particular strategies, and combinations the accuracy of the rules that penalizes deviations according strategies strategy A couple of observations pair that has several valid reconstructions, be regarded as doing a form of credit assignment. a problem/answer different credit assignment, the credit assignment the smallest minimize about RR can be made at this point. The first is that RR can that RR is given each of which violates a doing is implicitly it is doing the reconstruction with selects the rules. Put another way, it assigns credit so as to as it is deciding which rule violations rule. Then RR, in choosing the total amount of blame. by invoking a minimality In particular, suppose these reconstructions, hold. Moreover, total deviation among bias-it from The second observation concerns RR’s effectiveness in the weak theory. A direct operator affects as a function of the directness the final answer of a of the operators problem by directly altering the answer to be harder RR must therefore dangerous, By and large, effective RR will be. as the minimality therefore, to reconstruct, some part of it. An indirect operator does not manipulate itself, but rather affects the choice of other operators. because rely more on its minimality Indirect operators they are relatively unconstrained tend by the answer. them. This can be bias is only as accurate as the rules of the weak theory. in the weak theory are, the more bias in reconstructing the more direct the operators taken There enforce typically in PAM to RR, including this is the approach the validity constraint; is a variety of work related systems, and story-understanding that is, they produce among systems learning apprentices, plan recog- nizers, student-modelling systems. These systems all infer some kind of trace of the reasoning behind an agent’s observed behavior. Such traces systems that are consistent with the observed behavior. The differences lie in the bias the valid traces. One simple bias is to return the first valid they use for choosing among system. trace found; the one that makes A widely used bias is to prefer the work of Kautz and Allen fewest assumptions-as [ 181. The ACCEL system instead in the domain of the most coherent prefers automotive repair, prefers cal goal structure underlying adopt ory would have predicted. Such systems can be classified according in the space of strategies described modelling does arithmetic. the hierarchi- the linear sequence of the expert’s actions. Other systems to what a the- to where they fall student- to infer a model of how a student [26], which has also been used for plan recognition, trace. CELIA the valid [29], a learning trace that is thought apprentice to best capture the same bias as RR: they prefer above for RR. For instance, the simplest valid trace-i.e., [40], a story-understanding [5] uses a minimality-first trace that is closest the plan-recognition in, for example, the BUGGY the valid strategy system strategy will be used, with no pruning or ordering heuristics. Consider Example. The toy insurance domain, as usual, will furnish an illustration of RR. A pure validity-first the (see Fig. 4). The validity- reconstruction first strategy for the answer of medium first generates all valid operator sequences of the operator sequence for client Johnson that account risk: ( I ) attentive, (2) attentive,neutral, (1) *inattentive, (4) *inattentive, *endangered, medium-risk, *medium-risk. medium-risk. *medium-risk, is then measured. Operators *endangered, neutral, The deviation of each sequence with the ones predicted by the rules have been marked above with an asterisk the default deviation metric is used, then sequences with a score of 1.0; the choice among the deviation metric ‘student’ rule as less serious in the reconstruction reflected to disagree If (*). tie for first place them can only be made arbitrarily. However, treats violations of the (4) wins, as than other violations. Thus operator sequence that was actually used for this toy domain ( I ), (Z), and (4) that are found information in Fig. 4. shown In the process of reconstructing how an observed answer was derived, RR is bound of the weak theory. In such cases, the theory extension module to patch the weak theory appropriately. The general problem of theory 141. Chapter 41 gives a good overview of various the rubric of there has been subsequent work under takes a in which to theory repair. It is geared to the two particular situations for example. Because to turn up inadequacies is invoked (TE) is quite difficult. Wilkins repair techniques tried; that have been abduction [25] restricted approach TE is invoked by RR. the general problem is so hard, TE The lirst situation is when RR cannot pair. Viewing problem/answer reconstruction complete path from the start state (containing the answer). TE tries to complete between previously unconnected that will do this. TE selects metric. The cost metric inventing the minimal tind a valid operator sequence as a search task, this means the problem) to the goal state (containing for a given there was no states. In general, the path by proposing new operators to bridge gaps there will be multiple sets of operators is defined by a cost the cost of set, where minimality knowledge to evaluate typically uses domain-specific a new operator between a given pair of states. The second situation in which TE may be invoked that has zero deviation their prediction operator sequence to alter the rules to bring sequences. However, TE will only attempt In particular, if it is known template, current problem. then the new rule may be worth adding then TE can try proposing If this improves this under very constrained that a certain class of rules in the domain find a valid is when RR cannot from the rules. This presents an opportunity into agreement with one of the valid operator circumstances. fits a particular for the score of the best valid operator sequence, the template a new rule by instantiating the deviation to the theory. In the existing implementation, of its proposed changes. This provides a sanity check on whether the extensions to be reasonable. TE requests user approval before actually making any appear A.R. Gold@, P.S. Rosenbloom/Art~cial Intelligence 87 (1996) 215-254 229 attentive or inattentive endanaered or neutral high-risk or medium-risk or low-risk Fig. 7. RR’s search space for client Davis, whose answer has been modified to be negligible(Davis). Black arcs indicate applications of existing operators. Gray arcs are for new operators being considered by TE. recourse and forced to have an answer of negligible(Davis). examples (see Fig. 4) was modified Example. RR was able to reconstruct ance domain without a couple of additional client Davis could not find any operator sequence search space is shown tially known about so on. State sr is the final state, containing operator applications; ator, resulting the attentive state for its sibling operator, diagram the 30 cases in the case library for the toy insur- to TE. For illustrative purposes, however, RR was run on to call TE. In the first of these examples, RR this answer, and so it called TE. RR’s ini- the case: name( Davis) = Davis, address1 (Davis) = Toyon Hall, and Arcs represent oper- In the figure, state st have been collapsed with the arc and resulting in Fig. 7. State SO is the start state, containing for instance, an arc leaving state so applies This collapsing was done throughout the the new assertion attentive(Davis). the answer negligible(Davis). in a state st containing to theory extension. to hide distinctions arc and resulting the information the attentive inattentive. to explain irrelevant RR’s inability to reconstruct Davis can be seen from the unreachability of the final is to fix this by adding one or more new are considered, GO001 through G0004, shown by the gray for the insur- in a state, where an these, TE applies a cost metric is based on the number of inferences added by an operator. The initial state has zero inferences. across because the initial inferences, is an assertion in this domain state so. TR’s job in the figure. To choose among two assertions State sr has three and neutral(Davis). three have and final states. The metric state sr from operators. Four operators arcs ance domain. The metric inference State s2 has two inferences, tentive(Davis) states to be a constant tor to be the number of inferences to another. For instance, one three or a negative number of inferences, infinite ing existing erators ric can guide TE toward minimal GO001 through GO004 have costs 3, 2, 1, and infinity, G0003. This enables RR to infer for Davis. cost. The effect of this metric for as few as possible. This is a rudimentary to a state with is to connect for as many the cost of GO002 is 2, because inferences. it is considered to account extensions inferences operators inference to reach because other If an operator are needed inferences, the number of inferences then defines it; e.g., at- final is taken the cost of an opera- from one state it goes from a state with implicitly makes zero an is assigned and and final states us- and new op- example of how a cost met- of the theory. By the metric, operators hence TE prefers GO003 neutral, nonsensical, the initial as possible, respectively; it is implicitly making by going the operator sequence attentive, As an example of TE for rules, consider the rational reconstruction of client Johnson. As mentioned above, Johnson has four valid operator sequences: (I) attentive, (2) attentive, (3) *inattentive, (4) *inattentive, *endangered,medium-risk, *medium-risk, neutral, *endangered, neutral, medium-risk. *medium-risk, (*) Asterisks from the rules was sequence deviation. This signals an opportunity following in the list mark rule violations. The sequence with the smallest deviation (4 1 (as shown in Section 2.2.1), but it still has a positive that the the rules. Now suppose rule template for extending is known: If address2 (c ) = __ then endangered. TE may then instantiate the template for Johnson, yielding: If address2(c) = Stanford, CA then endangered. this rule is inserted agreement with When complete improvement nonzero. TE therefore proposes into the weak the rules-i.e., theory, it gives it brings sequence it a deviation of zero. This ( I) above into is an (4), and was from the previous best deviation, which was for sequence this new rule as a possible extension to the theory.’ 2.2.3. Threshold The threshold settirrg setting module (Tset) provides a principled way of choosing values for the thresholds of the core method. The thresholds are used in determining when an analogy is compelling. The definition of compellingness is repeated here for convenience: Compelling-p(d) G.=G? similarity-score(d) > SSO and accuracy ( A) 3 AO and (significance(d) 3 $1 or similarity-score(d) 3 SS,). is to enable the analogy is to pick values for the thresholds The point of compellingness to an analogy-i.e., when Tset, consequently, classified as compelling whenever takes a machine-learning the thresholds accept analogies analogies the user has the final say of what values to pick, based on Tset’s recommendations. the architecture to decide when it should listen is right and the rules are wrong. The goal of that will result in analogies being they would correct wrong answers of the rules. Tset tries to pick is, it should it should reject in that it generates so as to do the right thing for these training analogies-that that correct wron g answers of the rules, and, conversely, that spoil right answers of the rules. The approach is semi-automatic analogies, approach: training and Tset generates exemplar in the case its training library analogies in turn from the case is a target problem, library. and It pretends that each it finds all analogies s Although the new rule improves the system’s account of ihis particular client, it may worsen its account of other clients. The system depends on the user to verify that the rules proposed by TE are in fact reasonable additions to the theory. A.R. Go/ding, IT. Rosenbloom/Artijiciui Intelligence 87 (1996) 215-254 231 Fig. 8. Distributions of helpful, harmful, and misclassified analogies, as a function of similarity score, &To and SS+ mark the theoretically optimal settings for the similarity thresholds. ss,, ss+ Similarity score is harmful if it suggests for a target problem where to it from other exemplars. A training analogy right operator operator. An analogy the rules would have suggested one of selecting where misclassified harmful ones that are judged compelling. search While Tset could, threshold values in principle, that minimize the rules would have suggested is classified as helpful if it suggests the the wrong for a problem where task may now be framed as the wrong operator the number of misclassified analogies, the right operator. Tset’s the 4-dimensional space of threshold the number of misclassified for the one that minimizes quite costly in practice. Tset sets them one at a time. This gives up the guarantee of finding in exchange the first step, Tset temporarily run time. The threshold-setting for tractable analogies, Instead of trying to set all 4 thresholds simultaneously, adopts a simplified definition of compellingness: procedure has three steps. On settings this turns out to be therefore, the global minimum analogies are the helpful ones that are judged uncompelling plus the Compelling-p’ ( d) e+ similarity-score(d) > SO. requires analogies. Fig. 8 shows what prototypical distributions analogies would setting only one This definition misclassified and misclassified of SO that minimizes not choose user and lets him make the natural choice being a value just high enough Once a value of S.90 is selected, all training this value automatically, the number of misclassified threshold, SSa, to minimize the number of of helpful, harmful, look like at this stage of the processing. The value is also shown. Tset does to the is also set at this point, however, but rather displays the distributions the final decision. The SS+ threshold to exclude all harmful analogies. analogies whose similarity analogies they have already been classified as uncompelling, about how to set the rest of the thresholds. Each subsequent procedure below this value can be discarded; so offer no information of the threshold-setting only the ones that are left unclassified by the previous steps. This makes the subsequent steps faster smaller number of examples on which they are based. therefore has fewer training to run, although their conclusions less reliable due to the it also makes to process- analogies scores fall and step 232 A.R. Gelding, ES. Rosenhl~)onl/Art~~.iui Intelligence 87 (I 996) 215-254 250 g 200 ‘% 150 -$ d 100 50 0 0 I 2 7 3 5 6 7 Similarity score (a) IMributions of analogies by similarity score 0.2 0.4 0.6 0.8 I.0 Accuracy (b) Distributions of analogies by accuracy. 0.0 0.2 0.4 0.6 0.8 I .O Significance (c) Distributions ot analogies by significance. Fig. 9. Results of applying the threshold-setting procedure to the toy insurance problem. For each of the three steps of the procedure, the distributions of helpful, harmful. and misclassified training analogies are shown. The misclassified analogies are the helpful ones below a threshold value and the harmful ones at or above the value. Dashed lines indicate the values chosen for the thresholds. The second and third steps of the threshold-setting procedure respectively. These steps are similar to SS,). Each step adopts a temporary definition of compellingness, thresholds, analog more conjunct of the true definition. At the end of the third step, all four thresholds--S&, SS,, ACJ, and So-will to the first (except have been set. set the A0 and SO is no adding one that there Example. Tset was used to set the thresholds appear of the procedure. These curves do not quite have the ideal shape depicted for the insurance problem. The results of analogies are shown for each of the three steps in Fig. 8, in Fig. 9. The distributions A.R. Gelding, P.S. Rosenbloom/Artifcial Intelligence 87 (1996) 215-254 233 being based on only 30 cases, the number available for the insurance problem. The threshold values that were selected for this task were SSn = 4.0, SS+ = 6.0, A0 = 0.66, and So = 0.50. The values for SSe, SS+, and A0 were selected at or near the optimum values. The choice of So was less clear-cut, as the error curve was largely flat between 0.0 and 0.65 (this was because it was based on a lopsided 34 helpful analogies and 1 harmful analogy). Its value of 0.50 was chosen somewhat arbitrarily within this range. 2.3. Discussion A number of “frequently asked questions” about the design of the architecture are discussed below. They are grouped by whether they concern the combination of RBR and CBR, just RBR, or just CBR. 2.3. I. Combination issues Why is RBR applied before CBR? Rule-based and case-based reasoning can be com- bined in three main orders: RBR first, CBR first, or some interleaving of the two. The architecture presented here adopts the RBR-first strategy, using CBR merely to patch errors left by RBR. This strategy is appropriate when the rules are reasonably efficient and accurate to begin with. If the rules are deficient in some way, the CBR-first strategy may make more sense. If the rules and cases offer more balanced contributions to the problem solving, then an interleaving strategy may be best. from positive exemplars? While the architecture currently Can analogies be drawn draws all of its analogies from negative exemplars, analogies from positive exemplars could also be useful in certain situations. One way to use them would be to decide between RBR and CBR by weighing the evidence from positive analogies against that from negative analogies. The drawback of this approach, however, is that it relies on the case library to illustrate not only the places where the rules are wrong, but also all situations where they apply correctly. Given that the rules are assumed to be fairly accurate to begin with, this could require a huge number of positive exemplars. An alternative that relies less on having total analogical coverage of the domain is to use positive analogies to resolve nondeterminism in the rules-places where the rules suggest multiple operators. The operator with the greatest support from positive analogies is then selected. This approach is less sensitive to gaps in positive coverage because it compares positive analogies to other positive analogies, not to negative analogies. Gaps in positive coverage therefore tend to affect all operators in the comparison equally (especially if the evidence for each operator is averaged over a set of positive analogies). Such a scheme was implemented in Anapron, and is described below (see Section 3.3). This use of positive analogies may be regarded as a method for combining rules and cases to make nondeterministic answers unique. By contrast, the architecture presented here is a method for combining rules and cases to make deterministic answers more accurate. The two methods provide orthogonal functionality, and may be used separately or in combination. Anapron is an example of using them in combination. Could rules and cases be converted to a truly hybrid system-one all knowledge between inefficient or unreliable into a uniform representations. sources that works from multiple into a uniform representation? An alternative to convert and work from that. Converting tends to yield representations-is the conversion representation, See also Golding and Rosenbloom [ I5 1. rules and cases tends to be hazardous, however; 2.3.2. RBR issues if the rules are not of an i&then-else lire in any state to recommend form ? The architecture the next operator to the rules: a rule is held responsible it recommends. This credit assignment enables lets it associate past mistakes the architecture (negative of the rules-it What exactly one rule will affords an easy way of assignin g credit operators performance rules, and particular mistakes. In a more distributed, that of MYCIN 171, multiple is made. To accommodate credit-assignment of the credit for each decision later override similar incorrect behaviors by analogy evidence-gathering model of problem solving, rules can fire. and all contribute to each decision such a rule formalism procedure would be needed-one to each of the rules that contributed the architecture, an analogous into that would ascribe some proportion to it. to improve that assumes to apply. This for the the exemplars) with to the past such as that 2.3.3. CBR issues What is the appropriate draws an analogy, as an explicit the analogy. This purpose rule, involves it extracts the arule. level of generality the generalization It then uses the arule behind for arules? Each time the architecture the analogy, and represents it to do an empirical verification of in the case library. The trying out the arule on other cases is to see how well the generalization is not uniquely determined; An arule the only constraint holds up for other examples. to the similarity metric). The idea is to minimize specific-it in the arule all conditions the risk of overgeneralization. alization of the source and target problems. Currently, includes maximally get (according reduces more liberally: case library fication will be. Striking an appropriate balance between and the risk of overgeneralization verification the more general is. the easier However, the arule to which the arule applies, and thus the more informed is an area for future work. there is an argument for generalizing it will be to find cases in the the empirical veri- this greater ease of empirical is that it must be a gener- the architecture makes the arule shared by the source and tar- leap; this the inductive save its arules? Given the generalizations the arule the architecture Could the trouble of extracting could store the arule represents arule would be stored so as to always override form, this means ordering if-r/zen-else them. Incorporating Saving arules in this way would gradually shifting the burden of problem solving that the architecture already goes to its analogies behind into the existing (as arules), it certainly rule set is straightforward: it originated. Thus the rule. If the rules are of an the original the arule just ahead of the original “compile” the cases from CBR to RBR. Whether rule. into rules, thereby this should be done an exception class of the rule from which A.R. Gelding, P.S. Rosenbloom/Art$cial Intelligence 87 (I 996) 215-254 235 it saves a store-versus-compute tradeoff. The architecture the analogies; or it can compute is basically which case it saves the time of rederiving in which case imagine (re-)compute, constructed end up keeping could easily be rederived in the arules, the storage cost of keeping around all past arules. One could to the arules are that, because a policy of storing would these rules rather than store, was based on the reasoning above), that hardly ever fired; moreover, in either direction. The decision a large number of rules in the architecture to be maximally (as discussed this tradeoff its arules, if needed. can store resolving specific solving involve retrieving to a (disparate) is the process of for case adaptation the entire source solution, a source case to make it applicable do case adaptation? Case adaptation target case. Traditional and doing to patch the parts that are incompatible with the target case. the source from these individual How does the architecture transforming techniques localized problem The architecture case into individual operator sufficiently verbatim. Thus This strategy snippets, each of which addresses one subgoal of the case [ 211. employs to the idea of decomposing are to the target problem a strategy of “case adaptation by factoring”. that they can generally be transferred a source case into smaller parts, or presented here takes a different to the target problem. The tack: using RR, it factors It then draws analogies operator applications. operator applications the architecture fine grained applications is related individual learn new cases? Classical CBR [ 301 involves a learning it is stored back into the case library step could be incorporated ask, after each problem Such a learning Can the architecture after a target case is solved, bank of experience. presented here by having solution directly. If not, further dialogue would be needed away. This procedure run-time case library off-line is correct. If the answer if desired. feedback is affirmative, the architecture its the case may be added to the case library to debug the answer before it is stored it would create a need for from the user. However, additional cases can always be added to the is not currently implemented because step: to enrich the system’s the architecture into it solves, whether in the case itself against cases through empirical verification. A bad case may lead to a bad analogy there is a significant number of library handled? The architecture protects is noise How inaccurate being proposed; but the analogy will be rejected unless supporting score to exceed supporting been set high enough to avoid such spurious analogies. cases. The one exception the SS+ threshold; cases. This is if the bad analogy has a high enough similarity in that event, it will be accepted even without other should have is highly unlikely, however, as the SS+ threshold 3. Anapron The architecture presented here was applied to name pronunciation, resulting in the Anapron block for pronunciation system. Names, because of their varied etymology, systems; this has made name pronunciation are a notorious stumbling an important problem 236 A.R. Chiding, ES. Rosenbloonr/Art~crcrl Intelligence 87 (1996) 215-254 complex that perfect rules of pronunciation accurate and efficient synthesis. The domain rules have never been devised-rules is well suited to application of the architecture, in text-to-speech is as reasonably sufficiently inevitably have exceptions. This suggests application of the architecture presented here. The architecture can tapping pronunciations. potential not true hybrids. they may be, while also their has the existing systems, which are either rule-based or case-based, but source, namely examples of names and take advantage of the existing are known, yet the domain from both sources, into an alternative the architecture By assimilating to outperform knowledge knowledge imperfect though rules, The sections below start by introducing to this domain The appli- analogical cation of the architecture in the rules. mechanism are at a high level, to give the basic idea of Anapron’s operation and a The descriptions sense of the task of name pronunciation, without getting deep into the intricacies of the domain. For full details, see Golding the domain of name pronunciation. is then described; and an additional to deal with nondeterminism that was incorporated is presented [ 141. 3. I. Name pronunciation interest. application, applications, Name pronunciation of origin of a name, is a problem of practical but especially name-intensive that makes names unique, as compared It comes up in almost any such as telephone- (i.e., number to infer then decide how to treat foreign names. stilted at best, is an American user population, [ 381. The most important property is their varied etymology. Not only must a pronunciation it must to the native pronunciations at worst. What text-to-speech based credit validation, voice mail, and generic reverse directory assistance to name) regular words, the language Strict adherence and unintelligible some appropriately interpretation related difficulties make names problematic solution would be to construct a giant pronouncing is apt to encounter. The problem A system constantly a finite amount of resources building a name dictionary; always have to deal with the problem of unfamiliar names. of the foreign for pronunciation stories off the AP newswire, languages. These etymology- systems. The brute-force the system is in general open-ended. for instance, has to contend with a In the end, one can only expend systems will is that the set of names can come out sounding dictionary of all names reading changing is needed, assuming set of newsworthy pronunciation individuals, anglicized system Until fairly recently, the solution was simply to pronounce names badly; pronunciation to be an open problem effort has been devoted systems. The predominant to the problem, approach has been to develop to names, as in, for example, the OratorTM 6 system specifically commercial of proper names was acknowledged however, a substantial high-quality tailored DECvoice demonstrated, every contingency. No matter how many exceptions. This observation they have also shown [ 371. While these systems have achieved among the extreme difficulty of writing rules are written, is the basis for an alternative resulting [ 191. In recent years, in several rules (341 and yet to cover to be to the problem, there always seem approach the best performance rules h Orator is a trademark of Bellcore. A.R. Colding, P.S. Rosenbloom/Ar?ijicial Intelligence 87 (1996) 215-254 231 Table 1 Illustration of Anapron’s pronunciation modules for &IDEL; the output of the modules has been abridged for clarity Function Application to KEIDEL Module Language Morphology Transcription Determine language Identify prefix, root, and suffix morphemes Map letters to phones Syllable structure Break into syllables Stress assignment Assign level of stress to each syllable Selection Pick best language/morphology analysis if Generic; if German Generic or German KEIDEL = a single root morpheme kiydehl kaydehl kiy-dehl kay-dehl k-iydehl k‘ayd-ehl k‘ayd*ehl if Generic; if German if Generic; if German (German) than as of names and their pronunciations, one of a number of prespecified behaviors [ 91, is essentially a relevant source name from the dictionary, starting a new name by retrieving process. The approach, embodied from a large dictionary which views name pronunciation more as a huge bag of idiosyncratic a rule-governed in the TTS system case based, pronouncing performing (e.g., AGNANO = AGNELLI rule-based for case-based previous, practical system has taken a true hybrid approach. Sullivan and Damper have combined generates RBR and CBR within a solution as Anapron does. and and such as suffix exchange to the room and the two; however, no [35] but their model does not intermix imperfect to name pronunciation performance suggests combining in a model of human pronunciation, leaves the rule-based ‘ITS performs well-comparably like those other systems, either a pure rule-based or a pure case-based systems mentioned - ELLI + ANO). rules and cases The good, but transformations, improvement. approaches solution-it above-but of both still Name pronunciation is defined here as the task of converting into an output pronunciation, e.g., k‘ ayd’ehl is a written specification of how to pronounce to produce an actual spoken an input spelling, e.g., (rhymes with MY BELL). 7 The it could be fed the name; rendition. A pronunciation the sequence of phones or sounds the phones are kaydehl, stress on kay. The in the name, as well as the level of stress . and * are stress stress on for purposes of this * means primary while to put secondary is taken from DECtalk TM ’ but is unimportant , KEIDEL, pronunciation through a speech synthesizer includes to place on each syllable. Here, marks. The * says dehl. The notation paper. In Anapron, the task of name pronunciation is divided among six principle modules. Table 1 gives a brief account of what each module does, by way of illustration KEIDEL. Transcription to the output pronunciation and stress. The language Here, the language module generates they contribute are the top-level modules: directly. The other modules are in service of transcription answers. and morphology modules produce nondeterministic language classifications of the name- and stress assignment two possible for 7 This is an example of an appropriately anglicized pronunciation. The native German pronunciation more nearly rhymes with IDLE [ Stefanie Brtininghaus, personal communication, 19951. 8 DECtalk is a trademark of Digital Equipment Corporation. “Generic” or German. This nondeterminism the selection module it by choosing module makes its choice resolves is discussed below (see Section 3.3). the other modules until 1s carried the German analysis. The way the selection through 3.2. Applicutim of the architec~trrrr~ to its two top-level the application of the architecture briefy described, The architecture was applied not to the task of name pronunciation transcription as a whole, but and stress assignment. This section sketches sources are followed by an illustration of the architecture’s operation using them. sources for each task: a weak theory, :I The architecture works from three knowlcdgc to each of these subtasks. The knowledge subtasks: is then to work through pairs, and a similarity metric. The weak theory for transcription [ I], as well as introductory system text-to-speech Italian, and Spanish. Each operator set of problem/answer was based on the rules of the MITalk in the weak grammar texts for French, German, theory says how to map a letter or letter cluster into a string of phones. For instance, the operator C:S says to map the letter c to the sound s, i.e., a soft C. as in CENT. The to basic operation of the theory transcribe each letter or letter cluster. The rules for choosing which operator to apply can the language of the name, test the letters on either side of the cluster being transcribed, and its morphological if is the familiar the following this “C softening” the rule at imposes issue is matched. Such constraints the letters of a a circular dependency may arise, in which case a name may be processed. Occasionally has a total ot strategy deadlock-resolution 295 operators and 619 rules. letter is I, E, or Y, and the name is of Latinate origin--this rule. A rule can also test how surrounding structure. For example. one rule recommends is invoked. The weak theory for transcription the name, applying operators letters were trmscriDe& letters be transcribed that the surrounding the possible orders the C:s operator the constraint in which restrict before the grammar texts men- (241. The goal of stress The weak theory for stress assignment is based on MITalk, into a proper these binary stress theory of Liberman is to assign a level of stress-primary, in the name. The weak theory starts by assigning and Prince secondary, or zero (i.e., no stress) -to stress to each morpheme tioned above, and the stress assignment each syllable in the name individually. This is done in two backward passes of the morpheme: the first pass makes a binary decision as to whether each syllable has zero or nonzero stress; the stress pattern. levels second pass refines The stress patterns into a stress pattern for the individual morphemes are then combined structure on the morphemes. The for the whole name, based on imposing a hierarchical operators of the weak theory provide primitives the above procedure. For nonzcro with nonzero syllable with nonzero applied and how it is instantiated-e.g.. should jump back each time. The rules can test the spelling of the name, morphological has 7 operators the first backward pass of assigning Lero or the last syllable to the next is operator its language, and syllable structure. The weak theory for stress two operators to each syllable of a morpheme: MSR, which stress; and propagate, theory control which operator the propagate identifies jumps backward stress. The rules of the weak thereof) and 29 rules. structure, (not how many syllables for implementing transcription, instantiations three-valued implement repeatedly including instance. which stress A.R. Gelding, FS’. R~)senbloom/Arf~cicc[ Infelligence 87 (1996) 215-254 239 The second knowledge source of the architecture, the set of problem/answer pairs, in the case of both transcription of 5000 surnames. 9 The dictionary was derived, dictionary in the US, 1250 sampled ranks 10,000 to 60,000. The utility of these last two groups are important but that may not appear randomly includes the 2500 most frequent names from ranks 2500 through 10,000, and 1250 from that is to illustrate patterns in the very common names. and stress assignment, from a pronouncing there are two factors. First, The similarity metrics used in Anapron are based on broad, approximate knowledge For transcrip- vicinity of the cluster- effects: the next sounds, as well as of the cluster, aspects of the previous ones. The second factor affecting affect the cluster’s pronunciation. is pronouncing a given aspect of a name’s pronunciation. in the immediate This is due to assimilation the transcription it is anticipating the letters is the overall “shape” of the name-essentially, and vowels. The shape affects such as language factors into account by combining the letter cluster being the pronunciation in that it reflects global the two takes of the two names transcribed with a rough global comparison a detailed comparison and morphology. The transcription metric its pattern of (orthographic) about which factors determine tion, to-be-transcribed while the mouth retaining the cluster consonants influences preceding immediately of the names. around The stress metric is analogous in the region to the transcription metric: that is most critical of the two names at issue, as well as a rough global comparison, morphology. More detailed specifications for the particular it does a careful comparison stress operator to pick up on effects of language and [ 141. in Golding the abovementioned of the metrics can be found The remainder of this section illustrates how Anapron, given the name sources, pronounces of KEIDEL is actually performed in some order, to map letter clusters names. The illustration will be for the transcription is Generic, and once assuming transcription above, of knowledge twice, the KEIDEL example of Table 1. Transcription is once assuming to for the German case. As mentioned selects the the name, operators via the RC-Hybrid procedure. Table 9 summarizes the order in which the letters are actually processed. For the first letter of the name, K, RBR the letter K to the phone is invoked this choice of k (as in KITE). CBR is then invoked operator, but no such analogy the in the table, operator suggested by the rules, K:k. Application of the next two operators EI:ay and D:d, is similarly uneventful. it is German. This example involves applying operators is found. The combination module to propose analogies contradicting the K:k operator, which maps to strings of phones. Anapron the results, disregarding first, and suggests therefore applies For the E, things get more interesting. The rules suggest E:ey, the default pronunci- verification (as in F--GE). the E:eh operator However, CBR finds an analogy instead. This analogy has a similarity from VOGEL ation of E in German score of 0.73. which suggests says Empirical to apply E:eh to 7 cases in the case library: EDELBROCK, FOGEL, GEIBEL, LOGEL, SCHNABEL, SPEIDE_, and of course is 7/7 = 1.00. VOGEL. All 7 have E:eh applied. Thus is The significance works out to be 0.71. The way the thresholds were set, the analogy behind context-applies the accuracy of the analogy that the generalization in German names the analogy-which in a particular reveals ‘) This dictionary was kindly provided by Bellcore for purposes of this research. 240 Table 2 Transcription of t&IDEI. under the German analysis; the table shows the transcription operators recommended for each letter of the name by RBR. CBR, and combination RBR K:k may t,.d r::ey 1.:1 K I 1 I) Ii I. _ CBR Combination K:k m:ay rxd E:eh LA i::eh _____ deemed compelling. the analogy with VOGEL. Thus the combination module selects E:eh, overriding the rules by For the final L of the name, the rules suggest ~:l, which again goes unchallenged. the output of the transcription module for the German analysis of KEIDEL is opposed to kaydeyl. which is what the rules alone would have said. Thus kaydehl-as 3.3. Positive analogies rule applications. The method starts with multiple candidate pronunciations is to use the positive exemplars just as negative exemplars were used through rules in Anapron return multiple these aspects of a name. This rule the method of positive in the case base to detect of the language and morphology by seeing if the operators seem to have been applied correctly. correct analyzing As mentioned rule applications, the language and morphology is resolved by the selection module, above, answers, due to the difficulty of uniquely nondeterminism analogies. The idea of the method to reinforce incorrect a name, corresponding each candidate pronunciation rules. applied that pronunciation by drawing analogies between each operator application positive exemplars of the rule that recommended application evaluation of that operator will be. Specifically, score of the best analogy the scores of its transcription to the different ways of applying It evaluates in deriving seen, correct application, and stress operators. is to a previously lo that were It does this and the the operator the system’s is the similarity is the average of in the pronunciation that operator. The closer the more favorable the score for an operator found. The overall score for a pronunciation Table 3 shows how positive analogies were used in the KEIDEL example. Only analogies the Generic analysis; the German analysis was ultimately the operators are shown. On these, the German analysis outscored is why the German analysis did the same turns out to be true of the overall scores, which selected. The main reason for transcription “’ In addition, a pronunciation may receive bonuses or penalties assigned by the rules. The most common type of bonus is when a name contains a prefix or suffix characteristic of a particular language. For instance, the name ROCHAMBEAU has the characteristic French ending -EAU; the French analysis of this name therefore receives a bonus. These rule-based scores complement the analogy-based scores. and enable the system to decide among competing pronunciations of a name even in the absence of a case library, albeit in a less informed way. A.R. Gelding, RS. Rosenbloom/ArtifciaI Intelligence 87 (1996) 2 15-2.54 241 Table 3 Positive analogies for transcription operators of the German and Generic analyses of KEIDEL (a) German analysis Analogy KILLER -+ KEIDEL OP K:k EI:ay SPEJDEL-+ K~DEL DA E:eh L:l SPEIIJEL --+ KEIIJI~L VOGEL --. KEIDEL GEIBEL -+ KEIDEL Score 0.67 0.67 0.91 0.73 0.91 (b) Generic analysis Analogy KEELER --+ &~DEL R&ID-KEDEL RIEQEL -+ KEIQEL RIEDEL -+ KEIDEL RIEDEL- KEIDEL OP K:k EI:iy D:d E:e L:l score 0.88 0.00 0.71 0.86 0.88 Transcription score: 0.76 TranscriI%ion score: 0.56 operators is that the Generic analysis had little support better on transcription EI:iy operator; REID was used, but scored poorly due to its global dissimilarity KEIDEL. The name RIEDEL, while valuable elsewhere help with EI:iy, because the E:eh operator a rule; thus there are no positive exemplars on which to base its score. Instead, of such an operator it-in for its from in the Generic analysis, could not its I and E are in the wrong order. One other point concerns this operator was applied by analogy, not by the score that suggested this case, the VOGELKEIDEL in the German analysis: score of the analogy to be the similarity is taken analogy. 4. Evaluation Anapron’s performance was evaluated understanding in three phases. The goal of the first phase a profile was taken of system performance: was to gain a quantitative of how active each part of the system was in practice, and any deviations the expected performance were analyzed. The second phase stepped back from this internal the performance analysis of the system and to that of other of the rule/case systems, and humans were included approaches? Commercial systems, other research in the comparison. Once the overall performance of Anapron was ascertained, the third phase was to understand how it achieved of each of its components. This involved systematically modifying measuring phases. looked at the “bottom as embodied line”: how does compare the impact on system performance. this performance, by evaluating The sections below discuss and the three hybrid approach, each component, the contribution in Anapron, from 4.1. Exploratory measurements Exploratory measurements operation, emerged: names, although (2) below present and to detect any deviations (1) the system found fewer strong analogies of Anapron were taken to get a quantitative picture of its from the expected behavior. Two main findings for rare names than for common strong or weak, remained constant; and was too strict. The sections the test set that the exploratory measurements were based on, and the the total number of analogies, the system’s criterion compellingness for analogical measurements are grouped by whether nent. that were made, together with the resulting they were purely objective, or included findings. The measurements compo- a subjective 4.1.1. Test set The test set for this and the other experiments was drawn from the Donnelley a database of over 1.5 million distinct surnames covering 72 million households from extremely US. Names in over 670.000 households) to cxtremcly 1 household). The number of households to as the ,freyuency corpus, in the (e.g., SMITH, which occurs rare (e.g.. BOURIMAV~NG, which occurs in that have a particular name will be referred (of occurrence 1 of the name. in Donnelley common range than randomly the narrowest the names were selected and randomly had fewer from Donnelley sampling Test sets were constructed spectrum, If Donnelley from f that was big enough. The test set for the objective measurements by selecting points of interest along the an appropriate number of names at each frequency the desired number of names at some frequency point. frequency f. then con- band around ,4096. The frequencies were tains 13 exponentially of Anapron’s distributed in a pilot study, which showed that Anapron’s percentage behavior-this of acceptable pronunciations is decreased exponentially. The test set has a total of 10,000 names, with between 2.50 and 1000 at each frequency. the test, and the size These numbers of the confidence to be disjoint by rote lookup are unrepresentative frequencies: this yields evenly spaced measurements in the resulting measurements. represent a tradeoff between from Anapron’s dictionary, drops linearly as frequency since names pronounceable The names were chosen distributed because of system behavior. the cost of running was determined exponentially symmetric I. 2,4,8,. intervals 4.1.2. Objective ttteasurertmts morphology, Objective measurements were made for both the rule-based and case-based parts of the counted how many operators were applied by each system. The rule-based measurements module--language, The case-based measurements and rejected, and for what reason, where the reason corresponds satisfied or failed to satisfy the compellingness down by name frequency, rarer and thus more difficult syllable structure, and stress assignment. counted how many analogies were proposed, accepted, to the way the analogy predicate. All measurements were broken to see how the system’s behavior changes as the names get to pronounce. transcription, The main finding from the objective measurements was an effect termed the atuzlog- It says that as name frequency decreases, to the name decreases. where a highly plausible ical decline. analogies high similarity transcription scription analogies as a function of name frequency. accepted analogies, broken down into two reasons These correspond the number of highly plausible is one with a very score (this notion will be made more precise below). Fig. 10 shows the is based. It plots the number of tran- for in turn are for acceptance, denoted significant, and highly plausible. in the last clause the analogy satisfies and one for rejected analogies. The accepted analogies data on which the analogical decline to which of the two disjuncts It is split into two graphs-one analogy A.R. Gelding, P.S. Rosenblnom/Art~cial Intelligence 87 (1996) 215-254 243 of the definition of compellingness. for convenience: Compelling-p(d) u ” The definition of compellingness is repeated here similarity-score(d) and accuracy (A) 2 A0 and (significance(d) 2 SSe 3 SO or similarity-score(d) 3 SS+) . to be those compelling Since highly plausible be seen Rejected analogies, time for the two reasons whether analogies match the last disjunct of this definition, analogies whose similarity score are broken down into two groups, like the accepted analogies, inaccurate, and unsupported. These correspond the second or third conjunct of compellingness. they can now is KS+ or greater. this to I2 for rejection: to satisfy the analogy failed rank-correlation < 0.01, p(D) < O.Ol), but no other significant in these curves, a Spearman To test for upward or downward (p(rS) that the system that this does not mean trends test [ lo] was run on each. The results were that the curve of highly plausible was found to decrease was found. This means names. Note, however, rare names-it number of “normal plausibility” strated by the absence of a decreasing counts all accepted analogies other of the analogical decline can be found less effective at finding highly plausible analogies. analogies does not decrease significantly, trend in the curve of significant found fewer highly plausible that case-based than highly plausible ones. A further in Golding is merely reasoning [ 141. analogies trend for rare for In fact, the as demon- analogies, which is useless investigation analogies 4.1.3. Subjective measurements Subjective measurements of the system’s behavior were made not on the lO,OOO-name test set described to make it feasible at each of four (roughly) above, but on a scaled-down lOOO-name version. This was necessary to obtain human judgements. The lOOO-name test set had 250 names exponentially distributed frequencies: 1, 32, 256, and 2048. The subjective measurements consisted of judgements, of the following: the overall pronunciation, the and analysis, and the analogies (whether accepted or rejected). The judgements were made by the first author. editor was used, which provided about a name. The editor this rather laborious process, a judgement the choice of language/morphology for entering or changing for each name, about the individual transcription judgements acceptability stress operators applied, proposed To facilitate a graphical user interface also verified that the judgements for a name were complete and consistent. It has no reason score and accuracy, ” Analogies matching both disjuncts are counted as highly plausible-this such analogies. After looking at their similarity reason of high plausibility. I2 Analogies from the similarity technically and thus fail to satisfy Anapron; analogies. Consequently, that fail to satisfy both conjuncts are counted as inaccurate, to test whether score and accuracy, without having the system has been optimized analogies cannot be accurately to check further whether to not retrieve a third reason implausible for rejection, there is score less than S&i, the first conjunct of compellingness. Most implausible analogies are never generated by that would give rise to such the very distant analogs that have a similarity for analogies implausible, reflects the system’s processing of for them compelling the system declares again because they are unsupported. Also, this can be determined counted, and arc omitted from Fig. 10. they are also significant. ()_I_ 4096 1024 256 64 16 4 I (II 4096 1024 256 64 16 4 I Name frequent) Name frequency ( a) Accepted analogies. I h ) Rejected analogies Fig. IO. Number of transcription analogies as a function of name frequency. Each of the four curves plots the number of analogies that were accepted or rejected for a particular reason. The number of names at each frequency has been scaled to 1000. that were missed) were analogies commission compellingness The main result of the subjective measurements was that errors of analogical omis- errors that the system’s too strict. This could be fixed by criterion, or by the compellingness between good and bad (harmful criterion may have been thereby relaxing analogies drawn). This suggests to allow better discrimination the similarity metrics to greatly outnumber thresholds. ” the system’s found (helpful sion of analogical analogical lowering re-working analogies. systems to see how the performance of the rule/case In the second phase of the evaluation, Anapron was compared with a variety of other name-pronunciation hybrid method compares with that of alternative approaches. Seven other systems were used in three state-of-the-art commercial the comparison: (NETtalk), learning system ones mentioned earlier Bellcore and DECvoice Labs, which vanilla version of NETtalk block-decoding postprocessor results of the experiment. A more complete presentation Rosenbloom two versions of a machine- systems are the same (see from from DEC, both of which are rule based, and TTS from Bell is the is NETtalk enhanced with a [ II]. The sections below sketch the test set, design, and in Golding and and two humans. The commercial the beginning [ 331, and BP-block, which two versions of NETtalk the OratorTM system are BP-legal, which is case based. The of Section 3): can be found systems, [ 161. 4.2.1. Test set The test set for the system comparison was similar surements, except that: ( I) only 100 names to that used in the subjective mea- (not 2.50) were chosen at each frequency, ” The results of the threshold modification study suggest that the most effective threshold to lower would be .S&: see Section 4.3. A.R. Gelding. ES. Rosenbloom/Arti@ial Intelligence 87 (1996) 215-254 245 to reduce constrained system performance the burden on the human test subjects; and (2) to be disjoint from Anapron’s dictionary, the test set was no longer of as an unbiased measurement includes names both in and out of the dictionary. there is no objective criterion of correctness was evaluated by asking human 4.2.2. Design Because pronunciation ceptable. Each system was run on the 400~name of the computer of the human pronouncers was tape-recorded The two versions of NETtalk were trained on Anapron’s 5000~name pronouncing tionary. a it ac- test set described above. The output the output in the form of written pronunciations; as written pronunciations. for name pronunciations, systems was collected test subjects whether and transcribed they found dic- A cassette tape was made of the pronunciations duplicate pronunciations, randomly. The order of names in the test set was permuted the identities of the systems, generated by all systems. This and permuting in- the remain- randomly all pronunciations test subjects were read by the to the cassette listened speech synthesizer. A panel of 14 human for each name, eliminating volved, ing pronunciations as well. To hide DECtalk tape and rated the acceptability of each pronunciation. 4.2.3. Results The main appear results of the system comparison systems and humans have been omitted as their identities in Fig. 11. The names of the commercial are not relevant here. The figure gives the percentage of acceptable scores, out of a total of 5600, awarded The scores are broken down to each system by name labelled Ubound, which generates acceptable votes from pleased simultaneously, tested. (5600= 14 judges x 400 pronunciations). includes the pronunciation It measures the pronunciations the greatest number of to which all judges can be from the eight systems frequency. The figure for each name the judges. just using ninth system, that received an imaginary the degree available Fig. 11 shows that Anapron performs almost at the level of the commercial the two versions of NETtalk. Also, although than systems, the eight to score at least 97%. This suggests asymptote at 93%, the Ubound system demonstrates that there is room for improvement better and substantially systems seem to hit a performance that it is possible in all systems. To detect whether the differences between Anapron and the other systems were statis- an ANOVA was run, followed up by a Bonferroni multiple comparison in the table. sys- ranges, systems could not be tically significant, procedure. The results are shown Overall, Anapron outperformed tems, humans, and Ubound did better than Anapron. However, a significant detected. Given difference between Anapron and certain commercial the two versions of NETtalk, but the commercial in Fig. 11 as annotations in some frequency is able to exploit two knowledge sources, while on the scores that Anapron that Anapron did not outperform the other com- the puter systems use just one, commercial sources were put together as rapidly as possible it may be surprising It should be borne systems. in mind, however, from whatever that Anapron’s knowledge rules and cases could System Name frequency Overall 3048 256 ?2 UhCWiId 98 + Human I 07 + Human2 9x + corn I Con12 97 + 96 + Con13 96 + Anapron BP-block BP-legal 91 81 78 - - 98 + 93 t 94 + 95 + 90 +? 94 i- 88 83- 72 98 + 9.3 + i 94 c)? i 87 i ‘) 8’) C 85 77 66 I I. Percentage of acceptable scores Fig. shown as a table and as a graph. Scores in the table have a plus sign (+) if higher minus sign (-) if lower. Ail differences are aignilicant at the 0.01 mark ( ?), which are not significant even at the 0. IO level clutter: those of Ubound and Corn?. The curve fat- each sys~ern. broken down by name ‘The humans were omitted their curves would level, except lie between frequency. The data are than Anapron’s score, or a those marked with a question from the graph to avoid for BP-legal was truncated when it ran off the bottom of the graph systems, and unfortunately for the cast-based tuned rule sets for the rule-based in contrast, use extremely high-quality, the MITalk rules and a WOO-name pronouncing dictionary. The be obtained-basically propri- commercial systems, and a etary, knowledge sources-carefully system. Anapron was in fact found dictionary of over 40,000 names (see Section 4.3); it would to improve on the performance appear, however, this improvement was outweighed by the mediocre quality of the rules and cases used. Thus while Anapron provides a proof rules and cases improves of concept of the architecture-a systems must performance-actually for test- wait until such time as commercial-quality ing. that combining to outperform commercial knowledge sources can be obtained demonstration this improvement that in the system comparison, of its rules or cases alone using 4.3. Mod~ficution studies thresholds. to its overall performance, language knowledge. morphology 01’ Anapron’s components a set of in which various components were modified, and the effects rules and To gauge the contribution experiments was performed on system performance were observed. Five such studies were run, modifying: cases, knowledge. The first study-on combining achieved higher accuracy by combining either one alone. The threshold study tested how sensitive to the threshold SS,, A(), and Se. Extreme to hurt accuracy, although the effects of the key result that the system rules and cases than it could have achieved with the system’s performance was SSe, found improved accuracy at the expense raising or lowering of any one threshold was generally settings used in the definition of analogical rule-based and case-based lowering SSo sometimes rules and cases-directly and syllable-structure compellingness-i.e., investigated knowledge, It provided reasoning. A.R. Gelding, P.S. Rosenbloom/Art$icicinl Intelligence 87 (1996) 215-254 241 run of increasing knowledge-i.e., and stress. Degrading to have a substantial structure knowledge in Golding fully [ 141. knowledge needed time. The remaining three studies concerned in support of the two top-level support tasks, transcription sufficiently was found syllable- impact on system accuracy, while degrading had a relatively minor effect. These studies are described more the language or morphology negative the system’s knowledge The rule/case modification study [ 151 is the subject of the rest of this section, The test set, design, and results are discussed below. 4.3.1. Test set the rule/case Like the system comparison, required a great deal of human effort in the evaluation. The test set was therefore made the same size as in the system names at each of four frequencies. The only difference was that, as in comparison-100 the exploratory measurements, dictionary, since again rote lookup behaviors were not of interest. the test set was constrained from Anapron’s to be disjoint experiment 4.3.2. Design varying independently The rule/case study involved of rule strength and case strength, as the proportion of acceptable pronunciations the strength of the system’s rules the system was and cases. For each combination test set, and its accuracy and run time were recorded. Accuracy run on the 400-name generated by the system, was measured where acceptability was judged by the first author. I4 All judgements were cached and across trials. Run time re-used was the average in the test set. a name The system, written with 8M memory. in CommonLisp, was run on a Texas Instruments Microexplorer to help enforce consistency to pronounce if a pronunciation for the system in seconds, recurred, time, The rules were set to four different strengths: 0, l/3, 213, and 1. A strength of 1 the system would be unable in the system. Strength 0 means means all transcription and stress rules were retained that all rules were deleted except default rules. The default rules transcribe a letter or assign stress if no other more specific rule matches. The default rules cannot be deleted, otherwise for some names. Retaining rules corresponds rules and 16 of the 29 stress rules. Rule strengths between 0 and 1 correspond a proportional deleting a random to keeping 137 of the 619 transcription to retaining is obtained by rules subset of the nondefault The cases were set to six strengths: 0, 1000,2000,3000,4000, in the system. Each strength rules from the next higher strength. to generate a complete pronunciation number of nondefault and 5000. The strength that were kept in the case library. Again, each weakening the number of names is just of the case library produces an arbitrary subset of the previous case library. the default 4.3.3. Accuracy results Fig. 12 shows system accuracy as a function of both rule strength and case strength. in- as rule or case strength improves monotonically is that accuracy result The main I4 The first author was an unusually harsh judge, thus the scores here are not directly comparable to those of the system comparison. 248 AX. Gelding, PS. Kosenhbntll/Ari~~cr(1/ lnrelligence R7 (1996) 215-25.1 Fig. 12. System accuracy, shown as a table and as a 3D graph. Each value is the percentage of names in the test set for which the system produced an acceptable pronunciation. Kule strength 0 Case strength I 2 ( x 1000) 3 3 I 213 l/3 0 I .3 3.0 1.2 1.1 0.9 3.1 3.0 3.0 4.1 4.4 4.4 4.5 5.2 5.8 5.9 6.3 6.3 72 7.6 8.2 5 7.2 X.5 93 IO.2 A r. :, ‘-3 \ @ 0 1 . ..., ,I’ ” Rules Fig. 13. System run time, shown as a table and a:, A 3D graph. E&h value is the average time (in seconds) for the system to pronounce a name in the test set cases .. , ..,;/ improvement creases. The total 38% of the test set (depending (depending system’s overall accuracy. is able to achieve its best performance. on rule strength). This shows in accuracy due to adding is between 32% and on case strength). For cases it is between 12% and 17% to the that the system that rules and cases each contribute It is only by having both knowledge sources rules 4.3.4. Run-time results rules increasing is large, adding to the system actually decreases Fig. 13 gives the results on run time. The interesting point here is that when the case run time. For example, the rules from strength 0 to 1 lowers run is that adding rules to the system the rules effects. When into fewer negative result the that RBR and CBR do not merely exist library with the case library at size 5000, time from 10.2 to 7.2 seconds per name. The reason improves are more accurate, exemplars, and thus fewer opportunities in a corresponding savings load on the CBR component. This demonstrates side by side in the architecture: in run time. In short, adding rules to the system reduces the overall accuracy of the rules, barring sociopathic they will have fewer exceptions. This translates to draw analogies. The foregone analogies they interact beneficially. A.R. Golding, P.S. Rosenbloom/Artifciul Intelligence 87 (1996) 215-254 249 RBRICBR Hybrids Efficiency-improving Accuracy-improving Cases derived from rules Rules derived from cases Emphasis on invocation Emphasis on combination . CASEY l PRODIGY I ANALOGY l Quinlan and Rivest . DAEDALUS . CABARET . GREBE . IKBALS II l FRANK I Weak method l CELIA l Quinlan Knowledge-based method Per-case knowledge Similarity + meta-knowledge Similarity t other cases . MARS . DANIEL l ANAPRON Fig. 14. Taxonomy of methods for combining RBR and CBR. Examples of systems that use each method are listed at the leaf nodes. 5. Related work A number of other methods have been proposed for combining RBR and CBR. Each method is designed around a particular set of knowledge requirements; for instance, some methods expect independent rules and cases, while others start with just one knowledge source and derive the other from it. Methods also differ in their approach to integrating rules and cases; some focus on how and when RBR and CBR can each be profitably invoked, while others concentrate on how to reconcile conflicting results of RBR and CBR. Fig. 14 organizes the methods into a hierarchy according to these differences. The first branching point tests whether the rules and cases used by the method are dependent or independent. If the rules and cases are dependent, it means that one was derived from the other. Such methods are labelled as efficiency-improving; their primary motivation is to express their knowledge in whatever form will make problem solving most efficient. The methods with independent rules and cases are labelled as accuracy- improving; the primary motivation here is to maximize problem-solving accuracy by exploiting multiple knowledge sources. The efficiency-improving methods can be further broken down according to which of their knowledge sources was derived from which. Most CBR systems that include a rule component have cases that are derived from their rules. The cases are records of how the rules were applied to particular examples encountered previously. By reasoning from cases, the systems bypass the potentially lengthy process of solving a new problem from scratch via the rules. For example, CASEY [22] works in the domain of heart- reasoning rules are derived is derivational from diagnosing It has a complete but slow set of rules-in heart failures. When given a new case to diagnose, the case to a similar case diagnosed previously. When the form of a causal i’ailure diagnosis. it tries to model-for relate it can find such a case, its answer usually agrees with what the causal model would have said, but is obtained [ 361 can be an average of two orders of magnitude ii>r combining RBR and CBR to improve efficiency. regarded as a general architecture PRODIGY/ANALOGY’s solving via search; faster. PRODIGY/ANALOGY is problem [ 8 I. its version of case-based of rule-based equivalent reasoning analogy The systems whose procedure. The systems must still keep the cases around, because the rules by some their in these systems can in the cases. The rules of the data, a more compact and Rivest 12X], or providin, (7 more efficient access IO the cases, as in generalization rules do not encode all of the knowledge such as enabling serve various purposes, as in Quinlan Daedalus 12 j. their cases extract representation Systems utilizing the systems Again ia~oke the RBR and CBR components: the results once the components independent fall into two groups. The first group emphasizes how and when rules and cases are much closer to the second group emphasizes how to combirze to Anapron. in spirit have been invoked. goals Systems II work invocation and IKBALS that emphasize the seriousness the user’s position include CABARET to the task of diagnosing these systems are not intended [ 31 1. These systems are designed hack injuries. and generates medical [ 32 1, GREBE to gather evidence in [ 4 J , IKBALS II to support a the domain of legal finding su pport for one side or the other in a legal case. FRANK has been reports reflecting [39], and FRANK user‘s position. CABARET, GREBE. reasoning. applied the uscr’k expository (c.g.. downplay balanced account of the evidence). Because actual decision about whether resolve conflicts between RBR and CBR; effort in these systems but into determining when RBR and CBR can each be profitably to the target problem. CABARET a rule fires with an undesired conclusion, rule”. GREBE uses a control strategy antecedents, target case. IKBALS an open-textured blackboard-based to apply of the injury: or give a to make an they do not have to report all of the evidence. The the results of RBR and CBR, to contribute for this purpose, such as “If the rule and calls on RBR to establish and elaborate matches between a source and term that cannot be interpreted by further rule chaining. FRANK uses reasoning method opportunistic invoke CBR to find cases that calls on CBR to operationalize therefore goes not into combining that discredit abstract II starts with the rules. only to select the most appropriate uses a set of heuristics invoking CBR when is right or wrong, to a particular it encounters they merely subgoal. invoked control the conclusions of RBR and In the second group of systems, the locus is on reconciling can be done either hy a weak method-i.e., CBR. The reconciliation method CELIA CELIA system’s the expert’s next step. Prediction knowledge, that does not require knowledge of the domain-or a knowledge-based method. [ 29 1 and Quinlan’s method 127) are two examples of using a weak method. repair. A central part of the is a learning apprentice and predict two knowledge sources: abstract general is that of a novice mechanic, and cases. The abstract general knowledge is to watch an expert mechanic in the domain of automobile as a learning apprentice a general-purpose is done using function A.R. Gelding, ES. RosenbloomlArtijicial Intelligence 87 (1996) 215-254 251 sequences by an expert, and are considered highly and buggy. The cases, in contrast, its buggy model, and, independently, its prediction. If it is able represent actual reliable. To predict looks for to come up with a to it, else it falls back on the rule-based prediction. buggy general knowledge. to decide between abstract general knowledge and cases under the It is a weak method because it rules and cases, but rather simply incomplete case on which is thus assumed and troubleshooting the expert’s next step, CELIA applies an analogous to base prediction based on a case, it listens This a way of integrating assumption does not use domain knowledge prefers cases whenever Quinlan’s method of incomplete, [27] applies illustrates they are applicable. scheme an instance-based The simplest some metric) answer by using a model, M, to add a correction instance-based to the target, and just copy its answer. Quinlan’s method is to retrieve to generate an initial answer; this step corresponds the source case that is closest term; this step corresponds scheme It uses to CBR. (by improves on this to RBR. Let: to tasks whose answer is a numeric quantity. the target problem, the source case retrieved by the instance-based . T= 0 s= l A(S) = the answer given by the source case, l M(T) = the answer obtained by applying l M(S) = the answer obtained by applying the model the model scheme, to the target, to the source. The pure instance-based method gives A(S) + ( M(T) for differences numerically Systems between scheme would give the answer A(S). But Quinlan’s - M ( S) ) . The parenthesized the source and target problems. This answer from the results of RBR and CBR; no domain knowledge correction combined term helps account is thus obtained is needed. the results of RBR and [ 61. The main distinction among they use to do the combination. MARS reasoning. This rules; thus MARS’s first as possibilistic to combining that take a knowledge-based approach [ 121, and DAMEL is in the type of knowledge evidence from multiple that all of its knowledge be represented rules and cases using possibilistic its cases into the features of the case this form. The conversion requires certain knowledge that are relevant to its outcome, and the include Anapron, MARS CBR these systems combines requires step is to convert about each case: necessity enables MARS from rules and cases via possibilistic the per-case knowledge acquisitions, document that explains to represent the judge’s each case as a rule and subsequently is implied. This per-case knowledge aggregate evidence In MARS’s domain of mergers and processing of a reasoning. is acquired via natural-language ruling on each case. and sufficiency with which this outcome DANIEL combines CBR and RBR for legal interpretation. DANIEL explicitly ad- dresses conflicts between ponent. This component meta-knowledge-in arguments, and similarity between rules and cases by invoking a rule-based decides between CBR and RBR using coordination corn- two sources: domain and case-based force of the rule-based of the predicates involved-and the particular, the legal binding the degree of open-texturedness the source and target cases. In Anapron, decisions the analogy. Compellingness target, and an empirical verification, which on other cases in the case library. between RBR and CBR are based on the compellingness of the similarity between source and the analogy behind tests the generalization depends on two factors: 252 A.K. Chiding, P.S. Kosenbl~~om/Arri~~iui Intelligence 87 (I 996) 215-254 to arbitrate between RBR and CBR. The systems are therefore applicable It can be seen that MARS, DANIEL, and Anapron each depend on different kinds of in of cases that for argument, and when it is practical is appropriate. When a large supply of cases is for testing out an analogy, and again when a similarity metric can be specified, is appropriate. knowledge different situations: when MARS requires, MARS evaluating to specify a similarity metric, DANIEL available Anapron is appropriate. When domain meta-knowledge the strength of a case-based or rule-based to do the knowledge engineering it is practical is available 6. Conclusion for improving An architecture was presented in two forms: rules and cases. The architecture system accuracy by bringing is intended together knowledge that are understood well but not perfectly. The idea is that in such domains, expert knowledge for solving problems; in the form of rules can be used to provide a skeletal method and special cases cases are then used to flesh out the method by covering accurate and efficient that were not anticipated by the rules. In addition set of rules also needs a set of cases and a similarity metric. The set knowledge of cases should be extensive enough problems cannot be corrected. to serve as a starting point for problem solving, in support of CBR-namely, the errors in the rules; any unillustrated the architecture to a reasonably idiosyncrasies for domains to illustrate a modification The architecture was applied it was found to perform almost at the level of state-of-the-art to the task of name pronunciation. With minimal knowl- edge engineering, commer- that its performance cial systems. More importantly, was higher than what it could have achieved with its rules or cases alone. This demon- strates the capacity of the architecture to improve upon a pure rule-based or case-based to the accuracy benefits, having rules together with the cases allowed system. In addition first, the rules provided a natural way to index the two innovations cases (prediction-based they provided a method of doing case adaptation, termed “case adaptation by factoring”. in CBR technology: and second, experiment indexing); showed is available The architecture to whatever knowledge presented here is one datapoint in a hierarchy of possible hybrid is to keep the same reasoning them differently. The method of combina- in the domain, whether analytic (e.g., examples combining RBR and CBR). Another way to abstract away from its RBR component with some other reasoning method. answer obtained by any is that the benefits of having rules together and case adaptation approaches. One way to abstract away from its design components (RBR and CBR), but to combine tion could be tailored (e.g., heuristics about when to believe RBR versus CBR) or empirical of previous decisions the architecture CBR then becomes a postprocessor method of choice. The downside, however, with cases would be lost-alternative would be needed. A final level of abstraction, the work presented here, is simply to achieve higher accuracy. and the one that is in fact the essence of sources to improve an approximate to combine multiple methods of case is to replace independent knowledge indexing A.R. Gelding, PS. Rosenbloom/Artijicial Intelligence 87 (1996) 215-254 253 Acknowledgements solving The research for the initial and a vehicle implementations. the problem of name pronunciation reported here has its roots in the Soar architecture [ 231. Soar provided The influence on the work is due to Ken Church and Mark Liberman, who and proposed both a model of problem other important suggested the approach of pronuncia- tion by analogy. Murray Spiegel also provided generous assistance on the pronunciation dictionary of aspects of the work, including the ex- names systems: Mark periment to other name-pronunciation Liberman, Cecil Coker, Murray Spiegel, Tony Vitale, Tom Dietterich, John Laird, Con- nie Burton, and David Shapiro. Finally, we would like to thank the Artijicial Intelligence reviewers and Bill Freeman for their helpful comments on drafts of this article. to the many people who helped with in which Anapron was compared from Bellcore. We are grateful for us to borrow a pronouncing arranging This research was sponsored by NASA under cooperative 2-538, and by a Bell Laboratories PhD fellowship were partially provided by NIH grant LM05208. The views and conclusions in this document the official policies, Laboratories, are those of the authors and should not be interpreted either expressed or implied, of NASA, Institute of Health. to the first author. Computer or the National agreement number NCC facilities contained as representing the US Government, Bell References [ I ] J. Allen, M.S. Hunnicutt and D. Klatt, From Text to Speech: The MlTalk System (Cambridge University Press, Cambridge, 1987). 121 J.A. Allen and P Langley, A unified framework for planning and learning, in: Proceedings Workshop on Innovative Approaches to Planning, Scheduling, and Control, San Diego, CA ( 1990). [3] R. Barletta and W. Mark, Explanation-based indexing of cases, in: Proceedings CER Workshop, Clearwater Beach, PL ( 1988). [4] L.K. Branting, Building explanations (1991). from rules and structured cases, fnt. J. Man-Mach. Stud. 34 (6) [ 51 J.S. Brown and R.B. Burton, Diagnostic models for procedural bugs in basic mathematical skills, Cognit. Sci. 2 (1978). [6] S. Bruninghaus, DANIEL: integrating case-based and rule-based reasoning in law, in: Proceedings AAAI-94, Seattle, WA (1994). [ 71 B.G. Buchanan and E.H. Shortliffe, Rule-Based Expert Systems: The MYCIN Experiments of the Stanford Heuristic Programming Project (Addison-Wesley, Reading, MA, 1984). [ 81 J.G. Carbonell, Derivational analogy: a theory of reconstructive problem solving and expertise acquisition, in: Machine Learning: An Arti&ial Inielligence Approach 2 (Morgan Kaufmann, Los Altos, CA, 1986) 371-392. [ 91 C.H. Coker, K.W. Church and M.Y. Liberman, Morphology two powerful alternatives in: Conference on Speech Synthesis (European Speech and rhyming: to letter-to-sound Communication Association, for speech 1990). rules synthesis, [ 101 W. Daniel, Applied Nonparametric Statistics (PWS-Kent, Boston, MA, 1990). [ II] T.G. Dietterich, H. Hild and G. Bakiri, A comparative for English in: Proceedings Seventh International Workshop on Machine Learning, Austin, study of ID3 and backpropagation text-to-speech mapping, TX ( 1990). [ 121 S. Dutta and P Bonissone, Integrating case based and rule based reasoning: the possibilistic connection, in: Proceedings Sixfh International Conference on Uncertainty in Al, Cambridge, MA (1990). [ 131 J.L. Pleiss, Statistical Methods for Rates and Proportions (Wiley, New York, 1981). 254 A.R. Gelding, F.S. Rosenblootn/Arti~ciul Intelligence 87 (1996) 21.5-2.54 1141 1151 I161 I171 1181 I191 1201 121 I 1221 A.K. Gelding, Pronouncing names by a combination Stanford University, Stanford. CA ( 199 I ) A.R. Golding and P.S. Rosenbloom, Improving Procaedirrgs AAAI-Yf, Anaheim, CA ( 199 I ). A.R. Colding and P.S. Rosenbloom. A comparison of Anapron with seven other name-pronunciation of rule-based and case-based reasoning, PhD thesis, through case-based reasoning, rule-based systems in: systems, J. Am. hice Input/Output Sot. 14 ( 1993). F. Hayes-Roth, D. Waterman and D. Lenat, eds., Building Eqzrt Systems (Addison-Wesley, Reading, MA, 1983). H.A. Kautz and J.F. Allen. Generalized plan recognition, in: Proceedings AAAI-86, Philadelphia, PA (1986). D.H. Klatt, Review of text-to-speech conversion for English, J. Acoust. Sot. Am. 82 (3) ( 1987). J. Kolodner. Case-Bused Reusoning (Morgan Kaufmann, San Mateo, CA, 1993). from a case memory: a parallel implementation, in: Proceedings CBR J.L. Kolodner, Retrieving events Workshop. Clearwater Beach, FL ( 1988). I? Koton. Reasoning about evidence (1988). in causal explanations, in: Pmcerding.s AAAI-88. St. Paul, MN 1231 I.E. Laird. A. Newell and P.S. Rosenbloom. Soar: an architecture for general intelligence, Arrif Intel/. 33 (1987) i-64. [ 24 I M. Liberman and A. Prince, On stress and linguistic 12.51 to theory S. MolTis and P. O’Rorke, An approach S~wywsium on Aufomafed Abduction, Stanford. CA ( 1990) H.T. Ng and R.J. Mooney. A first-order horn-clause abductive system and its use in plan recognition revision using abduction, in: Proceedinp AAAI Sprin,q 17-61 rhythm, Linguist. Inquiry 8 (2) ( 1977). and diagnosis, submitted. J.R. Quinlan, Combining instance-based and model-based learning, in: Proc~eedinp Tenth Internutiontrl Workshp on Machine Learning, Amherst, MA ( 1993). J.R. Quinlan and R.L. Rivest, Inferring decision trees using the minimum description length principle, I@rm. Gunput. 80 ( 1989). M.A. Redmond. Learning by observing and understanding expert problem solving, PhD thesis, Tech. Kept. GIT-CC-92/43. Georgia Institute of Technology, Atlanta, GA (1992). C.K. Riesbeck and R.C. Schank, hide Cw-Based Reasoning (Lawrence Erlbaum, Hillsdale, NJ, 1989). E.L. Rissland. J.J. Daniels. Z.B. Rubinstein and D.B. Skalak, Case-based diagnostic analysis in a blackboard architecture, in: Proc,eedings AAAI-93. Washington. DC ( 1993). E.L. Rissland and D.B. Skalak, CABARET: Srud. 34 (6) ( I99 I ) T.J. Sejnowski and CR. Rosenberg, Parallel networks SW. 1 ( 1987). M.F Spiegel and M.J. Macchi, Synthesis of names by a demisyllable-based rule interpretation learn that to pronounce English text, Crjnrplex speech synthesizer (Orator). in a hybrid architecture. Inr. J. Man-Much 1271 1281 1291 I 30 I 131 I I32 133 134 1. Am. MJice Input/Output Sot. 7 ( 1990). 1351 K. Sullivan and R. Damper, A psychologically-governed approach to novel-word pronunciation within a text-to-speech in: Proceedings I36 I M.M. Veloso. Learning by analogical system. ICASSP. Albuquerque, NM ( 1990). reasoning in general problem solving, PhD thesis, Tech. Rept. CMU-CS-92- 174. Carnegie Mellon University, Pittsburgh, PA ( 1992). [ 37 1 A.J. Vitale, An algorithm for high accuracy name pronunciation by parametric speech synthesizer, J. Comput. Linguist. I38 I T. Vitale, The automation 17 (3) ( I99 I ). of name and address output as a utility for the telecommunications industry, m: Proceedin,ps Ncrfionul Cor,lmunic,crrions Forum ( 1989). [ 39 I G. Vosson. J. Zeleznikow, T. Dillon and V. Vossos, An example of integrating legal case based reasoning with object-oriented rule-based systems: IKBALS II. in: Proceedings 3rd International Conference on AI und Law, Oxford ( 199 I ). I40 I R. Wilensky, Pkunning und Understunding 141 I D.C. Wilkins, Apprenticeship learning (Addison-Wesley. Reading, MA, 1983). techniques for knowledge based systems, PhD thesis, Tech. Rept. STAN-CS-88- I242 or KSL-88- 14, Stanford University, Stanford, CA ( 1988) 