Artificial Intelligence 175 (2011) 299–345Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintHow does a box work? A study in the qualitative dynamics of solidobjects ✩Ernest DavisDept. of Computer Science, New York University, United Statesa r t i c l ei n f oa b s t r a c tArticle history:Available online 3 April 2010Keywords:Qualitative physicsNaive physicsCommonsense reasoningSolid objectsKinematicsDynamicsPlanning1. IntroductionThis paper is an in-depth study of qualitative physical reasoning about one particularscenario: using a box to carry a collection of objects from one place to another. Specificallywe consider the plan, plan1 “Load objects uCargo into box oBox one by one; carryoBox from location l1 to location l2”. We present qualitative constraints on the shape,starting position, and material properties of uCargo and oBox and on the characteristicsof the motion that suffice to make it virtually certain that plan1 can be successfullyexecuted. We develop a theory, consisting mostly of first-order statements together withtwo default rules, that supports an inference of the form “If conditions XYZ hold, andthe agent attempts to carry out plan1 then presumably he will succeed”. Our theory iselaboration tolerant in the sense that carrying out the analogous inference for carryingobjects in boxes with lids, in boxes with small holes, or on trays can reuse much of thesame knowledge. The theory integrates reasoning about continuous time, Euclidean space,commonsense dynamics of solid objects, and semantics of partially specified plans.© 2010 Elsevier B.V. All rights reserved.How does a box work? You won’t find an explanation in The Way Things Work [21] or at HowStuffWorks.com, for thevery good reason that any fool can see without assistance how a box works; and if you can’t see it, an elaborate explanationwon’t help. Indeed, the question, “How does a box work?” seems almost ill-formed; it violates the Gricean condition that aquestion must admit a useful answer.That people do indeed understand, in a productive and general sense, how a box works1 is evidenced by the fact thatthey can reason about how the functionality of a box relates to the geometric and physical properties of the box itself andthe objects it is used with. They understand, for example, that objects cannot come out of a closed box; that objects can becarried in an open box, if the box is moved smoothly and held upright; that objects will fall out of an open box if it is turnedupside down; that more and larger objects will fit in a large box than in a small box; and so on. These inferences can becarried out using only qualitative information about the geometry of the boxes and objects involved; precise specificationsof the geometry and material properties is not required. The knowledge involved is not specific to boxes; much the sameknowledge is used in the commonsense understanding of trays, shelves, drawers, and so on.✩My thanks to David Stewart, for information about the current state of the art in scientific computation in the theory of rigid solid objects; to SteveLaValle, for discussions about the relations of this work to robotics; to Leora Morgenstern and Vladimir Lifschitz, for discussions of non-monotonic inference;and to the reviewers for helpful suggestions. This research was supported in part by NSF grants IIS-097537 and IIS-0534809.E-mail address: davise@cs.nyu.edu.1 As opposed to, for instance, a theory that posits that the people’s interactions with boxes can be characterized in terms of stimulus/response behaviorthat subjects learn from positive and negative reinforcement when they put objects into boxes and take them out.0004-3702/$ – see front matter © 2010 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2010.04.006300E. Davis / Artificial Intelligence 175 (2011) 299–345Table 1PDDL theory of boxes.(define (domain Box)(:types object location)(:predicates(at ?o - object ?l - location)(in ?o ?b - object))(:action load:parameters:precondition (and (at ?o ?l) (at ?b ?l) (box ?b)):effect(and (in ?o ?b) (not (at ?o ?l))))(?o ?b - object ?l - location)(:action move:parameters:precondition (at ?o ?l1):effect(?o - object ?l1 ?l2 - location)(and (at ?o ?l2) (not (at ?o ?l1))))(:action unload:parameters:precondition (and (in ?o ?b) (at ?b ?l):effect(?o ?b - object ?l - location)(and (at ?o ?l) (not (in ?o ?b)))))But, of course, what is obvious to people can be very difficult to make obvious to computers. Currently there existimplementable theories at two levels that can be applied to boxes. On the one hand, there is the exact theory of rigid solidobjects: given exact geometrical and material specifications of the box, of the objects inside, and of the motion of the box,one can calculate exactly the resulting motions of the objects.2 On the other hand, one can develop a discrete, abstractrepresentation of the domain of boxes, using fluents like “in(O , B)” and actions like “putin(O , B)” and “move(B, L1, L2)”.(Table 1 shows one such representation in PDDL [28].)What is lacking is a theory at an intermediate level; a theory that, on the one hand explicitly deals with the geometry ofthe objects and motions involved, and, on the other hand, allows those geometries to be specified partially or qualitatively.Clearly it is often important to be able to reason at such a level; exact geometric characteristics of objects may be unknown,or one may wish to reason about classes of situations generically, or one may wish to reason about a system at an earlystage of design, before the exact geometry has been decided on. Clearly, also, human commonsense reasoning is often ableto deal with such reasoning without difficulty. Our objective in this paper is to develop a representation and a theory ofmoving objects in boxes at this level.This paper is thus a contribution to a small corner of the research programme first pioneered by John McCarthy nearlyfifty years ago [22,23]. In the very earliest days of AI, McCarthy foresaw that the representation of commonsense domainsand the automation of commonsense knowledge would be one of the major challenges in constructing intelligent programs;and that formal logic would be a powerful tool in constructing well-defined representations and powerful inference tech-niques. The years that have passed since then have entirely confirmed McCarthy’s original insights. Though short-term andsmall-scale progress in AI has often been made through the deliberate and systematic avoidance of issues of common-sense reasoning (see e.g. [5], pp. xvii–xviii), it has become ever clearer that, in the long run, no general intelligence canbe achieved without dealing with these issues, and that using representational systems that lack a well-defined logicalsemantics yields no real advantages and inevitably leads to muddle [26]. The research in this paper has also been deeplyinfluenced by other aspects of McCarthy’s work, particularly his study of non-monotonic inference [24] as a critical featureof commonsense reasoning, and his advocacy of elaboration tolerance [25] as a desideratum in the development of domaintheories.The other major inspiration for the research in this paper is Pat Hayes’ “Naive Physics Manifesto” [17], which advocatedcarrying out McCarthy’s representation project in the particular area of commonsense physical reasoning.The direct practical applications of a qualitative theory of boxes — e.g. for household or industrial robots that dealwith boxes; for deep understanding of natural language texts that describe the use of boxes; or for interpretation of videoshowing manipulation of boxes — would hardly in itself justify, in terms of a cost-benefit analysis, my labors of writingthis paper, your labors of reading it, and the labors, not yet begun, of implementing it and integrating it with such anapplication [7]. Boxes arise too rarely in these applications; it would be much more cost-effective either to use one of thelevels of representation and reasoning that currently exist, to contrive some application-specific hack, or to live with theslight gap in functionality entailed in an imperfect understanding of boxes.Rather, the importance of the theory we develop here is as part of a general theory of qualitative physical reasoning.There is good reason to hope that large parts of the conceptual analysis, the representation, and the formal theory can becarried over to a more general theory of qualitative physical reasoning; that our experience in developing the theory of2 This is actually more problematic than one might suppose, as we will discuss in Section 2 below.E. Davis / Artificial Intelligence 175 (2011) 299–345301boxes will be helpful in designing such a theory; and that a general theory, when complete or nearly so, will be so powerfuland broadly applicable as to justify the very large costs of development [19].This paper will deal with one specific, basic use of boxes: an open box can be used to carry a collection of objects, thecargo, from one place to another place. More specifically, we are concerned with the following plan (henceforth plan1)Load the objects one by one into the box;Move the box to its destination.3In this paper, we will formulate a set of qualitative boundary conditions on the box, the cargo, and the initial state sufficientto support the inference that plan1 will execute successfully. We will present a formal theory in which this inferencecan be carried out; this theory integrates continuous time, Euclidean space, physical dynamics of solid objects, and thesemantics of partially specified plans. We will give an extensive sketch of the formal proof of the correctness of the plan.The key characteristic of our analysis is that the verification is achieved using only qualitative geometric and physicalspecifications. Neither the number nor the shape of the cargo objects is constrained and the shape of the box is constrainedonly by the requirement that it is a box and is substantially larger than the combined size of the cargo. We do not haveto assume that other objects do not exist,4 only that they do not directly interfere with the loading and the carrying. Thetrajectories used in loading the blocks and in carrying the box are a little more constrained, but they too are permitteda large measure of freedom. Furthermore, we do not require that the objects remain in the position in which they arereleased; they may topple over or shift around, either when they are originally released, or when some other object isloaded on top of them, or while the box is being carted around. However, though they shift, they remain in the box; this isone of the main functions of a box. Therefore the planner does not have to make sure that he loads the objects in a stableposition.To ensure that our theory is elaboration tolerant [25] to a reasonable degree, and is not narrowly confined to this onespecific problem, we have kept a number of variant problems in mind. The theory is designed to extend fairly easily tosupport the following variant inferences and scenarios:1. Infer that, if the box is turned upside down and held that way while being carried, the objects will fall out, and theplan will fail.2. Infer that, if one or more of the cargo objects is attached to the ground then they cannot be loaded into the box.3. Infer that, if the box is attached to the ground, then it cannot be carried to the destination.4. Infer that, if the trajectory of the box is bumpy enough, then cargo objects may be thrown out and the plan will fail.5. Infer that, if object O is placed inside box B1 which is then placed in box B2, and B2 is carried to L2, then both O andB1 will come along with it.6. Infer that, if a lid is placed on the box after it is loaded and kept there while it is carried, then the objects will stay inthe box regardless of the motion of the box.7. Infer that, if a lid is placed on the box before it is completely loaded, then the loading cannot be completed.8. Infer that objects may be placed on an open tray and carried from one location to another, but that they cannot bepiled as high or moved as roughly as in a box.9. Infer that objects can be carried in a box with holes in the bottom or sides, like a milk crate as long as the objects aretoo large to fall through the holes.Due to limitations of time and space, we have not carried out a complete formal analysis of any of these variants, butwe are quite confident that the theory presented here can be extended without substantial difficulty to cover all or mostof these. Specifically, inferences 1, 4, and 8 would certainly require additional physical axioms. The extensions needed for1 and 4 should be straightforward; inference 8 is substantially more challenging. Note that, if one uses an open tray as ininference 8, objects must be stacked stably and maintain a fixed position, or one risks their falling off the side of the tray.The other inferences do not require any new physical axioms; these can all be carried out within the current theory withat most the addition of some additional geometric definitions and lemmas. Similarly, we have designed our theory so thatit is not inconsistent with the standard Newtonian theory of solid object dynamics (see Section 2.1), with the idea that thetwo theories can be merged in future work.One particular objective in this paper is to formulate the physical knowledge used in terms that avoid or minimizethe use of differential equations and forces, which are central to the Newtonian theory. As discussed at length in [6],analysis in terms of forces and of behavior over differential time is particularly unsuited to qualitative reasoning in thisdomain, because many scenarios which can be simply characterized over extended time are both extremely complicatedand extremely unstable when analyzed over differential time. Consider dropping an object on the ground and watching itsettle to a stable state. The characterization of its behavior in differential terms, between the time it first hit the ground3 We had originally hoped to include a final step of unloading the objects one by one; but it turns out that formulating conditions that guarantee that itis possible to unload the cargo raises new and difficult problems. We hope to return to this in future work.4 Readers who are not KR researchers may be surprised that this is worth mentioning; but such strong “closed world” assumptions are in fact ubiquitousin automated commonsense reasoning and planning.302E. Davis / Artificial Intelligence 175 (2011) 299–345and the time it comes to rest, can be very complicated; the thing rotates, spins, slides, bounces while impacts and forcescome and go. It is also very unstable; the exact sequence of impacts, forces, slidings, and so on depends very delicately anddiscontinuously on the exact shapes and material properties and the initial conditions. The characterization of its behaviorover extended time is very simple and robust; within a few seconds, it is at rest on the ground, not far from the initialpoint of impact. As we shall see, our theory achieves this objective to a very large degree; in fact, the physical theory weneed for this problem makes no reference to velocities, accelerations, or forces.Let us make clear at the outset a few objectives that this paper does not attempt to achieve:• We assume a single agent. The semantics is not easily extended to a world with multiple agents.• It does not cover all cases in which it is commonsensically obvious that the plan works.• It does not derive the rules from “first principles” of Newtonian physics, for reasons that will be discussed below.• It does not support reasoning about likelihood, or relative likelihood. We hope to address this in future work.• It does not discuss how this reasoning could be implemented in practice.The paper is structured as follows: Section 2 reviews related work, in mathematical physics (Section 2.1), in AI qualitativephysical reasoning (Section 2.2), and in robotics (Section 2.3). Section 3 gives a pre-formal analysis of plan1, discusses themany ways in which the plan can fail, and presents ways to formulate the boundary conditions, the physical constraints, andthe plan itself so that the plan can be relied on to succeed. Section 4 shows how this domain theory can be expressed in aformal first-order theory. Section 5 sketches a proof of the correctness of plan1; a complete proof is given in a Web-basedappendix at http://cs.nyu.edu/faculty/davise/box-proof.pdf. Section 6 summarizes our results and discusses future work.2. Related workPrevious work relevant to the research described here falls into three categories: mathematical physics analyzing theNewtonian dynamics of rigid solid objects (Section 2.1), work in AI on qualitative dynamics of rigid solid objects (Sec-tion 2.2), and work on robotic planning (Section 2.3).2.1. The Newtonian theory of rigid solid objectsThe study of the dynamics of solid objects, idealized as perfectly rigid, was begun by Galileo and Newton and continuedby physicists and mathematicians of the eighteenth, nineteenth, and twentieth centuries. It has recently enjoyed a revivalof research interest because of its many applications, which include physical simulation, robotics, computer-aided manu-facturing, animation, virtual reality, and video games. Recent research includes modelling issues (how best to model theinteractions of rigid objects), computational issues (how to effectively compute the behavior of a system of rigid objects),and theoretical issues (showing that every well-posed boundary value problem has a solution). Nonetheless, there remainmany fundamental unsolved problems in this domain. Stewart [36] surveys the literature and discusses the state of the art.In the kinematic theory of rigid solid objects, an object O is characterized by its shape, which is the region of space that Ooccupies in some standard position. We will assume throughout this paper that the shape of an object is bounded, regular(equal to the closure of its interior), and has a connected interior. In this section, though not in the remainder of the paper,we will further assume that the boundary is smooth; that is, there is a unique tangent plane at every boundary point. Theposition of object O at time T is determined by a rigid (orthonormal) mapping, called the placement of O at T . The regionthat O occupies at time T , called the place of O at T is equal to the image of the shape of O under the placement of Oat T .The kinematic theory consists of three constraints:1. Each object maintains a fixed shape. This is guaranteed by the above constraint that the place of O at T is related toits shape by a rigid mapping.2. The placement of O at time T is a continuous function of T .3. If O 1 (cid:2)= O 2 then the places of O 1 and O 2 at T do not overlap.The kinematic theory is unproblematic and well-understood.The dynamic theory extends the kinematic theory in the following ways: An object is further characterized by a densitydistribution over its shape, its coefficient of friction against other objects, and its elasticity. For each object O , at each timeT 1, the limit of derivative of the placement of O at T as T approaches T 1 from below, and the limit as T approaches T 1 fromabove, both exist, though they are not necessarily equal. We will call these the velocity before T 1 and after T 1 respectively.Two objects O 1 and O 2 that are in contact at a given time may interact in one of two ways: First, they may exert a forceon one another, distributed over the region of contact. Alternatively, when two objects collide, they may exchange a finitequantity of momentum instantaneously through exerting an impulse force on one another.In addition to forces between objects in contact, there are external forces, particularly the earth’s gravity and forces thatresult from the actions of autonomous agents. In most problems, some objects are specified to be fixed; that is, they do notmove under any circumstances.E. Davis / Artificial Intelligence 175 (2011) 299–345303The effect of forces and impulse forces on non-fixed objects is given by generalizations of Newton’s second law:4.A. (cid:3)F = M d(cid:3)v/dt, where (cid:3)F is the net force on an object O , M is the mass of O , and (cid:3)v is the linear velocity of the centerof mass of O .4.B. (cid:3)J = M(cid:2)(cid:3)v, where Jis the net impulse forces acting on object O , and (cid:2)(cid:3)v is the discontinuous change in the linearvelocity; i.e. the difference between the linear velocity of the center of mass after T minus the linear velocity of thecenter of mass before T .4.C. (cid:3)T = I d (cid:3)ω/dt, where (cid:3)T is the net torque, I is the tensor of inertia, and (cid:3)ω is the angular velocity.4.D. (cid:3)W = I(cid:2) (cid:3)ω where (cid:3)W is the net impulse torque and (cid:2) (cid:3)ω is the discontinuous change in the angular velocity.Newton’s third law asserts that:5. The force (ordinary force or impulse force) exerted by O 1 on O 2 at point P is exactly equal to the negative of the forceexerted by O 2 on O 1 at P .Finally, contact forces between objects are generated in the following ways: (The generation of external forces lies outsidethis theory; the external forces are given as boundary conditions in a problem.)6. (Constraint forces.) Two objects in contact may exert constraint forces on one another. The direction of constraint forcefrom O 1 on O 2 at contact point P is normal to their common tangent at P and points out of O 1 into O 2. Themagnitude of the constraint force is just large enough to ensure that, when all the forces are combined, the non-overlapping condition is maintained.7. (Coulomb friction.) Suppose that O 1 and O 2 are in contact at point P ; there exists a non-zero constraint force (cid:3)Nbetween O 1 and O 2 at P ; and the surfaces of O 1 and O 2 are moving at velocity (cid:3)v relative to one another at P . If(cid:3)v (cid:2)= (cid:3)0, then there is a sliding frictive force from O 1 to O 2 whose direction is −(cid:3)v and whose magnitude is μk| (cid:3)N|, whereμk is the kinetic coefficient of friction between the material of O 1 and the material of O 2. If (cid:3)v = (cid:3)0, there is a staticfrictive force between O 1 and O 2 whose magnitude is at most μs| (cid:3)N| and whose value is such that the equations ofmotion have a solution. The coefficient μs is the static coefficient of friction.8. If O 1 and O 2 are in contact at point P at time T 1 and their velocities before T 1 would cause them to interpenetratein the neighborhood P , this is a collision at P . The result of a collision is that O 1 and O 2 exert an impulse force on oneanother directed along the normal to their common tangent. There are a number of different models for determiningthe magnitude of this force; Newton’s “experimental law” is often used but is sometimes problematic. All of theminvolve a real-valued parameter, the coefficient of restitution, which depends on the material properties of O 1 and O 2.9. If O 1 and O 2 collide at time T , and they are part of a set of objects S which are spatially connected at T , then theimpulse force between O 1 and O 2 may propagate to the other objects in S (e.g. a cue billiard ball hitting into a set ofother balls, or a croquet mallet (O 1) striking one ball O 2 and knocking away a second ball). It is not well-establishedhow best to model this propagated impulse.10. If O 1 and O 2 collide at point P at time T 1 and their surfaces have a relative velocity at P which has a non-zerocomponent (cid:3)vt in the common tangent plane, then the two objects exert an impulse force on each other in the direction−(cid:3)vt . This is seen, for instance, in the way that the spin of a ball may change at a collision. Again, it is not well-established how to model this interaction.11. Under some circumstances, the equations of motion only admit a solution if there is a impulse force between twonon-colliding objects. See D. Stewart’s solution to the Painlevé paradox [35,36].The formalization of this theory is further complicated by the fact that two objects may be in contact at a finite collectionof isolated points, at every point on a curve, at every point on a surface, or at the union of a surface, a curve, and isolatedpoints, and that the place and form of contact can change discontinuously over time.There are a number of unresolved issues in formulating this theory. Ideally, one would like to have a theory that(a) agrees well with experimental measurements, up to the limits of the idealization;(b) has at least one solution for every well-posed boundary-value problem;(c) is demonstrably equal to the limit of the theory of elastic solids, as the elasticity goes to zero;(d) is demonstrably the limit of numerical computation, as the precision increases and the time-step goes to zero.But this ideal has not yet been attained. Strong results, specifically the existence of a solution for well-posed boundary-value problems, have been proved only under restricted conditions. There are a number of different sets of conditions thathave been proved sufficient to guarantee the existence of a solution; the following is typical:• Two objects are only in contact at a finite collection of points, not over an extended region.• The normals at the contact points between two objects lie in a single hemisphere.• Collisions are inelastic.304E. Davis / Artificial Intelligence 175 (2011) 299–345There is also a small philosophical/logical literature on axiomatizing the physics of rigid solid objects. The interest hereis mostly on issues in theoretical physics and philosophy of science, rather than on detailed physical models. For example,the axiomatization presented by Adams [1] includes only items 4.A and 4.C above; it does not even include the constraintthat objects do not overlap.The needs of knowledge-based commonsense reasoning are rather different from those of scientific computation. In atheory of commonsense reasoning, coverage is more important than precision; it is better to be able to rule out grosslyimpossible behaviors in all situations than to be able to give precise answers over a limited class of situations.Let me conclude here with some general comments about the relation between the scientific theory of solid objects andcommonsense knowledge of the same domain. The scientific theory intended to deal with every possible case of a collectionof objects sliding, spinning, rolling, and colliding. However, the problems that arise in everyday life are almost always muchmore constrained in one respect or another. Indeed, there is no reason to think that commonsense understanding is verygood at dealing with the general case; naive subjects find as basic a phenomenon as gyroscopic motion baffling and hard tobelieve even when directly experiencing it.In ordinary situations, people are usually interested in maintaining a very large measure of control over the objects theyinteract with; and it is hard to achieve control over an object that is moving freely.5 Also, a free motion of an object islikely to end in a collision; and people avoid subjecting objects to collisions for fear of damage. Commonsense reasoning isthus primarily concerned with cases where objects either stay where they are without need for intervention, or with caseswhere an agent moves an object in a controlled way. On the other hand, a commonsense theory must to some extent takeaccount of uncontrolled free motion, if only to be able to allow some useful predictions in the cases where this happens byaccident.In physics, the base case of the theory is an object moving with constant velocity under Newton’s first law withoutexternal forces.6 In commonsense reasoning, the base case is an object sitting motionless on a table.2.2. Qualitative physical reasoningThis project continues the work on qualitative reasoning about solid objects reported in [6], which presented a logicalanalysis of the inference that a marble dropped inside a funnel would fall out the bottom of the funnel. Rule-based ap-proaches to commonsense physical reasoning ultimately derive from [17]. Bennett et al. [3] presents a purely geometrictheory of rigid object kinematics in a language entirely defined in terms of the primitives “Region R1 is a part of regionR2”, and “Region R is a sphere”.Some of the fundamental difficulties and limitations of this methodology are discussed in [7]. A current survey of workin AI physical reasoning may be found in [10].Previous work on qualitative reasoning about kinematics includes [12,29]. Forbus et al. [14] extend these to includedynamic analyses of certain kinds. Gelsey [15] reports a simulator for predicting the dynamic interactions of solid objects.All of these require an exact shape description of the objects involved to be input. De Kleer’s NEWTON program [11]and Forbus’s FROB program [13] carried out qualitative prediction of the behavior of point objects interacting with fixedconstraints whose shape is qualitatively described. Stahovich et al. [34] present a system for qualitative analysis of a limitedclass of dynamic systems; this is similar to [14] but more elegant and more clearly defined, though more limited in scope.They claim that their system can work from a rough sketch of the objects involved, but it is not clear how this works.2.3. RoboticsThe literature on robotics discusses many of the same issues as are addressed here, but from a sufficiently differentangle that the techniques applied there are rarely directly applicable here. (LaValle’s [18] recent textbook is an extensiveand excellent survey of robotic planning.) We will discuss briefly a couple of issues that these two lines of research have incommon; a more extensive comparison is beyond the scope of this paper.Analysis of the mechanics of manipulation. As we will discuss below, in this paper we limit ourselves to an extremelysimplified model, in which a disembodied agent moves one object at a time through telekinesis, but in a broader setting,commonsense knowledge is aware of and reasons about physical aspects of manipulation, and we hope to address thesein future work. Even in this setting, however, it seems likely that there is a divergence between the roboticists’ analysisand the analysis needed for commonsense reasoning. Roboticists must carry their analysis to the level needed to actuallyexecute the manipulations involved, whereas it would seem that commonsense reasoning stops at a more abstract level,and leaves the ultimate implementation in muscular forces to learned control patterns. On the other hand, robotics research5 The most common contexts involving freely moving objects are aircraft and spacecraft; military and hunting projectiles, from slingshots and arrowsto guns and grenades; and sports that involve balls, pucks, shuttlecocks and so on. I think it is safe to say that, with the exceptions of sports, droppingtrash into a basket, and perhaps tossing bags of laundry, most contemporary Americans rarely deliberately toss or drop any large solid objects. I should beinterested to learn of any further exceptions. Note, by contrast, that liquids and collections of small solid objects like salt or coffee are generally poured.6 The rotational motion of such an object can be surprisingly complicated.E. Davis / Artificial Intelligence 175 (2011) 299–345305tends to focus on limited classes of controlled situations; for commonsense reasoning, it is important to reason about whatan agent can effectuate in any circumstance.Information limited planning. A very interesting branch of recent robotics research studies how a robot with limitedknowledge of the environment can nonetheless plan to achieve specified goals (see [18], Chaps. 11 and 12). These studiesobviously have elements in common with qualitative reasoning about planning; both deal with constructing plans in situa-tions that are not completely specified. But there is, I think, an important distinction centering around the standpoint of thereasoning being done. The information space analysis in robotics takes a first-person approach: the agent who is reasoningis the robot who is acting, and he has to get enough information to be able to actually carry out the actions involved.Qualitative reasoning takes a third-person approach: the reasoning is being done by someone other than the agent himselfwho has partial knowledge of the situation and wants to be able to reason that an agent, who may himself be omniscientor who may have limited knowledge, would be able to carry out a partially specified plan.Direction of inference. Finally, both robotics planning research and AI planning research focuses almost exclusively onconstructing and executing plans to meet specified goals. In commonsense reasoning this is only one of many possiblereasoning tasks. Other directions of inference include determining that a given goal cannot be achieved; inferring character-istics of the environment or the agent from the execution of a plan, or from the failed attempt to execute a plan, and so on.All these draw on the same kind of knowledge as plan construction, and therefore a general domain theory should supportall of them and a general knowledge-based reasoner should be able to carry all of them out.3. The execution of plan1: pre-formal analysisOur central objective in this paper is to validate plan1; that is, to show that, under suitable conditions, plan1 is areasonable plan and can be expected to succeed in achieving the goal of moving a collection objects to a destination. Thehard part of this analysis is actually at the pre-formal7 level: deciding which issues should be addressed in detail, whichshould be idealized, and which should be ignored; what problems should be covered; what knowledge must be used; andwhat assumptions must be made. Once all this is determined, the translation of this analysis into logical notation is, as weshall see, comparatively straightforward.We will assume throughout this paper that objects can be idealized as rigid and solid; thus, we do not have to worryabout the box breaking or the objects becoming crushed.3.1. A model of manipulating an objectAn execution of plan1 consists primarily of a sequence of manipulations of individual objects. We therefore start ouranalysis of the plan by formulating a theory of manipulation.What kinds of manipulations are in fact possible for a given physical agent depends on the geometry of its manipulatorsand the geometrical and physical constraints that govern them. For real agents, animal or robotic, these tend to be compli-cated. In order to abstract and simplify the details of the manipulator, we will use instead the following idealized modelof manipulation: we conceptualize the agent as, so to speak, having telekinetic powers over one object at a time. That is,the agent may choose any object O M and may move it along any physically possible path; we need not specify how thephysical manipulators of the robot could actually reach, grasp, and move the object to accomplish this. The motion of themanipulated object O M may cause motions of other objects, either because of kinematic constraints or because of frictiveforces. If other objects are in the way of the attempted motion of O M then O M will exert a force on them. If this forcecauses the other objects to move out of the way, then the motion is possible; if not, the motion is impossible.The effect of the idealization is to abstract away the robot’s actual manipulators. For instance, as compared to thecapacities of a human hand or an anthropomorphic robotic hand, this idealization allows us to ignore such issues as whatpositions of the fingers and palm relative to the object allow the object to be grasped; the space occupied by the hand;the constraints on motion placed by the structure of the hand and arm; and the limits on the strength of the hand. Forthe most part, therefore, the idealization is more powerful than a real manipulator. There is one thing, however, that areal manipulator can do that this idealization cannot; namely, to directly move more than one object at a time. A humanhand can hold several small objects simultaneously, but our idealization does not allow this. (We could, of course, changethe idealization to specify that the agent can move arbitrarily many objects within reach simultaneously. However, this isundesirable, because an agent who could do this has no use for boxes; it can simply carry all the cargo directly.) In futurework, we hope to consider more realistic models of manipulation.7 We do not mean to suggest that methodologically, “pre-formal analysis” is or should be completed before formalization begins. On the contrary, theprocess of constructing formal axiomatizations of domain knowledge and formal proofs gives important insights into the inherent nature of the knowledgeinvolved. In practice, research proceeds on all three fronts concurrently.306E. Davis / Artificial Intelligence 175 (2011) 299–3453.2. Characteristics of plan1Let us begin by writing out plan1 in more detail. Let oBox be the box, uCargo be the set of cargo objects, oTable1be the surface initially holding the objects, and oTable2 be the surface to which we wish to move the loaded box. Thenwe define plan1 in pseudo-code as followsplan1 ≡{ while (not all objects in uCargo are inside oBox){ O 1 := some accessible object uCargo outside oBox;load O 1 into oBox;}move oBox from oTable1 to oTable2;}Three characteristics of plan1 will be critical for our analysis. First, plan1 is hugely underspecified. In particular,a complete implementation using our idealized robot would have to specify how the plan executor is to choose the nextcargo object to move, the position within (or above) the box at which to release each object, and the trajectory along whichto move each object and the box.Second, plan1 is very well suited to reasoning with qualitative information. It makes no a priori assumptions aboutthe number, shapes, material properties, or initial positions of the cargo objects involved. Neither the agent himself nor anexternal reasoner needs to have this information to see that this is a reasonable plan; indeed, the plan is often executableby an agent who never gets this information. For instance, an agent with no visual or other precise spatial perception andwith only an approximate idea of the position of its own manipulator may well be able to execute the plan by groping forthe objects, getting them inside the box, and releasing them.The third characteristic is not a feature but a problem; as we elaborate below in Section 3.3, there are a large numberof ways in which the plan can fail. If we wish to posit conditions that allow the conclusion “The plan is guaranteed tosucceed” to be inferred with certainty, then we must necessarily posit quite restrictive conditions on the spatial and physicalcharacteristics of the box and the cargo, and we may also have to impose greater specificity in the plan statement. That is,we have to negotiate a three-way trade-off between(a) adding further specifications to the plan;(b) requiring that the objects and box meet more restrictive conditions;(c) allowing the conclusions we draw to be plausible or likely but uncertain.The trade-off between constraining the class of objects and specifying the plan amounts to the observation that, by usingmore intelligence about how to carry out the plan, one can apply it successfully to a substantially greater class of objects.This is not surprising; packing a box efficiently is, after all, an enterprise that requires some thought and skill, and is notachieved by tossing objects at random into the box. The trade-off between degree of certainty and the other two categoriesamounts to the observation that plans carried out haphazardly or in borderline circumstances are more likely to go wrong;again, this is not surprising. In this paper we will explore a small number of ways in which these trade-offs can be made.There are many different combinations of conditions and plan specifications that, to a commonsense understanding, justifythe conclusion that the plan [necessarily/probably/possibly] will achieve the goal; the theory developed in this paper willcover only a small fraction of these, though of course a complete theory commonsense theory of boxes would cover all ofthem.Establishing that plan1 is a valid plan to achieve the goal “The objects in uCargo are above oTable2” starting instate s1 involves that showing that every step of plan1 will be executable at its proper time and that at the end of anyexecution of plan1, the objects in uCargo are all above oTable2. Specifically, we need to posit or establish the followingpropositions:1. In s1, the cargo uCargo and the box oBox are all on oTable1.2. At each iteration of the loading loop, there is some object O 1 in uCargo that can be loaded into oBox.3. After O 1 has been loaded into oBox, O 1 will be in oBox.4. No cargo object exits oBox while O 1 is loaded into oBox.5. After the completion of the loading loop, it is feasible to carry oBox from oTable1 to oTable2.6. No objects come out of oBox while it is being carried from oTable1 to oTable2.7. After oBox has been carried from oTable1 to oTable2, oBox is on oTable2.8. If oBox is on oTable2 and O 1 is in oBox then O 1 is above oTable2.Clearly if the above propositions are true then plan1 is executable and succeeds in bringing the cargo uCargo tooTable2. However, these propositions are not formulated in a directly usable form. In particular, as far as possible, wewant our problem to be formulated in such a way that we posit that state s1 satisfies a collection of specified conditionsE. Davis / Artificial Intelligence 175 (2011) 299–345307Fig. 1. Bug 3.A.Fig. 2. Bug 3.B.and that the plan is executed starting in s1; and then from these boundary conditions we infer the correctness of conditionssuch as 2–8 above that characterize the world at later times. Our analysis below achieves this objective in large measurebut not completely. In particular, we need to posit isolation conditions that objects other than the cargo, the tables, and thebox do not interfere with the execution of the plan. (We could replace these with initial conditions on the external objectswhich support the isolation conditions as an inference; however, it seemed to us that positing the weak isolation conditionsis more reasonable for commonsense reasoning than positing the much stronger initial conditions on external objects thatwould be required.)At the outset, let us assume some conditions that are obviously necessary or useful:COND.1 In state s1, object oBox and cargo uCargo are stably supported on oTable1.COND.2 There is a “protected region” manipSpace1 which contains uCargo and oBox and is large enough so that eachobject can be moved through manipSpace1 into oBox; and it is guaranteed that no objects except uCargo,oBox, and oTable2 ever enter into manipSpace1.COND.3 The cargo uCargo fits inside oBox. That is, there is a configuration C in which each of the objects in uCargo isin the inside of oBox and which is physically feasible in the sense that no two overlap.COND.4 No other object reaches into the inside of oBox while it is being carried. (Condition COND.2 guarantees that thisdoes not happen during loading.)COND.5 oBox can be fully on top of oTable2 in a stable position.COND.6 There is a second “protected region” manipSpace2 which contains the starting and ending positions of oBox andwhich is large enough that oBox can be moved through manipSpace2 from start to end while remaining upright.No object other than oBox and uCargo enter into manipSpace2 during the execution of plan1.3.3. Potential problems and their fixesGiven conditions COND.1–COND.6 above, what can go wrong with the plan? Actually, it can go wrong in more waysthan one might at first suppose. (For convenience of cross-reference, I include here with each bug a forward pointer to thediscussion of how the bug is addressed.)BUG.1 oTable1 itself interferes with the loading of some object O 1 into the box, or with carrying of oBox away from L1.E.g. O 1 or oBox is fastened to oTable1; or oTable1 encloses O 1 in a cage. (Addressed in Section 3.3.1.)BUG.2 In the process of loading O 1 into the box, it may knock against one of the other cargo objects which then falls outof the protected region manipSpace1 and gets trapped by some other object, so that it can no longer be loaded.(Addressed in Section 3.3.1.)BUG.3 The target configuration C in which uCargo fits inside oBox may be unattainable, for any of a number of reasons:308E. Davis / Artificial Intelligence 175 (2011) 299–345Fig. 3. Bug 3.C.Fig. 4. Bug 4.a. It may be kinematically unattainable; e.g. it may depend on teleporting one object in uCargo into an inner cavityof another object, or disconnecting two objects that are fastened together (Fig. 1).b. It may be unstable; that is, if the objects are placed in C , they may fall into a different position where they arenot entirely inside the box (Fig. 2).c. It may be dynamically unattainable; that is, it cannot be attained by an agent who can only manipulate one objectat a time and who is loading one object at a time (Fig. 3).(All addressed in Section 3.3.2.)BUG.4 It is possible that in loading O 1 into the box, O 2 will be carried along with it, and will end up in a position whichprecludes completing the loading of the box. E.g. O 1 is a box and initially O 2 is inside O 1, but the cargo can onlybe fit into O B if some other object O 3 is placed inside O 1 underneath O 2. The plan plan1 does not include anymethod for dealing with this, even if, intuitively, it is easily solved by moving O 2 either before or after O 1 has beenloaded (Fig. 4). (Addressed in Section 3.3.1.)BUG.5 Loading a cargo object into the box or lifting the box may cause a trap to be sprung (as in the opening scene ofRaiders of the Lost Ark), which prevents the completion of the plan. This can happen either when the cargo object islifted, when it is placed in the box, or when the box is lifted. (Addressed in Section 3.3.1.)BUG.6 The box may fall over during loading, or it may be knocked off the table. (Addressed in Section 3.3.6.)BUG.7 Suppose that, at some stage of plan execution, object O 1 is sitting on the long end of a lever O L, and a heavy objectO 2 is dropped or falls onto the short end of O L. Then O 1 can be catapulted far from where it is supposed to be(Fig. 5). Specifically,a. During loading, if O 1 and O L are inside the box, and O 2 is placed on the other end of the lever, O 1 can becatapulted outside the box. (Addressed in Section 3.3.5.)b. During loading, if O 1 and O L are outside the box, O 2 is sitting on the other end of the lever, and O 1’s end ofthe lever is being held down by another heavy object O 3, then lifting O 3 to load it may cause the lever to bereleased, catapulting O 1 out of reach. (Addressed in Section 3.3.1.)E. Davis / Artificial Intelligence 175 (2011) 299–345309Fig. 5. Bug 7.c. During carrying, if O 1 is on lever O L inside the box, and the other objects inside the box shift in one wayor another, then O 2 may fall onto the other end of the lever, catapulting O 1 out of the box. (Addressed inSection 3.3.5.)There are also other, even more far-fetched, scenarios in which an object can fly out of the box; for example, a tid-dlywinks effect; or a wedge positioned in a crack between two heavy objects may be shot upward if the two objectsare squeezed together; or an elastic object like a basketball lying quietly on the ground may bounce upward if it ishit sharply from the top. We will consider all such possibilities as coming into the category of BUG.7.BUG.8 Objects may come out of the box while it is carried from oTable1 to oTable2.a. If the box leans over too far, the cargo may fall out. (Addressed in Section 3.3.3.)b. Similarly, if the box first leans to the left, and then to the right, then the cargo objects may accumulate on theleft-hand wall and then be lifted up about the opening. If the box leans back and forth numerous times, then thecargo can gradually climb the walls, being first carried up with each rising wall and then settling down into ahigher position on the opposite wall. (Addressed in Section 3.3.5.)c. If the motion of the box is very violent then the objects may be flung out. (Addressed in Section 3.3.4.)d. If the objects are very elastic and the motion is bumpy they may bounce out. (Imagine carrying a wooden box fullof ping-pong balls.) (Addressed in Section 3.3.1.)e. If the objects can roll or slide with little friction, and the inside of the box is curved (like a bowl) then they canbuild up a “sloshing” resonant motion inside the box that eventually allows them to escape, even if the motion ofthe box is quite smooth. (Addressed in Section 3.3.1.)f. If the sides of the box are slanted out, and the motion of the box is bumpy, then a cargo object can be graduallybumped up the back side of the box and eventually out. (Addressed in Section 3.3.4.)g. If the sides of the box are slanted out, and the box is spun rapidly, then centrifugal force may pull the objects out.(Addressed in Section 3.3.4.)h. If there are many cargo objects (e.g. a heap of sand), then in the course of motion the heap of objects can shapeitself into a ramp or bowl, allowing an object to escape methods (d), (e), or (h), even if the sides of the box itselfare vertical. (Addressed in Section 3.3.5.)With eight categories of bugs enumerated (plus subcategories), one might well wonder whether this is just the beginningof a list that can be extended indefinitely. As it happens, once we have addressed these bugs, we will have a plan that canbe formally validated, so this list of bugs is complete in the sense that it suggests a complete set of fixes.It should be noted that, with the significant exceptions of bugs 5, 7, 8.b, 8.f, 8.g, and 8.h, all of these are familiar toanyone who has extensively moved objects in boxes (that is to say, pretty much everyone), and people take them intoaccount in planning, executing, and correcting their box moving activities. (The same is true of the additional bugs withvariant boxes to be discussed in Section 3.4.) These are not at all unusual, and the strategies and conditions that we willsuggest to eliminate them are likewise formalized versions of commonsense understanding.We need to exclude all these bugs one way or another before we can validate the plan. As discussed above, there arethree general categories of fixes:1. Imposing stronger conditions on the shapes, material properties, initial configurations, and exogenous motions of theobjects involved. Such conditions reduces the scope of the correctness proof, and require that the agent have morecomplete knowledge of the state. This approach also leads to conditions on the plans that are more restrictive thanactually necessary. For instance, we will impose much stronger conditions than are actually necessary on the relationbetween the size of the cargo and the size of the box, in order to be able to be able to prove the general statement thatwhenever these conditions are met, the objects can be loaded into the box (see Section 3.3.2).2. Making the plan more specific, so that the agent uses some intelligence and care about how he carries out the loading,carrying, and unloading. This makes more demands on the agent; it also generally requires a more complex analysis ingenerating the correctness proof.3. Achieving less certainty in the conclusions; concluding that the plan is probably correct or correct by default ratherthan that it is guaranteed to be correct.310E. Davis / Artificial Intelligence 175 (2011) 299–3453.3.1. Basic geometric and physical conditionsTo begin with, we will posit some fairly stringent geometric and physical conditions. First, since our primary interestin this paper is in the use of the box, not in the theory of disassembling heaps, we will assume that initially the objectsare all placed separately on the fixed support oTable1, and that each object has a clear space above it, so that it can belifted vertically upward without touching any other object, and that it in fact is lifted without touching any other object.Second, we will assume that the objects in uCargo cannot roll, have a high coefficient of friction, and a low coefficient ofrestitution (that is, they don’t bounce).These two assumptions, between them, eliminate BUG.1 (that oTable1 blocks the loading of some object), BUG.2 (load-ing one object knocks some other cargo object out of the way), BUG.4 (that loading O 1 brings O 2 along in some interferingway), BUG.5 (that loading an object or lifting the box will trigger a trap), BUG.7.b (that loading one object results in anobject that is outside the box being catapulted), BUG.8.d (bouncing objects out of the box), and BUG.8.e (objects sloshingout of the box).3.3.2. Fitting the cargo in the boxBUG.4, that the fitting configuration is unattainable, can be dealt with by requiring oBox to be much larger thanuCargo. We consider two particular kinds of conditions here, corresponding to different specifications of plan1. If wewant plan1 to allow the agent to place the objects anywhere at all that they fit inside the box, then we can apply the fol-lowing condition: Let maxDiam be the maximum diameter of any object in uCargo. Let rDeep be the region of all points inthe X–Y plane where the inside of oBox has at least depth maxDiam and let nSquare be the number of non-overlappingsquares of side maxDiam in rDeep. Then, as long the number of cargo objects is less than nSquare/4, they can be loadedinto the box in this way, since any cargo object already in the box can block at most 4 such squares.The above result is not very satisfying since this does not allow any more cargo objects to be loaded in a deep box thanin a shallow one, as long as the depth is greater than maxDiam. Unfortunately, that is pretty much unavoidable with sucha weakly constrained loading strategy. The problem is that a sufficiently perverse and ingenious agent may be able to usethe first objects in uCargo to build a dome just inside the top of the box, which will make it impossible to add more cargono matter how large the volume underneath the dome. Note that our correctness proof is supposed to establish that theplan succeeds however the agent chooses to execute it as long as he follows the constraints defined in the plan; we are notallowed to complain that the agent is following the letter but not the spirit of what we had in mind.The following loading strategy is more effective: the agent is required to load each cargo object to a reasonably low openposition — not necessarily to the lowest possible position, just not to a position that is entirely higher than some otheroption. Specifically, the agent is prohibited from loading a cargo object to position M1 inside the box if it is possible toload it instead to some other position M2, such that highest point of M2 is lower than the lowest point of M1. If this notvery restrictive protocol is followed, then the following can easily be shown. Suppose that inside oBox there is an emptyrectangular cuboid of dimensions lCube long by wCube wide by hCube high. Then as long as the number of cargo objectsis less than(cid:5)lCube /2 maxDiam(cid:6) · (cid:5)wCube /2 maxDiam(cid:6) · (cid:5)hCube /2 maxDiam(cid:6)this loading strategy will get all the cargo into the box. In our formal axiomatization and correctness proof we will use thisplan and this constraint.This analysis, too, is far from optimal; it generally overestimates the space needed in the box by a factor of 8, and makesno allowance for the efficient stacking of large numbers of long thin objects. Since the focus of this paper is not optimalpacking, we have pursued this no further here. Readers who want to try their hands at getting stronger results, however,should note that, in the context of the theory in this paper, merely proving a geometric result, that there is a configurationin which all the cargo objects fit within the box, is not sufficient because it risks running into BUG.3. You have to showthat, if you load the objects into the box, they will remain in or settle into a position in which they all fit. “Remainingin” is a problem in qualitative statics; “settle into” is a problem in qualitative dynamics. For instance, if you are loadinga set of pencils into a case, you need to show that they do not somehow arrange themselves into a complicated latticework that blocks further loading while leaving plenty of empty space within the box. Our proof of the correctness of thestrategy above does indeed allow the possibility that the objects settle within the box after they have been placed, but wedemonstrate that even if they do settle, the loading can be completed.3.3.3. Tipping outBug 8.a, that the box is tilted so far in carrying that some of the cargo falls out, can be eliminated for the case of a singletilting motion (i.e. without a gradual climbing of the walls, as in 8.b) by requiring that the object not be loaded too closeto the top of the box and that the box be kept close to vertical. Assume that, if any objects in the box settles into a newposition as a result of tilting the box, its center of mass moves downward in setting. Let O be any cargo object, and let Fbe the diameter of O . Let H be the maximum horizontal distance between a point inside the box and a point in the top ofthe box in the initial state; let D be the minimum vertical gap between the top of the box and the center of mass of O inthe initial state; and let φ be the maximum tilt of the box from the vertical orientation. If D cos(φ) > H sin(φ) + F then Ocannot be tilted out of the box (Fig. 6). (This additional gap of F is necessary to block the possibility of some curved objectE. Davis / Artificial Intelligence 175 (2011) 299–345311Fig. 6. Tilting out of the box.executing a “Fosbury flop” in which the object can escape from the box while keeping the center of mass below the top ofthe box.)3.3.4. Smoothness of motionBugs 7.b (that cargo objects are flung out of the box), 8.f (that the objects work their way up the back of the box ina series of small bumps), and 8.g (that the objects are spun out of the box) could be eliminated by requiring that (a) thecargo objects are not loaded too near the top of the box; (b) motions of the box moved smoothly and not spun rapidly; and(c) the sides of the box are steep.In fact, we have not included these conditions in our formal analysis; rather, for simplicity we have relied on the defaultrule, introduced in the next section, that objects in a box generally do not move higher with respect to the box. However,let us briefly discuss the nature of these inferences in the more complete theory we eventually hope to attain.Commonsensically, there is a multi-way tradeoff between the bumpiness and rotational velocity of the motion of thebox, the steepness of the sides of the box, the gap between the top of the objects and the top of the box, and the likelihoodthat objects will come out of the box — one may as well throw in here the elasticity of the objects as well. However, thistradeoff• involves elements that are hard to quantify, such as the “bumpiness” of a trajectory;• would be very hard to justify by a formal analysis based on Newtonian mechanics, even if one confines attention tocases where the probability is 1 or 0;• is almost certainly not known very precisely by actual commonsense (human) reasoners.What reasoners do know, it seems reasonable to say, is a number of specific cases drawn from experience, and thegeneral structure of the tradeoff. This enables them to conclude that, for example, if the box is shaken up and down veryviolently, the objects will certainly come out the top; that if you fill a box to the brim with small objects and then roll it ina wheelbarrow down a bumpy road, it is quite likely the objects will come out; and that if the cargo objects are inelasticand you carry the box carefully and smoothly then the objects will certainly stay in the box. We hope to address theseissues in future work, but they are beyond the scope of the current paper.3.3.5. CatapultingBUG.7.a and BUG.7.c, that an object may be catapulted out of the box,8 are much more problematic than those we haveconsidered above. Two features of this bug are immediately apparent. First, it rarely if ever actually happens. My guess isthat no one in this history of packing boxes has ever been surprised by an object flying out in this way.9 Second, it obviouslycould happen if the agent specifically sets it up to happen. All that is needed is an object to act as fulcrum, an object to actas lever (or a single bent object to act as both fulcrum and lever), a light object to act as missile, and a heavy object (muchheavier than both missile and lever) to act as trigger (Fig. 5). Further thought reveals a third feature; namely, that it is verydifficult to formulate plausible constraints on the shapes of the objects or on the loading actions that suffice to make thisimpossible. The fulcrum and missile need only be comparatively small; the shape of the trigger is entirely unconstrained.The lever does have to be substantially longer than it is thick, but ruling out all objects of that kind — that is, requiring8 We have already dealt with BUG.7.b in which an object on oTable1 is catapulted out of the protected area.9 One of the reviewers disagrees, and thinks that probably this does occasionally happen in practice. Also, note, by contrast, that liquid spilling out ofthe top of a pail, either in filling the pail or in carrying it (analogous to BUG.8) is quite common and requires care to avoid if the pail is nearly full.312E. Davis / Artificial Intelligence 175 (2011) 299–345that all objects be more or less cubical — really does seem like an unacceptably strong restriction to fix a problem thatnever actually comes up. Note that the trigger need not be the object being loaded, so it does not suffice to posit thatthe agent sets each object down very gently in loading it; adding the new object, however gently, may disturb a carefullybalanced equilibrium and knock over some other object that will function as the trigger. One might think that one couldfind restrictions on the way in which objects are heaped and removed from heaps that would exclude this, but short ofdoing an exact simulation, which defeats the whole point of qualitative reasoning, that seems very difficult to do.So what should be done? The obvious temptation is just to posit that it can’t happen, since it never does. But I amafraid that this is a dangerous path. Quite clearly this can happen. It is not merely a theoretical consequence of Newtonianphysics, or a recondite case with specially designed objects; on the contrary it is quite obvious that anyone can make ithappen in a few minutes with a couple of household objects. Thus, a theory in which it cannot happen is inconsistentwith commonsense understanding of solid objects, and therefore cannot be extended to a general theory of commonsensereasoning about solid objects. Note that this is quite different from, for example, saying that the theory of rigid solid objectscannot be extended to a theory of non-rigid objects. The latter case has to do with theories of two very different scopes;naturally, one does not expect to deal with non-rigid objects in formulating a theory of rigid objects. Here the natural scopeof the overarching theory is the dynamic theory of rigid objects, which includes both boxes and catapults. In this paper, wehappen to be dealing with boxes, but certainly we would certainly hope to be able to develop our theory as a subset of abroader theory of rigid solid objects.A second idea is to restrict the physics to quasi-statics, the limiting case where dissipative forces are always so large ascompared to momentum that no object can travel more than a negligible distance under its own inertia; they only movewhen pushed by an agent or by gravity. Usually quasi-static theories are used in the context of two-dimensional objectsmoving on a horizontal surface, but one could develop such a theory for three-dimensional motion; intuitively, you imaginethe entire scenario as taking place in a vat of Liquid Prell.10 But we have decided not to pursue this. First, this extension tothree-dimensional dynamics involves some technical difficulties (for instance, how fast should an object move in free-fall orin falling over while partially supported?) Second, making this assumption obviously limits the generality of the theory.A third idea is to move to a probabilistic theory, especially as we will eventually have to do that anyway, and say that thecatapulting is very improbable. However, as far as I can tell, this does not fix the underlying problem, though it changes it.The problem now is that a probabilistic theory must specify the probability of events, not just absolutely, but conditionallyas well. And the probability of catapulting, which is negligibly small under most conditions, becomes 1 on the conditionthat the agent deliberately sets up a catapult. One might be tempted to say that it is very unlikely that the agent will wantto set up a catapult, but at that point we would be basing our physical theory on a theory of relative likelihood of goals,which does not seem like a good direction to go in.The best solution I have been able to find is to use a default theory. Intuitively, we want to posit a default rule thatcatapulting does not occur unless there is good reason to think that it might. Thus if we know that the agent has set up acatapult and is triggering it, then the catapulting must occur, the theory predicts that it will occur, and the default does notapply. If there is “good reason” to think that the agent may have set up and triggered a catapult, then the conditions of thedefault rule are negated, and we are left agnostic as to whether the catapulting occurs. Otherwise, the default rule applies,and we conclude that no catapulting occurs.Specifically, we define an “upward-motion-free” history as one in which no object in a heap ever moves upwards withrespect to the object(s) supporting the heap. We then posit a default rule that histories are, by default, upward-motion-free.The default rule does not apply to cases where an agent picks up the object directly or indirectly. (Some care must be takenin cases where the heap is supported by several objects or the support tilts in the course of the history. We will give amore exact statement in Section 3.7 after defining “heap” in Section 3.6.)This default rule also takes care of all the subcategories of BUG.8 except BUG.8.a, since they all rely on an object escapingout the top of the box. This is indeed how we will deal with these bugs in our formal theory. A more complete theory wouldcontain rules that would specify exceptional cases in which these bugs are likely or certain to occur; given such rules,one could then exclude the bugs for ordinary cases, either by using default rules or by explicitly negating their enablingconditions.Generally, the major difficulty in using a default rule of the form “Assume P unless P is impossible” is making sure thatP is not impossible; that is, P is not contradicted by anything else in the theory. For qualitative prediction, the followingapproach is possible: Suppose that you are given qualitative information about the boundary conditions; that is, the shapesand positions of the objects and the actions of the manipulator. If you can find a specific instance I that satisfies thequalitative constraint, such that when you run a Newtonian simulator on I , the defaults are satisfied, then clearly thedefaults are consistent with the boundary conditions and with Newtonian physics, and may therefore be applied.Of course, going from a monotonic theory to a non-monotonic theory has many drawbacks. For our purposes, the mostserious drawback is that the value of establishing any particular inference shrinks dramatically, in the following sense:In a monotonic theory, if you prove that Γ |(cid:7) φ, then you have simultaneously established that Γ ∪ (cid:2) |(cid:7) φ for any furtheraxioms (cid:2). Thus, you have established the validity of inferring φ from a whole class of possible knowledge bases. By contrast,10 A brand of shampoo that, some years ago, was the subject of a well-known advertising campaign featuring a demonstration that the shampoo wasparticularly viscous. For some reason, this was supposed to imply that it was also particularly good shampoo.E. Davis / Artificial Intelligence 175 (2011) 299–345313in non-monotonic theories this does not follow so easily; for any particular (cid:2) you have to re-establish that (cid:2) does notblock any of the non-monotonic rules that you used to prove φ from Γ . In probabilistic theories, the situation is even moredifficult; you have to show that φ is conditionally independent of (cid:2) given Γ , or approximately independent.A second general problem with non-monotonic theories is that it is very hard to be confident that they don’t haveunintended consequences. You can check that a monotonic theory is safe by constructing a model in which it is true; thenthe consequences of the theory cannot be any weirder than the model. But non-monotonic theories do not have semanticsof this kind. (This is one reason that recent work on non-monotonic theory has tended to use the non-monotonic inferenceto derive equivalent monotonic axioms; these can then be checked for validity in a model.) To alleviate this problem, wetry to keep our default rules as weak as possible, consistent with supporting our desired inference that objects ordinarilyremain in boxes during loading and carrying, so that there is as little risk as possible that the default rules have unintendedconsequences.Another problem is the Yale Shooting Problem [16]. Our default rule does indeed run into this; it allows a backwardscausality in which objects may be catapulted out at an earlier stage if that will prevent them from being catapulted outlater. However, since this only comes up in scenarios of Rube Goldberg-like complexity, I am not very concerned about it.I don’t think there’s much point worrying about how to fix this until one has addressed the underlying probabilistic issues.It may seem odd that I should now be worrying about the Yale Shooting Problem at all since this problem was “solved”many years ago. The difficulty is that all the solutions I know of (e.g. [20,33]) work by using closed-world assumptions toderive a suitable frame axiom, in the manner mentioned above. If that would work here, I wouldn’t need a default rule atall; I could just state the frame axiom monotonically. (The authors of these solutions are working with different underlyingconstraints as to what constitutes an acceptable formulation of a prediction problem.)Finally, it might be argued that the proposed default rule is just a way of disguising the argument, which we raised andrejected above, that catapulting is unusual because agents rarely have the goal of firing catapults. After all, if the populationof agents involved consisted entirely of seven-year olds who had just discovered the joys of catapulting things, then it mightbe reasonable to assume, by default, that whenever a plan can be instantiated so as to fire a catapult, it will be. Thus, ourproposed defaults above incorporate an assumption about the psychology of the agents involved. I don’t think this is right.It seems to me that there are two separate plausible inferences involved here; first, that the physical inference that loadingobjects into a box randomly will rarely cause catapulting, and second, the psychological inference that agents engaged inloading a box will rarely decide to construct a catapult. A physical theory of boxes must deal with the first, independentlyof the second.3.3.6. The box falls overThere are at least four different scenarios that could give rise to BUG.6, in which the box falls over or is pushed off thetable while being loaded. The first scenario is that if the walls of the box tilt outward, or the bottom of the box is rounded,and the cargo is loaded at a point that is outside the region where the box is supported by the table, then the weight ofthe cargo may make the box tip over onto its side (Fig. 7.A). We can exclude this by requiring that the center of mass ofevery cargo object is above the convex hull of the contact points of the box with the table. It is easy to show that if thiscondition holds, then any tilting by the box will raise the height of the centers of mass of the cargo objects; therefore, thecargo objects cannot be exerting a force that causes the box to tilt.A second scenario is illustrated in Fig. 7.B. By sliding down the slanted left-hand side of the box, O 1 could exert sufficientleftward force on the box to push its end over the table. The center of mass of the pair {O B, O 1} would still be over thetable, but if you now load a heavy object O 2 on the left-hand side of the box, the box could fall off the table.A third scenario is illustrated in Fig. 7.C: a cargo object O 1 sliding or rolling around a curve exerts enough horizontalforce to push the box over. (Note that if the side of the box is curved outward, then O 1 exerts a centrifugal force whosemagnitude is dependent on the velocity of O 1.)A fourth scenario is that, in the course of loading the box, the cargo objects settle and hit the side of the box in such away as to knock the box over on its side. I find it hard to draw a convincing picture of this, so I leave this to the imaginationof the reader.The first scenario is a quite plausible one, but as observed above, it is easy to find conditions that demonstrably excludeit. To exclude the remaining scenarios, we introduce the following default rule: If an object O B is stably supported on top ofobject O T and a collection of object O C is initially piled in heaps on top of O B, and the centers of mass of all the objectsin O C remain over the convex hull of the points of contact between O T and O B, and O T remains motionless, then assumeby default that O B remains motionless.We have fallen back on a default rule here, rather than look for conditions that are demonstrably sufficient in a Newto-nian theory for a number of reasons.• The second, third, and fourth scenario are uncommon. Violations of this default rule will be very infrequent.• It seems to be very difficult to find qualitative boundary constraints of the proper form — that is, constraints on shapeand material properties, constraints that apply in the initial state, and constraints on the execution of the plan — thatsuffice to ensure that these scenarios are impossible, particularly since the third and fourth scenario have a complicateddependence on the velocities of the objects involved.314E. Davis / Artificial Intelligence 175 (2011) 299–345• If one were to compute such constraints they would almost certainly be far more restrictive than necessary. It seemspointless to impose highly restrictive conditions on the scope of our inference in order to exclude possibilities that arein any case very rare.Fig. 7. Box falls over: three cases.3.3.7. Why not use defaults for all our problems?Since we are in any case resorting to default rules into order to deal with bugs 6, 7, and 8, why not do this for allthe categories of bugs? In general, any place where we have required a condition to eliminate a bug, we could replacethat, either with a default rule that the condition holds, or, even better, with a default rule that the bug doesn’t arise. Insome cases, this would clearly be unreasonable; it would be absurd to say that, by default, a given set of objects uCargofits inside a given box oBox. On the other hand, it would be quite reasonable to replace the absolute condition excludingobjects that can roll by a default rule that objects in general cannot roll. In the latter cases, whether or not to use a defaultrule would depend on what kinds of information are actually available and what kinds of situations actually arise in a givenapplication. (There are, for instance, applications in which rolling objects are common.) Here, our objective has been to useas few different default rules as possible; namely, the two default rules discussed in the previous two sections, which werethe only means we found to exclude bugs 6, 7.a, 7.c, 8.b, and 8.h. However we did not minimize the number of applicationsof this rule needed; as discussed in Section 3.3.4, we have used this default rule to exclude bugs 8.c through 8.f, whereaswe could reasonably have excluded these monotonically by imposing further conditions.3.4. VariantsWe now turn to the variants on simple open boxes mentioned in the introduction: namely, boxes with lids, boxes withholes in the bottom and sides, and trays. First as regards lids, we observe that if you cover the box with a lid and you canE. Davis / Artificial Intelligence 175 (2011) 299–345315guarantee that the lid will not come off during carrying, then you can be sure that none of the cargo items will come outof the box during carrying, thus eliminating BUG.7.c and all the subcategories of BUG.8. (That is the main point of having alid.) You can also guarantee that no external object will enter the box while it is being carried, thus allowing the “isolationcondition” COND.6 to be weakened. The plan, of course, must be modified to add the step of placing the lid onto the boxbetween loading and carrying the box. We assume that the lid, like the objects in uCargo, is initially resting isolated onoTable1 and that it fits on the box when the box is empty. However,BUG.9 The lid may no longer fit on the box once the box is filled.BUG.10 The lid may come off during carrying, either becausea. It falls off on its own (consider, for example, a lid which is just a flat piece of cardboard laid over the top of thebox).b. It is knocked off or removed by some external object during carrying.c. It is knocked off by the clattering of the cargo inside the box.Boxes with holes suffer from the bug thatBUG.11 Objects may fall through these holes at any stage.For trays and overfilled boxes, condition COND.3 is replaced by the condition(cid:9)COND.3The cargo uCargo can be arranged as stable heaps supported by oBox.and BUG.3 and BUG.4 are modified accordingly. However, we introduce a new subcategory of BUG.8:BUG.8.i Depending on the stability of the heaps, even quite smooth motions or small tilts may cause a heap to collapse,potentially causing some object to fall off the heap.The problem with trays is that it is very difficult to formulate reasonable qualitative constraints on object shapes thatsuffice to guarantee that the cargo can be piled in stable heaps on the tray; it is not even easy to guarantee that a singleobject stays put on a tray. (For example, if an object has a round bottom, then, even if it is weighted so that it can onlyroll very slightly and even if the tray is kept perfectly horizontal, the object can still gradually work its way off the trayin response to very small accelerations and decelerations in carrying the tray.) To formulate a reasonably general theoryof trays, therefore, probably the right approach is to posit the qualitative condition that the cargo can be piled into stableheaps on the tray; in particular circumstances, this itself may be inferrable from fairly precise specifications of the geometryof the cargo. This indeed is the advantage of a box over a tray; once the cargo is inside the box, it does not matter whetherthe objects shift their positions or not, as long as they do not move violently enough to run into bugs 8.b though 8.h. Also,because of the walls of the box, stable positions of the cargo in the box can be made taller than on a tray and are easier toattain.We fix the other bugs as follows:BUG.9. We posit that the cargo fits inside the box, and that the lid does not extend into the inside of the box.BUG.10. We posit that the lid caps the box; that it is heavy enough as compared to the impacts of objects inside and outthat it is not knocked off; and that the trajectory during carrying is smooth enough that it is not flung off that way.BUG.11. We posit that the objects do not fit through the holes.Finally, if we consider the special case where the cargo consists of a single object, what is perhaps most striking ishow many of the potential bugs still remain. Specifically, BUG.1, BUG.3.a, BUG.3.b, BUG.5, BUG,6, all the categories of BUG.8except BUG.8.h, BUG.9, BUG.10, and BUG.11 are still problematic (though BUG.3.a can easily be fixed by positing that oBoxdoes not “close in” on itself). BUG.2, BUG.3.c, BUG.4, BUG.7, and BUG.8.h no longer apply.3.4.1. Bugs and their fixes: overall viewIt may seem, on first glance, that once we have limited our theory by this large collection of qualifications and defaultrules there is not very much left. But in fact, most of these qualifications are essentially commonsensically obvious; a rea-soner who sees that the cargo is too big, or that the carrying is very bumpy, or that the cargo can fall through holes in thebottom and so on will expect that the plan may well fail. Though the exact formulation is driven by the need to formalizeand the desire to follow Newtonian physics as far as possible, these qualifications are, I would argue, basically part of acommonsense understanding of the domain.316E. Davis / Artificial Intelligence 175 (2011) 299–345Fig. 8. OB can be construed as a box with in many different possible insides QI.3.5. The geometry of a boxThere are a few more issues that we want to address at the pre-formal level before setting forth to turn our theory intofirst-order logic. The first is the definition of what it means to be a box. We define an open box as a geometric predicate asfollows:Definition 3.5.1. A region is a set of points that is connected, bounded, and topologically regular.11 The topological boundaryof region R, denoted “Bd(R)”, is the set of points in R that are not in the interior of R.Definition 3.5.2. Let R B and R I be two regions. We say that R B is an open box with inside R I if the following two conditionshold:• The interior of R I ∩ R B is empty. (R I is externally connected to R B [30].)• Bd(R I )–Bd(R B), the part of the boundary of R I that is not part of the boundary of R B, lies in a plane and contains acircular disk of positive radius. (The latter condition is a topological condition to guarantee that the opening of the boxis not a single point or a single curve but is a true face that a small enough object can get through.)Note that a given shape R B can often be construed as an open box with many different possible values for R I (Fig. 8).Indeed, if R B forms an open box with one region of R I then necessarily there are many different possible values of R I ,with faces running in many different directions, which are possible insides for R B. To give an intuition, if you can orient asolid object with shape R B in some position where it holds water, and then you fill some external cavity of O B with waterto some depth, then the region occupied by the water constitutes a possible inside for R B.Given a box R B with inside R I , the outside of (cid:11)R B, R I(cid:12) is the complement of R B ∪ R I . An opening of (cid:11)R B, R I(cid:12) is aconnected component of Bd(R I )–Bd(R B); all the openings of (cid:11)R B, R I(cid:12) lie in a single plane.If (cid:11)R B, R I(cid:12) form a geometric box, solid object O B has shape R B, and solid object O 2 is inside R I at one time andoutside R I at a later time, then O 2 must have exited through an opening of (cid:11)R B, R I(cid:12). Proof: Since O 2 went from inside R Ito outside R I it must have gone through the boundary of R I and it obviously can’t go through the part the boundary of R Ithat borders O B; end of proof. Therefore, if O 2 is initially inside R I , and the opening of (cid:11)R B, R I(cid:12) is always higher than O 2,then it follows that O 2 must remain inside R I .3.6. Heaps and stabilityA central concept in the qualitative physics of solid objects is that of a stable heap of objects. The precise definition of a“heap”, a canonical example of a vague concept, is necessarily somewhat arbitrary, but the following serves our purposeshere.To begin with, in the commonsense setting we must distinguish between mobile objects, which can move, and fixedobjects, which cannot. In a given state, a mobile object may be grasped by the agent; while it is being grasped, its motionsare controlled by the agent and are not affected by external objects. Thus, neither fixed objects nor grasped objects are11 A region is topologically regular if it is equal to the closure of its interior. This essentially requires that the region has some “thickness” in threedimensions; it excludes curves, surfaces, shapes that are solid in some places and two-dimensional lamina in other places, and so on.E. Davis / Artificial Intelligence 175 (2011) 299–345317affected by the motions of mobile objects; their motions are boundary conditions for a prediction problem.12 An object isfree-moving in state S if it is mobile and not grasped.A heap is a connected set of free moving objects; in our theory, unlike discussions of the Sorites paradox, a heap maycontain a single object. A heap of objects is defined with respect to some set of supporting objects. Usually a heap actuallyhas a single supporting object, such as the ground or a box, but in some cases a heap may rest on multiple supports, suchas a board that is lying with ends on two different tables.Definition 3.6.1. Let U H and U S be disjoint sets of objects, where U H is non-empty. In state S, U H is a heap with supportsU S if the following conditions hold in S:• All the objects in U H are free-moving.• If O 1 is in U H and object O 2 abuts O 1 then O 2 is either in U H or in U S.• Each object in U S abuts some object in U H .• If O A and O B are in U H then there exists a sequence13 O 1 = O A, O 2 . . . O k = O B such that O i ∈ U H and O i abutsO i+1.A set U H is a maximal heap in state S if U H is a heap with supports U S and all the objects in U S are fixed or grasped.Equivalently, a maximal heap is a maximal collection of mobile, non-grasped objects connected by abutment; the supportsof a maximal heap U H are all the fixed or grasped objects that abut some object in U H .A number of consequences follow directly from this definition:First, a fixed object or an object being grasped can only be a support; it cannot be part of a heap. A mobile objectcan be considered as part of a (non-maximal) heap or can be considered as a support; that is a matter of usefulness forthe reasoner. For instance, if one is loading objects into a box, it is sometimes convenient to think of the objects inside asforming a heap (or several heaps) supported by the box, and it is sometimes convenient to think of the box together withthe objects inside as forming a heap. Both viewpoints are OK.Second, in any state, the maximal heaps constitute a partitioning of the free-moving objects into equivalence classes,where the equivalence relation is the transitive closure of the relation “O A and O B are both free-moving and abut”.Third, two distinct maximal heaps cannot abut one another. Thus, around any maximal heap there is a clear space freeof any mobile objects. Since fixed objects and grasped objects are not affected by the motion of mobile objects, this meansthat a sufficiently small motion of any mobile object can only physically affect objects in the same heap. Similarly, anymotion by a grasped O G can only affect mobile objects in heaps for which O G is a support. This gives us a very usefullimit on the causal impact of events.Finally, if U H is a set of mobile objects that are connected through abutment but are in free fall, then U H is a heapwhose support is the null set of objects.We next introduce the notion of a heap being stably supported in a given state. We will not give necessary and sufficientconditions for this, but we axiomatize a couple of the properties that we will need here:Definition 3.6.2. Let U 1 and U 2 be sets of objects. and let H be a history. U 1 is isolated from all objects except U 2 if noobject outside U 1 ∪ U 2 comes into contact with any object in U 1.Axiom 3.6.1. If U H is stably supported by U S in state S, then U H is a heap with supports U S in S, and U S is non-empty.Axiom 3.6.2. Let H be a physically possible history with starting state S1. If heap U H is stably supported by U S in S1,and U S is motionless throughout H , and U H is isolated except for U S and free moving, then U H is stably supported andmotionless throughout H .Axiom 3.6.3. Let H be a physically possible history that is temporally unbounded in the future (in Section 4.3 we will callthis a “uhistory”). Let U S be a set of objects that is motionless throughout H . Let U H be a set of mobile objects disjointfrom U S. Assume that the objects in U H are not grasped at any time in H . Then eventually either every object in U H isin a stable heap supported by some subset of U S or some object in U H comes into contact with some object not in U S.Equivalently, if U H is free moving and isolated in H except for U S, then eventually every object in U H is in a stable heapsupported by some subset of U S.(The above axioms are formalized as axioms H.1, H.2, and H.3 in Table 19.)12 There is an important and awkward exception to this. If the agent is “trying” to move a grasped object O 1 in a given direction but that motion isblocked by a mobile object O 2 that is “stuck”, then moving O 2 may permit O 1 to proceed. A major difficulty in formulating an existence theorem forwell-posed problems in the theory of rigid solid object dynamics with manipulators is to characterize under what circumstances and in what sense aspecified manipulation constitutes a valid boundary condition.13 We assume throughout that there are only finitely many objects in the universe; hence all such sequences are finite.318E. Davis / Artificial Intelligence 175 (2011) 299–345This will be all we need for boxes. Reasoning about trays requires a more extensive theory of stability, which we willdevelop in future work.3.7. No upward motionFinally, we formulate the default rule that will allow us to infer that cargo objects do not come out of the top of thebox. We want to state that by default objects in the box do not move upward with respect to the box; more generally, thatobjects in a heap by default do not move upward with respect to the supports of the heap. There can be different possibledefinitions of what is meant by object O “moving upward”; for convenience we will interpret this as meaning that thecenter of mass of O moves upward and we axiomatize the center of mass as some point within the convex hull of O . (Ifthe region occupied by O is known, but the density distribution is entirely unknown, then all that can be said about O ’scenter of mass is that it is in O ’s convex hull.)Let us begin by formulating the rule in the special case where there is a single support object that maintains a constantvertical axis.Preliminary Definition 3.7.1. In state S1, let O be an object in heap U H that is supported by a singleton object set {O S}.Let H be a history with starting state S1. Assume that O S maintains a constant vertical during H (that is, O S may translateand may rotate around the ˆz axis, but it may not undergo a rotation that tilts the ˆz axis; it may yaw but not pitch or roll.)Let Q S be any point in O S and let Q C be the center of mass of O . O moves upward relative to O S in H if height( Q C )–height( Q S) is larger at the end of H than at the beginning of H . (Since O S maintains a constant vertical, if this is true forany point Q S in O S, it is true for all points in O S.) O has an anomalous upward motion in H if U H is free-moving andisolated from all objects except O S in H and O moves upward relative to O S in H .A history is upward motion free if, for every subhistory H1 of H , no object has an anomalous upward motion in H1.Default Rule 3.7.2. By default, any physically possible history is upward motion free.We can now prove the following theorem:Theorem 3.7.3. In state S, let O B be a box with opening Q T , let U H be a heap of objects supported by O B, and let O be an object inU H . Let F be the diameter of O , and let D be the vertical gap between Q T and the center of mass of O . Let H be a physically possiblehistory starting in S. Assume that throughout H , U H is free moving and isolated from all objects except O B, and that O B maintainsa constant vertical, though it may be moved and rotated around the z-axis. Assume that D > F . Then by default O remain in O Bthroughout H .Sketch of proof. By default, H is upward motion free. Suppose that O goes out of the box during H . As argued in Section 3.5above, if O goes out of the box, it must go through the opening at the top. Therefore, each point in O must be at the topat some point during H . Therefore at some time T 2 during H , the center of mass of O must be closer to the top of O B itwas at the start, so the center of mass of O has moved upward relative to O B in the subhistory of H that starts in S andends at T 2; but this contradicts the statement that H is upward motion free. (cid:2)To complete the proof, it is necessary to establish that the default conclusion is consistent, but it is easy to constructscenarios which are demonstrably consistent with the above givens, with Newtonian physics, and with all the axioms weshall state in Section 4 below, in which the objects in U H rest motionless at the bottom of O B throughout H . U H is astable pile at the bottom of O B which demonstrably does not move relative to O B during all of H .We next need to generalize the above rule in two respects. First, a heap may be supported by more than one supportobject. Second, the support object O S may rotate its vertical axis. In that case, even if the heap just sits quietly on top ofthe support, still the center of mass of some of the objects may move upward with respect to some of the points in O S.Indeed, if the center of mass of some object O in the heap does not lie above the convex hull of the horizontal projectionof O S, then the center of mass of O may move upward with respect to every point in the support O S (Fig. 9).As discussed above, in formulating our default rule, we try to keep it as restricted as possible, to lessen the likelihood ofweird consequences. We therefore address the above two cases as follows. First, we consider an object in a heap as movingupward with respect to its supports only if it moves upward with respect to all its supports. Second, we deal with theproblem of a support O S that rotates vertically as follows: For any history H , imagine taking a video of the behavior of thesupports and the heaps during H . At any point during the video, you can take a vertical arrow and attach it to O S throughany point in O S. Now replay the video from the beginning with that added arrow fixed to O S, so that it moves and rotatesalong with O S. We say that the heap object O moves upward with respect to O S in H if the projection of the center ofmass of O onto the arrow is higher at the end of H than at the beginning of H .Definition 3.7.4. In state S1, let O be an object in heap U H that is supported by an object set U S Let H be a history withstarting state S1. O “moves upward” with respect to U S in H if the following condition holds: For every object O S ∈ U SE. Davis / Artificial Intelligence 175 (2011) 299–345319Fig. 9. Object in a heap moves upward with respect to every point in support.and for every coordinate system Q C “attached” to O S which is vertically aligned in some state in H , the z-coordinate inQ C of the center of mass of O is larger at the end of H than at the beginning of H .The definitions of “anomalous upward motion free”, and of “upward motion free” in terms of “moves upward” are thesame as in the Preliminary Definition 3.7.1, replacing “O S” by “U S”, and the Default Rule 3.7.2 remains unchanged. It canbe seen that this deals reasonably, both with objects that stay fixed on the support, and with boxes. If an object stays ina constant position on the support, then, since any of these arrows are likewise fixed to the support, the projection of thecenter of mass on the arrow remains constant, consistent with the default rule.In the scenario of the heap of objects in the box, we can weaken the statement that the box maintains a constantvertical to the constraint that the maximum deviation from the vertical is φ, if we correspondingly increase the requiredgap between the top of the heap and the opening of the box.Theorem 3.7.5. (This is the result cited in Section 3.3.3.) In state S, let O B be a box with opening Q T , let U H be a heap of objectssupported by O B, and let O be an object in U H . Let F be the diameter of O , and let D be the vertical gap between Q T and the center ofmass of O . Let G be the maximum distance between the projection onto the x– y plane of the center of mass of O the projection of anypoint in the opening of the box in S. Let H be a physically possible history starting in S. Assume that throughout H , U H is free movingand isolated from all objects except U S, and that the vertical tilt of O B is never greater than φ. Assume that D cos(φ) > G sin(φ) + F .Then by default O remains in O B throughout H .Proof. It is easy to show geometrically that all of the opening is at least F higher than any of the boxes, where “height” ismeasured by projection on any of the tilted arrows that can be attached during H . The proof is otherwise identical to thatof Theorem 3.7.3 above. This result is essentially Lemma 2.29 in our formal proof. (cid:2)On the other hand, if the box tips far enough over that objects that can spill out, then, relative to the arrow attachedwhen the box is fully tipped, an object is moving downward, so the default is not violated.We next discuss the workings of this default rule on a number of further examples. As we will see, the default ruledoes the “right thing” for Examples 1–3; in Example 4 it is not clear what the right thing should be but what the defaultrule does is at least not obviously wrong; in Example 5, the default rule is certainly not giving us what we would wish for.Throughout these examples, we will assume that the theory under discussion includes both the axioms we give below inSection 4 and also the axioms of the Newtonian physics of solid objects. Note that adding the axioms of Newtonian physicsdoes not affect the inferences we have discussed above.Example 1. Consider Fig. 10. Suppose that object O T is fixed, and objects O A and O B are mobile. What will actuallyhappen here is that O A remains fixed and O B falls down. One might think that this would be a problem for the defaultrule, because by Definition 3.6.1, one can consider {O A} to be a heap with supports {O T , O B} and O A moves upwardrelative to O B. However, in fact the default is not a problem here, because the default rejects a behavior only if a heapobject moves upward with respect to all its supports, and O A is not moving upward with respect to O T .Example 2. Suppose that O A is in free fall inside box O B (Fig. 11). Then O B is not a support of any heap containing O A, sothe default does not apply. That is not a problem. If it is known that O A is initially moving downward, then we can provethat it will eventually hit either O B itself or some other object that is (directly or indirectly) in contact with O B. At thatpoint O A becomes part of a heap inside O B, so we can apply the default from that point. If it is known that O A is initiallymoving up, then it may well escape O B, if it is moving fast enough, so we do not want the default to apply. If the directionof motion of O A is not initially specified, there does not seem to be any very good reason to make the default assumptionthat it is not moving upward fast enough to escape, so the fact that the default rule does not apply is not a problem.320E. Davis / Artificial Intelligence 175 (2011) 299–345Fig. 10. Default rule: Example 1.Fig. 11. Default rule: Example 2.Fig. 12. Default rule: Example 3.Example 3. Suppose that O B is a box, O C is a ramp resting at the bottom of O B, and O A is on O C sliding rapidly upward.Since {O A, O C} is a heap with support {O B}, the condition of the defaults apply. However, if our theory includes the lawof inertia, then O A must be moving upward with respect to the box, so the default is explicitly overridden, so again we getthe correct answer (Fig. 12).Similarly if one explicitly sets up and triggers a catapult, then the axioms of Newtonian physics imply that the missilewill move upward, so the default rule is explicitly overridden.Example 4. Suppose that object O A is inside O B but it is not specified whether it is part of a heap supported by O B orwhether it is in free fall. Then the default rule applies, and gives rise to the conclusion that either O A is initially in a heapand remains in the box or it is initially in free fall and nothing can be said as to its motion. It is not clear to me whetherthis is the most desirable conclusion, or how one would decide what is the most desirable conclusion. Things get fairlynebulous at this level of ignorance. In any case, it seems to me that this is at least not indisputably wrong.Example 5. Consider Fig. 13. The box is made of three jointed pieces: The first piece O B1 consists of the left-hand walland the left-hand half of the floor. The second piece O B2 is the right-hand half of the floor, and the third piece O B3 is theright-hand wall. In the starting state, object O A rests on O B1 and O B2, so these are its supports. Now consider a historyin which right-hand side of the box is folded upward and inward so that O B2 becomes vertical. Then the default ruleapplies but it does not prevent O A from exiting the box, for the following reason: If you attach the vertical arrow to O B2at the end of the history, then that arrow is lying horizontally in the starting state, and therefore a motion of O A verticallyupward would not be upward with respect to the arrow at that point. Therefore, such a motion would not be anomalous,and would be consistent with the statement that the history is upward motion free.This example is unequivocally a failing of our theory; in this case, we definitely want to predict that O A does not exitthe box, and our default rule is not strong enough to support that. This strongly suggests that we have not found the bestpossible formulation of the default rule, in the case of multiple supports with vertical rotations. It should be noted, though,that this is at least the right direction for failure; it is much better to have the default rule be too weak than too strong.Finally, we need to specify a particular default logic in which the default rule can be stated and applied. It seems thatReiterian default theory [31] fits our needs better than circumscription [24]. Let me explain in terms of the standard exampleof birds that can fly. Suppose we have the following four first-order statements:E. Davis / Artificial Intelligence 175 (2011) 299–345321Fig. 13. Default rule: Example 5.1. ∀ X penguin( X ) ⇒ ¬canFly( X ).2. ∀ X penguin( X ) ⇒ bird( X ).3. ∃ X penguin( X ).4. bird(tweety).We also have the default rule, “By default, birds can fly”, and we would like to infer that Tweety can fly.In the Reiterian theory, this default can be represented by the rule5.R. bird( X ) : canFly( X ) / canFly( X ).The theory 1–4, 5.R supports the conclusion “canFly(tweety)” and therefore, from (1), ¬penguin(tweety).But there is no way to get this out of circumscription. The default rule is represented by the first-order statement5.C. bird(X) ∧ ¬ab( X ) ⇒ canFly( X )and the circumscriptive policy of minimizing the predicate “ab”. But this does not support the conclusion canFly(tweety),whether or not the extension of “penguin” is allowed to vary, because a model where Tweety is the only penguin and theonly abnormal entity does, in fact, minimize ab.If you replace (3) above with “penguin(fred)”, add the unique names assumption that tweety(cid:2)=fred, and adopt thecircumscriptive policy of minimizing “ab” while allowing “penguin” to vary, then you can indeed deduce that Tweety canfly. But you can also deduce that Fred is the only penguin. This seems like a lot of bath water to hold onto for the sake ofnot losing the baby.Going back to boxes: “canFly( X )” corresponds to “ X comes out of the box”, “bird( X )” corresponds to “ X is in a heapon the floor of the box” and “penguin( X )” corresponds to “ X is a missile being catapulted”. The existential statement(3) corresponds to the fact that a complete theory of solid object dynamics should certainly support the inference thatit is possible to set up and fire catapults. The impossibility of showing circumscriptively that Tweety is not a penguincorresponds to the impossibility of showing that the agent has not set up a catapult, given that he has loaded some objectsinto the box.Therefore, it seems to me that, despite the attractiveness of circumscription — it is usually much easier to verify thecorrectness of proofs in circumscription than in Reiterian default theory — it is not applicable here. The same considerationsapply to the default rule that we use to prove that the box will not fall over during loading.4. The formal theoryWe now proceed to encode the above theory in logical form. This is actually reasonably straightforward; except forthe semantics of plans, we have covered all of the tricky issues already. Other than the two default rules H.5 and UP.1,defined below, we represent all of our theory in first-order logic. In this section we first establish a few basics: notationalconventions and system of sorts (Section 4.1), and theories of real arithmetic and of Boolean operations on finite setsof objects (4.2). We will then describe the ontology, language, and theories that we will use for theories of time (4.3),space (4.4), motion (4.5), and physics (4.6). Section 4.7 presents a comprehension axiom for histories. Section 4.8 gives thesemantics of our language of plans. Finally we give the specification of the problem to be solved (4.9) and the specificationof the plan that solves it (4.10).We assume the standard mathematical theories of integer and real arithmetic, Boolean operators on finite sets, Euclideangeometry, and continuous functions. Therefore, in our axiomatization, we will enumerate the sorts and symbols we need,but we will not list the axioms. In our formal proof, we cite theorems from these theories as needed without axiomaticproofs (though when the theorems are not obvious, we give proofs in the usual sense).The axioms we enumerate are, for the most part, just those we need for the validation of the plan; we have not at-tempted anything like a complete axiomatization of these domains.322E. Davis / Artificial Intelligence 175 (2011) 299–345Table 2Axioms of sorts.SORT.1 The declaration of predicate symbol α as taking arguments of sorts σ1 . . . σk corresponds to the axiom∀ X1...Xk α( X1 . . . Xk) ⇒ sortOf( X1, σ1) ∧ · · · ∧ sortOf( Xk, σk).(Note: The equality symbol X = Y has no sort declaration, so this axiom does not apply.)SORT.2 The declaration of function symbol β as taking arguments of sorts σ1 . . . σk and returning a valueof sort σ0 corresponds to the two axioms ∀ X0, X1... Xk X0 = β( X1 . . . Xk) (cid:2)= ⊥ ⇒sortOf( X1, σ1) ∧ · · · ∧ sortOf( Xk, σk) ∧ sortOf( X0, σ0)and∀ X0, X1... Xk sortOf( X1, σ1) ∧ · · · ∧ sortOf( Xk, σk) ⇒ β( X1 . . . Xk) (cid:2)= ⊥.SORT.3 The declaration of constant symbol γ as having sort σ corresponds to the axiom sortOf(γ , σ ).SORT.4 ∀S ¬sortOf(⊥, S).(The null element has no sort.)SORT.5 subsort(S1, S2) ≡ ∀ X sortOf( X, S1) ⇒ sortOf( X, S2).(Definition of subsort.)4.1. Notational conventionsAll this is pretty much standard and self-explanatory, but it is as well to lay it out systematically.Our axioms are stated in a sorted first-order logic. We use symbols in Roman font beginning with a lower-case letter,such as “openBox”, for function and predicate symbols, and symbols in typewriter font, such as oBox, for constant symbols.We use upper case symbols in italics for variables. Standard mathematical functions and predicates are used in the standardway; e.g. X1 + X2 is an infix function; the pair of curly brackets of {E1, E2} is an outfix function (mapping E1 and E2to the set {E1, E2}). To aid readability, the sort of a variable is indicated by the first letter; however, all axioms are statedso that this convention is not necessary. Quantified variables are subscripted to their quantifier. For brevity, we use twoforms of restricted quantification in the subscript: a variable may be restricted by sort or by membership in a set. Logicaloperators follow the following precedence, from highest to lowest: negation ¬, conjunction ∧, disjunction ∨, implication⇒, equivalence ⇔, definitional equivalence ≡, and quantifiers ∀ and ∃. Thus, the scope of a quantifier is to the end of theformula or to a right bracket that contains it. Free variables are taken to be universally quantified, where the scope of theimplicit quantifier is the entire formula. Greek letters are infrequently used as meta-variables.We have a hierarchical system of sorts, which is interpreted as syntactic sugar for a standard first-order theory with anull element ⊥. (The null element is never used explicitly in our formulas.) In the translation to the base theory, an individ-ual sort such as “object” or “state” is considered an entity. There are two predicates over sorts: “sortOf( X, S)”, meaning thatX is an entity of sort S, and “subsort(S1, S2)”, meaning that S1 is a subsort of S2. We will abuse notation in our formulasby writing “S( X)” where S is a sort instead of “sortOf( X, S)”; e.g. we will write “object(O )” instead of “sortOf( X ,object)”.The sorts of the arguments to predicate and function symbols and to the values of function and constant symbols will bedeclared in a self-explanatory notation when these symbols are defined. Table 2 shows the translation of sort declarationsinto the base language.As axiom SORT.2 indicates, all functions are required to be total over the sort on which they are defined (except fornumerical division, which is grandfathered). Hence, when we have a mapping which is single-valued but not total, we willuse a relation symbol for it and add an axioms stating that it is single valued (when necessary). The “value” of the mappingwill conventionally be the last argument. For this reason, in cases where we do use a function symbol, even if that is definedand not primitive, such as “startTime( J )” in Section 4.3 below, we do not have to add an axiom stating that the function istotal over the sort; such an axiom is implicit from the use of the function symbol.Axioms SORT.1–SORT.4 together imply that any ground term with argument ⊥ evaluates to ⊥ and that any groundatomic formula with argument ⊥ is false, unless the predicate is the equals sign.4.2. Real arithmetic; set theoryAs stated above, we use real arithmetic and Boolean set theory over sets of elements. (As we shall see below, the sets thatwe need in this paper are sets of objects, and sets of geometric points; these two sorts are therefore defines as subsorts of“element”.) Table 3 enumerates the sorts and the symbols used. All the symbols are entirely standard, except “count(U , I )”,a predicate meaning that integer I is the number of elements in finite set U (if U is infinite, then this does not hold forany I ). The letter after the sort is the one we will use to indicate variables of that sort.4.3. TimeOur temporal theory in some respects resembles the phase-space theory of physics (and inherited by robotics fromphysics) rather than the situation-based theory more common in AI [32,27]. Specifically, for our purposes the state of theworld at an instant can be characterized by the values of a fixed class of fluents. The history of the world is a functionfrom real-valued time to states. A state may persist unchanged over a finite length of time, or a history may “return” to aprevious state; whereas the model of situations is generally taken to be strictly forward-branching with no cycles. In ourE. Davis / Artificial Intelligence 175 (2011) 299–345323Table 3Sorts and symbols for real arithmetic and set theory.Sorts:Real numbers ( X).Integers (I). Subsort of reals.Elements (E).Sets of elements (U ).Symbols:X1 + X2, X1 − X2, X1 · X2, X1/ X2, (cid:5) X(cid:6), min( X1, X2), X1 < X2, X1 (cid:2) X2, π .∅, {E1, E2 . . . Ek}, E ∈ U , U 1 ∪ U 2, U 1 ∩ U 2, U 1 ⊂ U 2, U 1 − U 2.count(U : set, I: integer).model an action A is feasible in state S if there exists a history starting in S in which A occurs; whereas most modelsof situation calculus theories have explicitly forward-branching structures. Therefore, we will use the word “state” rather“situation” to denote a snapshot of the universe at an instant.For brevity, we will treat clocktimes (e.g. May 1, 2006 12:45:00 PM) and durations (e.g. 1.57 hour) as real numbers,though of course a more rigorous treatment would take these to be separate sorts which have a real-valued measure ina given temporal coordinate system. For readability, we will use T for variables over clocktimes and D for variables overdurations.The other temporal sorts we will use are as follows:• A state is a snapshot of the universe.• A fluent is an entity that takes on different values in different states. A Boolean fluent such as “grasping(O )” (the agent isgrasping object O ) is true or false in a state; a non-Boolean fluent such as “place(O )” (the region occupied by object O )takes on values of some other sort. If a fluent Q takes on values of sort σ , we denote the sort of Q as “fluent[σ ]”;e.g. grasping(O ) has sort fluent[Bool] and place(O ) has sort fluent[region]. In translating the sort language to the baselanguage, the symbol “fluent” here is a function that maps a sort like “region” to the sort fluent[region].• A history is a function from a closed interval of clocktimes to states.14• Because we are using a language of plans that includes loops, which can be infinite loops, it is sometimes necessaryto allow histories that are closed on the left but unbounded on the right. These are also convenient for stating that acertain condition is eventually attained. A uhistory is a function to states whose domain is an interval of clocktimes thatis closed on the left and either closed or unbounded on the right. Thus, histories are a subsort of uhistories.Tables 4–7 enumerate the temporal symbols, definitions, and axioms we use. The temporal theory actually requires onlythree primitives (in addition to the primitives on the reals): holds(S, Q ), value(S, Q ), and stateAt( J , T , S). However, it isuseful to have a large vocabulary of defined predicates as convenient abbreviations.It will also be convenient to define some additional syntactic conventions for constructing functions over fluents fromfunctions and predicates over atemporal entities. First, if X is an atemporal entity, then we define value(S, X) = X for allstates S; that is, we conflate a fluent that are constant with its value.Let Φ( X1 : σ1 . . . Xk : σk) be a predicate (or equality sign) over atemporal sorts σ1 . . . σk. For i = 1 . . . k let Q i be a fluentof sort fluent[σi ]. Then we define Φ #(Q 1 . . . Q k) to be the Boolean fluent satisfying⇔ Φ(cid:3)value(S, Q 1) . . . value(S, Q k)(cid:3)S, Φ #(Q 1 . . . Q k)∀S:state holds(cid:2)(cid:2).Similarly let Ψ ( X1 . . . Xk) : σ be a function with arguments of atemporal sorts σ1 . . . σk and value of sort σ . ThenΨ #(Q 1 . . . Q k) is the fluent of sort fluent[σ ] satisfying∀S:state value(cid:2)(cid:3)S, Ψ #(Q 1 . . . Q k)(cid:2)(cid:3)value(S, Q 1) . . . value(S, Q k).= ΨFinally, if (cid:2) is a Boolean operator then (cid:2)# is the corresponding function over Boolean fluents (used with the same syntaxas the operator). That is,∀T :time holdsT , Q 1(cid:2)# Q 2⇔(cid:3)(cid:5)(cid:4)holds(T , Q 1)(cid:2)holds(T , Q 2).(cid:2)For example, if Q 1 and Q 2 are fluents whose value at each time is a set, then “ Q 1 =# ∅” is the Boolean fluent that holdsat those times where Q 1 is empty. “ Q 1 ⊂# Q 2” is the Boolean fluent that holds when Q 1 is a subset of Q 2. “ Q 1 ∪# Q 2”is the fluent whose value at each time S is the union of the values of Q 1 and Q 2. “ Q 1 ⊂# Q 2 ∨# Q 2 ⊂# Q 1” is the fluentthat holds at all times in which either Q 1 is a subset of Q 2 or Q 2 is a subset of Q 1.14 Some of the axioms below, particularly DYN.12, HC.4, PLD.3, PLD.5, and PLD.7 could be stated more elegantly if we allowed the use of bounded, openintervals as well. It is not clear whether the theory would be simpler overall.324E. Davis / Artificial Intelligence 175 (2011) 299–345Table 4Time: Sorts and symbols.Sorts:Time (T ) = real.Duration (D) = real.State (S).Fluent(Q ).History (H).Uhistory ( J ).Symbols:holds(S: state, Q : fluent[Bool]). Boolean fluent Q holds in state S.value(S: state, Q : fluent[γ ]) → γ . The value of non-Boolean fluent Q in state S.γ is a meta-variable ranging over sorts.J : uhistory). T is a time in the domain of uhistory J .stateAt( J : uhistory, T : time, S: state). S is the state of J at time T .timeIn(T : time,startTime( J : uhistory) → time. The starting time of uhistory J .endTime(H: history) → time. The ending time of history H.start( J : uhistory) → state. The starting state of uhistory J .end(H: history) → state. The ending state of history J .unbounded( J : uhistory).Uhistory J is unbounded on the right (i.e. not a proper history).stateOf(S: state,throughout( J : uhistory, Q : fluent[Bool]).J : uhistory). S is a state attained by uhistory J .Boolean fluent Q holds throughout uhistory J .throughoutxSE( J : uhistory, Q : fluent[Bool]).Q holds throughout uhistory J , except possibly at the start and end of J .J 1 is a temporal slice of J 2.historySlice( J 1, J 2: uhistory).historyPrefix( J 1, J 2: uhistory).historyProperPrefix(H1:history, J 2: uhistory). H1 is a proper prefix of J 2.historySuffix( J 1, J 2: uhistory).hsplice(H1: history,J 1 is a temporal prefix of J 2.J 1 is a suffix of J 2.J 2, J : uhistory).J is the result of splicing J 2 to the end of H1.sameTime( J 1, J 2: uhistory).singleHist(S: state, H: history). H is a history consisting of a single instant at S.J 1 and J 2 have the same clocktime interval as domain.Table 5Temporal theory: Definitions.Definitions: These definitions are self-explanatory given the descriptions in Table 4.TD.1 timeIn(T , J ) ≡ ∃S stateAt( J , T , S).TD.2 T = startTime( J ) ≡timeIn(T , J ) ∧ [∀T 1 timeIn(T 1, J ) ⇒ T (cid:2) T 1].TD.3 history( J ) ≡∃T 1∀T 2 timeIn(T 2, J ) ⇒ T 2 < T 1.TD.4 T = endTime(H) ≡timeIn(T , H) ∧ [∀T 1 timeIn(T 1, J ) ⇒ T 1 (cid:2) T ].TD.5 unbounded( J ) ≡ uhistory( J ) ∧ ¬history( J ).TD.6 S = start( J ) ≡ stateAt( J ,startTime( J ),S).TD.7 S = end(H) ≡ history(H) ∧ stateAt(H,endTime(H),S).TD.8 stateOf(S, J ) ≡ ∃T stateAt( J , T , S).TD.10 throughout( J , Q ) ≡ ∀S stateOf(S, J ) ⇒ holds(S, Q ).4.4. SpaceThe ontology we use for space is Euclidean geometry ((cid:24)3). The spatial language is constructed entirely ad hoc. That is,Table 8 enumerates the sorts and the predicates that we use in the physical axioms of Section 4.6 and in the problemstatement of Section 4.9; it does not attempt any systematic discussion of geometric reasoning. We give here the formaldefinition of the predicates “openBox”, “partlyAbove” and “altogetherAbove” but otherwise do not list any geometric axiomsor definitions, which are all standard. In our formal proof, we will cite standard or easily proved geometric theorems asneeded.The large number of geometric sorts that we use here may startle readers who are used to more ontologically pure the-ories such as [3], in which the only geometric sort allowed is the sort of well-behaved, fully dimensional regions. However,it turns out that, strictly speaking, the greater ontological profligacy here is illusory. As I have shown in [9], if you have afirst-order language that allows quantification over regions, then even if you restrict the language to the single predicate“closer( X, Y , Z )”, meaning “region X is closer to Y than to Z ” and you restrict the universe of entities to include only simplepolygons, nonetheless all of these ontological categories and the whole range of standard geometric concepts can be definedas first-order constructions in this language.E. Davis / Artificial Intelligence 175 (2011) 299–345325Table 6Temporal theory: More definitions.TD.11 throughoutxSE( J , Q ) ≡∀T timeIn(T , J ) ∧ stateAt( J , T , S) ∧ startTime( J ) < T ∧[unbounded( J ) ∨ T < endTime( J )] ⇒holds(S, Q ).TD.12 historySlice( J A, J B) ≡∀T timeIn(T , J A) ⇒[timeIn(T , J B) ∧ ∀S stateAt( J A, T , S) ⇔ stateAt( J B, T , S)].TD.13 hSlice( J , T 1, T 2, H) ≡historySlice(H, T ) ∧ startTime(H) = T 1 ∧ endTime(H) = T 2.TD.14 historyPrefix( J A, J B) ≡historySlice( J A, J B) ∧ startTime( J A) = startTime( J B).TD.15 historyProperPrefix(H A, J B) ≡historyPrefix(H A, J B) ∧ [¬unbounded( J B) ⇒ endTime(H A) < endTime( J B)].TD.16 historySuffix( J A, J B) ≡historySlice( J A, J B) ∧[[unbounded( J A) ∧ unbounded( J B)] ∨ endTime( J A) = endTime( J B)].TD.17 hsplice(H1, J 2, J ) ⇔historySlice(H1, J ) ∧ historySlice( J 2, J ) ∧ startTime( J 2) = endTime(H1).TD.18 sameTime( J 1, J 2) ≡ ∀T [timeIn(T , J 1) ⇔ timeIn(T , J 2)].TD.19 singleHist(H, S) ≡ startTime(H) = endTime(H) ∧ S = start(H).Table 7Temporal theory: Proper axioms.T.1 timeIn(T , J ) ⇒ ∃1S stateAt( J , T , S).(A history J has only one state S at a given time T .)T.2 ∀T , J timeIn(T , J ) ⇔startTime( J )(cid:2) T ∧ [unbounded( J ) ∨ T (cid:2)endTime( J )].(A history J has a state for every time T between its start time and end time.An unbounded uhistory has a state for every time after its start time.)T.3 ∀S,T ∃H singleHist(H, S) ∧ startTime(H) = T .(One can construct an instantaneous history corresponding to any state S.)T.4 ∀ J ,T 1,T 2 timeIn(T 1, J ) ∧ timeIn(T 2, J ) ∧ T 1 (cid:2) T 2 ⇒∃H historySlice(H, J ) ∧ startTime(H) = T 1∧ endTime(H) = T 2.(One can slice history J at any times T 1, T 2 within the scope of J ).T.5 ∀H1,H2 end(H1) = start(H2) ∧ endTime(H1) = startTime(H2) ⇒∃H hsplice(H1, H2, H).(Any two histories that meet properly can be spliced together.)Because of the large number of geometric sorts, we are less systematic about the use of initial letters to indicate sort ofvariables. In most cases, variables of sort “region” start with R; points start with P ; pointSets start with P S; rigid mappingsstart with M; distances start with D (the ambiguity with durations should not cause problems); coordinate systems startwith C ; other geometric variables start with G.A coordinate system is a standard three-dimensional orthogonal right-handed coordinate system. We assume a fixed unitof length for all coordinate systems. Different coordinate systems may differ in orientation and in the choice of origin.A region is a spatial region that could be the shape of a physical object. We posit that a region is topologically regular(i.e. equal to the closure of its interior), bounded, and connected.A rigid mapping is a positive, orthonormal mapping of three-dimensional space to itself; that is, the composition of arotation and a translation. (Reflections are not allowed.)The other geometric sorts are self-explanatory.We use some of the RCC [30] topological relations between regions. However, since our vocabulary of symbols is solarge, we preface the name with “rcc”. Thus, the predicate “rccC(R1, R2)” is the relation usually designated “C(R1, R2)” inthe qualitative spatial reasoning literature; namely, regions R1 and R2 are connected. Similarly “rccEC(R1, R2)” is the QSRrelation EC(R1, R2), R1 and R2 are externally connected; “rccDC(R1, R2)” is the QSR relation DC(R1, R2), R1 and R2 aredisconnected; “rccDR(R1, R2)” is the QSR relation DR(R1, R2), R1 and R2 are disjoint (either disconnected or externallyconnected); and “rccO(R1, R2)” is the QSR relation O(R1, R2), R1 and R2 overlap. The RCC relations are only applied toregions, not to other point sets.The function “mappingImage(M, G)” denotes the image of G under rigid mapping M. The sort of mappingImage(M, G) isthe same as the sort of G (in other words, all our geometric sorts are closed under rigid mappings).The predicate “diameter( P S, X )” means that X is the diameter of point set P S; that is, the least upper bound ondistance( P 1, P 2) where P 1, P 2 are points in P S. If P S is unbounded, then this does not hold for any X .The predicate “altogetherAbove( P S1, P S2)” means that every point in P S1 is above some point in P S2; and no point inP S2 is above any point in P S1 (Table 9).The predicate “partlyAbove( P S1, P S2)” means that some point in P S1 is above some point in P S1.326E. Davis / Artificial Intelligence 175 (2011) 299–345Table 8Spatial sorts and symbols.Sorts:distance (D) = real.angle = real.geomEntity (G).Any geometric entity. This is a supersort of all the sorts enumerated below.point (P ). Subsort of element.pointSet (P S). Any set of points. Subsort of set.vector.coordinateSystem.region (R). Subsort of pointSet.rigidMapping (M).Symbols:rccC(R1, R2: region).rccEC(R1, R2: region).rccDC(R1, R2: region).rccDR(R1, R2: region).rccO(R1, R2: region).mappingImage(M: rigidMapping, G: geomEntity) → geomEntity.The image of G under M.boundary(R: region) → pointSet. The boundary surface of R (R-interior(R)).planar(P S: pointSet). P S lies in a plane.openBox(R B, R I: region, P S: pointSet).R B is a box with inside R I and opening P S (Section 3.5).diameter(R: region) → distance.ˆz: vector. The absolute upward direction.zAxis(GC : coordinateSystem) → vector. The z axis of coordinate system GC .zCoor(P : point, GC : coordinateSystem) → real. The z-coordinate of P in GC .disk(P S: pointSet). P S is a two-dimensional solid disk.convexHull(P S: pointSet) → pointSet.pointAbove(P 1, P 2: point). P 1 is vertically above P 2.partlyAbove(P S1, P S2: pointSet).altogetherAbove(P S1, P S2: pointSet).height(P : point) → distance.top(R: region) → distance. D is the maximum value of height(P ) for P ∈ R.bottom(R: region) → distance. D is the minimum value of height(P ) for P ∈ R.xyProj(P S: pointSet) → pointSet.cuboid(R: region, L, D, H: distance).verticalTilt(M1, M2: rigidMapping) → real.cos(R: real) → real.sin(R: real) → real.Table 9A few spatial definitions.Definitions:SD.1 openBox(R B, R I, P S) ≡rccEC(R B, R I) ∧ P S = boundary(R I) − boundary(R B) ∧ planar(P S)∧∃P S D P S D ⊂ P S ∧ disk(P S D).SD.2 partlyAbove(P S1, P S2) ≡∃P 1,P 2 pointIn(P 1, P S1) ∧ pointIn(P 2, P S2) ∧ pointAbove(P 1, P 2).SD.3 altogetherAbove(P S1, P S2) ≡¬partlyAbove(P S2, P S1) ∧ ∀P 1∈P S1 ∃P 2∈P S2 pointAbove(P 1, P 2).It is useful to posit a standard coordinate system, with a vertical z-axis. The function “height( P )” is the height of pointP in the standard coordinate system. The function “xyProj( P S)” is the projection of point set P S in the standard coordinatesystem. The predicate “cuboid(R, L, D, H )” means that region R is a cuboid with length L, depth D, and height H (L and Dneed not be aligned with the standard coordinate axes).The meanings of the remaining symbols in Table 8 are obvious. Functions and predicates defined over point sets areoverloaded to apply to individual points by coercing the point P to the point set {P }.The function “verticalTilt(M1, M2)” (used in axiom P1.17, Section 4.10) is the angle between the vertical direction−1ˆz and the direction M2(M1 (ˆz)). The significance is as follows: Suppose that Q V is a pseudo-object vector withsource O . Let M1 = value(S1, placement(O )) and let M2 = value(S2, placement(O )). If Q V points upward in S1, thenverticalTilt(M1, M2) is the co-latitude of Q V in S2 (that is, the angle between the direction of Q V in S2 and the verticalaxis).E. Davis / Artificial Intelligence 175 (2011) 299–345327Table 10Kinematics: Symbols.Sorts:object (O ).pseudo.gObject (Q ). Supersort of object and pseudo.objectSet (U ). Set of objects.Symbols:source(O : gObject) → object.shape(Q : gObject) → geomEntity.placement(Q : gObject) → fluent[rigidMapping].place(Q : gObject) → fluent[geomEntity].motionless( J : uhistory, O : object).fixed(O : object).mobile(O : object).objectsOf(S: state) → objectSet.objectsOf( J : uhistory) → objectSet.(For readability, we overload the function “objectsOf”.)kinematicState → fluent[Bool].kinematic( J : uhistory).empty(R: region) → fluent[Bool].mappingDistance(M1, M2: rigidMapping; P : point).Table 11Kinematics: Definitions.Definitions:KD.1 value(S,place(Q )) = mappingImage(value(S,placement(Q )),shape(Q )).KD.2 motionless( J , O ) ≡∀S stateOf(S, J ) ⇒ value(S1,placement(O )) = value(start( J ),placement(O )).KD.3 mobile(O ) ≡ ¬fixed(O ).KD.4 holds(S,kinematicState) ⇔∀O 1,O 2∈objectsOf(S) holds(S,rccDR#(↑ O 1, ↑ O 2)).KD.5 kinematic( J ) ≡throughout( J ,kinematicState) ∧ ∀O ∈objectsOf( J ) fixed(O ) ⇒ motionless(H, O ).KD.6 holds(S,empty(R)) ⇔ ∀O ∈objectsOf(S) holds(S,rccDR#(↑ O , R)).KD.7 mappingDistance(M1, M2, P ) = distance(mappingImage(M1, P ),mappingImage(M2, P )).4.5. Kinematic theory of objects in motionWe can now formulate the kinematic theory of rigid objects in motion (Tables 10–12). We introduce three new sorts.An object is a rigid solid object. We assume that all objects are disjoint; we do not allow one object to be part of another.A pseudo-object [6] is a geometric entity that “moves around” with an object, such as the center of mass of an object, thehole of a donut, the apex of a cone, and so on. The source of pseudo-object Q is the object to which Q is “attached”.A generalized object (gObject) is a supersort that includes both objects and pseudo-objects.We characterize an object O and its associated pseudo-objects in terms of an arbitrary standard position. The shape of Ois the region that it occupies in its standard position. The shape of pseudo-object Q is the geometric entity that instantiatesQ when O is in its standard position.Any two possible positions of a rigid object O are related by a rigid mapping; that is, a combination of a translationand a rotation. For any object O and state S, we define the placement of O in S, denoted value(S,placement(O )), as therigid mapping from the standard position to the position in S. The sort of placement(O ) is thus fluent[rigidMapping].The region occupied by O in state S is the image of shape(O ) under the mapping value(S,placement(O )); this is denotedvalue(S,place(O )) (definition KD.1). The same holds for pseudo-objects; for any state S and pseudo-object Q , the place ofQ in S is the image under a rigid mapping of the shape( Q ). By constraining this rigid mapping to be the placement in S ofthe source of Q (axiom K.2), we enforce the condition that the pseudo-object “moves together” with the associated object.Since the function place(O ) is used so frequently in our theory, we abbreviate it using the symbol ↑ O . For example,the formula, “holds(S,rccEC#(↑ O 1, ↑ O 2))” is an abbreviation for “holds(S,rccEC#(place(O 1), place(O 2)))”, meaning thatO 1 and O 2 are externally connected in state S. Also, by convention, we extend any geometric predicate Φ to objects andpseudo-objects by defining Φ(Q 1 . . . Q k) = Φ(shape( Q 1) . . . shape( Q k)). For instance, if O is an object, then “cuboid(O )” isequivalent to “cuboid(shape(O ))”.A state S is kinematic if no two objects occupy overlapping regions in S. A history H is kinematic if all states in H arekinematic and all fixed objects are motionless. We do not posit that all histories are kinematic, because for some purposesit is useful to contemplate hypothetical histories that are not kinematic. For instance, the easiest way to define an impactbetween two objects is to assert that, if the objects continued with the same velocities, they would interpenetrate; and theeasiest way to express that contrary-to-fact conditional is in terms of a hypothetical, non-kinematic history in which the328E. Davis / Artificial Intelligence 175 (2011) 299–345Table 12Kinematic theory: Axioms.Axioms:K.1 object(O ) ⇒ source(O ) = O .K.2 ∀Q placement(Q ) = placement(source(Q )).K.3 object(O ) ⇒ region(shape(O )).K.4 stateAt( J , T , S) ⇒ objectsOf( J ) = objectsOf(S).K.5 ∀D E:distance,P :point, J ,O ,T 1,S1O ∈ objectsOf( J )∧ stateAt( J , T 1, S1) ∧ 0 < D E ⇒∃D D:duration 0 < D D ∧∀T 2,S2 T 1 − D D < T 2 < T 1 + D D ∧ stateAt( J , T 2, S2) ⇒mappingDistance(value(S1,placement(O )),< D E.value(S2,placement(O )),P )(Every object O moves continuously in every history J . This is the usual (cid:13) − δdefinition of continuity. D E is (cid:13), D D is δ.)Table 13Axioms of grasping.Symbols:freeGrasp → fluent[Bool].grasping(O : object) → fluent[Bool].Definition:GD.1 holds(S,freeGrasp) ⇔ ¬∃O holds(S,grasping(O )).Axioms:G.1 holds(S,grasping(O 1)) ∧ holds(S,grasping(O 2)) ⇒ O 1 = O 2.(The agent grasps at most one object at a time.)G.2 holds(S, grasping(O )) ⇒ O ∈ objectsOf(S).two objects do continue with the same velocity and do interpenetrate. (In Lemma 2.13 of our formal proof, we actually douse such hypothetical histories to simplify the proof.)We do posit (axiom K.5 below) that objects move continuously in every history; we have not found any use for discon-tinuous histories.4.6. Physical theoryWe now turn to the physical theory, which is new in this paper. (The previous theories are not.) Here we axiomatizesome of the properties of dynamic histories; that is, histories that obey the laws of the dynamics of solid objects. However,unlike kinematic histories, we do not give necessary and sufficient conditions for a history to be dynamic.We divide this section into four parts: The theory of grasping (Section 4.6.1), general characteristics of dynamic histo-ries (Section 4.6.2), the theory of stable heaps (Section 4.6.3), and the default rule prohibiting anomalous upward motion(Section 4.6.4).4.6.1. GraspingAs described in Section 3.1, we use a very rudimentary theory of grasping in this paper (Table 13). The agent can graspone object at a time, or may not be grasping anything.It will be convenient, for technical reasons, to assume that any state of grasping takes place over an open time interval.This can be related to a more realistic theory of manipulators if we define “grasping” to mean that the manipulators areexerting a positive force on the object; if the force is a continuous function of time, then it will be greater than zero overan open time interval.15 However, though this definition works well in straightforward cases, it may break down in morecomplicated cases; for instance if the agent tries to ungrasp an object when it is not otherwise stably supported. In suchcases, the idealization that there is a simple Boolean fluent “grasping” does not apply.4.6.2. Dynamic historiesIn this section we describe some general axioms that govern dynamic histories. We introduce the predicate “dynamic( J )”meaning that history J obeys the laws of the dynamic theories of rigid solid objects (Tables 14, 15). We do not attemptto characterize necessary and sufficient conditions for this, but merely state those axioms that we will use in our examplehere.15 Extending this idea, an alternative approach to axiomatizing grasping would be to posit a continuous real-valued fluent “graspForce( O )”, the graspingforce that the agent exerts on object O , and to define “grasping( O )” as holding in states where graspForce(O ) > 0. This would simplify the theory in somerespects and complicate it in others; it is not clear whether overall it would be a gain.E. Davis / Artificial Intelligence 175 (2011) 299–345329Table 14Dynamics: Symbols.Symbols:dynamic( J : uhistory).isolated(U H, U S: objectSet) → fluent[Bool].sameStateOn(S1, S2: state, U : objectSet).sameStateExcept(S1, S2: state, U : objectSet).sameHistoryOn( J 1, J 2: uhistory, U : objectSet).sameMotionOn( J 1, J 2: uhistory, U : objectSet, D: duration).sameUntilEnd(H1, H2: history).coherentGrasping( J 1, J 2: uhistory). See definition DYD.7 and axiom DYN.9.freeMotion(O : object) → fluent[Bool].movingThroughout(O : object, H: history).parallelMotion(O 1, O 2: object, H: history).Following our discussion in Section 3.6, we define the fluent “isolated(U H, U S)”. In state S, a collection of objects U H isisolated from all objects except U S if no object in U H is in contact with any object outside of U H ∪ U S. This fluent enablesus to posit that a collection of objects is free from interference from other objects without needing to impose draconianclosed-world assumptions that demand that such other objects do not exist. This boundary condition is important both inthe verification of our plan and in the statement of physical axioms.Another useful concept is that of two states S1 and S2 being the same on the set of objects U ; in our theory, this holdsif the positions of every object in U is the same in S1 as in S2 and object O in U is being grasped in S1 if and only if itis being grasped in S2. The concepts of two states being the same except on the objects in U , or of two histories being thesame on the objects in U are defined analogously.Axioms DYN.1 and DYN.2 of Table 16 both state that new states or histories can be constructed from old ones byvarious kinds of modifications. Axioms DYN.3–DYN.8 discuss how a dynamic histories can be constructed and modified.Note that not all the modification operators that apply to histories in general, or even to kinematic histories, apply todynamic histories. For instance the projection of a history H onto a subset of its objects is a history H1 (axiom DYN.2) andif H is kinematic then trivially H1 is kinematic, but it is not the case that if H is dynamic then H1 is dynamic. For instance,H may have mobile object o1 supported on fixed object o2; if you project onto just o1, then o1 is floating in mid-air.However, DYN.7 gives sufficient conditions under which the projection of a dynamic history is itself dynamic: if the objectsU S are all fixed or grasped throughout H , and the objects U M are isolated except for U S, then the projection of H ontothe object set U M ∪ U S is dynamic.DYN.8 is a converse, of a sort, to DYN.7. It states that ifJ 1 and J 2 are dynamic histories which are consistent in thesense that no objects in J 1 overlaps any object in J 2 at any time, that any objects in common between the two are placedin the same place, and if the agent is grasping O 1 in J 1, then he is not at the same time grasping O 2 in J 2, then onecan “play” J 1 and J 2 “side by side” and the combined history is itself dynamic. One might wonder whether the constraintthat no two objects overlap is not too weak; should we not have to require that no two objects from J 1 and J 2 come intocontact? After all, two solid objects do not have to collide to affect one another’s behavior, they merely have to come intocontact. The answer is this: Suppose that O 1 follows a trajectory in J 1 that comes into contact but does not overlap thetrajectory of object O 2 in J 2. Then the forces on O 1 from the objects in J 1 are sufficient to account for its trajectory, andlikewise for O 2, so there need not be any normal force between O 1 and O 2 (except possibly in the end state of J , but thathas no consequences in J ). If there is no normal force, then there is no frictive force either.Axioms DYN.10–DYN.13 (Table 17) characterize the agent’s ability to choose to grasp and ungrasp. In this representation,the feasibility of an action is expressed as the existence of a dynamic history in which the action is carried out. This isanalogous to branching models of time, such as the situation calculus, in which the feasibility of action A in situation S isexpressed as the existence of a successor state S1 such that A transforms S into S1. In dealing with continuous time, thereare generally two cases to be considered; first, the continuance or beginning of an action at a given time, following someprevious history; and, second, the continuance or beginning of an action immediately after a given state. Axioms DYN.10–DYN.13 describe these two options for grasping and ungrasping. Axiom DYN.10 states that at the end of any dynamic history,the agent can always choose to free his grasp. This is expressed by the rule that if H is a dynamic history, then there existsanother dynamic history H1 which is identical to H except that, in end(H1), the agent releases whatever he was holdingin end(H ). Axiom DYN.11 states that if the agent has been grasping O throughout H up until the end, he can continue tograsp O at the end. Axiom DYN.12 states that if the agent’s grasp is free in S then he can continue not to grasp anythingthroughout some history starting in H . Axiom DYN.13 states that if the agent’s grasp is free in S or if he is grasping O in S,then he can grasp O in some history starting immediately after S.In a similar way, DYN.14 gives a sufficient condition for the feasibility of manipulating an object O along a given tra-jectory H K : If history H K is kinematically possible, and all the objects in H K either move parallel to object O or aremotionless, then at least an initial segment of the motion of O in H K is dynamically possible; that is, there exists a dynam-ically possible history H2 starting in start(H K ) in which O follows the same motion as in H K . In the box example, supposethat S is the state when all the cargo is loaded, and H K is a trajectory of carrying the box along a specified path. ThenH K would be the history in which the objects inside the box keep a fixed position relative to the box and all other objects330E. Davis / Artificial Intelligence 175 (2011) 299–345Table 15Dynamics: Definitions.Definitions:DYD.1 holds(S,isolated(U H, U S)) ⇔U H ∩ U S = ∅ ∧∀O H∈U H,O S∈objectsOf(S) holds(S, rccC#(↑ O H, ↑ O S)) ⇒ O S ∈ U S ∪ U H.DYD.2 sameStateOn(S1, S2, U ) ≡U ⊂objectsOf(S1) ∧ U ⊂objectsOf(S2) ∧[∀O ∈U value(S1,placement(O )) = value(S2,placement(O )) ∧[holds(S1,grasping(O )) ⇔ holds(S2,grasping(O ))]].DYD.3 sameStateExcept(S1, S2, U ) ≡objectsOf(S1)−U = objectsOf(S2)−U ∧ sameStateOn(S1, S2,objectsOf(S1)−U ).DYD.4 sameHistoryOn( J 1, J 2, U ) ≡sameTime( J 1, J 2) ∧[∀T ,S1,S2 stateAt( J 1, T , S1) ∧ stateAt( J 2, T , S2) ⇒ sameStateOn(S1, S2, U )].DYD.5 sameMotionOn( J 1, J 2, U , D) ≡U ⊂objectsOf( J 1) ∩ objectsOf( J 2) ∧∀T ,S1,S2,O stateAt( J 1, T + D, S1) ∧ stateAt( J 2, T , S2) ∧ O ∈ U ⇒value(S1,placement(O )) = value(S2,placement(O )).(The objects in U have the same motion in J 2 as in J 1 with time shift D, though not necessarily the same grasping relations.)DYD.6 sameUntilEnd(H1, H2) ≡sameTime(H1, H2) ∧∀T ,S T < endTime(H1) ∧ stateAt(H1, T , S) ⇒ stateAt(H2, T , S).DYD.7 coherentGrasping( J 1, J 2) ≡∀O 1,O 2,T ,S1,S2 stateAt( J 1, T , S1) ∧ stateAt( J 1, T , S2) ∧holds(S1,grasping(O 1)) ∧ holding(S2,grasping(O 2)) ⇒ O 1 = O 2.( J 1 and J 2 do not place conflicting conditions on what the agent is grasping ata given time. Condition of axiom DYN.9.)DYD.8 holds(S,freeMotion(O )) ⇔O ∈objectsOf(S) ∧ mobile(O ) ∧ ¬holds(S,grasping(O )).DYD.9 parallelMotion(O 1, O 2, H) ≡∀S stateOf(S, H) ⇒∃M:rigidMapping value(S,placement(O 1)) =mappingImage(M,value(start(H),placement(O 1))) ∧value(S,placement(O 2)) =mappingImage(M,value(start(H),placement(O 2))).Table 16Basic properties of dynamics: Axioms (beginning).Axioms:DYN.1 ∀S,O ,M ∃S2 sameStateExcept(S, S2, O ) ∧M = value(S2, placement(O )).(One can change the placement of object O in state S to M and construct a new state S2. S2 is notnecessarily kinematically possible, but it is ontologically possible.)DYN.2 U ⊂objectsOf(H) ⇒∃H1 objectsOf(H1) = U ∧ sameHistoryOn(H1, H, U ).(One can project a history H onto a subset U of its objects, getting a history H1.)DYN.3 ∀S,H kinematic(S) ∧ singleHist(H, S) ⇒ dynamic(H).(A history H consisting of a single kinematic state S is dynamic.)DYN.4 ∀H dynamic(H) ⇒ ∃ J unbounded( J ) ∧ dynamic( J ) ∧ historyPrefix(H, J ).(Any dynamic history H can be extended to an unbounded dynamic history J .)DYN.5 dynamic( J ) ∧ historySlice( J 1, J ) ⇒ dynamic( J 1).(Any temporal slice of a dynamic history is dynamic.)DYN.6 dynamic(H1) ∧ dynamic( J 2) ∧ hsplice(H1, J 2, J ) ⇒ dynamic( J ).(If H1 and J 2 are dynamic and can be spliced together to form J , then J is dynamic.This excludes any kind of hysteresis.)DYN.7 [dynamic( J ) ∧ throughout( J ,isolated(U M, U S)) ∧[∀O ∈U S throughout( J ,¬#freeMotion(O ))] ∧objectsOf( J 1) = U M ∪ U S ∧ sameHistoryOn( J , J 1, U M ∪ U S)] ⇒dynamic( J 1).(Discussed in text.)DYN.8 [dynamic( J 1) ∧ dynamic( J 2) ∧objectsOf( J ) = objectsOf( J 1) ∪ objectsOf( J 2) ∧sameHistoryOn( J , J 1,objectsOf( J 1)) ∧ sameHistoryOn( J , J 2,objectsOf( J 2)) ∧kinematic( J ) ∧ coherentGrasping( J 1, J 2)] ⇒dynamic( J ).(Discussed in text.)DYN.9 dynamic( J ) ⇒ kinematic( J ).(A dynamic history is kinematic.)E. Davis / Artificial Intelligence 175 (2011) 299–345331Table 17Basic properties of dynamics: Axioms (continued).DYN.10 history(H) ∧ dynamic(H) ⇒∃H1 dynamic(H1) ∧ sameUntilEnd(H, H1) ∧ holds(end(H1),freeGrasp).DYN.11 dynamic(H) ∧ history(H) ∧ throughoutxSE(H,grasping(O )) ⇒∃H1 ¯dynamic(H1) ∧ sameUntilEnd(H, H1) ∧ holds(end(H1),grasping(O )).DYN.12 holds(S,kinematicState) ∧ holds(S,freeGrasp) ⇒∃H dynamic(H) ∧ S = start(H)∧ startTime(H) < endTime(H) ∧throughout(H,freeGrasp).DYN.13 holds(S,kinematicState) ∧ [holds(S,grasping(O )) ∨ holds(S,freeGrasp)] ⇒∃H dynamic(H) ∧ S=start(H) ∧ startTime(H) < endTime(H) ∧throughoutxSE(H,grasping(O )).DYN.14 [kinematic(H K ) ∧ holds(start(H K ),grasping(O )) ∧[∀O 1∈objectsOf(H) parallelMotion(O 1, O , H K ) ∨ motionless(O 1, H K )]] ⇒∃H2 startTime(H K ) = startTime(H2) < endTime(H2) ∧ start(H2) = start(H K )∧sameMotionOn(H2, H K , {O }, 0) ∧ throughoutxSE(H2,grasping(O )) ∧dynamic(H2).(These are all discussed in the text.)remain motionless. Clearly this is kinematically possible, given the condition COND.6. Axiom DYN.14 thus asserts that it isdynamically possible to carry the box along at least an initial segment of the specified trajectory, though the actual behaviorof the objects may not be that of H K . The objects in the box may settle, or other objects may move, for reasons of theirown.4.6.3. Heaps and stabilityWe next address the issue of heaps and stable heaps (Table 18). Again, the discussion here is preliminary; it is adequateto the problem of carrying cargo in boxes, but a considerably richer and more powerful theory would be required to analyzethe problem of carrying cargo piled in heaps on trays.A heap is defined (definition HD.3) as in Section 3.6. As with dynamic histories, we do not give necessary and sufficientconditions for a collection of objects to be in a stable heaps; we just posit some of the axioms that are needed for theinference we are concerned with. A state is stable if every freely moving object is part of a stable heap supported by fixedand grasped objects.Axiom H.1 asserts that a stable heap is a heap. Axiom H.2 asserts that if U H is a stable heap supported by U S whichremains motionless, and is isolated from all other objects then U H likewise remains motionless and remains a stable heap.Axiom H.3 asserts that if a set of objects is isolated and no object is moved by the agent, then eventually the set attains astable state. Axiom H.4 asserts that if U H is a stable heap on U S in state S1, and in S2 the objects in U H and U S are in thesame positions as in S1 and U H is isolated from everything except U S in S2, then U H is a stable heap with supports U Sin S2. (That is, the positions of other objects that are not in contact with U H do not affect whether U H is stable.) AxiomHD.5, HD.6, and H.5 encode the default rule used to infer that the box does not fall over during loading (Section 3.3.6):If object O B is stably supported by motionless object O T , and the objects in set U C are always above the convex hull ofthe contact points of O B with O T , and {O B} ∪ U C are isolated from everything except O T , then by default O B remainsmotionless. Specifically, axiom HD.5 defines a history in which this default rule is violated as exhibiting anomaly 2. AxiomHD.6 defines a history H as satisfying the property “noAnomaly2” if no slice of H exhibits anomaly 2. Default rule H.5 statesthat dynamic histories by default satisfy the “noAnomaly2” property.4.6.4. No upward motionThe final category of physical rules is the default rule that prevents the cargo from coming out of the top of the box.This follows our formulation in Section 3.7. Object O undergoes an upward motion with respect to object set U S in H if, forevery object O 1 in U S and for every coordinate system Q C that can be “attached” to O 1 at any time in H , the z-coordinateof the center of mass of O relative to Q C is higher at the end of H than at the beginning of H . An upward motion of Oin H relative to U S is anomalous if O is part of a heap U H supported by U S at the start of H and U H is isolated fromeverything except U S during H . A history H has no anomalous upward motions if none of the objects in H have anomalousupward motions in any temporal slice of H . By default, a dynamic history has no anomalous upward motions.4.7. Comprehension axioms for historiesWe will need to reason that, if the agent is grasping an object, then he can move it along any “well-behaved” trajec-tory consistent with the laws of physics. The dynamic axioms DYN.1 through DYN.14, especially DYN.12, enumerate someconditions that are sufficient for a history to be physically possible. What we need additionally are axioms that assert thatall these histories exist; specifically, that for any “well-behaved” (to be defined below) mathematical function from time tomappings, there exists a history in which object O follows that function. Such axioms are comprehension axioms for his-tories. There are two, not very different, ways to state these; either using first-order axiom schemas or using higher-orderlogic. There are subtle differences between the expressive power of these two, but nothing that affects our inferences here.In this paper, I will use first-order schemas to simplify the notational and sortal issues involved.332E. Davis / Artificial Intelligence 175 (2011) 299–345Table 18Heaps and stability: Symbols and definitions.Symbols:connectedGroup(U : objectSet) → fluent[Bool].allFree(U : objectSet) → fluent[Bool].heap(U H, U S: objectSet) → fluent[Bool].stableHeap(U H, U S: objectSet) → fluent[Bool].stable(U : objectSet) → fluent[Bool].anomaly2(H: history).noAnomaly2(H: history).Definitions:HD.1 holds(S,connectedGroup(U )) ⇔U ⊂objectsOf(S) ∧∀U 1,U 2 U 1 (cid:2)= ∅ ∧ U 2 (cid:2)= ∅ ∧ U 1 ∪ U 2 = U ⇒∃O 1∈U 1,O 2∈U 2 holds(S,rccC#(↑ O 1, ↑ O 2)).(A set of objects U is a connected group in state S if it cannot be divided into two spatially separated subsets U 1 and U 2).HD.2 holds(S,allFree(U )) ≡ ∀O ∈U holds(S,freeMotion(O )).HD.3 holds(S,heap(U H, U S)) ⇔holds(S,connectedGroup(U H) ∧# allFree(U H)) ∧U S ⊂objectsOf(S) ∧ U S ∩ U H = ∅ ∧[∀O H∈U H,O S∈objectsOf(S) holds(S, rccC#(O H, O S)) ⇒ O S ∈ U H ∪ U S] ∧[∀O S∈U S ∃O H∈U H holds(S,rccC#(↑ O S, ↑ O H))].(Definition of a heap, as in Section 3.6.)HD.4 holds(S,stable(U )) ⇔∀O ∈U holds(S,freeMotion(O )) ⇒∃U H,U S⊂U O ∈ U H ∧ holds(S,stableHeap(U H, U S)) ∧∀O S∈U S ¬holds(S,freeMotion(O S)).(A set of objects U is stable in state S if every mobile object in U is part of a stable heap supported by fixed or grasped objects.)HD.5 anomaly2(H) ≡∃U C,O B,O T ,S2dynamic(H) ∧ throughout(H,isolated(U C ∪ {O B}, O T ) ∧# freeMotion(O B)) ∧sameStateOn(start(H),S2,{O B, O T }) ∧ holds(S2,stableHeap({O B}, {O T })) ∧[∀O ∈U C throughout(H,above#(↑ O , convexHull#(↑ O T ∩∗ ↑ O B)))] ∧throughout(H,motionless(O T )) ∧ ¬throughout(H,motionless(O B)).HD.6 noAnomaly2(H) ≡ ¬∃H1 historySlice(H1, H) ∧ anomaly2(H1).Table 19Heaps and stability: Axioms.Axioms: (These are discussed in the text.)H.1 holds(S,stableHeap(U H, U S)) ⇒ holds(S,heap(U H, U S)) ∧ U S (cid:2)= ∅.H.2 [dynamic( J ) ∧ holds(start( J ),stableHeap(U H, U S)) ∧throughout( J ,isolated(U H, U S)) ∧ ∀O ∈U S motionless( J , O )] ⇒∀O ∈U H motionless( J , O ) ∧ throughout( J ,stableHeap(U H, U S)).H.3 [dynamic( J ) ∧ unbounded( J ) ∧throughout( J ,isolated(U M, U F ) ∧# allFree(U M)) ∧[∀O ∈U F motionless( J , O )]] ⇒∃ J 1 historySuffix( J 1, J ) ∧ throughout( J 1,stable(U F ∪ U M)).H.4 holds(S1,stableHeap(U H, U F )) ∧ sameStateOn(S1, S2, U H ∪ U F ) ∧holds(S2,isolated(U H, U F )) ⇒holds(S2,stableHeap(U H, U F )).Reiterian Default Rule:H.5 dynamic( J ) : noAnomaly2( J ) / noAnomaly2( J ).Table 20Center of mass.Symbol: centerOfMass(O ) → pseudo.Axioms:CM.1 ∀O :object point(shape(centerOfMass(O )).CM.2 ∀O :object shape(centerOfMass(O )) ∈ convexHull(shape(O )).The more serious question is what class of mathematical functions should be considered well-behaved. Note that this is,in general, a superset of the histories that are physically possible i.e. that satisfy dynamic(H ). Rather, these are the historiesthat are, so to speak, conceptually possible. Therefore, the decision here is mostly a matter of the convenience of the theorydeveloper.E. Davis / Artificial Intelligence 175 (2011) 299–345333Table 21Default rule excluding anomalous upward motion.Symbols:upwardMotion(O object, U S: objectSet, H: history).anomalousUpwardMotion(O : object, H: history).noAnomUpwardMotion(H: history).Definitions:UD.1 upwardMotion(O , U S, H) ≡∀O S∈U S,Q C,S M [source(Q C) = O S ∧ coordinateSystem(Q C ) ∧ stateOf(S M, H) ∧value(S M,zAxis#(↑ Q C)) = ˆz] ⇒value(end(H),zCoor#(↑centerOfMass(O ),↑ Q C )) >value(start(H),zCoor#(centerOfMass(↑ O ),↑ Q C )).UD.2 anomalousUpwardMotion(O , H) ≡∃U H,U S O ∈ U H ∧ holds(start(H),heap(U H, U S)) ∧throughout(H,isolated(U H, U S) ∧# allFree(U H)) ∧ upwardMotion(O , U S, H).UD.3 noAnomUpwardMotion(H) ≡∀O ∈objects(H),H1 historySlice(H1, H) ⇒ ¬anomalousUpwardMotion(O , H1).Reiterian Default Rule:UP.1 dynamic(H) : noAnomUpwardMotion(H) / noAnomUpwardMotion(H).There are two major constraints on the class of histories that we wish to enforce. The first, already discussed, is that wewill require all histories to be continuous. The second, more subtle, can be stated in the following principle:HCP.1 Let h1, h2, h3 . . . be an infinite sequence of histories, such that hi is a proper prefix of hi+1 for all i. Then there existsa uhistory j∞ which is an extension of all the hi .The force of this principle is most clearly illustrated in terms of an example that violates it. Suppose that for each k, hkis the history such that startTime(hk) = −1, endTime(hk) = −1/k, and for all T between startTime(hk) and endTime(hk), theplacement of O at time T in hk is a translation by distance sin(1/T ) in the ˆx direction. Then each hk is a prefix of hk+1, butthere does not exist a j∞ that subsumes them all, because the position of O does not converge to a limit at T = 0.To avoid this, we require that histories satisfy a Lipschitz condition that, between times T A and T B, no point in anyobject moves a distance greater than maxSpeed·|T B − T A|, where maxSpeed is a constant. It is easily shown that ifh1, h2 . . . satisfy the Lipschitz condition and hi is a prefix of hi+1, then the limit history j∞ exists and also satisfies theLipschitz condition.We chose to use this particular Lipschitz condition for reasons of simplicity. In the long run, imposing an attainableupper bound on speed could be problematic for a Newtonian theory; obviously it is not consistent with either Galilean orEinsteinian relativity or with the solution to some collision problems. There are many other possible condition that could beimposed instead for the same purpose. Keep in mind that there is no harm in imposing a very weak condition on histories,as long as it is sufficient to guarantee HCP.1.The real reason that we need principle HCP.1 is to justify the conclusion (Lemma 1.5 of our formal proof) that it isalways possible to attempt to carry out any given plan and to work on it until either it fails, it succeeds, or it cannot becontinued. If we allow histories like those in our counter-example above, then the plan of moving an object along the pathf (t) = sin(1/T )ˆx can be begun over the interval [−1, −1/T ] for every T < 0 but not over the interval [−1, 0]; it is difficultto define a semantics of planning in a way that accommodates this.As stated above, HCP.1 involves quantifying over infinite sequences of histories. Rather than do that, we use axiomschema HC.3 below. Let Ψ (H) be a property of histories H , and let H0 be a history satisfying Ψ . (Ψ may have associatedsome parameters X ; in this case, each valuation on X determines a property of H .) Let Γ ( J 1) be the property, “ J 1 isJ 1 that extends H0 satisfies Φ”. Then there exists a uhistory J M that isan extension of H0 and every proper prefix ofmaximal with respect to Γ ; that is, Γ holds on J M but not on any proper extension of J M.Axiom schema HC.3 is approximately equivalent to principle HCP.1 in the following sense. On the one hand, HCP.1 plusthe axiom of choice entails HC.3. Proof: Let us write h A < h B if H0 is a prefix of h A , h A is a proper prefix of h B , and Γ (h B );clearly this is a partial ordering. By Zorn’s lemma, there exists a maximal set of histories that is linearly ordered under <.Let H be some such maximal totally ordered set. If the end times of the histories in H are bounded above, let T Z be the(cid:9)K be any history in H whose end time is greater than T Z − 1/K and let h Kleast upper bound of these end times; let h(cid:9)be the prefix of hK be(cid:9)any history with end time greater than K , and let h K be the prefix of hK with end time equal to K . In either case, it isimmediate that h K < h K +1 so by HCP.1 there exists some j∞ that extends all the h K . If T Z is bounded, then the prefix ofj∞ that ends at T Z satisfies the conclusion of HC.3; if not, then j∞ itself satisfies the conclusion of HC.3.(cid:9)K ending at time T Z − 1/K . If the end times of the histories in H are not bounded above, let hConversely, HC.3 implies HCP.1, as long as h K can be defined in terms of a first-order formula in H and K ; the proof isimmediate.Axiom HC.2 asserts that any system of motions satisfying the Lipschitz condition constitutes a history. Here Ψ (O , T , M)is a first-order formula that defines a mapping from object O and time T to rigid mapping M. Axiom HC.2 states that if, for334E. Davis / Artificial Intelligence 175 (2011) 299–345Table 22Comprehension axioms on histories: Symbols and definitions.Symbols:maxSpeed → real.mapDist(M1, M2: rigidMapping, O : object) → distance.Definitions:HCD.1 mapDist(M1, M2, O ) = D ⇔[∃P ∈shape(O ) mappingDistance(M1, M2, P ) = D] ∧[∀P ∈shape(O ) mappingDistance(M1, M2, P ) (cid:2) D].HCD.2 Let Ψ (O : object, T : time, M: rigidMapping, X) be a formula.Then LipschitzΨ (O , X, T S, T E) is defined to be the following formula:∀T 1,T 2:time,M1,M2:rigidMappingT S (cid:2) T 1 (cid:2) T 2 (cid:2) T E ∧ Ψ (O , T 1, M1, X) ∧ Ψ (O , T 2, M2, X) ⇒mapDist(M1, M2, O ) (cid:2) maxSpeed · (T 2 − T 1).HCD.3 Let Φ(H: history, X) be a formula.AllPPsΦ (H, X) is defined to be the formula:∀H1 historyProperPrefix(H1, H) ⇒ Φ(H1, X).T (cid:2) T S and O ∈ U , Ψ defines a function from O and T to M that satisfies the Lipschitz condition, then there is a uhistoryJ that corresponds to Ψ ; that is startTime( J ) = T S, objectsOf( J ) = U , and for every object O ∈ U and time T (cid:2) T S theplacement of O at time T in H is the value that satisfies Ψ (O , T , H).Axioms HC.1 and HC.2 give necessary and sufficient conditions for a system of object motions to constitute a history. Forthis domain, this is an almost complete characterization of the class of histories. A complete characterization would involveadditionally:• Necessary and sufficient conditions for the evolution of grasping relations over time.• A uniqueness axiom stating that any two histories with the same time interval, the same objects, the same motions,and the same grasping relations are in fact the same history.• A comprehension axiom on states, positing that any placement of a set of objects constitutes a state.If we were to posit such a set of necessary and sufficient conditions, then quite a few of our axioms would in fact beconsequences of these conditions, specifically T.1—T.5, K.4, K.5, G.1—G.2, DYN.1, DYN.2 and HC.3. We have not taken thisapproach for reasons of elaboration tolerance. Axioms like these are applicable to a wide range of temporal and physicaltheories; by contrast, the proposed necessary and sufficient conditions on histories apply only to the partial theory of rigidsolid objects that we consider in this paper (Tables 20–22).Finally, the comprehension axiom HC.4 is a variant of HC.3. HC.3 states that there is always a maximal history over atopologically closed history J M that extends H and satisfies the condition “Φ holds over all proper prefixes of J M”. HC.4states, in effect, that there is a maximal history either over a closed interval, or over an interval that is open on the right,that extends H and satisfies the condition “Φ holds over all closed prefixes (not necessarily proper) ofJ M”. Since ourontology does not include histories over open time intervals, the statement of this is somewhat indirect. The point of thisis to deal with time structures which branch at the end point of an interval. If the agent is attempting to keep a fluent like“grasping(O )” true, and, following an open history there is one end point that keeps grasping(O ) true and one that makesit false, — i.e. the agent can choose to ungrasp(O ) at the end of H — we need to deduce that the agent can choose the onethat keeps it true, and can continue to keep it true through the continuum of such choices that must be made.The formal statement of these axioms proceeds as follows. First, let define the distance between rigid mappings M1 andM2 relative to object O , mapDist(M1, M2, O ) as the maximum over all points P in shape(O ) of the distance from M1(P )to M2(P ) (definition HCD.1).Assume that for any given object O and parameter value X , Ψ implicitly defines a function Ψ (cid:9)Let Ψ (O : object, T : time, M: rigidMapping, X1 . . . Xk) be any open formula with free variables O , T , M, and optionaladditional free variables X1 . . . Xk of any sort. For simplicity we will write the arguments X1 . . . Xk as a single argument X .O , X (T ) be from time T toO , X (T ). The formula LipschitzΨ (O , X, T S, T E) asserts that, for a givenO , X (T ) satisfies the Lipschitz condition that for anya rigid mapping M. that is, Ψ (O , T , M, X) ⇔ M = Ψ (cid:9)value of O and X , throughout the time interval T S, T E, the function Ψ (cid:9)point P in shape(O ), the distance from [Ψ (cid:9)O , X (T 2)](P ) is at most maxSpeed · |T 2 − T 1|.O , X (T 1)](P ) to [Ψ (cid:9)The definition of the Lipschitz condition is given in definition HCD.2. Note that this includes the condition that Ψ definesa single-valued mapping (consider the case where T 2 = T 1). Axioms HC.1, HC.2, HC.3 can now be stated as in Table 23.4.8. Executing plansSince our objective is to validate plan1, we next need to define what it means for a plan to be a correct solution toa problem. That is, we need to define a semantics of plans. As our plans are partially specified and our model of time iscontinuous, this is not entirely an established theory.E. Davis / Artificial Intelligence 175 (2011) 299–345335Table 23Comprehension axioms on histories.Axioms:HC.1 ∀O ,H,T 1,T 2,S1,S2 T 1 (cid:2) T 2 ∧ stateAt(H, T 1, S1) ∧ stateAt(H, T 2, S2) ⇒mapDist(value(S1,placement(O )), value(S2,placement(O )), O ) (cid:2)maxSpeed · (T 2 − T 1).Axiom HC.1 asserts that the Lipschitz condition holds on the formula,“∃S stateAt(H, T , S) ∧ M = value(S, placement(O ))”.HC.2 Let Ψ and LipschitzΨ be as in HCD.2. Assume that the variables U , T S, and J do not appear free in Ψ .Then the following formula is an axiom:∀U :objectSet,T S:time, X[∀O ∈U ,T E:time T S < T E ⇒ LipschitzΨ (O , X, T S, T E)] ⇒∃ J :uhistory startTime( J ) = T S∧ unbounded( J ) ∧ objectsOf( J ) = U ∧∀T ,S,M stateAt( J , T , S) ∧ Ψ (O , T , M, X) ⇒ value(S, placement(O )) = M.HC.3 Let Φ(H: history, X) be an open formula with a free variable H of sort history and optionally other freevariables X. Assume that variables J M and H1 are not free in Φ. Then the following is an axiom:∀H, X AllPPsΦ (H, X) ⇒∃ J M historyPrefix(H, J M) ∧ AllPPsΦ ( J M, X) ∧∀H1 historyProperPrefix( J M, H1) ⇒ ¬AllPPsΦ (H1, X).HC.4 Let Φ(H: history, X) be as in HC.3. Then the following is an axiom:∀H, X AllPPsΦ (H, X) ⇒∃ J M historyPrefix(H, J M) ∧ AllPPsΦ ( J M, X) ∧[¬∃ J 1 sameUntilEnd( J 1, J M) ∧ Φ( J 1)] ∨[Φ( J M) ∧∀H1 historyProperPrefix( J M, H1) ⇒ ¬AllPPsΦ (H1, X) ]].We will develop our theory top–down. A standard definition of the semantics of a partial plan is that the plan P correctlyachieves a task T starting in state S if the following holds: for all H , if H is a history starting in S, and the agent attemptsto execute P in H , then he succeeds in executing P in H and the execution of P constitutes a successful accomplishmentof T . (This definition does not address the issues of knowledge preconditions or knowledge acquisition.)What is meant by a successful execution of plan P in H is generally quite apparent from the form of P ; representationalsystems for partial plans usually directly characterize a successful execution. What is meant by an attempt to execute P isoften less obvious. For a TWEAK-style partial plan [4], for instance, we can define “attempts” as follows: a beginning of anexecution of plan P is an execution of the first k steps of the plan under some ordering and variable binding consistentwith the constraints. P is attempted in H if P is begun in H and cannot be continued, either because P is complete, orbecause there are no next steps whose preconditions are met.16The first thought is to define an attempt to execute P as the initial segment of a complete execution of P ; but underthat definition of “attempt”, the above definition of “correctness” become vacuous. Rather, we have to go in the oppositedirection. We view the form of the plan as specifying what it means to “attempt” the plan, and as specifying when such anattempt constitutes a successful execution of the plan. Additionally, as mentioned above, the fact that we are dealing withreal-valued time means that more care has to be taken than in similar theories over discrete time.We proceed, then, as follows: The semantics of a plan P is specified in terms of four primitive predicates. The predicate“worksOn( P , H )” states that H constitute a partial or complete execution of P . The predicate “beginnable( P , S)” states thatit is possible to initiate execution of P in S. The predicate “completion( P , H )” states that H constitutes a complete executionof P .For example, consider the plan, pHardBoil = “Hard-boil egg egg1”. The formula “beginnable(pHardBoil,S1)” is trueif in S1 there is a pot P O T 1 with water on a burner B1 of the stove. The formula “completion(pHardBoil,H )” is true ifthe sequence “put egg1 into P O T 1; turn the knob controlling B1; wait 12 minutes” is completely executed in H ; and theformula “worksOn(pHardBoil,H )” is true if some initial segment of that sequence is executed in H .The relations “attempts( P , J )” and “completes( P , H )” are defined in terms of the above three predicates. To simplify theprocess of plan definition, we require that our definitions of “attempts” and “completes” be coherent and well-behaved forany definition of “worksOn”, “beginnable”, and “completion”, whether or not these satisfy any particular logical or temporalrelations. For instance, intuitively one might think that if worksOn( P , H ) holds, then worksOn( P , H1) should hold for any16 This is actually weaker (more inclusive) than Chapman’s semantics, because it requires only that at each there is some step in the plan whose pre-decessors have been executed and whose preconditions are met. By contrast, Chapman’s semantics require that the preconditions are satisfied for everystep whose predecessors have been executed. To achieve Chapman’s semantics, it is necessary to define the beginning of the execution of a plan as thecombination of the execution of some of the steps together with the choice of a next step to execute, among steps all of whose predecessors have beenexecuted. Chapman’s definition is computationally more tractable; it is verifiable in polynomial time, whereas verifying our definition is NP-hard.336E. Davis / Artificial Intelligence 175 (2011) 299–345initial segment of H1; or that if P is not beginnable in S then “worksOn( P , H )” should not hold over any history H thatstarts in S. However, we do not impose either of these conditions, or indeed any constraints whatever on these three baserelations. Indeed, we could consistently specify a comprehension axiom, analogous to axiom P.2 of [8], which states thatthere exists a plan for any definition of these three predicates; we have not done that here because it is somewhat complexand we do not here need such an axiom. Achieving this in a theory of real-valued time requires a little care.The predicate “attempts( P , J )” and some of the other predicates we will define, takes as argument a possibly unboundeduhistory J to deal with the case that the plan P goes into an infinite loop.We posit a constant positive duration “reactionTime”, which is the time required for the agent to “realize” thatthe completion criterion “completion( P , H )” has been met. Of course, this is often realistic, but that is not the actualreason that we are including this feature in our theory. (The small increase in realism would not be worth the complexityand inelegance.) Rather the point of including this is to deal coherently with cases where “completion( P , H )” holds overan interval of time that is open on the left (or more generally where it holds on a set of time points that does notcontain its lower boundary). For instance, if the predicate “completion( P , H )” is defined as “the center of mass of O ismore than 1 foot higher than the table”, then there is no first time at which the predicate becomes true, so it would notbe consistent to specify that the agent stops working on the plan as soon as the completion condition holds. Therefore,we define the predicate “reactComplete( P , H )” (the agent can achieve the completion criterion of P and react to it) asholding if H finishes at a time which is reactionTime greater than the greatest lower bound on the times at which“completion( P , H )” becomes true (PLD.1). Note it is possible that “completion( P , H )” will no longer be true by the time that“reactComplete( P , H )” becomes true, but that is not a problem; in such a case, “completes( P , H )” still holds (Tables 24, 25).The imposition of a constant time delay on the completion of a plan has two further advantages in terms of achievinga coherent semantics. First, it eliminates the problem of defining “sequence( P 1, P 2)” where P 1 completes instantaneously;second, it eliminates the problems of loops that execute infinitely many iterations in finite time. The disadvantage of this isthat we must now define “worksOn( P , H )” in such a way that the agent works on P for the duration reactionTime afterP has met the completion criterion; if worksOn is not so defined, then “completes( P , H )” will not be achieved.Our definitions now continue as follows: The predicate “baseExec( P , H )” (H is a strictly partial execution of P )holds if H is dynamic and worksOn( P , H ) (PLD.2). The predicate “incompleteExec( P , H )” holds if baseExec( P , H ) but notreactComplete( P , H ) (PLD.3).We need to define “attempt” in such a way that the agent continues to work on P as long as possible. There are twocases to be addressed here, corresponding to the two topologies of the right-hand side of a time interval. First, if the agenthas been working on P over a closed time interval, and it is possible for him to continue working on P , then he does so.Second, if he has been working on P over an time interval that is open on the right, and it is possible for him to continueworking on P over the closure of that interval, then he does so.Thus, we define the following predicates. The predicate “beginsxE( P , H )” meaning “ P begins over H except possibly atits end” holds if P is beginnable at the start of J and incompleteExec( P , H1) holds over every proper prefix H1 of J (PLD.4).The predicate “begins( P , H )” holds if baseExec( P , H ) holds as well (PLD.5).A plan P is continuable at the end of H written “continuableEnd( P , H )” if beginsxE( P , H ) and it would be possible tocontinue working on P at the last moment of H (PLD.6). A plan P is continuable after H , written continuable( P , H, Q ) if itbegins over some extension of H satisfying Q (PLD.7).Plan P is attempted over H subject to isolation condition Q , (a) P is not beginnable at the start of H , and H consistsof that single state; or (b) beginxE( P , H ) but P cannot be continued at the end of H ; or (c) P begins over H but is notcontinuable past H (PLD.8). P completes over H if P is attempted over H and reactComplete( P , H ) (PLD.9).Thus, if P completes over H , then P is beginnable at start(H ); worksOn( P , H1) holds over every initial segment H1 ofH ; and completion( P , H1) holds over the initial segment H1 that ends a time reactionTime before the end of H .A problem is a specification of a starting state, a success criterion, and an isolation condition. Plan P is a correct solutionof problem R if the following holds: If H is a dynamic history starting in S satisfying the isolation condition, and P isattempted in H , then P is completed in H and H satisfies the success condition of R. For instance in our egg boilingexample, we might posit that H satisfies the success conditions of the problem boilEgg if egg1 is hard-boiled at the endof H , and that it satisfies the isolation condition of H if no other object interferes with the burner knob, the pot, or the eggduring H .There is, however, a difficulty integrating our default rules with this definition of “correct solution”. The default rules H.5and UP.1 above support the following inference: if history h1 starts in state s1, plan1 is attempted in h1, and h1 satisfiesthe isolation conditions, then plan1 will be completed in h1 and h1 will satisfy the success condition of problem1.However, Reiterian default theory does not permit us to carry out universal abstraction and conclude that this conditionholds for all histories H satisfying these conditions. Nor should it, at least in this instance. As we discussed in Section 3.3.5,it is not generally reasonable to assert that there is no history satisfying these conditions in which catapulting does notoccur, since, with many sets of cargo objects, the agent can actually carry out the plan in such a way that catapultingoccurs, if he so chooses. What we really want to say is that plan1 is a “generally correct” solution for problem1, meaningthat most histories H that satisfy start(H) = start(problem1), isolationCondition(problem1,H ) and attempts(plan1,H )also satisfy completes(plan1,H ) and succeeds(problem1,H ). This is an object-level relation between problems and plans(given some fixed probability distribution over histories) which is quite distinct from the default inference given above.E. Davis / Artificial Intelligence 175 (2011) 299–345337Table 24Plan semantics: Sorts and symbols.Sorts:plan.problem.Symbols:reactionTime → duration.worksOn(P : plan, H: history).beginnable(P : plan S: state).completion(P : plan, H: history).reactComplete(P : plan, H: history).baseExec(P : plan, H: history).beginsxE(P : plan, H: uhistory).begins(P : plan,continuableEnd(P : plan, H:uhistory).continuable(P : plan,attempts(P : plan,J : uhistory).completes(P : plan, H: history).startProblem(R: problem) → state.isolationCondition(R: problem,succeeds(R: problem, H: history).J : uhistory).J : uhistory).J : uhistory).Table 25Plan semantics.Definitions:PLD.1 reactComplete(P , H) ≡∀D D <reactionTime ⇒∃T C,H C T C <endTime(H)−D ∧ hSlice(H,startTime(H),T C ,H C ) ∧PLD.2 baseExec(P , H) ≡completion(P , H C ).dynamic(H) ∧ beginnable(P ,start(H)) ∧ worksOn(P , H).PLD.3 incompleteExec(P , H) ≡ baseExec(P , H) ∧ ¬reactComplete(P , H).PLD.4 beginsxE(P , H) ≡beginnable(P ,start(H)) ∧ dynamic(H) ∧∀H1 historyProperPrefix(H1, H) ⇒ incompleteExec(P , H1).PLD.5 begins(P , H) ≡ beginsxE(P , H) ∧ baseExec(P , H).PLD.6 continuableEnd(P , H) ≡∃H1 sameUntilEnd(H1, H) ∧ begins(P , H1).PLD.7 continuable(P , H) ≡∃H1 historyProperPrefix(H, H1) ∧ begins(P , H1).PLD.8 attempts(P , J ) ≡[¬beginnable(P ,start( J )) ∧ singleHist( J ,start( J ))] ∨[beginsxE(P , J ) ∧ ¬continuableEnd(P , J )] ∨[begins(P , J ) ∧ ¬continuable(P , J )].PLD.9 completes(P , H) ≡ attempts(P , H) ∧ reactComplete(P , H).Axiom:PL.1 0 < reactionTime.However, developing the requisite theory of measures of sets of histories is beyond the scope of this paper. We hope toreturn to this issue in future work, perhaps using a probabilistic logic along the lines of Bacchus [2].It should be also noted that our treatment of isolation conditions is not actually quite what is wanted. The problemis that, in the above definition, a plan P vacuously satisfies the conditions for being a “correct” solution to a problemif P specifies that the agent should himself deliberately violate the isolation conditions. Or, even more cleverly, P couldspecify that if something goes wrong, then the agent should deliberately violate the isolation conditions. I have not foundany adequate solution to this, and it may indeed be the case that, in the final analysis, boundary conditions for planningproblems must be stated in terms of constraints on the starting state and not of constraints on the history. (Providingisolation from the actions of other agents would then entail calling on some richer theory of multi-agent interactions.)However, this concern does not affect the analysis in this paper. It certainly does not affect the validity of using isolationconditions in physical axioms such as H.2, H.4, and UD.2; it is only relevant to the question of the relation of plans toproblems.4.8.1. Control structuresIn defining plan1, we use the standard programming language control structures “sequence” and “while”. The seman-tics of these operators is specified in our theory by axioms which state how the predicates “beginnable”, “worksOn”, and“completion” are defined for a complex plan in terms of its components. The axioms are given in Table 26, and are self-explanatory.338E. Davis / Artificial Intelligence 175 (2011) 299–345Table 26Semantics of plan control operators.Symbols:sequence(P 1 . . . P k: plan) → plan.if1(Q : fluent[Bool],P : plan) → plan. (Single-branch conditional).while(Q : fluent[Bool],P : plan) → plan.Axioms:CTL.1 beginnable(sequence(P 1, P 2),S) ⇔ beginnable(P 1, S).CTL.2 worksOn(sequence(P 1, P 2), J ) ⇔[worksOn(P 1, J ) ∧ ¬∃H historyProperPrefix(H, J ) ∧ completes(P 1, H)]∨∃H1, J 2 hsplice(H1, J 2, H) ∧ completes(P 1, H1) ∧ worksOn(P 2, J 2).CTL.3 completion(sequence(P 1, P 2),H) ⇔∃H1,H2 hsplice(H1, H2, H) ∧ completes(P 1, H1) ∧ completion(P 2, H2).CTL.4 beginnable(if1(Q , P ),S) ⇔¬holds(S, Q ) ∨ beginnable(P , S).CTL.5 worksOn(if1(Q , P ),H) ⇔[holds(start(H),Q ) ∧ worksOn(P , H)] ∨[¬holds(start(H),Q ) ∧ throughout(H,freeGrasp)].(Note: the condition throughout(H,freeGrasp) means simply that,if condition Q fails, the agent carries out a noop.)CTL.6 completion(if1(Q , P ),H) ⇔[holds(start(H),Q ) ∧ completion(P , H)] ∨[¬holds(start(H),Q ) ∧ endTime(H)=startTime(H)].CTL.7 sequence(P 1, P 2 . . . Pk) = sequence(P 1,sequence(P 2, . . . sequence(Pk−1, Pk) . . .)).CTL.8 while(Q , P ) = if1(Q ,sequence(P ,while(Q , P ))).Table 27Axioms for primitive actions.Symbols:move(O : object,H: history) → plan.waitUntil(Q : fluent[Bool]) → plan.Axioms:AC.1 beginnable(move(O , H),S) ⇔sameStateOn(S, start(H), {O })AC.2 worksOn(move(O , H T ),H) ⇔∃D D = startTime(H)-startTime(H T ) ∧ sameMotionOn(H, H T , {O }, D) ∧∀T ,S stateAt(H, T + D, S) ⇒[startTime(H T ) < T < endTime(H T ) ⇒ holds(S,grasping(O ))] ∧[T (cid:3) endTime(H T ) ⇒ holds(S,freeGrasp)].AC.3 completion(move(O , H T ),H) ⇔∃D D =startTime(H)−startTime(H T ) ∧ endTime(H T )+D (cid:2) endTime(H) ∧sameMotionOn(H, H T , {O }, D).AC.4 ∀Q ,S beginnable(waitUntil(Q ),S).AC.5 worksOn(waitUntil(Q ),H) ⇔ throughout(H,freeGrasp).AC.6 ∀H completion(waitUntil(Q ),H) ⇔ ∃T ,S stateAt(H, T , S) ∧ holds(S, Q ).4.8.2. Primitive action: move and waitThere are two primitive actions in our theory:• Move object O along the trajectory in history H . H is any history containing O ; all that is significant about H is thetrajectory that O follows in H .• Wait until Boolean fluent Q becomes true.Formally we consider these primitive actions to be of sort “plan”. Their semantics is therefore given in terms of thepredicates “beginnable”, “worksOn”, and “completion”. The axioms are given in Table 27; they are mostly self-explanatory,but a few require some discussion.Axiom AC.3 asserts that the completion condition for the action “Move O along trajectory H T ” is met in history H ifO executes the same motion in H as in H T subject to a time shift D and H continues at least as long as H T . However,our planning semantics requires that we define what it means to work on a plan for a time reactionTime after thecompletion condition is satisfied. (This is the disadvantage of positing a finite reaction time.) Axiom AC.2 reflects this. Inhistory H , O is moved along trajectory H T if (a) the motion of O is H is the same as its motion in H T up until eitherthe end time of H or the end time of H T , whichever comes first; (b) during the part of H up to the end time of H T , O isgrasped; (c) if H continues past the end time of H T , then the agent is not doing anything in this final segment.E. Davis / Artificial Intelligence 175 (2011) 299–345339Table 28Problem specification: Symbols.Symbols:oTable1, oTable2 → object.oBox → object.qInsideBox → pseudoObject.qTopBox → pseudoObject.rCuboid → region. Empty cuboid inside the box.lCube,wCube,hCube → distance.uCargo → objectSet.u1 → objectSet. The set of movable objects (cargo and box).s1 → state. Initial state.s2 → state. Hypothetical state with the box on Table 2.maxCargoDiam → distance. Maximum diameter of any cargo object.manipSpace1 → region. Free space above Table 1 for loading cargo into box.manipSpace2 → region.Free space from top of table 1 to top of Table 2 for carrying box.carryingPath → history. Possible trajectory of box from Table 1 to Table 2.loadingCount(D, L, W , H: distance) → integer.Conservative estimate of maximum number of cargo objects (see Section 3.3.2.)4.9. Problem specificationWe can now give the specification of our particular problem. There are, of course, many ways to formulate the problem.The choice of formulation involves a tradeoff between five desiderata: generality, that is, making the conditions as weakas possible; simplicity of the constraints; simplicity of the plan; standard form (e.g. describing regions in terms of specificgeometric constraints rather than in terms of the existence of a path); and ease of constructing the proof of correctness.(Ease of proof is a desideratum because we are not really interested here in clever or deep object-level proofs, just indemonstrating the adequacy of the representation.) The specific choices we have made are largely arbitrary; we have triedto include generalizations that we felt were interesting and exclude those that are merely difficult.The symbols (mostly constants) and axioms17 here are given in Tables 28, 29 and 30. The symbols are explained inTable 28 where necessary. Axioms PR.1–PR.7 characterize the objects: The set u1 includes the cargo and the box (PR.1), allof which are mobile (PR.2). PR.4 asserts that the box is box-shaped, and PR.3 defines the pseudo-objects associated with itsinside and its opening. The two tables are fixed (PR.5 and PR.6). The distance maxCargoDiam is the maximum diameterof the cargo objects (PR.7).Axioms PR.8 through PR.14 characterize the initial state s1. The state s1 is kinematic (PR.8). The box opens verticallyupward (PR.9). The inside of the box is empty (PR.10). Each cargo object constitutes a stable heap supported by oTable1(PR.11) and separated from every other cargo object (PR.12). No object in u1 is overhung by any other object in u1 or byoTable1 (PR.13). The inside of the box is altogether above the convex hull of the contact points between the box and thetable (PR.14); this is needed to make sure the box does not fall over (axiom H.4, Section 4.6.3).Axioms PR.15 through PR.19 define manipSpace1, the region used to load objects into the box. We have constructedthis definition so that each object can be lifted vertically, moved horizontally to a position over the inside of the box, andthen lowered vertically into the box; in this part of the constraints, we have given priority to stating the constraints insimple geometric terms and keeping the proof of correctness easy. The region manipSpace1 is defined as a region thatis at least as high as the top of the box plus the height of any of the cargo objects (PR.15, PR.16). The table is nowherehigher than the top of the box (PR.17). For each cargo object O , manipSpace1 includes the vertical prism whose x– ycross section is the convex hull of x– y projections of O and the box, and which extends vertically down from the topof manipSpace1 a distance which at least the height of O (PR.18). manipSpace1 also includes the region above everyobject O in u1 up to the plane at the top of manipSpace1 (PR.19).Axioms PR.20 through PR.23 enforce the constraint needed to guarantee that the cargo objects will fit in the box andwill not come out discussed in Sections 3.3.2 and 3.3.3. This puts an upper bound on the number of cargo objects as afunction of the size of the cargo objects and the size of the inside of the box.Axioms PR.24 through PR.27 characterize s2, a hypothetical state in which oBox sits on oTable2. (There is no need fors2 to contain any objects other than oBox and oTable2.) State s2 is kinematic (PR.24). oTable2 is in the same positionin s2 as in s1 (PR.25). In s2, the box sits stably on oTable2 (PR.26), the inside of the box is altogether above the table(PR.27), and, as in axiom PR.14, the inside of the box is altogether over the convex hull of the contact points between thebox and the table (PR.28). PR.27 is required in order to achieve our goal (PR.35) that all the cargo objects are altogetherabove the table.Axioms PR.29 through PR.31 characterize carryingPath, the trajectory of the box while being carried from oTable1to oTable2. (Here, by characterizing the space between these two boxes in terms of a trajectory rather than in absolute17 In the context of problem specification and plan specification, it is hard to distinguish between definitions and axioms, so we have lumped them all asaxioms.340E. Davis / Artificial Intelligence 175 (2011) 299–345Table 29Problem specification: Beginning.PR.1 u1 = uCargo ∪ { oBox }.PR.2 ∀O ∈u1 mobile(O ).PR.3 oBox = source(qInsideBox)=source(qTopBox).PR.4 openBox(oBox,qInsideBox,qTopBox).PR.5 fixed(oTable1).PR.6 fixed(oTable2).PR.7 ∀O ∈uCargo diameter(O ) (cid:2) maxCargoDiam.PR.8 holds(s1,kinematicState).PR.9 ∀P P ∈ value(s1,qTopBox) ⇒ height(P ) = value(s1,top#(↑qInsideBox)).PR.10 holds(s1,empty(qInsideBox)).PR.11 ∀O ∈u1 holds(s1,stableHeap({O }, { oTable1})).PR.12 ∀O 1,O 2∈u1 holds(s1,rccDC#(↑ O 1, ↑ O 2)).PR.13 ∀O 1∈u1∪{oTable1},O 2∈u1 ¬holds(s1,partlyAbove#(↑ O 1, ↑ O 2)).PR.14 holds(s1,altogetherAbove#(↑qInsideBox, convexHull#(↑oBox ∩# ↑oTable1))).PR.15 ∀O ∈uCargo value(s1,top#(↑ O ) −# bottom#(↑ O )) (cid:2) maxCargoHeight.PR.16 ∀O ∈uCargo value(s1,top#(↑oBox)) + maxCargoHeight < top(manipSpace1).PR.17 value(s1,top#(↑oTable1) (cid:2) value(s1,top#(↑oBox)).PR.18 ∀O ∈uCargo,P [xyProj(P ) ∈ value(s1,convexHull#(xyProj#(↑ O ∪ ↑ oBox))) ∧top(manipSpace1)−maxCargoHeight (cid:2) height(P ) (cid:2) top(manipSpace1) ] ⇒P ∈manipSpace1.PR.19 ∀O ∈u1,P ,P O holds(s1,P O ∈#↑ O ) ∧ pointAbove(P , P O ) ∧height(P ) (cid:2) top(manipSpace1) ⇒P ∈manipSpace1.Table 30Problem specification: Conclusion.PR.20 rCuboid ⊂ qInsideBox.PR.21 cuboid(rCuboid,lCube,wCube,hCube).PR.22 loadingCount(D, L, W , H) = (cid:5)L/2D(cid:6) · (cid:5)W /2D(cid:6) · (cid:5)H/2D(cid:6).PR.23 ∃N count(uCargo,N) ∧N (cid:2) loadingCount(maxCargoDiam,lCube,wCube,hCube).PR.24 holds(s2,kinematicState).PR.25 sameStateOn(s2,s1,{oTable2}).PR.26 holds(s2,stableHeap({oBox},{oTable2})).PR.27 holds(s2,altogetherAbove#(↑qInsideBox,↑oTable2)).PR.28 holds(s2,altogetherAbove#(↑qInsideBox, convexHull#(↑oBox ∩# ↑oTable2))).PR.29 sameStateOn(start(carryingPath), s1, {oBox}).PR.30 sameStateOn(end(carryingPath),s2,{oBox}).PR.31 ∀S stateOf(S,carryingPath) ⇒verticalTilt(valueIn(s1,placement(oBox)), valueIn(S,placement(oBox))) = 0.PR.32 throughout(carryingPath,(↑oBox ∪# ↑qInsideBox) ⊂# manipSpace2).PR.33 holds(S,isolFluent(problem1)) ≡[∀O :object holds(S,rccC#(↑ O ,manipSpace1 ∪ manipSpace2)) ⇒[O ∈ u1 ∨ O =oTable1 ∨ O =oTable2]]PR.34 isolationConditions(H,problem1) ≡ throughout(H,isolFluent(problem1)).PR.35 succeeds(problem1,H) ≡ ∀O ∈uCargo holds(S,altogetherAbove(O ,oTable2)).PR.36 startProblem(problem1) = s1.geometric terms, we have sacrificed stating constraints in normal form in favor of generality.) The trajectory carrying-Path starts with oBox in its position in s1 (PR.29) and ends with the oBox in its position in s2 (PR.30), and oBox isheld vertically upright throughout carryingPath (PR.31).As we shall see in Section 4.10, the actual execution of plan1 need not follow carryingPath and need not end withthe box at its position in s2. But the existence of this state and this trajectory guarantees the feasibility of the plan.Axiom PR.32 characterizes the region manipSpace2 as including the swathe swept out by the box and its inside whilemoving it along carryingPath.Finally, axioms PR.33 through PR.36 characterize the problem problem1. The isolation condition for problem1 isthat no object other than cargo objects, oBox, and the two tables come into contact with either manipSpace1 or ma-nipSpace2 during the execution of the plan. (PR.33, PR.34). PR.35 defines the goal of problem as achieving a state whereall the objects in u1 are altogether above oTable2, and where they are in a stable state on oTable2. PR.36 defines thestarting state of problem1 as s1.4.10. Specification of plan1Finally, we give the specifications of the plan. Our objective here is to define the plan as flexibly as possible. Thisflexibility has a number of advantages, depending on the application. For plan execution, it means that the fine details ofE. Davis / Artificial Intelligence 175 (2011) 299–345341Table 31Specification of plan1: Symbols.Symbols:plan1 → plan.loadedCargo → fluent[objectSet].unloadedCargo → fluent[objectSet].loadBox(U : fluent[objectSet], Q : pseudo, R: region) → plan.levelCount → integer.maxBottomHeight(N: integer) → distance.loadBoxCondition(O : object, H: history, U : fluent[objectSet], Q : pseudo, R: region,carryBox(O B: object, Q I, Q T : pseudo,S: state).U C : objectSet, O T : object, R: region) → plan.boxLoadingPos(O : object, Q I: pseudo) → fluent[Bool].goodBoxTrajectory(H: history, O B: object, Q I N, Q T : pseudo, U : objectSet).safeBoxTilt(S: state, Q I N, Q T : pseudo, O : object).carryBoxConditions(H: history, O B: object, Q I N, Q T : pseudo,U C : objectSet, R M: region, O S: object, S: state).moveTrajectory(H: history, O : object, U : objectSet, S: state, R M: region).freeAbove(O : object, R: region) → fluent[Bool].maxHeight(U ) → fluent[distance].bottom1(P S:pointSet, D:distance).the plan (the order in which to load the objects, the placement of the objects in the box, the trajectories to follow) can betailored to specific circumstances such as constraints on the way cargo objects should be packed, constraints on the way inwhich they should be moved, and limitations of the agent’s manipulators. For plan recognition, the broader the definitionof the plan, the more behaviors can be recognized as instances of the plan.Axiom P1.1 gives the high-level description of plan1; the agent loads unloaded objects one by one into the box, waitingafter each loading action until the objects have attained a stable state. The plan is composed of three basic actions:• loadBox(unloadedCargo,qInsideBox,manipSpace1) is the action of loading some unloaded cargo object intothe inside of the box, moving it through manipSpace1.• carryBox(oBox,qInsideBox,qTopBox,uCargo,oTable2,manipSpace2) is the action of carrying box oBoxwith inside qInsideBox and opening qTopBox and with uCargo inside to its final position on oTable2, mov-ing it through manipSpace2.• waitUntil(stable(u1 ∪ oTable1)) is the action of waiting until the cargo and the box have reattained a stable positionon oTable1. The semantics of “waitUntil” are defined in Section 4.8.2.Axioms P1.2 and P1.3 defines loadedCargo and unloadedCargo as the fluents whose value in any state is the setof cargo objects in the box/not in the box.Axioms P1.4–P1.13 define the semantics of “loadBox” as a partial specification of a “move” action. Axioms P1.10 throughP1.13 state that loadBox is executed (is beginnable/worked on/attains completion/attains failure) if in history H if an objectis moved along a trajectory H2 that satisfies the “load box conditions”. (There is no failure condition for “loadBox” for thesame reason that there is no failure condition for “move”; a loadBox action fails if it is physically impossible to continueit.) Axiom P1.9 states that the trajectory H2 meets the load box conditions if the cargo object being loaded ends in anappropriate “box loading position” and it satisfies the predicate “moveTrajectory”. Axioms P1.4–P1.7 defines “box loadingposition” as the constraint described in Section 3.3.2. (The wording of the condition in PL.6 is different, and in fact slightlyless restrictive, than the condition in Section 3.3.2, just because the condition here is easier to state in our first-ordertheory.) Axiom P1.8 defines “moveTrajectory(H, O , U AL S O , S, R M)” as the constraints that history H starts in S; that inhistory H , O remains with within the manipulation space R M, and that H is kinematically consistent with all the objectsoutside U AL S O remaining motionless. The set U AL S O is the set of objects that should be “brought along” by the move;specifically, the cargo objects while the box is being moved.Note that, although we specified the situation s1 so that there was room to load each cargo object by moving it upvertically, then horizontally, then down vertically, the plan does not require that the loading actually be carried out thatway.Similarly, axioms P1.14–P1.22 characterize “carryBox” as a partial specification of a move. Axioms P1.19–P1.22 state thatan execution of carryBox is an execution of a move that satisfies the “carry box conditions”. Axiom P1.18 defines “carryBox-Conditions” as the constraints that were placed on the final situation s2 in axioms PR.25–PR.29 plus the “moveBoxTrajectory”condition discussed above plus the condition from Section 3.3.3 that the box is never tilted too far from the vertical. Thislast condition on tilting is defined in axioms P1.16 and P1.17. Axioms P1.14 and P1.15 define the maximum and minimumheight of a set of objects (Tables 31–33).342E. Davis / Artificial Intelligence 175 (2011) 299–345Table 32Specification of plan1: Definition of loadBox.Axioms:P1.1 plan1 =sequence(while(unloadedCargo (cid:2)=# ∅,sequence(loadBox(unloadedCargo,qInsideBox,manipSpace1),waitUntil(stable(u1 ∪ {oTable1}))))carryBox(oBox,qInsideBox,qTopBox,uCargo,oTable2,manipSpace2)).P1.2 O ∈value(S,loadedCargo) ⇔ O ∈uCargo ∧ holds(S,↑ O ⊂#↑qInsideBox).P1.3 O ∈value(S,unloadedCargo) ⇔ O ∈uCargo ∧ ¬holds(S,↑ O ⊂#↑qInsideBox).P1.4 holds(S,freeAbove(O , R)) ⇔¬∃O 1∈objectsOf(S) O 1 (cid:2)= O ∧ holds(S,partlyAbove#(↑ O 1, ↑ O )) ∧holds(S,rccO#(↑ O 1, R)).P1.5 levelCount = (cid:5)lCube/ 2* maxCargoDiam(cid:6) * (cid:5)wCube/ 2* maxCargoDiam(cid:6).P1.6 maxBottomHeight(N) = 2 · maxCargoDiam * (cid:5)N/levelCount(cid:6).P1.7 holds(S,boxLoadingPos(O , Q I)) ⇔holds(S,kinematic) ∧ holds(S,freeAbove(O ,manipSpace1)) ∧ holds(S,↑ O ⊂#↑ Q I) ∧[∃O 1∈u1 holds(S, rccEC#(↑ O 1, ↑ O ))] ∧∀N count(value(S,loadedCargo),N) ⇒holds(S,height#(↑ centerOfMass(O )) (cid:2)#bottom#(rCuboid) +# maxBottomHeight#(N) +# maxCargoDiam).P1.8 moveTrajectory(H, O , U AL S O , S, R M) ⇔S = start(H) ∧ throughout(H,↑ O ⊂# R M) ∧∀O 1∈objectsOf(H) O 1 /∈ {O } ∪ U AL S O ⇒motionless(H, O 1) ∧ throughoutxSE(H, rccDC#(O , O 1)).P1.9 loadBoxConditions(O , H, U , Q I, R M, S) ⇔O ∈value(S, U ) ∧ holds(end(H),boxLoadingPos(O , Q I)) ∧moveTrajectory(H, O , ∅, S, R M).P1.10 beginnable(loadBox(U , Q I, R M),S) ⇔∃O ,H loadBoxConditions(O , H, U , Q I, R M, S).P1.11 worksOn(loadBox(U , Q I, R M),H) ⇔∃O ,H2 loadBoxConditions(O , H2, U , Q I, R M,start(H)) ∧worksOn(move(O , H2),H).P1.12 completion(loadBox(U , Q I, R M),H) ⇔∃O ,H2 loadBoxConditions(O , H2, U , Q I, R M,start(H)) ∧completion(move(O , H2),H).P1.13 ¬failure(loadBox(U , Q I, R M),H).Table 33Specification of plan1: Definition of carryBox.P1.14 ∀U :objectSet,S:stateP1.15 bottom1(R, D) ≡[∀O ∈U ,P holds(S,P ∈#↑ O ) ⇒ height(P ) (cid:2) value(S,maxHeight(U ))] ∧[∃O ∈U ,P holds(S, P ∈↑ O ) ∧ height(P ) = value(S,maxHeight(U ))].[∀P ∈R height(P ) (cid:3) D] ∧ [∃P ∈R height(P ) = D].P1.16 goodBoxTrajectory(H, O B, Q I N, Q T O P , U C A R G O ) ≡∀O ∈U C A R G O ,S,P H I stateOf(S, H) ∧P H I = verticalTilt(value(start(H), placement(O B)), value(S,placement(O B))) ⇒safeBoxTilt(P H I,start(H),Q I N, Q T O P , O ).P1.17 ∀D1 holds(S, bottom1#(↑ Q T O P , D1)) ⇒[safeBoxTilt(P H I, S1, Q I N, Q T O P , O ) ⇔0 (cid:2) P H I < π /2 ∧(D1-value(S, height#(↑centerOfMass(O )))·cos(P H I) >diameter(O ) + diameter(value(S, xyProj#(↑ Q T O P ∪ ↑ Q I N)))·sin(P H I)].P1.18 carryBoxConditions(H, O B, Q I N, Q T O P , U C A R G O , R M, O S2, S) ⇔holds(S,freeSpace(value(end(H),↑ O B))) ∧holds(end(H),altogetherAbove(↑ Q I N, ↑ O S2)) ∧holds(end(H),altogetherAbove#(↑ Q I N, convexHull#(↑ O B∩# ↑ O S2))) ∧moveTrajectory(H, O , U C A R G O , S, R M) ∧goodBoxTrajectory(H, O B, Q I N, Q T O P , U C A R G O ).P1.19 beginnable(carryBox(O B, Q I N, Q T O P , U C A R G O , O S2, R M),S) ⇔∃H carryBoxConditions(H, O B, Q I N, Q T O P , U C A R G O , R M, O S2, S).P1.20 worksOn(carryBox(O B, Q I N, Q T O P , U C A R G O , O S2, R M),H) ⇔∃H2 carryBoxConditions(H2, O B, Q I N, Q T O P , U C A R G O , O S2, R M,start(H))∧ worksOn(move(O B, H2),H).P1.21 completion(carryBox(O B, Q I N, Q T O P , U C A R G O , O S2, R M),H) ⇔∃H2 carryBoxConditions(H2, O B, Q I N, Q T O P , U C A R G O , O S2, R M,start(H))∧ completion(move(O B, H2),H).P1.22 ¬failure(carryBox(O B, Q I N, Q T O P , U C A R G O , O S2, R M),H).E. Davis / Artificial Intelligence 175 (2011) 299–3453435. Sketch of proofWe now can prove the following result: Given all the above, and given that for uhistory j1,J1.1 start(j1) = startProblem(problem1) = s1.J1.2 isolationCondition(problem1,j1)J1.3 attempts(plan1,j1)one can infer by default that completes(plan1,j1) and succeeds(problem1,j1).A fully detailed account of the proof is given in the online appendix http://cs.nyu.edu/faculty/davise/box-proof.pdf. Theoverall structure of the plan is a straightforward projection, though the details involve a lot of definition hunting, and a fairamount of the kind of fiddly argumentation characteristic of the analysis of continuous functions over real-valued time.To analyze the loading loop, we use the following loop invariant: The cargo objects outside the box and the box itself arein the same position as in s1. The cargo objects inside the box are in a stable position, and satisfy the following packingconstraint: Let K be the number of cargo objects in the box, let H be the greatest height of the center of mass of any cargoobject in the box, and let maxCargoDiam, lCube and wCube be as defined in axioms PR.7 and PR.21. Then(cid:6)K (cid:2)lCube2 · maxCargoDiamwCube2 · maxCargoDiamH2 · maxCargoDiam(cid:7)(cid:6)·(cid:7)(cid:6)·(cid:7).The main steps of the proof are as follows:• The loop invariant holds in s1.• Given the above loop invariant, at the beginning of each iteration, there will exist a loading action that satisfies the boxloading constraint.• Any move that satisfies the box loading constraint will execute successfully, and that when it is finished the new objectwill be inside the box and the above packing condition will hold.• After a loading action is complete and the object being loaded is released, the cargo will settle into a new stableposition with the box remaining fixed, and the cargo objects all remaining inside the box.• Once the cargo has settled into a stable condition, the loop invariant is satisfied.• The loading loop terminates because the number of unloaded cargo objects decreases on each iteration.• At the completion of the loading loop, there exists a move that satisfies the box carrying constraint.• If a move satisfies the box carrying constraint, then it can be executed successfully, and will result in a state thatsatisfies the goals of the problem. In particular, the cargo objects do not come out of the box while it is being carried.It may be noted that we have been careful to avoid the use of default rules until the very last step of the proof. The lastlemma preceding the final theoremLemma:start( J ) = s1 ∧ attempts(plan1, J )∧throughout( J , isolFluent) ∧ noAnomaly2( J ) ∧ noAnomUpwardMotion( J ) ⇒completes(plan1, J ) ∧ succeeds(problem1, J )has been proved using purely first-order logic. Therefore, this lemma has been validly proved even if some problem ariseswith the default rules.6. ConclusionAmong all these trees, it is easy to lose sight of the forest. What we have accomplished is this: We have developed atheory that is capable of justifying a commonsensically obvious inference about using boxes to carry cargo. The inferencerequires only qualitative constraints about the shapes and physical characteristics of the objects involved. The theory isdesigned to be elaboration tolerant and consistent with Newtonian physics; it contains no features that get in the wayof extending it to cover both other commonsense inferences in the domain and precise calculations based on Newtonianmechanics. As discussed in the introduction, our formulation of the physical laws used in this inference entirely avoids theanalysis of forces, and almost entirely avoids the use of axioms that use differential time (the only exceptions are axiomsK.5 and DYN.12).The theory, the boundary conditions that define the problem, and the representation of the plan, are certainly morecomplicated than one would at first have supposed necessary for such an obvious inference in such a simple domain. Buton careful consideration, it seems clear that a commonsense understanding of the domain and of this inference involvesall, or nearly all, of the sorts that we have defined, and is aware of all, or nearly all, of the potential “bugs” that we haveenumerated in Section 3.3. Therefore it seems reasonable to say that the complexity of our theory is mostly a reflection ofthe complexity of the domain and the sophistication of a commonsense understanding, and only in small part an artifact ofthe awkwardness of fitting this kind of commonsense reasoning to the limitations of deductive inference in first-order logic.344E. Davis / Artificial Intelligence 175 (2011) 299–345Certainly, the theory here is much more numerically precise than an actual commonsense understanding; no one wouldclaim that any actual commonsense reasoner thinks about conditions PR.23 and PR.24 or knows that these conditions aresufficient to ensure that the box can be loaded without fear of overflowing. But a commonsense understanding is aware ofsomething quite similar: namely, that if care is taken to load the box from bottom up, the space will be used reasonablyefficiently; and that, if objects are small and not too numerous, a reasonably efficient packing of the box will succeed infitting them all inside the box. Moreover, the commonsense understander has a “feel” for how small the objects shouldbe, how few they should be, and how much care needs to be taken in packing them. The precise numerical constraintsPR.23, PR.24 here are the closest we have been able to come to representing the knowledge that constitutes this “feel”.The numerical constraints are not, I would argue, as far from the “feel” as it might seem at first; and they are certainly nofurther than what can be expressed in any other notation that I know of. Despite the scorn that is often heaped on the veryidea that symbolic representations could be acceptable cognitive models for spatial knowledge,18 no other representationalsystem, especially “diagrammatic” representations, comes anything like as close to capturing the critical cognitive ability torepresent and reason about qualitative spatial and physical information.Establishing the consistency of this large and complex theory, even aside from the default rules, is certainly a concern.The major crux is likely to be finding a class of dynamic histories that satisfies both the existence and closure axiomsDYN.2–DYN.14 and also the rules for heaps H.2 to H.4. Another problem is that there is an inherent tension between DYN.6,which excludes any kind of hysteresis, and default rule UP.1, which has hysteresis built in (the motions possible to objectsin the heap at one time depend on their positions relative to the support at a different time.) I don’t think that these areactually inconsistent, but it is certainly possible that they suffice to rule out important forms of “settling” if the box is tiltedwhile being carried.The work in this paper is only a first step in the analysis of commonsense knowledge about solid objects. The mostimportant open problems in this analysis, which we hope to address in future work, are:• Incorporating a probabilistic theory or some other theory of relative likelihoods.• Analyzing the unloading of the box.• Merging this theory with the Newtonian theory of forces.• Developing a more realistic model of manipulation.• Extending the theory of the stability of heaps under perturbations (motions of the supports, contacts with externalobjects, and impacts of external objects).References[1] E.W. Adams, The foundations of rigid body mechanics and the derivation of its laws from those of particle mechanics, in: L. Henkin, P. Suppes, A. Tarski(Eds.), The Axiomatic Method — With Special Reference to Geometry and Physics, North-Holland, Amsterdam, 1959, pp. 250–265.[2] F. Bacchus, Representing and Reasoning with Probabilistic Knowledge: A Logical Approach to Probabilities, MIT Press, 1990.[3] B. Bennett, A.G. Cohn, P. Torrini, S.M. Hazarika, Describing rigid body motions in a qualitative theory of spatial regions, in: AAAI-00, pp. 503–509.[4] D. Chapman, Planning for conjunctive goals, Artificial Intelligence 32 (1987) 333–378.[5] E. Charniak, Statistical Language Learning, MIT Press, 1993.[6] E. Davis, A logical framework for commonsense predictions of solid object behavior, Int. Journal of AI in Engineering 3 (3) (1988) 125–140.[7] E. Davis, The naive physics perplex, AI Magazine 19 (4) (Winter 1998) 51–79.[8] E. Davis, L. Morgenstern, A first-order theory of communication and multi-agent plans, Journal of Logic and Computation 15 (5) (2005) 701–749.[9] E. Davis, The expressivity of quantifying over regions, Journal of Logic and Computation 16 (2006) 891–916.[10] E. Davis, Physical reasoning, in: Frank van Harmelen, Vladimir Lifschitz, Bruce Porter (Eds.), The Handbook of Knowledge Representation, Elsevier,Oxford, 2007, pp. 597–620.[11] J. de Kleer, Multiple representations of knowledge in a mechanics problem solver, in: IJCAI-77, pp. 299–304.[12] B. Faltings, Qualitative kinematics in mechanisms, in: Proc. IJCAI-87, pp. 436–443.[13] K. Forbus, Spatial and qualitative aspects of reasoning about motion, in: Proc. AAAI-80, pp. 170–173.[14] K. Forbus, P. Nielsen, B. Faltings, Qualitative spatial reasoning: The CLOCK project, Artificial Intelligence 51 (1991) 417–471.[15] A. Gelsey, Automated reasoning about machines, Artificial Intelligence 74 (1995) 1–53.[16] S. Hanks, D. McDermott, Nonmonotonic logic and temporal projection, Artificial Intelligence 33 (1987) 379–412.[17] P. Hayes, The naive physics manifesto, in: D. Michie (Ed.), Expert Systems in the Microelectronic Age, Edinburgh University Press, Edinburgh, 1979.[18] S. LaValle, Automated Planning, Cambridge University Press, 2006.[19] D. Lenat, The voice of the turtle: Whatever happened to AI?, AI Magazine 29 (2) (2008) 11–22.[20] V. Lifschitz, Formal theories of action, in: F. Brown (Ed.), The Frame Problem in Artificial Intelligence: Proceedings of the 1987 Workshop, MorganKaufmann, 1987.[21] D. Macaulay, The Way Things Work, Houghton Mifflin, 1988.[22] J. McCarthy, Programs with common sense, in: Proc. Symposium on Mechanization of Thought, vol. 1, London, 1959.[23] J. McCarthy, Programs with common sense, in: M. Minsky (Ed.), Semantic Information Processing, MIT Press, Cambridge, MA, 1968, pp. 403–418.[24] J. McCarthy, Circumscription — A form of nonmonotonic logic, Artificial Intelligence 13 (1980) 27–39.[25] J. McCarthy, Elaboration tolerance, in: 4th International Symposium on Logical Formalizations of Commonsense Reasoning, 1998.[26] D. McDermott, Tarskian semantics, or no notation without denotation!, Cognitive Science 2 (1978) 277–282.[27] D. McDermott, A temporal logic for reasoning about processes and plans, Cognitive Science 6 (1982) 101–155.[28] D. McDermott, The 1998 AI planning systems competition, AI Magazine 21 (2000).18 For instance, Waltz [37], p. 398 writes that “It was widely believed that logic could successfully model images and scenes, even though the baroqueimprobability of that effort should have long been clear to everyone who read Pat Hayes’ Naive Physics Manifesto”.E. Davis / Artificial Intelligence 175 (2011) 299–345345[29] P. Nielsen, A qualitative approach to mechanical constraint, in: Proc. AAAI-88, pp. 270–274.[30] D.A. Randell, Z. Cui, A.G. Cohn, A spatial logic based on regions and connection, in: Third International Conference on Principles of Knowledge Repre-sentation and Reasoning, 1992, pp. 165–176.[31] R. Reiter, A logic for default reasoning, Artificial Intelligence 13 (1980) 81–132.[32] R. Reiter, Knowledge in Action: Logical Foundations for Specifying and Implementing Dynamical Systems, MIT Press, Cambridge, MA, 2001.[33] M. Shanahan, Solving the Frame Problem, MIT Press, 1997.[34] T. Stahovich, R. Davis, H. Shrobe, Qualitative rigid-body mechanics, Artificial Intelligence 119 (2000) 19–60.[35] D. Stewart, Existence of solutions to rigid body dynamics and the paradoxes of Painlevé, Comptes Rendus de l’Academie des Sciences, Ser. I 325 (1997)689–693.[36] D. Stewart, Rigid-body dynamics with friction and impact, SIAM Review 41 (1) (2000) 3–39.[37] D. Waltz, Cognitive and computation models: Section introduction, in: J. Glasgow, H. Narayanan, B. Chandrasekaran (Eds.), Diagrammatic Reasoning:Cognitive and Computational Perspectives, AAAI Press, 1995, pp. 397–401.