Artificial Intelligence 174 (2010) 1172–1221Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintUpdating action domain descriptions ✩Thomas Eiter a, Esra Erdem b, Michael Fink a,∗, Ján Senko aa Institute of Information Systems, Vienna University of Technology, Vienna, Austriab Faculty of Engineering and Natural Sciences, Sabancı University, Istanbul, Turkeya r t i c l ei n f oa b s t r a c tArticle history:Received 28 November 2008Received in revised form 4 June 2010Accepted 27 June 2010Available online 17 July 2010Keywords:Knowledge representationReasoning about actions and changeTheory changeAction languagesPreference-based semanticsIncorporating new information into a knowledge base is an important problem which hasbeen widely investigated. In this paper, we study this problem in a formal frameworkfor reasoning about actions and change. In this framework, action domains are describedin an action language whose semantics is based on the notion of causality. Unlikethe formalisms considered in the related work, this language allows straightforwardrepresentation of non-deterministic effects and indirect effects of (possibly concurrent)actions, as well as state constraints; therefore, the updates can be more general thanelementary statements. The expressivity of this formalism allows us to study the updateof an action domain description with a more general approach compared to related work.First of all, we consider the update of an action description with respect to furthercriteria, for instance, by ensuring that the updated description entails some observations,assertions, or general domain properties that constitute further constraints that are notexpressible in an action description in general. Moreover, our framework allows us todiscriminate amongst alternative updates of action domain descriptions and to single outa most preferable one, based on a given preference relation possibly dependent on thespecified criteria. We study semantic and computational aspects of the update problem,and establish basic properties of updates as well as a decomposition theorem that givesrise to a divide and conquer approach to updating action descriptions under certainconditions. Furthermore, we study the computational complexity of decision problemsaround computing solutions, both for the generic setting and for two particular preferencerelations, viz. set-inclusion and weight-based preference. While deciding the existence ofsolutions and recognizing solutions are PSPACE-complete problems in general, the problemsfall back into the polynomial hierarchy under restrictions on the additional constraints. Wefinally discuss methods to compute solutions and approximate solutions (which disregardpreference). Our results provide a semantic and computational basis for developing systemsthat incorporate new information into action domain descriptions in an action language, inthe presence of additional constraints.© 2010 Elsevier B.V.Open access under CC BY-NC-ND license.1. IntroductionAs we live in a world where knowledge and information is in flux, updating knowledge bases is an important issuethat has been widely studied in the area of knowledge representation and reasoning (see e.g. [67,12,20,61] and references✩This paper is a revised and significantly extended version of a preliminary paper that appeared in: Proc. 19th International Joint Conference on ArtificialIntelligence (IJCAI 2005), pp. 418–423.* Corresponding author.E-mail addresses: eiter@kr.tuwien.ac.at (T. Eiter), esraerdem@sabanciuniv.edu (E. Erdem), michael@kr.tuwien.ac.at (M. Fink), jan@kr.tuwien.ac.at(J. Senko).0004-3702 © 2010 Elsevier B.V.doi:10.1016/j.artint.2010.07.004Open access under CC BY-NC-ND license.T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–12211173therein). However, the problem is far from trivial and many different methods have been proposed to incorporate newinformation, be it affirmative or prohibitive, which are based on different formal and philosophical underpinnings, cf. [67,39,57]. It appears that there is no general purpose method that would work well in all settings, which is partly due to thefact that an update method is also dependent to some extent on the application domain.In particular, in reasoning about actions and change, the dynamicity of the world is a part of the domain theory, andrequires special attention in update methods. For various approaches to formal action theories, including the prominentsituation calculus, event calculus, and action languages that emerged from the research on non-monotonic reasoning, theproblem of change has been widely studied and different methods have been proposed (see [64] for background and refer-ences, and Section 8.1 for a more detailed discussion).To give a simple example, consider an agent having the following knowledge, K TV , about a TV with remote control:(TV1) If the power is off, pushing the power button on the TV turns the power on.(TV2) If the power is on, pushing the power button on the TV turns the power off.(TV3) The TV is on whenever the power is on.1(TV4) The TV is off whenever the power is off.Now assume that the agent does not know how a remote control works (e.g., she does not know the effect of pushing thepower button on the remote control). Suppose that later she obtains the following information, K RC , about remote controls:(RC1) If the power is on and the TV is off, pushing the power button on the remote control turns the TV on.(RC2) If the TV is on, pushing the power button on the remote control turns the TV off.The task is now to incorporate this new knowledge into the current knowledge base K TV . In this particular case, thisseems unproblematic, as upon simply adding K RC to KTV the resulting stock of knowledge is consistent; in general, however,it might be inconsistent, and a major issue is how to overcome this inconsistency.We study the incorporation problem in the context of action languages [30]. In these formalisms, actions and change aredescribed by “causal laws.” For instance, in the action language C [32], the direct effect of the action of pushing the powerbutton on the TV, stated in (TV1), is described by the causal lawcaused PowerON after PushPBTV ∧ ¬PowerON,(1)which expresses that this action, represented by PushPBTV , causes the value of the fluent PowerON to change from false totrue; the indirect effect of this action that is stated in (TV3) is described by the causal lawcaused TvON if PowerON,(2)which expresses that if the fluent PowerON is caused to be true, then the fluent TvON is caused to be true as well.Action description languages are quite expressive to easily handle non-determinism, concurrency, ramifications, qualifica-tions, etc. The meaning of an action description can be represented by a “transition diagram”—a directed graph whose nodescorrespond to states and whose edges correspond to action occurrences; Fig. 1 below (Section 2) shows an example. Thereare reasoning systems, like CCalc2 and DLVK,3 that accept domain descriptions in an action language, like C or K respec-tively, and support various kinds of reasoning tasks over these descriptions, including planning, prediction and postdictionin CCcalc and computing different kinds of plans in DLVK.As far as action languages are concerned, the update problem was studied to a remarkably little extent. For the basicaction language A (see [30]), which is far less expressive than C, the update problem has been considered, e.g., in [44,47]. Both works focused on updates that consist of elementary statements (i.e., essentially facts) over time, and presentedspecific update methods, focusing on the contents of the knowledge base. We address the update problem from a moregeneral perspective in the following ways:• We consider a richer language (i.e., a fragment of C) to study the update problem, and updates are represented interms of a set of arbitrary causal laws.• We view the update problem from a more general perspective. Sometimes, ensuring consistency is not sufficient: wemight want to ensure also that the updated action description entails some scenarios, conditions, or general properties ofthe domain that cannot be expressed by causal laws. In our update framework, such further knowledge could be taken intoaccount.For example, for the effective use of the TV system in the above scenario, the following constraint might be imposed:(C) Pushing the power button on the remote control is always possible.41 Note that the statement is wrong; its defectiveness is observed and resolved upon update.2 http://www.cs.utexas.edu/users/tag/cc/.3 http://www.dbai.tuwien.ac.at/proj/dlv/K/.4 Note the conceptual difference between (C) and (TV2): (C) expresses an executability condition, whereas (TV2) captures a causal relationship.1174T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–1221If KRC is simply added to KTV , then (C) is not satisfied by KRC ∪ KTV : when the power and the TV are on, pushing the powerbutton on the remote control is not possible, since (RC2) and (TV3) contradict. The question is then how the agent canupdate KTV by incorporating KRC relative to (C); note that (C) is not expressible by causal laws in the action language C.To represent constraints like (C), we use formulas for “queries” in action languages like in [30]; here, the formulaALWAYS executable {PushPBRC}(3)has to evaluate to true, where {PushPBRC} stands for the concrete action of pushing the power button on the remote control.Similarly, consider the following scenario that we might want the updated action description to entail:(S) Sometimes, when the power is on, pushing the power button on TV turns the power off, and after that if we push thepower button on the TV then the power is on again.This scenario cannot be expressed by means of causal laws either; however, it can be expressed by a formulaSOMETIMES evolves PowerON; {PushPBTV };¬PowerON; {PushPBTV }; PowerON.• Sometimes, an action description can be updated in several ways. Our framework allows us to discriminate amongstalternatives and to single out a most preferable candidate as the result, based on a given preference relation possiblydependent on the additional constraint formulas.In this paper, we consider a generic framework for incorporating new causal laws into an existing action description,that takes into account the constraint formulas to be satisfied in the end. We thus take here the stance that the causal laws,which have been designed by the user or the knowledge engineer, are to be modified, while constraint formulas are notsubject to change (they might capture indisputable properties of the domain); a violation of constraints might be tolerated,though, if indicated by the user. Our main contributions can be summarized as follows:(1) We introduce a formal notion of an action update problem, which is, given action descriptions D and I , and a set Cwhich incorporates I into D. While D and I areof constraint formulas, to determine a (possibly new) action description Din (a canonical subset of) C, we describe conditions like (C) and scenarios like (S) by “constraints” using formulas from anaction query language, similar to the one in [30]. In a more fine-grained treatment, D is split into an unmodifiable part, D u ,and a modifiable part, Dm, while C is split into obligatory constraints, Co, (which must hold under all circumstances) andpreference constraints, C p (which ideally should hold, but might be violated).(cid:5)A solution to an action update problem is then defined in terms of an action description D(cid:5)that consists of I andstatements from D such that Co is satisfied by Dare possible, we use a (strict)preference relation (cid:2)C over action descriptions5 in order to discriminate amongst alternatives and to single out a mostas the result. Here the subscript C indicates that the preference relation is possibly dependentpreferable candidate Don the set C of constraints. Such a preference relation can be defined in different ways, in terms of syntactic conditions(e.g., the set of causal laws in an action description), or semantic conditions (e.g., the presence or absence of paths in thetransition diagram).; as, in general, different candidates D(cid:5)(cid:5)(cid:5)(2) We investigate semantic properties of action updates, and establish some basic properties regarding solution pref-erence, and special forms of updates, which serve as tests for the suitability of the notions proposed. We furthermoredetermine conditions under which computing a solution to an action update problem can be structurally decomposed, suchthat a divide-and-conquer approach becomes feasible. In particular, this is possible if the action description and the con-straints can be split into disjoint parts that interfere in a benign way, and if the preference ordering can be gracefullydecomposed along this split.(cid:5)(cid:5)holds given D and D(3) We study the computational complexity of the action update problem, where we consider the generic setting (makingsome assumptions about the cost of deciding whether the constraints C are satisfied by an action description D, denotedD |(cid:6) C , and whether D (cid:2)C D), as well as some natural instances. Among the latter are those wherethe preference relation (cid:2)C is ordinary set-inclusion and where it is weight-based relative to satisfied constraints. Underthe assumption that testing D |(cid:6) C and D (cid:2)C Dis feasible in polynomial space, deciding the existence of some solutionto an action update problem turns out to be PSPACE-complete in general, and also verifying a given solution candidate hasthis complexity. However, the complexity of both problems falls back into the polynomial hierarchy, if deciding D |(cid:6) C andD (cid:2)C Dis located there, and is located at most one level higher up there; we recall here that deciding the consistencyof an action description in C is intractable in general (and NP-complete for the canonical fragment of our concern). Giventhat the test D |(cid:6) C and D (cid:2)C Dis polynomial, deciding solution existence is NP-complete and thus not harder than theconsistency problem, and recognizing a given solution is only mildly harder.(cid:5)(cid:5)(cid:5)(4) We discuss methods for computing solutions and “pre-solutions” which approximate them, by disregarding solutionpreference. As for solutions, we focus on set-inclusion and one particular weight-based comparison, as preference relations5 That is, (cid:2)C is irreflexive and transitive.T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–12211175(cid:2)C , which use an oracle for pre-solutions. For pre-solutions, we present a method that reduces the problem into reasoningover an action description that is constructed from the problem input; here, evaluating constraint formulas can be exploitedto test given candidates.(5) Finally, we show the applicability of our algorithm based on the computation of pre-solutions, and the usefulness ofthe theoretical results on the decomposability of the update problem, in the context of the Zoo World, which is an actiondomain proposed by Erik Sandewall in his Logic Modelling Workshop.6 The Zoo World consists of several cages and theexterior, gates between them, and animals of several species, including humans, and its actions include moving within andbetween cages, opening and closing gates, and mounting and riding animals; a description of this domain in the actionlanguage C+ was given in [1].Our results go significantly beyond previous results in the literature (see Section 8.1), and provide a semantic and com-putational basis for developing systems that incorporate new information into action descriptions in an action language,in the presence of further constraints that can be expressed as formulas to be entailed by the updated description. Ourgeneric framework can be instantiated to different settings, which reflect different intuitions or criteria for solution prefer-ence. It thus provides a flexible tool for modeling action update. As a byproduct, we obtain decomposition results of actiondescriptions that emerge from special cases of action update instances, which are interesting in their own right.The rest of this paper is structured as follows. In the next section, we provide preliminaries about transition diagrams,action languages, and constraint formulas as needed for the problem setting. After that, we define in Section 3 the updateproblem in a generic framework and briefly introduce a syntactic and a semantic instance of it. In Section 4, we study somesemantic properties of updates, including possible decompositions. After that, we turn to computational issues. In Section 5,we characterize the computational complexity of problems around updates, and in Section 6 we provide algorithms forcomputing updates. Example applications in the Zoo World are considered in Section 7. After a discussion of related workand further aspects of the problem in Section 8, we conclude with a summary and issues for further research.2. PreliminariesWe describe action domains and the updates in an action description language, a fragment of C [32], by “causal laws.”Therefore, in the following, first we describe the syntax and the semantics of the action description language, which isdefined by means of “transition systems.”While updating an action domain description, we sometimes would like ensure that the updated description entailssome conditions or scenarios. Most of the time such scenarios or conditions are not expressible in the action language. Wedescribe them as constraints using formulas from an action query language, like the one in [30]. Therefore, we also describethe action query language we use, and define satisfaction of a constraint by an action domain description.Finally, we give sample constraints that are useful in action updates but cannot be represented in the action descriptionlanguage. We also discuss and emphasize the necessity of a query language in addition to the description language.2.1. Transition diagramsWe start with a (propositional) action signature that consists of a set F of fluent names, and a set A of action names.A literal is an expression of the form P or ¬P , where P is a fluent name. An action is a truth-valued function on A, denotedby the set of action names that are mapped to t. Thus, action names represent basic (atomic) actions, while a (compound)action is identified with the basic actions taking place at the same time, providing an intuitive representation of both,atomic and concurrent, actions.Definition 1. (See [30].) A (propositional) transition diagram of an action signature L = (cid:7)F, A(cid:8) consists of a set S of states, a(cid:5)function V : F × S → { f , t}, and a subset R ⊆ S × 2A × S of transitions. We say that V (P , s) is the value of P in s. The states s(cid:5)(cid:8) ∈ R are the possible results of the execution of the action A in the state s. We say that A is executable in ssuch that (cid:7)s, A, sif at least one such state sexists; and that A is deterministic in s if there is at most one such s.(cid:5)(cid:5)A transition diagram can be thought of as a labeled directed graph. Every state s is represented by a vertex labeled with(cid:5)(cid:8) ∈ R is represented by an edge leadingthe function P (cid:12)→ V (P , s) from fluent names to truth values. Every triple (cid:7)s, A, sfrom s to sand labeled A. An example of a transition diagram is shown in Fig. 1.(cid:5)2.2. Action description languagesWe consider the prime subset of the action description language C [32] that consists of two kinds of expressions (calledcausal laws): static laws of the formcaused L if G,6 http://www.ida.liu.se/ext/etai/lmw/.(4)1176T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–1221Fig. 1. A transition diagram.Fig. 2. An action description for KTV .where L is a literal and G is a propositional combination of fluent names, and dynamic laws of the formcaused L if G after H,(5)where L and G are as above, and H is a propositional combination of fluent names and action names. In (4) and (5) thepart if G can be dropped if G is True.An action description is a set of causal laws. For instance, the knowledge base about a TV system, D, of the agent in theprevious section, can be described by causal laws in Fig. 2. An expression of the forminertial L1, . . . , Lkstands for the causal lawscaused Li if Li after Li(1 (cid:2) i (cid:2) k)(6)describing that the value of the fluent Li stays the same unless changed by an action.The meaning of an action description can be represented by a transition diagram. Let D be an action description with asignature L = (cid:7)F, A(cid:8). Then the transition diagram (cid:7)S, V , R(cid:8) described by D, denoted by T (D), is defined as follows:(i) S is the set of all interpretations s of F such that, for every static law (4) in D, s satisfies G ⊃ L,(ii) V (P , s) = s(P ),(iii) R is the set of all triples (cid:7)s, A, s(cid:5)(cid:8) such that sis the unique interpretation of F which satisfies the heads L of all(cid:5)• static laws (4) in D for which s• dynamic laws (5) in D for which s(cid:5)(cid:5)satisfies G, andsatisfies G and s ∪ A satisfies H .(cid:5)The laws included in (iii) above are those that are applicable to the transition from s to scausal laws make sure that scausal laws handle the preconditions and the direct effects of A.caused by executing A: the staticis a state, and handles the ramifications and the qualifications of A; whereas the dynamicAction language C is based on the “principle of universal causation,” according to which every fact that obtains iscaused. In the definition above, the condition that sis the only interpretation satisfying the heads of the applicable causallaws ensures this. For instance, the transition diagram described by the action description for K TV in Fig. 2 is presented inFig. 1. Consider the transition (cid:7){¬PowerON, ¬TvON}, {PushPBTV }, {PowerON, TvON}(cid:8). The causal laws that are applicable tothis transition are(cid:5)(cid:5)caused PowerON after PushPBTV ∧ ¬PowerONcaused TvON if PowerON.Here {PowerON, TvON} is the only interpretation that satisfies the heads of these causal laws, i.e., {PowerON, TvON}.Now consider the triple (cid:7){¬PowerON, ¬TvON}, { }, {PowerON, TvON}(cid:8). There is only one of the two causal laws aboveapplicable to this triple, viz. the second. There are two interpretations that satisfy the head of this causal law: {PowerON,TvON} and {¬PowerON, TvON}. In other words, no causal law provides a causal explanation for PowerON. Therefore, thistriple is not a transition.T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–12211177We say that an action description is consistent if it can be represented by a transition diagram with nonempty state set.In the following, we suppose that an action description D consists of two parts: D u (unmodifiable causal laws) and Dm(modifiable causal laws). Therefore, we sometimes denote an action description D as D u ∪ Dm.2.3. Why action languages?In this work, we consider action languages to formalize action domains. There are several reasons for this decision.First of all, action description languages, like C, are quite expressive to easily handle non-determinism, concurrency,ramifications, defaults, qualifications, state constraints, etc. For instance, we can express that tossing a coin may lead toHeads or Tails by the causal lawscaused Heads if Heads after Tosscaused ¬Heads if ¬Heads after Toss.Concurrency is allowed unless no qualification constraint is violated or unless explicitly stated otherwise by a causal lawlikecaused False after MoveRight ∧ MoveLeft.The commonsense law of inertia is immediately expressed by causal laws of the form (6). A direct effect of turning on thepower is that the power is on; a ramification of turning on the power is that TV is on. We can express such a ramificationby the causal lawcaused TvON if PowerON.We can describe that a spring-loaded door is by default closed by the causal laws:caused Open if Open.Second, there are reasoning systems, like CCalc and DLVKK respectively, and allow various kinds of reasoning tasks over these descriptions., that accept domain descriptions in an action language, like C orThird, there is a large amount of theoretical and application-oriented work on action languages, including our earlierwork on planning and monitoring. On the other hand, as discussed briefly in the introduction, the update problem wasstudied to a remarkably little extent in the context of action languages. This paper not only extends our earlier work to takeupdates into account but also fulfills the need for a general approach to updates in action languages.2.4. Expressive constraintsOnce we describe an action domain, we may want check whether this domain description entails some observations ofthe world, assertions about the effects of the execution of actions, or even some scenarios. Similarly as in [18], we expresssuch conditions as constraints using formulas from an action query language, like the one in [30]. After that, we can checkwhether a given action description satisfies a given constraint using reasoning systems, e.g. CCalc (cf. the examples inAppendix C).Now constraint formulas are formally defined as follows.7An open constraint is either (a) a static constraint of the formholds F ,where F is a fluent formula, or (b) a dynamic constraint of the formnecessarily Q after A1; . . . ; An,(7)(8)where Q is an open constraint and each Ai is an action8; or (c) any propositional combination of open constraints. Anexistential constraint is an expression of the formSOMETIMES Q ,where Q is an open constraint; a universal constraint is of the formALWAYS Q ,(9)(10)where Q is an open constraint. A constraint q is a propositional combination of existential constraints and universal con-straints.7 In action query languages, “constraints” as here etc. are called “queries;” the former term is more appealing here as satisfaction is required.8 This amounts to [Q ] A1; . . . ; An in dynamic logic [37]; however, we stick here to the commonly used syntax of action queries.1178T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–1221For an open constraint q, its maximal nesting depth of dynamic constraints k is defined inductively as follows. If q is a staticconstraint, then k = 0; if q is a dynamic constraint of the form (8), then k = k Q + 1, where k Q is the maximal nestingdepth of dynamic constraints in Q ; if q is a Boolean combination of open constraints, then k is a maximal element fromthe set of maximal nesting depths of dynamic constraints of its subformulas. This definition is easily extended to (general)constraints. For an existential (universal) constraint of the form (9) (resp. of the form (10)), its maximal nesting depth ofdynamic constraints is k Q , i.e., the maximal nesting depth of dynamic constraints in Q . For a propositional combination ofexistential and universal constraints, its maximal nesting depth of dynamic constraints is a maximal element from the setof maximal nesting depths of dynamic constraints of its subformulas.As for the semantics, let T = (cid:7)S, V , R(cid:8) be a transition diagram, with a set S of states, a value function V mapping, ateach state s, every fluent P to a truth value, and a set R of transitions. A history of T of length n is a sequences0, A1, s1, . . . , sn−1, An, sn(11)where each (cid:7)si, Ai+1, si+1(cid:8) (0 (cid:2) i < n) is in R. We say that a state s ∈ S satisfies an open constraint Qof form (7)(resp. (8)) relative to T (denoted T , s |(cid:6) Q), if the interpretation P (cid:12)→ V (P , s) satisfies F (resp. if, for every historyh = s0, A1, s1, . . . , sn−1, An, sn of T which is of length n and such that s = s0, open constraint Q is satisfied at state sn).For other forms of open constraints Q , satisfaction is defined by the truth tables of propositional logic. If T is described byan action description D, then the satisfaction relation between s and an open constraint Q can be denoted by D, s |(cid:6) Q aswell.(cid:5)(cid:5)Note that, for every state s and for every fluent formula F ,D, s |(cid:6) holds F ⇐⇒ D, s |(cid:6) ¬holds ¬F .For every state s, every fluent formula F , and every action sequence A1, . . . , An (n (cid:3) 1), ifD, s |(cid:6) necessarily (holds F ) after A1; . . . ; AnthenD, s |(cid:6) ¬necessarily (¬holds F ) after A1; . . . ; An.We say that D satisfies a constraint q (denoted D |(cid:6) q) if one of the following holds:• q is an existential constraint (9) and D, s |(cid:6) Q for some state s ∈ S;• q is a universal constraint (10) and D, s |(cid:6) Q for every state s ∈ S;(cid:5)• q = ¬q;• q = q1 ∧ q2 and D |(cid:6) q1 and D |(cid:6) q2; or• q = q1 ∨ q2 and D |(cid:6) q1 or D |(cid:6) q2.and D (cid:16)|(cid:6) q(cid:5)For every open constraint Q ,D |(cid:6) SOMETIMES Q iff D |(cid:6) ¬ALWAYS ¬Q .For a set C of constraints, we say that D satisfies C (denoted D|(cid:6)C ) if D satisfies every constraint in C . Consider, e.g., theaction description presented in Fig. 2. It does not satisfy any set of constraints containingALWAYS necessarily (holds ¬TvON) after {PushPBRC}because this constraint is not satisfied at the state {TvON, PowerON}; but, it satisfies the constraints:ALWAYS holds PowerON ≡ TvON,ALWAYS holds PowerON ∧ TvON ⊃ ¬necessarily (holds TvON) after {PushPBTV }.(12)(13)In the rest of the paper, an expression of the formpossibly Q after A1; . . . ; An,where Q is an open constraint and each Ai is an action, stands for the dynamic constraint¬necessarily ¬Q after A1; . . . ; An;an expression of the formevolves F 0; A1; F 1; . . . ; Fn−1; An; Fn,where each F i is a fluent formula, and each Ai is an action, stands for(cid:2)holds F 0 ∧ possiblyholds F 1 ∧ possibly (holds F 2 ∧ . . .) after A2(cid:3)after A1;T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–12211179andexecutable A1; . . . ; Anwhere each Ai is an action, stands forpossibly True after A1; . . . ; An.We sometimes drop holds from static constraints appearing in dynamic constraints.2.4.1. ExamplesTo get a better intuition about the capability of constraints, we give some examples of properties that can be expressedby them.• Existence of certain states, transitions, and histories: For instance, we can express the existence of states where a formulaF holds by means of the constraintSOMETIMES holds F .Similarly, we can express the existence of a transition from some state where a formula F holds to another state wherea formula Fholds, by the execution of an action A:(cid:5)SOMETIMES holds F ∧ possibly F(cid:5)after A.In general, the existence of a history (11) such that, for each si of the history, the interpretation P (cid:12)→ V (P , si) satisfiessome formula F i is expressed by the constraint:SOMETIMES evolves F 0; A1; F 1; . . . ; Fn−1; An; Fn.For instance, the constraintSOMETIMES evolves PowerON; {PushPBTV };¬PowerON; {PushPBTV }; PowerONdescribes the presence of the following history in Fig. 1:{PowerON, TvON},{¬PowerON, ¬TvON},{PushPBTV },{PushPBTV },{PowerON, TvON}.• (Non-)executability of an action: Like in [16], executability of an action sequence A1, . . . , An (n (cid:3) 1) at every state can bedescribed byALWAYS executable A1; . . . ; An.That no action is possible at a state where formula F holds is expressed bySOMETIMES holds F ∧(cid:4)necessarily False after A.A∈2A• Mandatory and possible effects of actions: Like in [16], mandatory effects of a sequence A1, . . . , An (n (cid:3) 1) of actions in agiven context are described byALWAYS holds G ⊃ necessarily F after A1; . . . ; An;and possible effects of a sequence of actions in a context byALWAYS holds G ⊃ possibly F after A1; . . . ; An.In these constraints, F describes the effects and G the context.2.4.2. Constraints vs. causal lawsIn all action languages [30], queries have been expressed in a language different from the action description languages.As we consider constraints as queries that evaluate to true, it may look suggestive to merge causal laws and constraintsinto a single set of formulas that constitute an action description. However, constraints and causal laws are conceptuallydifferent: causal laws are axioms that describe action domains in a generative manner (in particular, in action language C viacausation), whereas constraints express conditions (which may also refer to time steps) that we would like to ensure aboutan action domain; they thus serve for eliminating unwanted models. In other words, constraints restrict the possibilities foran action description, but they are non-constructive in the sense that they do not causally generate transitions. The latter(cid:5)(cid:8) in the transition diagram is causallyhowever is at the heart of C and many other action languages: each edge (cid:7)s, A, s1180T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–1221explained (or “generated”), meaning that the follow up state slaws that “fire,” i.e., the causal laws that are applicable to (cid:7)s, A, sis uniquely described by the literals in heads of the causal(cid:5)(cid:8).(cid:5)For instance, if the action description consists of the only causal lawcaused G after A1 ∧ F ,where every fluent is inertial, then the transition diagram has the edge (cid:7){F , ¬G}, { A1}, {F , G}(cid:8), i.e., we can get from the(cid:5) = {F , G} with the occurrence of the action { A1}. However, the transition diagram does notstate s = {F , ¬G} to the state shave the edge (cid:7)∅, { A1}, {F , G}(cid:8). If instead of the causal law above, we consider the constraintALWAYS holds F ⊃ necessarily G after A1;which is similar to the causal law, then both (cid:7){F , ¬G}, { A1}, {F , G}(cid:8) and (cid:7)∅, { A1}, {F , G}(cid:8) would be included in the transitiondiagram (since F is false w.r.t. s = ∅, the implication is true).Although in some cases a constraint may be expressed by an equivalent causal law (or multiple such laws), this is notalways the case. Moreover, the meaning of a set of causal laws is described by a set of nodes and a set of edges that forma transition system, where each of these edges expresses a causal relationship (which generates the edge), whereas roughlyspeaking, the meaning of a constraint is described by a set of paths in the transition diagram without such a causal relation.In other words, constraints might describe conditions characterizing subgraphs of a transition diagram. Consequently, someconstraints cannot be expressed as causal laws, for instance “existential constraints” like the constraintSOMETIMES possibly F after A,the constraint (21), and similar constraints in Section 2.4.1. They cannot be expressed via causal laws, as the latter areinherently universal statements. Also “universal” constraints likeALWAYS (possibly F after A) ∧ (possibly ¬F after A)(which implicitly enforce existence of causal transitions) are difficult to express via causal laws. Another aspect is thatconstraints allow us to talk about sequences of actions, while causal laws do not.Due to the syntactic and the semantic differences between causal laws and queries, the reasoning systems (like CCalc)based on action languages also have different syntax for query formulas (cf. Appendix C); hence a difference in practiceas well. For instance, in reasoning systems, queries can be used to describe reasoning tasks (like temporal projection orplanning) about a given action domain.Although there are some formalisms (like situation calculus as in [60], dynamic logic as in [37], or answer set program-ming as in [48]) that can be used to describe both axioms and constraints, a distinction between formalisms to expressaxioms and constraints is not unusual in other areas either. Consider, for instance, the description of a circuit in propo-sitional logic and the conditions we want to check about this circuit that are expressed in a temporal logic [25]. Also,consider ontologies described in ontology description languages (like RDF), and constraints described in ontology querylanguages (like SPARQL).The differences between causal laws and query formulas also affect the computational efficiency of reasoning systems.For instance, given a domain description and a query, CCalc checks whether the query is entailed by the domain descriptionas follows:(1) it transforms the causal laws into a propositional theory ΓD ,(2) it transforms the negated query into a propositional theory ΓP ,(3) it checks whether ΓD ∪ ΓP is satisfiable;(4) if ΓD ∪ ΓP is unsatisfiable, it returns Yes;(5) otherwise, it returns No and presents a counter example extracted from a satisfying interpretation for ΓD ∪ ΓP .The transformations in the first two steps are different: the one in 1) is based on literal completion, whereas the one in 2)is based on a simpler procedure (see [31] for a detailed description). Such a difference allows one to check the entailmentof other queries without executing the first step again. If we had described a constraint by means of causal laws, then ingeneral we would have to transform the union of the causal laws and the constraint into a propositional theory; for largedomain descriptions, like the Zoo World, such a bulk transformation would lead to inefficient computations.3. Problem descriptionIn this section, we provide a formal description of the update problem, and its solution, as well as a weaker form ofsolution, called pre-solution. The basic problem is a theory change problem, i.e., a problem of incorporating new informationinto an existing stock of knowledge (cf. Sections 4.2 and 8.2 for more detailed discussions of relations to well-known workin this area). Since we study the incorporation problem in the context of an action language, we consider single causal lawsas the atomic entities that are subject to change (for a discussion how to refine this further, see Section 8.3). In additionto causal laws for incorporation, the new information may contain constraints that characterize intended properties ofT. Eiter et al. / Artificial Intelligence 174 (2010) 1172–12211181the change (reasons for the distinction between causal laws and constraints have been discussed in the previous section).Concerning solutions of the problem, we aim at keeping the size of the search space practically reasonable, as well as atbuilding on natural analogies with change operators developed in other areas of database or AI research (cf. [67,61,57] andreferences therein).Informally, we define an Action Description Update (ADU) problem by an action description D = D u ∪ Dm, a set I of causallaws (a partial action description), a set C = Co ∪ C p of constraints, and a preference relation (cid:2)C over action descriptions.Here D u and Dm are the unmodifiable (protected) and the modifiable part of D, respectively, and I is the update that hasto be incorporated. The constraints in Co are “hard (obligatory) constraints” that have to be satisfied in an acceptable actiondescription, while the constraints in C p are “soft (preference) constraints” that might be accounted for by the preferencerelation (cid:2)C . In the latter, D (cid:2)C Dexpresses that D is less preferable compared to D.(cid:5)(cid:5)Definition 2 (Action description update). Given an action description D = D u ∪ Dm, a set I of causal laws (a partial actiondescription), a set C = Co ∪ C p of constraints, and a preference relation (cid:2)C over action descriptions, all over the samesignature L, an action description Daccomplishes an (action description) update of D by I relative to C , if(cid:5)is consistent,(cid:5)(i) D(ii) D u ∪ I ⊆ D(cid:5) |(cid:6) Co,(iii) D(iv) there is no consistent action description D(cid:5) ⊆ D ∪ I ,(cid:5)(cid:5)such that D u ∪ I ⊆ D(cid:5)(cid:5) ⊆ D ∪ I , D(cid:5)(cid:5) |(cid:6) Co, and D(cid:5) (cid:2)C D(cid:5)(cid:5).9(cid:5)is called a solution to the ADU problem (D, I, C, (cid:2)C ). If an action description DSuch a Da pre-solution to the ADU problem (D, I, C, (cid:2)C ).(cid:5)satisfies (i)–(iii), then we call D(cid:5)Condition (i) expresses that an action description update, modeling a dynamic domain, such as the TV system in Sec-tion 1, must have a state. According to Condition (ii), new knowledge about the world and the invariable part of the existingaction description are kept, and the causal laws in the variable part are considered to be either “correct” or “wrong,” and inthe latter case simply disposed.Condition (iii) imposes semantical constraints Co on D, which comprise further knowledge about the action domaingained, e.g., from experience. It is important to note that C can be modified later for another action description update (aswill be discussed below).(cid:5)Finally, Condition (iv) picks the most preferred action description among the ones for which Conditions (i)–(iii) aresatisfied.In an ADU problem, the preference relation can be described in various ways. For instance, it can be defined in termsof syntactic conditions, like simple set inclusion. If we define (cid:2)C to be ⊂, then an action description D is less preferable. Alternatively, the preference relation (cid:2)C can be defined in terms of semanticthan an action description Dconditions. For instance, once a weight is assigned to each action description with respect to some semantic measure (e.g.,the number of certain paths present in the transition diagram of the description) by a function weight, we can take (cid:2)Cto be an operator <weight comparing the weights of the action descriptions; then an action description D is less preferablethan an action description Dif D ⊂ D.(cid:5)(cid:5)(cid:5)(cid:5)if D <weight DIn the literature, two kinds of changes that incorporate new information into a knowledge base have been identified, viz.revision (which adds more precise knowledge about the domain) and update (which is a change of the world per se) [66],which should be governed by different sets of postulates in axiomatic approaches like the AGM theory [2] and the KMtheory [39]. Our notion of ADU has more of a revision flavor, but we do not govern it with AGM or KM postulates, as theformalism does not satisfy the prerequisites; see Section 8.2 for more discussion. However, the constraints C can be adjustedif the nature of the change I is known. In case of a revision, C should reasonably contain all conditions corresponding toobservations made about the domain, while other conditions may be kept or dropped; on the other hand, if I is a changeof the world per se, then conditions corresponding to observations might be dropped.Eventually we remark that, in descriptive domains, like physical domains, one might carry out tests and collect respectiveresults (observations) in order to find out erroneous causal laws. In this case, the update problem would be rather viewedas a diagnosis problem. Note however, that such an approach hinges on the possibility to make observations for learningcausal relationships. In contrast, our approach is intended to also allow for normative (artificial) worlds modeled as actiondescriptions (e.g., agent systems, games, protocols), where the world is designed, rather than perceived. In such domains,and likewise for physical worlds that are not observable (where one is impeded to make observations for whatever reason),it is not feasible to treat the update problem as a diagnosis problem.9 Note that soft constraints C p are used implicitly in this definition, since the preference relation (cid:2)C is one in which C = Co ∪ C p is explicitly known asparameter.1182T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–1221Fig. 3. Causal laws for KRC .Fig. 4. Transition diagram described by D ∪ I of Example 1.3.1. ExamplesThe following is an example of an ADU problem with the syntax-based preference relation above.Example 1. Let D be the action description for KTV in Fig. 2, i.e., D = D u ∪ Dm withD u = {caused PowerON after PushPBTV ∧ ¬PowerON,caused ¬PowerON after PushPBTV ∧ PowerON,inertial PowerON, ¬PowerON, TvON, ¬TvON}and Dm = {caused TvON if PowerON, caused ¬TvON if ¬PowerON}, and let I be the set of causal laws for K RC in Fig. 3:caused TvON after PushPBRC ∧ PowerOn ∧ ¬TvON,caused ¬TvON after PushPBRC ∧ TvON.Furthermore, let C = Co contain besides constraints (3) and (13):ALWAYS executable {PushPBRC},ALWAYS holds PowerON ∧ TvON ⊃¬necessarily (holds TvON) after {PushPBTV },also the constraintALWAYS executable {PushPBTV },(14)and take (strict) set-inclusion (⊂) as the preference relation (cid:2)C . The transition diagram described by D ∪ I is shown inFig. 4. Here we can see that, at the state where both PowerON and TvON are mapped to t, the action PushPBRC is notexecutable. Therefore, D ∪ I is not a solution to the ADU problem (D, I, C, (cid:2)C ). In fact, a solution is obtained by droppingthe static law (2), i.e., caused TvON if PowerON, from D ∪ I .For an instance of a semantic definition of (cid:2)C , consider the following setting based on weights that are assigned toconstraints on C (i.e., weighted constraints in [18]). We define the weight of an action description D relative to a set C ofconstraints, and a weight function f : C → R mapping each constraint in C to a real number byweightq(D) =(cid:5)c∈C,D|(cid:6)cf (c).Intuitively, the weight of an action description defined relative to the weights of constraints encodes to what extent theset C of given preferable constraints is satisfied. (Note that f can easily express a threshold function as well.) With thisdefinition, the more the highly preferred constraints are satisfied, the more preferred the action description is.T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–12211183Example 2. Reconsider our previous example where C p consists of the constraint (13) with weight 1:ALWAYS holds PowerON ∧ TvON ⊃¬necessarily (holds TvON) after {PushPBTV }.Suppose that the preference relation (cid:2)C is defined in terms of a weight function on constraints (i.e., (cid:2)C = <weightqthe action descriptions D(cid:5)(cid:5)However, D). Then,(cid:5)(cid:5) = D u ∪ I satisfy Co and thus are pre-solutions.(cid:5) = (D ∪ I) \ {caused TvON if PowerON} and Ddoes not satisfy C p , which implies weightq(D(cid:5)(cid:5)) = 0, whereas weightq(D(cid:5)) = 1, and hence D(cid:5)(cid:5) (cid:2)C D.(cid:5)For further details on comparing action descriptions by means of weighted constraints and other semantic preferences,we refer the reader to [18].In the rest of the paper, we will study ADU problems at an abstract level, leaving the preference relation undefined. Forsome problems, we will provide more concrete results by instantiating the preference relation: we will take (cid:2)C as ⊂ (andC p = ∅, thus C = Co) for an instance of a syntax-based relation, and we consider (cid:2)C = <weightqas a representative of thesemantic-based approaches.4. Properties of updatesIn this section, we study some basic properties of solutions to an ADU problem. To this end, we first introduce asubsumption relation between action descriptions, and then show that solutions to an ADU problem fulfill some desiredproperties regarding special updates, provided that the preference relation (cid:21)C obeys some natural conditions. We then con-sider the structure of solutions and pre-solutions, and establish a disjoint factorization result that allows decomposing anADU into smaller parts.4.1. Basic update propertiesWe define subsumption of causal laws by an action description as follows.Definition 3 (Subsumption). Let D be an action description over a signature L = (cid:7)F, A(cid:8). Then,• a static law (4) over L is subsumed by D, if for every state s in T (D), the interpretation of F describing s satisfies G ⊃ L;(cid:5)(cid:8) in T (D), the following holds: if the inter-• a dynamic law (5) over L is subsumed by D, if for every transition (cid:7)s, A, ssatisfies G ⊃ L.pretation of F ∪ A describing s and A satisfies H , then the interpretation of F describing s(cid:5)A set S of causal laws is subsumed by an action description D, if every law in S is subsumed by D.Furthermore, we build on the properties of a preference relation (cid:2)C introduced next.In the following, for an action description D and a set C of constraints, let us denote by C D the set {c ∈ C | D |(cid:6) c}.Definition 4. Given a set of constraints C over a signature L = (cid:7)F, A(cid:8), a preference relation (cid:2)C over a L is called• monotone with respect to C , if for any two action descriptions D and Dmonotone with respect to C , if additionally C D(cid:5) ⊂ C D implies D• monotone with respect to L, if for any two action descriptions D and D(cid:5) (cid:2)C D;monotone with respect to L, if additionally D(cid:5) ⊂ D implies D(cid:5) (cid:2)C D;(cid:5)in L, C D(cid:5) ⊆ C D implies D (cid:16)(cid:2)C D(cid:5), and strongly(cid:5)in L, D(cid:5) ⊆ D implies D (cid:16)(cid:2)C D(cid:5), and strongly• non-minimizing with respect to L, if for any action description D in L, D |(cid:6) C implies D (cid:16)(cid:2)C D(cid:5)for all D(cid:5) ⊆ D, and stronglynon-minimizing with respect to L, if additionally D |(cid:6) C implies D(cid:5) (cid:2)C D for all D(cid:5) ⊂ D.We say that (cid:2)C is monotone, if it is either monotone with respect to C or monotone with respect to L (or both).Monotonicity is an intuitive potential requirement one might have on a preference relation: monotonicity with respectto C encodes the semantically motivated preference of satisfying preferable constraints as much as possible, whereas mono-tonicity with respect to L expresses a more syntactic view of retaining as many causal laws as possible. This is reflected inour representative preference relations. Notice that ⊂ is strongly monotone with respect to L (but not necessarily with re-spect to C ), whereas <weightqis monotone with respect to C if, for instance, all weights are non-negative (but not necessarilywith respect to L).Obviously, any monotone preference relation is also non-minimizing with respect to L, and strong monotonicity withrespect to L implies that (cid:2)C is also strongly non-minimizing with respect to L. Intuitively, a non-minimizing preferencerelation with respect to L ensures that syntactically smaller (with respect to subset inclusion) action descriptions cannotprevent an action description that satisfies all constraints from being a solution, while the respective strong property explic-itly excludes syntactically smaller action descriptions as solutions in this case (note that the additional condition implies the1184T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–1221condition of non-minimizing, and could serve as a definition alone). This intuition motivates basic properties of solutions toan ADU problem as follows.Proposition 1 (Subsumption). Let (D, I, C, (cid:2)C ) be an ADU problem, such that (cid:2)C is non-minimizing with respect to L, D is consistentand D |(cid:6) C . If D subsumes I , then D ∪ I is a solution to (D, I, C, (cid:2)C ). Moreover if (cid:2)C is strongly non-minimizing with respect to L,then D ∪ I is the unique solution.(cid:5) |(cid:6) Co implies D ∪ I (cid:16)(cid:2)C D(cid:5), R(cid:5), VLet T (D ∪ I) = (cid:7)S(cid:5) = S: Since D ⊆ D ∪ I , we get SSlaws of form (4) in I , i.e., S ⊆ S(cid:5) = V : Follows from S(cid:5) = R: Let (cid:7)s, A, sVR(cid:5).Proof. Let D = D u ∪ Dm and let T (D) = (cid:7)S, V , R(cid:8). Since D ∪ I = D u ∪ I ∪ Dm trivially satisfies (ii) of our definition of update(cid:5) ⊆ D ∪ I andaccomplishment, it remains to show: (i) D ∪ I is consistent, (iii) D ∪ I |(cid:6) Co, and (iv) for every DD, D u ∪ I ⊆ D(cid:5)(cid:5).(cid:5)(cid:8). In the following we prove that T (D ∪ I) = T (D).(cid:5) ⊆ S. Furthermore, D subsumes I and, hence, every s ∈ S satisfies G ⊃ L for all static(cid:5) = S and our labeling convention for states.(cid:5)(cid:8) be a candidate for a transition relation, R, of an action description, D, if (a) s(cid:5)(cid:5)satisfies G and s ∪ A satisfies H . Furthermore, let ssatisfies G, and (b) s(cid:5)of all static laws of form (4) in D, for which s(cid:5)in D, for which sheads of all laws applicable to (cid:7)s, A, sin F. Then, (cid:7)s, A, severy candidate (cid:7)s, A, s(cid:5)R is a candidate for R(cid:5) = R.A it follows that R(cid:5)(cid:8) for Ras well. As (cid:7)s, A, s(cid:5)(cid:5)(cid:8) ∈ R iff it is a candidate for R and s(cid:5)(cid:5)(cid:8) is neither in R nor in R(cid:5)(cid:8) uniquely determines s(cid:5)satisfies the heads Lsatisfies the heads L of all dynamic laws of form (5)(cid:5)be a determined successor of s w.r.t. A, if the set of, i.e., it contains (at least) one fluent literal for every fluentis a determined successor of s with respect to A. Since D ⊆ D ∪ I ,(cid:5)(cid:8) foris not a determined successor of s with respect to, if s(cid:5)(cid:5)is a candidate for R. Moreover, that D subsumes I implies that every candidate (cid:7)s, A, sGiven that D is consistent and that D |(cid:6) C , T (D ∪ I) = T (D) proves (i) and (iii). As for (iv), D |(cid:6) C and T(cid:5) = T implies(cid:5)D ∪ I |(cid:6) C . Since (cid:2)C is non-minimizing with respect to L, it follows for all D u ∪ I ⊆ D, whichproves (iv). Therefore, D ∪ I is a solution to (D, I, C, (cid:2)C ). Moreover, if (cid:2)C is strongly non-minimizing with respect to L,(cid:5) ⊆ D ∪ I . This implies that D ∪ I is the unique solution to (D, I, C, (cid:2)C ) in thisthen Dcase. (cid:3)(cid:5) (cid:2)C D ∪ I holds for all D u ∪ I ⊆ D(cid:5) ⊆ D ∪ I , that D ∪ I (cid:16)(cid:2)C DFrom this result, we obtain the following corollaries telling us that the solution to an ADU is as we would expect insome extremal cases, that correspond to cases that were considered for non-monotonic logic programming updates [5,20].Corollary 1 (Void update). Let (D, ∅, C, (cid:2)C ) be an ADU problem. If (cid:2)C is non-minimizing with respect to L, D is consistent, andD |(cid:6) C , then D is a solution to (D, ∅, C, (cid:2)C ). If (cid:2)C is strongly non-minimizing with respect to L, then D is the unique solution.Corollary 2 (Idempotence). Let (D, D, C, (cid:2)C ) be an ADU problem, such that (cid:2)C is non-minimizing with respect to L, D is consistent,and D |(cid:6) C , then D is the unique solution to (D, D, C, (cid:2)C ).Note that Void Update and Idempotence can easily be extended to cases where I ⊆ D: given that D is consistent andD |(cid:6) C , it holds that D is a solution if (cid:2)C is non-minimizing; for strongly non-minimizing (cid:2)C , it is the unique solution.Let us call a causal law tautological, if it is subsumed by every action description D. Informally, such a causal law has nological content, and updating with it should not lead to any change. In fact we have the following property.Corollary 3 (Addition of tautologies). Let (D, I, C, (cid:2)C ) be an ADU problem, such that (cid:2)C is non-minimizing with respect to L, Dis consistent, and D |(cid:6) C . If I consists of tautological causal laws, then D ∪ I is a solution to (D, I, C, (cid:2)C ). If (cid:2)C is strongly non-minimizing with respect to L, then D ∪ I is the unique solution.Notice that a similar property fails for logic programming updates as in [5,20].Example 3. Consider an action description D that has the following causal laws:inertial LightON, ¬LightON,caused LightON after SwitchLight ∧ ¬LightON,caused ¬LightON after SwitchLight ∧ LightON.Since D is consistent and ⊂ is strongly non-minimizing, we can state for any set C of constraints, such that D |(cid:6) C : D is(cid:5), C, ⊂) for anythe unique solution to (D, ∅, C, ⊂) (void update), as well as to (D, D, C, ⊂) (idempotence), and to (D, Dtautological action description D(addition of tautologies).(cid:5)with non-negative weights for any constraint c ∈ C instead of ⊂ as a preference relation (which isConsidering <weightqnon-minimizing), we can still infer that D(cid:5)is a solution, in general however, it need not be unique.T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–122111854.2. Postulates of belief changeIn the literature, two kinds of changes have been identified with the incorporation of new information, viz. revision(which adds more precise knowledge about the domain) and update (which is a change of the world per se) [66]. Despitethe nature of change, a distinction is made whether beliefs are represented by a theory, i.e., by a logically closed set ofsentences, or through a theory base (knowledge base), i.e., a finite representation of a theory [33]. Ideally, operators for thedifferent kinds of belief change are characterized by different sets of axioms or postulates like the AGM theory [2] for beliefrevision and the KM theory [39] for belief base update.Fitting our approach in this context, we first observe that a common basic assumption of the different belief changepostulates is that beliefs are sentences from a given logical language which is closed under the standard Boolean connec-tives; this is not the case for action languages. In order to evaluate our approach in the style of AGM, or KM respectively,it is thus necessary to interpret and adapt respective postulates. We note, however, that additional assumptions of the AGMtheory regarding the underlying inference relation, that it satisfies super-classicality, modus ponens, the deduction theoremetc. (cf. [57]), are inapplicable.Since an action description constitutes a finite representation of a theory about an action domain, our update approachhas to be classified as operating on belief bases. Let us briefly recall the KM postulates for belief base update10:(U1) KB (cid:22) φ implies φ.(U2) If KB implies φ, then KB (cid:22) φ ≡ KB.(U3) If both KB and φ are satisfiable, then KB (cid:4) φ is satisfiable.(U4) If KB1 ≡ KB2 and φ1 ≡ φ2, then KB1 (cid:22) φ1 ≡ KB2 (cid:22) φ2.(U5) (KB (cid:22) φ1) ∧ φ2 implies KB (cid:22) (φ1 ∧ φ2).(U6) If KB (cid:22) φ1 implies φ2 and KB (cid:22) φ2 implies φ1, then KB (cid:22) φ1 ≡ KB (cid:22) φ2.(U7) If KB is complete, then (KB (cid:22) φ1) ∧ (KB (cid:22) φ2) implies KB (cid:22) (φ1 ∨ φ2).(U8) (KB1 ∨ KB2) (cid:22) φ ≡ (KB (cid:22) φ1) ∨ (KB (cid:22) φ2).Besides these postulates for update, Katsuno and Mendelzon have reformulated the AGM postulates for the case of beliefbase revision in propositional logic:(R1) KB (cid:4) φ implies φ.(R2) If KB ∧ φ is satisfiable, then KB (cid:4) φ ≡ KB ∧ φ.(R3) If φ is satisfiable, then KB (cid:4) φ is satisfiable.(R4) If KB1 ≡ KB2 and φ1 ≡ φ2, then KB(cid:4)φ1 ≡ KB2 (cid:4) φ2.(R5) (KB (cid:4) φ1) ∧ φ2 implies KB (cid:4) (φ1 ∧ φ2).(R6) If (KB (cid:4) φ1) ∧ φ2 is consistent, then KB (cid:4) (φ1 ∧ φ2) implies (KB (cid:4) φ1) ∧ φ2.4.2.1. Interpretation of postulatesAs for an interpretation of these postulates in our setting, we may take the subsumption relation between an actiondescription and a set of causal laws for characterizing implication (and thus equivalence).Lemma 1 (Equivalence). Let D1 and D2 be action descriptions over a signature L = (cid:7)F, A(cid:8). Suppose that for every causal law l over L,it holds that D1 subsumes l iff D2 subsumes l. Then T (D1) = T (D2).Proof. Let T (D1) = (cid:7)S1, V 1, R1(cid:8) and T (D2) = (cid:7)S2, V 2, R2(cid:8). Towards a contradiction first suppose that S1 (cid:16)= S2. W.l.o.g., as-sume that s is a state in S1 such that s /∈ S2. Consider an arbitrary fluent F , and let ¯F denote ¬F if F is true in s, and Fotherwise. Then, D1 does not subsume l = caused ¯F if¬G, whereas D2 trivially subsumes l, a contra-s(G)=t G ∧(cid:5)(cid:8) ∈ R1diction. Hence, S1 = S2 holds, and therefore also V 1 = V 2. Next, suppose R1 (cid:16)= R2, and w.l.o.g. assume that (cid:7)s, A, sand (cid:7)s, A, s, and F otherwise. Then, D1does not subsume(cid:5)(cid:8) /∈ R2. Again consider an arbitrary fluent F , and let ¯F denote ¬F if F is true in ss(G)= f(cid:6)(cid:6)(cid:5)l = caused ¯F if(cid:4)(cid:4)(cid:4)(cid:4)(cid:4)(cid:4)G ∧¬G afterHa ∧¬Ha ∧H s ∧¬H s,Ha∈ Awhereas D2 trivially subsumes l, a contradiction. Therefore R1 = R2 holds as well. This proves the claim. (cid:3)s(H s)= fHa∈A\ As(H s)=ts(cid:5)(G)= fs(cid:5)(G)=tClosing the language under conjunction is also no problem, since an action description can be regarded as the con-junction of its causal laws. However, the meaning of negation (and disjunction) of causal laws and action descriptions isambiguous and undefined. Therefore, we refrain from an interpretation of postulates (U7) and (U8).10 Hansson’s [33] postulates for contraction would, in style of Levi Identity give rise to revision via contraction and expansion; however, this requires theuse of negation, which we lack here.1186T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–1221Another difficulty arises from the fact that the new information to be incorporated into our action description is char-acterized by syntactically and semantically different entities, namely causal laws and constraints. Naturally, KB implies φmight be understood component-wise as KB subsumes the causal laws given by φ and KB satisfies the constraints givenby φ.Given these considerations, we paraphrase the postulates as follows:(R1), (U1)(R2)(U2)(R3)(U3)(cid:5)If Dis a solution to (D, I, C, (cid:2)C ), then DIf D ∪ I is consistent and D ∪ I |(cid:6) C , then T (D(cid:5)) = T (D) for any solution DIf D subsumes I and D |(cid:6) C , then T (D(cid:5)(cid:5)If there exists an action description Dsuch that Dsolution to (D, I, C, (cid:2)C ).If D is consistent, and there exists an action description Dthen (D, I, C, (cid:2)C ) has a solution.is consistent, D(cid:5)(cid:5)(cid:5)subsumes I and D(cid:5)) = T (D) for any solution D(cid:5) |(cid:6) C .of (D, I, C, (cid:2)C ).(cid:5)of (D, I, C, (cid:2)C ).(cid:5)subsumes I and D(cid:5) |(cid:6) C , then there exists asuch that D(cid:5)is consistent, D(cid:5)subsumes I , and D(cid:5) |(cid:6) C ,(R4), (U4)If T (D1) = T (D2), T (I1) = T (I2), and C1 ≡ C2, then T (D(cid:5)1) = T (D(cid:5)2) for any solutions D(cid:5)1 and D(cid:5)2 of (D1, I1, C1,(cid:2)C ) and (D2, I2, C2, (cid:2)C ), respectively.(R5), (U5)If D(cid:5)is a solution to (D, I1, C1, (cid:2)C ) and D(cid:5) ∪ I2 subsumes l, then D(cid:5)(cid:5)subsumes l for some solution D(cid:5)(cid:5)of(R6)(U6)is a solution to (D, I1, C1, (cid:2)C ) and D(cid:5)(D, I1 ∪ I2, C1 ∪ C2, (cid:2)C ).If Dsubsumes l, for some solution DIf Dsuch that D(cid:5)2 subsumes I1 and D(cid:5)(cid:5)(cid:5)2(cid:5)1 is a solution to (D, I1, C1, (cid:2)C ) such that D|(cid:6) C1, then T (Dof (D, I1 ∪ I2, C1 ∪ C2, (cid:2)C ).(cid:5)1 subsumes I2 and D(cid:5)1) = T (D(cid:5)2).(cid:5) ∪ I2 is consistent and satisfies C2, then D(cid:5)(cid:5)subsumes l implies D(cid:5) ∪ I2(cid:5)1|(cid:6) C2, and D(cid:5)2 is a solution to (D, I2, C2, (cid:2)C )Obviously, (R1) and (U1) hold by definition, whereas (R2) holds for strongly non-minimizing (cid:2)C . For (U2), we alsoknow from Proposition 1 that it holds if D is consistent, in addition to a strongly non-minimizing (cid:2)C . Both conditions arenecessary.Concerning (R3) and (U3), they do not hold in general, unless D u ⊆ D(cid:5) ⊆ D ∪ I . In case of the latter they hold bydefinition; to wit the former, let D = D u = {caused F }, (cid:2)C = ⊂, I = {caused ¬F }, and C = ∅. Note that the property holdsif C = ∅ and D u = ∅.Proposition 2 (Solution existence). Let (D, I, C, (cid:2)C ) be an ADU problem, such that Dsome action description D(ii) C = ∅ and D u = ∅.is consistent, Dwith signature L. Then, there exists a solution to (D, I, C, (cid:2)C ) if (i) D u ⊆ D(cid:5)(cid:5)(cid:5) |(cid:6) C , and D(cid:5) ⊆ D ∪ I and D(cid:5)subsumes I for(cid:5) ∪ I |(cid:6) C , or(cid:5) ∪ I isProof. Note that consistency of D(cid:5) ∪ I is a pre-solution, which proves the existence(cid:5) ∪ I |(cid:6) C hold. Hence, Dconsistent. Furthermore, D u ⊆ Dof a solution. For (ii), observe that D u = ∅ ⊆ I ⊆ D ∪ I , and that I |(cid:6) C (since C = ∅). Hence, I is a pre-solution, which provesthe existence of a solution. (cid:3)subsumes I implies that I is consistent. In Case (i) this implies that D(cid:5)and that D(cid:5) ∪ I ⊆ D ∪ I and D(cid:5)Irrelevance of Syntax (R4/U4) does not hold, even for (cid:2)C = ⊂ and C = ∅: Consider D1 = {caused F , caused ¬F }, D2 ={caused G, caused F if G, caused ¬F if G}, and I1 = I2 = ∅.We remark, that the above counterexample is a canonical one, in the sense that I1 = I2 = ∅ and C = ∅, however withinconsistent D1 and D2. Note, that is easily modified to a counterexample where D1 and D2 are consistent (and, for instance,I1 and I2 are nonempty).Property (R5), (U5) holds if just consistency is required (C = ∅), D(cid:5) ∪ I2 is consistent, and (cid:2)C is strongly non-minimizing. In general it fails as witnessed by: D = Dm = {caused F after A}, (cid:2)C = ⊂, I1 = {caused ¬F after A ∧ ¬F },(cid:5)(cid:5) = I1 ∪ I2 is the only solution ofI2 = {caused ¬F after A ∧ F }, and C = {SOMETIMES executable A}. In this case, D(D, I1 ∪ I2, C, (cid:2)C ) (since D ∪ I1 ∪ I2 does not satisfy C ). However, Ddoes not subsume caused F after A, which is the(cid:5) ∪ I2 is incon-case for D(cid:5)(cid:5) = I1 ∪ I2, which does not subsumesistent: Let D = Dm = {caused F }, (cid:2)C = ⊂, I1 = {caused G}, I2 = {caused ¬F }. Then, Dcaused F .(cid:5) = D ∪ I1. The property also does not hold for strongly non-minimizing (cid:2)C in case of C = ∅ if DSimilarly, (R6) holds if just consistency is required (C = ∅), and (cid:2)C is strongly non-minimizing. In general it fails: LetD = Dm = {caused F after A ∧ F }, (cid:2)C = ⊂, I1 = ∅, I2 = {caused F after A ∧ ¬F }, C1 = {SOMETIMES ¬executable A}, and(cid:5) ∪ I2 = D ∪ I2 does not subsume l, althoughC2 = ∅. Then, Dit is consistent and trivially satisfies C2.(cid:5)(cid:5) = I2, which subsumes l = caused ¬F after A ∧ F . However, D(cid:5)(cid:5)Proposition 3 (Unique consequence). Let (D, I1, ∅, (cid:2)C ) and (D, I1 ∪ I2, ∅, (cid:2)C ) be ADU problems, such that (cid:2)C is strongly non-minimizing w.r.t. L. If D(cid:5) ∪ I2 is a solution to (D, I1 ∪ I2, ∅, (cid:2)C ).is a solution to (D, I1, ∅, (cid:2)C ) and D(cid:5) ∪ I2 is consistent, then D(cid:5)Proof. Obviously Da contradiction assume that there is a consistent action description D(cid:5) ∪ I2 is a pre-solution of (D, I1 ∪ I2, ∅, (cid:2)C ), since it is consistent and trivially satisfies C = ∅. Towards(cid:5)(cid:5) ⊆(cid:5)(cid:5)and D u ∪ I1 ∪ I2 ⊆ D(cid:5) ∪ I2) (cid:2)C Dsuch that (D(cid:5)(cid:5)T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–12211187(cid:5)). Then,D ∪ I1 ∪ I2. Then, since (cid:2)C is strongly non-minimizing w.r.t. L, we conclude that (D(cid:5) ⊂ D1. Furthermore, D1 is consistent (because satisfaction of static laws is monotone) and trivially satisfies C , i.e., D1 is aD(cid:5) (cid:2)C D1. Thispre-solution to (D, I1, ∅, (cid:2)C ). Because (cid:2)C is strongly non-minimizing w.r.t. L, it follows from D(cid:5) ∪ I2 is a solution tocontradicts the assumption that D(D, I1 ∪ I2, ∅, (cid:2)C ). (cid:3)is a solution to (D, I1, ∅, (cid:2)C ). Therefore, D(cid:5) ⊂ D1 that Dcannot exist, i.e., D. Let D1 = D(cid:5) ∪ I2) ⊂ D(cid:5)(cid:5) \ (I2 \ D(cid:5)(cid:5)(cid:5)(cid:5)(cid:5)Eventually, (U6) fails to hold even for strongly non-minimizing (cid:2)C if just consistency is required C = ∅: Let D = ∅,(cid:2)C = ⊂, I1 = {caused F after A ∧ F }, I2 = {caused F after A}, and C1 = C2 = ∅. Then I1 subsumes I2 and vice versa, butT (I1) (cid:16)= T (I2).4.2.2. DiscussionSumming up, we observe that even in the simple setting without unmodifiable laws (D u = ∅), without constraints (C =∅), and with set inclusion as preference relation ((cid:2)C = ⊂), not all postulates are satisfied. Concerning the revision postulates,apart from an additional consistency requirement for solution existence in R5, the only postulate that completely fails isIrrelevance of Syntax (R4/U4). This is intuitive, however, given that the causal information in an action description dependson its syntactical representation in terms of causal laws. While different sets of causal laws, i.e., knowledge bases, mayrepresent the same transition diagram, when (the same) new information is incorporated, this no longer needs to be thecase.Concerning the update postulates, in addition to the failure of (U4), postulate (U2) does not hold in general. The reasonis that solutions must be consistent, a property which has been discussed as one of the discriminating properties betweenupdate and revision. In this respect, our approach certainly acts like a revision operator. Moreover, (U6) fails to hold evenin this simple setting.Let us turn to more sophisticated ADU problems, where more than (static) consistency is required for solutions, anddynamic requirements need to hold after changing the knowledge base. Recall that in general such requirements cannot beexpressed in terms of causal laws. (With the latter, one can represent action domains that satisfy the respective requirement,which would amount to specify the solution as the new information to be incorporated, however, rather than expressing therequirement itself.) As soon as dynamic requirements can be demanded (C (cid:16)= ∅), several postulates cease to hold: (R3), (U3),(R5), (U5), and (R6). For (R3) and (U3), the reason is that the solution space is constrained to causal laws occurring in D ∪ I(which we consider a reasonable assumption for practical change operations in our setting). In case of (R5), (U5), and (R6),which are related to the supplementary AGM postulates (i.e., AGM postulates K∗7 and K∗8 [57]), the simple counterexamplesreveal that the main reason for this failure is due to the non-monotonicity of the action language and that it is ratherindependent of the problem definition.4.3. Disjoint factorizationWe next consider a structural property of solutions and pre-solutions, which can be exploited for a syntactical decompo-sition of an ADU problem, in a divide-and-conquer manner. Because of the involved semantics of transitions and causation,in general some prerequisites are needed.Definition 5 (NOP). We say that an action description D has NOP, if T (D) has either (i) a transition (cid:7)s, ∅, s(cid:8) for some state s,or (ii) for every state s, there exists a transition (cid:7)s, ∅, s(cid:5)(cid:8).Notice that NOP is a very natural property that often applies, in particular for time-driven domains, where passage oftime causes (cid:7)s, ∅, s(cid:8) by inertia, usually for all states s.LD the part of it which appears in any action description D.The following lemma is the key for our disjoint factorization result. For any action signature L = (cid:7)F, A(cid:8), we denote byLemma 2. Let T (D i) = (cid:7)S i, V i, R i(cid:8) for action descriptions D i , i = 0, 1, such that Lthe following hold:D0 ∩ LD1 = ∅. Let T (D0 ∪ D1) = (cid:7)S, V , R(cid:8). Then(i) S = {s0 ∪ s1 | s0 ∈ S 0, s1 ∈ S 1};(ii) if R0 (cid:16)= ∅ and R1 (cid:16)= ∅ then, for (cid:7)s0D0 , A ∩ L(iii) for (cid:7)s, A, s(cid:5)(cid:8) ∈ R, (cid:7)s ∩ L0, A0, s0D0 , s1(cid:5) ∩ L(cid:8) ∈ R0 and (cid:7)s10, A1, s1D0 (cid:8) ∈ R0 and (cid:7)s ∩ L(cid:8) ∈ R1, (cid:7)s00D1 , A ∩ L1∪ s1D1 , s0, A0 ∪ A1, s0(cid:5) ∩ LD1 (cid:8) ∈ R1.1∪ s11(cid:8) ∈ R;(cid:8) ∈ R. Suppose this is not the case. Then one of the following two cases holds:Proof. (i) is trivial. We prove (ii) and (iii) as follows.s01(ii) Suppose that R0 (cid:16)= ∅ and R1 (cid:16)= ∅. Take any (cid:7)s0∪ s11(1) For some dynamic law d of the form (5) in D0 ∪ D1, s00D1 = ∅, s0W.l.o.g., suppose that d is in D0. Then, since L(cid:8) /∈ R0, which is a contradiction.that (cid:7)s00, A0, s0D0 ∩ L100, A0, s01(cid:8) ∈ R0 and (cid:7)s10, A1, s11(cid:8) ∈ R1. We show that (cid:7)s00∪ s10, A0 ∪ A1,∪ A0 ∪ A1 satisfies H , and s01∪ s10∪ A0 satisfies H and s01 does not satisfy G ∧ L.1 does not satisfy G ∧ L. This implies∪ s11188T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–1221∪ s1(2) s022 is another state (different from s01) that satisfies the heads of all static laws (4) in D0 ∪ D1 for which s0∪ s100∪ A0 ∪ A1 implies that s0∪ s1satisfies G, and of every dynamic law (5) in D0 ∪ D1, such that satisfaction of H by s0101D0 ∩ Lsatisfies G. Then (since each causal law is in D0 or D1 but not in both, due to L2 satisfiesthe heads of all static laws (4) in D0 for which s00 satisfies G, and of every dynamic law (5) in D0, such that satisfaction of(cid:8) /∈ R1. (Symmetrically, the claim holds for D1.) This isH by s00again a contradiction.∪ s10D1 = ∅), it follows that, s01 satisfies G. This implies that (cid:7)s0∪ A0 implies that s00, A0, s0∪ s111(iii) Take any (cid:7)s, A, s(cid:5)(cid:8) ∈ R. W.l.o.g., suppose that (cid:7)s ∩ LD0 , A ∩ LD0 , s(cid:5) ∩ LD0 (cid:8) /∈ R0. Then one of the following two casesholds:Since L(2) s0D1 = ∅, s ∪ A satisfies H and s(1) For some dynamic law d of the form (5) in D0, s ∩ LD0 ∪ A ∩ LD0 ∩ Ldoes not satisfy G ∧ L. This implies (cid:7)s, A, s2 is another state that satisfies the heads of all static laws in D0 for which s ∩ L(cid:5)(cid:8) /∈ R, a contradiction.D0 satisfies G, and of every dynamiclaw (5) in D1 such that satisfaction of H by s ∩ LD0 satisfies G. Consider sD1 .D0 ∩ LDue to (i) above, ssatisfies the heads of all static laws (4) inD0 ∪ D1 for which s satisfies G, and of every dynamic law (5) in D0 ∪ D1, such that satisfaction of H by s ∪ A implies that(cid:5)sD0 ∪ A ∩ LD1 = ∅, the following holds: s(cid:5)(cid:8) /∈ R, which is a contradiction. (cid:3)satisfies G. This implies that (cid:7)s, A, sD0 does not satisfy G ∧ L.(cid:5)(cid:5) ∈ S. Moreover, since LD0 satisfies H , and sD0 implies that s(cid:5)(cid:5) = s02(cid:5) ∩ L(cid:5)(cid:5)(cid:5) ∩ L∪ s(cid:5)(cid:5) ∩ LIntuitively, this lemma describes how the transition diagram of an action description can be composed, if the actiondescription consists of two syntactically disjoint parts. It can thus be exploited to decompose a given action description intodisjoint parts as in our next result. For such a decomposition to be faithful in the sense that solutions to the respective ADUsubproblems can be composed to yield a solution to the original ADU problem, care has to be taken with respect to twoaspects: First, an empty set of transitions shall not compromise the approach, and thus has to be avoided, in the presenceof dynamic constraints (cf. Lemma 2(ii)). This can be guaranteed by the NOP property, which will in fact be sufficientfor composing pre-solutions. Second, for composing solutions the composed preference relation needs to comply with thepreferences of the subproblems. Stated from the viewpoint of decomposition, the preference relation must be factorizable.Towards a formal treatment of these ideas, we need further terminology. We call (L0, L1), where Li = (cid:7)Fi, Ai(cid:8), i = 0, 1,a partitioning of a signature L = (cid:7)F, A(cid:8), if (F0, F1) and (A0, A1) are partitioning of F and A, respectively. We first definedecompositions of action descriptions and constraints.Definition 6 (AD/constraint decomposition). Suppose (L0, L1) is a partitioning of a signature L = (cid:7)F, A(cid:8), and let X be eitheran action description or a set of constraints over L. Then a partitioning ( X 0, X 1) of X is called a decomposition of X withX i ⊆ Li , for i = 0, 1. Furthermore, X is decomposable with respect to (L0, L1), if such a decompositionrespect to (L0, L1), if Lexists.Based on this, we next define the notion of a near-decomposition of an ADU problem, which splits the action descriptionand the constraints in separate parts while disregarding preference.Definition 7 (Near-decomposition). Let (D, I, C, (cid:2)C ) be an ADU problem with signature L, and let (D0, D1), (I 0, I 1), and(C 0, C 1) be decompositions of D, I , and C , respectively, with respect to a partitioning (L0, L1) of L. Then, ((D0, I 0, C 0),(D1, I 1, C 1)) is a near-decomposition of (D, I, C, (cid:2)C ) with respect to (L0, L1).The following theorem now formally shows that the pre-solutions of an ADU problem can be obtained from those ofa near-decomposition, provided that some ramifying conditions hold. We say that a constraint c occurs positively (resp.negatively) in a set C of constraints, if c occurs in the scope of an even (resp. odd) number of negations in a constraint in C .Theorem 1 (Disjointness). Given an ADU problem (D, I, C, (cid:2)C ) with signature L, let ((D0, I 0, C 0), (D1, I 1, C 1)) be a near-decomposition with respect to a partitioning (L0, L1) of L, and let (cid:21)Ci be an arbitrary preference ordering for action descriptionsover Li , i = 0, 1. Then the following holds:(i) Let X i be a pre-solution to (D i, I i, C i, (cid:2)Then X 0 ∪ X 1 is a pre-solution to (D, I, C, (cid:2)C ).C i ) such that X i has NOP if some dynamic constraint occurs negatively in C 1−i , for i = 0, 1.(ii) Let X be a pre-solution to (D, I, C, (cid:2)C ), and let ( X 0, X 1) be any partitioning of X with respect to (L0, L1) such that X i ⊆ D i andX i has NOP if some dynamic constraint occurs positively in C 1−i , for i = 0, 1. Then, X i is a pre-solution to (D i, I i, C i, (cid:2)C i ), fori = 0, 1.Proof. Let T ( X 0 ∪ X 1) = (cid:7)S, V , R(cid:8) and let T ( X i) = (cid:7)S i, V i, R i(cid:8). We first show for any static constraint c, that X 0 ∪ X 1, s |(cid:6) cif c ∈ C i , X i, si |(cid:6) c, and s ∩ Li = si . Since for each fluent literal L in c, si |(cid:6) L implies s |(cid:6) L, and since c ∈ LC i ⊆ Li (i.e.,c contains only fluent literals from Li ), the claim follows. Conversely, for any static constraint c, it holds that X i, si |(cid:6) c ifc ∈ C i , X 0 ∪ X 1, s |(cid:6) c, and si = s ∩ Li . Again due to the fact that every fluent literal L in c is from Li , we conclude thatC i ⊆ Li that there existss |(cid:6) L implies si |(cid:6) L, which proves the claim. Therefore, we conclude for any static constraint c ∈ LT. Eiter et al. / Artificial Intelligence 174 (2010) 1172–12211189a state s ∈ S such that X 0 ∪ X 1, s |(cid:6) c iff there exists a state si ∈ S i such that X i, si |(cid:6) c. Moreover by the structure of S (cf.Lemma 2(i)), X 0 ∪ X 1, s |(cid:6) c for all s ∈ S iff X i, si |(cid:6) c for all si ∈ S i . Hence, if C just contains static constraints, then X 0 ∪ X 1satisfies C iff X 0 satisfies C 0 and X 1 satisfies C 1.We next consider dynamic constraints c of the form necessarily Q after A1; . . . ; An or ¬necessarily Q after A1; . . . ; Anand show the following: (1) X 0 ∪ X 1, s |(cid:6) c if c ∈ C i , X i, si |(cid:6) c, s ∩ Li = si , and X 1−i has NOP if c is negative, or Q containsa negative dynamic constraint; (2) X i, si |(cid:6) c if c ∈ C i , X 0 ∪ X 1, s |(cid:6) c, si = s ∩ Li , and X 1−i has NOP if c is positive, or Qcontains a positive dynamic constraint. We proceed by induction on the nesting depth k of the constraint.(cid:16)|(cid:6) Q . Since X 1−i has NOP, there exists a sequence of n + 1 states, such that h1−i = s1−i, ∅, s1−iBase case (k = 0): (1) Let c be positive and towards a contradiction consider a state s ∈ S, such that s ∩ Li = si andthere exists a history h = s, A1, s1, . . . , sn−1, An, sn, such that sn (cid:16)|(cid:6) Q . By Lemma 2(iii), every transition of the history hi =si, A1, s1 ∩ Li, . . . , sn−1 ∩ Li, An, sn ∩ Li is in R i . Furthermore, sn (cid:16)|(cid:6) Q implies sn ∩ Li (cid:16)|(cid:6) Q because c ∈ X i and Q containsonly static constraints. Contradiction. If c is negative, then there exists a history hi = si, A1, sin such thatsiis annhistory of X 1−i . By Lemma 2(ii), h = si ∪ s1−i, A1, . . . , An, si(cid:16)|(cid:6) Q impliessinn−1, An, si, . . . , s1−iis a history of X 0 ∪ X 1. Furthermore, sin(cid:16)|(cid:6) Q because c ∈ X i and Q contains only static constraints. Contradiction. This proves (1) for k = 0.∪ s1−in(2) Let c be positive and towards a contradiction consider a state si ∈ S i , such that si = s ∩ Li and there exists a history(cid:16)|(cid:6) Q . Since X 1−i has NOP, there exists a sequence of n + 1 states, such thath = si, A1, si1, . . . , sih1−i = s1−i, ∅, s1−iis a history ofX 0 ∪ X 1. Furthermore, si(cid:16)|(cid:6) Q because c ∈ X i and Q contains only static constraints. Contradiction. Ifnc is negative, then there exists a history h = s, A1, s1, . . . , sn−1, An, sn, such that sn (cid:16)|(cid:6) Q . By Lemma 2(iii), every transition ofthe history hi = si, A1, s1 ∩ Li, . . . , sn−1 ∩ Li, An, sn ∩ Li is in R i . Furthermore, sn (cid:16)|(cid:6) Q implies sn ∩ Li (cid:16)|(cid:6) Q because c ∈ X iand Q contains only static constraints. Contradiction. This proves (2) for k = 0.is a history of X 1−i . By Lemma 2(ii), h = si ∪ s1−i, A1, . . . , An, sin−1, ∅, s1−in(cid:16)|(cid:6) Q implies sinn−1, An, si, . . . , s1−in, such that sinn−1, ∅, s1−i1, . . . , si∪ s1−in∪ s1−in∪ s1−in11nnInduction step: Let (1) and (2) be true for dynamic constraints of nesting depth at most k − 1 and consider a dynamicconstraint c of nesting depth k. Then, Q contains only static constraints and dynamic constraints of nesting depth at mostk − 1. Thus, (1) and (2) also hold for c, as follows easily by the arguments of the base case, replacing justifications by the factthat Q contains only static constraints with a respective justification that Q contains only static constraints and dynamicconstraints of nesting depth at most k − 1.So far, we have shown that (1) and (2) hold for any open constraint. By the structure of S (cf. Lemma 2(i)), we concludefor any existential or universal constraint c that X 0 ∪ X 1 |(cid:6) c if c ∈ C i , X i |(cid:6) c, and X 1−i has NOP if c contains a negativedynamic constraint, as well as that X i |(cid:6) c if c ∈ C i , X 0 ∪ X 1 |(cid:6) c, and X 1−i has NOP if c contains a positive dynamicconstraint. Therefore, X i |(cid:6) C i and X 1−i has NOP if C i contains a negative dynamic constraint, for i ∈ {0, 1}, implies X 0 ∪X 1 |(cid:6) C . Conversely, X 0 ∪ X 1 |(cid:6) C and X 1−i has NOP if C i contains a positive dynamic constraint implies X i |(cid:6) C i , fori ∈ {0, 1}.We now proceed with the proof of the theorem. Case (i): Let X i be a pre-solution to (D i, I i, C i, (cid:2)C i ), for i = 0, 1. Supposethat, for i = 0, 1, X i has NOP if some dynamic constraint occurs negatively in C 1−i . We show that X 0 ∪ X 1 is a pre-solutionto (D, I, C, (cid:2)C ). By Lemma 2(i), X 0 ∪ X 1 is consistent, since X 0 and X 1 are consistent. Furthermore, D0∪ I 0 ∪ I 1 ⊆u∪ I 1 ⊆ X 1 ⊆ D1 ∪ I 1, respectively. Eventually, X 0 |(cid:6) C 0 andX 0 ∪ X 1 ⊆ D ∪ I follows from D0uX 1 |(cid:6) C 1 implies X 0 ∪ X 1 |(cid:6) C . This proves that X 0 ∪ X 1 is a pre-solution to (D, I, C, (cid:2)C ).∪ I 0 ⊆ X 0 ⊆ D0 ∪ I 0 and D1uCase (ii): Let X be a pre-solution to (D, I, C, (cid:2)C ), and let ( X 0, X 1) be a partitioning of X such that X 0 ⊆ D0 and X 1 ⊆ D1.Suppose that, for i = 0, 1, X i has NOP if some dynamic constraint occurs positively in C 1−i . We prove that for i = 0, 1, X iis a pre-solution to (D i, I i, C i, (cid:2)C i ). Since X is consistent, also X 0 and X 1 are consistent. To see this, observe that w.l.o.g.,if X 0 is inconsistent, then the static laws in X 0 are unsatisfiable, which implies X is unsatisfiable as well, a contradiction.Moreover, D u ∪ I ⊆ X ⊆ D ∪ I implies D0∪ I 1 ⊆ X 1 ⊆ D1 ∪ I 1. Finally, X 0 ∪ X 1 |(cid:6) C impliesuX 0 |(cid:6) C 0 and X 1 |(cid:6) C 1. Thus, X 0 and X 1 are near solutions to (D0, I 0, C 0, (cid:2)∪ I 0 ⊆ X 0 ⊆ D0 ∪ I 0 and D1u∪ D1uC 0 ) and (D1, I 1, C 1, (cid:2)C 1 ), respectively. (cid:3)Informally, the NOP property in Theorem 1 is needed to ensure that the transition diagrams of pre-solutions to the sub-problems can be “combined.” As already mentioned above, this is only necessary in the presence of dynamic constraints.For a full decomposition of an ADU problem, we need beyond a near decomposition also a factorization of the preferencerelation, which is formally defined as follows.Definition 8 (Preference factorization). Let (cid:2)C be a preference relation for action descriptions over signature L, and letC i for action descriptions over Li , i = 0, 1, is a(L0, L1) be a partitioning of L. A pair ((cid:2)C 1 ) of preference relations (cid:2)(cid:5)over L that are decomposable with respect tofactorization of (cid:2)C with respect to (L0, L1), if for any action descriptions D, D(L0, L1), it holds that D (cid:2)C DC 1 D1 or DC 1 Dimplies that either D0 (cid:2)C 0 D0 ∧ D1 (cid:2)(cid:5)0 ∧ DC 0 , (cid:2)C 0 D(cid:5)0 (cid:16)(cid:2)(cid:5)1 (cid:16)(cid:2)(cid:5)1.(cid:5)Note that preference by strict subset inclusion ((cid:21)C = ⊂) is always factorizable (e.g., taking ⊂ as the preference relationsof the factorization). We also remark that if the set of constraints C is decomposable with respect to (L0, L1), then theconstraint weight preference <weightqis factorizable, provided that weights are non-negative (for instance, taking the sameweights for the factorization).A full decomposition of an ADU problem is then as follows.1190T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–1221Definition 9 (ADU decomposition). A decomposition of a given ADU problem (D, I, C, (cid:2)C ) with respect to a partitioning(L0, L1) of its signature L is a pair ((D0, I 0, C 0, (cid:2)C 0 ), (D1, I 1, C 1, (cid:2)C 1 )) such that ((D0, I 0, C 0), (D1, I 1, C 1)) is a near-C 1 ) is a factorization of (cid:2)C .decomposition of (D, I, C, (cid:2)C ) and ((cid:2)C 0 , (cid:2)The following result, which is the main result of this section regarding solutions of an ADU problem, is then easilyobtained from Theorem 1.C 1 )) be a decomposition of an ADU problem (D, I, C, (cid:2)C ) with respect to a parti-Theorem 2. Let ((D0, I 0, C 0, (cid:2)tioning (L0, L1) of its signature L. Suppose that either (i) no dynamic constraint occurs in C , or (ii) no dynamic constraint occursin C 1. If X i is a solution to (D i, I i, C i, (cid:2)C i ) for i = 0, 1, where in case (ii) X 1 has NOP, then X 0 ∪ X 1 is a solution to (D, I, C, (cid:2)C ).Furthermore, in case (i) every solution to (D, I, C, (cid:2)C ) can be represented in this form.C 0 ), (D1, I 1, C 1, (cid:2)Item (i) states that we can fully decompose an ADU into two components, and that all solutions can be obtained bya simple combination of the solutions of the individual components. However, this works in general only in absence ofdynamic constraints (combining the transition graphs of the components is then unproblematic). Item (ii) accounts forpossible dynamic constraints in one component, which are unproblematic as long as solutions of the other have NOP.However, not all solutions can be composed from solutions of the components in general.Example 4. Consider the ADU problem (D ∪ DSince X 0 = D ∪ I \ {caused TvON if PowerON} is a solution to (D, I, C, ⊂) (cf. Example 1), X 1 = Dto (D{caused TvON if PowerON} is a solution to (D ∪ D(cid:5), ∅, ∅, ⊂) (cf. Example 3), and D(cid:5), I, C, ⊂), with D,(cid:5), I, C, ⊂).I , and C as in Example 1, and Dhas NOP (which is easily verified), by Theorem 2(ii) X 0 ∪ X 1 = (D ∪ Das in Example 3.is (the unique) solution(cid:5) ∪ I) \(cid:5)(cid:5)(cid:5)Example 5. Consider the ADU problem (D ∪ D(cid:5) ∪ I) \ {caused TvON if PowerON} is a solution to (D ∪ DExample 3. Again X 0 ∪ X 1 = (D ∪ DI \ {caused TvON if PowerON} is a solution to (D, I, C, <weightq ) (cf. Example 2), and as X 1 = D(Dto (D, I, C, <weightq ). Moreover, setting the weight of constraint (13)as in(cid:5), I, C, <weightq ), as X 0 = D ∪is (the unique) solution to(cid:5) ∪ I is a different pre-solution to this ADU problem since D u ∪ I is a pre-solution(cid:5), I, C, <weightq ), with D, I , C , and weightq as in Example 2, and D(cid:5), ∅, ∅, <weightq ). By Theorem 1, D u ∪ D(cid:5)(cid:5)ALWAYS holds PowerON ∧ TvON ⊃¬necessarily (holds TvON) after {PushPBTV }to 0 (which amounts to assigning the preferred constraints a ‘don’t care’ status), it would be another solution.Theorem 1 provides a basis for decomposing an ADU into smaller ADUs that can be solved in a divide-and-conquermanner,11 and Theorem 2 shows some possible exploitation. These results can be integrated into algorithms for computingsolutions, which we consider in Section 6 below; their effectiveness is demonstrated on a practical example in Section 7.2.Finally, note that for our exemplary preference relations ⊂ and <weightqwith non-negative weights, the benign properties ofmonotonicity and non-minimization with respect to L, carry over to their standard factorizations (given by restricting therelation to the relevant domain) and can be recursively exploited.5. Complexity analysisIn this section, we investigate the computational complexity of relevant tasks for solving an ADU problem, includingto decide whether a solution exists and whether a given action description is a solution. The complexity of these tasksstrongly depends on the complexity of deciding whether a given action description satisfies a set of (obligatory) constraints(i.e., D |(cid:6) Co), and whether an action description is preferred over another action description under the given preferencerelation (i.e., D (cid:2)C D).(cid:5)We first consider the worst-case complexity of the above mentioned subproblems as a parameter and derive upperbounds (in terms of membership results) for deciding whether an ADU problem has a solution, and for checking whetheran action description is a solution to an ADU problem in a generic setting. We then ‘instantiate’ this generic setting byconsidering different classes (restricted sets) of constraints which yield different complexities for deciding D |(cid:6) Co , and bystudying concrete preference relations for which the complexity of deciding D (cid:2)C Ddiffers. In particular, we provide com-pleteness results for the syntactic preference ⊂ (for which deciding D (cid:2)C Dis polynomial) and for the semantic preference(cid:5)<weightqranges up to PSPACE) for the various classes of constraints considered. Note thatthe class of admitted constraints is the main source of complexity in most concrete settings, in particular when decidingD (cid:2)C Dreduces to deciding constraint fulfillment.(for which deciding D (cid:2)C D(cid:5)(cid:5)(cid:5)11 For similar and stronger results in classical propositional logic see [54].T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–12211191Table 1Complexity of deciding solution existence and solution checking, depending on the complexity of the relevant sub-problems (completeness results; hardness holds for fixed preference relation (cid:2)C ).D |(cid:6) Co & D (cid:2)C D(cid:5)in PSPACEin (cid:5)Pi(i > 1)in PSolution existenceSolution checkingPSPACEΣ PiNPPSPACEΠ PiDP5.1. Generic upper boundsOur main result on generic upper bounds, which however also gives the general picture of more precise complexitycharacterizations, is summarized in Table 1. Recall that PSPACE is the class of decision problems that can be decided by a(deterministic) Turing machine using space at most polynomial in the length of the input. PSPACE contains the so-called= Σ P= Π Ppolynomial hierarchy, a sequence of classes defined as (cid:5)P, and000Π P. Finally, DP is the class of decision problems whose yes instances are characterized by the “conjunction” ofan NP problem and an independent coNP problem. The prototypical such problem is SAT-UNSAT, whose yes instances arepairs (F , G) of propositional formulas such that F is satisfiable and G is unsatisfiable; this problem is also complete for DP .For a background in complexity theory, we refer to [53].= P, and for i (cid:3) 0, by (cid:5)P= coNPΣ P= NPΣ P= PΣ P, Σ Pi+1i+1i+1iiiInformally, the results show that modulo the cost of deciding the satisfaction of constraints and preference, the com-plexity of solution existence and checking increases at most by one level in the polynomial hierarchy, which is due tothe exponential search space for a solution respectively a better solution candidate, which might be non-deterministicallyguessed. Since the search space can be traversed in polynomial space, there is no increase in complexity in the most generalcase.We next formally establish Table 1. Given an ADU problem (D, I, C, (cid:2)C ), let Ccheck denote the class of problems of(cid:5) ⊆ D ∪ I . Similarly, let Pcheck denote the class of problems of deciding whether(cid:5) |(cid:6) Co for any D u ∪ I ⊆ Ddeciding DD1 (cid:2)C D2 holds, for action descriptions D u ∪ I ⊆ D i ⊆ D ∪ I and i ∈ {1, 2}.Theorem 3. Deciding whether a given ADU problem (D, I, C, (cid:2)C ) has a solution (or a pre-solution) is(i) in PSPACE if Ccheck is in PSPACE,if Ccheck is in (cid:5)P(ii) in Σ Pi(iii) in NP if Ccheck is in P.i and i > 1,Given an ADU problem (D, I, C, (cid:2)C ) together with an action description D(cid:5), deciding whether D(cid:5)is a solution for it is(a) in PSPACE if Ccheck and Pcheck are in PSPACE,(b) in Π Pif Ccheck and Pcheck are in (cid:5)Pi(c) in DP if Ccheck and Pcheck are in P.i and i > 1,(cid:5)Proof. Let D = D u ∪ Dm. In order to decide whether (D, I, C, (cid:2)C ) has a solution, we can guess a pre-solution DD u ∪ I ⊆ Dotherwise in polynomial time (iii), respectively with the help of a Σ P(cid:5) ⊆ D u ∪ I , along with a state s for D(to witness consistency), and check Dsuch that(cid:5) |(cid:6) Co in polynomial space (i),i−1-oracle. This proves (i), (ii), and (iii)., or Dis a solution,together with a state sAs for deciding whether a given D(cid:5) (cid:16)⊆ D ∪ I . We also check whether Dlet us consider the complementary problem. We can non-and proceed as follows. We check in polynomial time whether(cid:5)is inconsistent (a) in polynomial space, respectively (b) with a(cid:5) (cid:16)|(cid:6) Co can be done in polynomial space in Case (a), and in polynomial(cid:5)(cid:5) ⊆ D ∪ I and if Di−1-oracle in Case (b). Furthermore, we check in polynomial time whether D u ∪ I ⊂ Dis(a) in PSPACE, and (b) in). Two further checks decide whether Di−1-oracle. Thus, the complementary problem is (a) in PSPACE, respectively (b) in Σ P,deterministically guess DD u ∪ I (cid:16)⊆ Dsingle call to an NP-oracle. Deciding whether Dtime with a Σ Pconsistent (whether spolynomial time with the help of a Σ Pproving (a) and (b).(cid:5)(cid:5) |(cid:6) Co and Dis state of D(cid:5) (cid:2)C D(cid:5)(cid:5)(cid:5)(cid:5)(cid:5)(cid:5)(cid:5)(cid:5)(cid:5)(cid:5)(cid:5)(cid:5)(cid:5)(cid:5)i(cid:5)For (c) we non-deterministically guess a state sdecide D u ∪ I ⊆ D(cid:5)(cid:5)complementary problem of guessing D(cid:5) (cid:2)C D(cid:5)(cid:5)s(cid:5)(cid:5) |(cid:6) Co , and Dwhich we use to check consistency in polynomial time. Also we(cid:5) ⊆ D u ∪ I in polynomial time. An independent coNP-check excludes more preferred pre-solutions, i.e., the(cid:5)(cid:5) ⊆ D ∪ I , consistency (whetherand checking D u ∪ I ⊂ Dtogether with a state s(cid:5)(cid:5)in polynomial time. This proves DP -membership for (c). (cid:3)is state of Dof D), D(cid:5)(cid:5)(cid:5)(cid:5)(cid:5)(cid:5)Before we turn our attention to ‘instantiating’ this general result for ADU problems with different classes (restrictedsets) of constraints and concrete preference relations, which will yield precise complexity characterizations in terms ofcompleteness results, we remark that to ease exposition, in the remainder of this section proofs are sketched, summarizingthe main arguments and constructions, while full proofs are given in Appendix A.1192T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–12215.2. Constraint fulfillmentAs outlined in the beginning of this section, one of the two important subtasks in solving ADU problems is checkingwhether a set of constraints is satisfied by an action description. This subtask has a major influence on the complexityof finding solutions of an ADU problem. Therefore, besides considering arbitrary constraints, we also investigate restrictedclasses of constraints. In particular, when the maximal nesting depth of dynamic constraints is fixed by an integer k, andwhen no dynamic constraints occur at all.Theorem 4. Given an action description D and a set C of constraints, deciding D |(cid:6) C is(i) PSPACE-complete in general,(ii) Θ P(iii) PNPk+3-complete if k is the maximal nesting depth of dynamic constraints in C , and(cid:24) -complete if C does not involve dynamic constraints.Here PNP(cid:24) means polynomial-time with a single parallel evaluation of calls to an NP oracle. Similarly for i > 1, Θ Piclass of problems that can be decided in polynomial time with parallel calls to a Σ Poften characterized by allowing O (log n) many oracle calls) [65].is thei−1 oracle (alternatively, this class isProof. Concerning (i) the result has been shown in [18]. Membership in Case (iii) follows from the fact that checking thetruth of a negated universal constraint of the form ¬ALWAYS Q , where Q is a conjunction of clauses over static constraintsof the form holds F or ¬holds F , is in NP. Hence, the complementary task, i.e., checking the truth of a positive universalconstraint, ALWAYS Q , is in coNP. Thus, D |(cid:6) c is decided in polynomial time with a single parallel evaluation of n NP-oraclecalls, given that n is the number of universal constraints in c. Similarly, one proves in Case (ii) by induction on the nestingdepth k, that D |(cid:6) c is decided in polynomial time with parallel Σ Pk+2-oracle calls.As for hardness, the problem in (iii) is reduced to the following PNP(cid:24) -hard decision version of Maximum CNF Satisfiabil-ity [40]: Given a Boolean formula F in conjunctive normal form (CNF) and an integer k, decide whether the maximum numberof clauses in F that can be simultaneously satisfied by an interpretation is 0 mod k. Consider a 3-CNF formula of the form(cid:6)i=1 Li,1 ∨ Li,2 ∨ Li,3, where Li, j , 1 (cid:2) i (cid:2) n, 1 (cid:2) j (cid:2) 3, is a literal over atoms X = { X1, . . . , Xm}, and the following actionndescription D1:caused Ci if Li,1,caused Ci if Li,2,caused ¬Ci if ¬Li,1 ∧ ¬Li,2 ∧ ¬Li,3,caused Ci if Li,3,1 (cid:2) i (cid:2) n(cid:7)caused F 1,1 if C1,caused F 1,0 if ¬C1,caused F i, j if Ci ∧ F i−1, j−1,caused ¬F i, j if ¬Ci ∧ F i−1, j−1,caused ¬F 1,1 if ¬C1,caused ¬F 1,0 if C1,(cid:7)caused F i, j if ¬Ci ∧ F i−1, j,caused ¬F i, j if Ci ∧ F i−1, j,(cid:7)2 (cid:2) i (cid:2) n, 1 (cid:2) j (cid:2) i2 (cid:2) i (cid:2) n, 0 (cid:2) j < i.Then D1 |(cid:6) ck iff the maximum number of clauses in F that can be simultaneously satisfied by an interpretation is 0 mod k,where ck is the following constraint:ALWAYS holds Fn,0 ∨SOMETIMES holds Fn,k ∧ ALWAYS (¬holds Fn,k+1 ∧ · · · ∧ ¬holds Fn,n) ∨. . .SOMETIMES holds Fn,lk ∧ ALWAYS (¬holds Fn,lk+1 ∧ · · · ∧ ¬holds Fn,n).For hardness in Case (ii), consider m Quantified Boolean Formulas (QBFs) Φl = Q 1 Xln El, 1 (cid:2) l (cid:2) m, wherej , 1 (cid:2) i, j (cid:2) n and 1 (cid:2) k, l (cid:2) m, are pairwise disjunct sets ofQ i = ∃ if i ≡ 1 mod 2 and Q i = ∀ otherwise, X kpropositional variables if i (cid:16)= j or k (cid:16)= l and El is Boolean formula over atoms in Xl = Xln, such that if Φl is false1then Φl+1, . . . , Φm are false, too. Deciding whether the maximum index o, 1 (cid:2) o (cid:2) m, such that Φo is true, is odd is Θ Pn+1-hard [65]. The problem of deciding D |(cid:6) c for a constraint c with nesting depth k of dynamic constraints is reduced to thisproblem, as follows.i and Xl∪ · · · ∪ Xl· · · Q n Xl1 Q 2 Xl2Let n = k + 2, 1 (cid:2) l (cid:2) m, and let the action description D2 consist of the following statements:T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–12211193(cid:7)caused F lcaused ¬F lcaused F lcaused ¬F li after Ai−1,i after Ai−1,i if F li if ¬F lj after Ai−1 ∧ F lj,j after Ai−1 ∧ ¬F lj,2 (cid:2) i (cid:2) n, F li∈ Xli(cid:8)2 (cid:2) i (cid:2) n, 1 (cid:2) j (cid:2) n, i (cid:16)= j, F lj∈ Xlj.(cid:9) (cid:10)Consider the constraint:(m−3)/2l=0(m−2)/2l=0co =(cid:10)(SOMETIMES f 2l+1 ∧ ALWAYS ¬ f 2l+2) ∨ gm if m is odd,(SOMETIMES f 2l+1 ∧ ALWAYS ¬ f 2l+2)otherwise,wheregm = SOMETIMES f m,f l = p1 N p1(cid:2)and. . . (pn−1 N pn−1 holds Elafter { An−1}) . . .(cid:3)after { A1},where N = necessarily, and where pi = ¬ if i is even and pi is void otherwise, for 1 (cid:2) i (cid:2) n − 1. Then, the maximum indexo such that Φo is true, is odd iff D2 |(cid:6) co. (cid:3)5.3. Solution existenceEquipped with these precise complexity characterizations of Ccheck for ADU problems of some classes of constraints,we aim to characterize exactly the complexity of the solution finding tasks for these classes of constraints and particularpreference relations. Notice that checking whether a solution exists is independent of the concrete preference relation andits computation. This leads to the following result.Theorem 5. Deciding whether a given ADU problem (D, I, C, (cid:2)C ) has a solution (or a pre-solution) is(i) PSPACE-complete in general,(ii) Σ P(iii) Σ P(iv) NP-complete if Co = ∅.k+3-complete, if k is the maximal nesting depth of dynamic constraints in Co ,2 -complete, if Co does not involve dynamic constraints, andProof. Membership follows from Theorems 3 and 4, and hardness in Case (i) follows from Theorem 4. For hardness inCase (ii), let n = k + 2 and let Φ = ∃Y Q 1 X1 · · · Q n Xn E be a QBF, where Q i = ∃ if i ≡ 0 mod 2 and Q i = ∀ otherwise.ConsiderD u = D2 ∪ {caused Y i after Ai−1 ∧ Y i, caused ¬Y i after Ai−1 ∧ ¬Y i | 2 (cid:2) i (cid:2) n},where D2 is the action description from the proof of Theorem 4 with l = 1, Dm = {caused Y i, caused ¬Y i | Y i ∈ Y }, I = ∅,C = Co ∪ C p with C p = ∅, and Co = {co}, whereco = ALWAYS p1 N p1. . .pn−1 N pn−1 holds E after { An−1}. . .after { A1},(cid:2)(cid:2)(cid:3)(cid:3)and where N = necessarily, and pi = ¬ if i is odd and void otherwise, for 1 (cid:2) i (cid:2) n − 1. Then, there exists a solution to theaction description update problem (D u ∪ Dm, I, C, (cid:2)C ) iff Φ is true.For (iii) let Φ = ∃Y ∀ X E and consider the action description update problem (D u ∪ Dm, I, C, (cid:2)C ), where D u = ∅, Dm ={caused Y i, caused ¬Y i | Y i ∈ Y }, I = ∅, and C = Co = {ALWAYS holds E}. Again, the action description update problem(D u ∪ Dm, I, C, (cid:2)C ) has a solution iff Φ is true.Finally, for (iv), let E be a Boolean formula over atoms Y and let us define D u = {caused Y 1 if ¬E, caused ¬Y 1 if ¬E},Dm = {caused Y i, caused ¬Y i | Y i ∈ Y }, I = ∅, and C = ∅. Then, (D u ∪ Dm, I, C, (cid:2)C ) has a solution iff E is satisfiable. (cid:3)This result can be instantiated with any preference relation and yields completeness results for deciding the existenceof a solution. When instantiated with our syntactic preference ⊂, a remarkable consequence is the following. Decidingwhether D ∪ Iis a solution to an ADU problem (D, I, C, ⊂) has the same complexity as deciding D |(cid:6) Co in general.Deciding the existence of an arbitrary solution is slightly harder than deciding D |(cid:6) Co for restricted settings of constraintsin Co . Intuitively, the additional computational effort accounts for the search of a solution candidate.5.4. Solution checkingWe finally turn our attention to the recognition of solutions, where we provide respective results for the syntacticpreference ⊂ and the semantic preference <weightq. Again the problem turns out to be PSPACE-complete in general. Similarlyas before, for ⊂ in restricted constraint settings testing arbitrary solution candidates has higher complexity than testingD ∪ I , which intuitively accounts for the additional maximality criterion to be checked for a solution.1194T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–1221Theorem 6. Given an ADU problem (D, I, C, ⊂) and an action description D(cid:5), deciding whether D(cid:5)is a solution for it is(i) PSPACE-complete for general constraints in Co ,(ii) Π P(iii) Π P(iv) DP -complete if Co = ∅.k+3-complete if k is the maximal nesting depth of dynamic constraints in Co ,2 -complete if Co does not involve dynamic constraints, andProof. Membership follows from Theorem 3, observing that for any given action descriptions Dcan be done in polynomial time, i.e., that Pcheck is in P for ⊂.Hardness in Case (i) follows from Theorem 4. For (ii) let n = k + 2 and let Φ = ∀Y Q 1 X1 · · · Q n Xn E be a QBF, where(cid:5)(cid:5)(cid:5)and D, deciding D(cid:5) ⊂ D(cid:5)(cid:5)Q i = ∃ if i ≡ 1 mod 2 and Q i = ∀ otherwise. ConsiderD u = D2 ∪ {caused Y i after Ai−1 ∧ Y i, caused ¬Y i after Ai−1 ∧ ¬Y i | 2 (cid:2) i (cid:2) n},where D2 is the action description from the proof of Theorem 4 with l = 1, Dm = {caused Y i, caused ¬Y i | Y i ∈ Y }, I = ∅,and C = Co = {ALWAYS f ∨ g}, where(cid:2)(cid:2)(cid:3)(cid:3)f = p1 N p1(cid:4)g =pn−1 N ¯pn−1 holds E after { An−1}SOMETIMES holds Y i ∧ SOMETIMES holds ¬Y i,. . .. . .after { A1},Y i ∈Ywhere N = necessarily, pi = ¬ if i is odd and void otherwise, for 1 (cid:2) i (cid:2) n − 1, and ¯pn − 1 = ¬ if n is odd and voidotherwise. Then, D u is a solution to the action description update problem (D u ∪ Dm, I, C, ⊂) iff Φ is true.For (iii) let Φ = ∀Y ∃ X E and consider the action description update problem (D u ∪ Dm, I, C, ⊂), where D u = ∅, Dm ={caused Y i, caused ¬Y i | Y i ∈ Y }, I = ∅, and C = Co = {ALWAYS ¬holds E ∨ g}, with g as before. The ADU problem (D u ∪Dm, I, C, ⊂) has D u = ∅ as a solution iff Φ is true.let E1 and E2 be Boolean formulas over atoms Y 1 and Y 2, respectively. Consider D u = {caused ¬F ,caused F if ¬E1}, Dm = {caused F if ¬E2}, I = ∅, and C = ∅. Then, (D u ∪ Dm, I, C, ⊂) has solution D u iff E1 is satisfi-able and E2 is unsatisfiable. (cid:3)Finally (iv),We next consider solution checking for the semantic preference <weightq. Note that while Pcheck is polynomial for ⊂,. However, intuitively whenever the complexity of Pcheck does not outweigh thethis is no longer the case for <weightqcomplexity of Ccheck, i.e., when we do not allow for more complex constraints in C p than in Co , then we stay withinthe same upper bounds as for ⊂. Providing also matching lower bounds yields the following result, which differs from theprevious one only if C = ∅. The intuitive reason is that for the syntactic preference also in this case a maximality checkis needed to recognize a solution, while the semantic preference is indifferent for C = ∅, which means that basically aconsistency check is sufficient and that every pre-solution also is a solution.Theorem 7. Given an ADU problem (D, I, C, <weightq ) and an action description D(cid:5), deciding whether D(cid:5)is a solution for it is(i) PSPACE-complete for general constraints in C ,(ii) Π P(iii) Π P(iv) NP-complete if C = ∅.k+3-complete if k is the maximal nesting depth of dynamic constraints in C ,2 -complete if C does not involve dynamic constraints, and(cid:5), hence we can decide whether DProof. Membership for (i), (ii), and (iii) follows easily from Theorems 3 and 4. For (iv), i.e. C = ∅, Pcheck is trivial for<weightqis a solution essentially by checking consistency.Hardness in Case (i) follows from Theorem 4. For (ii) let n = k + 2 and consider Φ, D u , Dm, I , and Co from the proofof Theorem 6(ii). Additionally, let C p = {ALWAYS holds Y i, ALWAYS holds ¬Y i | Y i ∈ Y } and consider a weight of 1 for eachc ∈ C p . Then, D u is a solution to (D u ∪ Dm, I, Co ∪ C p, <weightq ) iff it is a solution to (D u ∪ Dm, I, Co, ⊂).For (iii) consider Φ, D, I , and Co from the proof of Theorem 6(ii). Again, let C p = {ALWAYS holds Y i, ALWAYS holds ¬Y i |Y i ∈ Y } with weight 1 for each c ∈ C p . Then, for the same reason as above, D u is a solution to (D u ∪ Dm, I, Co ∪ C p, <weightq )iff it is a solution to (D u ∪ Dm, I, Co, ⊂).Finally (iv), let E be a Boolean formula over atoms Y and consider the ADU problem given by D u = {caused Y 1 if ¬E,caused ¬Y 1 if ¬E}, Dm = ∅, I = ∅, and C = ∅. Then, D u is a solution to (D u ∪ Dm, I, C, <weightq ) iff E is satisfiable. (cid:3)Hence, even recognizing solutions is quite hard. However, recognizing pre-solutions is easier for restricted sets of con-(cid:24) -complete if C has no dynamick+3-complete if the maximal nesting depth of dynamic constraints in C is k, PNPstraints (Θ Pconstraints, and NP-complete if C = ∅). This follows easily from Theorem 4.T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–12211195Fig. 5. Algorithm to compute some solution preferred by set-inclusion.6. Computing solutionsEquipped with a clear picture of the computational cost in terms of complexity for the relevant (sub-)tasks of solving anADU problem, we now turn to the issue of computing solutions using dedicated, deterministic algorithms.6.1. General algorithmsWith an oracle for pre-solutions, in case of the syntactic preference ⊂, we can incrementally compute a solution to anADU problem (D, I, C, ⊂) where D = D u ∪ Dm, in polynomial time using the algorithm in Fig. 5. By virtue of Theorems 5 and6, this algorithm is worst case optimal, even when the nesting depth k of dynamic constraints is restricted, since computingk+3 oracle. If the existence test for a pre-solution of (D u ∪ Dm, I, C, ⊂) in Step 1 or Step 2a solution needs the power of a Σ P(cid:5) := Dn andin fact returns some pre-solution Dn, then we can replace the respective assignment to DDm := Dm \ Dn.by the assignments D(cid:5)We remark that for semantic preferences, like <weightq, such a deterministic polynomial time procedure for computingsolutions, using an oracle for computing near solutions, does not work in general. However, in certain cases an oraclefor pre-solutions can be used effectively in a similar way. For instance, whenever the constraints in C p can be strictlyordered according to their (non-negative) weights, such that no subset of constraints that are before a constraint c in theordering can sum up to a higher weight than c. Then, in a procedure similar to Solution, one can iterate through the setof constraints C p once, using the oracle to determine whether pre-solutions exist to the slightly modified problem wherecertain constraints from C p are added to Co in order to determine the set of constraints from C p satisfied by an optimalsolution. Once this set is known, any pre-solution of the problem where these constraints are added to Co, is a solution tothe original problem.For the general case of <weightqwith non-negative weights, for instance, a branch and bound algorithm can be devisedfrom Algorithm Solution that uses an oracle for pre-solutions to compute an initial solution candidate and, throughout thecomputation, better candidates as usual in the style of an anytime algorithm.For other preferences (cid:2)C , algorithms will have to be developed that similarly exploit the structure of (cid:2)C to prune thesearch space effectively. If (cid:2)C is monotone with respect to the underlying signature, we may adapt Algorithm Solutionsimilarly as for <weightqto a branch and bound algorithm that aims at enumerating pre-solutions (for which e.g. techniquesas in [13] are useful) and cuts branches in the search tree if no better pre-solutions compared to the currently mostpreferred ones, D1, . . . , Dm, can be found in them; more precisely, any branch for a (partial) pre-solution D can be cutsuch that D ∪ {(cid:10)1, . . . , (cid:10)m} (cid:2)C D i for some D i . Note that every solution preferred under (cid:2)C is also preferred under set-inclusion, and we can adapt in the same way the variant of Algorithm Solution that exploits pre-solutions returned by theoracle. This scheme may be further refined, as usual, by exploiting properties like solution dominance (for each possible(cid:5) ⊆ {(cid:10)1, . . . , (cid:10)m}, one of the solutions D i is preferred); further investigation remains for futuresolution Dwork.such that D ⊆ D(cid:5)6.2. Pre-solutionsPre-solutions to a given ADU problem may be non-deterministically computed as in the membership part of Theorem 5,or may be obtained from a QBF encoding using a QBF solver. We present here a different computation method, whichbuilds on update descriptions and “update fluent sets.” Roughly, rather than to consider varying update descriptions, inthis method the problem is compiled into a single action description, called the update description, in which special updatefluents govern the inclusion and exclusion of causal laws. Determining an update then amounts to determine an appropriateupdate fluent set, which is semantically defined and may be computed by constraint satisfaction and state set generationalgorithms.1196T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–1221Fig. 6. Algorithm to compute some pre-solution.Definition 10. Let D = D u ∪ Dm be an action description with signature (cid:7)F, A(cid:8). The update description U (D) is the actiondescription obtained from D as follows:(1) Extend (cid:7)F, A(cid:8) by a set H of k = |Dm| new fluents (called update fluents) H 1, . . . , Hk;(2) label each static law (4) in Dm with a fluent H i ∈ H:caused L if G ∧ H i,and each dynamic law (5) in Dm with a fluent H i ∈ H:caused L if G after H ∧ H i,such that no two laws are labeled by the same fluent H i ;(3) for each H i labeling a law, add the dynamic law:inertial H i, ¬H i.(15)(16)(17)C , S UWe next define update fluent sets. To this end, we define, given an action description D u ∪ Dm and a set of constraints C¬C of the state set S U of the update description U = U (D) of D u ∪ Dm having the(cid:5) =H s}.(cid:5) |(cid:6) Q holdsH,s, if in Case (i) c is existential (9), E, sH,s; (iii) c is a Boolean combination of existential and= {s ∈ S U | cH,s, for all c ∈ C}. Furthermore, in the rest of this section, we identify states with the sets of fluents whichon the same signature, a partitioning S U(cid:5) ∈ S U let s =H sset H of update fluents, as follows. For any two states s, sGiven a constraint c and state s ∈ S U , we say that c holds at s w.r.t. S U(cid:5) ∈ S Uat some suniversal constraints ci , the combination evaluates to true if each ci has the value at s w.r.t. S Uholds at s w.r.t. S Uare true at that state.H,s; (ii) c is universal (10), E, s(cid:5) ∩ H, and let S UH,s(cid:5) |(cid:6) Q holds at all sH,s. Then, S Uiff s ∩ H = s(cid:5) ∈ S U | s(cid:5) ∈ S U= {sC(cid:5)Definition 11. An update (fluent) set for U relative to C is a set M ⊆ H such that(i) s ∩ H = M for some s ∈ S U , and(ii) S U⊆ S UC .H,sWith the notions above, we can compute a pre-solution to an ADU problem (D, I, C, (cid:2)C ), where D = D u ∪ Dm, with theAlgorithm Pre-Solution shown in Fig. 6. The key to its correctness is the following proposition.Proposition 4. Let (D, I, C, (cid:2)C ) be an ADU problem, with D = D u ∪ Dm. Let U be the update description of D ∪ I = D u ∪ I ∪ Dm,(cid:5) = D u ∪ I ∪ W is a pre-solution toand let W denote a subset of Dm containing laws labeled by the elements M ⊆ H in U . Then D(D, I, C, (cid:2)C ) iff M is an update set for U relative to Co .The proof of this correspondence result, which is technically involving, is given in Appendix B. It follows the intuitionthat by considering an update set for D ∪ I relative to Co and ‘adding’ the corresponding labeled laws (which by constructionare from Dm) to D u ∪ I , one ends up with an action description Dthat satisfies Co . The essential argument is by showing, which in turnthat for any state s of Dimplies that s ∈ S Dis consistent. Vice versa,Coto every pre-solution corresponds an update set M, given by the labels of the modifiable laws included in the pre-solution.(cid:5), s ∪ M is a state of U , and due to Condition (ii) of Definition 11 it is a state in S UCo(cid:5) |(cid:6) Co. Moreover, Condition (i) of Definition 11 guarantees that D, i.e., that D(cid:5)(cid:5)(cid:5)From Proposition 4, the correctness of Algorithm Pre-Solution is then easily established.Theorem 8. Let (D, I, C, (cid:2)C ) be an ADU problem, with D = D u ∪ Dm. Then Algorithm Pre-Solution outputs some pre-solution of(D, I, C, (cid:2)C ) if and only if some pre-solution of (D, I, C, (cid:2)C ) exists.T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–12211197We observe that for ⊂ as the preference ordering (cid:2)C , the algorithm can be easily adapted to find solutions insteadof near solutions: to this end, in Step 3 we take a maximal one. We also note that Step 1 is not necessary as far asmere computation of any pre-solution is concerned. However, in the view of ADU problem solving it may be worthwhileto particularly return D ∪ I first, if it is a pre-solution, since it constitutes the case where I can be incorporated withoutmodification to D. This is in particular relevant for preference relations (cid:2)C that are non-minimizing, as then in fact asolution is output.Example 6. Consider an ADU problem (D, I, C, (cid:2)C ) given by D, I , and C as presented in Example 1. Note that D ∪ I (cid:16)|(cid:6) C (asexplained in Example 1). We obtain the following update description U of D u ∪ I ∪ Dm, which contains D u ∪ I and the laws:caused TvON if PowerON ∧ H1,caused ¬TvON if ¬PowerON ∧ H2,inertial H i, ¬H i(1 (cid:2) i (cid:2) 2).According to the transition diagram described by U , we have that action PushPBRC is not executable, i.e., constraint (3):ALWAYS executable {PushPBRC} is violated at any state s ⊇ {PowerON, TvON, H 1}. Moreover, at any state s ⊇ {PowerON,TvON} such that H2 /∈ s, constraint (13):ALWAYS holds PowerON ∧ TvON ⊃¬necessarily (holds TvON) after {PushPBTV }(cid:11)=S U¬Cis not satisfied due to missing causation for ¬TvON. At every state of U , however, constraint (14): ALWAYS executable{PushPBTV } is satisfied. We thus obtains ∈ S U(cid:12)(cid:12) s satisfies H1 ∨ ¬H2and, for instance, {PowerON, TvON, H 2} ∈ S UC . Therefore, {H2} is an update set for U relative to C , and obviously it is theonly one. Hence, if we add the law labeled by H 2 to D u ∪ I , or equivalently remove the law caused TvON if PowerON, whichis labeled by H1, from D ∪ I , we obtain a pre-solution to the problem (cf. also Example 1).(cid:13),Example 7. Consider a slight variant of the previous Example 6, where also the dynamic laws in D (except for the inertialaws) are modifiable, and with the following causal laws added to Dm:caused TvON after PushPBTV ∧ ¬PowerON,caused ¬TvON after PushPBTV ∧ PowerON.The transition diagram described by D ∪ I is the same as in Fig. 4, and thus for the same reasons as mentioned in Example 1,D ∪ I (cid:16)|(cid:6) C . The update description U of D u ∪ I ∪ Dm consists of D u ∪ I , the labeled laws as presented in Example 6, and thefollowing causal laws:caused PowerON after PushPBTV ∧ ¬PowerON ∧ H3,caused ¬PowerON after PushPBTV ∧ PowerON ∧ H4,caused TvON after PushPBTV ∧ ¬PowerON ∧ H5,caused ¬TvON after PushPBTV ∧ PowerON ∧ H6,(3 (cid:2) i (cid:2) 6).inertial H i, ¬H iConstraint (3): ALWAYS executable {PushPBRC} is still violated according to the transition diagram described by U , since theaction PushPBRC is not executable whenever s ⊇ {PowerON, TvON, H 1}. Let us consider the remaining states s of U , i.e., onlythose such that H1 /∈ s. We first observe that a violation of constraint (13):ALWAYS holds PowerON ∧ TvON ⊃¬necessarily (holds TvON) after {PushPBTV }is witnessed by any such state where s ⊇ {PowerON, TvON}, H 6 /∈ s, and either H2 /∈ s or H4 /∈ s (or both), since there is nocausation for ¬TvON when executing PushPBTV . Finally, constraint (14): ALWAYS executable {PushPBTV } does not hold at anysuch state s where the power and the TV are off, i.e., s ∩ {PowerON, TvON} = ∅, if {H 2, H5} ⊆ s and H3 /∈ s. More formally,(cid:11)S U¬C=s ∈ S U(cid:12)(cid:12) s satisfies H1 ∨(cid:2)(cid:3)¬H6 ∧ (¬H2 ∨ ¬H4)(cid:13)∨ (¬H3 ∧ H2 ∧ H5).Two update sets for U relative to C are {H 3, H4, H5, H6} and {H2, H3, H4, H6}. (That they actually constitute update setsis witnessed, e.g., by {H3, H4, H5, H6} ∈ S UC , respectively.) We may choose either one and, byC and {H2, H3, H4, H6} ∈ S U1198T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–1221adding the corresponding causal laws to D u ∪ I , we get a pre-solution to the problem. Note however, that in case of (cid:2)C = ⊂,for instance, none of the pre-solutions is a solution, as removing caused TvON if PowerON is sufficient. This is reflected bythe (maximal) update set {H 2, H3, H4, H5, H6}.Algorithm Pre-Solution can be run in polynomial space, and is thus within the worst case optimal bounds. Indeed, theupdate description U for D and C can be easily computed in polynomial time, and after the consistency and constraintfulfillment check in Step 1, the bulk of the work is with Step 3, i.e., to compute an update set M. Here, we can resort todifferent methods. If the full state set S U of U would be explicitly given, then Step 3 is clearly feasible in polynomial time.Otherwise, we can use an algorithm that enumerates S U , and for each state s generated take s ∩ H as candidate update setH i ∈M H i ∧M for which condition (ii) S U(cid:6)belongs to S UH,s. Then, for each existential constraint c of form (9),define cs = SOMETIMES holds F s ∧ Q , and for each universal constraint c of form (10), define cs = ALWAYS holds F s ⊃ Q .For a Boolean combination c of existential and universal constraints, we define cs as the constraint obtained by rewritingC is equivalent to U |(cid:6) cs for eacheach occurrence of an existential or universal constraint as described above. Then S Uconstraint c in C .C is tested using constraint satisfaction; a brief outline is as follows. Let F s =H,s¬H i ; intuitively, F s holds at a state sH i ∈H\M⊆ S U⊆ S Uiff s(cid:6)H,s(cid:5)(cid:5)Thus, one can build algorithms to compute pre-solutions of an ADU on top of basic reasoning services for action descrip-tions that generate sets of states and allow for checking the satisfaction of constraints (as supported e.g. in AD-Constraint[21], under some limitations), which are applied to the update description U (D). Compared to a simple search over the(cid:5) |(cid:6) Co , this approach has some attractivepre-solution candidates Dadvantages. One is that we may compile the transition diagram of U (D) into an efficient representation (e.g., into binarydecision diagrams that are customary in efficient processing of transition-based formalisms), and perform state generationand check constraint fulfillment over this single representation, rather than to consider reasoning over varying transitiondiagrams, which may have considerable management cost (setting up data structures anew, etc.) at least without furtherprecaution and effort.(cid:5) ⊆ D ∪ I and testing whether Dsuch that D u ∪ I ⊆ D(cid:5)Furthermore, the update description is a useful basis for iterated Markovian (history-less) updates under lazy evaluation,and more generally for realizing non-Markovian semantics of sequences of updates I1, . . . , Ik, in analogy to update programsin the context of logic programming updates [5,20]. In the Markovian case, the result of updating an action description D isobtained by incorporating the I i , i = 1, . . . , k one after the other into D. The update description U (D) may be generalizedto capture such iterative updates rather easily, by using time stamped copies of action descriptions that are suitably linked,and modifying the preference ordering (cid:2)C appropriately into a prioritized version. In the non-Markovian case, linkage andpreference ordering can be tailored to realize particular update semantics. Investigating this is left for further work.7. Examples: updating the Zoo World into a CircusThe Zoo World is an action domain proposed by Erik Sandewall in his Logic Modelling Workshop. It consists of severalcages and the exterior, gates between them, and animals of several species, including humans. Actions in this domaininclude moving within and between cages, opening and closing gates, and mounting and riding animals. This domain wasdescribed in the action language C+ in [1].We present two examples for updating the action description of the Zoo World in C (derived from the one in [1])such that we obtain a description for a Circus. The first example illustrates the applicability of our method for computingpre-solutions; the second example illustrates the usefulness of the decomposability theorem.7.1. Singing and mounting in the CircusSuppose that we would like to update the action description of the Zoo World in C in such a way to obtain a descriptionfor a Circus by taking into account the following new information: a human can sing; and when he does, he becomes happyif he is also mounted on an animal. We also want to ensure the following condition: different from the Zoo World, in aCircus, the humans are expected to mount on each other, who further can mount on a large animal.First, we transform the description of [1] into the action language C; the modified description is available in Appendix C.Next, we describe the new information I by the following causal laws. Suppose that h ranges over constants denotinghumans, and anml ranges over constants denoting animals in the zoo:caused Happy(h) if True after Sing(h) ∧ Mounted(h, anml).Note that both h and anml are schematic variables; so the above expression stands for a set of “ground” causal laws.Next, we identify the causal laws Dm that could be modified. The modifications we desire are about the mounting actionin particular, so let Dm consist of the following causal laws. Suppose that h, h1 range over constants denoting humans, anmlranges over constants denoting animals in the zoo, and p ranges over positions in the zoo.• If a human tries to mount an animal that doesn’t change position, mounting is successful:caused Mounted(h, anml) if Pos(anml, p) after Pos(anml, p) ∧ Mount(h, anml).(18)T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–12211199Fig. 7. The landscape of the little zoo of [1]: positions 1–4 are inside the cage; positions 5–8 are outside the cage, the dashed lines denote the gate.• A human cannot attempt to mount a human who is mounted:caused False if True after Mount(h, h1) ∧ Mounted(h1, anml).• A human cannot be mounted on a human who is mounted:caused False if Mounted(h, h1) ∧ Mounted(h1, anml).(19)(20)We assume that our little Circus has two humans (a small boy named Bart and an adult named Homer) and an elephant(Jumbo). We assume that our Circus has the same landscape as the little Zoo as in [1]: there is a cage, with four positionsinside; outside the cage are four positions as well (Fig. 7).We can express the desired conditions (or scenarios) in this little Circus by constraints. For instance, consider the fol-lowing scenario of three steps: Initially, Jumbo and Bart are at different positions in the cage, and Homer is outside thecage; Homer is not happy. It should be possible at some point that first Homer mounts on Jumbo and next Bart mounts onHomer, so that in the end Homer is mounted on Jumbo, Bart is mounted on Homer, and Homer is happy. Suppose also thatJumbo does not change its location during the whole scenario. We can describe this scenario by the following constraint C :SOMETIMES(cid:14)holds Pos(Bart, l) ∧ Pos(cid:2)Homer, l(cid:5)(cid:3)(cid:2)∧ PosJumbo, l(cid:3)(cid:5)(cid:5)∧ ¬Happy(Homer) ∧l(cid:16)=l(cid:5)(cid:5), l,l(cid:5)(cid:5)<5, l(cid:5)>4(cid:2)possibly Mounted(Bart, Homer) ∧ Mounted(Homer, Jumbo) ∧Happy(Homer) after Mount(Homer, Jumbo); Mount(Bart, Homer) ∨possibly Mounted(Bart, Homer) ∧ Mounted(Homer, Jumbo) ∧(cid:3)Happy(Homer) after True; Mount(Homer, Jumbo); Mount(Bart, Homer)(cid:2)(cid:14)(cid:3)(cid:2)(cid:2)(cid:3)(cid:3)∧evolves PosJumbo, l(cid:5)(cid:5); True; PosJumbo, l; True; PosJumbo, l(cid:5)(cid:5)(cid:5)(cid:5);l(cid:5)(cid:5)<5True; Pos(cid:2)(cid:2)Jumbo, l(cid:3)(cid:5)(cid:5)(cid:5)(cid:5)(cid:2)(cid:3); True; Pos(cid:2)Jumbo, l(cid:3)(cid:5)(cid:5)(cid:3)(cid:5)(cid:5); True; Pos(cid:2)Jumbo, l(cid:3)(cid:5)(cid:5); True;(21)PosJumbo, l; True; PosJumbo, l.We can present this constraint to CCalc (as in Fig. 14 of Appendix C); and CCalc finds out that this scenario is not possiblewithin the Zoo World.Let us find a pre-solution Dto the ADU problem (D, I, C, ⊂), by applying Algorithm 6. For that, first we construct the(cid:5)update description U of the Zoo World:(1) We introduce update fluents as auxiliary fluents of the following three forms Aux1(h, anml, p), Aux2(h, h1, anml), andAux3(h, h1, anml).(2) We add new causal laws to make them inertialinertial Aux1(h, anml, p), Aux2(h, h1, anml), Aux3(h, h1, anml)inertial ¬Aux1(h, anml, p), ¬Aux2(h, h1, anml), ¬Aux3(h, h1, anml).(3) We replace the causal laws (18)–(20) with the following causal laws respectivelycaused Mounted(h, anml) if Pos(anml, p) after Pos(anml, p) ∧Mount(h, anml) ∧ Aux1(h, anml, p)caused False if True after Mount(h, h1) ∧ Mounted(h1, anml) ∧Aux2(h, h1, anml)1200T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–1221caused False if Mounted(h, h1) ∧ Mounted(h1, anml) ∧Aux3(h, h1, anml).After that, we can check whether the scenario represented by the constraint (21) is possible if we keep all the causal laws,except for those labeled by Aux2(Bart, Homer, Jumbo) and Aux3(Bart, Homer, Jumbo). For that, we just need to modify theCCalc constraint above by adding several lines, as shown in Fig. 15 of Appendix C. Then, CCalc finds a possible executionof this scenario as presented in Fig. 16 of Appendix C. It suggests dropping from Dm the causal lawscaused False if True after Mount(Bart, Homer) ∧ Mounted(Homer, Jumbo)caused False if Mounted(Bart, Homer) ∧ Mounted(Homer, Jumbo)to update the Zoo World description into a little Circus.7.2. Exchanging hats in the CircusConsider a world, which involves monkeys and dogs among other animals, where only monkeys can wear hats. We canobtain a C description D0 of such a world, from the C+ description of missionaries and cannibals exchanging hats [50]; itcan be presented to CCalc as in Fig. 17 (Appendix D).Now consider a variation of the Zoo World described in Section 7.1, which involves also monkeys and dogs, where onlymonkeys can wear hats. This variation of the Zoo World can be described by the union of the Zoo World description D 1discussed in Section 7.1 (Figs. 8–13, Appendix C) and the description D0 mentioned above.Suppose that we would like to update the action description D0 ∪ D1 of this extended Zoo World, to obtain a descriptionof a Circus where not only humans can mount on each other who further can mount on a large animal, but also animals canexchange hats with each other. Assume that the modifiable part D1m of D1 is the same as in Section 7.1, and the modifiablepart of D0m of D0 consists of the following causal laws:caused False if Owner(ha, anml)where ha ranges over hats, and anml ranges over animals except monkeys.We assume that our little Circus has the same landscape as in Fig. 7; and it contains two humans (a small boy Bart andan adult Homer), an elephant (Jumbo), a dog (Snoopy), three monkeys (a small monkey Abu and two large monkeys), andtwo hats. In this little Circus, in addition to the desired conditions (or scenarios) presented in Section 7.1 by the set C 1 ofconstraints (21), we also consider the following scenario: initially, Snoopy and Abu are wearing hats; they exchange hats atleast once. We can express this condition by the constraints C 0:SOMETIMES(cid:2)evolves Owner(ha1, Abu) ∧ Owner(ha2, Snoopy); exchange(ha1, ha2); True ∨evolves Owner(ha1, Abu) ∧ Owner(ha2, Snoopy); True; True;exchange(ha1, ha2); True ∨evolves Owner(ha1, Abu) ∧ Owner(ha2, Snoopy); True; True;True; True; True; exchange(ha1, ha2); True,(cid:3)where ha1 and ha2 range over hats. This constraint can be presented to CCalc as in Fig. 18 (Appendix D).Here, we can update D0 ∪ D1 relative to C 0 ∪ C 1. On the other hand, since ((D0, ∅, C 0), (D1, ∅, C 1)) is a near-decomposition of (D0 ∪ D1, ∅, C 0 ∪ C 1, ⊂), by Theorem 1, we can update D0 and D1 separately, in parallel. Consideringthe computation time CCalc takes to verify given constraints, the latter approach takes much less time. With the formerapproach, CCalc verifies constraints C 0 ∪ C 1 with respect to a propositional theory of size 20 450 atoms and 398 430 clauses(obtained from the update description of D0 ∪ D1) in about 9 minutes (including the grounding and completion time). Withthe latter approach, CCalc verifies C 0 with respect to a propositional theory of size 164 atoms and 766 clauses (obtainedfrom the update description of D0) in less than a second (including the grounding and completion time); and it verifies C 1with respect to a propositional theory of size 5462 atoms and 60 567 clauses (obtained from the update description of D 1)in less than 30 seconds (including the grounding and completion time).8. Discussion8.1. Related workUpdating and revising knowledge bases has been studied extensively in the context of both databases and AI, withdifferent approaches, and in various representation frameworks, see e.g. [67,34,57] and references therein. The relation ofT. Eiter et al. / Artificial Intelligence 174 (2010) 1172–12211201this problem to reasoning about actions has been identified earlier [66,59,56], since the effects of executing an action ina given situation can be modeled as the change of a theory representing the current state by a formula representing theaction effects. However, compared to reasoning in action languages, such an approach leaves the action under considerationand its effects rather implicit. Therefore, we restrict our attention to those works that either treat the notion of an actionexplicitly in the language, or that are otherwise more closely related to our work.Sakama and Inoue’s work [61] is similar to our work in that it also studies update problems in a non-monotonic frame-work (yet in logic programming) and considers the same criterion of minimal change. It deals with three kinds of updatesto a knowledge base D: theory update of D by some new information I , inconsistency removal from D, and view updateof D = D u ∪ Dm by some new information I . In the context of reasoning about actions and change, these kinds of updatesare expressible as ADU problems (D, I, ∅, ⊂), (D, ∅, ∅, ⊂), and (D u ∪ Dm ∪ I), ∅, ∅, ⊂). Sakama and Inoue show in [61] thatchecking for solution existence is NP-hard for each problem; this complies with Theorem 5(iii). An important differenceto [61] is that in an ADU problem (D, I, C, ⊂), the constraints C may not be directly expressed in D. Moreover, the se-mantics of an action description D in C is a transition diagram, and only captured by all answer sets of a logic programcorresponding to D by known transformations.Li and Pereira [44] and Liberatore [47] study, like we do, theory update problems in the context of reasoning aboutactions and change, based on an action language (but language A instead of C). New information, I , contains facts describingobservations over time (e.g., the action PushPBRC occurs at time stamp 0). The action language C we use is more expressivethan A in that it accommodates non-determinism and concurrency, and the changes in the world are not only due to directeffects of actions. To formulate temporal observations, we can extend our constraint language by formulas of the shapesE occurs at ti,P holds at ti,(22)(23)where E is an action name, P is a fluent name, and ti is a time stamp; a state s satisfies a constraint (22) resp. (23) if, forsome history (11) such that s = s0, E is in Ai+1 resp. si satisfies P .Our notion of consistency of an action description D (in essence, the existence of a state) is different from that of Zhangin [68]. They describe action domains in propositional dynamic logic, and require for consistency the existence of somemodel of an action description. Different from the setting here, conflicting action effects may prevent any model. With theextension of our constraint language discussed above, other forms of consistency studied in [68] can be achieved in ourframework, by describing possible scenarios or formulas as constraints.Some of the related work mentioned above, like [6,49,3,37], study action description updates in connection with theproblem of elaboration tolerance. The goal is to answer the following question: how can an action description be updatedto tolerate new elaborations on the action domain? [37] studies the update problem in the context of dynamic logic [35].Here action domains are represented in a simplified version of dynamic logic. An action domain description consists of staticlaws (e.g., Up → Light, which expresses that “if the switch is up then the light is on”), effect laws for actions (e.g., ¬Up →[Toggle]Up, which expresses that “whenever the switch is down, after toggling it, the room is lit up”), and executabilitylaws for actions (e.g., ¬Broken → (cid:7)Toggle(cid:8)(cid:28), which expresses that “toggle cannot be executed if the switch is broken”).To handle the frame problem and the ramification problem, a consequence relation is built (in a meta-language) overthe action description. Note that the action description language C does not require such a meta-language to be able tohandle these problems. In this formal framework for reasoning about actions and change, the authors consider revisingbeliefs about states of the world (as in, e.g., [38,62]), as well as revising beliefs about the action laws. They update actiondescriptions with respect to some elaborations (described also by causal laws), by modifying the causal laws in the actiondescription by first “contraction” and then “expansion.” In the end, the antecedents of some causal laws in the actiondescription are strengthened with respect to the new elaborations. Consider the example above; during a blackout, theagent toggles the switch when it is down, and the room is still dark. A respective elaboration is described by a causallaw, like Blackout → [Toggle]Light, which is to be contracted from the action description. The action description is modifiedby this elaboration, by first contracting the effect laws (e.g., ¬Up → [Toggle]Up) and then expanding the theory with theweakened laws (e.g., ¬Up ∧ ¬Blackout → [Toggle]Up). The idea behind modifying a theory with an elaboration of the formφ → [a]ψ in this way, is to ensure two conditions when φ does not hold: first a still has the effect ψ ; and second a hasno effect except on those literals that are consequences of ¬ψ . The semantics of such syntactic operations are given interms of changes (e.g., addition/removal of edges) in the transition diagram. Note that [37] modifies causal laws to tolerateelaborations, whereas we add new causal laws (which may be obtained from some observations, or which may describesome elaborations) to the original description and furthermore we drop a minimal set of causal laws from the originaltheory so that given constraints (which may describe some desired/preferred conditions on the domain) are satisfied bythe updated description. In other words, [37] is less suitable for the incorporation of new information compared to ourapproach. For instance in the example given above, elaborating w.r.t. the effect law Blackout → [ReplaceFuse]Blackout willnot serve the intended purpose to incorporate the effects of replacing a broken fuse, while in our approach we simplyupdate with the causal law caused ¬Blackout after ReplaceFuse ∧ Blackout for this purpose.Another related work that studies action description updates, for elaboration tolerance, is [3]. The authors introduce anaction description language, called Evolp Action Programs (EAPs), built upon the update language Evolp [4]. This languagecan be used to represent action domains, as well as their updates due to some elaborations. An action domain description1202T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–1221consists of static rules (e.g., Light ← Up), dynamic rules (e.g., effect(Light ← Up) ← Toggle, ¬Up which expresses that, if atsome step n the switch is down and the switch is toggled at step n, then Light ← Up becomes true at step n + 1), inertialdeclarations (e.g., inertial(Light)), and initialize declarations (e.g., initialize(Light) which stands for Light ← prev(Light) whereprev(F ) is a new atom introduced for describing the value of fluent F in the previous state) introduced for representinginertia. Note that in the action language C, there is no need to introduce new atoms to be able to handle the frame problem.An elaboration is encoded as a separate action description D, and then “asserted” to the main description, using the assertconstruct of Evolp. The semantics of an EAP (and thus the assert construct) is given by means of stable models [29]. Addingassert(D) to the initial description is different from adding D: like our approach it ensures static consistency of the resultingaction description (if the update itself is consistent); preference is implicitly given by set inclusion, i.e., maximal consistentsubsets of the initial laws are retained. Another similarity to our work is that updates that consist of static/dynamic rulesare described in the same language as the action description. Additionally, the language of [3] allows to specify changes ofrules, as a part of an update (using the assert construct). For instance, consider adding assert(Light ← Up) ← Toggle to anaction description. Then, when the switch is toggled, the rule Light ← Up remains inertially true until its truth is possiblydeleted afterwards. However, apart from rather cumbersome language extensions for handling the frame problem, EAPs donot provide a means to specify certain dynamic requirements that an update might have to satisfy (in particular universalproperties quantifying over all states), which is a main feature of our approach. For instance, in the setting of Example 1,translating D and I into a respective EAP would represent an update equivalent to the action description D ∪ I , i.e., one thatdoes not satisfy the constraints C . Since the constraints cannot be expressed in the language, additional analysis is needed(different from I ), which would enforce the required behavior when asserted to the initial actionto identify an update Idescription D.(cid:5)The works by Lifschitz [49] and by Balduccini and Gelfond [6] are similar to [3] in that they also modify action de-scriptions with respect to new elaborations, by means of adding causal laws, in the sense of additive elaboration tolerance[52,55]. Lifschitz describes in [49] an action domain in language C such that every causal law is defeasible (by means of anabnormality predicate). To formulate some other variations of the domain, the agent can just add new causal laws, some ofwhich “disable” some existing causal laws. In [6], the authors extend an action description, encoded as a logic program, with“consistency restoring” rules, so that when the action description and given observations are incompatible, these rules canbe “applied” to get some consistent answer set. This, however, is more geared towards handling exceptions (no causal lawsare modified). The approaches provide tools for the user to enact updates (by defeating causal laws, respectively by applyingconsistency restoring rules), but different from our approach, no particular modifications are characterized from first princi-ples as “intended” solutions of an update problem, which remains with the user. While adding abnormality predicates [49]is a simple technique that does not support preference constraints, [6] (which is more geared towards diagnosis) requiresto anticipate all possible updates in order to encode a priori solutions for potential inconsistencies with subsequent updatesinto the initial domain description at design time; the support for preferences on consistency restoring rules is limited, e.g.,cardinality based preferences are difficult to represent. Furthermore, as the result of updating an action description is notan action description, adjustments for iterated updates are necessary.Concerning results on the computational complexity, Eiter and Gottlob [23] study a number of syntax-based as wellas model-based knowledge base revision operators and provide precise complexity characterizations for the problem ofchecking whether a given formula is derivable from a revised (updated) knowledge base by reducing the problem to theevaluation of counterfactuals. Herzig [36] improved these complexity bounds for restricted settings under Winslett’s PossibleModels Approach. Liberatore [46] considers further approaches for belief update from the literature, derived correspondingcomplexity results, and extended them to the problem of iterated update. Baral and Zhang [7] considers the complexityof model checking for knowledge update. As for traditional belief update, the relation to reasoning about actions consistsin regarding the effects of an action as an update to the current state. However, motivated by sensing actions that do notchange the world, Baral and Zhang distinguish knowledge updates as belief updates where changes not only correspondto alterations of the real world but may also be affect an agent’s knowledge about the world. They give a model theoreticaccount of knowledge updates based on modal logics, show that the complexity of model checking is on the second layerof the polynomial hierarchy, and identify tractable subclasses.More closely related to our work are investigations concerning the complexity of reasoning about actions in an actionlanguage. For the action language A, Liberatore [45] establishes, for instance, NP-completeness of consistency checking andcoNP-completeness for entailment, which essentially amounts to checking whether D |(cid:6) ALWAYS necessarily (holds F ) afterA1; . . . ; An, for a given action description D, a fluent F , and a sequence of actions A1; . . . ; An in our setting. Lang et al. [42]investigated the computational complexity of the progression problem for simple causal action theories which constitute aspecial case of causal theories in different languages, in particular capturing the fragment of action language C that we con-sidered. Besides the progression problem, the complexity of other reasoning tasks, including executability and determinism,is addressed in this framework which is further extended to so-called generalized action theories. We remark that, like forprogression, several of these results can be obtained as special cases of deciding D |(cid:6) c for particular constraints c in oursetting. Moreover, to the best of our knowledge, the complexity of deciding constraint fulfillment has not been addressedso far (apart from the PSPACE result for the general case for the constraint language we considered, which has been provenin [18]), let alone the problem of updating action descriptions in the presence of constraints.T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–122112038.2. Nature of changeAs stated in the problem description, our approach is intended to also allow for designed (normative) worlds that arerepresented by means of action descriptions, where changes thus are considered to be updates rather than revisions. How-ever, as already briefly mentioned in Section 3, our notion of action update has more of a belief revision than a belief updateflavor. This view is supported by a deeper analysis of change in connection with reasoning about actions and change [41,58].Lang [41] describes a scope for revision and for update, and he notices that, as pointed out by [27,28], the scope cannotbe simply decided by whether the theory is about static vs. dynamic worlds. Then, as also pointed out by [10,14], Lang re-lates revision and update by means of backward–forward reasoning, in particular, by means of action progression. Accordingto [41], belief revision is to correct some initial beliefs about the past/present/future state of the world by some observationsabout the past/present state of the world. On the other hand, belief update by some formula α corresponds to progressingthe theory by a specific feedback-free action that will make α true with respect to a given update operator; here α doesnot describe observations. In this framework, Lang says that our approach is closer to a revision process than to an update;however, since our approach changes the transition diagram of an action description, it is meaningful to consider it as anupdate process as well.However, update and revision behave for our problem technically not much different: while informally, revision operatorsaim at selecting models of the new information that are closest to the models of the knowledge base globally, update opera-tors change each model of the knowledge base locally (this is intuitively captured by the axiom U8 of the KM postulates). Aseach action description D has a unique associated model given by T (D), the two methods yield the same result. The maindifference remaining is the behavior on inconsistent action descriptions. Revision with consistent information must make aninconsistent knowledge base consistent (as done in our approach), while update must preserve inconsistency. Clearly, ourmethod can be easily adapted to this behavior, and thus show an update flavor.The AGM and KM postulates [2,39] are based on several assumptions that do not hold for the action language C. One re-quirement which is not met is that of an underlying formal language which is governed by a logic, i.e., which is closed underBoolean connectives. Other requirements, including super-classicality, modus ponens, and the deduction theorem, essentiallyrestrict to formalisms with an underlying monotonic logic (an explicit restriction for instance in Hansson’s work [33]). How-ever, the action language C is non-monotonic. For instance, if D consists of the single lawcaused P if Pwhere P is the single fluent, then the transition diagram described by D, T (D), has two states s1 = {P }, s2 = {¬P }, andtwo transitions (cid:7)s1, ∅, s1(cid:8) and (cid:7)s2, ∅, s1(cid:8). Thus the causal law caused P after ∅ is satisfied by T (D) (equivalently, D |(cid:6)ALWAYS necessarily holds P after ∅), and can be seen a semantic consequence of D. However, if we addcaused ¬P if ¬Pto D, then T (D) has additional transitions ((cid:7)s1, ∅, s2(cid:8) and (cid:7)s2, ∅, s2(cid:8)) and D (cid:16)|(cid:6) ALWAYS necessarily holds P after ∅; thuscaused P after ∅ is no longer a semantic consequence. The AGM framework, and similarly the KM framework, is notsuitable for non-monotonic settings, as discussed, e.g., for non-monotonic logic programming in [20] and for defeasible logicin [9]. This has been confirmed by our study of KM-style properties in Section 4, where non-monotonicity turned out tobe the reason for several properties to fail. Thus governing our action description updates with the AGM or KM postulatesis not meaningful; and intuitively the same is true for postulates for contraction developed in monotonic settings. Werefrained from a formal investigation in this direction due to another reason however: action language C is not closedunder complement, more precisely it is neither defined nor clear what the complement of an action language should be, orhow it is represented. As a consequence, it does not constitute a logic and well-known identities, like the Levi Identity usedin classical belief change settings to relate contraction, expansion, and revision, cannot be applied.By the counterexamples for KM postulates given in Section 4, it also becomes clear that the same results are obtainedfor less general, alternative definitions. For instance, one may consider an initial action description D0, and a set of con-straints C0, as the initial knowledge to be modified by new information, which consists of a set of causal laws D1, and aset of constraints C1, which are considered to hold for sure in a solution. Preference is given to solutions that keep a max-imal sets of the original laws and constraints (w.r.t. set inclusion), such that the resulting action description is consistentand satisfies—in addition to all constraints in C1—also all constraints from C0 that are kept. Note that in our setting, this is(cid:5)(cid:5)amounts to a particular case where D = Dm = D0, Co = C1, C p = C0, and (cid:2)C is defined by D,C p= {c ∈ C p | D |(cid:6) c}, for any action description D. Note that all counterexamplesand one of the inclusions is strict, where D C pstated in Section 4 are also counterexamples for this setting. We further remark that the other properties (except for thosethat require strongly minimizing (cid:2)C , which is not the case for the above preference relation), and in particular results oncomputational complexity, hold for this particular setting as well.(cid:5) (cid:2)C D(cid:5) ⊆ D⊆ Diff D(cid:5)C p, D(cid:5)(cid:5)(cid:5)(cid:5)An AGM- respectively KM-style theory for non-monotonic logics with significant attention is, to our knowledge, stillmissing. We note that [38], for instance, considers the incorporation of belief change into the fluent calculus, geared byan axiomatic treatment of belief revision and update satisfying the AGM and KM postulates, respectively. However, theunderlying logic is monotonic and only static knowledge is subject to change, and preference is based on a ranking ofstates. Another notable work is [26], which considers the revision of rational preference orderings that underly certain (non-monotonic) consequence operators. However, in order to avoid shortcomings concerning the general principles of success1204T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–1221and minimality of change, which are impossible to adhere in general for the non-monotonic setting, restrictions are imposedconcerning the knowledge bases and the conditionals (akin to laws in our setting) admissible for revision. More closelyrelated to our setting is a very recent approach to belief revision for answer-set programs [15] with an operator that satisfiesthe majority of the AGM postulates. This is achieved by building on a strong underlying notion of equivalence (so-calledstrong equivalence), using a respective monotonic formal characterization of answer-set programs called SE-models, and byapplying well-known techniques from classical belief revision. Applying similar methods to action language C in order tocome up with a theory-revision operator is an interesting subject for future work. Work by Turner [63] on SE-models forcausal theories may serve as a starting point. However, several issues are not immediate and need further consideration.For instance, a direct application of Turner’s SE-models to laws in C is achieved for static laws only, while it is the dynamiclaws which we are mainly interested in for revision. Hence, the concept of SE-model has to be adapted appropriately. Notethat any revision operator, respectively update operator, obtained this way is characterized by semantic structures which isorthogonal to our aims in this article. It is not clear how the resulting semantic structures could be syntactically represented(something which could be achieved due to a characterization of SE-models in terms of answer-set programs in [15]). Even ifa suitable representation by means of causal laws is developed, it is not likely that the resulting action description after thechange is reminiscent of the original description (see also discussions in [17] and comments on this work in the followingsubsection).8.3. Repair of action descriptionsWe can sometimes improve solutions (and pre-solutions) to an ADU problem (D, I, C, (cid:2)C ) by considering a slightlydifferent version of the problem. We may take the view that a causal law is not completely wrong, and for instance holdsin certain contexts. Suppose that I is a dynamic law of the form:caused L(cid:5)after A(cid:5) ∧ G(cid:5),(cid:5)(cid:5)where Lfrom D, which describes the same transition diagram as D, by replacing each dynamic law (5) in Dm with:is a propositional combination of fluents, and Ais a literal, Gis an action. We can obtain an action description D s(cid:5)caused L if F after H ∧ G,caused L if F after H ∧ ¬G(cid:5)(cid:5).(cid:5)(cid:5)to (D, I, C, (cid:2)C ) there exists some pre-solution D s(cid:5)to (D s, I, C, (cid:2)C ) whichWe then have that for each pre-solution Das a subset (in particular, for subset preference ⊂, each solution to (D, I, C, ⊂) gives rise to some solutioncontains DC , the solutions of (D, I, C, (cid:2)C ) can thenof (D s, I, C, ⊂)); with an (ad-hoc) adaptation of the solution preference (cid:2)C to (cid:2)sbe recovered from the ones of (D s, I, C, (cid:2)sC ). Therefore, such a replacement method can be useful to prevent “completeremoval” of some laws from the given action description. Furthermore, solutions of (D s, I, C, (cid:2)sC ) which do not correspondto solutions of the original problem (D, I, C, (cid:2)C ) can be viewed as approximations of solutions for the latter. They might beof particular interest if the original problem has no solution.Similar methods are also useful for repairing an action description, e.g., if some dynamic laws (5) in the action descriptionhave missing formulas in H . In this case, we need to replace such causal laws by some modified statement(s) from acandidate space. Our current framework can be generalized in this direction by changing the candidate solution spaceholds for eachfor a solution D(cid:5) ∈ cand(D, I); if a modifiable causal law (cid:10)i in D gives rise to alternative candidate replacements cand((cid:10)i, I), then cand(D, I)D(cid:15)= {n(cid:5) ⊆ D u ∪ I to a set of action descriptions cand(D, I) such that D u ∪ I ⊆ Di=1 D i | D i ∈ cand((cid:10)i, I)} should hold, where D = {(cid:10)1, . . . , (cid:10)n}.from D u ⊆ D(cid:5)(cid:5)We note that as for repairing action descriptions, [17] took a slightly different, semantics-oriented view for resolvingconflicts between an action description and a set of constraints, in the context of action language C. Conflicts are character-ized by means of states and transitions in the transition diagram described by the given action description that violate somegiven constraints. The goal is to resolve each conflict by modifying the action description, but not necessarily by deletingsome causal laws. However, the repair of a single conflict might be achieved by numerous alternative changes to the actiondescription, such that the candidate solution space is very large; furthermore, the repairs of individual conflicts interferewith each other, and might introduce other conflicts. This led the authors of [17] to propose support for the user in terms ofreasoning services on an action description given constraints, which provide explanations for certain disorders, rather thanan automated repair; a respective tool and methodology for its usage to correct editorial errors in the knowledge represen-tation process (e.g., by typos or omitted formula parts) are described in [21,22]. An interesting issue for further work is toanalyze under which conditions such repairs can be obtained as solutions of an ADU problem in a generalized frameworkas outlined above.9. ConclusionIn this paper, we have considered the problem of updating an action description with some new information in theframework of action languages, where knowledge about the domain in terms of observations and other constraints is re-spected. To this end, we have introduced a formal notion of action description update which, given an action description D,T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–12211205the new information I (as a set of statements) and some desired constraints C (expressed as formulas in an action querylanguage), singles out a solution to the update problem, based on a preference relation (cid:2)C over action descriptions.We then studied semantical and computational properties of action updates in this framework, where we presentedamong other results decomposition results and complexity characterizations of basic decision problems associated withcomputing solutions, viz. deciding solution existence and solution recognition. We considered in the complexity analysisgeneric settings as well as particular instances, paying attention to different classes of constraints and preference relations.Furthermore, we presented some algorithms for computing solutions and pre-solutions (which approximate solutions), andwe discussed our work in the context of the literature.Several issues remain for further work. Our computational results provide a basis for the realization of concrete imple-mentations to incorporate updates into action descriptions in the action language C, based on top of existing reasoningsystems like the causal calculator [51] or AD-Constraint [21], which is an important need for deploying such systems toapplications. However, for practical concerns, efficient domain-tailored algorithms will need to be developed.In connection with this, meaningful fragments of low (polynomial) complexity are of interest; related to this is the studyof language fragments that correspond to simpler (less expressive) action languages, such as A or B (see [30]). However,several of the intractability results that we established here involved rather simple action descriptions, which suggests thatpolynomial complexity will have to be achieved by pragmatic constraints rather than logical or structural conditions. Onthe other hand, also richer, more expressive action languages, such as the language C with disjunctive causal laws maybe studied, the action language C+ [43], or the action language K [19] (into which the language considered here mapsnaturally) may be studied.Further issues are to consider richer forms of constraints (e.g., by generalized action query languages), and to extendthe current computational study to further notions of preference relations. For example, to syntax-based preference usingcardinality, lexicographic ordering, or formula ranking, possibly with priority levels on top [8,11], or to semantic-basedpreference that uses other weight assignments like those in [18] (which are computable in polynomial space) or preferencebased on state- and transition-rankings, inspired by approaches e.g. in conditional reasoning (see [24]).Another issue are multiple updates. The update descriptions that we presented here provide a useful basis for a real-ization of Markovian (history-less) updates I1, I2, . . . , Ik of an action description under lazy evaluation, and may be used,similar as update programs in the context of logic program updates [5,20], also to realize non-Markovian semantics of asequence of updates to an action description. However, this remains to be explored in further investigation.Finally, in regard with connection with AGM and KM theory, postulates and properties that are tailored to theories ofaction in a non-monotonic setting would be interesting.AcknowledgementsWe would like to thank the anonymous referees for their comments, which helped improve this paper considerably.This work was supported by the Austrian Science Fund (FWF) grant P16536-N04, the European Commission IST pro-gramme grants FET-2001-37004 WASP and IST-2001-33123 CologNeT, and by the Vienna Science and Technology Fund(WWTF) grant ICT08-020.Appendix A. Proofs for Section 5Theorem 4. Given an action description D and a set C of constraints, deciding D |(cid:6) C is(i) PSPACE-complete in general,(ii) Θ P(iii) PNPk+3-complete if k is the maximal nesting depth of dynamic constraints in C , and(cid:24) -complete if C does not involve dynamic constraints.Proof. Concerning (i) the result has been shown in [18]. We proceed with the proof of (ii) and (iii).Membership: W.l.o.g. C contains a single constraint c. Let us consider (iii) first. Then, c is a conjunction of clauses overuniversal constraints of the following form: ALWAYS Q or ¬ALWAYS Q , where Q is a conjunction of clauses over staticconstraints of the form holds F or ¬holds F . Checking truth of a negated universal (sub-)constraint of this form is in NP. Todo so, we non-deterministically guess a possible state s of D and verify in polynomial time that s is a state of D (satisfiesall static laws of D) and that s does not satisfy Q (there is a clause in Q such that none of its static constraints is satisfiedat s). Hence, the complementary task, i.e., checking the truth of a positive universal constraint, ALWAYS Q , is in coNP. Thus,we can decide D |(cid:6) c in polynomial time with a single parallel evaluation of n NP-oracle calls, given that n is the numberof universal constraints in c. This proves PNPFor (ii), the constraint c is a conjunction of clauses over universal constraints of the form ALWAYS Q or ¬ALWAYS Q ,where Q is a conjunction of clauses over static constraints as above and over dynamic constraints of the formnecessarily Q k−1 after A1; . . . ; An or ¬necessarily Q k−1 after A1; . . . ; An, where Q k−1 is a basic constraint of nestingdepth k − 1. Let c1 − c4 denote constraints of the form c1 = ALWAYS Q , c2 = ¬ALWAYS Q , c3 = ALWAYS ¬Q , andc4 = ¬ALWAYS ¬Q , respectively. We show by induction that deciding whether D |(cid:6) c is in Θ P(cid:24) -membership.k+3.1206T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–1221Base case (k = 0): For static Q , by (iii) deciding D |(cid:6) ci , is in PNP(cid:24) , for 1 (cid:2) i (cid:2) 4. Hence, let Q = necessarily Q k−1 afterA1; . . . ; An be a dynamic constraint. Deciding D |(cid:6) c1 is in NP since the complementary problem D |(cid:6) c2 is in coNP. Thelatter problem is decided by non-deterministically guessing a history h = s0, A1, s1, . . . , sn−1, An, sn of length n and checkingin polynomial time that h is a history of D, i.e., that si (0 (cid:2) i (cid:2) n) is a state of D and that (cid:7)si, Ai+1, si+1(cid:8) (0 (cid:2) i < n) isin R. Furthermore, D, sn |(cid:6) ¬Q k−1 can be checked in polynomial time since Q k−1 is a propositional combination of staticconstraints, witnessing D (cid:16)|(cid:6) c1. Deciding D |(cid:6) c3 is in Π P2 . To wit, in orderto disprove D |(cid:6) c3, guess a state s and—as outlined above—use the NP-oracle to verify that for all histories h of length nemanating from s (s0 = s) it holds that D, sn |(cid:6) Q k−1. This establishes D, s (cid:16)|(cid:6) ¬Q and hence, D (cid:16)|(cid:6) c3. Putting all together,in order to decide D |(cid:6) c, an oracle for Σ P2 problems is sufficient to decide the truth of any universal constraint in c. Thus,D |(cid:6) c can be checked in polynomial time with a polynomial number of parallel Σ P2 -oracle calls and therefore is in Θ P3 .Induction step: Let the nesting depth of dynamic constraints be k > 0, and assume that deciding D |(cid:6) Q k−1 is in Θ Pk+2for any subconstraint of nesting depth k − 1. Then, as easily seen by the arguments for the base case above, D |(cid:6) I can bedecided by means of a Σ Pk+3.(cid:24) -hard decision version of Maximum CNFSatisfiability: Given a Boolean formula F in conjunctive normal form (CNF) and an integer k, decide whether the maximumnumber of clauses in F that can be simultaneously satisfied by an interpretation is 0 mod k.k+2-oracle for any universal constraint Q ∈ c. Thus, again by parallel evaluation, D |(cid:6) c is in Θ PHardness: In order to prove (iii) we reduce the problem to the following PNP2 and the complementary problem D |(cid:6) c4 is in Σ PW.l.o.g., let F be a 3-CNF formula of the formi=1 Li,1 ∨ Li,2 ∨ Li,3, where Li, j , 1 (cid:2) i (cid:2) n, 1 (cid:2) j (cid:2) 3, is a literal overatoms X = { X1, . . . , Xm}. For Xi ∈ X , by ¬L we denote ¬ Xi if L = Xi and Xi if L = ¬ Xi . Consider the action description D1consisting of:(cid:6)n(cid:7)caused Ci if Li,3,1 (cid:2) i (cid:2) ncaused Ci if Li,2,caused Ci if Li,1,caused ¬Ci if ¬Li,1 ∧ ¬Li,2 ∧ ¬Li,3,caused F 1,1 if C1,caused F 1,0 if ¬C1,caused F i, j if Ci ∧ F i−1, j−1,caused ¬F i, j if ¬Ci ∧ F i−1, j−1,caused F i, j if ¬Ci ∧ F i−1, j,caused ¬F i, j if Ci ∧ F i−1, j,(cid:7)caused ¬F 1,1 if ¬C1,caused ¬F 1,0 if C1,(cid:7)2 (cid:2) i (cid:2) n, 1 (cid:2) j (cid:2) i2 (cid:2) i (cid:2) n, 0 (cid:2) j < i.Observe that D1 contains only static laws. A state, s, consistent with D1 corresponds to an arbitrary total interpretation onX together with a total interpretation on fluents Ci , 1 (cid:2) i (cid:2) n, such that Ci is true at s iff the interpretation on X satisfiesclause Ci . The latter is enforced by the first 4n laws in D1. The remaining laws cause a total interpretation on fluents F i, j ,1 (cid:2) j (cid:2) i (cid:2) n, such that F i, j is true at s iff the interpretation on X satisfies j clauses among {C1, . . . , Ci}.Now consider the following constraint ck:ALWAYS holds Fn,0 ∨SOMETIMES holds Fn,k ∧ ALWAYS (¬holds Fn,k+1 ∧ · · · ∧ ¬holds Fn,n) ∨. . .SOMETIMES holds Fn,lk ∧ ALWAYS (¬holds Fn,lk+1 ∧ · · · ∧ ¬holds Fn,n),where l = (cid:30)n/k(cid:31).We show that the maximum number of clauses in F that can be simultaneously satisfied by an interpretation is 0 mod kiff D1 |(cid:6) ck.Only-if: Suppose that the maximum number o of clauses in F that can be simultaneously satisfied by an interpretationis 0 mod k. Consider o = 0 first. Then, no clause of F is satisfiable. By construction, F i,0 holds for 1 (cid:2) i (cid:2) n at everystate s of D1. In particular, Fn,0 holds at every state, and therefore ALWAYS holds Fn,0 is satisfied by D1, i.e., D1 |(cid:6) ck.Now let o > 0. W.l.o.g. o = ak for some 1 (cid:2) a (cid:2) l. Then, by construction Fn, j is false for o < j (cid:2) n at every state s of D1.Therefore, D1 |(cid:6) ALWAYS (¬holds Fn,ak+1 ∧ · · · ∧ ¬holds Fn,n). Also by construction, Fn,o is true at a state corresponding toan assignment that maximizes the simultaneously satisfied clauses. This implies D1 |(cid:6) SOMETIMES holds Fn,ak. Observingthat, together, these two constraints constitute a conjunct of ck, we conclude that D1 |(cid:6) ck.If: Suppose D1 |(cid:6) ck, and assume D1 |(cid:6) ALWAYS holds Fn,0 first. Then, by construction no clause in F is satisfiable, hencethe maximum number o of clauses in F that can be simultaneously satisfied by an interpretation is 0 and thus o ≡ 0 mod k.Now let any other conjunct of ck be satisfied by D1, i.e., for some 1 (cid:2) a (cid:2) l it holds that D1 |(cid:6) SOMETIMES holds Fn,ak andD1 |(cid:6) ALWAYS (¬holds Fn,ak+1 ∧ · · · ∧ ¬holds Fn,n). Then, there is a state s at which Fn,ak is true. By construction, thismeans that ak clauses of F can simultaneously be satisfied. Moreover, Fn, j is false at every state s of D1 if j > ak. Againby construction, this implies that ak is the maximum number of clauses in F that can be simultaneously satisfied. Sinceak ≡ 0 mod k this proves the claim.T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–12211207For hardness in Case (ii), consider m quantified Boolean formulas of form Φl = Q 1 Xln El, 1 (cid:2) l (cid:2) m, where1 Q 2 Xlj , 1 (cid:2) i, j (cid:2) n and 1 (cid:2) k, l (cid:2) m, are pairwise disjunct sets ofQ i = ∃ if i ≡ 1 mod 2 and Q i = ∀ otherwise, X kpropositional variables if i (cid:16)= j or k (cid:16)= l. and El is Boolean formula over atoms in Xl = Xln, such that if Φl is1false then Φl+1, . . . , Φm are false, too. Deciding whether the maximum index o, 1 (cid:2) o (cid:2) m, such that Φo is true, is odd isΘ Pn+1-hard.We reduce the problem of deciding D |(cid:6) c for a constraint c with nesting depth k of dynamic constraints to this problem,i and Xl∪ · · · ∪ Xl· · · Q n Xl2as follows.Let n = k + 2, 1 (cid:2) l (cid:2) m, and let D2 be the action description consisting of the statements:(cid:7)caused F lcaused ¬F lcaused F lcaused ¬F li after Ai−1,i after Ai−1,i if F li if ¬F lj after Ai−1 ∧ F lj,j after Ai−1 ∧ ¬F lj,2 (cid:2) i (cid:2) n, F li∈ Xli(cid:8)2 (cid:2) i (cid:2) n, 1 (cid:2) j (cid:2) n, i (cid:16)= j, F lj∈ Xlj.Observe that a state s of D2 corresponds to an arbitrary consistent total interpretation over X 1 ∪ · · · ∪ Xm. Note also that(cid:5)(cid:8) (1 (cid:2) i (cid:2) n − 1) is a transition in the transition diagram described by D2 iff all fluents are interpreted identically(cid:7)s, { Ai}, sexcept those over X 1∪ · · · ∪ Xmi+1i+1.Consider the constraint:(cid:9) (cid:10)(cid:10)(m−3)/2l=0(m−2)/2l=0co =where(SOMETIMES f 2l+1 ∧ ALWAYS ¬ f 2l+2) ∨ gm if m is odd,(SOMETIMES f 2l+1 ∧ ALWAYS ¬ f 2l+2)otherwise,gm = SOMETIMES f m,f l = p1 N p1. . .(cid:2)(cid:2)andpn−1 N pn−1 holds Elafter { An−1}(cid:3)(cid:3). . .after { A1},where N = necessarily, and where pi = ¬ if i is even and pi is void otherwise, for 1 (cid:2) i (cid:2) n − 1.∪ · · · ∪ Xl∪ · · · ∪ Xln will turn the assignment on Xl1We first prove that Φl is true iff there exists a state s of D2, such that D2, s |(cid:6) f l.For the only-if direction suppose Φlis true. We show by a recursive argument that if a state s0 coincides with a1 then D2, s0 |(cid:6) f l. Assume that sn−2 is a state of D2 that coincides with asatisfying truth assignment for Φl on Xln−1. We show that D2, sn−2 |(cid:6) pn−1 N pn−1 holds El after { An−1}. If∪ · · · ∪ Xlsatisfying truth assignment for Φl on Xl1n − 1 is odd then Q n = ∀. Thus, any assignment on Xln−1 given by sn−2into a satisfying assignment for El. Thus, every transition by { An−1} from sn−2 will lead to a state sn−1 that satisfiesEl. This proves D2, sn−2 |(cid:6) necessarily holds El after An−1 if n − 1 is odd. So let n − 1 be even. Then Q n = ∃. In thisn that, together with the assignment on Xlcase, there exists an assignment on Xln−1 given by sn−2, is a sat-1isfying assignment for El. Thus, there is a transition by { An−1} from sn−2 to a state sn−1 that satisfies El. Therefore,D2, sn−2 |(cid:6) ¬necessarily ¬holds El after An−1 if n − 1 is even. In any case, D2, sn−2 |(cid:6) pn−1 N holds pn−1 El after { An−1}.Applying this argument recursively proves the claim that if a state s0 coincides with a satisfying truth assignment for Φl on1, then D2, s0 |(cid:6) f l, and thus, that there exists a state of D2 such that D2, s |(cid:6) f l.XlFor the if-direction let s be a state of D2, such that D2, s |(cid:6) f l. We establish the truth of Φl recursively as follows.Let h = s, A1, s1, . . . , sn−3 An−2, sn−2 be a history of D2. We show that sn−2 is a state of D2 that coincides with a truthn−1, such that Q n El is true. If n − 1 is odd, then D2, sn−2 |(cid:6) necessarily holds El after An−1,∪ · · · ∪ Xlassignment on Xl1since D2, s |(cid:6) f l. Thus, any assignment on Xln will turn the assignment on Xln−1 given by sn−2 into a satisfying1assignment for El. If n − 1 is even, then D2, sn−2 |(cid:6) ¬necessarily ¬holds El after An−1, since D2, s |(cid:6) f l. Therefore, thereexists an assignment on Xln−1 given by sn−2 into a satisfying assignmentfor El. Hence, in any case Q n El is true. Applying this argument recursively proves the claim that D2, s |(cid:6) f l implies thetruth of Φl.n that will turn the assignment on Xl1We now show that the maximum index o such that Φo is true, is odd iff D2 |(cid:6) co.Only-if: Let the maximum index o such that Φo is true be odd. Consider any state s of D2 such that D2, s |(cid:6) f o. If o = mof D2. Hence, D2 |(cid:6) SOMETIMES f o andthis proves D2 |(cid:6) co. So let o < m. Then additionally D2, s (cid:16)|(cid:6) f o+1, for every state sD2 |(cid:6) ALWAYS ¬ f o+1, i.e., for l = (o − 1)/2 D2 |(cid:6) SOMETIMES f 2l+1 ∧ ALWAYS ¬ f 2l+2. This proves D2 |(cid:6) co.If: Assume D2 |(cid:6) co. If m is odd and D2 |(cid:6) gm. Then m is the maximum index o such that Φo is true, and o is odd. Thisproves the claim. So consider the remaining cases, i.e., there is an index l (0 (cid:2) l (cid:2) (m − 3)/2 if m is odd and 0 (cid:2) l (cid:2) (m − 2)/2,otherwise), such that D2 |(cid:6) SOMETIMES f 2l+1 ∧ ALWAYS ¬ f 2l+2. Then, there is a state s of D2 such that f 2l+1 is satisfied,whereas f 2l+2 is not satisfied at any state sof D2. Let o = 2l + 1. We conclude that Φo is true and Φo+1 is false. Thus, ois the maximum index such that Φo is true, and it is odd. This proves the claim and therefore Θ Pk+3-hardness. (cid:3)n+1-hardness, i.e., Θ P∪ · · · ∪ Xl∪ · · · ∪ Xl(cid:5)(cid:5)1208T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–1221Theorem 5. Deciding whether a given ADU problem (D, I, C, (cid:2)C ) has a solution (or a pre-solution) is(i) PSPACE-complete in general,(ii) Σ P(iii) Σ P(iv) NP-complete if Co = ∅.k+3-complete, if k is the maximal nesting depth of dynamic constraints in Co,2 -complete, if Co does not involve dynamic constraints, andProof. Membership: Follows from Theorems 3 and 4.Hardness: Hardness in Case (i) follows from Theorem 4. For (ii) let n = k + 2 and let Φ = ∃Y Q 1 X1 · · · Q n Xn E be a QBF,where Q i = ∃ if i ≡ 0 mod 2 and Q i = ∀ otherwise. ConsiderD u = D2 ∪ {caused Y i after Ai−1 ∧ Y i, caused ¬Y i after Ai−1 ∧ ¬Y i | 2 (cid:2) i (cid:2) n},where D2 is the action description from the proof of Theorem 4 with l = 1, Dm = {caused Y i, caused ¬Y i | Y i ∈ Y }, I = ∅,C = Co ∪ C p with C p = ∅, and Co = {co}, whereco = ALWAYS p1 N p1. . .pn−1 N pn−1 holds E after { An−1}. . .after { A1},(cid:2)(cid:2)(cid:3)(cid:3)and where N = necessarily, and pi = ¬ if i is odd and void otherwise, for 1 (cid:2) i (cid:2) n − 1. We show that there exists asolution to the action description update problem (D u ∪ Dm, I, C, (cid:2)C ) iff Φ is true.For the only-if direction, let D u ⊆ Dcoincide withsome interpretation on Y and an arbitrary interpretation on X1, . . . , Xn. By the same arguments as in the hardness proof ofTheorem 4(ii), the fact that D(cid:5) |(cid:6) Co witnesses the truth of Φ.For the if-direction let Φ be true. Consider a satisfying truth assignment on Y , let Dis consistent and states of D(cid:5) ⊆ D u ∪ Dm be a solution. Then D(cid:5)(cid:5)(cid:5) = D u ∪ D(cid:5)m. Then, D(cid:5)is consistent and D u ⊆ D(cid:5) |(cid:6) Co. This proves that D(cid:5)m be the set of static causal laws(cid:5) ⊆ D u ∪ Dm. Moreover,is a pre-solution, and hence(cid:5)from Dm compliant with this assignment, and let Dby the same arguments as in the hardness proof of Theorem 4(ii), Dthe existence of a solution.For (iii) let Φ = ∃Y ∀ X E and consider the action description update problem (D u ∪ Dm, I, C, (cid:2)C ), where D u = ∅, Dm ={caused Y i, caused ¬Y i | Y i ∈ Y }, I = ∅, and C = Co = {ALWAYS holds E}. We prove that the action description updateproblem (D u ∪ Dm, I, C, (cid:2)C ) has a solution iff Φ is true.For the only-if direction, let D u ⊆ Dcoincide with some(cid:5) |(cid:6) Co, E is true at every such state, witnessing that anyinterpretation on Y and an arbitrary interpretation on X . Since Dtruth assignment on X turns the joint assignment on both, Y and X , into a satisfying assignment for E. This proves thetruth of Φ.is consistent and states of D(cid:5) ⊆ Dm be a solution. Then D(cid:5)(cid:5)For the if-direction let Φ be true. Consider a satisfying truth assignment on Y , and let Dbe the set of static causal laws(cid:5) ⊆ Dm. Moreover, since Φ is true, any truthfrom Dm compliant with this assignment. Then, Dassignment on X turns the joint assignment on both, Y and X , into a satisfying assignment for E. Therefore, E holds at allstates of Dis a pre-solution, and hence the existence of a solution.is consistent and D u ⊆ D(cid:5) |(cid:6) Co . This proves that D, witnessing DFinally, for (iv), let E be a Boolean formula over atoms Y and let us define D u = {caused Y 1 if ¬E, caused ¬Y 1 if ¬E},Dm = {caused Y i, caused ¬Y i | Y i ∈ Y }, I = ∅, and C = ∅. Then, (D u ∪ Dm, I, C, (cid:2)C ) has a solution iff E is satisfiable.(cid:5)(cid:5)(cid:5)For the only-if direction, let D u ⊆ D(cid:5) ⊆ D u ∪ Dm be a solution. Then D(cid:5)is consistent and states of Dcoincide with some(cid:5)(cid:5)interpretation on Y . Since D u ⊆ D(cid:5), E is true at every such state. This proves the satisfiability of E.For the if-direction let E be satisfiable. Consider a satisfying truth assignment on Y , and let Dlaws from Dm compliant with this assignment. Then, D(cid:5)trivially. This proves that Dis a pre-solution, and hence the existence of a solution. (cid:3)(cid:5) = D u ∪ D(cid:5)m is consistent and D u ⊆ D(cid:5)m be the set of static causal(cid:5) |(cid:6) Co(cid:5) ⊆ D u ∪ Dm. Moreover DTheorem 6. Given an ADU problem (D, I, C, ⊂) and an action description D(cid:5), deciding whether D(cid:5)is a solution for it is(i) PSPACE-complete for general constraints in Co ,(ii) Π P(iii) Π P(iv) DP -complete if Co = ∅.k+3-complete if k is the maximal nesting depth of dynamic constraints in Co ,2 -complete if Co does not involve dynamic constraints, andProof. Membership: Follows from Theorem 3, observing that for any given action descriptions Dcan be done in polynomial time, i.e., that Pcheck is in P for ⊂.Hardness: Hardness in Case (i) follows from Theorem 4. For (ii) let n = k + 2 and let Φ = ∀Y Q 1 X1 · · · Q n Xn E be a QBF,(cid:5)(cid:5)(cid:5)and D, deciding D(cid:5) ⊂ D(cid:5)(cid:5)where Q i = ∃ if i ≡ 1 mod 2 and Q i = ∀ otherwise. ConsiderD u = D2 ∪ {caused Y i after Ai−1 ∧ Y i, caused ¬Y i after Ai−1 ∧ ¬Y i | 2 (cid:2) i (cid:2) n},where D2 is the action description from the proof of Theorem 4 with l = 1, Dm = {caused Y i, caused ¬Y i | Y i ∈ Y }, I = ∅,and C = Co = {ALWAYS f ∨ g}, whereT. Eiter et al. / Artificial Intelligence 174 (2010) 1172–12211209(cid:2)(cid:2). . .pn−1 N ¯pn−1 holds E after { An−1}(cid:3)(cid:3). . .after { A1},f = p1 N p1(cid:4)g =SOMETIMES holds Y i ∧ SOMETIMES holds ¬Y i,Y i ∈Ywhere N = necessarily, pi = ¬ if i is odd and void otherwise, for 1 (cid:2) i (cid:2) n − 1, and ¯pn − 1 = ¬ if n is odd and voidotherwise. We show that D u is a solution to the action description update problem (D u ∪ Dm, I, C, ⊂) iff Φ is true.Obviously, D u is consistent and I ⊆ D u . Additionally, states of D u consist of arbitrary truth assignments to Y andX1, . . . , Xn. Therefore, D u satisfies g, and hence D u |(cid:6) Co. This proves that D u is a pre-solution. We show that it is amaximum pre-solution iff Φ is true.For the only-if direction, towards a contradiction assume that Φ is false. Then ¬Φ is true. Observe that ¬Φ is a QBFof the form considered in the hardness proof of Theorem 5(ii) with E negated. Applying the arguments of this proof, weobtain that there exists a set D u ⊂ D. (Notethat ¯pn−1 accounts for the negation of E.) Therefore Dis a pre-solution. This contradicts the maximalityof D u .(cid:5)(cid:5) |(cid:6) Co, and thus D(cid:5) ⊆ D u ∪ Dm, such that Dfor every state s of Dis consistent and D(cid:5), s |(cid:6) f(cid:5)(cid:5)fFor the if-direction, towards a contradiction assume that D u is not maximal. Then, all states of a maximum solutioncoincide on at least one assignment to some Y i ∈ Y , and therefore it does not satisfy g. Consequently,is satisfied at allstates of a maximum solution. Applying the arguments of the hardness proof of Theorem 5(ii), we conclude that ¬Φ is true,a contradiction.For (iii) let Φ = ∀Y ∃ X E and consider the action description update problem (D u ∪ Dm, I, C, ⊂), where D u = ∅, Dm ={caused Y i, caused ¬Y i | Y i ∈ Y }, I = ∅, and C = Co = {ALWAYS ¬holds E ∨ g}, with g as before. We prove that the actiondescription update problem (D u ∪ Dm, I, C, ⊂) has D u = ∅ as a solution iff Φ is true.Obviously, D u is consistent and I ⊆ D u . Additionally, states of D u consist of arbitrary truth assignments to Y and X .Therefore, D u satisfies g, and hence D u |(cid:6) Co . This proves that D u is a pre-solution. We show that it is a maximum pre-solution iff Φ is true.For the only-if direction, towards a contradiction assume that Φ is false. Then ¬Φ is true. Observe that ¬Φ is a QBFof the form considered in the hardness proof of Theorem 5(iii) with E negated. Applying the arguments of this proof, we(cid:5) |(cid:6) Co . Therefore,obtain that there exists a set D u ⊂ DDis a pre-solution, which contradicts the maximality of D u .For the if-direction, towards a contradiction assume that D u is not maximal. Then, all states of a maximum solutioncoincide on at least one assignment to some Y i ∈ Y , and therefore it does not satisfy g. Consequently, a maximum solutionmust satisfy ALWAYS ¬holds E. Applying the arguments of the hardness proof of Theorem 5(iii), we conclude that ¬Φ istrue, a contradiction.(cid:5) |(cid:6) ALWAYS ¬holds E, i.e., D(cid:5) ⊆ Dm, such that Dis consistent and DFinally (iv), let E1 and E2 be Boolean formulas over atoms Y 1 and Y 2, respectively. Consider D u = {caused ¬F , caused Fif ¬E1}, Dm = {caused F if ¬E2}, I = ∅, and C = ∅. Then, (D u ∪ Dm, I, C, ⊂) has solution D u iff E1 is satisfiable and E2 isunsatisfiable.(cid:5)(cid:5)Obviously, I ⊆ D u , and D u |(cid:6) Co. Therefore, D u is a solution iff it is consistent and maximal, i.e., no superset of D u isconsistent. We show that this two conditions hold iff E 1 is satisfiable and E2 is unsatisfiable.For the only-if direction, assume that D u is consistent and maximal. Then E1 is satisfiable witnessed by the truthassignment to Y 1 of any state of D u . Furthermore, D u ∪ Dm is inconsistent (otherwise it would be a solution, since ittrivially satisfies Co), which implies that E2 is unsatisfiable.For the if-direction, let E1 be satisfiable and E2 be unsatisfiable. Then any satisfying assignment to fluents in Y 1 togetherwith assigning falsity to F and any truth assignment to fluents from Y 2 yields a state of D u witnessing its consistency.Moreover, D u ∪ Dm is inconsistent due to the unsatisfiability of E 2, which implies that D u is maximal. This proves DP -hardness. (cid:3)Theorem 7. Given an ADU problem (D, I, C, <weightq ) and an action description D(cid:5), deciding whether D(cid:5)is a solution for it is(i) PSPACE-complete for general constraints in C ,(ii) Π P(iii) Π P(iv) NP-complete if C = ∅.k+3-complete if k is the maximal nesting depth of dynamic constraints in C ,2 -complete if C does not involve dynamic constraints, andProof. Membership: For (i), (ii), and (iii) membership follows from Theorems 3 and 4. Note that in order to decideD2 for any action descriptions D1 and D2, such that D u ∪ I ⊆ D i ⊆ D ∪ I for i ∈ {1, 2}, and a set of weightedD1 <weightqconstraints C p , we decide D i |(cid:6) c, for every c ∈ C p (i.e., polynomially many), and sum up the corresponding weights inpolynomial time. Thus, if D i |(cid:6) c can be decided in polynomial space, respectively in polynomial time with the help of a. For (iv), i.e. C = ∅, Pcheck is trivial for <weightqΣ P.In this case we can decide whether Din polyno-(cid:5) ⊆ D ∪ I in polynomial time. This provesmial time (witnessing consistency) and additionally checking D u ∪ I ⊆ DNP-membership for (iv).i−1-oracle, then Pcheck is in PSPACE, respectively in (cid:5)Pis a solution by guessing a state s and checking that it is a state of Di , for <weightqand D(cid:5)(cid:5)(cid:5)1210T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–1221(cid:5)(cid:5)Hardness: Hardness in Case (i) follows easily from Theorem 4. For (ii) let n = k + 2 and consider Φ, D u , Dm, I , andCo from the proof of Theorem 6(ii). Additionally, let C p = {ALWAYS holds Y i, ALWAYS holds ¬Y i | Y i ∈ Y } and consider a(cid:5) ⊆ D u ∪ Dm, since weightq(D u) = 0, whereas all statesweight of 1 for each c ∈ C p . Then, D u <weightqcoincide on at least one assignment to some Y i ∈ Y , thus making at least one of the constraints in C p true, i.e.,of D(cid:5)) (cid:3) 1. Therefore, D u is a solution to (D u ∪ Dm, I, Co ∪ C p, <weightq ) iff it is a solution to (D u ∪ Dm, I, Co, ⊂), whichweightq(Dproves Π Pk+3-hardness (cf. Theorem 6(ii)).Y i ∈ Y } with weight 1 for each c ∈ C p . Then, for the same reason as above, D u <weightqTherefore, D u is a solution to (D u ∪ Dm, I, Co ∪ C p, <weightq ) iff it is a solution to (D u ∪ Dm, I, Co, ⊂), proving Π PFor (iii) consider Φ, D, I , and Co from the proof of Theorem 6(ii). Again, let C p = {ALWAYS holds Y i, ALWAYS holds ¬Y i |(cid:5) ⊆ D u ∪ Dm.2 -hardness.Finally (iv), let E be a Boolean formula over atoms Y and consider the ADU problem given by D u = {caused Y 1 if ¬E,for every D u ⊂ Dfor every D u ⊂ DDDcaused ¬Y 1 if ¬E}, Dm = ∅, I = ∅, and C = ∅. Then, D u is a solution to (D u ∪ Dm, I, C, <weightq ) iff E is satisfiable.(cid:5)For the only-if direction, let D u be a solution. Then D u is consistent, states of D u coincide with some interpretation onY , and E is true at every such state. This proves the satisfiability of E.For the if-direction let E be satisfiable. A satisfying truth assignment on Y is a state of D u , i.e., D u is consistent. Moreover,D u ∪ I ⊆ D u ⊆ D ∪ I and D u |(cid:6) Co trivially. And since D u ∪ I = D u = D ∪ I , we conclude that D u is a solution. (cid:3)Appendix B. Proofs for Section 6Prior to the proof of Proposition 4, we establish the following lemma which pinpoints the relation between states andobtained by an (arbitrary) selection of modifiable laws.transitions of an update description U and any action description D(cid:5)Lemma 3. Let D = D u ∪ Dm be an action description, and let Dby Ddiagram described by U . Let M be the subset of H labeling the laws in D(cid:5)m be a subset of Dm. Let (cid:7)S, V , R(cid:8) be the transition diagram described(cid:5)m. Let U = U (D) be the update description of D, with a set H of update fluents, and let (cid:7)S U , V U , R U (cid:8) be the transition(cid:5) = D u ∪ D(cid:5)m. Then the following hold:(i) s \ H ∈ S iff s ∈ S U and s ∩ H = M,(cid:5)(cid:8) in R U iff s =H s(ii) (cid:7)s, A, s(iii) (cid:7)s \ H, A, s, and(cid:5) \ H(cid:8) ∈ R iff (cid:7)s, A, s(cid:5)(cid:5)(cid:8) ∈ R U and s ∩ H = M.Proof. (i) For the only-if direction consider any state s ∈ S. By the definition of a transition diagram described by an actiondescription, for every static law (4) in D, s satisfies G ⊃ L.(cid:5)Case 1. Take any static law (4) in U , that does not contain any H i ∈ H. By the definition of an update description, this staticlaw is in D u as well. Then, since s satisfies G ⊃ L, s ∪ M satisfies G ⊃ L.Case 2. Take any static law (15) in U such that H i ∈ M. By the definition of an update description, there is a correspondingstatic law (4) in D(cid:5)m. Then, since s satisfies G ⊃ L, s ∪ M satisfies G ∧ H i ⊃ L.Case 3. Take any static law (15) in U such that H i /∈ M. Since s ∪ M does not satisfy G ∧ H i , s ∪ M satisfies G ∧ H i ⊃ L.By the definition of an update description, U does not contain any other static laws. Therefore, from these three cases, itfollows that s ∪ M is a state in S U .For the if-direction consider any state s in S U , such that s ∩ H = M. By the definition of a transition diagram describedby an action description, for every static law (4) in U , s satisfies G ⊃ L.Case 1. Take any static law (4) in D u . By the definition of an update description it is also in U , and it does not contain anyelement of H. Therefore, s \ H satisfies G ⊃ L.(cid:5)Case 2. Take any static law (4) in Dm, there is astatic law (15) in U . Since, for every corresponding static law (15) in U , s satisfies G ∧ H i ⊃ L, and since by assumption H iis in s, s \ H satisfies G ⊃ L.(cid:5)m. By the definition of an update description, for every static law (4) in DFrom these two cases, it follows that, for every static law (4) in D(ii) Since no element of H appears in the head of any causal law in U except for the inertia laws (17), we conclude that, s \ H satisfies G ⊃ L. Thus, s \ H is in S.(cid:5)(cid:7)s, A, s(cid:5)(cid:8) in R U iff s =H s(cid:5).(iii) For the only-if direction consider any (cid:7)s, A, sdescription, for every dynamic law (5) in Dsatisfies G). Due to (i), both s ∪ M and s(cid:5), s(cid:5)(cid:5) ∪ M are in S U .(cid:5)(cid:8) in R. By the definition of a transition diagram described by an action(cid:5)(cid:5)(cid:8) (i.e., s ∪ A satisfies H and ssatisfies L if the law is applicable to (cid:7)s, A, sT. Eiter et al. / Artificial Intelligence 174 (2010) 1172–12211211Fig. 8. The Zoo World: animals.Case 1. Consider any dynamic law (5) in U , that does not contain any H i ∈ H. Suppose that it is applicable to (cid:7)s ∪ M, A, sM(cid:8). Then, since no H i ∈ H occurs in this law, it is applicable to (cid:7)s, A, s(cid:5)(cid:8) is in R, sthis law is in D u . Since (cid:7)s, A, s(cid:5) ∪(cid:5)(cid:8) as well. By the definition of an update description,(cid:5) ∪ M satisfies L.satisfies L. Then s(cid:5)Case 2. Consider any dynamic law (16) in U , that is not of the form (17), where H i labels a dynamic law (5) in DH i ∈ M. Suppose that it is applicable to (cid:7)s ∪ M, A, sdoes not contain any H i ∈ H, s ∪ A satisfies H ; since G does not contain any H i ∈ H, sdynamic law (5) in D(cid:5) ∪ M(cid:8). That is, s ∪ M ∪ A satisfies H ∧ H i and s(cid:5)m, i.e.,(cid:5) ∪ M satisfies G. Since Hsatisfies G. Then, the corresponding(cid:5) ∪ M satisfies L.(cid:5)(cid:8). Since (cid:7)s, A, ssatisfies L. Then, s(cid:5)(cid:8) is in R, s(cid:5)m is applicable to (cid:7)s, A, s(cid:5)(cid:5)1212T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–1221Fig. 9. The Zoo World: movement.Case 3. Consider any dynamic law (17) in U . By (ii) we conclude that (cid:7)s, A, s(cid:5) ∪ M satisfies H i . Therefore, this law is applicable to (cid:7)s ∪ M, A, ssConsequently, M is the only interpretation on H satisfying the heads of the applicable inertia laws.(cid:5). Hence, s ∪ M satisfies H i iff(cid:5) ∪ M(cid:8) iff L = H i and H i is in M, or L = ¬H i and H i /∈ M.(cid:5)(cid:8) in R U iff s =H sBy the definition of an update description, U does not contain any other dynamic laws applicable to (cid:7)s ∪ M, A, sSo far we have shown that, (a) for every (cid:7)s, A, s(cid:5)(cid:8) in R, s(cid:5) ∪ M(cid:8). Moreover, we can observe that (b) for each dynamic law in D(cid:5) ∪ M satisfies the heads of every dynamic law in U that is(cid:5)(cid:8), there(cid:5)(cid:5) ∪ M(cid:8), and that (c) except for the inertia laws (17), U does not containapplicable to (cid:7)s, A, s(cid:5) ∪ M(cid:8).applicable to (cid:7)s ∪ M, A, sis a corresponding law in U applicable to (cid:7)s ∪ M, A, sany other dynamic laws applicable to (cid:7)s ∪ M, A, s(cid:5)(cid:5) ∪ M(cid:8).Since we know that sis the only interpretation satisfying the heads of all dynamic laws in D(cid:5)(cid:8), it(cid:5) ∪ M is the only interpretation satisfying the heads of all dynamic laws in Uapplicable to (cid:7)s, A, s(cid:5)follows from (a)–(c) and Case 3 above, that sapplicable to (cid:7)s ∪ M, A, s(cid:5) ∪ M(cid:8). Therefore, (cid:7)s ∪ M, A, s(cid:5) ∪ M(cid:8) is in R U .For the if-direction consider any (cid:7)s, A, s(cid:5) ∩ H = M. Due to (i) above, s \ H and sBy the definition of a transition diagram described by an action description, for every dynamic law (5) in U , sthe law is applicable to (cid:7)s, A, s(cid:5)(cid:8) (i.e., s ∪ A satisfies H and s(cid:5)(cid:8) in R U , such that s ∩ H = ssatisfies G).(cid:5) \ H are in S.(cid:5)satisfies L if(cid:5). Suppose that it is applicable to (cid:7)s \ H, A, s(cid:5)(cid:5) \ H(cid:8). That is, (s \ H) ∪ A satisfies H andConsider any dynamic law (5) in D(cid:5) \ H satisfies G.sCase 1. This law is in D u . Since G and H do not contain any element of H, s ∪ A satisfies H and slaw (5) is applicable to (cid:7)s, A, sin R U , ssatisfies L. Since L does not contain any element of H, s(cid:5)(cid:8) as well. By the definition of an update description, this law is also in U . Since (cid:7)s, A, ssatisfies G, and thus the(cid:5)(cid:8) is(cid:5) \ H satisfies L.(cid:5)(cid:5)T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–12211213Fig. 10. The Zoo World: actions, part 1.Case 2. This law is in DBy the definition of an update description, there is a corresponding law (16) in U , which is applicable to (cid:7)s, A, s(cid:7)s, A, s(cid:5)m. Since s contains every element H i of H labeling a dynamic law in Dsatisfies L. Since L does not contain any element of H, s(cid:5)m, s ∪ A satisfies H ∧ H i .(cid:5)(cid:8). Since(cid:5) \ H satisfies L.(cid:5)(cid:8) is in R U , s(cid:5)So far we have shown that, (a) for every (cid:7)s, A, s(cid:5) \ H satisfies the heads of every dynamic law in D(cid:5) \ H(cid:8). Moreover, we can observe that (b) for each dynamic law in U applicable to (cid:7)s, A, s(cid:5)(cid:8) in R U , sapplicable to (cid:7)s \ H, A, sfor the inertia laws (17), there is a corresponding law in Dany other dynamic laws applicable to (cid:7)s \ H, A, s(cid:5) \ H(cid:8).(cid:5)applicable to (cid:7)s \ H, A, s(cid:5) \ H(cid:8), and that (c) D(cid:5)(cid:5)that is(cid:5)(cid:8), exceptdoes not containSince we know that sit follows from (a)–(c) that s(cid:7)s \ H, A, s(cid:5) \ H(cid:8). Therefore, (cid:7)s \ H, A, s(cid:5) \ H(cid:8) is in R. (cid:3)(cid:5)is the only interpretation satisfying the heads of all dynamic laws in U applicable to (cid:7)s, A, s(cid:5) \ H is the only interpretation satisfying the heads of all dynamic laws in D(cid:5)(cid:5)(cid:8),applicable toProposition 4. Let (D, I, C, (cid:2)C ) be an ADU problem, with D = D u ∪ Dm. Let U be the update description of D ∪ I = D u ∪ I ∪ Dm,(cid:5) = D u ∪ I ∪ W is a pre-solution toand let W denote a subset of Dm containing laws labeled by the elements M ⊆ H in U . Then D(D, I, C, (cid:2)C ) iff M is an update set for U relative to Co.Proof. Let (D, I, C, (cid:2)C ) be an ADU problem, with D = D u ∪ Dm. Let U be the update description of D ∪ I = D u ∪ I ∪ Dm,with a set H of update fluents, describing the transition diagram T U = (cid:7)S U , V U , R U (cid:8). Let W be a subset of Dm containinglaws labeled by M ⊆ H in U . Let T = (cid:7)S, V , R(cid:8) be the transition diagram described by Disa pre-solution to (D, I, C, (cid:2)C ) iff M is an update set for U relative to Co.(cid:5) = D u ∪ I ∪ W . We show that D(cid:5)For the if-direction suppose that M is an update set for U relative to Co. We show that D(cid:2)C ) the definition of a solution hold.(cid:5)is a pre-solution to (D, I, C,(i) Since s ∩ H = M for some state s ∈ S U , and due to Lemma 3(i), S is not empty. Therefore, Dthat D u ∪ I ⊆ D(ii) It follows from the definition of D(iii) For any state s in S, observe that by Lemma 3(i), s ∪ M is in S U .(cid:5) ⊆ D ∪ I .(cid:5)(cid:5)is consistent.1214T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–1221Fig. 11. The Zoo World: actions, part 2.We show for any static or dynamic constraint c and any state s in S, that U , s ∪ M |(cid:6) c implies D(cid:5), s |(cid:6) c. Towards a(cid:5), s (cid:16)|(cid:6) c, and consider a static constraint c first. Since no element of H appears in c,contradiction assume U , s ∪ M |(cid:6) c and Dand the constraint is static, s ∪ M (cid:16)|(cid:6) c follows. However, this contradicts the assumption. So let c be a dynamic constraint(cid:5), sn (cid:16)|(cid:6) Q . We continue by induction on the nesting depth k of c. If k = 0,and h a history (11) in T such that s0 = s and Dthen Q is a static constraint and, since no element of H appears in c, it follows that sn ∪ M (cid:16)|(cid:6) Q . Moreover, by Lemma 3(iii),hU = s0 ∪ M, A0, s1 ∪ M, . . . , sn−1 ∪ M, An, sn ∪ Mis a history in T U . Thus, we conclude U , s ∪ M (cid:16)|(cid:6) c, a contradiction. So let us assume the claim holds for dynamic constraintswith maximum nesting depth k − 1, and consider a dynamic constraint of nesting depth k. Then, Q contains only static(cid:5), sn (cid:16)|(cid:6) Q implies U , sn ∪ M (cid:16)|(cid:6) Q .constraints and dynamic constraints of nesting depth at most k − 1. By hypothesis, DFurthermore, again by Lemma 3(iii), the history hU corresponding to h is a history in T U . Thus, we conclude U , s ∪ M (cid:16)|(cid:6) c, a(cid:5), s |(cid:6) c for all s in S, and any static or dynamic constraint c, and thus alsocontradiction. This proves U , s ∪ M |(cid:6) c implies Dfor any open constraint c.We continue considering existential and universal constraints c. We show that if c holds at s ∪ M w.r.t. S UH,s∪M, then(cid:5) |(cid:6) c. For an existentially quantified open constraint Q , the claim follows from the fact that, by definition, if c holds at(cid:5) \ H is a state(cid:5) |(cid:6) c. So let c be a(cid:5) ∈ S U exists such that U , s(cid:5) |(cid:6) Q and the fact that Q is open, it follows that D(cid:5) =H s. By Lemma 3(i), we conclude that sH,s∪M, some s. Moreover, from U , sDs ∪ M w.r.t. S Uof D(cid:5) \ H |(cid:6) Q , and hence D(cid:5) |(cid:6) Q and s(cid:5), s(cid:5)T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–12211215Fig. 12. The Zoo World: actions, part 3.(cid:5)such that D(cid:5), s(cid:5) (cid:16)|(cid:6) Q . Note that by Lemma 3(i) s(cid:5), s(cid:5) |(cid:6) Q follows which is in contradiction with our assumption). However, U , sofuniversally quantified open constraint Q , and towards a contradiction, assume that D(cid:5) ∪ M (cid:16)|(cid:6) QD(cid:5) ∪ M (cid:16)|(cid:6) Q contradicts that c(otherwise D(cid:5) |(cid:6) c for every existential and universalholds at s ∪ M w.r.t. S Uconstraint c; the same follows for any Boolean combination of existential and universal constraints. This proves that if cholds at s ∪ M w.r.t. S U(cid:5) ∪ M ∈ S U . Moreover, since Q is open we conclude that U , sH,s∪M. Therefore, if c holds at s ∪ M w.r.t. S U(cid:5) |(cid:6) c, for any constraint c.H,s∪M, then D(cid:5) (cid:16)|(cid:6) c. Then, there exists a state s(cid:5)H,s∪M, then DFinally, we show that D(cid:5) |(cid:6) Co. Consider an arbitrary s ∈ S (which exists, since by (i) D(cid:5)(cid:5) |(cid:6) c for all c ∈ Co. This proves D. This means by definition that c holds at s w.r.t. S U(cid:5) |(cid:6) Co.be a pre-solution to (D, I, C, (cid:2)C ). We show that M is an update set for U relative to Co,is consistent). Then, due toH,s for every c ∈ Co. AsCondition (ii) for update fluent sets, s ∪ M ∈ S UCowe have shown above, this implies DFor the only-if direction let D(cid:5)i.e., (i) s ∩ H = M for some s ∈ S U , and (ii) S UH,s⊆ S UCo.is consistent there exists a state s ∈ S. Furthermore, by Lemma 3(i) we conclude that s ∪ M ∈ S U , for any(cid:5)(i) Since Dsuch state s.1216T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–1221Fig. 13. The Zoo World: actions, part 4.Fig. 14. The sample constraint given in Section 7.1 for updating the Zoo World into a little Circus, expressed as a query in CCalc.T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–12211217Fig. 15. The constraint of Fig. 14 modified by adding further constraints as described in Section 7.1.Fig. 16. A possible scenario which shows that the constraint of Fig. 15 is satisfied by the Zoo World (i.e., the Zoo World can be updated into a little Circus)if we remove the causal laws labeled by aux2(bart, homer, jumbo) and aux3(bart, homer, jumbo).(ii) We first show for any static or dynamic constraint c and any state s in S, that D(cid:5), s |(cid:6) c implies U , s ∪ M |(cid:6) c. Towards(cid:5), s |(cid:6) c and U , s ∪ M (cid:16)|(cid:6) c, and consider a static constraint c first. Since no element of H appearsa contradiction assume D(cid:5), s |(cid:6) c. So let c be a dynamicin c, and the constraint is static, s (cid:16)|(cid:6) c follows. However, this contradicts the assumption Dconstraint and hU a history (11) in T U such that s0 = s ∪ M and U , sn (cid:16)|(cid:6) Q . We continue by induction on the nesting depthk of c. If k = 0, then Q is a static constraint and, since no element of H appears in c, it follows that sn \ H (cid:16)|(cid:6) Q . Furthermore,by Lemma 3(ii), si =H s0 for 1 (cid:2) i (cid:2) n. Therefore, by Lemma 3(iii),h = s0 \ H, A0, s1 \ H, . . . , sn−1 \ H, An, sn \ H(cid:5), s (cid:16)|(cid:6) c, a contradiction. So let us assume the claim holds for dynamic constraints withis a history in T . Thus, we conclude Dmaximum nesting depth k −1, and consider a dynamic constraint of nesting depth k. Then, Q contains only static constraints(cid:5), sn \ H (cid:16)|(cid:6) Q . Furthermore, againand dynamic constraints of nesting depth at most k − 1. By hypothesis, U , sn (cid:16)|(cid:6) Q implies D(cid:5), s (cid:16)|(cid:6) c, a contradiction.by Lemma 3(ii) and (iii), the history h corresponding to hU is a history in T . Thus, we conclude D1218T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–1221Fig. 17. Monkeys exchanging hats.Fig. 18. The sample constraint to check that Snoopy and Abu can exchange hats.Fig. 19. The sample constraint to check that Snoopy and Abu can exchange hats, if we remove the causal laws labeled by aux4 from the description inFig. 17.T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–12211219Fig. 20. A possible scenario to show that the sample constraint to check that Snoopy and Abu can exchange hats is satisfied by the description in Fig. 17 ifwe remove the causal laws labeled by aux4.This proves Dconstraint c.(cid:5), s |(cid:6) c implies U , s ∪ M |(cid:6) c for all s in S, and any static or dynamic constraint c, and thus also for any openthat D(cid:5) ∈ S, such that D(cid:5) ∪ M |(cid:6) Q . Moreover s(cid:5) |(cid:6) c implies that c holds at s w.r.t. S UWe continue considering existential and universal constraints c. Let s be any state in S U such that s ∩ H = M. We showH,s. For an existentially quantified open constraint Q , the claim follows from the(cid:5) ∪ M is a state in S U , and since Q is open, itH,s by definition. So let c be a universallyH,s. Then there exists(cid:5), s (cid:16)|(cid:6) Q follows. However, this, and since Q is open, DH,s for every existential and universal constraint c; the(cid:5) |(cid:6) c implies that cfact that then there exists a state sfollows that U , squantified open constraint Q , and towards a contradiction, assume that c does not hold at s w.r.t. S U(cid:5) \ M is a state of D(cid:5) ∈ S Us(cid:5) |(cid:6) c, then c holds at s w.r.t. S Ucontradicts Dsame follows for any Boolean combination of existential and universal constraints. This proves that Dholds at s w.r.t. S U(cid:5) ∪ M =H s, and hence, c holds at s w.r.t. S U(cid:5) (cid:16)|(cid:6) Q . By Lemma 3(i) s(cid:5) |(cid:6) Q . By Lemma 3(i) s(cid:5) |(cid:6) c. Therefore, if DH,s, such that U , s(cid:5), s(cid:5)H,s.Therefore, given that D(cid:5)is a pre-solution and hence D(cid:5) |(cid:6) Co, we conclude that S UH,s⊆ S UCo. (cid:3)Appendix C. The Zoo World in CThe Zoo World was described in the action language C+ and presented in the language of CCalc in [1], in five parts:animals (zoo-animals), movement (zoo-movement), actions (zoo-actions), landscape (zoo-landscape), as wellas their union (zoo). We have transformed the first three components into C (in the language of CCalc as well)12 asshown in Figs. 8–13, by replacing the non-Boolean fluents of the form pos(Animal) = Position with Boolean fluentspos(Animal,Position), and by adding several causal laws to make sure that they express the same fluent13:constraint[\ /P | pos(ANML, P)].caused -pos(ANML,P) if pos(ANML, P1) & P\ = {P}1.The first three forms of causal laws in Fig. 13 constitute the modifiable part Dm of this description. The sample constraintgiven in Section 7.1 can be represented by the CCalc query given in Fig. 14.Appendix D. Exchanging hats in the CircusConsider a Circus world including monkeys and dogs, where only monkeys can exchange hats with each other. We canobtain a C description of this world, from the C+ description of missionaries and cannibals exchanging hats [50], andpresent it to CCalc as in Fig. 17.Now consider a variation of the Zoo World described in Section 7.1, which involves also monkeys and dogs, where onlymonkeys can exchange hats. This variation of the Zoo World can be described by the union of the Zoo World descriptionD1 discussed in Section 7.1 (Figs. 8–13) and the description D0 mentioned above (Fig. 17).Suppose that we would like to update the action description D0 ∪ D1 of this extended Zoo World, to obtain a descriptionof a Circus where not only humans can mount on each other who further can mount on a large animal, but also animals canexchange hats with each other. Assume that the modifiable part D1m of D1 is the same as in Section 7.1, and the modifiablem of D0 consists of the last causal law in Fig. 17. The sample constraint given in Section 7.2 can be represented bypart of D0the CCalc query in Fig. 18. (See also Figs. 19 and 20.)12 The input language of CCalc is explained at its manual at http://www.cs.utexas.edu/users/tag/cc/, with further examples.13 In CCalc an expression of the form constraint G is called a constraint; it is shorthand for the causal law caused False if ¬G.1220T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–1221References[1] V. Akman, S.T. Erdogan, J. Lee, V. Lifschitz, H. Turner, Representing the zoo world and the traffic world in the language of the causal calculator, ArtificialIntelligence 153 (1–2) (2004) 105–140.[2] C. Alchourrón, P. Gärdenfors, D. Makinson, On the logic of theory change: Partial meet contraction and revision functions, Journal of Symbolic Logic 50(1985) 510–530.[3] J.J. Alferes, F. Banti, A. Brogi, From logic programs updates to action description updates, in: Proc. CLIMA V (revised selected and invited papers), in:Lecture Notes in Computer Science, vol. 3487, Springer, 2004, pp. 52–77.[4] J.J. Alferes, A. Brogi, J.A. Leite, L.M. Pereira, Evolving logic programs, in: Proc. JELIA-02, 2002, pp. 50–61.[5] J.J. Alferes, J.A. Leite, L.M. Pereira, H. Przymusinska, T.C. Przymusinski, Dynamic updates of non-monotonic knowledge bases, Journal of Logic Program-ming 45 (1–3) (2000) 43–70.[6] M. Balduccini, M. Gelfond, Logic programs with consistency-restoring rules, in: International Symposium on Logical Formalization of CommonsenseReasoning, AAAI 2003 Spring Symposium Series, 2003, pp. 9–18.[7] C. Baral, Y. Zhang, Knowledge updates: Semantics and complexity issues, Artificial Intelligence 164 (1–2) (2005) 209–243.[8] S. Benferhat, C. Cayrol, D. Dubois, J. Lang, H. Prade, Inconsistency management and prioritized syntax-based entailment, in: Proc. IJCAI-93, 1993,pp. 640–647.[9] D. Billington, G. Antoniou, G. Governatori, M.J. Maher, Revising nonmonotonic theories: The case of defeasible logic, in: Proc. German National Confer-ence on Artificial Intelligence (KI)-99, 1999, pp. 101–112.[10] C. Boutilier, A unified model of qualitative belief change: A dynamical systems perspective, Artificial Intelligence 98 (1–2) (1998) 281–316.[11] C. Cayrol, M.-C. Lagasquie-Schiex, T. Schiex, Nonmonotonic reasoning: From complexity to algorithms, Annals of Mathematics and Artificial Intelli-gence 22 (3–4) (1998) 207–236.[12] J. Chomicki, R. van der Meyden, G. Saake, Logics for Emerging Applications of Databases, Springer-Verlag, 2003.[13] R. Dechter, A. Itai, Finding all solutions if you can find one, Technical Report ICS-TR-92-61, University of California at Riverside, September 1992.[14] A. del Val, Y. Shoham, A unified view of belief revision and update, Journal of Logic and Computation 4 (5) (1994) 797–810.[15] J.P. Delgrande, T. Schaub, H. Tompits, S. Woltran, Merging logic programs under answer set semantics, in: P.M. Hill, D.S. Warren (Eds.), ICLP, in: LectureNotes in Computer Science, vol. 5649, Springer, 2009, pp. 160–174.[16] T. Eiter, E. Erdem, M. Fink, J. Senko, Updating action domain descriptions, in: Proc. IJCAI-05, 2005, pp. 418–423.[17] T. Eiter, E. Erdem, M. Fink, J. Senko, Resolving conflicts in action descriptions, in: Proc. ECAI-06, 2006, pp. 424–433.[18] T. Eiter, E. Erdem, M. Fink, J. Senko, Comparing action descriptions based on semantic preferences, Annals of Mathematics and Artificial Intelli-gence 50 (3–4) (2007) 273–304.[19] T. Eiter, W. Faber, N. Leone, G. Pfeifer, A. Polleres, A logic programming approach to knowledge-state planning: Semantics and complexity, ACMTransactions on Computational Logic 5 (2) (2004) 206–263.[20] T. Eiter, M. Fink, G. Sabbatini, H. Tompits, On properties of update sequences based on causal rejection, Theory and Practice of Logic Programming 2 (6)(2002) 721–777.[21] T. Eiter, M. Fink, J. Senko, A tool for answering queries on action descriptions, in: Proc. JELIA-06, in: Lecture Notes in Computer Science, vol. 4160,Springer, 2006, pp. 473–476.[22] T. Eiter, M. Fink, J. Senko, Error classification in action descriptions: A heuristic approach, in: Proc. AAAI-08, AAAI Press, 2008, pp. 905–910.[23] T. Eiter, G. Gottlob, On the complexity of propositional knowledge base revision, updates, and counterfactuals, Artificial Intelligence 57 (2–3) (1992)227–270.[24] T. Eiter, T. Lukasiewicz, Default reasoning from conditional knowledge bases: Complexity and tractable cases, Artificial Intelligence 124 (2) (2000)169–241.[25] E.A. Emerson, Temporal and modal logic, in: J. van Leeuwen (Ed.), Handbook of Theoretical Computer Science, Volume B: Formal Models and Seman-tics (B), Elsevier, 1990, pp. 995–1072.[26] M. Freund, On the revision of preferences and rational inference processes, Artificial Intelligence 152 (1) (2004) 105–137.[27] N. Friedman, J.Y. Halpern, Belief revision: A critique, Journal of Logic, Language and Information 8 (4) (1999) 401–420.[28] N. Friedman, J.Y. Halpern, Modeling belief in dynamic systems, part II: Revision and update, Journal of Artificial Intelligence Research 10 (1999) 117–167.[29] M. Gelfond, V. Lifschitz, The stable model semantics for logic programming, in: Proc. International Conference and Symposium on Logic Programming(ICLP/SLP), 1988, pp. 1070–1080.[30] M. Gelfond, V. Lifschitz, Action languages, Electronic Transactions on Artificial Intelligence 3 (1998) 195–210.[31] E. Giunchiglia, J. Lee, V. Lifschitz, N. McCain, H. Turner, Nonmonotonic causal theories, Artificial Intelligence 153 (1–2) (2004) 49–104.[32] E. Giunchiglia, V. Lifschitz, An action language based on causal explanation: Preliminary report, in: Proc. AAAI-98, 1998, pp. 623–630.[33] S.O. Hansson, Knowledge-level analysis of belief base operations, Artificial Intelligence 82 (1–2) (1996) 215–235.[34] S.O. Hansson, A Textbook of Belief Dynamics: Theory Change and Database Updating (Applied Logic), Kluwer, 1999.[35] D. Harel, D. Kozen, J. Tiuryn, Dynamic logic, in: Handbook of Philosophical Logic, MIT Press, 1984, pp. 497–604.[36] A. Herzig, The PMA revisited, in: Proc. KR-96, 1996, pp. 40–50.[37] A. Herzig, L. Perrussel, I.J. Varzinczak, Elaborating domain descriptions, in: Proc. ECAI-06, 2006, pp. 397–401.[38] Y. Jin, M. Thielscher, Representing beliefs in the fluent calculus, in: Proc. ECAI-04, 2004, pp. 823–827.[39] H. Katsuno, A.O. Mendelzon, On the difference between updating a knowledge base and revising it, in: Proc. KR-91, 1991, pp. 387–394.[40] M. Krentel, The complexity of optimization problems, Journal of Computer and System Sciences 36 (1988) 490–509.[41] J. Lang, Belief update revisited, in: Proc. IJCAI-07, 2007, pp. 2517–2522.[42] J. Lang, F. Lin, P. Marquis, Causal theories of action: A computational core, in: Proc. IJCAI-03, 2003, pp. 1073–1078.[43] J. Lee, V. Lifschitz, Describing additive fluents in action language C+, in: Proc. IJCAI-03, 2003, pp. 1079–1084.[44] R. Li, L.M. Pereira, What is believed is what is explained (sometimes), in: Proc. AAAI-96, 1996, pp. 550–555.[45] P. Liberatore, The complexity of the language A, Electronic Transactions on Artificial Intelligence 1 (1997) 13–38.[46] P. Liberatore, The complexity of belief update, Artificial Intelligence 119 (1–2) (2000) 141–190.[47] P. Liberatore, A framework for belief update, in: Proc. JELIA-00, 2000, pp. 361–375.[48] V. Lifschitz, Answer set planning, in: D.D. Schreye (Ed.), Proceedings of the 16th International Conference on Logic Programming (ICLP’99), Las Cruces,New Mexico, USA, The MIT Press, 1999, pp. 23–37.[49] V. Lifschitz, Missionaries and cannibals in the causal calculator, in: Proc. KR-00, 2000, pp. 85–96.[50] V. Lifschitz, W. Ren, Irrelevant actions in plan generation (extended abstract), in: Proc. Ninth Ibero-American Workshops on Artificial Intelligence(IBERAMIA 2004), 2004, pp. 71–78.[51] N. McCain, H. Turner, Satisfiability planning with causal theories, in: Proc. KR-98, Morgan Kaufmann, 1998, pp. 212–223.[52] J. McCarthy, Elaboration tolerance, in: Proc. 1998 Symposium on Logical Formalizations of Commonsense Reasoning (CommonSense 98), London,January 7–9, 1998, pp. 198–216. Available at www.ida.liu.se/ext/etai/nj/fcs-98/198/paper.ps (accessed June 3, 2010).T. Eiter et al. / Artificial Intelligence 174 (2010) 1172–12211221[53] C. Papadimitriou, Computational Complexity, Addison-Wesley, 1994.[54] R. Parikh, Beliefs, belief revision, and splitting languages, Journal of Logic, Language and Information 2 (1999) 266–278.[55] A. Parmar, Formalizing elaboration tolerance. Dissertation, Department of Computer Science, Stanford University, August 2003.[56] P. Peppas, Belief change and reasoning about action – an axiomatic approach to modelling dynamic worlds and the connection to the logic of theorychange. Dissertation, Basser Department of Computer Science, University of Sydney, 1993.[57] P. Peppas, Belief revision, in: F. van Harmelen, V. Lifschitz, B. Porter (Eds.), Handbook of Logic in Artificial Intelligence and Logic Programming, Elsevier,2008, pp. 317–360 (Chapter 8).[58] P. Peppas, A.C. Nayak, M. Pagnucco, N.Y. Foo, R.B.H. Kwok, M. Prokopenko, Revision vs. update: Taking a closer look, in: Proc. ECAI-96, 1996, pp. 95–99.[59] A.S. Rao, N.Y. Foo, Minimal change and maximal coherence: A basis for belief revision and reasoning about actions, in: Proc. IJCAI-89, 1989, pp. 966–971.[60] R. Reiter, Knowledge in Action: Logical Foundations for Specifying and Implementing Dynamical Systems, MIT Press, 2001.[61] C. Sakama, K. Inoue, An abductive framework for computing knowledge base updates, Theory and Practice of Logic Programming 3 (6) (2003) 671–713.[62] S. Shapiro, M. Pagnucco, Y. Lespérance, H.J. Levesque, Iterated belief change in the situation calculus, in: Proc. KR-00, 2000, pp. 527–538.[63] H. Turner, Strong equivalence for causal theories, in: V. Lifschitz, I. Niemelä (Eds.), LPNMR, in: Lecture Notes in Computer Science, vol. 2923, Springer,2004, pp. 289–301.[64] F. van Harmelen, V. Lifschitz, B. Porter, Handbook of Logic in Artificial Intelligence and Logic Programming, Elsevier, 2008.[65] K. Wagner, Bounded query classes, SIAM Journal on Computing 19 (5) (1990) 833–846.[66] M. Winslett, Reasoning about actions using a possible models approach, in: Proc. AAAI-88, 1988, pp. 89–93.[67] M. Winslett, Updating Logical Databases, Cambridge University Press, 1990.[68] D. Zhang, S. Chopra, N. Foo, Consistency of action descriptions, in: Proc. PRICAI-02, 2002, pp. 70–79.