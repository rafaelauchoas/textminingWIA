Artificial Intelligence 171 (2007) 332–360www.elsevier.com/locate/artintInductive situation calculusMarc Denecker a,∗, Eugenia Ternovska ba Department of Computer Science, KU Leuven, Belgiumb School of Computing Science, Simon Fraser University, CanadaReceived 15 November 2006; received in revised form 7 February 2007; accepted 8 February 2007Available online 20 February 2007AbstractTemporal reasoning has always been a major test case for knowledge representation formalisms. In this paper, we develop aninductive variant of the situation calculus in ID-logic, classical logic extended with inductive definitions. This logic has beenproposed recently and is an extension of classical logic. It allows for a uniform representation of various forms of definitions,including monotone inductive definitions and non-monotone forms of inductive definitions such as iterated induction and inductionover well-founded posets. We show that the role of such complex forms of definitions is not limited to mathematics but extends tocommonsense knowledge representation. In the ID-logic axiomatization of the situation calculus, fluents and causality predicatesare defined by simultaneous induction on the well-founded poset of situations. The inductive approach allows us to solve theramification problem for the situation calculus in a uniform and modular way. Our solution is among the most general solutionsfor the ramification problem in the situation calculus. Using previously developed modularity techniques, we show that the basicvariant of the inductive situation calculus without ramification rules is equivalent to Reiter-style situation calculus.© 2007 Elsevier B.V. All rights reserved.Keywords: Knowledge representation; Inductive definitions; Situation calculus1. IntroductionID-logic1 [5,8,10] is an extension of classical logic with inductive definitions (ID). In mathematical texts, inductivedefinitions are usually represented as collections of rules, which represent the base case and inductive cases. Inductiverules may be monotone or non-monotone. An example of the latter is the following rule in the definition of the truthrelation |=:I |= ¬ψ ifI (cid:3)|= ψ,which states that I satisfies ¬ψ if I does not satisfy ψ. It is well known that in general, inductive definitions cannotbe represented in first-order logic (FO). ID-logic extends classical logic with a construction that allows for a uniform* Corresponding author.E-mail address: Marc.Denecker@cs.kuleuven.be (M. Denecker).1 The term ID-logic was introduced by the first author in [5] to denote a logic of sets of classical first-order logic sentences and definitions.This logic was extended to its current definition in [8] and in [7], where it was called NMID-logic in order to emphasize that the logic deals withnon-monotone inductive definitions (NMIDs).0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2007.02.002M. Denecker, E. Ternovska / Artificial Intelligence 171 (2007) 332–360333representation of different sorts of inductive definitions; moreover, this representation preserves the rule-based natureof definitions in mathematical texts. The semantics of this new construct is based on the well-founded semantics oflogic programming [41]. This semantics correctly formalizes the semantics of different types of definitions that canbe found in mathematics, e.g. recursion-free definitions, monotone inductive definitions, and non-monotone inductivedefinitions such as inductive definitions over well-founded orders and iterated inductive definitions [4,6].ID-logic occupies an interesting place in the spectrum of logics used in mathematics, computer science and knowl-edge representation. As an extension of classical logic with a fixpoint semantics for inductive definitions, it can beviewed as a new element in the family of fixpoint logics. Monotone fixpoint logics have their origin in the logicalstudy of monotone inductive definitions [1,28]. The contribution of ID-logic is that it formalizes two non-monotoneinductive principles (i.e., inductive definition over a well-founded order and iterated inductive definition), which differfrom the non-monotone principle based on the inflationary fixpoint studied in the inflationary fixpoint logic IFP [16].ID-logic is similar to description logics [2] in its separation of definitional and assertional knowledge, but it allowsdefinitions for n-nary predicates and non-monotone inductive definitions. In addition, ID-logic is formally an exten-sion of Logic Programming and its variants such as Abductive Logic Programming and Datalog. In this way, ID-logicinduces an alternative informal semantics for logic programming, solidly based on the mathematical principle of in-ductive definitions. As such, the study of semantical and computational aspects of ID-logic can lead to synergy andintegration of all these different areas.On the computational level, ID-logic has recently been proposed as the underlying language for a constraint pro-gramming framework [27]. This framework is based on ideas from descriptive complexity theory and is similar insome respects to Answer Set Programming [20,29]. A problem instance is a finite structure, and a problem specifica-tion is an ID-logic formula defining the relationship between an instance and its solutions. Solving a problem amountsto expanding the structure with new relations to satisfy the formula. Depending on the expressiveness allowed, theframework captures various complexity classes, including P and NP. Several ID-logic solvers have been developed[21,30].The focus of this paper is on knowledge representation and modeling in ID-logic. Although diverse forms ofinductive definitions occur frequently in mathematics, there is little awareness in the logic and KR community ofnon-monotone forms of inductive definitions and of the potential role of inductive definitions for knowledge repre-sentation. Thus, a central aim of this paper is to clarify and illustrate these types of definitions. We provide examplesof monotone definitions, definitions by induction over well-founded order and iterated inductive definitions and relatethese to other knowledge representation principles such as completion and circumscription. Moreover, we show thatthe role of these complex forms of definitions is not limited to mathematics but extends to commonsense knowledgerepresentation.A second major purpose of the paper is to illustrate the use of a “tool set” from [8,42] for analyzing definitions,consisting of different modularity theorems, totality theorems and translation theorems. Our experiment demonstratesthe effectivity of the tool set for breaking up large complex definitions into conjunctions of smaller and simplerones, for translating definitions into classical logic, and for proving consistency and correctness of ID-logic theo-ries.The domain of application selected for our study is temporal reasoning. Since the early days of AI, temporal rea-soning, in particular the situation calculus, has been a major test case for knowledge representation languages. In [25],McCarthy and Hayes exposed the famous frame problem, showing the difficulty of axiomatizing actions and causa-tion in classical logic. This problem has (partly) motivated the development of the area of non-monotonic reasoning,leading to non-monotone logics such as default logic [32] and non-monotone reasoning techniques in classical logicsuch as circumscription [23] and completion [3]. Many different temporal reasoning formalisms were developed. Cur-rently, the most widely adopted formalization of situation calculus is the one in classical logic developed by Reiter andhis collaborators in the nineties [18,31,34]. Other well-known solutions are Event calculus [35], Fluent calculus [39],non-monotonic logic approaches such as the (many extensions of) the language A [14] and non-monotonic causaltheories [15,22].We present here a formalization of situation calculus in ID-logic, which we call the inductive situation calculus.Temporal reasoning is a natural application for using inductive definitions on the set of situations. In Reiter’s situ-ation calculus for example, the description of the initial state may be viewed as the base case, and successor stateaxioms may be seen the inductive case. By axiomatizing situation calculus in ID-logic, we explicitate the definitionalstructure underlying situation calculus. The main component of the inductive situation calculus will be a definition334M. Denecker, E. Ternovska / Artificial Intelligence 171 (2007) 332–360of fluent and causality predicates by simultaneous, non-monotone, iterated induction in the well-founded set of situ-ations. This definition and its components are natural illustrations of each of the above mentioned types of inductivedefinitions.A first benefit in explicitating the definitional structure of situation calculus, is that we considerably gain on therepresentational level. In particular, the inductive situation calculus is more expressive and modular than Reiter’sclassical logic version. On the level of modularity, in the inductive situation calculus it is possible to represent ef-fects of specific actions on specific fluents in specific circumstances by individual effect rules. It is well-known thatincreased modularity may improve elaboration tolerance [24]. On the level of expressivity, the inductive situationcalculus can handle recursive ramifications, where an effect to one fluent may cause an effect to another fluent andvice versa. The challenge in handling such recursive ramifications is to avoid erroneous models in which the re-lated fluents “cause” each other and become true simultaneously without external cause. By interpreting effect rulesas definitional rules, such spontaneous generation of effects is avoided. As a consequence, the inductive situationcalculus currently provides the most general solution of the ramification problem. It also provides the most generalsolution for defining fluents in situation calculus, since fluents can be defined by monotone or non-monotone inductivedefinitions.We also prove a range of correctness results of the inductive situation calculus, which are obtained using the abovementioned tool set. Our strategy will be to break up the large simultaneous inductive definition of all fluents in aconjunction of small component definitions, to prove their totality and to translate them into classical logic. The mainresults are the following:• We use the tool set to prove equivalence between Reiter’s situation calculus and a subformalism of the inductivesituation calculus. More precisely, our techniques allow us to translate this subformalism into classical first-orderlogic theories, closely related and provably equivalent to Reiter style situation calculus.• Extending the previous result, we show that a much broader class of inductive situation calculus theories canbe translated into extensions of Reiter’s situation calculus in first- or second-order logic, without using the in-ductive definition construct of ID-logic. However, the advantage of using explicit inductive definitions is thatdifferent effect and ramification theories, which can be modeled in a uniform way in the inductive situationcalculus, require different translation policies, using different combinations of predicate completion and circum-scription.• We will prove an initial state expansion property for the inductive situation calculus. This theorem guarantees thatfor each model satisfying the subtheory that axiomatizes the initial situation, and each extension of this modelinterpreting the action symbols, there is a unique way to extend this structure into a model of a complete inductivesituation calculus theory. To demonstrate the importance of this property, we discuss two of its implications. First,the inductive situation calculus satisfies the well-known property of relative satisfiability [31]: a theory in it is sat-isfiable if and only if the subtheory of the initial state is satisfiable. Satisfiability of a first-order or ID-logic theoryis, in general, an undecidable property. The initial state expansion property thus reduces the problem of provingsatisfiability of an inductive situation calculus to the smaller problem of proving satisfiability of the theory of theinitial situation.Second, this proposition shows that the inductive situation calculus correctly solves the frame problem. Recallfrom [25] that, put simply, the frame problem is the problem of representing what does not change as a result ofperforming actions. In first order logic, it turned out that a “naive” situation calculus theory, consisting merelyof effect and inertia formulas, provides only a weak, highly incomplete axiomatization of the temporal reasoningdomain, in the sense that the theory accepts many unintended models which differ from the intended models bythe fact that fluents become true spontaneously or are caused by the wrong type of action. To find elegant andgeneral solutions for this problem turned out to be challenging. Recall Hank and McDermot’s famous TurkeyShooting experiment [17], in which all early non-monotone approaches to temporal reasoning were shown to betoo weak, in the sense of accepting unintended models. Ultimately, it took the knowledge representation com-munity about two decennia to come up with sufficiently general theories that avoid these unintended models. Inthe inductive situation calculus, this problem is excluded from the start, because successor states are defined interms of the initial state; hence, an initial state, together with a choice of actions, can be extended in exactly onemodel. This model is constructed using the effect rules and correctly captures the state transitions of the dynamicsystem. Thus, the initial state expansion property guarantees that there are no unintended models of an inductiveM. Denecker, E. Ternovska / Artificial Intelligence 171 (2007) 332–360335situation calculus unless its initial situation is an unintended model of the subtheory of the initial situation. Theinitial state expansion property is, in this respect, an important correctness property of formalizations of situationcalculus.• Our results imply that the initial state expansion property and all its implications are satisfied by Reiter’ssituation calculus as well, since this formalism is (equivalent to) a subformalism of the inductive situa-tion calculus. To our knowledge, this is the first time that such a theorem was proven for situation calcu-lus.There are other topics in this paper which are of wider interest for the history of knowledge representation and thephilosophy of logic.• ID-logic achieves a coherent and conceptually clean integration of classical monotonic logic and logic pro-gramming, two knowledge representation paradigms which so far seemed to be incompatible. Our experimentillustrates the different roles of these formalisms. In particular, integrating (extended forms of) logic programswith classical logic compensates for the latter’s representational weakness on inductive definability.• In a similar spirit, ID-logic is also a clean and coherent integration of monotone and non-monotone logic anddisplays both monotone and non-monotone behaviour. ID-logic extends classical logic with a new type of atomicformulae, the definition, which is a set of definitional implications. As such, ID-logic is a monotone logic, in thesense that adding an ID-logic formula to an ID-logic theory preserves all logical consequences of the original the-ory. On the other hand, extending an ID-logic definition with a new definitional implication has a non-monotoneeffect and does not preserve logical consequences. For instance, adding the rule ∀x(p(x) ← x = b) to the defini-tion {∀x(p(x) ← x = a)} deletes the logical consequence ¬p(b). Consequently, the definitional implications arethe non-monotone modules of ID-logic.2• The definitional implication is an interesting, non-standard sort of conditional which, to the best of our knowledge,has not been studied from a philosophical logic perspective. The properties of this non-monotone, non-truth-functional connective are nicely illustrated in the inductive situation calculus, where definitional implicationsare used to represent effects of specific actions on specific fluents in specific circumstances. Interestingly, theserules are very similar to the so called effect rules in Reiter’s situation calculus. Semantically however, there is animportant difference between these rules in the two formalisms. In Reiter’s situation calculus, they are interpretedas material implications, and must be completed by additional axioms to obtain the final axiomatization in terms ofsuccessor state axioms. In the inductive situation calculus, effect rules are interpreted as definitional implications,which entail the corresponding material implications, but are not equivalent to them. As a consequence, we obtainan axiomatization which is equivalent to Reiter’s solution to the frame problem in a natural way, without addinganything to our effect rules. In this sense, we claim that Reiter’s situation calculus makes hidden use of inductivedefinitions.• The natural and effective use of definitional rules for representing effects (including recursive ramifications!)also suggests an unexpected and intriguing relationship between inductive definitions and causality. In retrospect,this is not so surprising at all, since an inductive definition can be understood as a description of a mathematicalconstruction process, where the definitional implications represent atomic operations executed during the process.But this is exactly the role of an effect rule in a causal theory. This topic deserves a deeper investigation, whichmight lead to a better understanding of the role of inductive definitions and logic programming in knowledgerepresentation and philosophical logic.The paper is structured as follows. In the next section, we define ID-logic and present the modularity, totality andtranslation theorems that form the tool set using which we will analyze the inductive situation calculus. In Section 3,we review the more traditional variant of the situation calculus, which is similar to [34]. In the rest of the paper,2 Be aware that in this paper the term monotonicity is used in two different meanings, one stemming from inductive definability, the other fromknowledge representation. A “monotone” inductive definition is—roughly—a definition without negation in rule bodies but the subformalism of“monotone” inductive definitions is non-monotone in the knowledge representation sense, since adding (monotone) definitional rules to such adefinition is a non-monotone operation, as illustrated by the example.336M. Denecker, E. Ternovska / Artificial Intelligence 171 (2007) 332–360we present the formalism of the inductive situation calculus, address the ramification problem and consider severaldetailed examples.This paper extends the conference version [7].2. Preliminaries2.1. Preliminaries from logicWe begin by fixing notation and terminology for the basic syntactic and semantic notions related to first- andsecond-order logic.We assume an infinite supply of distinct symbols, which are classified as follows:1. Logical symbols:(a) Parentheses: (,);(b) Logical connectives: ∧, ¬;(c) Existential quantifier: ∃;(d) Binary equality symbol: = (optional);(e) Two propositional symbols: t and f.2. Non-logical symbols:(a) countably many object symbols. Object symbols are denoted by low-case letters;(b) for each positive integer n > 0, countably many n-ary function symbols of arity n. Function symbols aredenoted by low-case letters;(c) for each positive integer n, countably many n-ary relation symbols, also called predicate or set symbols ofarity n. We use upper-case letters to denote predicates.As usual, we identify object symbols with 0-ary function symbols and propositional symbols with predicate symbolsof arity 0.Remark 1. In most parts of this paper, we do not make a formal distinction between variable and constant symbols.Symbols occurring free in a formula can be viewed as constants. Symbols in the scope of a quantifier are viewedas variables. In examples, we tend to quantify over x, y, X, Y , and leave c, g, f and P , Q free and treat them asconstants. This convention allows us to simplify the exposition by considering several cases at once.We define a vocabulary as any set of non-logical symbols. We denote vocabularies by τ, τ oΔ, . . . . We use σ , σ1,σ2 etc., to refer to an arbitrary symbol of the vocabulary. We write ¯σ to denote a sequence of symbols (σ1, σ2, . . .)or, depending on the context, the set of symbols {σ1, σ2, . . .}. Likewise, ¯X denotes a sequence or a set of relationalsymbols (i.e., set variables or constants), and ¯x is used to denote a sequence or a set of object symbols, etc.A term is defined inductively as follows:– an object symbol is a term;– if t1, . . . , tn are terms and f is an n-ary function symbol, where n (cid:2) 1, then f (t1, . . . , tn) is a term.A formula is defined by the following induction:– if P is an n-ary predicate constant or variable, and t1, . . . , tn are terms then P (t1, . . . , tn) is a formula, called anatomic formula or simply an atom;– if φ, ψ are formulas, then so are ¬φ, φ ∧ ψ;– if x is an object symbol, f a function symbol, X is a predicate symbol and φ is a formula, then ∃x φ, ∃f φ and∃X φ are formulas.M. Denecker, E. Ternovska / Artificial Intelligence 171 (2007) 332–360337A bounded occurrence of symbol σ in formula φ is an occurrence of σ in a sub-formula ∃σ ψ of φ. A freeoccurrence of σ in φ is an unbounded occurrence. The set of symbols which occur free in φ is denoted free(φ). Thisset can also be defined inductively:– If φ is atomic, say of the form A(t1, . . . , tn) then the set free(φ) is the set of all object, relational and functionalsymbols occurring in φ;– free(¬φ) := free(φ) ;– free(φ ∧ ψ) := free(φ) ∪ free(ψ);– free(∃σ φ) := free(φ) \ {σ }.A relation symbol X has a negative (positive) occurrence in formula F if X has a free occurrence in the scope of anodd (even) number of occurrences of the negation symbol ¬.A formula φ is a formula over vocabulary τ if its free symbols belong to τ (free(φ) ⊆ τ ). We use SO[τ ] to denotethe set of all formulas over τ ; and we use FO[τ ] to denote the set of first-order formulas over τ , that is those withoutquantified predicate or function variables.We use (φ ∨ ψ), (φ ⊃ ψ), (φ ≡ ψ), ∀xφ, ∀f φ and ∀Xφ, in the standard way, as abbreviations for the formulas¬(¬φ ∧ ¬ψ), ¬(φ ∧ ¬ψ), ¬(φ ∧ ¬ψ) ∧ ¬(ψ ∧ ¬φ), ¬∃x(¬φ), ¬∃f (¬φ), ¬∃X(¬φ), respectively.Having defined the basic syntactic concepts, we define the semantic concepts. Let A be a non-empty set. A valuefor an n-ary relation (function) symbol σ of vocabulary τ in A is an n-ary relation (function) in A. A value for a0-ary function symbol, i.e., an object constant or variable, is an element of the domain A. A value for a 0-ary relationsymbol Y is either ∅ or {( )}, the singleton of the empty tuple. We identify these two values with false, respectivelytrue. The value of the equality symbol is always the identity relation on A. The value of t is {( )} (true) and the valueof f is ∅ (false).A structure I for a given vocabulary τ (in short, a τ -structure) is a tuple of a domain dom(I ), which is a non-empty set, and a mapping of each symbol σ in τ to a value σ I in dom(I ). If σ ∈ τ and I is a τ -structure, we say thatI interprets σ . We also use letters J , K, L, M to denote structures. Given I , τI denotes the set of symbols interpretedby I .Let us introduce notation for constructing and modifying structures with a shared domain A. Let I be a τ -structure,and ¯σ be a tuple of symbols not necessarily in τ . Structure I [ ¯σ : ¯v] is a τ ∪ ¯σ -structure, which is the same as I , exceptsymbols ¯σ are interpreted by values ¯v in dom(I ). Given a τ -structure I and a sub-vocabulary τ (cid:15) ⊆ τ , the restrictionof I to the symbols of τ (cid:15) is denoted I |τ (cid:15) . Vice versa, I is called an extension of Io if I |τIoLet t be a term, and let I be a structure interpreting each symbol in t. We define the value t I of t under I by the= Io.usual induction:– if t is an object symbol σ , then t I is σ I , the value of σ in I ;– if t = f (t1, . . . , tn), then t I := f I (t I1 , . . . , t In ).Next we define the satisfaction or truth relation |=. Let I be a structure and let φ be a formula such that each freesymbol in φ is interpreted by I . We define I |= φ (in words, φ is true in I , or I satisfies φ) by the following standardinduction:– I |= X(t1, . . . , tn) if (t I– I |= ψ1 ∧ ψ2 if I |= ψ1 and I |= ψ2;– I |= ¬ψ if I (cid:3)|= ψ;– I |= ∃σ ψ if for some value v of σ in the domain dom(I ) of I , I [σ : v] |= ψ.n ) ∈ XI ;1 , . . . , t INote that the truth of a formula φ is only well-defined in a structure interpreting each free symbol of φ. We shalldenote the truth value of φ in I by φI , i.e., if I |= φ then φI is true and otherwise, it is false.We use notation φ(x1, . . . , xn) to emphasize that symbols x1, . . . , xn are distinct and are free in φ. Sometimes, wewish to investigate the truth value of a formula φ as a function of the values assigned to a specific tuple of symbols ¯σ .We then call these symbols the parameters of φ and denote the formula by φ( ¯σ ). Let I be some structure and let ¯vbe a tuple of values for ¯σ in the domain dom(I ). We often write I |= φ[ ¯v] to denote I [ ¯σ : ¯v] |= φ. If X is an n-ary338M. Denecker, E. Ternovska / Artificial Intelligence 171 (2007) 332–360relation symbol and ¯d is an n-tuple of elements of some domain A, then X[ ¯d] is a domain atom in A. For I a structurewith domain A, the value of X[ ¯d] in I is true if ¯d ∈ XI ; otherwise it is false. For a vocabulary τ , we define At τA as theset of all domain atoms in domain A over relation symbols in τ .For a set ¯X of relation symbols, we define Atin ¯X. In general, for a given vocabulary τ with predicates ¯X, we denote At¯XA as the set of all domain atoms in domain A over relation symbols¯XA as At τA.2.2. ID-logicIn this subsection, we describe ID-logic [10]. ID-logic was introduced by the first author in [5] as a logic of sets offirst order logic sentences and definitions. In [8] and in [7], this logic was extended to its current definition by allowingarbitrary boolean combinations of atoms and definitions.Let us fix some vocabulary τ . A new binary connective ← is called the definitional implication. A definition Δ isa set of rules of the form∀ ¯x(X(¯t) ← ϕ),where ¯x is a tuple of object variables, X is a predicate symbol (i.e., a predicate constant or variable) of some arity r,¯t is a tuple of terms of length r of the vocabulary τ , ϕ is an arbitrary first-order formula of τ , which may containfree object or relational variables. The definitional implication ← must be distinguished from material implicationdenoted ⊃.Note that in front of rules, we allow only universal quantifiers. In the rule ∀ ¯x(X(¯t) ← ϕ), X(¯t) is called the headand ϕ is the body of the rule. A defined symbol of Δ is a relation symbol that occurs in the head of at least one rule ofΔ; other relation, object and function symbols are called open. Let τ be a vocabulary including all free symbols of Δ.The subset of defined symbols of definition Δ is denoted τ dΔ. The set of open symbols of Δ in τ is denoted τ oΔ. The= τ , and τ dsets τ dΔA well-formed formula of ID-logic over vocabulary τ is defined by the following (monotone) induction:Δ form a partition of τ , i.e., τ dΔΔ and τ o∩ τ oΔ∪ τ oΔ= ∅ .(1) If X is an n-ary predicate symbol, and t1, . . . , tn are terms then X(t1, . . . , tn) is a formula.(2) If Δ is a definition then Δ is a formula.(3) If φ, ψ are formulas, then so is (φ ∧ ψ).(4) If φ is a formula, then so is (¬φ).(5) If φ is a formula, then ∃σ φ is a formula (σ can be either a first- or second-order symbol).A formula φ is an ID-logic-formula over vocabulary τ if the set of free symbols of φ is a subset of τ . It is a FO(ID)[τ ]-formula if it does not contain any second-order quantifiers, and it is a SO(ID)[τ ]-formula otherwise.As an example, in the language of the natural numbers, the following SO(ID)[τ ] formula, where τ = {0, s/1},expresses that there is a set which is the least set containing 0 and closed under taking successor numbers, and whichcontains all domain elements. It is equivalent to the standard induction axiom and to the domain closure axiom:(cid:2)(cid:3)∃N∀x (N(x) ← x = 0),∀x (N(s(x)) ← N(x))(cid:4)(cid:5)∧ ∀xN(x).(1)Note that this formula contains an existential quantification over the second-order variable N . The second-orderquantification can be avoided by skolemizing N and using a predicate constant instead. In fact, all examples ofsecond-order quantification that appear in this paper, are of the same kind as in this example and can be eliminated inthe same way, by skolemization of the existentially quantified second-order variable.The semantics of the ID-logic is an extension of classical logic semantics with the well-founded semantics fromΔ-structure Io.logic programming [6,12,40]. We now define the well-founded model of a definition Δ extending a τ oFor each defined symbol X of Δ, we defineϕX( ¯x) := ∃ ¯y1( ¯x = ¯t1 ∧ ϕ1) ∨ · · · ∨ ∃ ¯ym( ¯x = ¯tm ∧ ϕm),(2)where ¯x is a tuple of new variables, and ∀ ¯y1(X(¯t1) ← ϕ1), . . . , ∀ ¯ym(X(¯tm) ← ϕm) are the rules of Δ with X in thehead. For every defined symbol Y , we introduce a new relation symbol Y (cid:15) of the same arity. We obtain ϕ(cid:15)X from ϕX( ¯x)by substituting Y (cid:15) for each negative occurrence of each defined symbol Y .M. Denecker, E. Ternovska / Artificial Intelligence 171 (2007) 332–360339For any pair of τ -structures I, J extending Io, define IJ as the extension of Io which interprets each defined symbolX of Δ as XI , the value of X in I , and each new symbol X(cid:15) as XJ , the value of X in J . The basis of the constructionof the well-founded model extending Io is the operator TΔ which maps pairs I, J of extensions of Io to a structureI (cid:15), also extending Io, such that for each defined symbol X, XI (cid:15) := { ¯a | IJ |= ϕ(cid:15)[ ¯a]}. Thus, the operator TΔ evaluatespositive occurrences of defined symbols in rule bodies by I , and negative occurrences of defined symbols by J .XIn the lattice of τ -structures extending Io, the operator TΔ is monotone in its first argument and anti-monotonein its second argument. Define the stable3 operator STΔ as follows: STΔ(J ) := lfp(TΔ(·, J )). This stable operator isΔ), andanti-monotone, hence its square is monotone and has a least and largest fixpoint. We define IoIoΔ↑ := gfp(ST 2For an intuitive explanation of the well-founded semantics and an argument why it formalizes different forms ofΔ↓ := lfp(ST 2Δ).inductive definitions, we refer to [6].Definition 1. Definition Δ is total in τ othe Δ-extension of Io and is abbreviated as Ioτ oΔ if Δ is total in each τ oof T .Δ-structure Io if IoΔ-structure extending Ko. Δ is total in a theory T over τ oΔ↓ = IoΔ↑) is calledΔ↑. When this is the case, IoΔ. More generally, Δ is total in a structure Ko interpreting a subset ofΔ-modelΔ if Δ is total in each τ oΔ↓ (or IoThe aim of an inductive definition is to define its defined symbols. This is the case only when IoΔ↓ = IoΔ↑.Therefore, a natural quality requirement for a definition is that it is total.Definition 2 (φ true in structure I ). Let φ be a ID-logic-formula and I any structure interpreting all free symbolsof φ. We define I |= φ (in words, φ is true in I , or I satisfies φ, or I is a model of φ) by the following induction:n ) ∈ XI ;(1) I |= X(t1, . . . , tn) if (t IΔ↓ = Io(2) I |= Δ if I = Io(3) I |= ψ1 ∧ ψ2 if I |= ψ1 and I |= ψ2;(4) I |= ¬ψ if I (cid:3)|= ψ ;(5) I |= ∃σ ψ if for some value v of σ in the domain dom(I ) of I , I [σ : v] |= ψ.1 , . . . , t IΔ↑, where Io is the restriction of I to τ oΔ;Given an ID-logic theory4 T over τ , a τ -structure I satisfies T (is a model of T ) if I satisfies each φ ∈ T . This isdenoted by I |= T .Definition 2 is a prototypical example of a non-monotone inductive definition, more specifically a definition overa well-founded poset, namely the set of ID-logic formulas ordered by the sub-formula relation. It contains non-monotone recursion in rule 4. This is an example of the sort of induction formalized in ID-logic.As mentioned before, the definitional implication should be distinguished from material implication. Rule∀ ¯x(X(¯t) ← ϕ) in a definition does not correspond to the disjunction ∀ ¯x(X(¯t) ∨ ¬ϕ), although it implies it. Intuitively,the definitional implication should be understood as the “if” found in rules in inductive definitions (e.g. Definition 2consists of 5 such rules).A definitional implication always contains an atom in the head, never a negative literal. This reflects a generalprinciple of inductive definitions, which is that one defines a concept by enumerating positive cases, i.e., cases inwhich a defined predicate is true. Given such an enumeration, the closure mechanism underlying inductive definitionsyields the negative cases.2.3. Analysing definitionsIn this section, we recall the modularity, totality and translation theorems from [8].Definitions in ID-logic are non-monotone, in the sense that adding a rule to a definition in general does not preservelogical consequence. As a consequence, splitting a definition into a conjunction of two or more parts is, in general,3 This operator is often called the Gelfond–Lifschitz operator and was introduced in [13].4 By a theory, we mean a finite set of axioms.340M. Denecker, E. Ternovska / Artificial Intelligence 171 (2007) 332–360not equivalence preserving. This is quite obviously the case when we split up rules defining the same predicate. Forexample, the definition(cid:3)∀x (P (x) ← x = a),∀x (P (x) ← x = b)(cid:4)and the conjunction of its partition(cid:7)∀x (P (x) ← x = a)∧(cid:6)(cid:7)(cid:6)∀x (P (x) ← x = b)are not equivalent. Indeed, in a Herbrand model I of the definition, P I = {a, b}, and such a model satisfies neither thefirst component definition (since P I (cid:3)= {a}) nor the second (since P I (cid:3)= {b}).This motivates the following definition.Definition 3 (partition of definitions). A partition of definition Δ is a set {Δ1, . . . , Δn}, 1 < n, such that Δ = Δ1 ∪· · · ∪ Δn, and if defined symbol P appears in the head of a rule of Δi , 1 (cid:3) i (cid:3) n, then all rules of Δ with P in thehead belong to Δi and only to Δi .Notice that Δi has some “new” open symbols. For instance, if P is defined in Δ, but not in Δi , then it is a new= ∅(cid:8), 1 (cid:3) i (cid:3) n. Also,i τ dΔi= τ dΔ and τ dΔi∩ τ dΔj∪ τ dΔ= τ oΔi∪ τ dΔiopen symbol of Δi . Of course, it holds that τ = τ oΔwhenever i (cid:3)= j .Even if we put all rules defining the same predicate in the same module, splitting may not be equivalence preserving.For example, in the unique model of the definition{P ← Q, Q ← P },P and Q are false, whereas the conjunction{P ← Q} ∧ {Q ← P }(3)has two models, one in which P and Q are both false and another in which they are both true. A non-trivial exampleof a splittable definition is the following simultaneous inductive definition of even and odd numbers:⎧⎪⎨⎪⎩(cid:3)⎫⎪⎬∀x (E(x) ← x = 0),∀x (E(S(x)) ← O(x)),∀x (O(S(x)) ← E(x))∀x (E(x) ← x = 0),∀x (E(S(x)) ← O(x))(cid:4).⎪⎭(4)In the domain of the natural numbers (interpreting 0 by 0 and S by the successor function Succ), this definition can beshown to be equivalent to the conjunction(cid:7)(cid:6)∀x (O(S(x)) ← E(x)).∧(5)By splitting this definition, we obtain two non-inductive definitions, one of even numbers, the other of odd numbers.Such non-inductive definitions can be translated to classical logic using our translation results:∀x (E(x) ≡ x = 0 ∨ ∃y (x = S(y) ∧ E(y))) ∧∀x (O(x) ≡ ∃y (x = S(y) ∧ E(y))).(6)This example illustrates the potential use of modularity and translation results for analysis of inductive definitions.Whether a partition of a definition is equivalent to the original definition depends on whether the split breaks upcircular dependencies between defined facts. For example, in the definition (3), P and Q mutually depend on eachother. Splitting the definition breaks up this cycle, hence the equivalence is lost. In the definition (4), although E and Oare defined in terms of each other, there are no cyclic dependencies at the level of atoms. I.e., an atom E(n) dependsonly on O(n − 1), which in turn depends on E(n − 2), etc. So, by splitting the definition, no dependency cyclesare broken and the equivalence is preserved. Below, the intuitive notion of a dependency relation between atoms isformalized by the concept of a reduction relation.Assume a definition Δ over τ and a structure Ko with domain A such that τKoA be the set of domainatoms over τ in domain A, i.e., the set of atoms P [a1, . . . , an] (or P [ ¯a]), where P is relation symbol of τ and⊆ τ oΔ. Let At τM. Denecker, E. Ternovska / Artificial Intelligence 171 (2007) 332–360341A. If Q[ ¯b] ≺ P [ ¯a], we will say that P [ ¯a] dependsa1, . . . , an are elements of A. Let ≺ be any binary relation on At τon Q[ ¯b] (according to ≺). For any domain atom P [ ¯a] and any pair I, J of τ -structures with domain A, we defineI ∼=≺P [ ¯a] J if f I = f J for every constant and function symbol f appearing in Δ, and for each atom Q[ ¯b] ≺ P [ ¯a],I |= Q[ ¯b] iff J |= Q[ ¯b]. We extend this to pairs by defining (I, J ) ∼=≺P [ ¯a] (I (cid:15), J (cid:15)) if I ∼=≺P [ ¯a] I (cid:15) and J ∼=≺P [ ¯a] J (cid:15).Let ϕP [ ¯a] be as in (2).Definition 4 (reduction relation). A binary relation ≺ on At τA is a reduction relation (or briefly, a reduction) of a rule∀ ¯x (P (¯t[ ¯x]) ← ϕ( ¯x)) ∈ Δ if for all τ -structures I, J, I (cid:15), J (cid:15) extending Ko, for all tuples ¯a and ¯d such that ¯a = ¯t J [ ¯x: ¯d],if (I, J ) ∼=≺P [ ¯a] (I (cid:15), J (cid:15)) then it holds that IJ |= ϕ(cid:15)[ ¯d] iff I (cid:15)J (cid:15) |= ϕ(cid:15)[ ¯d].The relation ≺ is a reduction relation of Δ in Ko if for each defined predicate P of Δ, ≺ is a reduction relation ofthe rule ∀ ¯x(P ( ¯x) ← ϕP ) in Ko.Intuitively, the definition expresses that ≺ is a reduction relation if the truth of the formulas ϕP [ ¯a] depends only onthe truth of the atoms on which P [ ¯a] depends according to ≺.Proposition 1. If ≺ is a reduction relation of a rule or of a definition Δ in Ko, then any superset of ≺ is also areduction relation of that rule, resp. of Δ in Ko.Proposition 2. Let ≺ be a reduction relation of each rule in Δ in Ko. Then ≺ is a reduction relation of Δ in Ko.The above propositions suggest a methodology for constructing reductions of a definition: define reductions foreach of its rules and take the union. We illustrate this for definition (4) in the context of the natural numbers. Weobtain a reduction for this definition as the union of reductions for each of its rules:∅ ∪(cid:6)∪(E(n), O(n + 1)), | n ∈ N(cid:7)(cid:6)(O(n + 1), E(n + 2)) | n ∈ N.(cid:7)(7)Recall that a pre-well-founded order is a reflexive and transitive relation such that every non-empty subset contains aminimal element. The following definition is crucial for two decomposition theorems.Definition 5 (reduction partition). Call partition {Δ1, . . . , Δn} of definition Δ a reduction partition of Δ in τ oΔ-structure Io if there is a reduction pre-well-founded order ≺ of Δ in Io and if for each pair of defined domain atomsP [ ¯a], Q[ ¯b] such that Q[ ¯b] ≺ P [ ¯a] and P [ ¯a] ≺ Q[ ¯b], P and Q are defined in the same Δi .The intuition underlying this definition is that in a reduction partition, if an atom defined in one module depends onan atom defined in another module, then the latter atom does not depend on the first atom and hence is strictly less inthe reduction ordering.A partition {Δ1, . . . , Δn} of Δ is called total in Ko if each Δi is total in Ko.Theorem 1 (modularity, [10, Theorem 5.20]). If {Δ1, . . . , Δn} is a reduction partition of Δ in Ko, then for anyτ -structure M extending Ko, M |= Δ1 ∧ · · · ∧ Δn iff M |= Δ.Theorem 2 (totality, [10, Theorem 5.24]). If {Δ1, . . . , Δn} is a total reduction partition of Δ in Ko, then Δ is totalin Ko.It is easy to see that the reduction relation (7) turns the partition in (5) into a reduction partition. Hence, in the con-text of the natural numbers the definition is equivalent to its partition. Moreover, since the two component definitionsare non-inductive and hence, total, it follows that definition (4) is total. This illustrates the role of these theorems: theytell us when we can understand a large definition as a conjunction of smaller ones, and they allow us to prove totalityof a large definition given the totality of smaller ones.Δ such that for any τ oΔ-model Mo of To, {Δ1, . . . , Δn} is a reduction partition of ΔSuppose To is a theory over τ oin Mo. Under this assumption, two important corollaries hold:342M. Denecker, E. Ternovska / Artificial Intelligence 171 (2007) 332–360Corollary 1. To ∧ Δ and To ∧ Δ1 ∧ · · · ∧ Δn are logically equivalent.Corollary 2. If in addition, {Δ1, . . . , Δn} is a total partition in To, then Δ is total in To.Now we consider two special cases of definitions and explain how to translate them into classical logic. Let Δ be apositive definition, i.e., with only positive occurrences of defined symbols in rule bodies, defining the symbols ¯P . LetXi and Pi have the same arity. Define(cid:16)(cid:17)(cid:16)(cid:18)PID(Δ) :=Δ ∧ ∀ ¯XΔ[ ¯P / ¯X] → ¯P ⊆ ¯XandCIRC(Δ) :=(cid:19)(cid:16)Δ ∧ ∀ ¯X(cid:17)(cid:16)(cid:18)Δ[ ¯P / ¯X] → ( ¯X ⊆ ¯P → ¯P ⊆ ¯X).Δ is the conjunction of formulas obtained by replacing definitional with material implications in Δ, Δ[ ¯P / ¯X]Here,is the definition obtained by substituting Xi for each defined symbol Pi and ¯P ⊆ ¯X is a shorthand for the formula∀ ¯x (P1( ¯x) ⊃ X1( ¯x)) ∧ · · · ∧ ∀ ¯x (Pn( ¯x) ⊃ Xn( ¯x)).The formula PID(Δ) is the standard second-order formula to express that predicates ¯P satisfy the positive inductivedefinition Δ. The theory PID(Δ) expresses that the defined relations are the least relations closed under the rules of Δin a τ oΔ-structure. Because the rules of Δ are positive, such least relations are guaranteed to exist. The theory CIRC(Δ)is a circumscription axiom [23] and expresses that the defined relations are minimal relations closed under the rulesof Δ in a τ oΔ-structure. Since the least relations closed under the rules of Δ are the unique minimal relations closedunder the rules of Δ, both formulas are equivalent.Theorem 3. (See [10, Theorem 6.3].) If Δ is positive (i.e., contains no negative occurrences of defined symbols in rulebodies) then it is total in each τ oΔ-structure, and for any τ -structure I , I |= Δ iff I |= PID(Δ) iff I |= CIRC(Δ).These results can be applied, for example, in the context of definition (4) of even and odd numbers. Another resultis concerned with (possibly non-monotone) definitions over well-founded posets. First, we propose a formalizationfor this informal concept in ID-logic.Definition 6 (strict reduction relation). A reduction relation ≺ of Δ on At τorder (i.e., an antisymmetric, transitive binary relation without infinite descending chains).A is strict in Ko if it is a strict well-foundedThus, if P [ ¯a] ≺ Q[ ¯b] holds, then the bodies of rules defining Q[ ¯b] may depend on the truth value of P [ ¯a], but notvice versa.Definition 7 (definition by well-founded induction). Let Δ be a definition with a strict reduction relation ≺ in Ko. Wecall Δ a definition by well-founded induction (over ≺) in Ko.This type of definitions can be formalized in first-order logic using the well-known concept of completion [3].Define the completion of Δ, denoted comp(Δ), as the conjunction, for each defined symbol X of Δ, of formulas∀ ¯x(X( ¯x) ≡ ϕX( ¯x)).In general, a definition Δ entails its completion comp(Δ) but not vice versa. However, in case of a definition bywell-founded induction, the inverse is true as well.Theorem 4 (completion, [10, Theorem 6.9]). Suppose Δ is a definition by well-founded induction in τ oThen (a) definition Δ is total in Io, and (b) the model IoΔ of Δ is the unique model of comp(Δ) extending Io.Δ-structure Io.An example of a definition by well-founded induction is the definition (4) in the structure (cid:22)N, 0, Succ(cid:23). Indeed, thetransitive closure of the reduction relation in (7) is a strict well-founded order and a reduction relation of definition(4). As a consequence, this definition and its completion, formula (6), are equivalent in this structure: each model ofthe definition extending (cid:22)N, 0, Succ(cid:23) is a model of its completion and vice versa.M. Denecker, E. Ternovska / Artificial Intelligence 171 (2007) 332–360343One observes that the above theorem does not prove logical equivalence, i.e., equivalence in all structures, butonly equivalence in the context of a given structure. In fact, a definition may have a strict reduction relation in onestructure and not in other structures. Consider for example the structure Ko with domain {a, b} and 0Ko = a, andSKo = {(a, a), (b, b)}. In this structure, the least reduction relation of definition (4) is(cid:7)(cid:6)(E(a), O(a)), (O(a), E(a)), (E(b), O(b)), (O(b), E(b)).Each other reduction is a superset of this relation. Since each transitive relation extending this relation contains(E(a), E(a)), the definition has no strict reduction relation in this structure. In fact, the definition (4) and its comple-tion (6) are not equivalent in this structure. The unique model I of the definition interprets EI = {a} and OI = {a}.On the other hand, the completion has an additional model in which EI = {a, b} and OI = {a, b}.Suppose To is a theory over τ oΔ such that for any τ oin Mo. Under this assumption, two useful corollaries hold:Δ-model Mo of To, Δ is a definition by well-founded inductionCorollary 3. To ∧ Δ and To ∧ comp(Δ) are logically equivalent.Corollary 4. Δ is total in To.Notice that positive inductive definitions and definitions by well-founded induction have different (and, in general,non-equivalent) formalizations in classical logic.Some of the techniques that were introduced here are similar to methods found in logic programming. For example,Theorem 4 shows similarity to Fages theorem [11]. However, Fages notion of tight program is not equivalent toour notion of definition over a well-founded order; Fages theorem is only for Herbrand interpretations, and relatescompletion with stable semantics while ours is for general interpretations and relates completion with well-foundedsemantics.3. Reiter-style situation calculusFrom now on, we are dealing with many-sorted logic. All results and definitions introduced so far easily extendto this case. The vocabulary τsc of the situation calculus is a many-sorted vocabulary with equality and with sorts foractions (Act), situations (Sit), and possibly a finite number of domain-specific sorts called object sorts (Ob1, . . . , Obk),where each Obi is an arbitrary name. The vocabulary contains a potentially infinite set of domain-dependent functionsymbols of the sort Act. The sort of each argument of such a function is an object sort. For example, in the block worlddomain, we may have actions pick_up(x) and put_on(x, y) ranging over the sort Block.The vocabulary contains a binary relation (cid:24) with arguments of sort Sit and denoting precedence of situations. Theconstant S0 of sort Sit denotes the initial situation. Function do of sort Sit maps actions and situations to situations,i.e., given a and s, term do(a, s) denotes the successor situation which is obtained from situation s by performingaction a. The predicate constants F1, F2, . . . are called fluents and denote properties of the world (both in the initialsituation and in other situations). Fluents always have exactly one argument of sort Sit, while the sort of each otherargument is an object sort. For example, On(x, y, s) of arity 3 denotes that object x is on object y in situation s.Definition 8 (Duna(S)). The theory of unique name axioms for sort S, Duna(S), is the set of axioms in the followingaxiom schema: for distinct function symbols f and g of sort S∀ ¯x∀ ¯y ¬(f ( ¯x) = g( ¯y))∀ ¯x∀ ¯y (f (x1, . . . , xn) = f (y1, . . . , yn) ⊃ x1 = y1 ∧ · · · ∧ xn = yn).The axioms (9) hold for every function symbol f with arity greater than zero.(8)(9)Definition 9 (Df). The foundational axioms of the situation calculus, Df, are the set of axioms consisting of the uniquename axioms for situations Duna(Sit), the domain closure axiom for situations) ⊃ P (do(a, s))) ⊃ ∀sP (s))(cid:15)∀a (P (s∀P (P (S0) ∧ ∀s(10)(cid:15)(cid:15)and the precedence axioms for situations344M. Denecker, E. Ternovska / Artificial Intelligence 171 (2007) 332–360∀s ¬(s (cid:2) S0),∀s∀s(cid:15)∀a (s (cid:2) do(a, s(cid:15)) ≡ s (cid:24) s(cid:15))where s (cid:2) s(cid:15) is an abbreviation for s (cid:24) s(cid:15) ∧ ¬(s(cid:15) (cid:24) s).(11)(12)The role of axiom (10) is to guarantee that the domain of situations Sit is the smallest set closed under applicationsof the function symbol do, which satisfies the unique name axioms for situations. Every two models of Df withidentical domains of sort Act will have identical domains of sort Sit (modulo isomorphism).Definition 10 (Dss). The successor state axioms, Dss, are of the form:∀ ¯x∀a∀s (F ( ¯x, do(a, s)) ≡ (γ+F ( ¯x, a, s) ∨ F ( ¯x, s) ∧ ¬γ−F ( ¯x, a, s))).(13)Formula γ+F ( ¯x, a, s) (respectively, γ−F ( ¯x, a, s)) denotes a first-order formula specifying the conditions under whichaction a causes fluent F to become true (respectively, false) in the situation s [33]. The only free variables of theseformulas are among ¯x, a, s and the only symbol of sort Sit is the free variable s. An example of a successor axiom is∀sw∀a∀s (On(sw, do(a, s)) ≡a = toggle(sw) ∧ ¬On(sw, s) ∨On(sw, s) ∧ a (cid:3)= toggle(sw)).This axiom says that a switch is on in situation do(a, s) if and only if this situation was obtained by performing actiontoggle(sw) in situation s where this switch was off, or the switch was already on and an action other than toggle(sw)was performed.Successor state axioms are obtained from a set of effect rules of the form:∀ ¯x∀a∀s (δiF ( ¯x, a, s) ⊃ F ( ¯x, do(a, s)))for i ∈ {1, . . . , k}, and∀ ¯x∀a∀s (νjF ( ¯x, a, s) ⊃ ¬F ( ¯x, do(a, s))),(14)(15)−for j ∈ {1, . . . , m}, where formulas δiF . Each of these rules specifiesan initiating or terminating effect of a particular action in one particular condition. Together these rules exhaustivelydescribe all effects. Effect rules are transformed into the successor state axioms using the following equations:F satisfy the same conditions as γF and νj+F and γγ+F ( ¯x, a, s) :=k(cid:20)i=1δiF ( ¯x, a, s)and γ−F ( ¯x, a, s) :=m(cid:20)j =1νjF ( ¯x, a, s).This transformation is not equivalence preserving but transforms an incomplete specification of the action domain intoa final axiomatization.Definition 11 (DS0 ). A description of the initial situation, DS0 , is a set of first-order sentences that are uniform in S0,that is, it contains no situation term other than S0.A basic action theory consists of Df ∪ Duna(Act) ∪ DS0∪ Dss.4. Inductive situation calculusIn this section, we define a variant of Reiter-style situation calculus, which we call the inductive situation calculus.All fluents will be defined by simultaneous induction on the well-founded set of situations. Ramifications describingpropagation of effects of actions are modeled as monotone or non-monotone inductions at the level of situations. Theresult is an iterated inductive definition with alternating phases of monotone and non-monotone induction. Below wedescribe the components of the inductive situation calculus.M. Denecker, E. Ternovska / Artificial Intelligence 171 (2007) 332–360345The vocabulary τisc of the inductive situation calculus extends τsc by two types of symbols. Symbols IF1 , IF2, . . .are used to describe the initial situation and correspond to the fluents F1, F2, . . . , Fn, but have no situation argument.They are open symbols of the inductive situation calculus. The other type of symbols denotes causality relations. Thesesymbols will be introduced a bit later. The initial state vocabulary τinit consists of all symbols of τisc not involvingisc of the inductive situation calculus extends τinit with So, do, (cid:24), and the actionsorts Act or Sit. The open vocabulary τ osymbols. This vocabulary consists of all symbols of τisc except for all fluents and causality predicates.The ID-logic induction axiom (1) of the natural numbers can be extended to arbitrary sorts in the following way.Definition 12 (DDCA(S)). Given a vocabulary τ , the domain closure axiom for sort S, DDCA(S), is the axiom:⎧⎡⎪⎪⎪⎨⎢⎢⎢⎪⎪⎪⎩⎣∃P∀x (P (x) ← x = c),· · ·∀x1 . . . ∀xn (P (f (x1, . . . , xn)) ← P (xi1) ∧ · · · ∧ P (xim))· · ·⎤∧ ∀xP (x)⎥⎥⎥⎦⎫⎪⎪⎪⎬⎪⎪⎪⎭where the definition contains one rule for every constant c of sort S and for every function symbol f ∈ τ of sort Swith arguments i1, . . . , im of sort S.For example, the domain closure axiom DDCA(Sit) for situations is:(cid:2)(cid:3)∃P∀s (P (s) ← s = S0),∀a∀s (P (do(a, s)) ← P (s))(cid:4)(cid:5)∧ ∀sP (s).(16)The role of axiom (16) is to guarantee that the domain of situations Sit is the smallest set containing S0 and closedunder applications of the function symbol do. It is equivalent to Reiter’s induction axiom for situations. Recall thatthe second order variable can be eliminated by skolemization.A general property of the combination of unique names axioms and domain closure axiom is that they are consistentand fix the domain in a unique way.Proposition 3. Let τo be a sorted vocabulary, and τ extends τo with a new sort S and a set of constant and functionsymbols of sort S. For every τo-structure Io, there is a non-empty class of τ -structures extending Io and satisfyingDuna(S), and there is a unique (modulo isomorphism) extension of Io satisfying Duna(S) ∧ DDCA(S).The foundational axioms of the inductive situation calculus, Dif, are the unique name axioms Duna(Sit) for situa-tions, the domain closure axiom DDCA(Sit) for situations and the following definition of the precedence relation(cid:3)Δ(cid:24) :=∀s∀s∀s∀s(cid:15) ← s = s(cid:15)(s (cid:24) s(cid:15)(cid:15)∀a (s (cid:24) do(a, s(cid:15)),) ← s (cid:24) s(cid:4).(cid:15))(17)An initial structure A of the inductive situation calculus is a multi-sorted structure with a non-empty domain foreach sort of the language, which interprets all symbols of τ oisc and which satisfies the foundational axioms Dif.Proposition 4. For any τinit-structure Io and arbitrary extension I of Io to (the symbols of ) sort Act, there is a unique(modulo isomorphism) initial structure A extending I . Io has a unique extension satisfying Duna(Act) ∪ DDCA(Act).Proof. By application of Proposition 3 for sort Sit, we can prove that an arbitrary extension I of Io to sort Act, has\ {(cid:24)})-structure satisfying Duna(Sit) ∪ DDCA(Sit). By Theorem 3, this structurea unique (modulo isomorphism) (τ oisccan be extended in a unique way to a definition of Δ(cid:24). By, again, Proposition 3, only one of these extensions satisfiesDuna(Act) ∪ DDCA(Act). (cid:3)Proposition 5. Let A be an initial structure. In every such structure, the substructure (cid:22)SitA, (cid:24)A(cid:23) is a well-foundedposet (and, thus a pre-well-founded set).Proof. In an initial structure A, the collection of situations is isomorphic to the set of finite sequences of elements ofsort Act, where SAto the constructor appending an action object to a0 corresponds to the empty sequence, and doA346M. Denecker, E. Ternovska / Artificial Intelligence 171 (2007) 332–360finite sequence. Since A satisfies the definition (17), it holds for two situations s, s(cid:15) that s (cid:24)A s(cid:15) iff the sequence of sis an initial segment of that of s(cid:15). This is a well-founded order. (cid:3)The following proposition demonstrates that the remaining two foundational axioms of the situation calculus aspresented in [34], are implied by the definition above.Proposition 6. The theories Df and Dif are logically equivalent.Proof. Both theories contain Duna(Sit). The induction axiom of Df is equivalent to DDCA(Sit) in Dif. It is not difficult toprove that in a structure A satisfying Duna(Sit) ∪ DDCA(Sit), where situations correspond to finite sequences of actions,the unique relation (cid:24)A that satisfies sentences (11) and (12) is the same relation defined by definition (17). (cid:3)In place of DS0 , the description of the initial situation in terms of fluents which hold in S0, in the inductive situationcalculus we describe the initial situation in terms of symbols IFi . The corresponding collection of axioms is Dinit. Thisis any theory in the vocabulary τinit.A basic action theory of the inductive situation calculus will be a collection of axioms of the form:Dif ∪ Duna(Act) ∪ Dinit ∪ {Δsc},(18)where Δsc is an inductive definition of the fluents. We will often include also the domain closure DDCA(Act) for actionsin an inductive situation calculus theory. In the next sections, we present three variants of Δsc.4.1. Specifying direct effects of actionsFor each fluent Fi , we introduce two additional auxiliary relations, CFi and C¬Fi . These relations represent initi-ating and terminating causes for Fi , respectively. Both CFi and C¬Fi have the same sort of arguments as Fi plus oneaction argument. Let Dinit axiomatize the initial situation using IF1, . . . , IFm .We augment Dif ∪ Duna(Act) ∪ Dinit with the following definitionΔsc =n(cid:27)i=1Δifluent∪n(cid:27)i=1ΔieffectwhereΔifluent:=Δieffect:=⎧⎪⎨⎪⎩(cid:28)∀ ¯xi (F ( ¯xi, S0) ← IF ( ¯xi)),∀ ¯xi∀a∀s (Fi( ¯xi, do(a, s)) ← CFi ( ¯xi, a, s)),∀ ¯xi∀a∀s (Fi( ¯xi, do(a, s)) ← Fi( ¯xi, s) ∧ ¬C¬Fi ( ¯xi, a, s))+∀ ¯xi∀a∀s (CFi ( ¯xi, a, s) ← γFi∀ ¯xi∀a∀s (C¬Fi ( ¯xi, a, s) ← γ( ¯xi, a, s)),−( ¯xi, a, s))Fi(cid:29).⎫⎪⎬,⎪⎭+Fi−FiHere, formulas γ( ¯xi, a, s) are analogous to those found in Reiter-style situation calculus. They areformulas without causality predicates, with free variables among ¯xi, a, s and the only symbol of sort Sit is the freevariable s. All fluent atoms in such formulas are of the form Fj (¯t, s).( ¯xi, a, s), γThe intuitive meaning of this definition is as follows. The first rule of Δifluent defines the fluent Fi in situation S0.The second rule says that if an action causes a fluent in some situation, then the fluent holds in the successor situation.The third rule deals with the case where a fluent is not affected by an action and will be referred to as the law ofinertia. The rules in Δieffect describe direct effects of actions on the fluent Fi .Note that any fluent may appear in the rules for a causality predicate. Hence, the definition Δsc is one largesimultaneous inductive definition. Moreover, since the inertia law contains a negative occurrence of C¬Fi , and thispredicate may be defined in terms of fluents, Δsc is, in general, a non-monotone inductive definition. In what follows,we use the results of Section 2.3 in order to obtain the standard successor state axioms of the situation calculus.Proposition 7. The definition Δsc is a definition by well-founded induction in each τ oaxioms Dif.isc-model of the foundationalM. Denecker, E. Ternovska / Artificial Intelligence 171 (2007) 332–360347Proof. Let A be an initial structure with domain A. We shall construct a reduction relation ≺ of Δsc in A. This binaryrelation on At τiscA , the set of all domain atoms, should represent (at least) all potential dependencies between domainatoms that are not interpreted by A, i.e., between the fluent and causality atoms. We construct ≺ in a rule-by-rule way,suggested by Proposition 2, as the set of all tuples:[ ¯u, a, s], Fi[ ¯u, do(CFi(Fi[ ¯u, s], Fi[ ¯u, do(Fi[ ¯u, s], C(¬)FjA[ ¯v, a, s]),A(a, s)]),(a, s)]), (C¬Fi[ ¯u, a, s], Fi[ ¯u, doA(a, s)]),for arbitrary tuples of objects ¯u and ¯v, for arbitrary elements a of the action sort and s of the situation sort, for eachi, j .It is easy to see that the tuples in the first two lines provide a reduction relation of the two inductive rules of fluents,while the tuples in the third line represent all possible dependencies in direct effect rules. It follows from Proposition 2that ≺ is a reduction relation of Δsc in A.Since, by Proposition 1, any superset of a reduction relation is also a reduction relation, the transitive closure ≺∗of ≺ is a reduction relation. Moreover, it follows from the fact that (cid:22)SitA, (cid:24)A(cid:23) is a well-founded set (Proposition 5),that ≺∗ is a strict well-founded order on At τiscA . (cid:3)This proposition, together with Corollary 3, has an interesting consequence.Proposition 8. The theories Dif ∧ Δsc and Dif ∧ comp(Δsc) are logically equivalent.We now formulate the property mentioned in the introduction of this paper.Definition 13. We say that a basic action theory Disc := Dif ∪ Duna(Act) ∪ Dinit ∪ {Δsc} of the inductive situationcalculus satisfies the Initial State Expansion property if for every τinit-model Io of Dinit, for arbitrary extension I of Ioto (symbols of) sort Act, if I satisfies Duna(Act), then there is a unique τ -model (modulo isomorphism) of Disc whichextends I .When Disc satisfies the Initial State Expansion property, then, in particular, every τinit-model Io of Dinit has aunique τ -extension (modulo isomorphism) satisfying Disc ∪ Duna(Act) ∪ DDCA(Act).As argued in Section 1, the initial state expansion property shows that the inductive situation calculus satisfies theproperty of relative satisfiability and correctly solves the frame problem in the sense that a basic action theory has nounintended models with spontaneous generation of effects (or “deus ex machina” effects, as they were called in [9])of the kind that occurred in early solutions to the frame problem. Another of its implications is that the subtheorymodeling the state transitions is logically independent of the theory of the initial state and does not interfere with it indetermining what are the initial states. Clearly, it would be most unpleasant if describing the effects of actions wouldsomehow impose constraints on the initial state.Proposition 9. A basic action theory of the inductive situation calculus (18) satisfies the Initial State Expansionproperty.Proof. By Proposition 4, each extension of a τinit-structure to sort Act can be extended in a unique initial structure A.By Corollary 4, the extension of A that satisfies Δsc is unique. (cid:3)We now investigate the relationship to Reiter’s situation calculus.For a given vocabulary τ , let M|τ denote the restriction of the structure M to the symbols of τ .Definition 14. Suppose that τ1, τ2 are vocabularies extending τ , and let T1, T2 be theories in respectively τ1, τ2. Wecall T1 equivalent in τ to T2 if for each τ1-model M1 of T1, there exists a τ2-model M2 of T2 such that M1|τ = M2|τand vice versa.348M. Denecker, E. Ternovska / Artificial Intelligence 171 (2007) 332–360Recall that τisc extends τsc with the new symbols IFi , CFi and C¬Fi .Theorem 5. A basic action theory of the inductive situation calculusDif ∪ Duna(Act) ∪ Dinit ∪ {Δsc}is equivalent in τsc to the Reiter-style basic action theoryDf ∪ Duna(Act) ∪ DS0∪ Dss,where DS0 is the theory obtained from Dinit by substituting Fi(¯t, S0) for each atom IFi (¯t) and Dss is the set of thesuccessor state axioms corresponding to Δsc.Proof. Dif and Df are logically equivalent. By Proposition 8, Df ∪ Duna(Act) ∪ Dinit ∪ {Δsc} is logically equivalent toDf ∪ Duna(Act) ∪ Dinit ∪ comp(Δsc), where comp(Δsc) isn(cid:16)i=1(cid:15)∃a∃sn(cid:16)∧i=1n(cid:16)i=1∧∀ ¯xi∀s Fi( ¯xi, s) ≡ (s = S0 ∧ IFi ( ¯xi) ∨s = do(a, s(cid:15)) ∧ (CFi ( ¯xi, a, s(cid:15)) ∨ Fi( ¯xi, s(cid:15)) ∧ ¬C¬Fi ( ¯xi, a, s(cid:15))))∀ ¯xi∀a∀s CFi ( ¯xi, a, s) ≡ γ+Fi( ¯xi, a, s)∀ ¯xi∀a∀s C¬Fi ( ¯xi, a, s) ≡ γ−Fi( ¯xi, a, s).Since, by the domain closure axiom for situations,∀s(s = S0 ∨ ∃a∃s(cid:15)s = do(a, s(cid:15))),Df ∪ {(19)} is logically equivalent to Df ∪ {(20), (21)}, whereandn(cid:16)i=1n(cid:16)i=1∀ ¯xi∀s∀a Fi( ¯xi, do(a, s)) ≡ CFi ( ¯xi, do(a, s)) ∨ Fi( ¯xi, s) ∧ ¬C¬Fi ( ¯xi, do(a, s))∀ ¯xi IFi ( ¯xi) ≡ Fi( ¯xi, S0)∧∧n(cid:16)i=1n(cid:16)i=1∀ ¯xi∀s∀a CFi ( ¯xi, a, s) ≡ γ+Fi( ¯xi, a, s)∀ ¯xi∀s∀a C¬Fi ( ¯xi, a, s) ≡ γ−Fi( ¯xi, a, s).(19)(20)(21)Given the equivalences in (21), it is clear that Dif ∪ Duna(Act) ∪ Dinit ∪ {(20), (21)} is logically equivalent to Df ∪Duna(Act) ∪ DS0∪ Dss ∪ {(21)}.Finally, observe that in the latter theory, the predicate symbols IFi , CFi and C¬Fi occur only at the left-hand∪ Dss ∪ {(21)} is equivalent in τsc toside of the explicit definitions in (21). It follows that Df ∪ Duna(Act) ∪ DS0Df ∪ Duna(Act) ∪ DS0∪ Dss. (cid:3)Note that our definition Δifluent does not contain rules of the form∀ ¯xi∀a∀s (¬Fi( ¯xi, a, s) ← C¬Fi ( ¯xi, a, s)).(22)M. Denecker, E. Ternovska / Artificial Intelligence 171 (2007) 332–360349However, under a natural requirement, we can derive negative effect axioms of actions, as we demonstrate below. Therequirement is that a fluent and its negation are not caused to hold in the same situation. Formally, the requirement isthat the basic action theory should entail the following sentence:n(cid:16)i=1∀ ¯xi∀a∀s ¬(γ+Fi( ¯xi, a, s) ∧ γ−Fi( ¯xi, a, s)).It is easy to show now that if this requirement is satisfied, then the negative effect axiom is implied. Observe that eachsuccessor state axiom entails∀ ¯xi∀a∀s (¬γ+Fi( ¯xi, do(a, s)) ∧ γ−Fi( ¯xi, do(a, s)) ⊃ ¬Fi( ¯xi, do(a, s))).Under the requirement, the first literal in the condition is entailed by the second, so we can drop it and we obtain thenegative effect rule−∀ ¯xi∀a∀s (γFi( ¯xi, do(a, s)) ⊃ ¬Fi( ¯xi, do(a, s))).Therefore, in the context of Inductive Situation Calculus, rule (22) is not necessary. This observation illustrates aprinciple of inductive definitions which was mentioned in Section 2.2. In an inductive definition, one defines a conceptby enumerating positive cases. Given such an enumeration, the closure mechanism underlying inductive definitionsyields the negative cases.Recall that in Reiter’s situation calculus, the successor state axioms, in particular the formulas γ−F ( ¯x, a, s) are obtained by compiling a set of effect rules of the form ∀ ¯x∀a∀s (δiγ∀ ¯x∀a∀s (νjtional implications:+F ( ¯x, a, s) andF ( ¯x, a, s) ⊃ F ( ¯x, do(a, s))) andF ( ¯x, a, s) ⊃ ¬F ( ¯x, do(a, s))). In ID-logic, the unique rule defining CF can be replaced by a set of defini-∀ ¯x∀a∀s (CF ( ¯x, a, s) ← δiF ( ¯x, a, s)).Likewise, the predicate C¬F can be defined directly by a set of effect rules of the form:∀ ¯x∀a∀s (C¬F ( ¯x, a, s) ← νjF ( ¯x, a, s)).Note that in Reiter’s situation calculus, the compilation of effect rules into successor state axioms is crucial toobtain a correct axiomatization of the action domain. While each effect axiom is correct independently, together theyare too weak to axiomatize the action domain, i.e., there are many unintended models. The compilation into successorstate axioms modifies the meaning of the theory and eliminates all unintended models. The transformation turns anincorrect (in the sense of too weak) theory into a correct theory (provided the set of effect axioms is correct andcomplete).In the inductive situation calculus, the situation is very different. Indeed, substituting all definitional effect rulesdefining CF by the unique rule(cid:30)∀ ¯x∀a∀sCF ( ¯x, a, s) ←(cid:31)δiF ( ¯x, a, s)k(cid:20)i=1is equivalence preserving, and likewise for C¬F . Compilation is not necessary anymore to obtain a correct represen-tation! It is this phenomenon that we had in mind in the introduction when we claimed that Reiter-style situationcalculus contains hidden forms of definitions.4.2. Indirect effectsThe ramification problem arises when one wants to capture indirect effects of actions in a logic-based formalism.It has been shown (e.g., [19]) that state constraints are generally inadequate for deriving indirect effects of actions,and that some notion of causation is needed. Unlike material implication, causal implications are not contrapositivewhich makes them similar to the rules of inductive definitions. This correspondence between inductive definition rulesand causal rules is the foundation of our solution to the ramification problem. The semantic correspondence betweencausality rules and rules in an inductive definition was independently pointed out in [36,37] and in [9]. The resultingdefinition Δsc is not a definition by well-founded induction but, in general, an iterated inductive definition.350M. Denecker, E. Ternovska / Artificial Intelligence 171 (2007) 332–360Let, as before, CFi and C¬Fi represent initiating and terminating causes for Fi , respectively. We extend theuse of the causality predicates to specify indirect effects of actions. For example, according to the causal rule∀a∀s(CF2(a, s) ← C¬F1(a, s)), when an action a causes termination of F1, then the same action, indirectly, causesthe initiation of F2. We relax the conditions on Δieffect, so that any number of rules of the following form can appearin it:+∀ ¯x∀a∀s (CFi ( ¯xi, a, s) ← ΨFi∀ ¯x∀a∀s (C¬Fi ( ¯xi, a, s) ← Ψ( ¯xi, a, s)),−( ¯xi, a, s))Fi(23)where Ψ + and Ψ − are formulas with free variables among ¯xi, a, s, with only free occurrences of a and s and no othersymbols of sort Act or Sit. In such a formula, a fluent atom is of the form Fj (¯tj , s) and a causality atom is of the formC(¬)Fk (¯tk, a, s). Note that in the direct effect case, causality predicates were excluded from bodies of rules of Δieffect.The basic action theory (18) in which now we allow ramification rules of the form (23) in Δsc, encodes our solutionto the ramification problem in the inductive situation calculus.∪ · · · ∪ Δneffect, the collection of direct and indirect effect rules for all fluents. ConsiderLet us define Δeffect = Δ1the following partition of Δsc:fluent, . . . , Δn{Δ1fluent, Δeffect}.effect(24)Proposition 10. Partition (24) is a reduction partition of Δsc in each initial structure A.Proof. Let A be an initial structure with domain A. We construct a reduction ≺ of Δsc on At τiscway. This produces the following tuples:A in the rule-by-ruleA(a, s)]),(a, s)]), (C¬FiA[ ¯u, a, s], Fi[ ¯u, do(CFi(Fi[ ¯u, s], Fi[ ¯u, do(Fj [ ¯u, s], C(¬)Fi(C(¬)Fj[ ¯v, a, s]),[ ¯u, a, s], C(¬)Fi[ ¯v, a, s]),[ ¯u, a, s], Fi[ ¯u, doA(a, s)]),for arbitrary tuples of objects ¯u and ¯v, for arbitrary elements a of the action sort and s of the situation sort and for each[ ¯v, a, s] depends on each fluent atom in s and each other causalityi, j . Notice that a causality domain atom C(¬)Fjatom in a and s. This is a reduction of rules of the form (23).Since any superset of a reduction relation is also a reduction relation, the reflexive, transitive closure ≺∗ is areduction relation. Moreover, it follows from the fact that (cid:22)SitA, (cid:24)A(cid:23) is a (pre-)well-founded set (Proposition 5), thatA , if Q[ ¯b] ≺∗ P [ ¯a] and≺∗ is a pre-well-founded order on At AP [ ¯a] ≺∗ Q[ ¯b], then P and Q are defined in the same sub-definition. Therefore, partition (24) is a reduction partitionof Δsc. (cid:3)A . It is easy to see that for atoms P [ ¯a], Q[ ¯b] from At AAs a corollary of this proposition, we obtain the following property.Proposition 11. A basic action theory (18) with indirect effects is equivalent toDif ∪ Duna(Act) ∪ Dinit ∪(cid:28)(cid:29)n(cid:16)i=1Δifluent∧ Δeffectand toDf ∪ Duna(Act) ∪ DS0∪(cid:29)comp(Δifluent) ∧ Δeffect.(cid:28)n(cid:16)i=1(25)(26)Proof. The theory (25) is obtained from the basic action theory by splitting Δsc. Since partition (24) is a reductionpartition in Dif, it follows from Corollary 1 that this is equivalence preserving. The proof of the equivalence with (26)is similar as the proof of Theorem 5. The main step is to show that Δifluent) are equivalent in initialfluent and comp(ΔiM. Denecker, E. Ternovska / Artificial Intelligence 171 (2007) 332–360351structures. This follows from the fact that each Δiwell-founded order constructed in the proof of Proposition 7. (cid:3)fluent is a definition by well-founded induction over ≺∗, the strictProposition 12. If Δeffect is total in (any subtheory of ) Dif ∪ Duna(Act) ∪ Dinit, the basic action theory (18) with indirecteffects satisfies the Initial State Expansion property.Proof. Let I be an extension of a τinit-model of Dinit to sort Act which satisfies Duna(Act) and let A be its uniqueisc-extension satisfying Dif. Since Δeffect is total in A, partition (24) is a total reduction partition of Δsc in A, and byτ oTheorem 2, Δsc is total in A and has a unique model extending A. (cid:3)In general, there is no simple uniform way in which a basic action theory with ramification rules can be translatedinto classical logic. However, the corollary provides a basis for proving several translation results, depending on theproperties of Δeffect. The theorem below considers the case that Δeffect is a positive inductive definition.Theorem 6. If Δeffect is a positive definition then the basic action theory (18) satisfies the Initial State Expansionproperty and is equivalent to the theoryDf ∪ Duna(Act) ∪ DS0∪and to the theoryDf ∪ Duna(Act) ∪ DS0∪(cid:29)fluent) ∧ PID(Δeffect)comp(Δi(cid:28)n(cid:16)i=1(cid:29)fluent) ∧ CIRC(Δeffect)comp(Δi.(cid:28)n(cid:16)i=14.2.1. Example: N Gear wheelsLet us describe a simple idealized mechanical system consisting of a number of gear wheels w1, . . . , wn, each pairof which may or may not be mechanically connected. For each of these wheels, we consider two states: turning orstopped. For each of these wheels, we consider two actions start(wi) and stop(wi). The first action gives an impulseto the wheel which propagates over the system to all connected gear wheels; the second action brakes the wheel andall connected wheels. We assume that once a wheel turns, it continues to turn (there is no friction; this system behavesas a perpetuum mobile) until there is a stop action.We are faced here with a ramification problem—the problem of how to describe the propagation of effects throughthe system of connected gear wheels. The goal is to develop a modular temporal theory describing the effects of thebasic actions and the propagation of effects. As a correctness criterion, we should be able to prove the state constraintthat in all situations, a gear wheel w is turning if and only if all reachable wheels (those connected to w in the transitiveclosure of the connection graph) are turning as well.We could represent this example in Reiter’s basic situation calculus [34]. To do this we could pre-compute foreach wheel the set of reachable wheels in the connection graph; it suffices then to express that the action of starting(respectively, stopping) a wheel w has the immediate effect to initiate (respectively, terminate) the turning state ofwheel w and each wheel reachable from w. This representation would have some important drawbacks. First, noticethat this pre-compilation would be impossible if the physical connection relation between gear wheels would be adynamic relation and gear wheels could be connected or disconnected. Such an example is worked out in Section 4.3.1.Second, the transitive closure of the physical connections between gear wheels is an example of a global propertyof the system which emerges as an interaction of local properties, namely the physical connections between gearwheels. If we explicitly represent such global properties then a small change of a local property (e.g. adding a newconnection or deleting an existing connection between two gear wheels) may have a strong impact on the globalproperties and hence on the theory (e.g. disconnecting one pair of gear wheels may split a large interconnected set ofconnected wheels and would affect the representation of the effect of all actions on all wheels in this set). In a modularrepresentation, only local properties of the components should be represented explicitly; global properties should bederivable from a generic part of the theory which does not explicitly depend on the actual configuration of the system.This is an aspect of elaboration tolerance [24].352M. Denecker, E. Ternovska / Artificial Intelligence 171 (2007) 332–360To obtain a modular representation in the gear wheel example, we need to be able to express the reachability from aspecific wheel in an arbitrary graph. It is well-known that this concept cannot be expressed in first-order logic. Belowwe present a formalization through an iterated inductive definition.In the gear wheel example, there is one domain-dependent sort, denoted Gear_wheel. Action symbols are start andstop and have an argument of sort Gear_wheel. The unique fluent Turns has arguments of sort Gear_wheel and Sit.Basic components of the inductive situation calculus for the Gear wheel example are the foundational axioms Dif ofsituations and the unique name axioms Duna(Act) for actions. The main axiom of our theory is the simultaneous iteratedinductive definition Δsc of the fluent Turns and its causality predicates CTurns and C¬Turns. The effect propagationprocess caused by start or stop actions in one situation will be modeled by a monotone induction. To define the fluentTurns for all states, the monotone induction is then iterated over the well-founded structure of situations.The definition Δsc can be split up in two sub-definitions. The first part of the definition consists of the standardrules for the fluent Turns:⎧⎪⎨⎪⎩ΔTurnsfluent:=∀g (Turns(g, S0) ← ITurns(g))∀g∀a∀s (Turns(g, do(a, s)) ← CTurns(g, a, s))∀g∀a∀s (Turns(g, do(a, s)) ← Turns(g, s) ∧ ¬C¬Turns(g, a, s)).⎫⎪⎬.⎪⎭The second part is the definition Δeffect which describes the causation predicates CTurns and C¬Turns. The followingset of rules Δeffect specify direct and indirect effects of actions:Δeffect :=⎧∀g∀a∀s (CTurns(g, a, s) ← a = start(g)),⎪⎪⎪⎨∀g∀a∀s (C¬Turns(g, a, s) ← a = stop(g)),⎪⎪⎪⎩∀g∀a∀s (CTurns(g, a, s) ← ∃g∀g∀a∀s (C¬Turns(g, a, s) ← ∃g(cid:15)Connected(g, g(cid:15)(Connected(g, g(cid:15)) ∧ CTurns(g(cid:15), a, s)),(cid:15)(cid:15)) ∧ C¬Turns(g, a, s)))⎫⎪⎪⎪⎬⎪⎪⎪⎭.These rules contain positive recursion. Define Δsc := ΔTurnsfluentCTurns and C¬Turns by simultaneous non-monotone induction in terms of the open predicates ITurns and Connected.∪ Δeffect. This definition defines the predicates Turns,Notice that the statement of the problem does not specify what gearwheels exist, how they are connected andwhether they are initially turning. Consequently, the theory Dinit consists only of two axioms which express generallaws of connected gearwheels. The first axiom expresses that the relation symbol Connected, which describes thephysical connections between the gear wheels, is a symmetric relation:(cid:15)∀g∀g(Connected(g, g(cid:15)) ⊃ Connected(g(cid:15), g)).The second axiom of Dinit is related to the state constraint of this system which is that interconnected gear wheels arein the same state: either turning or in rest. The ramification rules guarantee that this state constraint is preserved, butnot that it holds initially. Therefore, we have to add the constraint for the initial state. This is described by the axiom(cid:15)∀g∀g(Connected(g, g(cid:15)) ⊃ ITurns(g) ≡ ITurns(g(cid:15))).The full axiomatization of the domain consists ofDwheels := Dif ∪ Duna(Act) ∪ Dinit ∪ {Δsc}.(27)Below we analyze the theory Dwheels. Since Δeffect is a positive definition, the basic action theory Dwheels satisfiesthe conditions of Theorem 6. Consequently, we have the following proposition.Proposition 13. The theory Dwheels satisfies the Initial State Expansion property and is equivalent toFluent) ∧ PID(ΔEffect)}.Df ∪ Duna(Act) ∪ Dinit ∪ {comp(ΔTurnsProposition 14. The theory Dwheels logically entails the state constraint:∀g∀g(cid:15)∀s (Connected(g, g(cid:15)) ⊃ Turns(g, s) ≡ Turns(g(cid:15), s)).Proof. The proof is model-theoretic. Let I be a model of Dwheels. We use induction on the length of the situations. Itfollows from axiom (27) on the initial state, that(cid:15)∀g∀g(Connected(g, g(cid:15)) ⊃ Turns(g, S0) ≡ Turns(g(cid:15), S0)).M. Denecker, E. Ternovska / Artificial Intelligence 171 (2007) 332–360353Assume that the property is satisfied for situation s. We prove that it holds for the successor situation doI (a, s), forarbitrary action a.Select any pair (g, g(cid:15)) ∈ ConnectedI . By definition Δeffect, if CTurn(g(cid:15), a, s) is true then so is CTurn(g, a, s). Becausethe graph ConnectedI is symmetric, it follows that CTurn(g, a, s) and CTurn(g(cid:15), a, s) have the same truth value. Thesame holds for C¬Turn. The induction hypothesis states that in situation s all connected wheels are in the same state.By the above observation, the action a has the same effects on all connected wheels. Consequently, the inductionhypothesis is preserved in situation doI (a, s). (cid:3)4.2.2. Non-monotone ramification rulesIn [9], it was argued that to model certain forms of ramifications, also non-monotone ramification rules are useful.We illustrate this with a variant of the suitcase example from [19].Example 1 (suitcase). Several versions of this example (e.g. [9,19,38]) have been used to demonstrate that domainconstraints are not strong enough to solve the ramification problem and that an explicit notion of causality is necessary.Suppose we have a suitcase which is opened by a spring mechanism on the moment both its locks are being open. Tomodel this example, the sort lock is used. Fluent O represents the fact that the suitcase is open; fluent OpenL withan argument of sort lock means that the lock is open. Action symbols open and close with one argument of sort lockrepresent actions of opening and closing the respective lock. Two constants l1, l2 of sort lock represent the two locks.Let Δeffect consist of the following rules:∀l∀a∀s (COpenL(l, a, s) ← a = open(l)),∀l∀a∀s (C¬OpenL(l, a, s) ← a = close(l))and∀a∀sCO (a, s) ← ∀lCOpenL(l, a, s) ∨(OpenL(l, s) ∧ ¬C¬OpenL(l, a, s))!!.(28)For every fluent F from the set {OpenL, O}, we have the standard fluent definition ΔFfluent. Finally, we have:Dinit := DDCA(lock) ∪ Duna(lock) ∪(cid:6)∀l(IOpenL(l) ⊃ IO(cid:7).Interestingly, the definition Δeffect is not recursive and hence is total in each structure. It can be translated intoclassical logic by taking its completion. Consequently, the entire definition Δsc can be translated into the classicallogic theory comp(Δsc).The example illustrates several points of interest. First, ramifications may sometimes rely on the absence of certaincauses. In such cases, the use of non-monotone causation rules such as the rule defining CO is appropriate. Second,ramification rules are useful for modeling simultaneous effects and concurrency. Such simultaneous effects cannotoccur in the above situation calculus but could occur in extensions with concurrent actions or with additional ac-tions and/or ramifications which could affect both locks simultaneously. For the sake of illustrating this, consider thefollowing extension.Example 2. Consider an extension of Example 1 in which the suitcase has a central button which switches the stateof the two locks of the suitcase. The effects of pushing this button are expressed by the additional effect rules:∀l∀a∀s (COpenL(l, pushbutton, s) ← ¬OpenL(l, s)),∀l∀a∀s (C¬OpenL(l, pushbutton, s) ← OpenL(l, s)).Note that executing the action pushbutton in a state where one lock is open and the other is closed, produces simul-taneous effects of opening one lock and closing the other lock, and this would not open the suitcase. In fact, theramification rule describes the intended behaviour of the suitcase for every combination of effects on both locks.As a last point, we illustrate an alternative style of representing complex forms of ramifications. 354M. Denecker, E. Ternovska / Artificial Intelligence 171 (2007) 332–360Example 3. In the suitcase example, the suitcase is caused to open on the instant that both locks are open. Let usreplace the rule (28) by the following more direct representation of this:∀a∀s (CO (a, s) ← ∀lOpenL(l, do(a, s))).(29)According to this rule, when all locks are open in the successor state do(a, s), then a causes the suitcase to openin situation s. Adding this axiom changes the structure of the definition. So far, causality predicates at state s weredefined in terms of fluents and causality predicates at state s. Here, CO in state s is defined in terms of OpenL inthe future state do(a, s). This is no longer induction on the well-founded set of situations. However, the resultingdefinition is still a definition by well-founded induction in each initial structure A, although the underlying order doesnot entirely follow the order of situations. Indeed, the reduction relation ≺ constructed in the standard way, consistsof the following tuples, for arbitrary lock l, situation s and action a:A(a, s)]),(COpenL[l, a, s], OpenL[l, doA(OpenL[l, s], OpenL[l, do(CO [a, s], O[do(a, s)]),(O[s], O[do(OpenL[l, doAA(a, s)]), (C¬O [a, s], O[doA(a, s)], CO [a, s]).A(a, s)]),(a, s)]), (C¬OpenL[l, a, s], OpenL[l, doA(a, s)]),It is easy to verify that the transitive closure ≺∗ is a strict well-founded order. Hence, Δsc is a definition by well-founded induction in each initial structure A. It follows that this definition can be translated in FO using completionand the Initial State Expansion property is still satisfied.4.2.3. Limits of the approachAs pointed out in [9], there is a subtle modeling issue involved in the use of non-monotone ramification rules. Inthe inductive situation calculus, the ramification rules are used to model an effect propagation process. In the physicalreality, the effect propagations in this process are not instantaneous, but take a small lapse of time. The intermediatestates during this process are not modeled explicitly in the situation calculus. In each of these intermediate states,certain causes may have occurred already, and other causes did not yet occur. Therefore, it is possible that the conditionof an effect rule, if it contains a negative cause literal ¬CF (¯t, a, s), is satisfied during such an intermediate state, whenthe cause of F (¯t ) was not yet produced, but not in the final state. In such a case, according to the inductive situationcalculus, the effect described by the rule will not occur. Stated differently, if, during the propagation process, theconditions of an effect rule are satisfied in some intermediate state, and one of the conditions is the absence of acertain cause, then the effect will not be inferred if there is a possibility that this cause is still produced later duringthe propagation process.Example 4. Reconsider the effect rule for opening the suitcase of Example 1 and Example 2:COpenL(l, a, s) ∨(OpenL(l, s) ∧ ¬C¬OpenL(l, a, s))CO (a, s) ← ∀l∀a∀s!!.Suppose we push the central button to switch the states of the locks. The mechanism might be just a tiny bit faster toswitch the lock l1 than the lock l2. If the first one was already closed and the second open, then there will be a briefintermediate state during which the two locks will be open and the conditions of the above effect rule are satisfied.This state will last only a fraction of a second, after which the second lock is closed. For an old-fashioned suitcasewith mechanical spring mechanism, this is not enough time to open the suitcase. So, the suitcase does not open. Theabove rule correctly models this situation.Now, consider a high-tech suitcase in which a microprocessor monitors the state of the two locks, and when bothare open, it sends a signal to an electric motor to open the suitcase. Compared to the old-fashioned suitcase, the effectpropagations are the same. However, there is a difference on the level of the reaction time of the opening effect. Themicroprocessor reacts in microseconds and will detect the state change of the first lock before that of the second. So,in this case, the suitcase will be opened. The ramification rules of the inductive situation calculus cannot be used tomodel the high-tech suitcase. M. Denecker, E. Ternovska / Artificial Intelligence 171 (2007) 332–3603554.3. Defined fluentsIn this section, we propose a second extension of the inductive situation calculus by allowing defined fluents. Suchfluents are not governed by effect laws and the law of inertia, but by a definition in terms of existing fluents.Example 5. In the standard ontology of the blocks world problem, there are basic actions pick(b) and put(b, l), andfluents• On(b, l, s): the block b is on location l, which is the table or another block;• Clear(b, s): nothing is on block b;• Clasped(b, s): the robot clasps block b;• Free(s): the robot hand is free.We could represent the effects of the actions on every of these fluents. It is perhaps more natural to represent theeffects on On and Clasped and to define the fluent Clear in terms of On and the fluent Free in terms of Clasped. Thedefinitions are:(cid:6)(cid:7)∀b∀s (Clear(b, s) ← ¬∃b, b, s))(cid:7)(cid:6)∀s (Free(s) ← ¬∃b Clasped(b, s))(cid:15) On(b,.(cid:15)We could also define the fluent Above(b, b(cid:15), s) expressing that in state s, block b is above b(cid:15). It is defined as thetransitive closure of the fluent On(b, b(cid:15), s):(cid:3)∀b∀b1∀s (Above(b, b1, s) ← On(b, b1, s)),∀b∀b1∀s (Above(b, b1, s) ← ∃b2(Above(b, b2, s) ∧ Above(b2, b1, s)))(cid:4).In a sense, defining fluents is also a way of representing ramifications. Indeed, one could view the fact that Free(s)is initiated or terminated as a ramified effect of terminating or initiating Clasped(b, s). Yet, there is a definite differencewith the sort of ramification considered in Section 4.2. In that section, the causality rules model the propagation ofeffects through the system. Here, a defined fluent is (sometimes) only a new name denoting some, potentially complex,configuration of the primitive fluents.Below we distinguish between defined fluents and primitive fluents. Primitive fluents are defined in the standardway. To represent defined fluents, we extend the inductive situation calculus by allowing the definition Δsc of Sec-tion 4.2 to be extended with a set of rules Δdef of the form:∀ ¯x∀s (Fd ( ¯x, s) ← Ψ ( ¯x, s)),(30)where Fd is a defined fluent and Ψ is a formula where s has only free occurrences, contains no causality predicatesand every fluent atom is of the form Fi(¯ti, s), where Fi may be a defined or a primitive fluent. We do not introduceinitial state or causation predicates for defined fluents in τisc.Consider the following partition of Δsc:{Δ1fluent, Δeffect, Δdef}fluent, . . . , Δnfluent is the standard definition of a primitive fluent Fi .where Δi(31)Proposition 15. Partition (31) is a reduction partition of Δsc in each initial structure A.Proof. Let A be an initial structure with domain A. We construct a reduction relation ≺ in At τiscrule-by-rule way. It consists of all tuples:A in the normal[ ¯u, a, s], Fi[ ¯u, do(CFi(Fi[ ¯u, s], Fi[ ¯u, do(Fj [ ¯u, s], C(¬)FiA[ ¯v, a, s]),A(a, s)]),(a, s)]), (C¬Fi[ ¯u, a, s], Fi[ ¯u, doA(a, s)]),356M. Denecker, E. Ternovska / Artificial Intelligence 171 (2007) 332–360[ ¯u, a, s], C(¬)Fi(C(¬)Fj(Fi[ ¯u, s], Fk[ ¯v, s]),[ ¯v, a, s]),for arbitrary i, for arbitrary j and j (cid:15) such that Fj and Fj (cid:15) are primitive fluents, for arbitrary k such that Fk is a definedfluent, for arbitrary tuples of objects ¯u and ¯v, for arbitrary elements a of the action sort and s of the situation sort.Notice that according to the last line, each defined fluent domain atom Fk[ ¯v, s] depends on each fluent atom Fi[ ¯u, s]and hence, ≺ is a reduction relation of each rule in Δdef.From here on, the proof is very similar to that of Proposition 10. Again, it is easy to show that ≺ is a reductionA . It is easyA such that Q[ ¯b] ≺∗ P [ ¯a] and P [ ¯a] ≺∗ Q[ ¯b], P and Q are defined in therelation. Its reflexive, transitive closure ≺∗ is a reduction relation and a pre-well-founded order on At τiscto see that for atoms P [ ¯a], Q[ ¯b] from At τiscsame sub-definition. Therefore, partition (31) is a reduction partition of Δsc in A. (cid:3)As a corollary of this proposition and the decomposition theorems, Theorem 1 and Theorem 2, we obtain thefollowing property.Corollary 5. If Δeffect and Δdef are total in (each subtheory of ) Dif ∪ Duna(Act) ∪ Dinit, then the basic action theory(18) satisfies the Initial State Expansion property, and is equivalent to the theory Df ∪ Duna(Act) ∪ DS0∧Δeffect ∧ Δdef}.(cid:19)ni=1 Δifluent∪ {This modularity result can be used to prove the correctness of several translations from inductive situation calculuswith defined fluents to classical logic.4.3.1. Example: Gear wheels with frictionIn this example, we consider another version of the gear wheel problem in which the connections between gearwheels can be dynamically changed (as in the gears of a car) and in which friction is taken into account. We assumethat some of the gear wheels have a fixed connection to an engine. This engine can be started or stopped. A gear wheelis in rest unless it is connected directly or indirectly to a running engine. There are actions to start or stop (the engineof) a gear wheel and to connect or disconnect gear wheels.We use the following vocabulary with sort Gear_wheel:• Turn(g, s): gear wheel g is turning;• Emp(g, s): gear wheel g is empowered;• DirEmp(g, s): gear wheel g is attached to an operating motor (i.e., is directly empowered);• Con(g, g(cid:15), s): gear wheels g and g(cid:15) are directly connected;• start(g), stop(g): the actions of starting and halting the engine attached to g;• connect(g, g(cid:15)), disconnect(g, g(cid:15)): the actions of connecting and disconnecting a pair of gear wheels.Defined fluents are axiomatized by the following set Δdef of rules. We represent that a gear wheel g is turning iffit is empowered. It is empowered if it is attached to a running engine (i.e., DirEmp(g, s) is true), or there is a path ofgear wheel connections to such a directly empowered gear wheel:⎧⎪⎨⎪⎩Δdef =ΔDirEmpfluent=⎧⎪⎨⎪⎩⎧⎪⎨⎪⎩∀g∀s (Turn(g, s) ← Emp(g, s)),∀g∀s (Emp(g, s) ← DirEmp(g, s)),∀g∀s (Emp(g, s) ← ∃g1(Con(g, g1, s) ∧ Emp(g1, s)))⎫⎪⎬,⎪⎭∀g (DirEmp(g, S0) ← IDiREmp(g)),∀g∀a∀s (DirEmp(g, do(a, s)) ← CDirEmp(g, a, s)),∀g∀a∀s (DirEmp(g, do(a, s)) ← DirEmp(g, s) ∧ ¬C¬DirEmp(g, a, s)),ΔConfluent=∀g∀g∀g∀g∀g∀g(cid:15)(cid:15)(Con(g, g(cid:15)∀a∀s (Con(g, g(cid:15)∀a∀s (Con(g, g(cid:15)(cid:15), S0) ← ICon(g, g(cid:15))),, do(a, s)) ← CCon(g, g(cid:15), do(a, s)) ← Con(g, g(cid:15), a, s)),, s) ∧ ¬C¬Con(g, g(cid:15), a, s))⎫⎪⎬,⎪⎭⎫⎪⎬,⎪⎭M. Denecker, E. Ternovska / Artificial Intelligence 171 (2007) 332–360357Δeffect =⎧⎪⎪⎪⎪⎪⎪⎪⎨⎪⎪⎪⎪⎪⎪⎪⎩∀g∀a∀s (CDirEmp(g, a, s) ← a = start(g)),∀g∀a∀s (C¬DirEmp(g, a, s) ← a = stop(g)),(cid:15)∀g∀g∀g∀g∀g∀g∀g∀g(cid:15)∀a∀s (CCon(g, g(cid:15)∀a∀s (CCon(g(cid:15)∀a∀s (C¬Con(g, g(cid:15)∀a∀s (C¬Con(g, g, a, s) ← CCon(g, g, a, s) ← a = connect(g, g, a, s)),, a, s) ← a = disconnect(g, g, a, s)), g, a, s) ← C¬Con(g, g)),(cid:15)(cid:15)(cid:15)(cid:15)(cid:15)(cid:15)(cid:15))),⎫⎪⎪⎪⎪⎪⎪⎪⎬⎪⎪⎪⎪⎪⎪⎪⎭.In this definition, the fluents Turn and Emp are defined. The fluent Emp is defined inductively. The theory Dinitconsists of a single axiom expressing that the initial connection relation between gear wheels is symmetric:(cid:15)∀g∀g(ICon(g, g(cid:15)) ⊃ ICon(g(cid:15), g)).Let DFriction := Dif ∪ Duna(Act) ∪ Dinit ∪ {Δsc} where Δsc consists of Δfluent ∪ Δeffect ∪ Δdef as defined above. Theconditions of Corollary 5 apply. Because Δfluent is a definition by well-founded induction and Δeffect and Δdef arepositive inductive definitions, this theory can be translated into classical logic.Proposition 16. The basic action theory with definitions DFriction satisfies the Initial State Expansion property and isequivalent to the SO theoryDf ∪ Duna(Act) ∪ Dinit ∪4.4. More extensions(cid:7)(cid:6)comp(Δfluent) ∧ PID(Δeffect) ∧ PID(Δdef).Many other extensions of situation calculus have been proposed, for example natural actions, concurrency andcontinuous time [34]. Most of these extensions can be integrated seamlessly in the inductive situation calculus. Oneextension that we briefly discuss here is the one with non-deterministic actions. Obviously, in this case, successorstates cannot be defined in terms of predecessor states and actions, since the latter do not determine the first in aunique way. A simple technique to model non-determinism is by introducing new open predicates. For example,consider the non-deterministic effect of rolling a dice, which causes the fluent Dice to take a value between 1 and 6.This could be represented in the inductive situation calculus by introducing a new binary open predicate Thrown witha first argument of sort int and a second of sort sit. The effect of rolling a dice on the fluent Dice of sort int is thenrepresented by the effect rule:∀n∀s (CDice(n, throw, s) ← Thrown(n, s))together with axioms stating that for all situations s, there is a unique number n between 1 and 6 such that Thrown(n, s)holds. This technique can be generalized into a general methodology to represent non-deterministic actions.5. Related workThe prime goal of this paper is to clarify inductive definitions and their role in common sense knowledge represen-tation. The application domain is temporal reasoning, situation calculus in particular. In this respect, this paper is onlypreceded by earlier work of the authors. The semantic correspondence between inductive definitions and causalitywas pointed out independently in [36,37] and [9]. In both cases, the motivation for using inductive definitions wasthe similarity between the process of effect propagation in a dynamic system and inductive definitions. Inductive de-finition formalizations of situation calculus were first presented by Ternovska in [36,37] and, a bit later, by Deneckerin [5]. The backgrounds of these studies were quite different, in one case the classical logic approach developed atthe Cognitive Robotics Group at the University of Toronto, and in the other case, logic programming formalizationsof temporal reasoning. Ternovska [36,37] observed that the construction of a model of Reiter-style situation calculusis an induction over the well-founded order on situations, and therefore, proposed to model situation calculus with alogic of inductive definitions. Her approach used Aczel-style abstract monotone induction definitions [1]. To handlethe inherent non-monotonicity of the situation calculus, the monotone definitions were constructed by simultaneousnon-monotone induction. She also extended her solution to acyclic ramification rules and demonstrated that an induc-tive definition of the set of situations implies the general induction principle on situations [33]. In [9], Denecker et al.358M. Denecker, E. Ternovska / Artificial Intelligence 171 (2007) 332–360focussed on the ramification problem in general, and pointed to the similarity with inductive definitions. They studiedthe ramification problem with cyclic effect rules and negative conditions, and proposed to use the well-founded se-mantics to model such complex ramifications. The inductive situation calculus integrates this work in the context ofthe situation calculus.For an overview of the many different approaches for temporal reasoning and/or the ramification problem, we referto [9,15,26,34,35,38,39]. Here we limit our discussion to approaches with an explicit representation of causal laws insituation calculus or non-monotonic logic.It has been observed that the process of effect propagation is a constructive process: basic actions cause changesand effects which propagate through the dynamic system; changes do not appear without an external cause (i.e.,no spontaneous generation of effects, or no deus ex machina effects). The same constructive intuition is found ininductive definitions. This explains why inductive definitions can correctly model recursive effect propagations. Inthis respect, the inductive situation calculus is more general than two other well-known classical logic formalizationsof the situation calculus with ramifications, namely Lin’s approach [19] and McIlraith’s solitary stratified theories [26].Both approaches impose constraints on ramification rules which preclude recursive ramifications. A strong constraintin solitary stratified theories is that no fluent symbol is allowed to appear both as an effect and in the precondition ofthe same action. On the other hand, McIlraith addresses the qualification problem, which we don’t.While the above approaches are based on classical logic, causality has also been investigated from a non-monotonicreasoning perspective. Perhaps the best known non-monotonic logic that takes causality as its basic principle is thelogic of non-monotonic causal theories [15,22]. This language extends propositional logic with causal implicationsϕ ⇐ ψ . Interestingly, this approach takes the opposite point of view with respect to spontaneous generation of effectsthan in the inductive situation calculus. Spontaneous generation is not seen as a flaw but as a feature, used to modelexogeneous fluents, fluents that can change state spontaneously. This is modeled by pairs of causal rulesP ⇐ P ,¬P ⇐ ¬P .As a consequence, cyclic effect rules as found in the gear wheel example, cannot correctly be modeled by recursivecausal rules in this formalism because such a theory would accept unintended models in which two connected gearwheels cause each other to turn, without external cause. While this seems a weakness of this formalism, it is clearthat the possibility of representing exogeneous events or fluents is a useful feature. The challenge here is to integrateexogeneous fluents with a correct treatment of cyclic effect rules.6. ConclusionThis paper explains the inductive nature of the situation calculus. We have shown that—unsuspected by itscreators—the original Reiter-style situation calculus makes hidden use of inductive definitions. We made these de-finitions explicit and found monotone and non-monotone induction. We formalized these definitions in a logic ofinductive definitions (ID-logic) thus obtaining a variant of the situation calculus which we call the inductive situationcalculus. We presented a translation to classical logic to show that the inductive situation calculus is indeed equivalentto the standard formalization in the case without ramifications.Our ID-logic formalization offers a number of advantages compared to classical logic. First, in the Reiter-stylesituation calculus, different forms of induction are formalized in different ways. By using a logic of inductive defini-tions, we obtained a uniform and modular representation. Second, the use of inductive definitions allowed us to extendthe situation calculus to cope with complex temporal phenomena such as (recursive) ramifications and (inductively)defined fluents. We also proved that the inductive situation calculus (and Reiter’s situation calculus) satisfies the InitialState Expansion property.Our work contributes also on other levels. First, it presents the situation calculus as an application of the principle ofiterated induction in the context of commonsense reasoning thus giving insight into this complex and little known formof non-monotone induction. Second, our analysis showed that the modularity, totality and transformation theoremsare powerful tools for analyzing and transforming large definitions, by allowing to break them up using the modularitytheorem and translating them piecewise to classical logic.Finally, our experiment demonstrates that the use of different forms of inductive definitions is not limited to mathe-matics, but is applicable in a much wider area of knowledge representation and commonsense reasoning. In particular,M. Denecker, E. Ternovska / Artificial Intelligence 171 (2007) 332–360359it seems that inductive definitions are well-suited for reasoning about causality. Perhaps this is not so surprising. Af-ter all, mathematical induction is about construction of complex mathematical objects. In this respect, mathematicalinduction may be viewed as an application of causal reasoning in the idealized abstract context of mathematics, ratherthan in the much more complex realm of commonsense reasoning.References[1] P. Aczel, An introduction to inductive definitions, in: J. Barwise (Ed.), Handbook of Mathematical Logic, North-Holland Publishing Company,Amsterdam, 1977, pp. 739–782.[2] F. Baader, D. Calvanese, D. McGuinness, D. Nardi, P. Patel-Schneider (Eds.), The Description Logic Handbook. Theory, Implementation andApplications, Cambridge University Press, 2002.[3] K.L. Clark, Negation as failure, in: H. Gallaire, J. Minker (Eds.), Logic and Databases, Plenum Press, 1978, pp. 293–322.[4] M. Denecker, The well-founded semantics is the principle of inductive definition, in: J. Dix, L. Fariñas del Cerro, U. Furbach (Eds.), Logicsin Artificial Intelligence, Schloss Daghstull, in: Lecture Notes in Artificial Intelligence, vol. 1489, Springer, 1998, pp. 1–16.[5] M. Denecker, Extending classical logic with inductive definitions, in: J. Lloyd, et al. (Eds.), First International Conference on ComputationalLogic (CL2000), London, in: Lecture Notes in Artificial Intelligence, vol. 1861, Springer, 2000, pp. 703–717.[6] M. Denecker, M. Bruynooghe, V. Marek, Logic programming revisited: logic programs as inductive definitions, ACM Transactions on Com-putational Logic 2 (4) (2001) 623–654.[7] M. Denecker, E. Ternovska,in: Proceedings of Ninth International Conference on Principles ofKnowledge Representation and Reasoning, Delta Whistler Resort, Canada, 2004, pp. 545–553, http://www.cs.kuleuven.ac.be/cgi-bin-dtai/publ_info.pl?id=41085.Inductive situation calculus,[8] M. Denecker, E. Ternovska, A logic of non-monotone inductive definitions and its modularity properties, in: V. Lifschitz, I. Niemelä (Eds.),7th International Conference on Logic Programming and Nonmonotonic Reasoning, 2004.[9] M. Denecker, D. Theseider Duprè, K. Van Belleghem, An inductive definition approach to ramifications, Linköping Electronic Articles inComputer and Information Science 3 (7) (1998) 1–43, http://www.ep.liu.se/ea/cis/1998/007/.[10] M. Denecker, E. Ternovska, A logic of non-monotone inductive definitions, ACM Transactions on Computational Logic (TOCL), 2007.[11] F. Fages, Consistency of Clark completion and existence of stable models, Journal of Methods of Logic in Computer Science 1 (1994) 51–60.[12] M. Fitting, Fixpoint semantics for logic programming a survey, Theoretical Computer Science 278 (1–2) (2002) 25–51.[13] M. Gelfond, V. Lifschitz, Classical negation in logic programs and disjunctive databases, New Generation Computing 9 (1991) 365–385.[14] M. Gelfond, V. Lifschitz, Describing action and change by logic programs, in: Ninth Joint International Conference and Symposium on LogicProgramming JICSLP’92, MIT Press, 1992.[15] E. Giunchiglia, J. Lee, V. Lifschitz, N. McCain, H. Turner, Nonmonotonic causal theories, Artificial Intelligence (AIJ) 153 (2004) 49–104.[16] Y. Gurevich, S. Shelah, Fixed-point extensions of first-order logic, Annals of Pure and Applied Logic 32 (1986) 265–280.[17] S. Hanks, D. McDermott, Nonmonotonic logic and temporal projection, Artificial Intelligence 33 (1987) 379–412.[18] H.J. Levesque, F. Pirri, R. Reiter, Foundations for the situation calculus, Electronic Transactions on Artificial Intelligence 2 (1998) 159–178.[19] F. Lin, Embracing causality in specifying the indirect effects of actions, in: Proc. of IJCAI 95, 1995, pp. 1985–1991.[20] V.W. Marek, M. Truszczy´nski, Stable models and an alternative logic programming paradigm, in: K.R. Apt, V. Marek, M. Truszczy´nski,D.S. Warren (Eds.), The Logic Programming Paradigm: A 25 Years Perspective, Springer, 1999, pp. 375–398.[21] M. Mariën, R. Mitra, M. Denecker, M. Bruynooghe, Satisfiability checking for PC(ID), in: G. Sutcliffe, A. Voronkov (Eds.), Proc. LPAR’05,in: Lecture Notes in Artificial Intelligence, vol. 3835, Springer, 2005, pp. 565–579.[22] N. McCain, H. Turner, Causal theories of action and change, in: Proc. of AAAI 97, 2007, pp. 460–465.[23] J. McCarthy, Circumscription—a form of nonmonotonic reasoning, Artificial Intelligence 13 (1980) 27–39.[24] J. McCarthy, Elaboration tolerance, in: COMMON SENSE 98, Symposium on Logical Formalizations of Commonsense Reasoning, January1998.[25] J. McCarthy, P.J. Hayes, Some philosophical problems from the standpoint of artificial intelligence, in: B. Meltzer, D. Michie (Eds.), MachineIntelligence 4, Edinburgh University Press, 1969, pp. 463–502.[26] S. McIlraith, An axiomatic solution to the ramification problem (sometimes), Artificial Intelligence 116 (1–2) (2000) 87–121.[27] D. Mitchell, E. Ternovska, A framework for representing and solving NP search problems, in: Proceedings of the Twentieth National Confer-ence on Artificial Intelligence (AAAI-05), 2005, pp. 430–435.[28] Y.N. Moschovakis, Elementary Induction on Abstract Structures, North-Holland Publishing Company, Amsterdam, New York, 1974.[29] I. Niemelä, Logic programs with stable model semantics as a constraint programming paradigm, Annals of Mathematics and Artificial Intel-ligence 25 (3,4) (1999) 241–273.[30] N. Pelov, E. Ternovska, Reducing ID-logic to propositional satisfiability, in: Proceedings of the Twenty First International Conference onLogic Programming (ICLP 2005), 2005.[31] F. Pirri, R. Reiter, Some contributions to the metatheory of the situation calculus, ACM 46 (3) (1999) 325–361.[32] R. Reiter, A logic for default reasoning, Artificial Intelligence 13 (1980) 81–132.[33] R. Reiter, The frame problem in the situation calculus: a simple solution (sometimes) and a completeness result for goal regression, in:V. Lifschitz (Ed.), Artificial Intelligence and Mathematical Theory of Computation: Papers in Honor of John McCarthy, Academic Press, SanDiego, CA, 1991, pp. 359–380.[34] R. Reiter, Knowledge in Action: Logical Foundations for Describing and Implementing Dynamical Systems, MIT Press, 2001.[35] M. Shanahan, Solving the Frame Problem, MIT Press, 1997.360M. Denecker, E. Ternovska / Artificial Intelligence 171 (2007) 332–360[36] E. Ternovskaia, Causality via inductive definitions, in: Working Notes of “Prospects for a Commonsense Theory of Causation”, AAAI SpringSymposium Series, March 23–28, 1998.[37] E. Ternovskaia, Inductive definability and the situation calculus, in: Transaction and Change in Logic Databases, in: Lecture Notes in ComputerScience, vol. 1472, Springer, 1998.[38] M. Thielscher, Ramification and causality, Journal of Artificial Intelligence 89 (1997) 317–364.[39] M. Thielscher, Introduction to the fluent calculus, Electronic Transactions on Artificial Intelligence 3–4 (1998) 179–192, http://www.ep.liu.se/ej/etai/1998/006/.[40] A. Van Gelder, An alternating fixpoint of logic programs with negation, Journal of Computer and System Sciences 47 (1993) 185–221.[41] A. Van Gelder, K.A. Ross, J.S. Schlipf, The well-founded semantics for general logic programs, Journal of the ACM 38 (3) (1991) 620–650.[42] J. Vennekens, D. Gilis, M. Denecker, Splitting an operator: Algebraic modularity results for logics with fixpoint semantics, ACM Transactionson Computational Logic (TOCL) 2006, submitted for publication.