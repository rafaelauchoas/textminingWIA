Artificial Intelligence 165 (2005) 137–163www.elsevier.com/locate/artintDecision making on the sole basis ofstatistical likelihoodPhan H. Giang a,∗, Prakash P. Shenoy ba Computer Aided Diagnosis and Therapy Solutions (CAD), Siemens Medical Solutions,51 Valley Stream Pkwy, Malvern, PA 19355, USAb University of Kansas School of Business, 1300 Sunnyside Ave, Summerfield Hall,Lawrence, KS 66045-7585, USAReceived 10 May 2004; accepted 16 March 2005Available online 10 May 2005AbstractThis paper presents a new axiomatic decision theory for choice under uncertainty. Unlike Bayesiandecision theory where uncertainty is represented by a probability function, in our theory, uncertaintyis given in the form of a likelihood function extracted from statistical evidence. The likelihood prin-ciple in statistics stipulates that likelihood functions encode all relevant information obtainable fromexperimental data. In particular, we do not assume any knowledge of prior probabilities. Conse-quently, a Bayesian conversion of likelihoods to posterior probabilities is not possible in our setting.We make an assumption that defines the likelihood of a set of hypotheses as the maximum likelihoodover the elements of the set. We justify an axiomatic system similar to that used by von Neumannand Morgenstern for choice under risk. Our main result is a representation theorem using the newconcept of binary utility. We also discuss how ambiguity attitudes are handled. Applied to the sta-tistical inference problem, our theory suggests a novel solution. The results in this paper could beuseful for probabilistic model selection. 2005 Elsevier B.V. All rights reserved.Keywords: Decision theory; Likelihood; Statistical inference; Ambiguity attitude* Corresponding author.E-mail addresses: phan.giang@siemens.com (P.H. Giang), pshenoy@ku.edu (P.P. Shenoy).0004-3702/$ – see front matter  2005 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2005.03.004138P.H. Giang, P.P. Shenoy / Artificial Intelligence 165 (2005) 137–1631. IntroductionVarious formal decision theories for choice under risk and uncertainty have been studiedsince the seminal work by von Neumann and Morgenstern (vNM) [38] where the expectedutility maximization principle was formally established. With few exceptions, a commonfeature in these theories is the use of probability to express uncertainty in decision situ-ations. An axiomatic model is as good as its axioms, the debate on axioms of the vNMtheory started almost immediately with their publication [2]. As a result of this ongoingdebate, axiomatic systems that are weaker than vNM but still possess the expected utilityrepresentation have been investigated [17,32,33]. There is also a recognition that the uncer-tainty that one usually associates with the words “ambiguity”, “vagueness” and “fuzziness”are not the same kind as that associated with “risk”. The latter is captured by standard nu-merical probability.In this paper,1 we consider a class of choice problems where uncertainty is character-ized by likelihood functions. This class includes a typical statistical inference problem thatis formulated as follows. Suppose we are to analyze a statistical experiment on a randomvariable Y given (i) Y follows one of the distributions in F = {Pθ | θ ∈ Ω} parameter-ized by θ ; and (ii) the outcome of the experiment is Y = y. The question is: what can weconclude about the true value of parameter θ ?There is consensus among statisticians about what information sample y brings to theunknown parameter. According to the likelihood principle, one of the fundamental princi-ples of statistics [4,5,8], all relevant information of the sample is encoded in the likelihoodfunction on the parameter space. And the consensus also ends at this point. The statisticalinference problem is treated differently by different approaches [3].According to the decision-theoretic approach advocated by Wald [39], the inferenceproblem is viewed as a choice problem. For example, in the context of a hypothesis testingproblem, the choice is to either accept or reject a hypothesis. Within the decision-theoreticapproach there are several variations. Wald’s maximin decision rule selects an action thatdelivers the most favorable worst-case outcome. A Bayesian treatment of the problem sug-gests a calculation of posterior probability function on Ω via Bayes’s theorem from thelikelihood function by assuming a prior distribution. Given the posteriors, actions are com-pared on the basis of their expected utility. In this paper, we proposes a third alternative.We construct a decision theory that works directly with likelihood information. We chooseto treat likelihood as uncertainty in its own right for a simple reason: priors are not knownin many situations.The problem of probabilistic model selection in the areas of AI, machine learning, pat-tern recognition and data mining is an example of the statistical inference problem. Givena (training) data set y, researchers construct a probabilistic model P (e.g., a Bayesian net)that generates/fits the data and then use this model for inference with future observations.Because there are, almost always, more than one models that emerge as plausible candi-dates, model selection is an essential part of model construction.1 A preliminary version of this work has appeared in the Proceedings of 18th Conference on Uncertainty inArtificial Intelligence (UAI 2002) [21].P.H. Giang, P.P. Shenoy / Artificial Intelligence 165 (2005) 137–163139From a decision theoretic point of view, the prevailing practice to select a model usingsimple criteria such as maximum likelihood (ML) or maximum a posteriori probability(MAP) is equivalent to assuming equal utilities (costs) for all models under consideration.This assumption however does not explain the following example. Given two models ofapproximately the same likelihoods, most researchers would go for a simpler one (and jus-tify this choice by invoking Occam’s razor principle). In the statistics literature, modelsare selected by using Akaike Information Criterion (AIC) [1] or Schwarz’s criterion (a.k.a.Bayesian Information Criterion or BIC) [34]. The idea underlying both AIC and BIC is topenalize model’s likelihood by an amount depending on its number of parameters. Polandand Shachter [31] suggest the “effectiveness ratio” criterion where the penalty has an ex-plicit computational interpretation. Clearly, the concern on complexity can be viewed asa cost associated with a model. In broader terms, an implication from these works is thatdifferent models are associated with different costs that must be taken into account in amodel selection process.This paper is organized as follows. In the next section, we discuss extending a likelihoodfunction to a function on the set of subsets of possible worlds. In the main part (Section 3),we develop a decision theory for likelihood uncertainty. We begin by proposing a set of fiveaxioms that are justified by intuition as well as by the stochastic dominance principle. Next,we introduce the concept of binary utility and prove the representation theorem for likeli-hood lotteries. That is followed by comments on related works. In Section 4, our decisiontheory is applied for a statistical inference problem. Section 5 contains some concludingremarks.2. Likelihood as uncertainty measureLet us consider the statistical inference problem as described earlier. Although the phe-nomenon under study is described probabilistically (by a set of probability functions F ),the uncertainty pertaining to the choice problem is not. It is a likelihood function. The term‘likelihood’ used in modern statistics was coined by R.A. Fisher who mentioned it as earlyas 1922 [18]. Fisher used likelihoods to measure “mental confidence” in competing sci-entific hypotheses as a result of a statistical experiment (see [14] for a detailed account).Likelihood has a puzzling nature. For each θ ∈ Ω, there is a likelihood quantity that bymagnitude equals Pθ (y)—the probability (or probability density in case of infinite Ω)2 ofobserving y if θ is in fact the true value of the parameter. However, if we view the set oflikelihood quantities as a function on the parameter space, we have a likelihood function.A likelihood function is not a probability function. For a simple reason, the sum of alllikelihood values (over the parameter space) may not add to unity. Moreover, likelihoodfunctions are equivalent up to a proportional constant.To emphasize the fact that a likelihood function is tied to data y and has θ as the variable,the notation liky(θ ) is used instead of Pθ (y). Technically, probability and likelihood are2 One can write Pθ0 (y) in the form of a conditional probability: P (Y = y | θ = θ0). The latter notation impliesthat there is a probability measure on parameter space Ω. This is the case for the Bayesian approach. In this paper,we do not assume such a probability measure. So we will stick with the former notation.140P.H. Giang, P.P. Shenoy / Artificial Intelligence 165 (2005) 137–163two kinds of animals, but they are as close as mule and donkey. This proximity is thereason for an intertwining relationship. Obviously, (posterior) probability is derived fromlikelihood and priors via Bayes theorem. Since such priors are supposed to summarize theinformation about the parameter before the experiment is conducted, the assumption of itsexistence is beyond the realm of science as many statisticians contend. Although in certainsituations prior probability comes naturally, there is no compelling argument why it mustalways be known to an experimenter in all situations.Another path from likelihood to probability, that bypasses the issue of priors, was startedby Fisher himself. He suggested to compute what he called fiducial probabilities by nor-malizing the likelihoods (dividing by the sum of likelihoods). Fisher’s idea has been shownto work for isolated examples and but it faces a serious difficulty when applied to generalcases. Some statisticians now believe that the fiducial probability is a mistake [3].Belief function theory was proposed by Dempster [9] in an attempt to overcome thedifficulty of the fiducial argument. Shafer [35] is mainly responsible for turning Dempster’sidea into a full-fledged theory of evidence. A basic construct in Dempster–Shafer theory isbasic probability assignment (BPA)m : 2Ω → [0, 1]such that m(∅) = 0 and(cid:1)A⊆Ωm(A) = 1(1)Value m(A) for A ⊆ Ω is called probability mass of A. If m(A) > 0 then A is called afocus. A standard probability function is a belief function whose foci are singletons. Froma BPA, one can derive a plausibility functionPl(A) def=(cid:1)B∩A(cid:7)=∅m(B)for all ∅ (cid:7)= A ⊆ Ω(2)BPA and plausibility have the same information content since the original m can be recov-ered from Pl.Shafer [35] proposes to represent statistical evidence by a belief function with nestedfoci (consonant belief function or CBF) such that plausibilities on singletons are propor-tional to the likelihood values. Given a likelihood function likx , the corresponding CBFis constructed as follows. Suppose likx partitions Ω into {Ωi} according to its valuesΩi = {ω | likx(ω) = ai} with a1 > a2 > · · · > ak. Then there are k foci (Ai) and k massesAi =i(cid:2)j =1Ωiand m(Ai) = (ai − ai+1)a1(3)where ak+1def= 0.A consequence of nested-focus structure is that plausibility function is union decom-posable, i.e., for A, B ⊆ Ω(cid:4)(cid:3)Pl(A ∪ B) = maxPl(A), Pl(B)(4)P.H. Giang, P.P. Shenoy / Artificial Intelligence 165 (2005) 137–163141A crucial argument in favor of Shafer’s original3 proposal is that likelihood treatment inCBF is in agreement with the maximum likelihood method (ML) of statistics. In ML, thelikelihood assigned to a set of hypotheses is taken to be the maximum of the likelihoodsof individual hypothesis in the set. The idea of taking the maximum individual likelihoodas the likelihood for a set has been a standard practice since the publication of seminalpapers [30] by Neyman and Pearson (1928). ML is not only intuitively appealing, but it isalso backed by various asymptotic optimality properties [26,27].We will use different notation than one in [35]. We want to emphasize the nature oflikelihood and avoid belief function connotations. While Shafer is mainly interested inrepresenting and reasoning with evidence, our goal is decision making. Let us define anextended likelihood function or ELF Liky : 2Ω → [0, 1] as follows.Liky(θ ) def=liky(θ )supω∈Ω liky(ω)where ˆθ is the maximum likelihood estimate of θ .= liky(θ )liky( ˆθ )for θ ∈ ΩLiky(A) def= supω∈ALiky(ω)for A ⊆ Ω(5)(6)After learning that the true value of parameter is in a subset of the parameter space B ⊆ Ωsuch that Liky(B) > 0, one should condition the ELF by the following equation.Liky(A | B) def= Liky(A ∩ B)Liky(B)(7)This definition of likelihood conditioning is derived from Dempster’s rule of combinationapplied for a consonant belief function in plausibility form. It also conforms to the likeli-hood principle as the following example demonstrates.We use the convention Liky(∅) = 0. Some properties of Lik follow directly from itsdefinitions.Lemma 1.(i) Liky(Ω) = 1.(ii) Liky(A ∪ B) = max{Liky(A), Liky(B)}.(iii) max{Liky(A), Liky( ¯A)} = 1 where ¯A is the complement of A in Ω.(iv) If A ⊆ B then Liky(A) (cid:1) Liky(B).Example. A r.v. Y is known to have a normal distribution. It is also known that meanµ ∈ {0, 1} and standard deviation σ ∈ {1, 1.5}. Suppose that value y = 1.4 is observed. We3 Shafer [36] later renounces his idea on the ground that the set of CBFs is not closed under Dempster’s rule ofcombination, which is the standard rule to combine two distinct pieces of evidence. It implies that representationof compound evidence is not the same as the combination of individual evidences. However, later Walley [40]shows that Dempster’s rule is not compatible with the likelihood principle, and therefore is not suitable forcombining statistical evidence. He also shows that set of CBFs is closed under an alternative combination rule.With respect to conditioning Dempster’s rule and Walley’s alternative are identical.142P.H. Giang, P.P. Shenoy / Artificial Intelligence 165 (2005) 137–163Table 1Likelihood, extended likelihood and conditioninglik1.4(∗)Lik1.4(∗)Lik1.4(∗ | D)ω10.14970.40650.0000ω20.17210.46730.6704ω30.36831.00000.0000ω40.25670.69701.0000An.a.0.46730.6704Bn.a.11Cn.a.10Dn.a.0.69701.0000want to calculate the ELF representing uncertainty about unknown parameters. The un-known parameter θ = (µ, σ ). Ω = {ω1, ω2, ω3, ω4} with ω1 = (0, 1), ω2 = (0, 1.5), ω3 =(1, 1), ω4 = (1, 1.5). Let A denote event µ = 0, B denote µ = 1, C denote σ = 1 and Ddenote σ = 1.5. That means A = {ω1, ω2}, B = {ω3, ω4}, C = {ω1, ω3} and D = {ω2, ω4}.In the first row are densities at 1.4 of normal probability density function given a configu-ration of mean µ and standard deviation σ : f (1.4 | µ, σ ). For example, f (1.4 | µ = 0, σ =1) = 0.1497. Obviously, density is not defined for a set of configurations (A, B, C or D).Eq. (6) is used to calculate the second row.Suppose in addition to that, it becomes known that σ = 1.5. From a statistical point ofview, in the new situation mean µ is the unknown parameter of interest. The likelihoodsof µ = 0 and µ = 1 are 0.1721 and 0.2567 respectively. The likelihood ratio is 0.6704.In terms of extended likelihood, the new situation is coded by conditional Lik1.4(· | D).This yields Lik1.4(ω1 | D) = Lik1.4(ω3 | D) = Lik1.4(C | D) = 0 and Lik1.4(A | D) =Lik1.4(ω2)/Lik1.4(D) = 0.6704 and Lik1.4(B | D) = Lik1.4(ω4)/Lik1.4 = 1. The ratio ofextended likelihoods of µ = 0 and of µ = 1 is 0.6704. Keeping in mind that the likelihoodprinciple holds that the ratio of likelihoods is what matters, we see that our definition ofconditioning of extended likelihoods conforms to the standard practice in statistics.It is worth noting that while our derivation of the extended likelihood (CBF) is moti-vated by statistical considerations, the properties listed in Lemma 1 are also the definingproperties of a possibility measure [12,41]. What distinguishes a possibility function froma CBF is its fuzzy set semantics and, consequently, the notion of ordinal conditioning:(cid:5)π(A | B) =1π(A ∩ B)if π(A ∩ B) = π(A)otherwise(8)Technically, possibility theory can entertain both notions of conditioning: the ordinal(Eq. (8)) and the numerical one specified by Eq. (7). In this sense, extended likelihoodis a possibility measure equipped with numerical conditioning.4 It is not difficult to check(using the previous example) that if Lik was updated using ordinal conditioning then theresult would not be consistent with the likelihood principle.4 Dubois, Moral and Prade [11] show that a possibility measure is the result of taking supremum on a family oflikelihood functions. On that semantics, the min rule for combination of possibility measures is justified.P.H. Giang, P.P. Shenoy / Artificial Intelligence 165 (2005) 137–1631433. A decision theory with likelihood uncertaintyLet us formalize the decision problem we will study. We assume a decision situationdescribed by a tuple (Ω, X, A, y, π). Ω is the set of simple hypotheses (the parameterspace); X is the set of rewards measured in a utility currency; A is a set of actions of theform Ω → X; y is the data/observation/evidence and π is the ELF 2Ω → [0, 1] calculatedfrom y representing uncertainty on hypotheses.For actions in this setting, the states on which rewards are contracted are not observable.The utility nature of rewards implies that the risk attitude factor in decision making can beignored. Also, since utility can be transformed by a linear function, we can assume thatrewards are restricted to the unit interval [0, 1]. For the sake of clarity, we assume that Xis finite and its elements are denoted by x1, x2, . . . , xr .A simple likelihood lottery is an action coupled with a likelihood measure. Each lotteryis a mechanism that delivers rewards with associated likelihoods. Formally, a lottery Linduced by π and a is a mapping from X → [0, 1] such that L(x) = π(a−1(x)) for x ∈ Xwhere a−1 is a set-valued inverse mapping of action a. For the remainder of this paper,we denote a simple lottery by [L(x1)/x1, L(x2)/x2, . . .] with convention that those xj forwhich L(xj ) = 0 are omitted. In this notation, a consequence x ∈ X is identified with a1(cid:1)i(cid:1)m a−1(xi) = Ω. Since πunary lottery [1/x]. Notice that for any lottery [Li/xi]mis an ELF and Li = π(a−1(xi)), therefore, max1(cid:1)i(cid:1)m Li = 1.i=1,(cid:6)We also consider compound lotteries whose rewards are other lotteries. The set of lot-teries is denoted by L.3.1. AxiomsWe study preference relation (cid:9) on the set of lotteries L ((cid:9) ⊆ L2). Indifference ∼ andstrict preference (cid:11) relations are derived from (cid:9). L1 ∼ L2 iff L1 (cid:9) L2 & L2 (cid:9) L1. L1 (cid:11) L2iff L1 (cid:9) L2 & L2 (cid:7)(cid:9) L1. We postulate that (cid:9) satisfies five axioms similar to those proposedby von Neumann and Morgenstern for the classical linear utility theory (in the form pre-sented in [29]). They are as follows.A1 Order. (cid:9) is reflexive, transitive and complete.Since the consequences in X are special lotteries, (cid:9) is also the order on consequences.We can assume that x1 (cid:9) x2 (cid:9) · · · (cid:9) xr with x1 (cid:11) xr . In some cases to make clear weare dealing with the best and the worst consequences, special notations are used for x1and xr namely, x ≡ x1 and x ≡ xr . A lottery that involves only the best x and the worstconsequences x as potential outcomes is called a canonical lottery. The set of canonicallotteries is denoted by Lc.A2 Reduction of compound lotteries.Let L = [δ1/L1, δ2/L2, . . . , δk/Lk] and Li = [κi1/x1, κi2/x2, . . . , κir /xr ] then L ∼[κ1/x1, κ2/x2, . . . , κr /xr ] with κj = max1(cid:1)i(cid:1)k{δi.κij }.A3 Substitutability.If Li ∼ L(cid:13)i then [δ1/L1, . . . δi/Li . . . δk/Lk] ∼ [δ1/L1, . . . δi/L(cid:13)i . . . δk/Lk].144P.H. Giang, P.P. Shenoy / Artificial Intelligence 165 (2005) 137–163A4 Existence of equivalent canonical lottery.For each x ∈ X there is a s ∈ Lc such that x ∼ s.A5 Qualitative monotonicity.[λ/x, µ/x] (cid:9) [λ(cid:13)/x, µ(cid:13)/x]iff(λ (cid:2) λ(cid:13)) & (µ (cid:1) µ(cid:13))(9)Among the axioms, A1 and A3 are standard assumptions about a preference relation.A2 is an implication of the conditioning operation. Suppose that the unknown parameterθ is a vector. We can think, for example, θ = (γ , σ ). Let us consider a compound lotteryL = [δ1/L1, δ2/L2, . . . , δk/Lk] where Li = [κi1/x1, . . . , κir /xr ] for 1 (cid:1) i (cid:1) k. UnderlyingL, in fact, is a two-stage lottery. The first stage is associated with a scalar parameter γ . Itaccepts values γ1, γ2, . . . , γk with likelihoods δ1, δ2, . . . , δk respectively. If γi is the truevalue, the holder of L is rewarded with simple lottery Li that, in turn, is associated withscalar parameter σ that accepts σoi (1), σoi (2), . . . , σoi (r) with likelihoods κi1, κi2, . . . , κirwhere oi is a permutation of (1, 2, 3, . . . , r). When σoi (j ) obtains, the holder is rewardedwith consequence xj .Let us consider another one-stage lottery L(cid:13) that delivers xj in case tuple (cid:14)γiσoi (j )(cid:15) isthe true value of θ for 1 (cid:1) i (cid:1) k. Because of conditioning equation (7), we haveLik(γiσoi (j )) = Lik(γi)Lik(σ = σoi (j ) | γ = γi) = δi.κij(10)The set of tuples for which xj is delivered is {(cid:14)γiσoi (j )(cid:15) | 1 (cid:1) i (cid:1) k}. Thus, the extendedlikelihood associated with consequence xj in lottery L(cid:13)(cid:3){γiσoi (j ) | 1 (cid:1) i (cid:1) k}(cid:4)Lik= max{δi.κij | 1 (cid:1) i (cid:1) k}(11)Since L and L(cid:13) have the property that no matter what is the true value of θ , the conse-quences they deliver are always the same, we require L ∼ L(cid:13) which is axiom A2. Fig. 1shows an example where k = 2 and r = 2, o1(1) = 1, o1(2) = 2, o2(1) = 2 and o2(2) = 1.Axiom A4 requires that for any consequence x ∈ X there is a canonical lottery c =[λ1/x, λ2/x] such that x ∼ c. For clarity, let us assume that x = 1, x = 0 (the argumentremains valid for any real values of x and x as long as x > x). For any x ∈ X, we needto find a canonical lottery c equivalent to x. We will describe a likelihood gamble for thispurpose.There are three parties in this game: the Arbiter, the House and the Player. The goal ofthe game is to gauge binary utility function for the Player. The game plays as follows. TheArbiter preselects a single parameter probability distribution fθ . She also predeterminesFig. 1. Two-stage L and one-stage L(cid:13)are equivalent.P.H. Giang, P.P. Shenoy / Artificial Intelligence 165 (2005) 137–1631452 values {θ1, θ2} that she will use for the unknown parameter. Probability distribution fθas well as the possible values of the parameter are revealed to all parties. For example,a normal distribution5 with given standard devision σ = 1 can be used as fθ where θ isunknown mean and θ ∈ {−1, +1}.The Arbiter secretly picks a value θ in {θ1, θ2} then generates a value y from fθ . Themechanism used by the Arbiter to pick the value θ is unknown to both the Player andthe House. Both the Player and the House are told about the data y. The House offers agamble that pays x to the Player if the value actually used by the Arbiter to generate theobservation is θ1 and x if it is θ2. What is the highest price the Player would be willing topay for this gamble? If the answer is x, then for the Player,x ∼(cid:7)Liky(θ1)/x, Liky(θ2)/xwhere Liky(θ1) ∝ fθ1(y) and Liky(θ2) ∝ fθ2 (y).(cid:8)(12)One can repeat this gamble any number of times to get a table of correspondence be-tween xi and [Likyi (θ1)/x, Likyi (θ2)/x]. What we assume in A4 is that we can makethe table rich enough so that for any x ∈ X we can look up the table for an equivalent[Liky(θ1)/x, Liky(θ2)/x].Comparing the likelihood gamble with a probabilistic gamble6 used in practice to ex-tract decision maker’s (unary) utility, we see a number of important differences. First,instead of r.v. with a known distribution, e.g., tossing a fair coin or rolling a dice, a partiallyspecified probability model is used. Second, the rewards for the Player in the likelihoodgamble are contracted, not on observations (y) but on the unobservable true value of theparameter (θ ). In this sense, a likelihood gamble is a simple hypothesis testing problembecause the Player needs to decide which of two hypotheses θ = θ1 or θ = θ2 is true. Therelationship is made clear in Fig. 5.What kind of betting behavior should be expected from a rational decision maker? Cer-tain patterns should be excluded as irrational. In the example of a likelihood gamble thatuses a normal distribution with known s.d. σ = 1 and pays $1 if mean is −1 and 0 if itis 1, paying $0.20 for the gamble if y = −3 and paying $0.70 if y = 1 would be irrational.Intuitively, y = −3 lends more support to hypothesis θ = −1 than y = 1 does. Let us for-malize this intuition. We impose a mild constraint in the form of monotonicity axiom A5.Basically, we require that the price for lottery [λ/1, µ/0] is greater or equal to the pricefor [λ(cid:13)/1, µ(cid:13)/0] if the likelihood of getting 1 in the former is higher than that of the latter(λ (cid:2) λ(cid:13)) and likelihood of getting 0 in the former is less than that of the latter (µ (cid:1) µ(cid:13)).We justify A5 on the basis of first order stochastic dominance (FSD). Not being strictlyBayesian, we won’t assume to know the prior probability of P (θ = θ1), but we will assumethat such a prior exists. This situation can be modeled by viewing the prior of θ = θ1 as ar.v. ρ taking value in the unit interval. The distribution of ρ is unknown to us. We calculatethe posterior of θ = θ1 given y and ρ.Pρ(θ = θ1 | y) =ρ · Liky(θ1)ρ · Liky(θ1) + (1 − ρ) · Liky(θ2)(13)5 Any other distribution will work as fine.6 Suppose u($0) = 0 and u($1) = 1, and d the price a decision maker is willing to pay for a gamble that pays $1if a toss of a fair coin turns Head and $0 if it turns Tail, then u(d) = 0.5.146P.H. Giang, P.P. Shenoy / Artificial Intelligence 165 (2005) 137–163The expected payoff of the likelihood gamble(14)Vy(ρ) = Pρ(θ = θ1 | y) · x + Pρ(θ = θ2 | y) · x= x + Pρ(θ = θ1 | y) · (x − x)(15)With x − x > 0, Vy(ρ) is a strictly increasing function of Pρ(θ = θ1 | y). When x = 1and x = 0, Eq. (14) is further simplified to Vy(ρ) = Pρ(θ = θ1 | y). Being a function of ρ,Vy(ρ) is a r.v.The concept of stochastic dominance (SD) has been used extensively in economics,finance, statistics [28]. Suppose X and Y are two distinct r.v. with the cumulative distrib-utions F and G respectively. We say that X stochastically dominates (to the first degree)Y (written as XD1Y ) iff F (x) (cid:1) G(x) ∀x. Since X and Y are distinct, strict inequalitymust hold for at least one value x. FSD is important because of the following equiva-lence: X stochastically dominates (first order) Y iff the expected utility of X is greaterthan or equal to the expected utility of Y for all non-decreasing utility functions i.e.,XD1Y iff E(u(X)) (cid:2) E(u(Y )) ∀u ∈ U where U the class of non-decreasing utility func-tions and E(.) is the expectation operator.In the immediately following discussion, we will assume x = 1 and x = 0 for the sakeof clarity without any loss on generality.Lemma 2. For ρ ∈ (0, 1)Vy(ρ) > Vy(cid:13)(ρ)iff(cid:7)Liky(θ1)/1, Liky(θ2)/0(cid:8)(cid:11)(cid:7)Liky(cid:13) (θ1)/1, Liky(cid:13)(θ2)/0(cid:8)(16)Theorem 1. Suppose ρ is a r.v. taking values in the unit interval. Then Vy(ρ) stochasticallydominates (first degree) Vy(cid:13) (ρ) iff(cid:11)(cid:7)Liky(cid:13)(θ1)/1, Liky(cid:13) (θ2)/0(cid:7)Liky(θ1)/1, Liky(θ2)/0(cid:8)(cid:8)The order on canonical lotteries stipulated by axiom A5 is the order by first degreestochastic dominance of their expected payoffs if the prior is r.v. In Fig. 2, the lower curveis the graph for V0.60(ρ) (at Y = .6, the corresponding lottery is [.3011/1, 1/0]) and theupper curve is the graph for V0.26(ρ) ([.5945/1, 1/0]). This completes our justification forthe five axioms.Fig. 2. Payoff functions for y = .60 (lower) and y = .26 (upper).P.H. Giang, P.P. Shenoy / Artificial Intelligence 165 (2005) 137–1631473.2. Binary utilityWe will now proceed to study the preference relation satisfying the axioms. The follow-ing lemma shows that the set {L/ ∼} of equivalent classes of lotteries wrt the indifferencerelation ∼ is isomorphic to the set of canonical lotteries (Lc).Lemma 3. If the preference relation (cid:9) on the set of lotteries L satisfies axioms A1though A5, then for each lottery there exists one and only one canonical lottery indifferentto it.The significance of Lemma 3 is that it reduces a comparison of lotteries to one of canon-ical lotteries that have a simple structure and a straightforward interpretation. We want torepresent (cid:9) by a utility function so that a comparison of lotteries can be done throughthe calculation of their utilities. Our main idea here is to use as a utility scale a set that isisomorphic to the set of canonical lotteries. Let us define(cid:9)U def=(cid:14)a, b(cid:15) | a, b ∈ [0, 1] and max(a, b) = 1(cid:10)(17)In words, U is the set of pair of numbers in the unit interval such that one of them is 1.A linear order —(cid:18) on U (to distinguish from the order (cid:2) on scalars) is defined as(cid:14)a, b(cid:15)(cid:18) (cid:14)a—(cid:13)(cid:13)(cid:15), biffa = a(cid:13) = 1 & b (cid:1) b(cid:13), ora = 1 & a(cid:13) (cid:1) 1, ora (cid:2) a(cid:13) & b = b(cid:13) = 1(18)Strict preference ((cid:18)) and indifference (=) derivatives are also used. The special structureof U allows a simplification of order definition given in Eq. (18). The proof of the followinglemma is straightforward and is therefore omitted.Lemma 4. For (cid:14)a, b(cid:15), (cid:14)a(cid:13), b(cid:13)(cid:15) ∈ U(cid:13)(cid:14)a, b(cid:15) (cid:18) (cid:14)a(cid:18) (cid:14)a—(cid:13)(cid:14)a, b(cid:15)(cid:14)a, b(cid:15) = (cid:14)a, b(cid:13), b(cid:13)(cid:15), b(cid:13)(cid:15)(cid:13)(cid:15)iff(a > a(cid:13)iffiff(a (cid:2) a(cid:13)(a = a) ∨ (b < b(cid:13)) ∧ (b (cid:1) b(cid:13)) ∧ (b = b(cid:13))(cid:13)))(19)(20)(21)We refer to U equipped with order —(cid:18) as the binary utility scale. Roughly, we can inter-pret two components in a utility value as indices of goodness (first) and badness (second).One binary utility value is better than another if the goodness index of the former is higherthan that of the latter or the badness index of the former is smaller than badness index ofthe latter. Note that this binary utility is a special case of the lexicographic utility [16].Lemma 4 shows that two indices have symmetrical roles, no one has precedence over theother. One index is used as tie breaking in case equality holds for the other index.148P.H. Giang, P.P. Shenoy / Artificial Intelligence 165 (2005) 137–163Fig. 3. Binary utility scale U .To operate on binary utilities, we extend7 product and max operations to work withpairs as follows. For scalar α, β, π and γα.(cid:14)β, γ (cid:15) def= (cid:14)α.β, α.γ (cid:15)(cid:4)(cid:3)def=(cid:14)α, β(cid:15), (cid:14)γ , π(cid:15)max(cid:14)(cid:15)max(α, γ ), max(β, π)(22)(23)We have some properties of the extended max operation. The proof is straightforwardand is therefore omitted.Lemma 5. (i) U is closed under max, i.e., u, u(cid:13) ∈ U then max(u, u(cid:13)) ∈ U . (ii) max ismonotone on each argument, for example, max(u, v) —(cid:18) max(u, v(cid:13)) if v (cid:2) v(cid:13).3.3. Representation theoremA utility function is a mapping from the set of lotteries into the utility scale U : L → U .We say that a preference relation (cid:9) is represented by a utility function U whenever L (cid:9) L(cid:13)(cid:18) U (L(cid:13)). For a function f defined on set X, we let f (X) denote {f (x) | x ∈ X}.iff U (L) —We have the following theorem.Theorem 2. (cid:9) on L satisfies axioms A1 through A5 if and only if there exists a utilityfunction QU : L → U representing (cid:9) such that (cid:14)1, 0(cid:15), (cid:14)0, 1(cid:15) ∈ QU(X) and(cid:3)(cid:4)[π1/L1, . . . , πk/Lk]QU(cid:9)(cid:10)πi.QU(Li)= max1(cid:1)i(cid:1)kWhile proposing axioms A1 through A5, we argue the rationale for each axiom sep-arately, but not the consistency of the axiom system as a whole. The fact that the axiomsystem is represented by a well defined utility function proves that it is free from inconsis-tency. In particular, when L is a simple lottery, Eq. (24) can be rewritten as(cid:3)(cid:4)[π1/x1, . . . , πr /xr ]QU(cid:9)(cid:10)πi.QU(xi)= max1(cid:1)i(cid:1)r(24)(25)7 We have decided in favor of “overloading” operations product and max instead of creating new symbols.Hopefully, this slight abuse of notation does not lead to any confusion because the type of arguments will indicatewhich rule to apply.P.H. Giang, P.P. Shenoy / Artificial Intelligence 165 (2005) 137–163149Fig. 4. Qualitative utility calculation.The form of QU in (25) resembles the vNM expected utility expression. The expectedutility of a probabilistic lottery p on X is defined as U (p) def=1(cid:1)i(cid:1)r p(xi).U (xi).Maximization in (25) plays the same role as its counterpart—addition—in the vNMexpected utility. This similarity leads us to refer to QU also as expected qualitative utilityfunction.(cid:16)Fig. 4 illustrates QU calculation for a two-stage lottery. Assuming QU(x1) = (cid:14)1, 0(cid:15),QU(x2) = (cid:14)1, .8(cid:15) and QU(x3) = (cid:14)0, 1(cid:15), a roll-back calculation shows that(cid:3)(cid:7)(cid:8)(cid:4)QU1/[.4/x1, .7/x2, 1/x3], .5/[1/x1, .2/x3]= (cid:14).7, 1(cid:15)Although qualitative and vNM utilities share fundamental structure, it is important toemphasize that the qualitative utility is not just a simple translation of vNM utility in a newlanguage. Not all properties of vNM utility hold for the qualitative version. Notably, thequalitative utility only satisfies weaker versions of independence and Archimedian proper-ties [25].Theorem 3. (a) Suppose L1, L2, L3 ∈ L, λ, µ ∈ [0, 1] and max(λ, µ) = 1. If L1 (cid:9) L2,then [λ/L1, µ/L3] (cid:9) [λ/L2, µ/L3].(b) Suppose L1, L2, L3 ∈ L such that L1 (cid:11) L2 (cid:11) L3. Then there exists λ, µ, λ(cid:13), µ(cid:13) ∈[0, 1], max(λ, µ) = max(λ(cid:13), µ(cid:13)) = 1 and (cid:14)λ, µ(cid:15), (cid:14)λ(cid:13), µ(cid:13)(cid:15) /∈ {(cid:14)0, 1(cid:15), (cid:14)1, 0(cid:15)} such that [λ/L1,µ/L3] (cid:11) L2 and L2 (cid:11) [λ(cid:13)/L1, µ(cid:13)/L3].Note that property (a) does not hold for strict preference. That is, in general, we don’thave [λ/L1, µ/L3] (cid:11) [λ/L2, µ/L3] if L1 (cid:11) L2.3.4. Related workIn the AI literature, a number of decision models that do not assume probability havebeen studied [7,24,37]. Brafman and Tennenholtz [7] characterize qualitative decisionrules: maximin, minimax regret and competitive ratios and maximax. They show that thesedifferent decision criteria are equivalent in terms of representation power. These purelyqualitative rules ignore the uncertainty relevant to choice problem. Smets [37] proposesa two-level decision model for Dempster–Shafer belief functions. At the credal level, anagent uses belief functions to represent and reason with uncertainty. When she needs tomake decision she will translate a belief function into probability using pignistic trans-formation. Basically, this transformation allocates the probability mass that assigned to a150P.H. Giang, P.P. Shenoy / Artificial Intelligence 165 (2005) 137–163focus equally to each of its element. Smets’ model is not able to handle ambiguity attitudes.For example, when applied for Ellsberg’s paradox [15], this model produces an unintuitivesolution. Halpern [24] studies a very general uncertainty measure called the plausibilitymeasure. To make decisions, he defines an operation that maps the product of consequencedomain and plausibility domain into a valuation domain. The order on valuation domainis defined by a decision rule. In [20], we also study a decision making model for Spohn’stheory of epistemic beliefs. This uncertainty measure is closely related to extended like-lihood, and can be interpreted as order-of-magnitude approximation of probabilities or asdegrees of plain beliefs.More relevant to this work is an approach to decision making with possibility the-ory proposed by Dubois et al. [10,13]. As noted earlier, a possibility function satisfiesEqs. (5), (6) that define an ELF. The main difference is about the conditioning operation.Dubois et al. use the ordinal conditioning defined by Eq. (8). The likelihood conditioning(or the numerical conditioning) is defined in Eq. (7). They distinguish two decision crite-ria: pessimistic and optimistic. For each decision criterion, there is an axiom system anda qualitative utility functional representing preference relation that satisfies the axioms.A detailed comparative analysis between our approach vs the approach argued by Duboiset al. is presented in [22]. We show that our approach, modified for ordinal conditioning,generalizes and unifies pessimistic and optimistic decision criteria.In our framework, a decision maker’s attitude toward ambiguity shows itself in herbasic utility assignment for consequences in X. Recall that the indifference between aconsequence and a (binary) utility value is determined through a likelihood gamble. Wewill see that her betting behavior encodes an interesting information, namely, her attitudetoward ambiguity.Suppose that our decision maker equates payoff x with canonical lottery [λ/1, µ/0].From the Bayesian decision theory point of view, this indifference means that the expectedpayoff Vy(ρ) (with respect to prior ρ) of the likelihood gamble is equal to x. Substitute xfor Vy(ρ) and λ, µ for Liky(θ1), Liky(θ2) into Eq. (13) and solve for ρ we findρ =xµ(1 − x)λ + xµFrom Eq. (26) we havelogit(ρ) = logit(x) − ln(λ/µ)(26)(27)where logit(z) def= ln(z/(1 − z)). We call ρ calculated by Eq. (27) an implicit prior8 for theobvious reason. When λ = µ = 1 we have ρ = x. Therefore, ρ can be interpreted as theprice the decision maker pays for a “fair” likelihood lottery [1/1, 1/0].Recall that in the context of a likelihood gamble, ρ is the probability, in Player’s judg-ment, that the Arbiter selects θ1 (on which x is contracted) as the parameter value to gen-erate the given observation. Thus inequality ρ < 0.5 can be interpreted as that the Playera priori deems the bad outcome is more likely than the good one. English language has a8 It is necessary to note that the implicit prior value is unique for a single bet. A betting behavior that impliesdifferent implicit priors for different likelihood gambles can still be consistent with A5. For more details on therange of permissible priors, readers are referred to [19].P.H. Giang, P.P. Shenoy / Artificial Intelligence 165 (2005) 137–163151$risk attitudeprobabilitygamble(cid:1)xambiguity attitude(cid:1)(cid:14)λ, µ(cid:15)likelihoodgambleFig. 5. Risk and ambiguity in transformation from money to binary utility.specific name for the mental attitude that tends to emphasize adverse aspects—pessimism.Similarly, the opposite ρ > 0.5 can be argued as a manifestation of optimism. This defin-ition of pessimism (optimism) is very different than the notion of pessimism (optimism)9put forward by Dubois et al. [10] where it is a property of an axiom system attributed to adecision maker. In this paper, however, pessimism (optimism) is a property attributed to abasic utility assignment by a decision maker.Another sensible terminology can be used for pessimism and optimism. A bettingbehavior is said to exhibit ambiguity averse (ρ < 0.5), ambiguity neutral (ρ = 0.5) or am-biguity seeking (ρ > 0.5) attitudes. It is useful to analyze similarity as well as distinctionbetween the notion of ambiguity attitude and the established notion of risk attitude. Thelatter is a property of a utility function (money-to-utility conversion). Risk averse, riskneutral and risk seeking attitudes correspond to concavity, linearity and convexity of utilityfunctions. In this paper, we do not explicitly consider the risk attitude issue because of theassumption that X measured in a utility currency. Fig. 5 illustrates the roles of risk andambiguity attitudes in the transformation of monetary reward to a binary utility via unaryutility.In Economics and Statistics literature, a prominent axiomatic decision theory withoutadditive probability has been studied by Schmeidler [33] and extended by Gilboa [23] andSarin and Wakker [32]. The concept of co-monotonicity has a crucial role in Schmeidler’ssystem. Two acts f and g are co-monotonic if for no two states s1, s2 f (s1) (cid:11) f (s2) andg(s2) (cid:11) g(s1). The independence property is required to hold only for set of co-monotonicacts. The preference relation that satisfies Schmeidler’s axioms is represented by a Choquetexpected utility function (CEU). A real-valued function v : 2Ω → [0, 1] is called capacityfunction if v(∅) = 0, v(Ω) = 1 and for A ⊆ B ⊆ Ω v(A) (cid:1) v(B). CEUv(f ) is defined asfollows. For simplicity, we assume that X is a set of reals, interpreted as utilities, and isdef= {s ∈ Ω | f (s) (cid:2) xk}—set of states whereordered x0 > x1 > · · · > xm. For an act f , Afkf delivers xk or better consequence. Obviously Af⊆ · · · ⊆Afi are nested, i.e., Af⊆ Af10m = ΩCEUv(f ) def= x0v(Af0 ) +k(cid:1)i=1xi(cid:3)v(Afi ) − v(Af(cid:4)i−1)(28)The main difference between Schmeidler’s approach and our approach is in the role of aconditioning operation for uncertainty measure. CEU representation is the result of con-sidering (i) separation of “utility” from “probability” and (ii) “functional representations9 The definition of pessimism (optimism) by Dubois et al. requires that possibilistic lottery π is preferred to(less preferred than) lottery π (cid:13)is greater or equal to thepossibility of getting that consequence in π , i.e., π (cid:9)pes π (cid:13)if the possibility of getting any consequence in π (cid:13)(π (cid:13) (cid:9)opt π ) if π (cid:13) (cid:2) π .152P.H. Giang, P.P. Shenoy / Artificial Intelligence 165 (2005) 137–163which are the sum of products of two numbers; one number has a “probability” interpre-tation and the other has a “utility” interpretation” [33, p. 584]. The updating operation isnot explicitly considered for capacity function. In contrast, our approach starts with anuncertainty calculus with its properly defined updating rules and then develops a decisiontheory where utility is derived from “probability”. In this sense, although an ELF satisfiesrequirements for a capacity measure, it is not a special case of capacity because it has awell defined conditioning operation.To see the difference between CEU and QU, let us calculate CEU for a canonical= A andact with respect to ELF π . Suppose for simplicity x = 1 and x = −1. Since Aa0Aa1= Ω, by Eq. (28)(cid:4)(cid:3)[A/x, A/x]CEUπ= π(A) −(cid:4)(cid:3)1 − π(A)= 2π(A) − 1First we observe that CEU for a canonical act does not depend on the capacity of eventleading to the worst consequence. v(A) (cid:7)= 1 − v(A) because a capacity measure is non-additive. In contrast, A5 requires a comparison of likelihoods of getting worst consequencewhen the likelihoods of getting the best consequence are equal. This observation seems tosuggest that CEU is not appropriate for existing (non-probabilistic) uncertainty calculisuch as Dempster–Shafer belief functions [35], fuzzy possibility [41] and plausibility mea-sures [24] that have well-defined updating rules.The lack of an updating rule for capacity subjects CEU to the following criticism. Sup-pose v is a capacity measure, one can define its dual by v(cid:13)(A) def= 1 − v(A) ∀A ⊆ Ω. It isnot difficult to see that v(cid:13) is also a capacity measure. It is arguable that v and v(cid:13) containthe same information because v is recoverable from v(cid:13). Despite visible symmetry betweenv and v(cid:13), rankings of acts by CEUv and by CEUv(cid:13) are different. In this sense, CEU is notsensitive to information. Such criticism is void for uncertainty calculi with well defined up-dating rules. The dual of a probability measure is itself. The dual of a possibility measure isa necessity measure but their updating rules are different. The same is also true for the dualpair of belief and plausibility functions in Dempster–Shafer theory. Thus, the measures arenot symmetric despite being duals of each other.4. Likelihood solution to statistical inference4.1. Decision-theoretic approach to statistical inferenceWe will review the decision-theoretic approach to statistical inference. We assume asgiven the set of alternative actions denoted by A, and the sample space of Y by Y. A lossV (a, θ ) measures the loss that arises if we take action a and the true value of the parameteris θ .10 A decision rule is a mapping δ : Y → A, that is for observation y the rule recom-10 In terms of the decision problem definition (Section 3), any superset of V (A, Ω), the set of possible lossvalues, could be the set of consequences X.P.H. Giang, P.P. Shenoy / Artificial Intelligence 165 (2005) 137–163153mends an action δ(y). The risk function of a decision rule δ at parameter value θ is definedas(cid:3)δ(Y ), θ(cid:4)Rdef= Eθ V(cid:3)δ(Y ), θ(cid:4)=(cid:3)δ(y), θ(cid:4)Vpθ (y)(29)(cid:17)YThe risk function measures the average loss by adopting the rule δ in case θ is the truevalue.The further use of risk functions depends on how much information we assume is avail-able. For each point in the parameter space, there is a value of the risk function. In case noa priori information about parameter exists, Wald [39] advocated the use of minimax rulewhich minimizes the worst risk that could be attained by a rule.∗δminimax= arg minδ∈∆maxθ∈ΩR(δ, θ )(30)where ∆ is the set of decision rules. δ∗ is called the minimax solution.If we assume, as the Bayesian school does, the existence of a prior distribution for theparameter, then the risk could be averaged out to one number called Bayes risk(cid:17)r(δ) = EρR(δ, θ ) =R(δ, θ )ρ(θ )Ω(31)where ρ is prior distribution for θ . Then the optimal rule is one that minimizes the Bayesrisk which is called the Bayes solution.= arg minδ∈∆∗Bayes,ρr(δ)(32)δWald [39] pointed out there exists a prior distribution ρ∗ called “the least favorable” forwhich the Bayes solution is the minimax solution. The term “Bayes” is justified by thefact that the solution is also obtained via a more intuitive route using Bayes theorem andthe principle of minimizing expected loss. Given prior probability distribution ρ on Ω, foreach data y ∈ Y a posterior probability on Ω is obtained via Bayes theoremp(θ | y) ∝ pθ (y)ρ(θ )Denote by ap(y) the action that minimizes the expected loss given data y(cid:17)ap(y) = arg mina∈AV (a, θ )p(θ | y)(33)(34)ΩLet us define a rule δ∗minimizes the expected loss.P (y) (cid:21)→ ap(y), i.e., for each data y, rule δ∗P delivers the action thatLemma 6. δ∗P is a Bayes solution, i.e., r(δ∗P ) = r(δ∗Bayes,ρ).4.2. Likelihood solutionWithout knowing prior ρ, we propose the following solution based on the logic thatP . Each y ∈ Y is associated with an ELF Liky . An action together with an ELFleads to δ∗154P.H. Giang, P.P. Shenoy / Artificial Intelligence 165 (2005) 137–163induce a likelihood lottery. Denote by La(y) the lottery generated from action a and obser-vation y. Likelihood lotteries are compared by QU. The optimal action given observationy isaLik(y) = arg supa∈AQU(cid:4)(cid:3)La(y)(35)(cid:18) .where sup11 is the operation taking maximum element according to the binary order —We define a decision rule δ∗Lik(y) (cid:21)→ aLik(y) which assigns for each point in the samplespace an action that maximizes the (qualitative) utility. We call such decision rule a likeli-hood solution.minimax, δ∗Bayes and δ∗There are two dimensions in which solutions δ∗Lik can be compared.The first concerns information. One can differentiate two kinds of information relevant tothe statistical inference problem: the extra-experiment information embodied by a priorprobability and the experimental information embodied by a likelihood function. TheBayesian approach requires both kinds and utilizes them to arrive at the solution. In Wald’sproposal, the risk function has no special role for the actually observed data and the priorprobability is not considered. Thus both kinds of information are ignored. The likelihoodsolution does not assume knowing the prior, but it does make use of likelihood informationprovided by data in identifying the best action.The concept of stochastic dominance provides another dimension for comparing thethree solutions. Apart from FSD, stochastic dominance of second and higher degree aredefined. For simplicity, following [6], assume r.v. are non-negative, i.e., cumulative distri-bution functions satisfy F (0) = 0. For cumulative distribution function F , define for anynatural nFn(z) =z(cid:17)0Fn−1(x) dx(36)with notation F1 = F . Suppose X, Y are two r.v. (we use the same symbols for their cumu-lative distribution function), we say X is preferred to Y according to n-degree stochasticdominance (write XnSDY ) if Xn(z) (cid:1) Yn(z) for z (cid:2) 0. It is well known that (i) n-degreedominance implies all higher degree dominance and (ii) higher the degree, the greater rel-ative importance is assigned to small value of r.v. Borch [6] shows that Wald’s minimaxrule is equivalent to stochastic dominance of infinite degree. The order satisfying vNMaxioms can be viewed as “zero degree” stochastic dominance because it boils down to thecomparison of numbers—expected utility values—that are, of course, singular r.v. Thus,we can arrange Bayes, likelihood and minimax solutions in an increasing order accordingto their SD degrees.4.3. An illustrative exampleThe following example is adapted from [3]. The manufacturer of small travel clockswhich are sold through a chain of department stores agrees to service any clock once only11 In contrast to max defined in Eq. (23) that operates on scalars (cid:2).P.H. Giang, P.P. Shenoy / Artificial Intelligence 165 (2005) 137–163155if it fails to operate satisfactorily in the first year of purchase. For any clock, a decisionmust be made on whether to merely clean it or replace the works, i.e., the set of actionsA = {a1, a2} where a1 denotes “clean the clock then replace the work if needed”, and a2denotes “immediately replace the works”.Let us assume that there are only two possible faults, i.e., Ω = {θ1, θ2} where θ1 meansthere is the need for cleaning and θ2 means the clock has been physically damaged and theworks need replacement. Utility and loss functions are given in the following table. Therelationship between utility (u) and loss (V ) is through equation V = 1 − u.u(a, θ)a1a2θ1.8.5θ2.3.5V (a, θ)a1a2θ1.2.5θ2.7.5The loss table is roughly estimated from the fact that cleaning a clock costs $0.20 and re-placing the works costs $0.50. If the policy is to replace the works for every clock needingservice then the cost is $0.50 no matter which problem is present. If the policy is to cleana clock first, if the state is θ1 then the service costs $0.20, however in the case of physicaldamage then cleaning alone obviously does not fix the problem and the manufacturer endsup replacing the works also. Thus the total cost is $0.70.The manufacturer can ask the customer to provide a symptom of malfunction when aclock is sent to the service center. Assume the sample space Y = {y1, y2, y3} where y1means “the clock has stopped operating”, y2—“the clock is erratic in timekeeping” andy3—“clock can only run for a limited period”. Such information gives some indicationabout θ that is expressed in terms of likelihoodliky (θ) or pθ (y)θ1θ2y1.1.7y2.4.2y3.5.1For each point in the sample space, you can either choose a1 or a2, so there are 8 possibledecision rules in total. Each decision rule specifies an action given an observation.δj (yi )y1y2y3δ1a1a1a1δ2a1a1a2δ3a1a2a1δ4a1a2a2δ5a2a1a1δ6a2a1a2δ7a2a2a1δ8a2a2a2We calculate the risk function values for each rule and parameter value in the followingtableRijθ1θ2δ1.2.7δ2.35.68δ3.32.66δ4.47.64δ5.23.56δ6.38.54δ7.35.52δ8.50.50Notice that there is no rule which is superior to all other for both values of θ . Wald’sminimax solution is δ8. If we assume prior distribution of θ then we can calculate the Bayesrisks for the rules. For example if prior probability p(θ1) = .7, then Bayes risks r.7(δi) are156P.H. Giang, P.P. Shenoy / Artificial Intelligence 165 (2005) 137–163δ1.35δ2.449δ3.442δ4.541δ5.329δ6.428δ7.401δ8.50Thus, δ5 is the Bayes solution. The following sensitivity analysis shows how Bayes solu-tions depend on prior p(θ1)Bayes solution Whenδ8δ7δ5δ1p(θ1) (cid:1) .118.118 (cid:1) p(θ1) (cid:1) .250.250 (cid:1) p(θ1) (cid:1) .824.824 (cid:1) p(θ1)In our approach, suppose unary utility is translated into binary utility according to thefollowing table. The table is obtained assuming ambiguity neutrality. For example, to finda binary utility equivalent to 0.8, plugging x = 0.8 and implicit prior ρ = 0.5 into Eq. (27)we have logit(0.8) = ln(λ/µ) + logit(0.5). Therefore, λ/µ = 4. Since max(λ, µ) = 1 wehave λ = 1 and µ = .25. Thus 0.8 ∼ (cid:14)1, 0.25(cid:15).Unary utility.8.5.3Binary utility(cid:14)1, .25(cid:15)(cid:14)1, 1(cid:15)(cid:14).43, 1(cid:15)Given y1, the ELF is Liky1(θ1) = .14 and Liky1 (θ2) = 1. Action a1 corresponds to lotteryLa1(y1) = [.14/(cid:14)1, .25(cid:15), 1/(cid:14).43, 1(cid:15)](cid:4)(cid:3)La1(y1)QU(cid:9)= max(cid:9)= max(cid:10).14(cid:14)1, .25(cid:15), 1(cid:14).43, 1(cid:15)(cid:10)(cid:14).14, .035(cid:15), (cid:14).43, 1(cid:15)= (cid:14).43, 1(cid:15)Action a2 is associated with lottery La2(y1) = [.14/(cid:14)1, 1(cid:15), 1/(cid:14)1, 1(cid:15)] and QU(La2 (y1)) =(cid:14)1, 1(cid:15). Thus, a2 (cid:11)y1 a1. Given y2, Liky2 (θ1) = 1 and Liky2 (θ2) = .5. So, QU(La1 (y2)) =(cid:14)1, .5(cid:15) and QU(La2 (y2)) = (cid:14)1, 1(cid:15). Thus, a1 (cid:11)y2 a2. Given y3, Liky2 (θ1) = 1 andLiky2(θ2) = .2. QU(La1 (y3)) = (cid:14)1, .25(cid:15) and QU(La2 (y3)) = (cid:14)1, 1(cid:15). Thus, a1 (cid:11)y3 a2. Insummary, the likelihood solution is δ5.It is also interesting to know how likelihood solutions depend on the ambiguity attitude.It can be shownLikelihood solutionδ7δ5Implicit priorρ (cid:1) 0.33330.3334 (cid:1) ρLet us make few informal comments. Depending on ambiguity attitude, the likelihoodsolution can be δ7 or δ5 while the minimax solution is δ8. As we noted, the latter ignoresthe uncertainty generated by an observation while the former does not.If the prior probability is a value in interval [0.250, 0.824], then the Bayes solution isδ5 the same as the likelihood solution when the ambiguity attitude ρ is in [0.3334, 1]. IfP.H. Giang, P.P. Shenoy / Artificial Intelligence 165 (2005) 137–163157prior probability is known, one can argue that Bayes solution is the optimal one. However,the “optimality” of the Bayes solution does not come without cost. The prior probabilityrequirement can be satisfied either at some monetary cost (doing research, or buying fromthose who have) that should have been deducted from the benefit of having the optimal ac-tion. Alternatively, the decision maker can just assume some prior distribution in an ad hocmanner. This, however, would compromise the claimed optimality. One can extend theconcept of Bayes solution by including a sensitivity analysis. This certainly helps decisionmaker by providing a frame of reference. But sensitivity analysis itself does not constituteany basis for knowing the prior probability. Moreover, when the parameter space is large,a multiple way sensitivity analysis may be very difficult.The behavior comparison of the likelihood solution and the Bayes solution when ρand p(θ1) vary is more interesting. When p(θ1) increases from 0 to 1, the Bayes solu-tion moves from δ8 to δ7 to δ5 and to δ1. When ρ increases from 0 to 1, the likelihoodsolution moves from δ7 to δ5. Thus, the likelihood solutions do not include δ8, δ1 that cor-respond to Bayes solutions at extreme values of prior p(θ1). In particular, δ7 chooses a1and δ8 chooses a2 at y3. δ1 chooses a1 and δ5 chooses a2 at y1. There are two factors thatameliorate this discrepancy. First, extreme values of p(θ1) are far from non-informativepriors which can be expected in a situation of no prior information. In other words, byselecting p(θ1) close to 0 or 1, the decision maker has some (or is willing to assume)significant a priori information that would make the comparison with likelihood solutionvoid. Second, at extreme values of implicit prior ρ, the utilities of a1 and a2 (at any ob-servation) are very close. For example, if ρ = 0.1 then QU(La1 (y3)) = (cid:14)1, 0.052(cid:15) andQU(La2 (y3)) = (cid:14)1, 0.111(cid:15). At non-extreme cases the likelihood solution and the Bayessolution basically agree. Decision rules δ7, δ5 are selected in both approaches for largesegments of values p(θ1) and ρ.This pattern is comforting but one should be careful not to draw too much from it.Specifically, one should not use this agreement as a justification for the likelihood solution.As we pointed out, axioms A1 to A5 on which likelihood solution is based, are structurallysimilar to those used by Luce and Raiffa [29] to justify the expected utility maximizationprinciple which ultimately is the basis for Bayes solutions. Thus, at a foundational level,optimality of likelihood solution could be justified in the same way as the optimality forBayes solution although the two optimality concepts are obviously different. It can beargued that the question of which optimality is more appropriate depends on how muchinformation is available.Although p(θ1) and ρ have similar roles on the behavior of solutions, they havevery different semantics. p(θ1) is a specification of prior probability on the parameterspace. Therefore, it gauges the a priori information (empirical or assumed) about pa-rameters. In practice, when this space has many elements, the specification would bemuch more difficult and sensitivity analysis becomes more complex. ρ, on the otherhand, gauges the attitude toward ambiguity of a decision maker. It is determined, in-dependently to the parameter space, on simple situations of two hypotheses and fixedrewards.158P.H. Giang, P.P. Shenoy / Artificial Intelligence 165 (2005) 137–1635. Summary and conclusionIn this paper, we develop a decision theory that directly utilizes likelihood informationwithout assuming the knowledge of prior probability. We extend likelihood functions asthe uncertainty measure pertaining to a statistical inference problem. This extension, con-forming to the maximum likelihood methods, defines the likelihood for a set of parametervalues to be the maximum likelihood over elements of the set.Our approach is axiomatic. The axioms considered are similar in spirit to those of thelinear utility theory, but strictly different in several important aspects. We describe a bet-ting behavior based on likelihood rather than on probability. This behavior satisfies thestochastic dominance principle. We prove a representation theorem for preference relationover likelihood lotteries using a newly developed concept of binary utility.Applied to the statistical inference problem, our theory suggests a new solution thatpicks an action by maximizing expected qualitative utility. This solution is sandwichedbetween Wald’s minimax solution and the Bayes solution in terms of information use anddemand. It makes use of uncertainty information that is ignored by the minimax solutionbut does not require a prior probability as the Bayes solution does.Appendix A. Proofs of lemmas and theoremsProof of Lemma 2. By Eq. (15), Vy(ρ) > Vy(cid:13) (ρ) iff Pρ(θ = θ1 | y) > Pρ(θ = θ1 | y(cid:13)). ByEq. (13), Pρ(θ = θ1 | y) > Pρ(θ = θ1 | y(cid:13)) iffLiky(θ1)Liky(θ2)>Liky(cid:13)(θ1)Liky(cid:13)(θ2)(A.1)Because max(Liky(θ1), Liky(θ2)) = max(Liky(cid:13)(θ1), Liky(cid:13)(θ2)) = 1, there are 4 cases toconsider. Eq. (A.1) excludes the case where Liky(θ2) = Liky(cid:13)(θ1) = 1. For 3 remainingcases, we have (a) If Liky(θ1) = Liky(cid:13)(θ1) = 1, Eq. (A.1) holds iff Liky(θ2) < Liky(cid:13)(θ2);(b) If Liky(θ2) = Liky(cid:13) (θ2) = 1, Eq. (A.1) holds iff Liky(θ1) > Liky(cid:13) (θ1); (c) If Liky(θ1) =Liky(cid:13)(θ2) = 1, Eq. (A.1) holds iff either Liky(θ2) < 1 or Liky(cid:13) (θ1) < 1. By Eq. (9), we haveEq. (A.1) holds iff [Liky(θ1)/1, Liky(θ2)/0] (cid:11) [Liky(cid:13)(θ1)/1, Liky(cid:13) (θ2)/0]. (cid:1)Proof of Theorem 1. (⇒) For any v ∈ (0, 1), let us denote the roots of equationsVy(ρ) = v and Vy(cid:13) (ρ) = v by ρv and ρ(cid:13)v) = v. If[Liky(θ1)/1, Liky(θ2)/0] (cid:11) [Liky(cid:13) (θ1)/1, Liky(cid:13)(θ2)/0] then by Eq. (16) Vy(ρv) > Vy(cid:13)(ρv).Therefore, Vy(cid:13)(ρ(cid:13)v) > Vy(cid:13) (ρv). Because Vy(cid:13) (ρ) is strictly increasing, we infer ρv < ρ(cid:13)v.Since Vy(ρ) and Vy(cid:13) (ρ) are increasing, P (Vy(ρ) (cid:1) v) = P (ρ (cid:1) ρv) and P (Vy(cid:13) (ρ) (cid:1) v) =P (ρ (cid:1) ρ(cid:13)v, P (Vy(ρ) (cid:1) v) (cid:1) P (Vy(cid:13) (ρ) (cid:1) v). This last inequality meansVy(ρ) D1 Vy(cid:13) (ρ).v respectively, i.e., Vy(ρv) = v and Vy(cid:13)(ρ(cid:13)v). Because ρv < ρ(cid:13)(⇐) If for all 0 < x < 1, Vy(x) (cid:1) Vy(cid:13) (x), then assumption Vy(ρ)D1Vy(cid:13)(ρ) is violated.Otherwise, Eq. (16) implies that(cid:8)(cid:7)Liky(θ1)/1, Liky(θ2)/0(cid:11)(cid:7)Liky(cid:13)(θ1)/1, Liky(cid:13) (θ2)/0(cid:8)(cid:1)P.H. Giang, P.P. Shenoy / Artificial Intelligence 165 (2005) 137–163159Proof of Lemma 3. We prove the existence of indifferent canonical lottery by inductionon the depth of lottery trees. For a constant lottery (of depth 0), because of A4, each con-sequence xi is indifferent to a canonical lottery si . Let assume xi ∼ si = [κi1/x, κir /x] for1 (cid:1) i (cid:1) r.A lottery of depth 1 is a simple lottery. If it is a canonical lottery, by reflexivity, a canon-ical lottery is indifferent to itself. For a simple lottery L = [π1/x1, π2/x2, . . . , πr /xr ],by A3, L ∼ L1 where L1 = [π1/s1, π2/s2, . . . , πr /sr ]. L1 can be reduced to a canon-ical lottery L2 such that L1 ∼ L2 as follows. Let us write a canonical lottery siinthe form [κi1/x, κi2/x2, . . . , κir /x] with κij = 0 for 2 (cid:1) j (cid:1) r − 1. By A2, L1 ∼ L2where L2 = [κ1/x, κ2/x2, . . . , κr /x] with κj = max{πi.κij | 1 (cid:1) i (cid:1) k}. Since κij = 0 for2 (cid:1) j (cid:1) r − 1, we have κj = 0 for 2 (cid:1) j (cid:1) r − 1. Thus, L2 is a canonical lottery. Bytransitivity, L ∼ L2.Suppose for any lottery of depth not greater than n, there is a canonical lottery in-different to it. For a lottery L of depth n + 1. This lottery is a compound lottery whoseconsequences are lotteries of depth not greater than n. Because of induction hypothesis,each consequence of L is indifferent to a canonical lottery. By substitutability, L is indif-ferent to a compound lottery of depth 2 which, in turn, is indifferent to a canonical lotteryby induction hypothesis. By transitivity, L is indifferent to some canonical lottery.Finally, we have to show that there is only one canonical lottery indifferent to a givenlottery. Suppose there are two canonical lotteries s1, s2 ∈ Lc such that s1 ∼ L and s2 ∼ L.By A1, we have s1 ∼ s2. But by A5, this is possible only if s1 = s2. (cid:1)Proof of Theorem 2. (⇒) Suppose (cid:9) satisfies the axioms. We will show that thereexists a function QU : L → U that satisfies Eq. (24) and represents (cid:9). We construct func-tion QU as follows. For a canonical lottery, define QU([λ/x, µ/x]) = (cid:14)λ, µ(cid:15). Obviously,(cid:14)1, 0(cid:15), (cid:14)0, 1(cid:15) ∈ QU(X). For any lottery L, by Lemma 3, there exists a unique canonicals such that L ∼ s, we set QU(L) = QU(s). Obviously, QU is well defined. By Eqs. (9)(cid:18) QU(s(cid:13)). That fact to-and (18), for canonical lotteries s, s(cid:13) we have s (cid:9) s(cid:13) iff QU(s) —gether with Lemma 3 and the way by which QU is defined allow us to conclude QUrepresents (cid:9).Now, we will show that QU satisfies Eq. (24). Consider depth-one lottery L =[π1/x1, . . . , πr /xr ]. By A4, each consequence xilot-tery, say si = [κi1/x, κir /x]. Therefore, QU(xi) = (cid:14)κi1, κir (cid:15). Consider lottery L(cid:13) =[π1/s1, π2/s2, . . . , πr /sr ]. From A3, L ∼ L(cid:13). Using A2 and the argument in the proofof Lemma 3, we have L(cid:13) is indifferent to canonical lottery s = [κ1/x, κr /x] whereto a canonicalis indifferentκl = max1(cid:1)i(cid:1)r{πi.κil} where l ∈ {1, r}(A.2)Therefore, on one hand QU(L) = QU(L(cid:13)) = QU(s) = (cid:14)κ1, κr (cid:15). On the other hand,(cid:9)(cid:10)πi.(cid:14)κi1, κir (cid:15)(cid:10)(cid:14)πi.κi1, πi.κir (cid:15)(cid:9)(cid:10)πi.QU(xi)(cid:9)max1(cid:1)i(cid:1)r= max1(cid:1)i(cid:1)r(cid:14){πi.κi1}, max1(cid:1)i(cid:1)rThus, we show QU(L) = max1(cid:1)i(cid:1)r {πi.QU(xi)}. By induction on lottery’s depth, we= (cid:14)κ1, κr (cid:15)max1(cid:1)i(cid:1)r== max1(cid:1)i(cid:1)r{πi.κir }(cid:15)can prove this property for any lottery.160P.H. Giang, P.P. Shenoy / Artificial Intelligence 165 (2005) 137–163(⇐) Suppose (cid:9)q is represented by QU that satisfies Eq. (24) and (cid:14)1, 0(cid:15), (cid:14)1, 0(cid:15) ∈(cid:18) QU(L(cid:13)). We show that (cid:9)q satisfies axioms A1(cid:18) defined on U by Eq. (18) is reflexive,QU(X), i.e., L (cid:9)q L(cid:13) iff QU(L) —through A5. A1 is satisfied because relation —complete and transitive.Let L = [π1/L1, . . . , πi/Li, . . . , πk/Lk] and L(cid:13) = [π1/L1, . . . , πi/L(cid:13)i . By definition of (cid:9)q , it means QU(Li) = QU(L(cid:13)i, . . . , πk/Lk]. As-sume Li ∼q L(cid:13)i). Apply Eq. (24) twice forcompound lotteries L, L(cid:13). We see that the right-hand sides are identical. So the left-handsides which are QU(L) and QU(L(cid:13)) must be equal. By definition of (cid:9)q , we have L ∼q L(cid:13).Thus, A3 is satisfied.Let L = [π1/L1, π2/L2, . . . , πk/Lk] where Li = [κi1/x1, κi2/x2, . . . , κir /xr ] for 1 (cid:1)i (cid:1) k. Let us assume QU(xj ) = (cid:14)λj , µj (cid:15) for 1 (cid:1) j (cid:1) r. Apply Eq. (24) for Li and then L,(cid:9)(cid:10)κij .(cid:14)λj , µj (cid:15)(cid:9)(cid:10)(cid:14)κij .λj , κij .µj (cid:15)(cid:15)= max1(cid:1)j (cid:1)r{κij .µj }max1(cid:1)j (cid:1)r(cid:9)(cid:14)πi.(cid:9)(cid:14){κij .λj }, max1(cid:1)j (cid:1)r{κij .λj }, max1(cid:1)j (cid:1)rmax1(cid:1)j (cid:1)r(cid:15)(cid:10){κij .µj }(cid:15)(cid:10){κij .µj }QU(Li) = max1(cid:1)j (cid:1)r(cid:14)=QU(L) = max1(cid:1)i(cid:1)k= max1(cid:1)i(cid:1)k(cid:14)πi. max1(cid:1)j (cid:1)r{πi. max1(cid:1)j (cid:1)r(cid:9){κij .λj }, πi. max1(cid:1)j (cid:1)r(cid:9)(cid:10), max1(cid:1)i(cid:1)k(cid:9){κij .λj }(cid:10)πi. max1(cid:1)j (cid:1)r(cid:10)(cid:15){κij .µj }(cid:10)(cid:15)max1(cid:1)j (cid:1)r{πi.κij .λj }, max1(cid:1)i(cid:1)kmax1(cid:1)j (cid:1)r{πi.κij .µj }(cid:15)max1(cid:1)i(cid:1)k(cid:14)max1(cid:1)i(cid:1)k(cid:14)===max1(cid:1)j (cid:1)rmax1(cid:1)i(cid:1)k{πi.κij .λj }, max1(cid:1)j (cid:1)rmax1(cid:1)i(cid:1)k{πi.κij .µj }Let us consider the simple lottery mentioned in A2: Ls = [κ1/x1, . . . , κr /xr ] whereκj = max1(cid:1)i(cid:1)k{πj .κij }Apply Eq. (24) for Ls , we haveQU(Ls) = max1(cid:1)j (cid:1)r= max1(cid:1)j (cid:1)r(cid:14)(cid:9)(cid:10)κj .(cid:14)λj , µj (cid:15)(cid:9)(cid:14)= max1(cid:1)j (cid:1)r(cid:9)(cid:10)(cid:14)κj .λj , κj .µj (cid:15)(cid:15)(cid:10)(cid:15)max1(cid:1)i(cid:1)k{πj .κij .λj }, max1(cid:1)i(cid:1)k{πj .κij .λj }, max1(cid:1)j (cid:1)rComparing the last expressions, we have QU(L) = QU(Ls). By definition of (cid:9)q , L ∼q Ls .Thus, A2 is satisfied.{πj .κij .µj }{πj .κij .µj }max1(cid:1)j (cid:1)rmax1(cid:1)i(cid:1)kmax1(cid:1)i(cid:1)k=Denote by x, x the elements of X such that QU(x) = (cid:14)1, 0(cid:15) and QU(x) = (cid:14)0, 1(cid:15). ByEq. (18) and definition of (cid:9)q , we have x (cid:9)q x and x (cid:9)q x for all x ∈ X. For any canon-ical lottery [λ/x, µ/x] where max{λ, µ} = 1, by Eq. (24) we have QU([λ/x, µ/x]) =max{λ.(cid:14)1, 0(cid:15), µ.(cid:14)0, 1(cid:15)} = max{(cid:14)λ, 0(cid:15), (cid:14)0, µ(cid:15)} = (cid:14)λ, µ(cid:15). Thus, by Eq. (18) we conclude thatA5 is satisfied.Finally, for x ∈ X, let assume QU(x) = (cid:14)λ, µ(cid:15). By above argument, we have QU(x) =QU([λ/x, µ/x]). By definition of (cid:9)q we infer x ∼q [λ/x, µ/x]. Thus, A4 is satisfied. (cid:1)P.H. Giang, P.P. Shenoy / Artificial Intelligence 165 (2005) 137–163161Proof of Theorem 3. Let us assume QU(Li) = (cid:14)λi, µi(cid:15) for i = 1, 2, 3.(a) If L1 ∼ L2, then the conclusion is a result of substitutability. Suppose L1 (cid:11) L2. Thismeans λ1 (cid:2) λ2 & µ1 (cid:1) µ2 and at least one of them is a strict relation. Applying Theorem 2,we have(cid:4)(cid:3)[λ/L1, µ/L3](cid:4)(cid:3)[λ/L2, µ/L3](cid:14)(cid:14)(cid:15)max(λ.λ1, µ.λ3), max(λ.µ1, µ.µ3)(cid:15)max(λ.λ2, µ.λ3), max(λ.µ2, µ.µ3)==QUQUSo, max(λ.λ1, µ.λ3) (cid:2) max(λ.λ2, µ.λ3), max(λ.µ1, µ.µ3) (cid:1) max(λ.µ2, µ.µ3). Thismeans QU([λ/L1, µ/L3]) —(cid:18) QU([λ/L2, µ/L3]). By representation theorem[λ/L1, µ/L3] (cid:9) [λ/L2, µ/L3].(b) L1 (cid:11) L2 (cid:11) L3 means λ1 (cid:2) λ2 (cid:2) λ3 & µ1 (cid:1) µ2 (cid:1) µ3 and for indices 1 (cid:1) i < j (cid:1) 3either λi > λj or µi < µj . We will identify λ, µ (cid:2) 0 satisfying max(λ, µ) = 1 such that[λ/L1, µ/L3] (cid:11) L2. Since QU([λ/L1, µ/L3]) = (cid:14)max(λ.λ1, µ.λ3), max(λ.µ1, µ.µ3)(cid:15),the requirement will satisfied if either max(λ.λ1, µ.λ3) > λ2 or max(λ.µ1, µ.µ3) < µ2.If λ1 > λ2, choosing λ = 1 will satisfy the former inequality. Otherwise λ1 = λ2, wehave then µ1 < µ2. We choose λ = 1 and µ strictly positive and small enough so thatµ.µ3 < µ2. Thus max(λ.µ1, µ.µ3) < µ2. Similarly, we can choose λ(cid:13), µ(cid:13) so that L2 (cid:11)[λ(cid:13)/L1, µ(cid:13)/L3]. (cid:1)Proof of Lemma 6. We need to show that the Bayes risk for δ∗P is minimal, i.e.,∀δ ∈ ∆ r(δ∗P ) (cid:1) r(δ)Substitute Eq. (29) into Eq. (31), we have(cid:3)δ(y), θpθ (y)ρ(θ ) =r(δ) =V(cid:17)(cid:17)(cid:4)ΩY(cid:3)δ(y), θ(cid:4)Vpθ (y)ρ(θ )(cid:17)(cid:17)YΩ(A.3)(A.4)(cid:17)It would be enough to show that ∀y ∈ Y,(cid:3)(cid:4)ap(y), θpθ (y)ρ(θ ) =(cid:3)∗P (y), θδVV(cid:17)ΩΩ(cid:4)pθ (y)ρ(θ ) (cid:1)(cid:17)Ω(cid:3)δ(y), θ(cid:4)pθ (y)ρ(θ )VThe last inequality is an implication of Eqs. (33) and (34). (cid:1)References[1] Akaike, Information theory and an extension of the maximum likelihood principle, in: B.N. Petrox, F. Caski(Eds.), Second International Symposium on Information Theory, Academiai Kiado, Budapest, 1973, p. 267.[2] M. Allais, The foundations of a positive theory of choice involving risk and a criticism of the postulatesand axioms of the American School, in: M. Allais, O. Hagen (Eds.), Expected Utility Hypotheses and theAllais Paradox, Reidel, Dordrecht, 1979, pp. 27–145. The English translation of “Fondements d’une TheoriePositive des Choix Comportant un Risque et Critique des Postulats et Axiomes de L’Ecole Americaine”,Econometrie, Colloques Internationaux du Centre National de la Recherche Scientifique, Paris, vol. XL,1953, pp. 275–332.[3] V. Barnett, Comparative Statistical Inference, third edition, Wiley, New York, 1999.162P.H. Giang, P.P. Shenoy / Artificial Intelligence 165 (2005) 137–163[4] D. Basu, I. Ghosh, Statistical Information and Likelihood: A Collection of Critical Essays by Dr. Basu,Lecture Notes in Statistics, Springer, New York, 1988.[5] J.O. Berger, R.L. Wolpert, The Likelihood Principle, second edition, Lecture Notes-Monograph Series, In-stitute of Mathematical Statistics, Hayward, CA, 1988.[6] K. Borch, Utility and stochastic dominance, in: M. Allais, O. Hagen (Eds.), Expected utility hypotheses andthe Allais paradox, Reidel, Dordrecht, 1979, pp. 193–202.[7] R.I. Brafman, M. Tennenholtz, An axiomatic treatment of three qualitative decision criteria, J. ACM 47 (3)(2000) 452–483.[8] D.R. Cox, D.V. Hinkley, Theoretical Statistics, Chapman and Hall, London, 1974.[9] A. Dempster, A generalization of Bayesian inference, J. Roy. Statist. Soc. Ser. B 30 (1968) 205–247, withdiscussion.[10] D. Dubois, L. Godo, H. Prade, A. Zapico, On the possibilistic decision model: from decision under un-certainty to case-based decision, Internat. J. Uncertainty Fuzziness Knowledge-based Syst. 7 (6) (1999)631–670.[11] D. Dubois, S. Moral, H. Prade, A semantics for possibility theory based on likelihoods, J. Math. Anal.Appl. 205 (1997) 359–380.[12] D. Dubois, T.H. Nguyen, H. Prade, Possibility theory, probability and fuzzy sets, in: D. Dubois, H. Prade(Eds.), Handbook of Fuzzy Sets Series, Kluwer Academic, Boston, 2000, pp. 344–438.[13] D. Dubois, H. Prade, Possibility theory as basis for qualitative decision theory, in: Proceedings of 14thInternational Joint Conference on Artificial Intelligence (IJCAI-95), Montreal, Quebec, vol. 2, Morgan Kauf-mann, San Mateo, CA, 1995, pp. 1924–1930, ftp://ftp.irit.fr/pub/IRIT/RPDMP/PTBQDT.ps.gz.[14] A.W.F. Edwards, Likelihood, Cambridge University Press, Cambridge, 1972.[15] D. Ellsberg, Risk, ambiguity and the Savage’s axioms, Quart. J. Econ. 75 (4) (1961) 643–669.[16] P.C. Fishburn, Lexicographic orders, utilities and decision rules: A survey, Management Sci. 20 (11) (1974)1442–1471.[17] P.C. Fishburn, Nonlinear Preference and Utility Theory, The Johns Hopkins University Press, Baltimore,1988.[18] R.A. Fisher, On the mathematical foundation of theoretical statistics, Philos. Trans. Royal Soc. LondonA 222 (1922) 309–368. Reprinted in: J.H. Bennett (Ed.), Collected Papers of R.A. Fisher, vol. 1, Universityof Adelaide, 1971.[19] P.H. Giang, A decision theory for non-probabilistic uncertainty and its applications, PhD thesis, Universityof Kansas, Lawrence, Kansas, 2003.[20] P.H. Giang, P.P. Shenoy, A qualitative linear utility theory for Spohn’s theory of epistemic beliefs, in:C. Boutilier, M. Goldszmidt (Eds.), Uncertainty in Artificial Intelligence: Proceedings of the Sixteenth Con-ference (UAI-2000), San Francisco, CA, Morgan Kaufmann, San Mateo, CA, 2000, pp. 220–229.[21] P.H. Giang, P.P. Shenoy, Statistical decisions using likelihood information without prior probabilities, in:A. Darwiche, N. Friedman (Eds.), Uncertainty in Artificial Intelligence: Proceedings of the Eighteenth Con-ference (UAI-2002), San Francisco, CA, Morgan Kaufmann, San Mateo, CA, 2002, pp. 170–178.[22] P.H. Giang, P.P. Shenoy, Two axiomatic approaches to decision making using possibility theory, EuropeanJ. Oper. Res. 162 (2) (2005) 450–467.[23] I. Gilboa, Expected utility with purely subjective non-additive probabilities, J. Math. Econ. 16 (1987) 65–88.[24] J.Y. Halpern, Reasoning about Uncertainty, MIT Press, Cambridge, MA, 2003.[25] N.E. Jensen, An introduction to Bernoullian utility theory I: Utility functions, Swedish J. Econ. 69 (1967)163–183.[26] W.C.M. Kallenberg, Asymptotic Optimality of Likelihood Ratio Tests in Exponential Families, Mathemati-cal Centre Tracts, vol. 77, Mathematisch Centrum, Amsterdam, 1978.[27] E.L. Lehmann, G. Casella, Theory of Point Estimation, second edition, Springer Texts in Statistics, Springer,New York, 1998.[28] H. Levy, Stochastic dominance and expected utility: Survey and analysis, Management Sci. 38 (4) (1992)555–593.[29] R.D. Luce, H. Raiffa, Games and Decision, Wiley, New York, 1957.[30] J. Neyman, E.S. Pearson, On the use and interpretation of certain test criteria for purposes of statisticalinference, part 1, Biometrica 20A (1928) 175–240. In: J. Neyman, E.S. Pearson, Joint Statistical Papers,University of California Press, 1967.P.H. Giang, P.P. Shenoy / Artificial Intelligence 165 (2005) 137–163163[31] W.B. Poland, R.D. Shachter, Three approaches to probability model selection, in: R. Lopez de Mantaras,D. Poole (Eds.), Uncertainty in Artificial Intelligence: Proceedings of the Tenth Conference (UAI-94), Mor-gan Kaufmann, San Mateo, CA, 1994.[32] R. Sarin, P. Wakker, A simple axiomatization of nonadditive expected utility, Econometrica 60 (6) (1992)1255–1272.[33] D. Schmeidler, Subjective probability and expected utility without additivity, Econometrica 57 (3) (1989)571–587.[34] G. Schwarz, Estimating the dimension of a model, Ann. Statist. 6 (1978) 461–464.[35] G. Shafer, A Mathematical Theory of Evidence, Princeton University Press, Princeton, NJ, 1976.[36] G. Shafer, Belief functions and parametric models, J. Royal Statist. Soc. Ser. B 44 (3) (1982) 322–352.[37] P. Smets, The transferable belief model for quantified belief representation, in: D.M. Gabbay, P. Smets(Eds.), Handbook of Defeasible Reasoning and Uncertainty Management System, vol. 1, Kluwer, Dordrecht,1998, pp. 267–301.[38] J. von Neumann, O. Morgenstern, Theory of Games and Economic Behavior, second edition, PrincetonUniversity Press, Princeton, NJ, 1947.[39] A. Wald, Statistical Decision Function, Wiley, New York, 1950.[40] P. Walley, Belief function representation of statistical evidence, Ann. Statist. 15 (4) (1987) 1439–1465.[41] L. Zadeh, Fuzzy set as a basis for a theory of possibility, Fuzzy Sets and Systems 1 (1978) 3–28.