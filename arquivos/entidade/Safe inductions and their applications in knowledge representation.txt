Artificial Intelligence 259 (2018) 167–185Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintSafe inductions and their applications in knowledge representation ✩Bart Bogaerts a,∗a Department of Computer Science, KU Leuven, 3001 Heverlee, Belgiumb Department of Computer Science, KU Leuven, Campus De Nayer, 2860 Sint-Katelijne-Waver, Belgium, Joost Vennekens a,b, Marc Denecker aa r t i c l e i n f oa b s t r a c tIn many knowledge representation formalisms, a constructive semantics is defined based on sequential applications of rules or of a semantic operator. These constructions often share the property that rule applications must be delayed until it is safe to do so: until it is known that the condition that triggers the rule will continue to hold. This intuition occurs for instance in the well-founded semantics of logic programs and in autoepistemic logic. In this paper, we formally define the safety criterion algebraically. We study properties of so-called safe inductions and apply our theory to logic programming and autoepistemic logic. For the latter, we show that safe inductions manage to capture the intended meaning of a class of theories on which all classical constructive semantics fail.© 2018 Elsevier B.V. All rights reserved.Article history:Received 1 December 2017Received in revised form 13 March 2018Accepted 25 March 2018Available online 28 March 2018Keywords:Approximation fixpoint theoryLattice operatorInductive definitionsInduction processConstructionWell-founded semanticsGroundednessLogic programmingAutoepistemic logicAbstract argumentation1. IntroductionIn many fields of computational logic, natural forms of induction show up. Such an induction can be seen as a sequence of semantic structures obtained by iterative applications of rules or a semantic operator. For instance, in logic programming, it is natural to think of sequences of interpretations where at each stage a number of rules whose bodies are satisfied are triggered (i.e., their head is added to the current interpretation). For positive logic programs, all such sequences converge to the minimal model. For non-positive programs, this strategy may yield meaningless results. For instance, for the program(cid:2)(cid:3)P =ab ← ¬a,one such sequence isA short version of this paper was published in the proceedings of the IJCAI’17 conference [6]. This paper extends the previous work with more ✩theoretical results, examples, proofs of all propositions and applications of the work to argumentation frameworks.* Corresponding author.E-mail addresses: bart .bogaerts @cs .kuleuven .be (B. Bogaerts), joost .vennekens @cs .kuleuven .be (J. Vennekens), marc .denecker @cs .kuleuven .be(M. Denecker).https://doi.org/10.1016/j.artint.2018.03.0080004-3702/© 2018 Elsevier B.V. All rights reserved.168B. Bogaerts et al. / Artificial Intelligence 259 (2018) 167–185N1 = ∅, {b}, {b, a},the limit of which is not even a supported model of the logic program. On the other hand, the sequenceN2 = ∅, {a}is another such sequence that does end in the intended model of P , namely its perfect model. Intuitively, what is wrong with N1 is that the rule b ← ¬a is applied too soon, before the value of a is established. For stratified programs, like P , this problem has been resolved, e.g., by Apt et al. [2]. For the general case, the well-founded semantics [33] offers a solution that uses three-valued interpretations instead of two-valued interpretations.In recent work, the notions of natural and safe inductions for inductive definitions were introduced [15,16]. It was argued that this kind of process forms the essence of our understanding of inductive definitions.In this paper, we lift those ideas of safe and natural inductions to a more general setting: we provide a principled study of such inductions in the context of approximation fixpoint theory (AFT) (Denecker, Marek and Truszczy ´nski (DMT) [10]), an algebraic theory that provides a unifying framework of semantics of nonmonotonic logics. We show convergence of safe inductions in this general setting and study the relationship between (algebraic) safe inductions and various fixpoints defined in approximation fixpoint theory.By presenting our theory in AFT, our results are broadly applicable. DMT [10] originally developed AFT to unify seman-tics of logic programs [32], autoepistemic logic [26] and default logic [28]. Later, it was also used to define semantics of extensions of logic programs, such as HEX logic programs [1] and an integration of logic programs with description log-ics [23]. Strass [30] showed that many semantics for Dung’s argumentation frameworks (AFs) [17] and abstract dialectical frameworks (ADFs) [7] can be obtained by direct application of AFT. Bogaerts and Cruz-Filipe [3] showed that AFT has applications in database theory, for defining semantics of active integrity constraints [19].The theory we present in this paper induces for each of the above logics notions of (safe) inductions and a safe semantics. Our complexity results are obtained for general operators and hence can also be transferred to various logics of interest. Throughout the paper, we give examples from logic programming.In Section 7, we apply our theory to autoepistemic logic. There we show that safe inductions induce a constructive semantics that captures the intended semantics of a class of theories for which classical constructive semantics fail. This failure was recently exposed and solved using a notion of set-inductions which is based on sets of lattice elements instead of intervals (which are standard in AFT) [5]. We show that safe inductions provide an alternative solution to this problem. Our solution is more direct: in contrast to set-inductions or well-founded inductions [14], safe inductions do not require any form of approximation; they are sequences in the original lattice. For logic programming, this means that they are sequences of interpretations such that some atoms are derived in each step. For AEL, this means that they are sequences of possible world structures such that additional knowledge is derived in each step.In Section 8, we apply our theory to Dung’s argumentation frameworks [17], where we show the surprising result that two different operators that exist for a given argumentation framework have the same safely defined point. Furthermore, this point corresponds to an existing semantics: it is the so-called grounded extension.The rest of this paper is structured as follows. In Section 2, we give preliminaries regarding lattices and operators. In Section 3, we define (safe) inductions and provide some basic results. We continue by studying complexity of some inference problems related to safe inductions in Section 4. In Section 5, we recall the basics of AFT; we use this in Section 6 to study how (safe) inductions relate to various fixpoints studied in AFT. Afterwards, in Sections 7 and 8, we apply our general theory to autoepistemic logic and argumentation frameworks respectively. We conclude in Section 9.2. Preliminaries: lattices and operators(cid:4)A partially ordered set (poset) (cid:5)L, ≤(cid:7) is a set L equipped with a partial order ≤, i.e., a reflexive, antisymmetric, transitive relation. We write x < y for x ≤ y ∧ x (cid:9)= y. If S is a subset of L, then x is an upper bound, respectively a lower bound of S if for every s ∈ S, it holds that s ≤ x, respectively x ≤ s. An element x is a least upper bound, respectively greatest lower boundof S if it is an upper bound that is smaller than every other upper bound, respectively a lower bound that is greater than every other lower bound. If S has a least upper bound, respectively a greatest lower bound, we denote it lub(S), respectively glb(S). As is custom, we sometimes call a greatest lower bound a meet, and a least upper bound a join and use the related S = lub(S) and x ∨ y = lub({x, y}). We call (cid:5)L, ≤(cid:7) a complete lattice if every notations subset S of L has a least upper bound and a greatest lower bound. A complete lattice has a least element ⊥ and a greatest element (cid:13).S = glb(S), x ∧ y = glb({x, y}), An operator O : L → L is monotone if x ≤ y implies that O (x) ≤ O ( y) and anti-monotone if x ≤ y implies that O ( y) ≤O (x). An element x ∈ L is a prefixpoint, a fixpoint, a postfixpoint of O if O (x) ≤ x, respectively O (x) = x, x ≤ O (x). Every monotone operator O in a complete lattice has a least fixpoint [31], denoted lfp(O ), which is also O ’s least prefixpoint and the limit of any terminal monotone induction of O , defined below.(cid:5)Definition 2.1. A monotone induction of a lattice operator O : L → L is an increasing sequence (for some ordinal β) (xi )i≤β of elements xi ∈ L satisfyingB. Bogaerts et al. / Artificial Intelligence 259 (2018) 167–185169• x0 = ⊥,• xi ≤ xi+1 ≤ O (xi), for successor ordinals i + 1 ≤ β,• xλ = lub({xi | i < λ}), for limit ordinals λ ≤ β.A monotone induction is terminal if O (xβ ) = xβ .Logic programming. Let (cid:4) be an alphabet, i.e., a collection of symbols which are called atoms. A literal is an atom p or the negation ¬q of an atom q. The former are called positive literals; the latter are called negative literals. A logic program Pis a set of rules r of the form h ← ϕ, where h is an atom called the head of r, denoted head(r), and ϕ is a conjunction of literals called the body of r, denoted body(r). An interpretation I of (cid:4) is a subset of (cid:4). The set of interpretations 2(cid:4) forms a lattice equipped with the order ⊆. The truth value (t or f) of a propositional formula ϕ in a structure I , denoted ϕ I , is defined as usual. With a logic program P , we associate an immediate consequence operator T P [32] that maps a structure I to the structure{p ∈ (cid:4) | ∃r ∈ P : head(r) = p ∧ body(r)I = t}.This is an operator on the lattice (cid:5)2(cid:4), ⊆(cid:7). We call a logic program P positive if for each rule r ∈ P , body(r) consists of only positive literals. If P is positive, then T P is monotone.3. Safe inductionsIn this section, we define the central concept of this paper, namely the notion of a safe induction and study its basic properties. Let L be a lattice and O an operator on L, fixed throughout the rest of this paper.Definition 3.1. We call y ∈ L derivable from x ∈ L if x ≤ y ≤ x ∨ O (x).Definition 3.2. Let x be an element of L. An O -induction in x is a sequence (xi)i≤β such that• x0 = x,• xi+1 is derivable from xi for each i < β,• xλ = lub({xi | i < λ}), for limit ordinals λ ≤ β.We call xβ the limit of (xi)i≤β .Intuitively, we view O as an operator that constructs certain lattice points. An O -induction is the associated construction process. Intuitively, if we are at a stage xi , O (xi) represents what can be concluded from this given stage. Therefore, the next step xi+1 in the induction is at least xi (xi+1 ≥ xi ) and at most the combination of xi and what can be concluded from it (xi+1 ≤ xi ∨ O (xi)). In the context of a powerset lattice (a lattice of the form (cid:5)2S , ⊆(cid:7)), this means that xi+1 ⊆ xi ∪ O (xi), i.e., xi+1 only contains elements that were already in xi or such that O concludes them from xi .Definition 3.3. Let N = (xi)i≤β and N (cid:19) = ( yi)i≤α be two O -inductions. We say that N (cid:19)all i ≤ β. The extension is strict if yα (cid:9)= xβ .extends N if α ≥ β and xi = yi for Definition 3.4. An O -induction is terminal if there exists no O -induction that strictly extends it.Proposition 3.5. An O -induction (xi)i≤β is terminal if and only if xβ is a prefixpoint of O .Proof. Let N denote (xi)i≤β .If xβ is a prefixpoint of O , then O (xβ ) ≤ xβ , hence, in each extension (xi)i≤α with α > β of N , it must hold thatxβ ≤ xβ+1 ≤ xβ ∨ O (xβ ) = xβ ,hence xβ+1 = xβ and by induction also xα = xβ .On the other hand, if xβ is not a prefixpoint, then (xi)i≤β+1 with xβ+1 = xβ ∨ O (xβ ) is a strict extension of N . (cid:2)Proposition 3.6. If O is monotone, all monotone inductions of O (see Definition 2.1) are O -inductions in ⊥ and vice versa.Proof. It is clear that all monotone inductions in ⊥ are O -inductions since the definitions only differ in the second condi-tions, which is more restrictive for monotone inductions.170B. Bogaerts et al. / Artificial Intelligence 259 (2018) 167–185For the other direction, let (xi)i≤β be any O -induction. We first claim that each xi is a postfixpoint of O . This claim is clear for i = 0 and the limit of an increasing sequence of postfixpoints of a monotone operator is a postfixpoint. If xi is a postfixpoint, the xi ≤ O (xi) and hence O (xi) ∨ xi = O (xi). Furthermore, since O is monotone, O (xi) ≤ O (xi+1). Combining these two equations we get thatxi ≤ xi+1 ≤ O (xi) ∨ xi = O (xi) ≤ O (xi+1)and see that indeed, xi+1 is a postfixpoint as well.Hence, for each i, xi ≤ O (xi) and thus xi ∨ O (xi) = O (xi). Thus, (xi)i≤β is indeed a monotone induction, which we needed to show. (cid:2)Corollary 3.7. If O is monotone, all terminal O -inductions in ⊥ converge to lfp(O ).There is a high degree of non-determinism in O -inductions. For monotone operators O , despite this non-determinism, all O -inductions converge to the same point. As such, O -inductions provide (if O is monotone) a way to construct an intended lattice point (lfp(O )). For non-monotone operators, the situation is quite different: O -inductions might not converge to a single point.Example 3.8. Let P be the logic program⎧⎪⎪⎨⎪⎪⎩pq ← pr ← sr ← p⎫⎪⎪⎬⎪⎪⎭This is a positive logic program, hence T P is monotone. The following are the three terminal strict T P -inductions in ⊥ = ∅:N1 = (∅, {p}, {p, q}, {p, q, r})N2 = (∅, {p}, {p, r}, {p, q, r})N3 = (∅, {p}, {p, q, r})They indeed all converge to the intended model of P , namely the least fixpoint of T P . (cid:2)Example 3.9. Let P be the logic program(cid:2)(cid:3)pq ← ¬pThis is a simple, stratified logic program [2,27]. Its intended fixpoint (its so-called perfect model) is {p}. Let T P denote its immediate consequence operator. The following are the three terminal strict T P -inductions in ⊥ = ∅.N1 = (∅, {q}, {p, q})N2 = (∅, {p, q})N3 = (∅, {p})(cid:2)The previous example shows that certain derivations in an O -induction can happen prematurely. For instance, in N1 and N2, q is derived by the non-monotonic rule q ← ¬p. As soon as p is derived, this rule no longer applies: q /∈ T P ({p, q}) = {p}. In these two sequences, the rule was applied when it was not safe to do so. Below, we formally define a notion of safety to avoid such premature derivations, i.e., to only derive facts that remain derivable, regardless of which other derivations are made further on in the induction process.(cid:19)Definition 3.10. Let xholds that x(cid:19) ≤ x ∨ O (xβ ).(cid:19)be derivable from x. We say that xis safely derivable from x if for each O -induction (xi)i≤β in x, it An O -induction (xi)i≤β is safe if xi+1 is safely derivable from xi for each i < β.(cid:19)In words, x(cid:19)is safely derivable from x if no matter what other derivations we make (ending up in xβ ), xconsists at most of what we have in x combined with what O concludes from xβ , i.e., x(cid:19) ≤ x ∨ O (xβ ).Proposition 3.11. If y is safely derivable from x and x ≤ z ≤ y, then z is safely derivable from x.B. Bogaerts et al. / Artificial Intelligence 259 (2018) 167–185171Proof. It follows directly from the definition that z is derivable from x. To see that it is safely derivable, take any O -induction in x with limit xβ . Then z ≤ y ≤ x ∨ O (xβ ) and the result follows. (cid:2)(cid:5)Y is safely derivable from x. Hence, for each x, there exists Proposition 3.12. If Y ⊆ L and each y ∈ Y is safely derivable from x, then a largest y such that y is safely derivable from x.Proof. It is easy to see that limit xβ . Then y ≤ x ∨ O (xβ ) for each y ∈ Y and hence also (cid:5)Y is derivable from x. To see that it is safely derivable, take any O -induction in x with Y ≤ x ∨ O (xβ ) and the result follows. (cid:2)(cid:5)Example 3.13 (Example 3.8 continued). All derivations in all of the inductions here are safe. Consider for instance the deriva-tion of {p, r} from {p} in N2. For each interpretation I ⊃ {p}, it holds that r ∈ T P (I). Hence, for each T P induction (xi)i≤βin {p} it holds that xβ ⊃ {p} and thus that r ∈ T P (xβ ). Now this means that {p, r} ⊆ {p} ∪ T P (xβ ) and thus indeed, this derivation is safe. (cid:2)The situation in Example 3.13 is not a coincidence, as the following proposition shows.Proposition 3.14. If O is monotone and y is derivable from x, then y is safely derivable from x.Proof. Suppose y is derivable from x, i.e., that x ≤ y ≤ O (x) ∨ x. Let (xi)i≤β be any O -induction in x. Then xβ ≥ x and hence, by monotonicity of O , O (xβ ) ≥ O (x). Thus, indeed y ≤ x ∨ O (x) ≤ x ∨ O (xβ ), as we needed to show. (cid:2)For non-monotone operators, the situation is different, as is to be expected.Example 3.15 (Example 3.9 continued). The (intuitively) wrong derivation of {q} from ∅ is not safe. Indeed, N1 is a T P -induction with as limit {p, q}, but{q} (cid:9)⊆ ∅ ∪ T P ({p, q}) = ∅ ∪ {p} = {p}.(cid:2)An induction is terminal if it cannot be extended into a strictly larger induction. We define a similar concept for safe inductions.Definition 3.16. A safe O -induction N is safe-terminal if there exists no strict extension N (cid:19)of N that is safe.In Example 3.9, we showed that not all terminal O -inductions converge to the same lattice point. Luckily, the safety criterion leads to a better situation.Theorem 3.17. For each x ∈ L, all safe-terminal O -inductions in x converge to the same lattice point.In order to prove this theorem, we use the following result.Lemma 3.18. Let N = (xi)i≤β , N (cid:19) = ( yi)i≤γ be two safe O -inductions with x0 = y0. For every i ≤ β, j ≤ γ it holds that if i + 1 ≤ βthen xi+1 ∨ y j is safely derivable from xi ∨ y j and if j + 1 ≤ γ then xi ∨ y j+1 is safely derivable from xi ∨ y j .Proof. The product order ≤ for ordinal pairs (given by (i, j) ≤ (k, l) if i ≤ k, j ≤ l) is a well-founded order, hence every set of such pairs contains minimal elements in this order.Assume towards contradiction that pairs (i, j) ≤ (β, γ ) exist that contradict this lemma, and let (i, j) be a minimal such pair in the product order. Hence, either xi+1 ∨ y j exists and is not safely derivable from xi ∨ y j , or xi ∨ y j+1 exists and is not safely derivable from xi ∨ y j .Assume that it is the first case. Thus, i +1 ≤ β and xi+1 ∨ y j is not safely derivable from xi ∨ y j . By the minimality of (i, j), the sequence N (cid:19)(cid:19) = (xi ∨ yk)0≤k≤ j is a safe O -induction from xi with limit xi ∨ y j . Since xi ≤ xi+1, also xi ∨ y j ≤ xi+1 ∨ y j . Since xi+1 is safely derivable from xi , and N (cid:19)(cid:19)is an O -induction with limit xi ∨ y j , it holds that xi+1 ≤ xi ∨ O (xi ∨ y j), hence also xi+1 ∨ y j ≤ xi ∨ y j ∨ O (xi ∨ y j). Hence xi+1 ∨ y j is derivable from xi ∨ y j . We now show that this derivation is safe.Since xi+1 is safely derivable from xi , for each O -induction in xi with limit z, it must hold that xi+1 ≤ xi ∨ O (z). Now, each O -induction in xi ∨ y j can be turned into an O -induction in xi by composing N (cid:19)(cid:19)with it, hence, for each O -induction from xi ∨ y j with limit z, it must also hold that xi+1 ≤ xi ∨ O (z), thus that xi+1 ∨ y j ≤ xi ∨ y j ∨ O (z). Thus, xi+1 ∨ y j is safely derivable from xi ∨ y j , which yields a contradiction.The second case is obtained by a symmetrical argument. (cid:2)172B. Bogaerts et al. / Artificial Intelligence 259 (2018) 167–185Proof of Theorem 3.17. Let N = (xi)i≤β and N (cid:19) = ( yi)i≤γ be two safe-terminal O -inductions. Consider the sequence (zi)i≤β+γ where zi = xi if i ≤ β and zβ+i = xβ ∨ yi if i ≤ γ . By Lemma 3.18, this sequence is a safe O -induction. Since N is safe-terminal, this sequence cannot be a strict extension of N and hence xβ ∨ yγ = zβ+γ = xβ , i.e., yγ ≤ xβ . A sym-metric argument shows that xβ ≤ yγ , hence xβ = yγ , as desired. (cid:2)Definition 3.19. The safely defined point by O , denoted safe(O ) is the limit of all safe-terminal O -inductions in ⊥.Example 3.20 (Example 3.9 continued). The induction N3 is the only safe-terminal induction in ∅ in which each derivation is strict. Its limit is the intended model of P , namely the perfect model. (cid:2)By Theorem 3.17, the safely defined point is well-defined. We now study some properties of the safely defined point.Proposition 3.21. For any operator O , safe(O ) is a postfixpoint of O , i.e., safe(O ) ≤ O (safe(O )).Proof. Let N = (xi)i≤β be a safe O -induction in ⊥. We show by induction that xi ≤ O (xβ ) for each i. The claim trivially holds for i = 0 since x0 = ⊥. It is preserved in limit ordinals i since j<i x j ≤ O (xβ ) if x j ≤ O (xβ ) for each j < i. We show that it also holds for successor ordinals. Hence, assume that xi ≤ O (xβ ) with i < β and that xi+1 is safely derivable from xi . Since N is an O -induction and xi+1 is safely derivable from xi , it must hold that(cid:5)xi+1 ≤ xi ∨ O (xβ ) ≤ O (xβ ) ∨ O (xβ ) = O (xβ )and the result follows. (cid:2)Example 3.22. The safely defined point is not always a fixpoint of O . Consider a lattice {⊥, (cid:13)} with two elements and an operator O that maps ⊥ to (cid:13) and (cid:13) to ⊥. The safely defined point by O is ⊥, since (cid:13) is not safely derivable ((cid:13) (cid:9)≤⊥ ∨ O ((cid:13))). Here, the O -induction N = (⊥) is safe-terminal, but not terminal. (cid:2)Definition 3.23. We call an operator O complete if the safely defined point by O is a fixpoint of O , i.e., if O (safe(O )) =safe(O ).We will be mostly interested in complete operators O , as they uniquely determine a fixpoint of interest of O .Proposition 3.24. An operator O is complete if and only if every safe-terminal O -induction in ⊥ is terminal.Proof. If O is complete, safe(O ) is a fixpoint of O . It follows then from Proposition 3.5 that every O -induction with limit safe(O ) is terminal.On the other hand, assume that every safe-terminal O -induction in ⊥ is terminal. Thus (by Proposition 3.5) safe(O ) is a prefixpoint of O . By Proposition 3.21, safe(O ) is also a postfixpoint of O . Hence, it must be a fixpoint of O . (cid:2)Proposition 3.25. If O is a monotone operator, then O is complete and safe(O ) = lfp(O ).Proof. From the monotonicity of O , it easily follows that every O -induction is safe. The result then follows from Corol-lary 3.7. (cid:2)Proposition 3.26. If O is an anti-monotone operator, then safe(O ) = lfp(O 2).Proof. Consider for any ordinal β the sequences N = (xi)i≤β given byx0 = ⊥xi+1 = O ( yi), for each i < β(cid:13)xλ =xi, for each limit ordinal λ ≤ βi<λand ( yi)i≤β given byy0 = (cid:13)yi+1 = O (xi), for each i < βyλ =yi, for each limit ordinal λ ≤ β(cid:14)i<λB. Bogaerts et al. / Artificial Intelligence 259 (2018) 167–185173We will prove the following claims about this sequence.1. For each i ≤ β, xi ≤ yi and if i < β, xi ≤ xi+1 and yi+1 ≤ yi .2. (xi)i≤β is a monotone O 2-induction.3. (xi)i≤β is a safe O -induction.The first statement follows from the construction of the two sequences and the fact they converge to the so-called least alternating pair of the anti-monotone operator O . We do prove this below for completeness.From the last two claims it follows that for β large enough xβ = safe(O 2) = lfp(O 2). Since O (xβ ) is derivable from xβand O (O (xβ )) = xβ , it follows that (xi)i≤β , as an O -induction, is safe-terminal. Hencesafe(O ) = xβ = safe(O 2) = lfp(O 2),which is what we needed to show. We now show that the claims we made indeed hold.1. We prove this by induction.It certainly holds for i = 0 since x0 = ⊥ and y0 = (cid:13).If the claim holds for i < β, then xi ≤ yi . Hence by anti-monotonicity of O ,yi+1 = O (xi) ≥ O ( yi) = xi+1.Also, since i + 1 < β and the claim holds for i, it holds that xi ≤ xi+1 and yi+1 ≤ yi . Now, by anti-monotonicity of O ,yi+1 = O (xi) ≥ O (xi+1) = yi+2andxi+2 = O ( yi+1) ≥ O ( yi) = xi+1.Hence, we proved that all three inequalities in the claim also hold for i + 1.Finally, suppose the claim holds for all i < λ with λ ≤ β some limit ordinal. For each i ≤ j < λ, it holds that xi ≤ x j ≤ y j . Similarly, for each j ≤ i < λ, it holds that xi ≤ yi ≤ y j . Hence, for all i, j < λ, xi ≤ y j . Thus also(cid:13)(cid:14)xλ =xi ≤y j = yλ.i<λj<λIf furthermore λ < β, then we know that for each j < λ, y j ≥ yλ. Hence, by anti-monotonicity of O , x j+1 = O ( y j) ≤O ( yλ) for each j < λ. Thus(cid:14)xλ ≤x j+1 ≤ O ( yλ) = xλ+1.j<λSimilarly we find that alsoyλ ≥ yλ+1and we see that the claim indeed also holds for λ.Hence, we showed by transfinite induction that the first claim is indeed satisfied for all i ≤ β.2. To see that (xi)i≤β is a monotone O 2-induction, we note that by the first claim, for each i:yi ≥ yi+1,hence by anti-monotonicity of O alsoxi+1 = O ( yi) ≤ O ( yi+1) = O 2(xi).Thus, it holds thatxi ≤ xi+1 ≤ O 2(xi).3. First, we show that for each i < β, xi+1 is derivable from xi . To see this, note that from the first claim, it follows thatxi ≤ xi+1 ≤ yi+1 = O (xi),hence xi+1 is indeed derivable from xi .174B. Bogaerts et al. / Artificial Intelligence 259 (2018) 167–185Second, we show that xi+1 is safely derivable from xi . To show this, fix i and let (z j) j≤γ be any O -induction in xi . We need to show that xi+1 ≤ xi ∨ O (zγ ). In order to show this, we claim that for each j, xi ≤ z j ≤ yi . We show this claim by (transfinite) induction on j. It certainly holds for j = 0, since z0 = xi . If our claim holds for j, since z j+1 is a refinement of z j , it holds that z j ≤ z j+1 ≤ z j ∨ O (z j). By our induction hypothesis, and the fact that O is anti-monotone,xi ≤ z j ≤ z j+1 ≤ z j ∨ O (z j) ≤ y j ∨ O (x j) = y j ∨ y j+1 = y jand indeed our claim follows. It is easy to see that it also holds in limit ordinals.Now, since our claim holds for all j ≤ γ , it also holds for j = γ . Hence, we find that yi ≥ zγ and thus that xi+1 =O ( yi) ≤ O (zγ ) and it indeed follows that xi+1 is safely derivable from xi , which is what we still needed to show. (cid:2)Theorem 3.17 shows that safe O -inductions, despite their high degree of non-determinism, uniquely determine a lattice point of interest. Furthermore, if O is monotone, this point is the least fixpoint of O . The question now arises: what if O is non-monotone? How does the safely defined point by O relate to other points of interest? In particular, how does it relate to fixpoints defined in approximation fixpoint theory, especially to those with a constructive characterization? We study this in Section 6. First, we study complexity of some inference tasks related to safe inductions.4. ComplexityIn this section, we assume that a class C = {(cid:5)L, O (cid:7)} of pairs of a finite lattice L and an operator O : L → L is given.The height of a finite lattice L is the length n of the longest sequence ⊥ = x0 < x1 < · · · < (cid:13) = xn in L. We call y ∈ L a direct successor of x ∈ L if x < y and there is no z such that x < z < y. The branching width of a finite L is the maximum over all x ∈ L of the number of direct successors of x. All complexity results presented below are in terms of the sum of the branching width and the height of the input lattice. This means that we use the sum of the branching width and the height as the measure of our input.1Let FC denote the function problem: given one of the (cid:5)L, O (cid:7) in C and p, p(cid:19) ∈ L, compute1. O (p),(cid:19)2. p ∨ p3. {x | x is a direct successor of p}., andWe assume that FC can be solved in polynomial time.The kind of setting used here is not so unusual: it is essentially an algebraic variant of data complexity. For instance, in logic programming, each non-ground program P determines a class of lattices and associated operators (immediate consequence operators of the groundings of P with respect to a given domain). The height and branching width of the lattice are then polynomial in terms of the domain size. In this setting, the problem FCP is indeed polynomially solvable.Theorem 4.1. Let C be a class as above. The decision problem “given Li ∈ C, x, y ∈ Li , is y safely derivable from x by O i ?” is in co-NP.Proof. Algorithm 1 contains a nondeterministic program to decide that y is not safely derivable from x. It takes as input (cid:5)L, O (cid:7), x, and y.Algorithm 1 Nondeterministic algorithm to decide that y is not safely derivable from x by O .s ← xwhile true doif y (cid:9)≤ x ∨ O (s) thenreturn trueelse if O (s) ≤ s thenreturn false(cid:19) ∈ Li with s < s(cid:19) ≤ s ∨ O (s)elsechoose an s(cid:19)s ← send ifend whileThis program nondeterministically traverses an O -induction from x. Every state xthat can be reached by a natural induction from x can be reached by a run of this program. The algorithm stops with true when it reaches a lattice point that provides a counterexample for the safe derivability of y. It stops with false if the reached structure is a prefixpoint (cid:19)1 As you might notice, the input of some of the problems we consider also contains, besides (cid:5)L, O (cid:7) a number of lattice points. It is always possible to encode lattice points in a way that is polynomial in terms of the sum of the branching width and height of the lattice, e.g., by describing paths from ⊥ to the given lattice point.B. Bogaerts et al. / Artificial Intelligence 259 (2018) 167–185175of O and it still provides no counterexample for the safe derivability of y. In this case, the traversed O -induction was a terminal one that was not a witness that y was not safely derivable.One run of the algorithm builds a strictly growing sequence of lattice points; hence, the number of iterations is bound by the height of the lattice. At each step, the main computations are the computations of O (x), x ∨ O (x) and checking for (cid:19) ≤ s ∨ O (s)}, we can two lattice points whether one is smaller than the other. In order to branch on all elements {siteratively compute all direct successors of s and check whether they satisfy the condition above. These operations require to solve the function problem FC . Hence, Algorithm 1 runs in nondeterministic polynomial time that has a run and terminates with true if and only if y is not safely derivable from x. It follows that deciding that y is not safely derivable from x is in NP and its dual is in co-NP. (cid:2)(cid:19) | s ≤ sTheorem 4.2. Let C be a class as above. The decision problem “given (cid:5)L, O (cid:7) ∈ C, s ∈ L, is safe(O ) ≥ s?” is in (cid:8)Pthis problem is co-NP hard.2 . For some classes C, 2 . First note that if y is safely derivable from x, then so is every z with x ≤ z ≤ y. Proof. We first show containment in (cid:8)PHence, the safely defined point can be reached by a safe O -induction such that for each j, x j+1 is a direct successor of x j . By solving a polynomial number (in terms of the branching width of L) of co-NP problems, we can compute the set of direct successors y of x that are safely derivable from x. By doing this a polynomial number of times (in terms of the height of L), we find the safely defined structure and can determine whether safe(O ) ≤ s.We now show the hardness result. To do this, we encode the co-NP hard problem of deciding validity of a propositional formula ϕ (over a propositional vocabulary (cid:4)) in Disjunctive Normal Form (DNF). Let Val denote a symbol not in (cid:4) and (cid:4)(cid:19) = (cid:4) ∪ {Val}. Consider the lattice (cid:5)L, ≤(cid:7) = (cid:5)2(cid:4)(cid:19). Consider a logic program P over (cid:4)(cid:19)that consists of a rule, ⊆(cid:7), i.e., elements of L are propositional interpretations of (cid:4)(cid:19)Val ← x1 ∧ · · · ∧ xnfor each disjunct x1 ∧ · · · ∧ xn of ϕ and of a rulex ← Valfor each x in (cid:4).We claim that Val ∈ safe(T P ) if and only if ϕ is valid.To see this, note that for each interpretation I of (cid:4)(cid:19)Now, if ϕ is false in ∅, then ϕ is not valid. In this case, ∅ is a fixpoint of T P and hence (∅) is the unique T P -induction. , Val ∈ T P (I) if and only if I |= ϕ.We see that in this case, Val /∈ safe(T P ) and ϕ is not valid.Otherwise, ∅ |= ϕ. In this case {Val} is derivable from ∅, but not necessarily safely derivable. If ϕ is valid, then Val ∈ T P (I)for each I and hence {Val} ≤ ∅ ∨ T P (I) for each I . Thus in this case, {Val} is indeed safely derivable. On the other hand, if ϕis not valid, there exists an interpretation I ⊆ (cid:4) such that I (cid:9)|= ϕ. Now, in this case Val /∈ T P (I ∪ {Val}). Notice that I ∪ {Val}is derivable from {Val}. This means that (∅, {Val}, {Val} ∪ I) is a T P -induction with {Val} (cid:9)≤ ∅ ∨ T P (I ∪ {Val}), i.e., that {Val} is not safely derivable from ∅.We conclude that safe(T P ) is greater than {Val} if and only if ϕ is valid. Since deciding validity of a sentence in DNF is co-NP hard, we obtain the desired result. (cid:2)As can be seen, there still is a gap in the complexity results: we managed to prove containment in (cid:8)P2 but only co-NP hardness in Theorem 4.2. While we tried, we did not manage to close this gap and present this as a challenge to the community.5. Preliminaries: AFTGiven a lattice L, approximation fixpoint theory makes use of the lattice L2. We define projections for pairs as usual: (x, y)1 = x and (x, y)2 = y. Pairs (x, y) ∈ L2 are used to approximate all elements in the interval [x, y] = {z | x ≤ z ∧ z ≤ y}. We call (x, y) ∈ L2 consistent if x ≤ y, that is, if [x, y] is non-empty. We use Lc to denote the set of consistent elements. Elements (x, x) ∈ Lc are called exact. We sometimes use the tuple (x, y) and the interval [x, y] interchangeably. The precision ordering on L2 is defined as (x, y) ≤p (u, v) if x ≤ u and v ≤ y. In case (u, v) is consistent, this means that (x, y) approxi-mates all elements approximated by (u, v), or in other words that [u, v] ⊆ [x, y]. If L is a complete lattice, then (cid:5)L2, ≤p(cid:7) is also a complete lattice.AFT studies fixpoints of lattice operators O : L → L through operators approximating O . An operator A : L2 → L2 is an approximator of O if it is ≤p -monotone, and O (x) ∈ A(x, x) for all x ∈ L. It follows from this definition that approximators map Lc into Lc . As usual, we restrict our attention to symmetric approximators: approximators A such that for all x and y, A(x, y)1 = A( y, x)2. DMT [12] showed that the consistent fixpoints of interest (defined below) are uniquely determined by an approximator’s restriction to Lc , hence, sometimes we only define approximators on Lc .AFT studies fixpoints of O using fixpoints of A. The A-Kripke–Kleene fixpoint is the ≤p -least fixpoint of A and has the property that it approximates all fixpoints of O . A partial A-stable fixpoint is a pair (x, y) such that x = lfp( A(·, y)1) and 176B. Bogaerts et al. / Artificial Intelligence 259 (2018) 167–185Fig. 1. The Kleene truth tables [21].y = lfp( A(x, ·)2), where A(·, y)1 denotes the operator L → L : x (cid:21)→ A(x, y)1 and analogously for A(x, ·)2. The A-well-founded fixpoint is the least precise partial A-stable fixpoint. An A-stable fixpoint of O is a fixpoint x of O such that (x, x) is a partial A-stable fixpoint. This is equivalent to the condition that x = lfp( A(·, x)1). A-stable fixpoints are minimal fixpoints of O . The A-Kripke–Kleene fixpoint of O can be constructed by iterative applications of A, starting from (⊥, (cid:13)). For the A-well-founded fixpoint, a similar constructive characterization has been worked out by Denecker and Vennekens [14].Definition 5.1. An A-refinement of (x, y) is a pair (x(cid:19), y(cid:19)) ∈ L2 satisfying one of the following two conditions:• (x, y) ≤p (x• x(cid:19) = x and A(x, y(cid:19)) ≤p A(x, y), or(cid:19) ≤ y.(cid:19))2 ≤ y(cid:19), yAn A-refinement is strict if (x, y) (cid:9)= (x(cid:19), y(cid:19)).Definition 5.2. A well-founded induction of A is a sequence (xi, yi)i≤β with β an ordinal such that• (x0, y0) = (⊥, (cid:13));• (xi+1, yi+1) is an A-refinement of (xi, yi), for all i < β;• (xλ, yλ)=lub≤p{(xi, yi)|i < λ} for limit ordinals λ ≤ β.A well-founded induction is terminal if its limit (xβ , yβ ) has no strict A-refinements.Denecker and Vennekens [14] showed that all terminal A-inductions converge to the A-well-founded fixpoint of O .are pairs (I1, I2) of interpretations. Logic programming. In the context of logic programming, elements of the bilattice Such a pair (I1, I2) corresponds to a four-valued interpretation I that interprets each atom as true (t), false (f), unknown (u) or inconsistent (i):(cid:16)2(cid:15)2(cid:4)⎧⎪⎪⎨⎪⎪⎩I =pif p ∈ I1 and p ∈ I2tu if p ∈ I1 and p /∈ I2if p /∈ I1 and p /∈ I2fif p /∈ I1 and p ∈ I2i(cid:19)with I1 ⊆ ITruth values are ordered by the truth order ≤t induced by f ≤t u ≤t t, f ≤t i ≤t t. The pair (I1, I2) approximates all interpre-(cid:19) ⊆ I2. We often identify an interpretation I with the four-valued interpretation (I, I). We are mostly tations Iconcerned with consistent (also called partial or three-valued) interpretations: tuples I = (I1, I2) with I1 ⊆ I2. For such an interpretation, the atoms in I1 are true (t) in I, the atoms in I2 \ I1 are unknown (u) in I and the other atoms are false (f) in I. If I is a three-valued interpretation, and ϕ a formula, we write ϕIfor the standard three-valued valuation based on the Kleene truth tables (see Fig. 1).Several approximators have been defined for logic programs. The most common is Fitting’s immediate consequence operator (cid:9)P [18], a direct generalization of T P to partial interpretations, given bypψP (I) = max≤t{body(r)I | r ∈ P ∧ head(r) = p}DMT [10] showed that the well-founded fixpoint of (cid:9)P is the well-founded model of P as defined by Van Gelder et al. [33] and that (cid:9)P -stable fixpoints are exactly the stable models of P as defined by Gelfond and Lifschitz [20]. In this case, the operator (cid:9)P (·, y)1 coincides with the immediate consequence operator of the Gelfond–Lifschitz reduct [20].6. Safe inductions and AFTIn this section, we study how (safe) O -inductions relate to the fixpoints studied in AFT.Theorem 6.1. Let O be an operator and A an approximator of O . The A-well-founded fixpoint approximates the safely defined point by O .B. Bogaerts et al. / Artificial Intelligence 259 (2018) 167–185177The proof makes use of the following proposition.Proposition 6.2. Let O be an operator and A an approximator of O . Let (xi, yi)i≤β be an A-well-founded induction. The following claims hold:1. (xi)i≤β is a safe O -induction, and2. for each i ≤ β and each O -induction N = (z j) j≤α with z0 = xi , it holds that zα ≤ yβ .Proof. The proof is by induction on the length β of the well-founded induction.Our claim trivially holds for β = 0 and it is easy to see that it is preserved in limit ordinals. Assume it holds for i, we show that it also holds for i + 1; we distinguish two cases.First, assume that (xi, yi) ≤p (xi+1, yi+1) ≤p A(xi, yi).1. We show that xi+1 is safely derivable from xi . Since every tuple in a well-founded induction is consistent [14], (xi, yi) ≤p (xi, xi) and hence it holds thatxi ≤ xi+1 ≤ A(xi, yi)1 ≤ A(xi, xi)1 ≤ O (xi),hence xi+1 is derivable from xi . Furthermore, we know that for each O -induction N = (zi)i≤α with z0 = xi , it holds thatxi ≤ zα ≤ yi.Since A is an approximator of O and zα ∈ [xi, yi], it holds thatxi+1 ≤ A(xi, yi)1 ≤ O (zα) ≤ xi ∨ O (zα).Since this holds for each O -induction, xi+1 is indeed safely derivable from xi .2. Let (zi)i≤α be an O -induction in xi . From the induction hypothesis, it follows that zα ≤ yi . We show that zα ≤ yi+1by induction on α. Since well-founded inductions are consistent and increasing in precision, it holds that xi ≤ xi+1 ≤yi+1 ≤ yi , hence our claim holds for α = 0 (since z0 = xi ). It is clear that this property is preserved in limit ordinals. Assume it holds for α = j, we show that it also holds for j + 1. We have that xi ≤ z j ≤ yi . Since A is an approximator of O ,O (z j) ∈ A(z j, z j) ≥p A(xi, yi) ≥p (xi+1, yi+1).Hence, it follows that O (z j) ≤ yi+1. Thus also z j+1 ≤ z j ∨ O (z j) ≤ yi+1 and indeed, the claim follows.Second, assume that xi+1 = xi and A(xi, yi+1)2 ≤ yi+1 ≤ yi .1. The first claim is trivial since xi+1 = xi .2. Let (z j) j≤α be an O -induction in xi . From the induction hypothesis, it follows that zα ≤ yi . We show that zα ≤ yi+1by induction on α. Since well-founded inductions are consistent and increasing in precision, it holds that xi ≤ xi+1 ≤yi+1 ≤ yi , hence our claim holds for α = 0 (since z0 = xi ). It is clear that this property is preserved in limit ordinals. Assume it holds for α = j, we show that it also holds for j + 1. We have that xi ≤ z j ≤ yi+1. Since A is an approximator of O ,O (z j) ∈ A(z j, z j) ≥p A(xi, yi+1).Hence O (z j) ≤ A(xi, yi+1)2 ≤ yi+1. Since also z j ≤ yi+1, it follows that z j+1 ≤ z j ∨ O (z j) ≤ yi+1 and indeed, the claim follows. (cid:2)Proof of Theorem 6.1. Let z denote the safely defined point of O and let (xβ , yβ ) denote the A-well-founded fixpoint of O . For any terminal A-well-founded induction (xi, yi)i≤β , it holds that xβ ≤ z by the first point of Proposition 6.2. Furthermore, by the second point of Proposition 6.2 it holds that any O -induction stays under yβ ; hence z ≤ yβ . (cid:2)Example 6.3 (Example 3.9 continued). In this example, the well-founded model is ({p}, {p}), i.e., it is two-valued. It follows immediately from Theorem 6.1 that in this case safe(T P ) = {p} as well. (cid:2)Example 6.4. Consider a logic program⎧⎨P =⎩⎫⎬⎭pq ← ¬r ∧ pr ← ¬q ∧ p178B. Bogaerts et al. / Artificial Intelligence 259 (2018) 167–185The (cid:9)P -well-founded model of P is ({p}, {p, q, r}). In this case, the only safe-terminal strict induction is(∅, {p}).Indeed, from {p}, the interpretations {p, q}, {p, r}, and {p, q, r} are derivable, but none of them is safely derivable. Hence, the operator T P is not complete. (cid:2)Example 6.5. Consider a logic program(cid:2)P =(cid:3)p ← pp ← ¬pIn this case, the (cid:9)P -well-founded model of P is (∅, {p}). This is not two-valued. The safely defined point by T P is {p}since(∅, {p})is a safe-terminal T P induction. Hence, the operator T P is complete. (cid:2)Theorem 6.1 has several consequences.Corollary 6.6. If the A-well-founded fixpoint of O is exact, i.e., equal to (x, x) for some x ∈ L, then O is complete and safe(O ) = x.The converse of Corollary 6.6 does not hold: it can be the case that O is complete while the A-well-founded fixpoint is not exact. This can be seen, e.g., in Example 6.11.Corollary 6.7. Let O be an operator and A an approximator of O . The A-Kripke–Kleene fixpoint of O approximates the safely defined point by O .Corollary 6.8. If the A-Kripke–Kleene fixpoint of O is exact, i.e., equal to (x, x) for some x ∈ L, then O is complete and safe(O ) = x.Safe O -inductions identify a unique lattice point of interest. Since an operator can have multiple stable fixpoints, we cannot expect a strong link between the safely defined point and stable fixpoints. However, we do find the following relation between stable fixpoints and O -inductions.Theorem 6.9. Let A be an approximator of O . If x is an A-stable fixpoint of O , then x is the limit of a terminal O -induction.Proof. If x is an A-stable fixpoint of O , then x = lfp( A(·, x)1). Consider the sequence (xi)i≤α given byx0 = ⊥,xi+1 = A(xi, x)1,xλ = lub({xi | i < λ}), for limit ordinals λ.If α is large enough, it holds that x = xα . We claim that (xi)i≤α is an O -induction. First, since A(·, x)1 is monotone, xi+1 ≥ xifor each i. Second, notice that for each i, xi ≤ x, hence xi ∈ [xi, x] and thus O (xi) ∈ A(xi, x), i.e., O (xi) ≥ A(xi, x)1. From this we conclude that xi+1 ≤ O (xi) ≤ O (xi) ∨ xi . Thus (xi)i≤α is indeed an O -induction. It is terminal since x is a fixpoint of O . (cid:2)Example 6.10. Consider the logic program(cid:2)P =(cid:3)p ← ¬qq ← ¬pIt holds that {p} is a stable model of P (i.e., a (cid:9)P -stable fixpoint of T P ). Also, {p} is the limit of the T P -induction (∅, {p}). This induction is not safe since (∅, {q}) is also a T P -induction and {p} (cid:9)≤ T P ({q}) ∨ ∅ = {q}. (cid:2)The limit of a terminal O induction is not always a stable fixpoint of O . In fact, the example below shows that there exist safe inductions such that the limit is not A-stable for any approximator of O .B. Bogaerts et al. / Artificial Intelligence 259 (2018) 167–185179Example 6.11. Consider the logic program⎧⎪⎪⎨⎪⎪⎩p ← pp ← qq ← ¬pq ← q⎫⎪⎪⎬⎪⎪⎭P =In this case (∅, {q}, {q, p}) is the unique terminal T P -induction. It can be verified that this is a safe induction and that T Pis complete. The safely defined point is a non-minimal fixpoint of T P , hence it is also non-grounded (see [4]) and not an A-stable fixpoint for any approximator A of T P . In the well-founded model of P , all atoms are unknown. (cid:2)While Theorem 6.1 shows that the relation between safe inductions and the well-founded fixpoint is strong, Example 6.11shows that the connection with the other fixpoints defined in AFT is weaker.7. Safe inductions and autoepistemic logicRecently, Bogaerts et al. [5] exposed a problem in several semantics of autoepistemic logic (AEL). They showed that for very simple, stratified theories, the well-founded and other semantics fail to identify the intended model. They solved this problem by defining, algebraically, a new constructive semantics that is based on a refined notion of approximations of a lattice point (more refined than intervals, i.e., elements of L2). In this section, we show that safe inductions provide a direct solution to the aforementioned problem without the need for any approximation. First, we recall some background on AEL.7.1. AFT and autoepistemic logicAEL is a non-monotonic logic for modeling the beliefs or knowledge of a rational agent with perfect introspection capa-bilities [26].Let L be the language of propositional logic based on a set of atoms (cid:4). Extending this language with a modal operator K , which is read “I (the agent) know”,2 yields a language LK of modal propositional logic. An autoepistemic theory is a set of formulas in LK . A crucial assumption about such theories that distinguishes this logic from the standard modal logic S5 is that all of the agent’s knowledge is encoded in the theory: it either belongs to the theory, or can be derived from it. Levesque [22] called this the “all I know assumption”.A modal formula is a formula of the form K ψ ; an objective formula is a formula without modal subformulas. If ϕ is a formula, At(ϕ) denotes the set of all atoms that occur in ϕ and At O (ϕ) the set of all atoms that occur objectively in ϕ, i.e., outside of the scope of an operator K .An interpretation is a subset of (cid:4). A possible world structure is a set of interpretations. A possible world structure can be seen as a Kripke structure in which the accessibility relation is total. The set of all possible world structures is denoted W(cid:4); it forms a lattice with the knowledge order ≤k such that Q ≤k Q. A possible world structure Q is a mathematical object to represent all situations that are possible according to the agent: interpretations q ∈ Q represent possible states of affairs, i.e., states of affairs consistent with the agent’s knowledge, and interpretations q /∈ Q represent impossible states of affairs, i.e., states of affairs that violate the agent’s knowledge.iff Q ⊇ Q(cid:19)(cid:19)If ϕ is a formula in LK , Q is a possible world structure and I is an interpretation, satisfaction of ϕ with respect to Qand I (denoted Q , I |= ϕ) is defined as in the modal logic S5 by the standard recursive rules of propositional satisfaction augmented with one additional rule:Q , I |= K ϕ if Q , I(cid:19) |= ϕ for every I(cid:19) ∈ Q .In this formula, Q represents the belief of the agent and I represents the actual state of the world. Modal formulas are evaluated with respect to the agent’s belief, while objective formulas are evaluated with respect to the actual state of the world. We furthermore define Q |= K ϕ (ϕ is known in Q ) if Q , I |= ϕ for every I ∈ Q . Moore [26] associated with every theory T an operator DT on W(cid:4) as follows:DT (Q ) = {I ∈ W(cid:4) | Q , I |= T }.The intuition behind this operator is that DT (Q ) is a revision of Q consisting of all worlds that are consistent with the agent’s current beliefs ( Q ) and the constraints in T .DMT [11] defined approximators for DT and showed that AFT induces all main and some new semantics for AFT.2 Or, following DMT [13]: “My knowledge entails”.180B. Bogaerts et al. / Artificial Intelligence 259 (2018) 167–185Monotonically stratified AEL theories. Following Vennekens et al. [34], we call an autoepistemic theory T stratifiable3 w.r.t. a partition ((cid:4)i)0≤i≤n of its alphabet if there exists a partition (Ti)0≤i≤n of T such that for each i, At O (Ti) ⊆ (cid:4)i and At(Ti) ⊆(cid:17)0≤ j≤i (cid:4) j . This notion of stratification significantly extends the notion from Marek and Truszczy ´nski [24]. A stratification is modally separated if for every modal subformula K ψ of Ti , either At(ψ) ⊆ (cid:4)i or At(ψ) ⊆(cid:17)0≤ j<i (cid:4) j .Let (cid:4)1 and (cid:4)2 be two disjoint vocabularies. If Q 1 and Q 2 are possible world structures over (cid:4)1 and (cid:4)2 respectively, then def= {I1 ∪ I2 | I1 ∈ Q 1 ∧ I2 ∈ Q 2}. the extension of Q 1 by Q 2 is the possible world structure over (cid:4)1 ∪ (cid:4)2 defined as Q 1 ⊕ Q 2If Q is a possible world structure over (cid:4)1 ∪ (cid:4)2, the restriction of Q to (cid:4)1 is Q |(cid:4)1def= {I ∩ (cid:4)1 | I ∈ Q }.DMT [13] have made strong arguments in favor of a constructive semantics for AEL. Bogaerts et al. [5], however, showed that the two constructive semantics induced by AFT (well-founded and Kripke–Kleene semantics) are too weak for AEL. They gave the following example.Example 7.1. Consider the autoepistemic theoryT = {q ⇔ ¬K p, r ⇔ ¬K q}.The informal reading of this theory is as follows:“I (an introspective autoepistemic agent) only know the following: q holds iff I do not know p and r holds iff I do not know q.”Since p does not occur objectively in T , an agent who only knows T does not have any information about p. Thus, in the intended model, it knows neither p nor ¬p, i.e., ¬K p and ¬K ¬p must hold in the intended model. The first sentence then entails q, hence K q must hold. Now, the last sentence implies ¬r; the intended model is thus {{p, q}, {q}}, the unique possible world structure in which ¬K p, ¬K ¬p, K q, and K ¬r hold. (cid:2)Bogaerts et al. [5] showed that the well-founded semantics (for any approximator) fails to identify the intended model in the above example. They generalized this example to the class of monotonically stratified theories and defined a notion of perfect model for them.Definition 7.2. We say that T is monotonically stratified with respect to a partition ((cid:4)i)0≤i≤n of its alphabet if there is a modally separated stratification (Ti)0≤i≤n of T such that all subformulas K ψ of Ti with At(ψ) ⊆ (cid:4)i occur negatively (in the scope of an odd number of negations) in Ti .The construction of the perfect model of an autoepistemic theory is as follows. In a monotonically stratified theory, each theory Ti defines knowledge of the symbols in (cid:4)i in terms of knowledge of symbols in lower strata ((cid:4) j with j < i). is The last condition of Definition 7.2 guarantees that for a fixed interpretation of the knowledge of lower strata, DTia monotone operator and hence its intended fixpoint is clear. The perfect model of T is then constructed by iterated monotone inductions, each of them computing the knowledge of symbols in (cid:4)i based on the knowledge of symbols in lower strata. In the example above, first ignorance of p is established; next, knowledge of q is established and in the final stage, knowledge of ¬r is concluded. This construction was formalized as follows.Proposition 7.3 (Proposition 3.3 from Bogaerts et al. [5]). Let (Ti)0≤i≤n be a monotonic stratification of T w.r.t. ((cid:4)i)0≤i≤n. For some i, let Q i−1 be a possible world structure over : Q (cid:21)→ DTi (Q ⊕ Q i−1)|(cid:4)i is monotone.j<i (cid:4) j . The operator D i : W(cid:4)i→ W(cid:4)i(cid:17)Definition 7.4. Let T be a monotonically stratified autoepistemic theory and (Ti)0≤i≤n a monotonic stratification of T . The perfect model of T (denoted pm(T )) is defined by induction on n.• If n = 0, then DT is monotone and the perfect model of T is the least fixpoint of DT .• Otherwise, let Q n−1 denote pm(T j) and let Dn be as in Proposition 7.3; in this case we define pm(T ) as (cid:17)j<nlfp(Dn) ⊕ Q n−1.In general, the construction of the perfect model may not always work as expected. Bogaerts et al. [5] defined a criterion that guarantees that this construction behaves nicely, called weak permaconsistency.Definition 7.5. An autoepistemic theory T is called weakly permaconsistent if for every possible world structure Q , there is at least one I such that Q , I |= T .3 As mentioned in the introduction, we restrict to finite stratifications here.B. Bogaerts et al. / Artificial Intelligence 259 (2018) 167–185181This resulted in a “sanity criterion” for semantics of autoepistemic logic as follows.Definition 7.6. We say that a semantics for autoepistemic logic respects stratification if all weakly permaconsistent monoton-ically stratified theories have exactly one model, namely their perfect model.7.2. AEL and safe inductionsHere, we show that the safely defined point of DT manages to identify the fixpoint of interest for Example 7.1 and that this result generalizes: the safely defined semantics (defined formally below) respects stratification. This result shows that safe inductions can identify the perfect model, without prior information on the stratification and without the need for any form of approximation. Even stronger, the perfect model construction is a terminal safe induction.Definition 7.7. The safely defined semantics is given by Q |=sd T if Q = safe(DT ) and DT is complete.The condition that DT is complete has as effect here that the safely defined model of T must be a fixpoint of DT . In other words, the knowledge of the agent must be such that it can no longer be revised by the revision operator.(cid:9)|= K p and Q iExample 7.8 (Example 7.1 continued). A first observation is that there are no possible world structures Q such that DT (Q ) |= K p or DT (Q ) |= K ¬p. Hence, if N = (Q i)i≤β is a DT -induction in ⊥ = 2, it also has the property (cid:9)|= K ¬p for each i. For each Q i , it then holds that DT (Q i) |= K q. From this it follows that that Q idef= {{p, q}, {q}, {p, q, r}, {q, r}}, the ≤k-least possible world structure in which K q holds, is safely derivable from ⊥. Now, Q qfor every possible world structure Q ≥k Q q, it holds that DT (Q ) |= K ¬r. Thus, this also holds for all possible world struc-tures in a DT -induction from Q q. Hence, it follows that {{p, q}, {q}} is safely derivable from Q q. Since this is a fixpoint of DT , the safe DT -induction{p,q,r}(⊥, Q q, {{p, q}, {q}})is terminal and hence also safe-terminal. Thus, the perfect model of T is indeed the safely defined point by DT . (cid:2)We now show that the above example is not a coincidence, i.e., that it generalizes to the class of monotonically stratified theories.Theorem 7.9. The safely defined semantics respects stratification. That is: for each monotonically stratified theory T : if T is weakly permaconsistent, then DT is complete and safe(DT ) is the perfect model of T .The proof of this theorem makes use of the following two results.Lemma 7.10. Suppose (Ti)0≤i≤n is a monotone stratification of T w.r.t. ((cid:4)i)0≤i≤n. Let (cid:4)(cid:19)world structure Q it holds that(cid:17)i denote j≤i (cid:4) j for each i. For every possible DT (Q ) =DTi (Q |)|(cid:4)i .(cid:4)(cid:19)i(cid:18)0≤i≤nProof. For every interpretation it holds that I ∈ DT (Q ) if and only ifQ , I |= T .Since (Ti)0≤i≤n is a partition of T , this condition is equivalent withQ , I |= Ti for each i.To evaluate whether Q , I |= Ti , objective atoms are evaluated with respect to I , and modal atoms with respect to Q . Since all objective atoms in Ti are over (cid:4)i and all modal atoms in Ti are over (cid:4)(cid:19)i , the previous condition is equivalent withQ |, I|(cid:4)iHence, for each i,(cid:4)(cid:19)i|= Ti for each i.= DTi (Q |DT (Q )|(cid:4)iand the result follows. (cid:2))|(cid:4)i(cid:4)(cid:19)i182B. Bogaerts et al. / Artificial Intelligence 259 (2018) 167–185Lemma 7.11. Suppose T is monotonically stratified w.r.t. ((cid:4)i)0≤i≤n. Furthermore suppose T is weakly permaconsistent. Let (cid:4)(cid:19)(cid:17)j≤i (cid:4)i for each i. If Q 1 and Q 2 are two possible world structures such that Q 1|(cid:4)(cid:19)i= Q 2|(cid:4)(cid:19)i, then also DT (Q 1)|= DT (Q 2)|(cid:4)(cid:19)ii denote .(cid:4)(cid:19)iProof. This is proven as part of Theorem 6.3 by Bogaerts et al. [5]. (cid:2)Lemma 7.10 shows how DT is composed from the various DTi . Lemma 7.11 states that if two possible world structures agree on the lower strata, then so does their image under DT for any weakly permaconsistent theory T . In other words: the knowledge of symbols in a given stratum in DT (Q ) only depends on the knowledge of symbols of smaller (or equal) strata in Q .Proof of Theorem 7.9. In this proof, we will use the following notation. If (cid:4)(cid:19) ⊆ (cid:4) and Qover (cid:4)(cid:19)(cid:19)(cid:27) to denote the ≤k-least possible world structure Q over (cid:4) such that Q |(cid:4)(cid:19) = Q, we use (cid:26)Qis a possible world structure . It is easy to see that(cid:19)(cid:19)(cid:14)(cid:26)Q(cid:19)(cid:27) ={Q | Q |(cid:4)(cid:19) = Q(cid:19)} = Q(cid:19) ⊕ ⊥|(cid:4)\(cid:4)(cid:19) .Let (Ti)0≤i≤n be a monotonic stratification of T with respect to ((cid:4)i)0≤i≤n. Furthermore, let (cid:4)(cid:19)We will prove the following claim by induction on i.i denote (cid:17)j≤i (cid:4) j for each i. Claim: for each i, there exists a safe DT -induction N = (Q j) j≤β in ⊥ such that(cid:19)Q β = (cid:26)pm({Tk | k ≤ i})(cid:27).Taking i = n, the theorem easily follows from the claim. Indeed, the claim then yields that(cid:19)Q β = (cid:26)pm({Tk | k ≤ n})(cid:27) = (cid:26)pm(T )(cid:27) = pm(T ),i.e., that there exists a safe induction that has pm(T ) as limit. Since the perfect model of T is always a fixpoint of DT , the aforementioned safe-induction is terminal and DT is indeed complete.We now show that the claim indeed holds. The claim is trivial for the empty theory (i = −1). Assuming it holds for i < n, we show that it holds as well for i + 1. Let N = (Q j) j≤β be a safe DT -induction in ⊥ such that(cid:19)Q β = (cid:26)pm({Tk | k ≤ i})(cid:27).Consider the sequence (Q(cid:19)k)k≤α given byQQ(cid:19)0(cid:19)λ= Q β ,(cid:13)=Qk<λ(cid:19)k for limit ordinals λ < α,Q(cid:19)k+1= (cid:26)DT (Q k)|(cid:4)(cid:19)i+1(cid:27) for each k < α.From Lemma 7.10, it follows thatQ(cid:19)k+1= (cid:26)DT (Q k)|(cid:17)= (cid:26)D(cid:4)(cid:19)T j (Q k)|i+1(cid:27)j≤i(cid:4)(cid:19)iSince Q β |(cid:4)(cid:19)iis the perfect model of ⊕ DTi+1 (Q k)|(cid:4)i+1(cid:27).(cid:17)T j we then find thatj≤iQ(cid:19)k+1= (cid:26)Q β |(cid:4)(cid:19)i⊕ DTi+1 (Q k)|(cid:4)i+1(cid:27).Or, using D i as defined in Proposition 7.3, we find thatQ(cid:19)k+1= (cid:26)Q β |(cid:4)(cid:19)i⊕ D i+1(Q k|(cid:4)i+1 )(cid:27).Hence, for sufficiently large α, we find that Q1. (Q2. (Q(cid:19)k)k≤α is a DT -induction in Q β , and(cid:19)k)k≤α is safe.(cid:17)= (cid:26)pm((cid:19)α{Tk | k ≤ i + 1})(cid:27). What remains to prove is thatB. Bogaerts et al. / Artificial Intelligence 259 (2018) 167–185183The fact (1), that it is a DT -induction in Q β , follows easily from the fact that for every possible world structure Q , (cid:26)Q |(cid:4)(cid:19) (cid:27) ≤k Q . Hence,Q(cid:19)k+1= (cid:26)DT (Q k)|≤k DT (Q k).(cid:27)(cid:4)(cid:19)i+1(cid:19)k)k≤α is a safe DT -induction, take any DT -induction (QTo see that (2) holds, i.e., that (Q|(cid:4)(cid:19)i= Q β . This claim clearly holds for j = 0 since Q(cid:19)(cid:19)l= Q β as well. Hence, it also holds for l + 1. Similarly, we find that Qthat for each l, Q(cid:19)(cid:19)l )|(cid:4)ithat DT (Qdefined in Proposition 7.3 is a monotone operator, we thus find that Qwe find that Qfor each l. Taking l = γ , we find that (Q(cid:19)k)k≤α is indeed safe. (cid:2)(cid:19)(cid:19)(cid:19)k. First we claim l )l≤γ in Q(cid:19)k. If it holds for l, from Lemma 7.11, it follows (cid:19)|(cid:4)i+1 . Since each D i as k(cid:27), = (cid:26)Q(cid:19)(cid:19)≥k Ql. Furthermore, since Q≤k Q≤k Q|(cid:4)i+1= Q(cid:19)(cid:19)l(cid:19)(cid:19)l(cid:19)(cid:19)0(cid:4)(cid:19)(cid:4)(cid:19)(cid:4)(cid:19)i+1i+1i+1(cid:19)k(cid:19)k(cid:19)k(cid:19)k|||8. Safe inductions and argumentation frameworksAbstract argumentation frameworks (AFs) [17] are simple and abstract systems to deal with contentious information and draw conclusions from it. An AF is a directed graph where the nodes are arguments and the edges encode a notion of attack between arguments. In AFs, we are not interested in the actual content of arguments; this information is abstracted away. In spite of their conceptual simplicity, there exist many different semantics with different properties in terms of characterization, existence and uniqueness.Recently, Strass [30] showed that many of the existing semantics of AFs (and, as a generalization, also of abstract dialec-tical frameworks (ADFs) [8,7]) can be obtained by a direct application of AFT. In this section we use the aforementioned study to relate safe inductions to AFs.An abstract argumentation framework (cid:11) is a directed graph ( A, R) in which the nodes A represent arguments and the edges in R represent attacks between arguments. We say that a attacks b if (a, b) ∈ R. A set S ⊆ A attacks a if some s ∈ Sattacks a. A set S ⊆ A defends a if it attacks all attackers of a. An interpretation of an AF (cid:11) = ( A, R) is a subset S of A. The intended meaning of such an interpretation is that all arguments in S are accepted (or believed) and all arguments not in S are rejected. Interpretations are ordered according to the acceptance relation: S 1 ≤ S2 iff S1 ⊆ S2, i.e., if S2 accepts more arguments than S1. There exist many different semantics of AFs which each define different sets of acceptable arguments according to different standards or intuitions. The major semantics for argumentation frameworks can be formulated using two operators: the characteristic function F (cid:11), which maps an interpretation S toF (cid:11)(S) = {a ∈ A | S defends a}and the operator U (cid:11) (U stands for unattacked), which maps an interpretation S toU (cid:11)(S) = {a ∈ A | a is not attacked by S}.An interpretation S is conflict-free if it is a postfixpoint of U (cid:11) (S ≤ U (cid:11)(S)), i.e., if no argument in S is attacked by S. The characteristic function is a monotone operator; its least fixpoint is called the grounded extension of (cid:11). The operator U (cid:11) is an anti-monotone operator; its fixpoints are called stable extensions of (cid:11). Many more semantics, such as admissible interpretations, complete extensions, semi-stable extensions, stage extensions and preferred extensions [17] can be characterized using the above operators as well.The following theorem shows that the grounded extensions as defined in argumentation theory have very close ties to safe inductions.Theorem 8.1. Let (cid:11) be an argumentation framework. The following are all equal• the grounded extension of (cid:11),• the safely defined point by F (cid:11),• the safely defined point by U (cid:11).Proof. Since the grounded extension of (cid:11) is the least fixpoint of F (cid:11), it follows from Proposition 3.25 that the first two are = F (cid:11); the result then equal. To see that the last two are equal, we claim that U (cid:11) is an anti-monotone operator with U 2(cid:11)follows from Proposition 3.26.To see that our claim holds, notice that a ∈ F (cid:11)(S) if and only if S defends a. This holds if and only if S attacks all (cid:11)(S), attackers of a, i.e., if for all attackers b of a, b /∈ U (cid:11)(S). This holds iff a is not a is not attacked by U (cid:11)(S), i.e., iff a ∈ U 2which is what we needed to show. (cid:2)184B. Bogaerts et al. / Artificial Intelligence 259 (2018) 167–185Example 8.2. Consider the following framework:eacbdIn this example a is unattacked, hence we expect it to be accepted; b is attacked by a, hence should not be accepted. The argument e is defended by a, hence can safely be accepted. c and d mutually attack each other and hence, defend themselves. Since we have already established that b is rejected, the only remaining argument that defends c is c itself. The grounded extension rejects self-defending arguments (i.e., rejects both c and d); it is {a, e}. The grounded extension is the limit of the following induction (that is both a safe F (cid:11)- and a safe U (cid:11)-induction):(∅, {a}, {a, e}).(cid:2)9. ConclusionIn this paper, we presented the notions of O -inductions and safe O -inductions for a lattice operator O . We studied how they relate to various fixpoints of O studied in AFT. We studied the semantics induced by these concepts in the context of autoepistemic logic, where we find that the safely defined point has interesting properties for a class of operators. We applied our theory to Dung’s argumentation frameworks, where we found that for two existing operators, safe inductions yield the same (existing) semantics. It is a topic of future work to study the semantics induced by safe inductions for other application domains of AFT, such as abstract dialectical frameworks [8] and active integrity constraints [19,3].For the latter, we conjecture that safe inductions will prove helpful to tackle the problems with the well-founded se-mantics such as Example 18 of Cruz-Filipe [9].AcknowledgementsThis work was supported by the KU Leuven under project GOA 13/010 and by the Research Foundation – Flanders (FWO-Vlaanderen). Bart Bogaerts is a postdoctoral fellow of the Research Foundation – Flanders (FWO).References[1] C. Antic, T. Eiter, M. Fink, Hex semantics via approximation fixpoint theory, in: P. Cabalar, T.C. Son (Eds.), Logic Programming and Nonmonotonic Reasoning, 12th International Conference, Proceedings, Corunna, Spain, September 15–19, 2013, in: LNCS, vol. 8148, Springer, 2013, pp. 102–115, https://doi .org /10 .1007 /978 -3 -642 -40564 -8 _11.[2] K.R. Apt, H.A. Blair, A. Walker, Towards a theory of declarative knowledge, in: [25], 1988, pp. 89–148.[3] B. Bogaerts, L. Cruz-Filipe, Fixpoint semantics for active integrity constraints, Artif. Intell. 255 (2018) 43–70, https://doi .org /10 .1016 /j .artint .2017.11.003.[4] B. Bogaerts, J. Vennekens, M. Denecker, Grounded fixpoints and their applications in knowledge representation, Artif. Intell. 224 (2015) 51–71, https://[5] B. Bogaerts, J. Vennekens, M. Denecker, On well-founded set-inductions and locally monotone operators, ACM Trans. Comput. Log. 17 (4) (Sep. 2016) doi .org /10 .1016 /j .artint .2015 .03 .006.27, pp. 1–32, http://doi .acm .org /10 .1145 /2963096.[6] B. Bogaerts, J. Vennekens, M. Denecker, Safe inductions: an algebraic study, in: [29], 2017, pp. 859–865, https://doi .org /10 .24963 /ijcai .2017 /119.[7] G. Brewka, H. Strass, S. Ellmauthaler, J.P. Wallner, S. Woltran, Abstract dialectical frameworks revisited, in: F. Rossi (Ed.), IJCAI 2013, Proceedings of the 23rd International Joint Conference on Artificial Intelligence, Beijing, China, August 3–9, 2013, IJCAI/AAAI, 2013, pp. 803–809, http://www.aaai .org /ocs /index .php /IJCAI /IJCAI13 /paper /view /6551.[8] G. Brewka, S. Woltran, Abstract dialectical frameworks, in: F. Lin, U. Sattler, M. Truszczy ´nski (Eds.), Principles of Knowledge Representation and Reason-ing: Proceedings of the Twelfth International Conference, KR 2010, Toronto, Ontario, Canada, May 9–13, 2010, AAAI Press, 2010, pp. 102–111, http://aaai .org /ocs /index .php /KR /KR2010 /paper /view /1294.[9] L. Cruz-Filipe, Grounded fixpoints and active integrity constraints, in: M. Carro, A. King, M. De Vos, N. Saeedloei (Eds.), Technical Communications of the 32nd International Conference on Logic Programming, ICLP 2016 TCs, October 16–21, 2016, New York City, USA, in: OASIcs, vol. 52, Schloss Dagstuhl, Nov. 2016, pp. 11:1–11:14, https://doi .org /10 .4230 /OASIcs .ICLP.2016 .11.[10] M. Denecker, V. Marek, M. Truszczy ´nski, Approximations, stable operators, well-founded fixpoints and applications in nonmonotonic reasoning, in: J. Minker (Ed.), Logic-Based Artificial Intelligence, in: The Springer International Series in Engineering and Computer Science, vol. 597, Springer US, 2000, pp. 127–144, https://doi .org /10 .1007 /978 -1 -4615 -1567 -8 _6.[11] M. Denecker, V. Marek, M. Truszczy ´nski, Uniform semantic treatment of default and autoepistemic logics, Artif. Intell. 143 (1) (2003) 79–122, https://doi .org /10 .1016 /S0004 -3702(02 )00293 -X.[12] M. Denecker, V. Marek, M. Truszczy ´nski, Ultimate approximation and its application in nonmonotonic knowledge representation systems, Inf. Comput. 192 (1) (Jul. 2004) 84–121, https://lirias .kuleuven .be /handle /123456789 /124562.[13] M. Denecker, V. Marek, M. Truszczy ´nski, Reiter’s default logic is a logic of autoepistemic reasoning and a good one, too, in: G. Brewka, V. Marek, M. Truszczy ´nski (Eds.), Nonmonotonic Reasoning – Essays Celebrating Its 30th Anniversary, College Publications, 2011, pp. 111–144, http://arxiv.org /abs /1108 .3278.[14] M. Denecker, J. Vennekens, Well-founded semantics and the algebraic theory of non-monotone inductive definitions, in: C. Baral, G. Brewka, J.S. Schlipf (Eds.), LPNMR, in: Lecture Notes in Computer Science, vol. 4483, Springer, 2007, pp. 84–96, https://doi .org /10 .1007 /978 -3 -540 -72200 -7 _9.[15] M. Denecker, J. Vennekens, The well-founded semantics is the principle of inductive definition, revisited, in: C. Baral, G. De Giacomo, T. Eiter (Eds.), KR, AAAI Press, 2014, pp. 1–10, http://www.aaai .org /ocs /index .php /KR /KR14 /paper /view /7957.[16] M. Denecker, J. Vennekens, B. Bogaerts, A logical study of some common principles of inductive definition and its implications for knowledge repre-sentation, CoRR, arXiv:1702 .04551, 2017, http://arxiv.org /abs /1702 .04551.B. Bogaerts et al. / Artificial Intelligence 259 (2018) 167–18518500330 -3.[17] P.M. Dung, On the acceptability of arguments and its fundamental role in nonmonotonic reasoning, logic programming and n-person games, Artif. Intell. 77 (2) (1995) 321–357, https://doi .org /10 .1016 /0004 -3702(94 )00041 -X.[18] M. Fitting, Fixpoint semantics for logic programming — a survey, Theor. Comput. Sci. 278 (1–2) (2002) 25–51, https://doi .org /10 .1016 /S0304 -3975(00 )[19] S. Flesca, S. Greco, E. Zumpano, Active integrity constraints, in: E. Moggi, D.S. Warren (Eds.), Proceedings of the 6th International ACM SIGPLAN Conference on Principles and Practice of Declarative Programming, 24–26 August, 2004, Verona, Italy, ACM, 2004, pp. 98–107, http://doi .acm .org /10 .1145 /1013963 .1013977.[20] M. Gelfond, V. Lifschitz, The stable model semantics for logic programming, in: R.A. Kowalski, K.A. Bowen (Eds.), ICLP/SLP, MIT Press, 1988, pp. 1070–1080, http://citeseer.ist .psu .edu /viewdoc /summary ?doi =10 .1.1.24 .6050.[21] S.C. Kleene, On notation for ordinal numbers, J. Symb. Log. 3 (4) (1938) 150–155, http://www.jstor.org /stable /2267778.[22] H.J. Levesque, All I know: a study in autoepistemic logic, Artif. Intell. 42 (2–3) (1990) 263–309, https://doi .org /10 .1016 /0004 -3702(90 )90056 -6.[23] F. Liu, Y. Bi, M.S. Chowdhury, J. You, Z. Feng, Flexible approximators for approximating fixpoint theory, in: R. Khoury, C. Drummond (Eds.), Advances in Artificial Intelligence – 29th Canadian Conference on Artificial Intelligence, Canadian AI 2016. Proceedings, Victoria, BC, Canada, May 31–June 3, 2016, in: Lecture Notes in Computer Science, vol. 9673, Springer, 2016, pp. 224–236, https://doi .org /10 .1007 /978 -3 -319 -34111 -8 _28.[24] V. Marek, M. Truszczy ´nski, Autoepistemic logic, J. ACM 38 (3) (1991) 588–619, https://doi .org /10 .1145 /116825 .116836.[25] J. Minker (Ed.), Foundations of Deductive Databases and Logic Programming, Morgan Kaufmann, 1988.[26] R.C. Moore, Semantical considerations on nonmonotonic logic, Artif. Intell. 25 (1) (1985) 75–94, https://doi .org /10 .1016 /0004 -3702(85 )90042 -6.[27] T.C. Przymusinski, On the declarative semantics of deductive databases and logic programs, in: [25], 1988, pp. 193–216.[28] R. Reiter, A logic for default reasoning, Artif. Intell. 13 (1–2) (1980) 81–132, https://doi .org /10 .1016 /0004 -3702(80 )90014 -4.[29] C. Sierra (Ed.), Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence, IJCAI 2017, August 19–25, 2017, Melbourne, Australia, 2017, ijcai .org, http://www.ijcai .org /Proceedings /2017/.[30] H. Strass, Approximating operators and semantics for abstract dialectical frameworks, Artif. Intell. 205 (2013) 39–70, https://doi .org /10 .1016 /j .artint .2013 .09 .004.321978 .321991.116825 .116838.[31] A. Tarski, A lattice-theoretical fixpoint theorem and its applications, Pac. J. Math. (1955).[32] M.H. van Emden, R.A. Kowalski, The semantics of predicate logic as a programming language, J. ACM 23 (4) (1976) 733–742, https://doi .org /10 .1145 /[33] A. Van Gelder, K.A. Ross, J.S. Schlipf, The well-founded semantics for general logic programs, J. ACM 38 (3) (1991) 620–650, https://doi .org /10 .1145 /[34] J. Vennekens, D. Gilis, M. Denecker, Splitting an operator: algebraic modularity results for logics with fixpoint semantics, ACM Trans. Comput. Log. 7 (4) (2006) 765–797, https://doi .org /10 .1145 /1182613 .1189735.