Artificial Intelligence 289 (2020) 103389Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintReal-time reasoning in OWL2 for GDPR compliancePiero A. Bonatti a,∗Ida R. Siahaan ba Università di Napoli Federico II, Italyb CeRICT, Italy, Luca Ioffredo b, Iliana M. Petrova b, Luigi Sauro a, a r t i c l e i n f oa b s t r a c tArticle history:Received 19 April 2019Received in revised form 31 July 2020Accepted 17 September 2020Available online 18 September 2020Keywords:Tractable OWL2 fragmentsStructural subsumptionImport-by-queryKnowledge compilationSemantic policy languagesGDPRThis paper shows how knowledge representation and reasoning techniques can be used to support organizations in complying with the GDPR, that is, the new European data protection regulation. This work is carried out in a European H2020 project called SPECIAL. Data usage policies, the consent of data subjects, and selected fragments of the GDPR are encoded in a fragment of OWL2 called PL (policy language); compliance checking and policy validation are reduced to subsumption checking and concept consistency checking. This work proposes a satisfactory tradeoff between the expressiveness requirements on PL posed by the modeling of the GDPR, and the scalability requirements that arise from the use cases provided by SPECIAL’s industrial partners. Real-time compliance checking is achieved by means of a specialized reasoner, called PLR, that leverages knowledge compilation and structural subsumption techniques. The performance of a prototype implementation of PLR is analyzed through systematic experiments, and compared with the performance of other important reasoners. Moreover, we show how PL and PLR can be extended to support richer ontologies, by means of import-by-query techniques. We prove novel tractability and intractability results related to PL, and some negative results about the restrictions posed on ontology import.© 2020 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).1. IntroductionThe new European General Data Protection Regulation1 (GDPR), that has come into force on May 25, 2018, places strin-gent restrictions on the processing of personally identifiable data. The regulation applies also to companies and organizations that are not located in Europe, whenever they track or provide services to data subjects that are in the European Union.2 In-fringements may severely affect the reputation of the violators, and are subject to substantial administrative fines (up to 4% of the total worldwide annual turnover or 20 million Euro, whichever is higher). Therefore, the risks associated to infringe-ments constitute a major disincentive to the abuse of personal data. Given that the collection and the analysis of personal data are paramount sources of innovation and revenue, companies are interested in maximizing personal data usage within the limits posed by the GDPR. Consequently, data controllers (i.e. the personal and legal entities that process personal data) are looking for methodological and technological means to comply with the regulation’s requirements efficiently and safely.* Corresponding author.E-mail address: pab@unina.it (P.A. Bonatti).1 http://data .consilium .europa .eu /doc /document /ST-5419 -2016 -INIT /en /pdf.2 Cf. Article 3 of the GDPR.https://doi.org/10.1016/j.artint.2020.1033890004-3702/© 2020 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).P.A. Bonatti, L. Ioffredo, I.M. Petrova et al.Artificial Intelligence 289 (2020) 103389The European H2020 project SPECIAL3 is aimed at supporting controllers in complying with the GDPR. SPECIAL is tackling several hard problems related to usability, transparency and compliance, see [13,9,34] for an overview. In this paper, we focus on SPECIAL’s approach to the representation of data usage activities and consent to data processing, together with the associated reasoning tasks related to the validation of data usage policies and compliance checking.The management of the consent to data processing granted by data subjects plays a central role in this picture. The GDPR is not concerned with anonymous data, nor data that do not describe persons (like astronomical data). The other data (hereafter called personal data) must be processed according to the legal bases provided by the regulation. Some examples of such legal bases include public interest, the vital interests of the data subject, contracts, and the legitimate interests of the data controller, just to name a few.4 These legal bases are constrained by a number of provisos and caveats that restrict their applicability.5 So, in practice, the kinds of personal data processing that are most useful for data-driven business are almost exclusively allowed by another legal basis, namely, the explicit consent of the data subjects.6 Thus, it is important to encode consent appropriately, so as to record it for auditing, and give automated support to compliance checking.Also the controller’s usage of personal data must be appropriately represented and stored, in order to fulfill the obligation to record personal data processing activities,7 and in order to verify that such activities comply with the available consent and with the GDPR.SPECIAL tackles these needs by adopting a logic-based representation of data usage policies, that constitutes a uniform language to encode consent, the activities of controllers, and also selected parts of the GDPR. A logic-based approach is essential for achieving several important objectives, including the following:• strong correctness and completeness guarantees on permission checking and compliance checking;• ensuring the mutual coherence of the different reasoning tasks related to policies, such as policy validation, permission checking, compliance checking, and explanations;• ensuring correct usage after data is transferred to other controllers (i.e. interoperability), through the unambiguous semantics of knowledge representation languages.Some of SPECIAL’s use cases place challenging scalability requirements on reasoning. During the execution of the controllers’ data processing software, each operation involving personal data must be checked for compliance with the consent granted by the data subjects. The frequency of such compliance checks may be significantly high, so SPECIAL needs to implement the corresponding reasoning tasks in such a way that the time needed for each check does not exceed a few hundreds of μ-seconds. For example, here is a real-world scenario provided by SPECIAL’s industrial partners.Streaming Scenario Telecom providers, that nowadays are also Internet providers, receive from their base stations about 15000 call records per second, and receive about 850 millions of probing records per day from their wi-fi network (almost 10000 events per second). The data contained in the aforementioned records are of great interest for strategic applications and services, such as location-based services and taylored recommendations; however, these are personal data, and the European regulations on data protection prohibit the above usage without the data subject’s consent. Without it, even storing the data temporarily, waiting for a batch process to discard the records that cannot be processed, is illegal. Then the description of how each application processes the data and why, that we will call business policy in the following, must be checked in real-time for compliance against the available consent for the record being processed, while the stream of data is generated. The scenario is further complicated by the fact that each data subject can withdraw or modify her consent anytime, and that she may selectively decide to opt in or out each processing option (e.g. a customer might accept only location tracking, and not internet tracking). (cid:2)We address real-time requirements by designing a specialized reasoner for the policy language.After recalling the notions about description logics and their properties, that will be needed in the paper, our contribu-tions will be illustrated in the following order.• Section 3 shows how to encode usage policies and the relevant parts of the GDPR with a fragment of SROIQ(D)(the logical foundation of OWL2-DL). The details of the encoding will be related explicitly to GDPR’s requirements. Afterwards, we formally define PL, that is, the fragment of SROIQ(D) used to encode data usage policies.• Section 4 is devoted to the complexity analysis of reasoning in PL. We consider concept satisfiability and subsump-tion checking, that constitute the core of policy validation and compliance checking. We will show that unrestricted PLsubsumption checking is coNP-complete. However, under a restrictive hypothesis motivated by SPECIAL’s use cases, sub-sumption checking is possible in polynomial time. Tractability is proved by means of a specialized two-stage reasoner 3 https://www.specialprivacy.eu/.4 Cf. Article 6 of the GDPR.5 Of particular relevance here are the data minimization principle introduced in Article 5, and the limitations to the legitimate interests of the controller rooted in Article 6.1(f).6 Article 6.1(a).7 Cf. Article 30 of the GDPR.2P.A. Bonatti, L. Ioffredo, I.M. Petrova et al.Artificial Intelligence 289 (2020) 103389called PLR, based on a preliminary normalization phase followed by a structural subsumption algorithm. A preliminary account of this section has been published in [8].• Section 5 shows how to support richer ontology languages for the description of policy elements. The vocabularies for policy elements are treated like imported ontologies by means of an import by query (IBQ) approach, that can be im-plemented with a modular integration of the specialized reasoner for PL with a reasoner for the imported ontology. We prove that this integration method is correct and complete, and justify the restrictive assumptions on the imported ontologies, by adapting and slightly extending previous results on IBQ limitations. Moreover, we show that under hy-potheses compatible with SPECIAL’s application scenarios, the external ontology can be compiled into a PL ontology, thereby reducing the IBQ approach to plain PL reasoning.• PL subsumption checking is experimentally evaluated in Section 6. After describing the implementation of PLR and its optimizations, PLR’s performance is compared with that of other important engines, such as ELK [33], GraphDB [25], Hermit [23], and RDFox [37]. For this purpose, we use two sets of experiments. The first set is derived from the pilots of SPECIAL that have reached a sufficient development level, namely, a recommendation system based on location data and internet navigation information, designed by Proximus, and a financial risk analysis scenario developed by Thomson Reuters. The second batch of experiments is fully synthetic, instead, and contains increasingly large policies and ontologies, in order to assess the scalability of PLR.Section 7 concludes the paper with a final discussion of our results and interesting perspectives for future work. Related work is heterogeneous (declarative policy languages, legal reasoning, tractable description logics, IBQ methods) so we dis-tribute its discussion across the pertinent sections, rather than in a single dedicated section.2. Preliminaries on description logicsHere we report the basics on the Description Logics (DL) needed for our work and refer the reader to [4] for further details. The DL languages of our interest are built from countably infinite sets of concept names (NC), role names (NR), indi-vidual names (NI), concrete property names (NF), and concrete predicates (NP). For brevity, individual names will sometimes be called constants. A signature (cid:2) is a subset of NC ∪ NR ∪ NI ∪ NF.8We will use metavariables A, B for concept names, C, D for (possibly compound) concepts, R, S for roles, a, b for indi-vidual names, f , g for concrete property names, and p for concrete predicates. Concepts are built from concept names and from the concept constructors listed in Table 1. Similarly, roles are built from role names and from the role constructors listed in Table 1. In the following the term expression refers to both concepts and roles., defined over (cid:2), is such that (i) AAn interpretation I of a signature (cid:2) is a structure I = ((cid:3)I , ·I ) where (cid:3)Iis a nonempty set, and the interpretation function ·Iif a ∈ NI; if A ∈ NC; (ii) RI ⊆ (cid:3)I × (cid:3)D if f ∈ NF, where (cid:3)D denotes the domain of the predicates in NP. The semantics of an n-ary predicate (iv) fp ∈ NP is a set of tuples pD ⊆ ((cid:3)D)n. As usual, the pair ((cid:3)D, NP) is called concrete domain.9 In this paper we use (cid:3)D = Nand unary concrete predicates in(cid:4),u, where (cid:4), u ∈ N, such that inD= [(cid:4), u]. To enhance readability we will abbreviate (cid:4),ubelongs to (∃ f .[(cid:4), u])Iin(cid:4),u( f ) to ∃ f .[(cid:4), u]. So an individual d ∈ (cid:3)IThe third column of Table 1 shows how to extend the valuation ·Iif, for some integer i ∈ [(cid:4), u], (d, i) ∈ fof an interpretation I to compound DL expressions and axioms. GCI stands for “general concept inclusion”. An interpretation I satisfies an axiom α (equivalently, I is a modelof α) if I satisfies the corresponding semantic condition in Table 1. When I satisfies α we write I |= α. We will sometimes use axioms of the form C ≡ D, that are abbreviations for the pair of inclusions C (cid:8) D and D (cid:8) C .if R ∈ NR; (iii) aI ⊆ (cid:3)I × (cid:3)II ⊆ (cid:3)II ∈ (cid:3)IA knowledge base K is a finite set of DL axioms. Its terminological part (or TBox) is the set of terminological axioms10 in I.K, while its ABox is the set of its assertion axioms.If X is a DL expression, an axiom, or a knowledge base, then (cid:2)( X) denotes the signature consisting of all symbols occurring in X , but concrete predicates. An interpretation I of a signature (cid:2) ⊇ (cid:2)(K) is a model of K (in symbols, I |= K) if I satisfies all the axioms in K. We say that K entails an axiom α (in symbols, K |= α) if all the models of K satisfy α. The subsumption problem consists in deciding whether K |= C (cid:8) D for given K, C , and D.A pointed interpretation is a pair (I, d) where d ∈ (cid:3)I. We say (I, d) satisfies a concept C iff d ∈ C. In this case, we write I(I, d) |= C .2.1. The description logics used in this paperThe logic SRIQ supports the SRIQ constructors and axioms illustrated in Table 1. In a SRIQ knowledge base, in order to preserve decidability, the set of role axioms should be regular and the roles S, S 1, S2 simple, according to the definitions stated in [28].11 Horn-SRIQ further restricts SRIQ GCIs as specified in [38]. For simplicity, here we illustrate 8 Concrete predicates are deliberately left out due to their special treatment.9 We are assuming – for brevity – that there is one concrete domain. However, this framework can be immediately extended to multiple domains.10 See Table 1.11 The definitions are omitted because they are not needed in our results.3P.A. Bonatti, L. Ioffredo, I.M. Petrova et al.Artificial Intelligence 289 (2020) 103389Table 1Syntax and semantics of DL constructs and axioms.NameSRIQ concept and role constructors (the latter recognizable by the word “role” in the name)SemanticsSyntax−I }(R ∈ NR)inverse roletopbottomintersectionunioncomplementexistential restrictionuniversal restrictionnumber restrictionsselfAdditional concept and role constructors of SROIQ (D) (the latter with the word “role” in the name){( y, x) | (x, y) ∈ R(cid:10)I = (cid:3)I⊥I = ∅(C (cid:13) D)I = C(C (cid:15) D)I = C(¬C)I = (cid:3)I \ C{d ∈ (cid:3)I | ∃(d, e) ∈ R{d ∈ (cid:3)I | ∀(d, e) ∈ R(cid:2)x ∈ (cid:3)I | #{ y | (x, y) ∈ S{x ∈ (cid:3)I | (x, x) ∈ SR(cid:10)⊥C (cid:13) DC (cid:15) D¬C∃R.C∀R.C(cid:17)(cid:18) n S.C∃S.SelfI }I }I ∧ y ∈ CI : e ∈ CI : e ∈ CI ∩ DI ∪ DII } (cid:17)(cid:18) nI }(cid:3)II((cid:17)(cid:18)=≤, ≥)universal rolenominalsconcrete constraintsSRIQ terminological axiomsU{a}p( f 1, .., fn)GCIrole disjointnesscomplex role inclusionsSRIQ concept and role assertion axiomsC (cid:8) Ddisj(S1, S2)R1 ◦ ... ◦ Rn (cid:8) RI }I = (cid:3)I × (cid:3)I(a ∈ NI)U{a}I = {a{x∈(cid:3)I | ∃(cid:22)v∈((cid:3)D)n. (x, v i ) ∈ fI satisfies the axiom if:I ⊆ DCII= ∅∩ SS12II◦ . . . ◦ RRn1⊆ RIIIi(1 ≤ i ≤ n) and (cid:22)v ∈ pD}conc. assrt.role assrt.C(a)R(a, b)II ∈ Ca(a, b)I ∈ RIOther terminological axioms expressible with the above axioms and used in low-complexity DLsdisjointnessfunctionalityrangedisj(C, D)func(R)range(R, C)CRRI = ∅I ∩ DII ⊆ (cid:3)I × Cis a partial functionITable 2The Horn restriction of SRIQ GCIs (normal form).C1 (cid:13) C2 (cid:8) D∃R.C (cid:8) DC (cid:8) ∀R.DC (cid:8) ∃R.DC (cid:8) ≤ 1 S.DC (cid:8) ≥ n S.DThe above concepts C, C1, C2, D either belong to NC ∪ {⊥, (cid:10)}, or are of the form ∃S.Self. Symbol S de-notes a simple role [28].only the normal form adopted in [39], see Table 2. Like all Horn DLs, Horn-SRIQ is convex, that is, K |= C0 (cid:8) C1 (cid:15) C2 holds iff either K |= C0 (cid:8) C1 or K |= C0 (cid:8) C2denotes the extension of EL+The logic EL is a fragment of Horn-SRIQ that supports only atomic concepts and roles, (cid:10), (cid:13), and existential restric-tions. Supported axioms are GCIs and assertions. We will denote with EL+the extension of EL with ⊥ and range axioms. EL++with nominals, concrete domains, complex role inclusions, and range axioms.12 Sub-sumption checking and consistency checking are tractable in EL and EL+provided that concrete domains have a tractable entailment problem and are convex, in the sense that |= p1((cid:22)f 1) ∨ . . . ∨ pn((cid:22)fn) holds iff |= pi((cid:22)f i)holds for some i ∈ [1, n] [3]. EL++provides the foundation for the OWL2-EL profile.13. The same holds for EL++The logic DL-lite is a fragment of Horn-SRIQ that supports only inverse roles, unqualified existential restrictions (i.e. concepts of the form ∃R.(cid:10)), GCIs and assertions. Moreover, complements (¬) are allowed on the right-hand side of GCIs. HDL-liteR extends DL-lite with role inclusions of the form R (cid:8) S and R (cid:8) ¬S. DL-litehorn extends DL-lite by supporting (cid:13) and role inclusions of the form R1 (cid:8) R2. Subsumption and consistency checking are tractable in both logics. DL-lite constitutes the foundation of the OWL2-QL profile.14The logic SROIQ(D) supports all the constructs and axioms illustrated in Table 1. It is the description logic underlying the standard OWL2-DL.12 Range axioms must satisfy the restrictions described in Sec. 2.2.6 of https://www.w3 .org /TR /owl2 -profiles. We do not need those details in this paper.13 https://www.w3 .org /TR /owl2 -profiles /#OWL _2 _EL.14 https://www.w3 .org /TR /owl2 -profiles /#OWL _2 _QL.4P.A. Bonatti, L. Ioffredo, I.M. Petrova et al.Artificial Intelligence 289 (2020) 103389To fix ideas, in the following two subsections let K range over SROIQ(D) knowledge bases. However, the results and definitions of those subsections hold also for the DLs that are not fragments of SROIQ(D), such as the logic supported by CLASSIC [17] and the DLs with fixpoints [14].2.2. The disjoint model union propertyA knowledge base K such that (cid:2)(K) ∩ NI = ∅ enjoys the disjoint model union property if for all disjoint models I and J of K, their disjoint union I (cid:25) J = (cid:26)(cid:3)I (cid:25) (cid:3)J , ·I(cid:25)J (cid:27) – where Pfor all P ∈ NC ∪ NR ∪ NF – satisfies K, too ([4], Ch. 5). This definition is extended naturally to the union S of an arbitrary set S of disjoint models. The disjoint model union property plays an important role in our results. It is broken by the universal role and nominals. The main problem with nominals (and the reason of the prerequisite (cid:2)(K) ∩ NI = ∅) is that if I and J are disjoint, then for all individual constants a ∈ NI, ashould be. This problem can be resolved for the constants occurring in ABoxes. Informally speaking, it suffices to pick the constants’ interpretation from an arbitrary argument of the union.15, so it is not immediately clear what aI(cid:25)J = P(cid:4)I (cid:25) PI (cid:28)= aI(cid:25)JJJDefinition 2.1 (Generalized disjoint union). For all sets of mutually disjoint interpretations S and all I ∈ S, let interpretation U such that:(cid:5){(cid:3)J | J ∈ S}J | J ∈ S}{P(cid:5)(cid:3)U =U =U = aPaIfor all P ∈ NC ∪ NR ∪ NFfor all a ∈ NI .(cid:4)I S be the If the terminological part of a knowledge base K has the (standard) disjoint model union property, then the generalized union of disjoint models of K is still a model of K:Proposition 2.2. Let K = T ∪ A, where T is the terminological part of K and A is its ABox. If T has the disjoint model union property then for all sets S of mutually disjoint models of K, and for all I ∈ S, (cid:4)I S |= K.(cid:4)I S. Note that (cid:2)(T ) ∩ NI = ∅, otherwise the disjoint union of Proof. Let S and I be as in the statement, and let U =T ’s models would not be defined and T would not enjoy the disjoint model union property, contradicting the hypothesis. For all interpretations J , let J \NI denote the restriction of J to the symbols in NC ∪ NR ∪ NF (i.e. excluding the individual constants in NI). Note that for all J ∈ S, J \NI is a model of T , because (cid:2)(T ) ∩ NI = ∅. Therefore, by hypothesis, {J \NI |(cid:4)I S is a model of T . We are only J ∈ S} is a model of T . Clearly, left to prove that U is a model of A. Consider an arbitrary assertion α ∈ A. Since the models in S are disjoint, and the U ∈ CU , binterpretation of constants in U ranges over (cid:3)I, and I ) ( f ∈ NF). Moreover, I is a model of A by hypothesis. It follows immediately that U is a model of A. (cid:2)U (af(cid:4)I S)\NI; as a consequence, also {J \NI | J ∈ S} = (, it holds that aU ) ∈ RU ) = fI ) ∈ RI ∈ Ciff (aI , biff aI (a, (a(cid:4)(cid:4)UUII2.3. Modularity and localityA knowledge base K is semantically modular with respect to a signature (cid:2) if each interpretation I = ((cid:3)I , ·I ) over (cid:2) can , for all symbols X ∈ (cid:2). Roughly speaking, be extended to a model J = ((cid:3)J , ·J ) of K such that (cid:3)J = (cid:3)Ithis means that K does not constrain the symbols of (cid:2) in any way.J = Xand XA special case of semantic modularity exploited in [21] is locality: A knowledge base K is local with respect to a signature I(cid:2) if the above J can be obtained simply as specified in the next definition.Definition 2.3 (Locality). A knowledge base K is local with respect to a signature (cid:2) if each interpretation I = ((cid:3)I , ·I ) over (cid:2) can be extended to a model J = ((cid:3)J , ·J ) of K by setting XI = ∅ for all concept and role names X ∈ (cid:2)(K) \ (cid:2).Locality will be needed in Section 5, for the integration of PL knowledge bases with imported ontologies. In particular, it is an essential ingredient of the completeness proof for IBQ reasoning.3. Semantic encoding of data usage policiesSPECIAL’s policy language PL – that is a fragment of OWL2-DL – has been designed to describe data usage. Such de-scriptions can be exploited to encode: (i) the consent to data processing given by data subjects, (ii) how the controller’s 15 The following formalization of this idea generalizes a proof technique used in [21, Lemma 1].5P.A. Bonatti, L. Ioffredo, I.M. Petrova et al.Artificial Intelligence 289 (2020) 103389internal processes use data, and (iii) selected parts of the GDPR that can be used to support the validation of the con-troller’s internal processes. Moreover, PL is used to encode the entries of SPECIAL’s transparency ledger, that is a log of data processing operations that can be queried by:• data subjects, in order to monitor how their personal data are used by the controller and where they are transferred to;• data protection officers, in order to audit the behavior of the controller;• the controllers themselves, in order to monitor their own internal processes.The aspects of data usage that have legal relevance are clearly indicated in several articles of the GDPR and in the available guidelines. They are mentioned, for example, in the specification of what is valid consent, what are the legal bases for processing, what are the rights of data subjects, which aspects should be covered by national regulations, and the obligation of controllers to keep a record of the processing operations that involve personal data (see, inter alia, Articles 6.1, 6.3, 6.4, 7, 15.1, 23.2, 23.2, 30.1). See also the section titled “Records should contain” in the guidelines for SMEs published on http://ec .europa .eu /justice /smedataprotect /index _en .htm. That section describes how to fulfill the obligation to record the data subjects’ consent to processing (Article 7) and, in particular, it specifies which pieces of information should be recorded. According to the above sources of requirements, the main properties of data usage that need to be encoded and archived are the following:• reasons for data processing (purpose);• which data categories are involved;• what kind of processing is applied to the data;• which third parties data are distributed to (recipients);• countries in which the data will be stored (location);• time constraints on data erasure (duration).The above properties characterize a usage policy. SPECIAL adopts a direct encoding of usage policies in description logics, based on those features. The simplest possible policies have the form:∃has_purpose.P (cid:13) ∃has_data.D (cid:13) ∃has_processing.O (cid:13) ∃has_recipient.R (cid:13)∃has_storage(∃has_location.L (cid:13) ∃has_duration.T ) .(1)All of the above roles are functional. Duration is represented as an interval of integers [t1, t2], representing a minimum and a maximum storage time (such bounds may be required by law, by the data subject, or by the controller itself). The classes P , D, O , etc. are defined in suitable auxiliary vocabularies (ontologies) that specify also the relationships between different terms. The expressiveness requirements on the vocabularies and their design are discussed later, in Section 5. Until then, the reader may assume that the vocabularies are defined by means of inclusions A (cid:8) B and disjointness constraints disj( A, B), where A, B are concept names. Such restrictions will be lifted later.If the data subject consents to a policy of the form (1), then she authorizes all of its instances. For example if D =DemographicData then the data subject authorizes – in particular – the use of her address, age, income, etc. as specified by the other properties of the policy.It frequently happens that the data controller intends to use different data categories in different ways, according to their usefulness and sensitivity, so consent requests comprise multiple simple usage policies like (1) (one for each usage type). The intended meaning is that consent is requested for all the instances of all those policies; accordingly, such a compound policy is formalized with the union of its components. The result is called full (usage) policy and has the form:P 1 (cid:15) . . . (cid:15) P n(2)where each P i is a simple usage policy of the form (1). Symmetrically, with a similar union, data subjects may consent to different usage modalities for different categories of data and different purposes.Example 3.1. A company – call it BeFit – sells a wearable fitness appliance and wants (i) to process biometric data (stored in the EU) for sending health-related advice to its customers, and (ii) share the customer’s location data with their friends. Location data are kept for a minimum of one year but no longer than 5; biometric data are kept for an unspecified amount of time. In order to do all this legally, BeFit needs consent from its customers. The internal (formalized) description of such consent would look as follows:6P.A. Bonatti, L. Ioffredo, I.M. Petrova et al.Artificial Intelligence 289 (2020) 103389(∃has_purpose.FitnessRecommendation (cid:13)∃has_data.BiometricData (cid:13)∃has_processing.Analytics (cid:13)∃has_recipient.BeFit (cid:13)∃has_storage.∃has_location.EU)(cid:15)(∃has_purpose.SocialNetworking (cid:13)∃has_data.LocationData (cid:13)∃has_processing.Transfer (cid:13)∃has_recipient.DataSubjFriends (cid:13)∃has_storage.(∃has_location.EU (cid:13) ∃has_duration.[ y1, y5]) .(3)Here y1 and y5 are the integer representation of one year and five years, respectively. If “HeartRate” is a subclass of “BiometricData” and “ComputeAvg” is a subclass of “Analytics”, then the above consent allows BeFit to compute the average heart rate of the data subject in order to send her fitness recommendations. BeFit customers may restrict their consent, e.g. by picking a specific recommendation modality, like “recommendation via SMS only”. Then the first line should be replaced with something like ∃has_purpose.(FitnessRecommendation (cid:13) ∃contact.SMS). Moreover, a customer of BeFit may consent to the first or the second argument of the union, or both. Then her consent would be encoded, respectively, with the first argument, the second argument, or the entire concept (3). Similarly, each single process in the controller’s lines of business may use only biometric data, only location data, or both. Accordingly, it may be associated to the first simple policy, the second simple policy, or their union. In other words, (3) models the complete data usage activities related to the wearable device, that may be split across different processes. (cid:2)The usage policies that are actually applied by the data controller’s business processes are called business policies and include a description of data usage of the form (1). Additionally, each business policy is labeled with its legal basis and describes the associated obligations that must be fulfilled. For example, if the data category includes personal data, and processing is allowed by explicit consent, then the business policy should have the additional conjuncts:∃has_legal_basis.Art6_1_a_Consent (cid:13)∃has_duty.GetConsent (cid:13) ∃has_duty.GiveAccess (cid:13)∃has_duty.RectifyOnRequest (cid:13)∃has_duty.DeleteOnRequest(4)that label the policy with the chosen legal basis, and model the obligations related to the data subjects’ rights, cf. Chapter 3 of the GDPR. More precisely, the terms involving has_duty assert that the process modeled by the business policy includes the operations needed to obtain the data subject’s consent (∃has_duty.GetConsent) and those needed to receive and apply the data subjects’ requests to access, rectify, and delete their personal data.Thus, business policies are an abstract description of a business process, highlighting the aspects related to compliance with the GDPR and data subjects’ consent. Similarly to consent, a business policy may be a union BP1 (cid:15) . . . (cid:15) BPn of simple business policies BPi of the form (1) (cid:13) (4).In order to check whether a business process complies with the consent given by a data subject S, it suffices to check whether the corresponding business policy BP is subsumed by the consent policy of S, denoted by CPS (in sym-bols, BP (cid:8) CPS). This subsumption is checked against a knowledge base that encodes type restrictions related to policy properties and the corresponding vocabularies, i.e. subclass relationships, disjointness constraints, functionality restrictions, domain and range restrictions, and the like. Some examples of the actual axioms occurring in the knowledge base are:func(has_purpose)range(has_data, AnyData)Demographic (cid:8) AnyDataUpdate (cid:8) AnyProcessingErase (cid:8) Updatedisj(AnyData, AnyPurpose)(recall that more general knowledge bases will be discussed later).In order to verify that all the required obligations are fulfilled by a business process (as abstracted by the business policy), selected parts of the GDPR are formalized with concepts like the following. The first concept states that a business policy should either support the rights of the data subjects, or concern anonymous data, or it should fall under some of the exceptional cases mentioned by the regulation, such as particular law requirements. The remaining requirements are notlisted here (they are replaced with an ellipsis):(∃has_duty.GetConsent (cid:13) ∃has_duty.GiveAccess (cid:13) . . .) (cid:15)∃has_data.Anonymous (cid:15)∃has_purpose.LawRequirement (cid:15) . . .7(5)P.A. Bonatti, L. Ioffredo, I.M. Petrova et al.Artificial Intelligence 289 (2020) 103389The second example encodes the constraints on data transfers specified in Articles 44–49 of the GDPR:∃has_storage.∃has_location.EU (cid:15)∃has_storage.∃has_location.EULike (cid:15) . . .(6)It states that data should remain within the EU, or countries that adopt similar data protection regulations. The ellipsis stands for further concepts that model the other conditions under which data can be transferred to other nations (e.g. under suitable binding corporate rules). Please note that the above concepts constitute only a largely incomplete illustration of the actual formalization of the GDPR, that is significantly longer due to the special provisions that apply to particular data categories and legal bases. The purpose of the above examples is conveying the flavor of the formalization. Its usage is sketched below.A business policy BP can be checked for compliance with the formalized parts of the GDPR by checking whether the aforementioned knowledge base entails that BP is subsumed by the concepts that formalize the GDPR.Example 3.2. The following business policy complies with the consent-related obligations formalized in (5) since it is sub-sumed by it:(∃has_purpose.FitnessRecommendation (cid:13)∃has_data.BiometricData (cid:13)∃has_processing.Analytics (cid:13)∃has_recipient.BeFit (cid:13)∃has_storage.∃has_location.EU (cid:13)∃has_legal_basis.Art6_1_a_Consent) (cid:13)∃has_duty.GetConsent (cid:13) . . . all the remaining concepts in (4) . . .)(cid:15)(∃has_purpose.Sell (cid:13)∃has_data.Anonymous (cid:13)∃has_processing.Transfer (cid:13)∃has_recipient.ThirdParty) .(7)In particular, the two disjuncts of (7) are subsumed by the first two lines of (5), respectively. Note that the second simple policy does not place any restrictions on location, so it allows data to flow to any country, including those that do not enjoy adequate data protection regulations. However, this is compliant with the GDPR because data are anonymous. (cid:2)The concepts in the range of existential restrictions may themselves be a conjunction of atoms, interval constraints and existential restrictions. We have already seen in policy (3) that has_storage may contain a conjunction of existential restric-tions over properties has_location and has_duration. Another example, related to SPECIAL’s pilots, concerns the accuracy of locations, that can be modeled with concepts like:∃has_data.(Location (cid:13) ∃has_accuracy.Medium) .Based on the above discussion, we are now ready to specify PL (policy logic), a fragment of OWL 2 that covers – and slightly generalizes – the encoding of the usage policies and of the GDPR outlined above.Definition 3.3 (Policy logic PL). A PL knowledge base K is a set of axioms of the following kinds:• func(R) where R is a role name or a concrete property;• range(S, A) where S is a role and A a concept name;• A (cid:8) B where A, B are concept names;• disj( A, B) where A, B are concept names.Simple PL concepts are defined by the following grammar, where A ∈ NC, R ∈ NR, f ∈ NF, and l and u are integers:C ::= A | ⊥ | ∃ f .[l, u] | ∃R.C | C (cid:13) C .A (full) PL concept is a union D1 (cid:15) . . . (cid:15) Dn of simple PL concepts (n ≥ 1). PL’s subsumption queries are inclusions C (cid:8) Dwhere C, D are (full) PL concepts.3.1. Discussion of the encodingThe formalization of policies as classes of data usage modalities addresses several needs.8P.A. Bonatti, L. Ioffredo, I.M. Petrova et al.Artificial Intelligence 289 (2020) 103389First, on the controller’s side, each instance of a process may slightly differ from the others. For example, different instances of a same process may operate on data that are stored in different servers, possibly in different nations (this typically happens to large, international companies). The concrete data items involved may change slightly (e.g. age may be expressed directly or through the birth date; the data subject may be identified via a social security number (SSN), or an identity card number, or a passport number). By describing storage location, data, and the other policy attributes as classes, controllers can concisely describe an entire collection of similar process instances. With reference to the above examples, classes allow to express that data are stored “somewhere in the EU” and “in the controller’s servers”; both age and birthdate fall under the class of demographic data; SSN and document numbers can be grouped under the class of unique identifiers.A second advantage of classes is that they support a rather free choice of granularity. For example, the classes that model locations can be formulated at the granularity of continents, federations, countries, cities, zip-codes, down to buildings and rooms. Subsumption naturally models the containment of regions into other regions. A flexible choice of granularity helps in turning company documentation into formalized business policies, since it facilitates the import of the abstractions spontaneously used by domain experts.The third, and perhaps most important advantage is that classes facilitate the reuse of consent. The GDPR sometimes allows to process personal data for a purpose other than that for which the data has been collected, provided that the new purpose is “compatible” with the initial purpose.16 Compatibility cannot be assessed automatically, in general, because it is not defined in the regulation; only a human with specific legal background can deal reliably with the involved subtleties. However, by expressing purposes as classes, one can at least have the data subject consent upfront to a specified range of “similar” purposes. Roughly speaking, the accepted class of purposes is like an agreement – between data subjects and controllers – on which purposes are “compatible” in the given context. Also expressing the other policy properties as classes is beneficial. If data subjects consent to wider classes of usage modalities, then the need for additional consent requests tends to decrease; this may yield benefits to both parties, because:1. data subjects are disturbed less frequently with consent requests (improved usability, better user experience);2. the costs associated to consent requests decrease. Consider that sometimes the difficulties related to reaching out to the data subjects, and the concern that too many requests may annoy users, make controllers decide not to deliver a service that requires additional consent.From a theoretical viewpoint, the class-based policy formalization adopted by SPECIAL is essentially akin to a well-established policy composition algebra [10]. The algebra treats policies as classes of authorizations (each policy P is identified with the set of authorizations permitted by P ). In turn, authorizations are tuples that encode the essential elements of permitted operations, such as the resources involved and the kind of processing applied to those resources. Analogously, each PL policy like (1) denotes a set of reifications of tuples, whose elements capture the legally relevant properties of data usage operations.3.2. Related policy languagesLogic-based languages constitute natural policy languages, because policies are knowledge. First, note that policies encode declarative constraints on a system’s behavior, that depend on metadata about the actors and the objects involved (e.g. ownership, content categories), and an environment (as some operations may be permitted only in certain places, or at specified times of the day, or in case of emergency). Semantic languages and formats have been expressly designed to encode metadata, so standard knowledge representation languages can represent in a uniform way both policy constraints and the metadata they depend on.The second important observation is that – like knowledge and unlike programs – every single policy is meant to be used for multiple, semantically related tasks, such as the following:• permission checking: given an operation request, decide whether it is permitted;• compliance checking: does a policy P 1 fulfill all the restrictions requested by policy P 2? (Policy comparison);• policy validation: e.g. is the policy contradictory? Does it comply with a given regulation? Does a policy update strengthen or relax the previous policy?• policy explanation: explain a policy and its decisions.The terse formal semantics of logical languages is essential in validating the correctness of the policies themselves and the implementation of the above tasks, ensuring their mutual coherence. Moreover, when data are transferred under agreed policies, it is crucial that both parties understand the policies in the same way. So unambiguous semantics is essential for correct interoperability, too.In the light of the above observations, it is clear that knowledge representation languages are ideal policy representation languages. Indeed, both rule languages and description logics have already been used as policy languages; a non-exhaustive 16 See for example articles 5.1 (b) and 6.4.9P.A. Bonatti, L. Ioffredo, I.M. Petrova et al.Artificial Intelligence 289 (2020) 103389list is [49,30,48,32,11]. As noted in [7], the advantage of rule languages is that they can express n-ary authorization con-ditions for arbitrary n, while encoding such conditions for n > 2 is challenging in DL. The advantage of DL is that all the main policy-reasoning tasks are decidable (and tractable if policies can be expressed with OWL 2 profiles), while compli-ance checking is undecidable in rule languages, or at least intractable, in the absence of recursion, because it is equivalent to Datalog query containment. So a DL-based policy language is a natural choice in a project like SPECIAL, where policy comparison is the predominant task.The aforementioned works on logic-based policy languages focus on access control and trust management, rather than data usage control. Consequently, those languages lack the terms for expressing privacy-related and usage-related concepts. A more serious drawback is that the main reasoning task in those papers is permission checking; policy comparison (which is central to our work) is not considered. Both Rei and Protune [32,11] support logic program rules. Therefore, as we pointed out above, policy comparison is generally hard and possibly undecidable. This drawback makes such languages unsuitable to SPECIAL’s purposes. Similarly, KAoS [48] is based on a DL that, in general, is not tractable, and supports role-value maps – a construct that easily makes reasoning undecidable (see [4], Chap. 5). The papers on KAoS do not discuss how the policy language is restricted to avoid this issue.The terms used as role fillers in SPECIAL’s policies are imported from well established formats for expressing privacy preferences and digital rights, such as P3P (the Platform for Privacy Preferences)17 and ODRL (the Open Digital Right Lan-guage).18 More general vocabularies will be discussed in Section 5. It is interesting to note that P3P’s privacy policies – that are encoded in XML – are almost identical to simple PL policies: the tag STATEMENT contains tags PURPOSE, RECIPIENT, RETENTION, and DATA-GROUP, that correspond to the analogous properties of SPECIAL’s usage policies. Only the information on the location of data is missing. The tag STATEMENT is included in a larger context that adds infor-mation about the controller (tag ENTITY) and about the space of web resources covered by the policy (through so-called policy reference files). All of these additional pieces of information can be directly encoded with simple PL concepts. Similar considerations hold for ODRL. The tag RIGHTS associates an ASSET (the analogue of has_data) to a PERMISSION that specifies a usage modality. ODRL provides terms for describing direct use (e.g. play or execute), reuse (e.g. annotate or aggregate), transfer (sell, lend, lease), and asset management operations (such as backup, install and delete, just to name a few). These terms provide a rich vocabulary for specifying the has_processing property of SPECIAL’s policies. Also in the case of ODRL, the tree-like structure of XML documents can be naturally encoded with PL concepts.3.3. Related work on legal reasoningDespite superficial similarities, SPECIAL’s policy framework and the many works on legal reasoning have different goals. The survey [44] lists several applications of logic and reasoning to the legal domain that can be grouped as follows:a. Supporting the legislators in writing less ambiguous, possibly normalized legal documents.b. Modeling legal concepts and definitions.c. Interpreting the law.d. Modeling the debates and pleadings that take place in courts, and deriving legal qualifications.The work on vocabularies carried out by SPECIAL and the DPVCG can be regarded as a streamlined version of (b), while the use case of business policy validation based on GDPR’s partial formalization does not really match any of the above points. Policy validation is less ambitious than legal reasoning; it is only aimed at checking whether the different properties of the policy are mutually coherent (e.g. by checking that the legal basis matches the data category), and whether all relevant parts have been included (such as the appropriate obligations in case of consent-based processing or data transfers outside the EU). The latter is a way to check whether the human responsible has “ticked all the necessary boxes”, and by no means tackles the legal reasoning required to assess whether the obligations have been actually and appropriately fulfilled; according to our experience in SPECIAL, algorithms and ontologies are not yet trusted on this matter – especially due to the severe consequences in case of wrong decisions.Both business policy validation and compliance checking w.r.t. consent policies shall verify that business policies do the right thing in all contexts while the literature on legal reasoning focuses on whether a legal qualification (such as an obligation, a permission, the validity of a contract, etc.) holds in a specific situation [44]. This difference has remarkable technical consequences: as we have already pointed out, validation in all contexts (i.e. policy comparison) is intractable in rule-based languages (that are common in the works on legal reasoning, since the seminal paper [45]), and even undecidable if rules are recursive [7]. The DL-based approach we adopted guarantees decidability and – under suitable hypotheses – tractability, as shown in the following sections.The ambitious goals of legal reasoning have been tackled with sophisticated formalisms, such as deontic and nonmono-tonic logics, see for example [31,29,1,24]. Fortunately, the different goals of SPECIAL’s compliance checking make these complications unnecessary. Simplicity is strategic for the project, since the personnel that is expected to write the business 17 http://www.w3 .org /TR /P3P11.18 https://www.w3 .org /TR /odrl/.10P.A. Bonatti, L. Ioffredo, I.M. Petrova et al.Artificial Intelligence 289 (2020) 103389policies has no background on mathematical logic, deontic logic, nor nonmonotonic logic. The usability of SPECIAL’s simple, form-like business policies has been successfully tested by one of the industrial partners of SPECIAL.Formal ontologies based on DLs have been used to represent and reason over legal concepts, or as interchange formats to merge different sources of legal information. An example of legal ontology is LKIF Core [27] which has been developed in OWL1.1. LKIF Core follows a stratified approach defining an intentional layer on top of the legal layer. The intentional layer models different aspects of intentional behavior such as actions, plans, beliefs, and intentions. The legal layer concerns public acts, like norms, that have a legal relevance. Norms are further specialized in Right, Obligation, Permission, and Prohibition, that are coherently related to normative qualifications such as Allowed, Disallowed, Obliged, etc.Recent work on legal reasoning – leveraging deontic and nonmonotonic logics – has been expressly tailored to the GDPR. The authors of [41,42] propose an ontology, PrOnto, aiming at supporting legal reasoning in general and compliance checking w.r.t. the GDPR. PrOnto defines a taxonomy of basic concepts and roles occurring in the GDPR and is organized in 5 distinct modules: Data and Documents, Agent and Role, Data Processing, Purposes and Legal Basis, and Deontic Operators.In [40] PrOnto and LegalRuleML (a semantics-neutral interchange format) have been included in a larger architecture for developing GDPR-compliant cloud computing platforms for eGovernment. The graphic tool RAWE supports legal experts in translating legal text into formal rules which can be applied to a BPMN description of an eGov service. Compliance with the GDPR is then checked by the defeasible legal reasoning engine SPINdle. As a use case scenario, the article shows the formalization of Art. 8 of the GDPR concerning parental consent.Differently from SPECIAL, the framework proposed in [40–42] pursues the more ambitious goals of legal reasoning and operates on a workflow-based representation of the controller’s activities, more complex than business policies. These choices increase the cost of framework instantiation and rely on users with the necessary legal and logical background for editing and verifying legal rules – two assumptions that are not aligned with SPECIAL’s reference scenarios. Further-more, compliance checking is only static, and it does not address SPECIAL’s need for real-time compliance checking with respect to the changing consent of data subjects. Summarizing, SPECIAL trades advanced legal reasoning capabilities for usability and scalability.4. Reasoning with PLAs explained in the introduction, some of the use cases of SPECIAL place challenging scalability requirements on the compliance checker, that should be able to execute over 104 subsumption checks per second, as in the streaming scenario. These scalability requirements have been addressed by finding a tradeoff between expressiveness and efficiency. The lan-guage PL – that is rich enough to encode the policies of interest – is also simple enough to be implemented very efficiently. Intervals, however, are a source of complexity and must be suitably restricted. In this section, we are first going to prove that unrestricted subsumption checking in PL is coNP-complete. Then we show that the structure of usage policies can be exploited to make restrictive assumptions on the occurrences of intervals. Under such assumptions, we can prove that an approach articulated in two stages – where first business policies are suitably normalized, then compliance with con-sent policies is checked with a structural subsumption algorithm – is correct, complete, and tractable. Its scalability will be experimentally assessed in Section 6.We start by laying out the formal description and the theoretical properties of normalization and structural subsump-tion. In particular, this section deals with the correctness and completeness of the two-stages method, and discusses the computational complexity of arbitrary subsumptions and of the restricted, tractable case. We first prove the intractability of unrestricted subsumption in PL.Theorem 4.1. Deciding whether K |= C (cid:8) D, where K is a PL knowledge base and C, D are PL concepts, is coNP-hard.19 This statement holds even if the knowledge base is empty and C is simple.Proof. Hardness is proved by reducing 3SAT to the complement of subsumption. Let S be a given set of clauses ci =Li1 ∨ Li2 ∨ Li3 (1 ≤ i ≤ n) where each Li j is a literal. We are going to use the propositional symbols p1, . . . , pm occurring in S as property names in PL concepts, and define a subsumption C (cid:8) D that is valid iff S is unsatisfiable. Let C =(cid:7)(cid:6)∃p1.[0, 1] (cid:13) . . . (cid:13) ∃pm.[0, 1] , where each ˜Li j encodes the complement of Li j as follows:˜Li1 (cid:13) ˜Li2 (cid:13) ˜Li3and D = (cid:15)ni=1(cid:7)(cid:6)(cid:8)˜Li j =∃pk.[0, 0]∃pk.[1, 1]if Li j = pk ,if Li j = ¬pk .The correspondence between the propositional interpretations I of S and the interpretations J of C (cid:8) D is the following.Given I and an arbitrary element d, define J = (cid:26){d}, ·J (cid:27) such that (d, 0) ∈ piff I(pi) = false, and (d, 1) ∈ pBy construction, (J , d) |= C , and I |= S iff (J , d) (cid:28)|= D. Consequently, if S is satisfiable, then C (cid:8) D is not valid.Ji otherwise. JiConversely, if C (cid:8) D is not valid, then there exist J and d ∈ (cid:3)Jinterpretation I of S by setting I(p) = true iff (d, 1) ∈ pwhich proves that if C (cid:8) D is not valid, then S is satisfiable.Jisuch that (J , d) |= C (cid:13) ¬D. Define a propositional . By construction (and since d does not satisfy D in J ), I |= S, 19 As customary, we assume a positional representation of integers.11P.A. Bonatti, L. Ioffredo, I.M. Petrova et al.Artificial Intelligence 289 (2020) 103389We conclude that the above reduction is correct. Moreover, it can be clearly computed in polynomial time. This proves that subsumption is coNP-hard even if the knowledge base is empty and C simple. (cid:2)Later on we will complete the characterization of PL subsumption by proving its membership in coNP (Theorem 4.13).The above intractability result does not apply to SPECIAL’s usage policies because each simple usage policy contains at most one interval constraint, namely, a specification of storage duration of the form ∃has_storage.∃has_duration.[(cid:4), u]. We are going to show that this property (actually, a slight generalization thereof) makes reasoning quite fast. More specifically, it enables an efficient treatment of interval constraints based on a suitable interval normalization method. Such normalization produces subsumption queries that satisfy the following property.Definition 4.2 (Interval safety). An inclusion C (cid:8) D is interval safe iff, for all constraints ∃ f .[(cid:4), u] occurring in C and all ∃ f(cid:29)] occurring in D, either [(cid:4), u] ⊆ [(cid:4)(cid:29), u(cid:29)], or [(cid:4), u] ∩ [(cid:4)(cid:29), u(cid:29).[(cid:4)(cid:29), u(cid:29)] = ∅.Roughly speaking, interval safety removes the need for treating intervals like disjunctions; it makes them behave like plain atomic concepts. Every inclusion can be turned into an equivalent, interval safe inclusion, using the following method.Definition 4.3 (Interval normalization, splitD (C)). For each constraint ∃ f .[(cid:4), u] in C , let x1 < x2 < · · · < xr be the integers that occur as interval endpoints in D and belong to [(cid:4), u]. Let x0 = (cid:4) and xr+1 = u and replace ∃ f .[(cid:4), u] with the equivalent concept(cid:6)(cid:7)∃ f .[xi, xi] (cid:15) ∃ f .[xi + 1, xi+1 − 1](cid:15) ∃ f .[xr+1, xr+1] .r(cid:15)i=0(8)Then use distributivity of (cid:13) over (cid:15) and the equivalence ∃R.(C1 (cid:15) C2) ≡ ∃R.C1 (cid:15) ∃R.C2 to move all occurrences of (cid:15) to the top level. Denote the result of this interval normalization phase with split D (C).Example 4.4. Let C = ∃ f .[1, 9] (cid:13) A and D = ∃ f .[5, 12]. Then r = 1 and x0 = 1, x1 = 5, x2 = 9 (12 falls outside [1, 9] and is ignored). According to (8), the concept ∃ f .[1, 9] in C is replaced by the following union:∃ f .[1, 1] (cid:15) ∃ f .[2, 4] (cid:15) ∃ f .[5, 5] (cid:15) ∃ f .[6, 8] (cid:15) ∃ f .[9, 9] .Then, after applying distributivity, we obtain the concept split D (C) (that is a full PL concept):(∃ f .[1, 1] (cid:13) A) (cid:15) (∃ f .[2, 4] (cid:13) A) (cid:15) (∃ f .[5, 5] (cid:13) A) (cid:15) (∃ f .[6, 8] (cid:13) A) (cid:15) (∃ f .[9, 9] (cid:13) A) . (cid:2)The reader may easily verify that:Proposition 4.5. For all PL subsumption queries C (cid:8) D, splitD (C) is equivalent to C and splitD (C) (cid:8) D is an interval-safe PLsubsumption query.In general, splitD (C) may be exponentially larger than C , due to the application of distributivity (e.g. this happens with the concepts C and D in the proof of Theorem 4.1). However, as we have already pointed out, each simple policy has at most one, functional concrete property so no combinatorial explosion occurs during interval normalization. Accordingly – and more generally – the following proposition holds:Proposition 4.6. Let C = C1 (cid:15) . . . (cid:15) Cn be a PL concept, and suppose that for all i = 1, . . . , n, the number of concrete properties occurring in Ci is bounded by a constant c. Then, for all concepts D, the size of splitD (C) is O (|C| · |D|c).20Note that C as a whole may still contain an unbounded number of interval constraints, as n grows, because the bound capplies only to the individual disjuncts Ci .The structural subsumption algorithm for PL’s subsumption queries accepts subsumptions whose left-hand side is fur-ther normalized with respect to the given knowledge base K by exhaustively applying the rewrite rules illustrated in Table 3. Such rules make contradictions explicit and merge functional properties. They clearly preserve equivalence, as stated in the next proposition:Proposition 4.7. If C (cid:2) C(cid:29)then K |= C ≡ C(cid:29).20 We denote the size of the encoding of an expression E with |E|.12P.A. Bonatti, L. Ioffredo, I.M. Petrova et al.Artificial Intelligence 289 (2020) 103389Table 3Normalization rules w.r.t. K. Intersections are treated as sets (the ordering of conjuncts and their repetitions are irrelevant). (cid:8)∗denotes the reflexive and transitive closure of {( A, B) | ( A (cid:8) B) ∈ K}.1)2)3)4)5)6)7)⊥ (cid:13) D (cid:2) ⊥∃R.⊥ (cid:2) ⊥∃ f .[l, u] (cid:2) ⊥(∃R.D) (cid:13) (∃R.D(cid:29)) (cid:13) D(cid:29)(cid:29) (cid:2)∃R.(D (cid:13) D∃ f .[l1, u1] (cid:13) ∃ f .[l2, u2] (cid:13) D (cid:2)∃ f .[max(l1, l2), min(u1, u2)] (cid:13) D∃R.D (cid:13) D(cid:29) (cid:2) ∃R.(D (cid:13) A) (cid:13) D(cid:29)if l > u(cid:29)) (cid:13) D(cid:29)(cid:29)if func(R) ∈ KA1 (cid:13) A2 (cid:13) D (cid:2) ⊥if func( f ) ∈ Kif range(R, A) ∈ K, and neither Anor ⊥ are conjuncts of Dif A1 (cid:8)∗1, A2 (cid:8)∗A(cid:29)2) ∈ K1, Adisj( A2, and A(cid:29)(cid:29)(cid:29)The proof is trivial and left to the reader. It is easy to see that concepts can be normalized in polynomial time:Lemma 4.8. Each PL concept C can be normalized w.r.t. a given PL knowledge base K in time O (|C|2 · |K|).(cid:29)Proof. We take this chance to illustrate an algorithm which is similar to the one actually used in the implementation of normalization. First C is parsed into a syntax tree T (time O (|C|)) where each conjunction of n concepts is modeled as a single node with n children. Then the tree is scanned in a depth-first fashion, looking for nodes labeled with an existential restriction in order to apply rule 4). For each such node ν, if R is the involved role and func(R) ∈ K, then the previous siblings of ν are searched looking for a node ν(cid:29)is replaced with the intersection of Citself and the child of ν, then ν is deleted. This operation (including the functionality test for R) takes time O (|K| + |C|) for each existential restriction. Thus, the exhaustive application of rule 4) needs time O (|C| · |K| + |C|2). Rule 5) is dealt with similarly (but instead of merging children, the interval associated to ν is intersected with the interval associated to ν(cid:29)); the cost is the same. None of the other rules adds any new existential restrictions, so rules 4) and 5) are not going to be applicable again in the rest of the algorithm.with the same role R. If such a ν(cid:29)is found, then the child Cof ν(cid:29)Next, rule 6) is applied by searching the tree T for existential restrictions whose role R occurs in an axiom range(R, A) ∈K. For each of such nodes, A is added to the children as a new conjunct (if necessary). The cost for each existential restriction is O (|K| + |C|) (where |C| is the cost of verifying whether the existential restriction already contains A or ⊥). So the exhaustive application of rule 6) is again O (|C| · |K| + |C|2). The remaining rules can remove a range A only by substituting it with ⊥, so rule 6) cannot be triggered again in the rest of the algorithm.(cid:29)Finally, the nodes of T are visited in a depth-first fashion in order to apply rules 1), 2), 3), and 7).Rule 7) is the most expensive. K is regarded as a labeled classification graph, where each node is labeled with an atomic concept and with the disjointness axioms in which that concept occurs. The disjointness test between A1 and A2 in rule 7) can be implemented by a relatively standard linear-time reachability algorithm, that climbs the classification graph (cid:29)2), searching for A2. In from A1 and starts descending the classification whenever it finds a node labeled with disj( Athe worst case, this stage involves O (|C|2) searches (one for each pair A1, A2 in each conjunction), so its global cost is O (|C|2 · |K|).(cid:29)1, AFinally, note that rules 1–3 do not need to be iteratively applied. If C contains an empty interval [l, u] (l > u), or an occurrence of ⊥, at any nesting level, then surely C can be rewritten to ⊥. Therefore, it suffices to scan C once, looking for empty intervals or ⊥.Since the cost of rule 7 dominates the cost of the other rules, normalization can be computed in time O (|C|2 ·|K|). (cid:2)Normalized queries are passed over to a structural subsumption algorithm, called STS (Algorithm 1). It takes as inputs a PL knowledge base K and an elementary PL subsumption C (cid:8) D:Definition 4.9 (Elementary subsumptions). A PL subsumption C (cid:8) D is elementary (w.r.t. a PL knowledge base K) if both Cand D are simple, C (cid:8) D is interval safe, and C is normalized w.r.t. K.The full subsumption checking procedure (that applies to all PL subsumptions) is called PL Reasoner (PLR for short). It is summarized in Algorithm 2.PLR is correct and complete. We only state this result, whose proof is sketched in [8], since we are going to prove it in a more general form for an extended engine that supports more expressive knowledge bases (Section 5).13P.A. Bonatti, L. Ioffredo, I.M. Petrova et al.Artificial Intelligence 289 (2020) 103389Algorithm 1: STS(K, C (cid:8) D).Input: A PL KB K and a PL subsumption C (cid:8) D that is elementary w.r.t. KOutput: true if K |= C (cid:8) D, false otherwiseNote 1: Below, we treat intersections like sets. For example, by C = C(possibly not the first one).Note 2: (cid:8)∗denotes the reflexive and transitive closure of {( A, B) | ( A (cid:8) B) ∈ K}.(cid:29) (cid:13) C(cid:29)(cid:29)we mean that either C = C(cid:29)(cid:29)or Cis a conjunct of C1 begin2(cid:29)(cid:29) (cid:13) Cand Aif C = ⊥ then return true ;(cid:29) (cid:8)∗if D = A, C = AA then return true ;(cid:29), u(cid:29)(cid:29)] (cid:13) C(cid:29)if D = ∃ f .[l, u] and C = ∃ f .[land l ≤ l(cid:29)(cid:29)(cid:29)) (cid:13) C(cid:29)(cid:29) (cid:8) Dand STS(K, Cif D = ∃R.D(cid:29)), and STS(K, C (cid:8) D(cid:29) (cid:13) D, STS(K, C (cid:8) Dif D = Delse return false ;, C = (∃R.C(cid:29)(cid:29)and u(cid:29) ≤ u then return true ;(cid:29)) then return true ;(cid:29)(cid:29)) then return true ;8 endAlgorithm 2: PLR(K, C (cid:8) D).Input: A PL KB K and a PL subsumption query C (cid:8) DOutput: true if K |= C (cid:8) D, false otherwise1 begin2(cid:29)) ;(cid:29)be the normalization of C w.r.t. K (with the rules in Table 3) ;let C(cid:29)(cid:29) = splitD (Clet C(cid:29)(cid:29) = C1 (cid:15) . . . (cid:15) Cm and D = D 1 (cid:15) . . . (cid:15) Dn// assume that C// check whether each Ci is subsumed by some D jfor i = 1, . . . , m doif STS(K, Ci (cid:8) D j) = true then skip to next i in outer loop;for j = 1, . . . , n doendreturn falseendreturn true3456734567891011 endTheorem 4.10. For all PL knowledge bases K and all PL subsumption queries q,K |= q iff PLR(K, q) = true .With this result, we can prove that subsumption checking in PL becomes tractable if the number of interval constraints per simple policy is bounded by a constant c (recall that in SPECIAL’s policies c = 1). First we estimate the complexity of PLR.Lemma 4.11. For all PL knowledge bases K and all PL subsumption queries C (cid:8) D, PLR(K, C (cid:8) D) can be computed in time O (|C (cid:8) D|c+1 + |C (cid:8) D|2 · |K|), where c is the maximum number of interval constraints occurring in a single simple concept of C .Proof. By Lemma 4.8 and Proposition 4.6, respectively, the complexity of line 2 of PLR is O (|C|2 · |K|) and the complexity of line 3 is O (|C| · |D|c) = O (|C (cid:8) D|c+1). Now consider the complexity of the calls STS(K, Ci (cid:8) D j) in line 6. Each of them, in the worst case, scans Ci once for each subconcept of D j , searching for a matching concept. Matching may require to solve a reachability problem on the hierarchy (cid:8)∗, so the cost of each call is O (|D j| · |Ci| · |K|). If we focus on the outer loop (lines 4–9) then clearly each subconcept of D is matched against all disjuncts of C , in the worst case. Then the overall cost of the outer loop is O (|D| · |C| · |K|). By relating these parameters to the size of the query, it follows that the cost of the outer loop is bounded by O (|C (cid:8) D|2 · |K|). This dominates the cost of line 2. So we conclude that the overall time needed by PLR in the worst case is O (|C (cid:8) D|c+1 + |C (cid:8) D|2 · |K|). (cid:2)Tractability immediately follows from Theorem 4.10 and Lemma 4.11:Theorem 4.12. Let c be an integer, and Qc be the set of all PL subsumptions C1 (cid:15) . . . (cid:15) Cn (cid:8) D such that each Ci contains at most cinterval constraints (i = 1, . . . , n). Then deciding whether a query in Qc is entailed by a PL knowledge base K is in P.14P.A. Bonatti, L. Ioffredo, I.M. Petrova et al.Artificial Intelligence 289 (2020) 103389We conclude this section by completing the characterization of the complexity of unrestricted PL subsumptions. The following result, together with Theorem 4.1, proves that PL subsumption is coNP-complete.Theorem 4.13. Deciding whether K |= C (cid:8) D, where K is a PL knowledge base and C, D are (simple or full) PL concepts, is in coNP.Proof. We prove the theorem by showing that the complement of subsumption is in NP. For this purpose, given a query C (cid:8) D, it suffices to choose nondeterministically one of the disjuncts Ci in the left hand side of the query, and replace each (cid:29)constraint ∃ f .[(cid:4), u] occurring in Ci with a nondeterministically chosen disjunct from (8). Call Ci the resulting concept and note that it is one of the disjuncts in split D (C). Therefore, K (cid:28)|= C (cid:8) D iff K (cid:28)|= splitD (C) (cid:8) D iff, for some nondeterministic (cid:8) D is interval-safe by construction. Then this subsumption test can be evaluated choice of C(cid:29)i w.r.t. K and then applying STS, that is complete for elementary in deterministic polynomial time by first normalizing Cqueries [8, Theorem 2]. It follows immediately that the complement of PL subsumption can be decided in nondeterministic polynomial time, hence its membership in NP. (cid:2)(cid:8) D. Note that C(cid:29)i , K (cid:28)|= C(cid:29)i(cid:29)i5. Supporting general vocabulariesSPECIAL has founded the “Data Privacy Vocabularies and Controls Community Group” (DPVCG),21 a W3C group aimed at developing privacy-related vocabularies. The purpose of this initiative is developing ontologies for the main properties of usage policies and related GDPR concepts, with the contribution of a group of stakeholders that spans beyond SPECIAL’s consortium. This group aims at developing upper ontologies, that can be later extended to meet the needs of specific application domains.We intend to put as few constraints as possible on the development of such standardized vocabularies, since it is difficult to predict the expressiveness needs that may arise in their modeling – especially because standards usually change to include new application domains and follow the evolution of the old ones. PL knowledge bases are too simple to address this requirement. We already have evidence that it is useful to have roles whose domain is a vocabulary term, such as the accuracy of locations (cf. Section 3); so, in perspective, we should expect the ontologies that define privacy-related vocabularies to include at least existential restrictions (that cannot be used in PL knowledge bases, but are supported – say – by the tractable profiles of OWL2). It is hard to tell which other constructs will turn out to be useful.For the above reasons, we are going to show how to integrate PL and its specialized reasoner with a wide range of ontologies, expressed with description logics that can be significantly more expressive than PL.Our strategy consists in treating such ontologies – hereafter called external ontologies – as oracles. Roughly speaking, whenever STS needs to check a subsumption between two terms defined in the external ontologies, the subsumption query is submitted to the oracle. In the easiest case, the queries to the oracle can be answered with a simple visit to the classification graph of the vocabularies. Of course this method, called import by query (IBQ), is not always complete [21,20]. In this section, we provide sufficient conditions for completeness.More formally, let K and O be two given knowledge bases. The former will be called the main KB, and may use terms that are axiomatized in O, that plays the role of the external ontology. For example, in SPECIAL’s policy modeling scenario, K defines policy attributes – by specifying their ranges and functionality properties – while O defines the privacy-related vocabularies that provide the fillers for policy attributes. Therefore, in SPECIAL’s framework, K is a PL knowledge base, while O could be formulated with a more expressive DL. The reasoning task of interest in such scenarios is deciding, for a given subsumption query q = (C (cid:8) D), whether K ∪ O |= q. Both C and D are PL concepts that usually contain occurrences of concept names defined in O.SPECIAL’s application scenarios make it possible to adopt a simplifying assumption that makes oracle reasoning techni-cally simpler [21,20], namely, we assume that neither K nor the query q shares any roles with O. This naturally happens in SPECIAL precisely because the roles used in the main KB identify the sections that constitute a policy (e.g. data cat-egories, purpose, processing, storage, recipients), while the roles defined in O model the contents of those sections, e.g. anonymization parameters, relationships between recipients (like ownership, employment relations), relationships between storage locations (e.g. part-of relations), and the like.This layered structure does not require arbitrary alternations of roles coming from the main KB and from the external ontologies (more precisely, the roles occurring in the main KB need not occur within the scope of any role in (cid:2)(O)). As a consequence, the roles of the external ontology can be allowed in the queries as syntactic sugar, as explained in the following.Remark 5.1. Let q be a PL subsumption query, and RO range over the roles occurring in O. According to the above discussion, assume that for all concept of the form ∃RO.C occurring in q, C contains only roles from (cid:2)(O) (no alternation of roles from the main KB and O). Every such concept ∃RO.C can be eliminated from q by replacing it with a fresh atom A, and extending O with the axiom A ≡ ∃RO.C , under the mild assumption that the language of O supports such 21 www.w3 .org /community /dpvcg/.15P.A. Bonatti, L. Ioffredo, I.M. Petrova et al.Artificial Intelligence 289 (2020) 103389(cid:29)and O(cid:29)be the query and the ontology obtained by applying the above transformation for all RO ∈ (cid:2)(O). equivalences. Let qClearly, by construction, O(cid:29)is equivalent to q. Moreover, (cid:2)(O(cid:29)) ∩ NR = (cid:2)(O) ∩ NR holds (cid:29)implies that the resulting query qby the assumption that the concepts C in ∃RO.C contain only roles from (cid:2)(O). Now it is easy to see that the requirement that the main KB should share no roles with O(cid:29)is preserved by the transformation, since the main KB is not affected and (cid:2)(O(cid:29)) ∩ NR = (cid:2)(O) ∩ NR. Due to the same equality, qcontains no roles in (cid:2)(O(cid:29)) because, by construction, it contains no roles in (cid:2)(O). Summarizing, every query q where the roles in (cid:2)(K) do not occur within the scope of the roles in (cid:2)(O)(cid:29)can be transformed in polynomial time into an equivalent qthat satisfies the requirement on role sharing, by means of a simple extension of O.(cid:29)5.1. On the completeness of IBQ reasoningThe IBQ framework was introduced to reason with a partly hidden ontology O. For our purposes, IBQ is interesting because instead of reasoning on K ∪ O as a whole, each of the two parts can be processed with a different reasoner (so, in particular, policies can be compared with a very efficient algorithm similar to STS). The reasoner for K may query O as an oracle, using a query language QL consisting of all the subsumptionsA1 (cid:13) . . . (cid:13) Am (cid:8) Am+1 (cid:15) . . . (cid:15) An(9)such that A1, . . . , An are concept names. If n = m, then we stipulate that the right-hand side of the inclusion is ⊥. We will denote with pos(O) all the queries to O that have a positive answer, that is:pos(O) = {q ∈ QL | O |= q} .Remark 5.2. Each subsumption of the form (9) is equivalent to a concept (in)consistency check of the form:A1 (cid:13) . . . (cid:13) Am (cid:13) ¬ Am+1 (cid:13) . . . (cid:13) ¬ An (cid:8) ⊥ .(10)By [21, Theorem 2], such consistency checks (and, consequently, QL) constitute a fully general oracle query language, under the assumption that K and the query q share no roles with O. By “fully general” we mean that it can be decided whether K ∪ O |= q holds using only the axioms of K and the members of pos(O).The problem instances we are interested in are formally defined by the next definition.Definition 5.3 (PL subsumption instances with oracles, PLSO). A PL subsumption instance with oracle is a triple (cid:26)K, O, q(cid:27)where K is a PL knowledge base (the main knowledge base), O is a Horn-SRIQ knowledge base (the oracle), and q is a PL subsumption query, such that ((cid:2)(K) ∪ (cid:2)(q)) ∩ (cid:2)(O) ⊆ NC. The set of all PL subsumption instances with oracle will be denoted by PLSO.The restrictions on K, O and q will be motivated in depth in Section 5.5. We anticipate only two observations. First, the restriction on the signatures is aimed at keeping the roles of O separated from those of K and q, as discussed in the previous section. The second observation is that the important properties of O are the absence of nominals and its convexity with respect to QL, in the following sense:Definition 5.4 (Convexity w.r.t. QL). A knowledge base O is convex w.r.t. QL if for all subsumptionsq = A1 (cid:13) . . . (cid:13) Am (cid:8) Am+1 (cid:15) . . . (cid:15) Anin QL, q ∈ pos(O) iff there exists i ∈ [m + 1, n] such that ( A1 (cid:13) . . . (cid:13) Am (cid:8) Ai) ∈ pos(O). A description logic is convex w.r.t.QL if all of its knowledge bases are convex w.r.t. QL.Accordingly, in Definition 5.3, we required O to be in Horn-SRIQ because, to the best of our knowledge, this is the most expressive description logic considered so far in the literature that is both nominal-free and convex w.r.t. QL.The next lemma rephrases the original IBQ completeness result [21, Lemma 1] in our notation. Our statement relaxes the requirements on O by assuming only that it enjoys the disjoint model union property (originally it had to be in SRIQ). The proof, however, remains essentially the same.Lemma 5.5. Let K and O be knowledge bases and α a GCI, such that1. K and α are in SROIQ(D) without U , where D is the concrete domain of integer intervals;2. The terminological part of O enjoys the disjoint model union property;16P.A. Bonatti, L. Ioffredo, I.M. Petrova et al.Artificial Intelligence 289 (2020) 1033893. The terminological part T of K is local w.r.t. (cid:2)(O);4. ((cid:2)(K) ∪ (cid:2)(α)) ∩ (cid:2)(O) ⊆ NC.Then K ∪ O |= α iff K ∪ pos(O) |= α.Proof. We have to prove that under the above hypotheses K ∪ O |= α iff K ∪ pos(O) |= α. The right-to-left direction is trivial since by definition O |= pos(O). For the other direction, by contraposition, assume that K ∪ pos(O) (cid:28)|= α. We shall , ¯d ∈ (C (cid:13) ¬D)Nfind a model N of K ∪ O such that N (cid:28)|= α. Since α is of the form C (cid:8) D, this means that for some ¯d ∈ (cid:3)N. The construction is similar to that used in [21, Lemma 1].By assumption, K ∪ pos(O) has a model I such that I (cid:28)|= α, that is, there exists ¯d ∈ (cid:3)Isuch that ¯d ∈ (C (cid:13) ¬D)I. Now we extend the interpretation I over (cid:2)(K) ∪ (cid:2)(α) to a model N of K ∪ O.We need some auxiliary notation: for each d ∈ (cid:3)I, let lit(d, I) denote the set of all the literals L in the language of Osatisfied by d, that is,lit(d, I) = {L | (I, d) |= L and either L = A or L = ¬ A, where A ∈ NC ∩ (cid:2)(O)} .(cid:2)Since I |= pos(O), it follows that for all d ∈ (cid:3)I, there exists a pointed interpretation (Jd, d) of (cid:2)(O) such that Jd |= O and lit(d, Jd) = lit(d, I). We may assume without loss of generality that (cid:3)Jd ∩ (cid:3)I = {d} and that (cid:3)Jd ∩ (cid:3)J(cid:4)J {Jd | d ∈ (cid:3)I }. By hypothesis 2 and Proposition 2.2, U is a model of O. M = ∅ for all predicates X ∈ ((cid:2)(K) ∪lit(d, I) (cid:8) ⊥ (see Remark 5.2). Then, for all d ∈ (cid:3)IMoreover, by hypothesis 3, U can be extended to a model M of T , by setting X(cid:2)(α)) \ (cid:2)(O).Let J be any of the above Jd and U =(cid:29) = ∅ if d (cid:28)= d, O (cid:28)|=.d(cid:29)Finally, let N be the interpretation such that:(cid:8)(cid:3)N = (cid:3)MIXXN =XM(note that (cid:3)I ⊆ (cid:3)Mfor all symbols X ∈ ((cid:2)(K) ∪ (cid:2)(α)) \ (cid:2)(O)for all symbols X ∈ (cid:2)(O) .)The next part of the proof proceeds exactly as in [21, Lemma 1], in order to show that N |= K ∪ O. Note that by definition M and N have the same domain and agree on the symbols in (cid:2)(O), therefore N is a model of O because Mis. So one is only left to prove that N |= K. For this purpose, first it is proved that((cid:7)) for all C in the closure22 of K and α, CN = CI ∪ (CM \ (cid:3)I ).The proof of ((cid:7)) makes use of hypotheses 1 and 4. Then, using ((cid:7)) and the fact that M is a model of T , it can be shown that M is a model of K. Almost all details of the proof of ((cid:7)) and M |= K can be found in [21]. Here we only have to add the details for ((cid:7)) concerning interval constraints (that are not considered in [21]). Let C = ∃ f .[l, u]. By hypothesis 4, M = ∅, f ∈ ((cid:2)(K) ∪ (cid:2)(α)) \ (cid:2)(O). Then, by definition of N and M, fso ((cid:7)) obviously holds.M = ∅. Consequently, CFor our formulation of this theorem, we only have to add the observation that ((cid:7)) implies also that ¯d ∈ (C (cid:13) ¬D)I ⊆N = CN = fand Cand fII(C (cid:13) ¬D)N, therefore N (cid:28)|= α. (cid:2)Using the above lemma, we prove a variant of IBQ completeness for PLSO. The locality requirement of Lemma 5.5 is removed by shifting axioms from K to O.Theorem 5.6. For all problem instances π = (cid:26)K, O, q(cid:27) ∈ PLSO, letK− = {α ∈ K | α = range(R, A) or α = func(R) }and let O+K = O ∪ (K \ K−). ThenK ∪ O |= q iff K− ∪ pos(O+K) |= q .Proof. Since K ∪ O = K− ∪ O+K, it suffices to show thatK− ∪ O+K |= q iff K− ∪ pos(O+K) |= q .This equivalence can be proved with Lemma 5.5; it suffices to show that K−lemma. First note that K−is a PL knowledge base and O+K and q satisfy the hypotheses of the K is a Horn-SRIQ knowledge base (because, by definition of , O+22 The closure of a set of axioms K is the set of all (sub)concepts occurring in K.17P.A. Bonatti, L. Ioffredo, I.M. Petrova et al.Artificial Intelligence 289 (2020) 103389Table 4Normalization rules for STSis irrelevant, and duplicates are removed).O+K . Conjunctions are treated as sets (i.e. the ordering of conjuncts 1)2)3)4)5)6)7)(cid:29)) (cid:13) D(cid:29)(cid:29) (cid:2) ∃R.(D (cid:13) D⊥ (cid:13) D (cid:2) ⊥∃R.⊥ (cid:2) ⊥if l > u∃ f .[l, u] (cid:2) ⊥if func(R) ∈ K−(∃R.D) (cid:13) (∃R.D∃ f .[l1, u1] (cid:13) ∃ f .[l2, u2] (cid:13) D (cid:2) ∃ f .[max(l1, l2), min(u1, u2)] (cid:13) Dif func( f ) ∈ K−if range(R, A) ∈ K−neither A nor ⊥ are conjuncts of Dif O+K |= A1 (cid:13) . . . (cid:13) An (cid:8) ⊥A1 (cid:13) . . . (cid:13) An (cid:13) D (cid:2) ⊥(cid:29) (cid:2) ∃R.(D (cid:13) A) (cid:13) D∃R.D (cid:13) D(cid:29)) (cid:13) Dand(cid:29)(cid:29)(cid:29)K can be expressed in Horn-SRIQ, and K. Moreover, both PL and Horn-SRIQ enjoy the disjoint model union property, therefore hypothesis 2 is satisfied. Next (transferred from K to PLSO, K is in PL and O in Horn-SRIQ, and the axioms shifted from L to O+too). Both PL and Horn-SRIQ are fragments of SROIQ(D) without U , therefore hypothesis 1 is satisfied by K−O+recall that ((cid:2)(K) ∪ (cid:2)(q)) ∩ (cid:2)(O) ⊆ NC holds, by definition of PLSO. Since the axioms α ∈ K \ K−O+K) contain no roles (they are of the form A (cid:8) B or disj( A, B)), it follows that((cid:2)(K−) ∪ (cid:2)(q)) ∩ (cid:2)(O+K) ⊆ NC ,that is, hypothesis 4 holds. A second consequence of this inclusion is that K−and func( A) such that R /∈ (cid:2)(O+local w.r.t. (cid:2)(O+K) and hypothesis 3 is satisfied. (cid:2)K). They are trivially satisfied by any interpretation I such that Rcontains only axioms of the form range(R, A)is I = ∅. Therefore K−5.2. Extending PL’s reasoner with IBQ capabilitiesThe integration of the PLR reasoner with external oracles relies on the axiom shifting applied in Theorem 5.6. Accord-ingly, in the following, let K−and O+K be defined as in Theorem 5.6.The next step after axiom shifting consists in replacing the relation (cid:8)∗used by the normalization rules and STS with suitable queries to the oracle. This change concerns the normalization rules (Table 3) and STS. The new set of rules is given in Table 4. We say that a PL concept C is normalized w.r.t. K and O if none of the rules in Table 4 is applicable.Hereafter, (cid:2) denotes the rewriting relation according to Table 4. Clearly, the new rules preserve the meaning of concepts, in the following sense:Proposition 5.7. If C (cid:2) C(cid:29)then K− ∪ pos(O+K) |= C ≡ C(cid:29).The notion of elementary inclusion is modified accordingly, by requiring normalization w.r.t. both K and O.Definition 5.8. A PL subsumption C (cid:8) D is elementary w.r.t. K and O if both C and D are simple, C (cid:8) D is interval safe, and C is normalized w.r.t. K and O.Then STS is integrated with the oracle O by replacing its line 3 as in the following algorithm STSwe call a subconcept “top level” if it does not occur in the scope of any existential restriction.O+K . In the following, Algorithm 3: STSO+Input: Ontology O+Output: true if K− ∪ pos(O+K (C (cid:8) D).K (as defined in Theorem 5.6) and a PL subsumption C (cid:8) D that is elementary w.r.t. K and OK) |= C (cid:8) D, false otherwise, where K−is defined as in Theorem 5.61 begin2if C = ⊥ then return true ;if D = A and ( A1 (cid:13) . . . (cid:13) An (cid:8) A) ∈ pos(O+if D = ∃ f .[l, u] and C = ∃ f .[l(cid:29)) (cid:13) Cif D = ∃R.D(cid:29) (cid:13) Dif D = DK (C (cid:8) Delse return false ;(cid:29)] (cid:13) Cand STS(cid:29)), and STS, C = (∃R.CO+(cid:29)(cid:29), STS(cid:29), u(cid:29)(cid:29)(cid:29)(cid:29)and l ≤ lO+K (CO+34567(cid:29)and u(cid:29) ≤ u then return true ;(cid:29) (cid:8) DK (C (cid:8) D(cid:29)) then return true ;(cid:29)(cid:29)) then return true ;K), where A1, . . . , An are the top-level concept names in C then return true ;8 endFinally, the reasoner for general PL subsumptions with oracles can be defined as follows:18P.A. Bonatti, L. Ioffredo, I.M. Petrova et al.Artificial Intelligence 289 (2020) 103389Algorithm 4: PLRO(K, C (cid:8) D).Input: O, K and C (cid:8) D such that π = (cid:26)K, O, C (cid:8) D(cid:27) ∈ PLSOOutput: true if K ∪ O |= C (cid:8) D, false otherwise1 begin23456789and O+K as defined in Theorem 5.6 ;construct K−(cid:29)be the normalization of C w.r.t. K and O (with the rules in Table 4) ;let C(cid:29)(cid:29) = splitD (Clet C(cid:29)(cid:29) = C1 (cid:15) . . . (cid:15) Cm and D = D 1 (cid:15) . . . (cid:15) Dn// assume that C// check whether each Ci is subsumed by some D jfor i = 1, . . . , m do(cid:29)) ;if STSK (Ci (cid:8) D j) = true then skip to next i in outer loop;for j = 1, . . . , n doO+endreturn false1011endreturn true12 endThe rest of this section is devoted to proving the soundness and completeness of PLRO. We will need a set of canonical counterexamples to invalid subsumptions.Definition 5.9. Let C (cid:28)= ⊥ be a simple PL concept normalized w.r.t. K and O. A canonical model of C (w.r.t. K and O) is a pointed interpretation (I, d) defined as follows, by induction on the number of existential restrictions.(cid:6) (cid:2)(cid:7)(cid:6) (cid:2)tn(cid:13)i=1 Aij=1(cid:6) (cid:2)I = {d} if ni=1 Ai (cid:8) AI = {(d, u j) | j = 1, . . . t} ;a. If C =• A• f• all the other predicates are empty.∃ f j.[l j, u j]∈ pos(O+(cid:7)(cid:7)(i.e. C has no existential restrictions), then let I = (cid:26){d}, ·I (cid:27) whereK) ;b. If the top-level existential restrictions of C are ∃R i.D i (i = 1, . . . , m), then for each i = 1, . . . , m, let (Ii, di) be a canon-ical model of D i . Assume w.l.o.g. that all such models are mutually disjoint and do not contain d. Define an auxiliary interpretation J as follows:• (cid:3)J = {d, d1, . . . , dm};(cid:7)• AK), where A1, . . . , An are the top-level concept names in C ; all other concept names ∈ pos(O+(cid:6) (cid:2)ni=1 Ai (cid:8) AI = {d} if are empty;J = {(d, u) | ∃ f .[l, u] is a top-level constraint of C };Ji• f• RFinally let I be the union of J and all Ii , that is= {(d, di) | i = 1, . . . , m}.(cid:3)I = (cid:3)J ∪I = AAJ ∪I = RRJ ∪(cid:5)i(cid:5)i(cid:5)i(cid:3)IiIiAIiR( A ∈ NC)(R ∈ NR ∪ NF) .The canonical model is (I, d).Note that each C has a unique canonical model up to isomorphism. The canonical model satisfies K−, O+K, and C :Lemma 5.10. If C is a simple PL concept normalized w.r.t. K and O, and C (cid:28)= ⊥, then each canonical model (I, d) of C enjoys the following properties:a. I |= K− ∪ pos(O+b. (I, d) |= C .K);Proof. By induction on the maximum nesting level (cid:4) of C ’s existential restrictions.If (cid:4) = 0 (i.e. there are no existential restrictions) then obviously (I, d) |= C by construction (see Definition 5.9.a). The contains only range and functionality axioms, that are trivially satisfied since all K). Suppose not, i.e. there entailment I |= K−roles are empty in I. In order to prove the base case we are only left to show that I |= pos(O+holds because K−19P.A. Bonatti, L. Ioffredo, I.M. Petrova et al.Artificial Intelligence 289 (2020) 103389I). By construction of I, d ∈ Bexists an inclusion B1 (cid:13) . . . (cid:13) Bm (cid:8) A in pos(O+K) such that d ∈ (B1 (cid:13) . . . (cid:13) Bm)I(cid:2)j only if pos(O+(cid:3)InK) contains concept names in C . These inclusions, together with B 1 (cid:13) . . . (cid:13) Bm (cid:8) A, imply by simple inferences that be in pos(O+case.(where d is the only member of i=1 Ai (cid:8) B j for all j = 1, . . . , m, where the Ai are the top-level i=1 Ai (cid:8) A must should contain {d} by definition (a contradiction). This completes the proof of the base K), too. But then Abut d /∈ A(cid:2)nNow suppose that (cid:4) > 0. By induction hypothesis (I.H), we have that all the submodels (Ii , di) used in Definition 5.9.b satisfy D i . Then it is immediate to see that (I, d) |= C by construction. We are only left to prove that I satisfies all axioms α in K− ∪ pos(O+If α = func(R), then rewrite rules 4) and 5) make sure that C contains at most one existential restriction for R, so JK).IIsatisfies α. Since all Ii satisfy α by I.H., I satisfies α, too.If α = range(R, A), then rule 6) makes sure that for each top-level concept of the form ∃R.D i in C , D i ≡ D(cid:29)i(cid:13) A. Then, by I.H., (Ii, di) |= A and, consequently, α is satisfied by I.Finally, if α is an inclusion in pos(O+individuals in (cid:3)Isatisfy α by I.H. (cid:2)K), then d satisfies it by the same argument used in the base case, while the other Another key property of the canonical models of C is that they characterize all the valid elementary subsumptions whose left-hand side is C :Lemma 5.11. If C (cid:8) D is elementary w.r.t. K and O, C (cid:28)= ⊥, and (I, d) is a canonical model of C , thenK− ∪ pos(O+K) |= C (cid:8) D iff (I, d) |= D .Proof. (Only If part) Assume that K− ∪ pos(O+I ⊆ DC. Moreover, by Lemma 5.10.b, d ∈ CI ⊆ DII. Therefore (I, d) |= D.K) |= C (cid:8) D. By Lemma 5.10.a, we have I |= K− ∪ pos(O+K), so by assumption (If part) Assume that (I, d) |= D. We are going to prove that K− ∪ pos(O+If D = A (a concept name), then d ∈ A(cid:6) (cid:2)ni=1 Ai (cid:8) Aand pos(O+K) |= C (cid:8) D by structural induction on D.by assumption. Then, by construction of I, there must be an inclusion (cid:2)ni=1 AiK), where A1, . . . , An are the top-level concept names of C . This implies that both |= C (cid:8)i=1 Ai (cid:8) A hold, hence K− ∪ pos(O+∈ pos(O+(cid:2)nK) |= C (cid:8) D.K) |=(cid:7)IIf D = D1 (cid:13) D2, then (I, d) |= D i (i = 1, 2), therefore, by induction hypothesis, K− ∪ pos(O+K) |= C (cid:8) D i (i = 1, 2), hence K− ∪ pos(O+K) |= C (cid:8) D.If D = ∃R.D1, then for some di ∈ (cid:3)Iand (Ii, di) |= D1, where (Ii, di) (by construction of I) is the canonical model of a concept C1 occurring in a top-level restriction ∃R.C1 of C . It follows that |= C (cid:8) ∃R.C1 and (by induction K) |= C1 (cid:8) D1, hence K− ∪ pos(O+hypothesis) K− ∪ pos(O+K) |= C (cid:8) D.I(cid:29)) ∈ f(cid:29)], so by interval safety (that is implied by the assumption that C (cid:8) D is elementary), [(cid:4)(cid:29), u. By construction of I, C must contain a top-level constraint (cid:29)] ⊆ [(cid:4), u]. Then |= C (cid:8)If D = ∃ f .[(cid:4), u], then for some u(cid:29) ∈ [(cid:4), u], (d, u, (d, di) ∈ RI∃ f .[(cid:4)(cid:29), uD. (cid:2)Moreover, by means of canonical models, one can prove that interval safety makes the non-convex logic PL behave likea convex logic.Lemma 5.12. For all interval safe PL subsumption queries q =K and O, the entailment K− ∪ pos(O+K) |= q holds iff for all i ∈ [1, m] there exists j ∈ [1, n] such that K− ∪ pos(O+K) |= Ci (cid:8) D j .C1 (cid:15) . . . (cid:15) Cm (cid:8) D1 (cid:15) . . . (cid:15) Dnsuch that each Ci is normalized w.r.t. (cid:6)(cid:7)j=1 D j holds for all i ∈ [1, m], (ii) if KB |= Ci (cid:8) D j holds for some j ∈ [1, n], then KB |= Ci (cid:8) (cid:15)nK). By simple logical inferences, these two facts hold: (i) KB |= q iff KB |= Ci (cid:8)j=1 D j . So we are only left j=1 D j .By assumption and Lemma 5.11, the canonical model (I, d) of Ci is such that (I, d) |= ¬D j for all j ∈ [1, n]. Therefore j=1 D j . Moreover, (I, d) satisfies both KB and Ci by Lemma 5.10. Then I and d witness that KB (cid:28)|= Ci (cid:8)Proof. Let KB abbreviate K− ∪ pos(O+(cid:15)nto show the converse of (ii): assuming that for all j ∈ [1, n], KB (cid:28)|= Ci (cid:8) D j holds, we shall prove that KB (cid:28)|= Ci (cid:8) (cid:15)n(I, d) |= ¬ (cid:15)n(cid:15)nj=1 D j . (cid:2)Now that the semantic properties are laid out, we focus on the algorithms. Roughly speaking, the next lemma says that O+K decides whether the canonical model (I, d) of C satisfies D.STSLemma 5.13. If C (cid:8) D is elementary w.r.t. K and O, C (cid:28)= ⊥, and (I, d) is the canonical model of C , thenO+K (C (cid:8) D) = true iff (I, d) |= D .STS20P.A. Bonatti, L. Ioffredo, I.M. Petrova et al.Artificial Intelligence 289 (2020) 103389(cid:2)ni=1 Ai (cid:8) A in pos(O+Proof. By structural induction on D. If D = A (a concept name), then by definition STSan inclusion By def. of I, this holds iff d ∈ AK (C (cid:8) D) = true iff there exists K) such that the Ai ’s are the top-level concept names in C (see line 3 of Algorithm 3). , that is, (I, d) |= D. This proves the base case.If D = D1 (cid:13) D2, then the lemma follows easily from the induction hypothesis (see line 6 of Algorithm 3).If D = ∃R.D1, then STSK (C (cid:8) D) = true iff: (i) C has a top-level subconcept ∃R.C1, and (ii) STSK (C1 (cid:8) D1) = true(see line 5). Moreover, by definition of I, (I, d) |= D holds iff fact (i) holds and: (ii’) (Ii, di) |= D1, where (Ii, di) is a canonical model of C1. By induction hypothesis, (ii) is equivalent to (ii’), so the lemma immediately follows.O+O+IIf D = ∃ f .[(cid:4), u], then STSK (C (cid:8) D) = true iff the following property holds:O+O+C has a top-level subconcept ∃ f .[(cid:4)(cid:29)(cid:29)] such that [(cid:4)(cid:29), u(cid:29)] ⊆ [(cid:4), u], u(11)(see line 4). We are only left to prove that (11) is equivalent to (I, d) |= D.Property (11) implies (by construction of I) that (d, uConversely, if (I, d) |= D, then there exists u(cid:29) ∈ (cid:3)Imust have a top-level subconcept ∃ f .[(cid:4)(cid:29), uthe fact that [(cid:4)(cid:29), u(cid:29)] and [(cid:4), u] have u(cid:29)I(cid:29)) ∈ fand usuch that (d, u(cid:29) ∈ [(cid:4), u], that is, (I, d) |= D.(cid:29)) ∈ fI(cid:29) ∈ [(cid:4), u]. Then, by construction of I, C(cid:29)]. By interval safety (that is implied by the hypothesis that C (cid:8) D is elementary), (cid:29)] ⊆ [(cid:4), u]. Therefore, (11) holds. This completes the proof. (cid:2)in common implies [(cid:4)(cid:29), uand uWe are now ready to prove that PLROis correct and complete.Theorem 5.14. Let (cid:26)K, O, C (cid:8) D(cid:27) be any instance of PLSO. ThenPLRO(K, C (cid:8) D) = true iff K ∪ O |= C (cid:8) D .(cid:29)(cid:29)STSProof. D is of the form D1 (cid:15) . . . (cid:15) Dn. Let C1 (cid:15) . . . (cid:15) Cm be the concept Cproving the following claim, for all i = 1, . . . , m and j = 1, . . . , n:O+K (Ci (cid:8) D j) = true iff K− ∪ pos(O+K) |= Ci (cid:8) D j .There are two possibilities. If Ci = ⊥, then clearly K− ∪ pos(O+K (Ci (cid:8) D j) = true (see line 2 of Algorithm 3), so (12) holds in this case. If C (cid:28)= ⊥, then note that Ci (cid:8) D j is elementary w.r.t. K and O by construction of (cid:29)(cid:29)(which is obtained by splitting the intervals of the normalization of C w.r.t. K and O). Then (12) follows immediately Cfrom Lemmas 5.11 and 5.13.computed by lines 2 and 3 of PLRK) |= Ci (cid:8) D j and STSBy (12) and convexity (Lemma 5.12), we have that lines 5–11 of Algorithm 4 return true iff K− ∪ pos(O+(cid:29)(cid:29) (cid:8) D. Moreover, Ccan be equivalently replaced by C in this entailment, by Proposition 5.7 and Proposition 4.5. The resulting entailment is equivalent to K ∪ O |= C (cid:8) D by Theorem 5.6. It follows that Algorithm 4 returns true iff K ∪ O |= C (cid:8) D. (cid:2). We start by K) |= C(12)O+(cid:29)(cid:29)OOPLRruns in polynomial time, modulo the cost of oracle queries.Lemma 5.15. PLRnumber of interval constraints occurring in a single simple concept of C .O(K, C (cid:8) D) runs in time O (|C (cid:8) D|c+1 + |C (cid:8) D|2 · |K|) using an oracle23 for pos(O+K), where c is the maximum K counts as one Proof. Each query to the oracle triggered by the application of normalization rule 7 or by line 3 of STSstep of computation, according to the definition of time complexity for oracle machines. Then, by the same arguments used takes time O (|C|2 · |K| +in the proof of Lemma 4.11, the computation of the normalization steps in lines 2 and 3 of PLR|C| · |D|c), while the loops spanning over lines 5–9 take time O (|D| · |C| · |K|). The lemma follows by expressing the size of C and D in terms of |C (cid:8) D| (as in Lemma 4.11). (cid:2)OO+As a consequence of the above lemma, the classes of subsumption instances where c is bounded can be decided in polynomial time, modulo the cost of oracle queries.Definition 5.16. For all non-negative integers c, let PLSOc be the set of PLSO instances (cid:26)K, O, C (cid:8) D(cid:27) such that the maximum number of interval constraints occurring in a single simple concept of C is bounded by c.Theorem 5.17. For all c, PLSOc is in Ppos(O+K).Computing the consequences of O, in general, is intractable, although O is restricted to Horn-SRIQ knowledge bases. Hhorn– subsumption For other Horn DLs, however – like the profiles of OWL2 and their generalizations EL++and DL-lite23 Here we mean the notion of “oracle” used in the definition of oracle machines and related complexity classes [43].21P.A. Bonatti, L. Ioffredo, I.M. Petrova et al.Artificial Intelligence 289 (2020) 103389checking is tractable. By Theorem 5.17, the tractability of convex oracles extends to reasoning in PL with such oracles. More precisely, it suffices to assume that membership in pos(O+K) can be decided in polynomial time, since in that case Ppos(O+horn, since the axioms shifted from K to O (i.e. O+K \ O) and DL-litecan be expressed both in EL++K is in the same logic as O. This is formalized as follows:K) = P. This is what happens when O is in EL++and in DL-lite, therefore O+HDefinition 5.18. For all integers c ≥ 0, let PLSODLcbe the set of instances of PLSOc whose oracle is in DL.Corollary 5.19. For all c ≥ 0, PLSOEL++cand PLSODL-litecHhornare in P.It can also be proved that the normalization rules in Table 4 may be used as a policy validation method, to detect unsatisfiable policies.Theorem 5.20. Let (cid:26)K, O, q(cid:27) be a PLSO instance and C be a PL concept such that (cid:2)(C) ∩ (cid:2)(O) ⊆ NC.1. A PL concept C = C1 (cid:15) . . . (cid:15) Cn is unsatisfiable w.r.t. K ∪ O iff Ci (cid:2)∗ ⊥ for all i ∈ [1, n].242. Under the above hypotheses, PL concept satisfiability testing w.r.t. K ∪ O is in Ppos(O+K) (hence in P if O belongs to a tractable logic).Proof. By Proposition 5.7 and Lemma 5.10, C is satisfiable w.r.t. K− ∪ pos(O+Moreover, by Theorem 5.6,K) iff Ci (cid:2)∗ ⊥ does not hold for some i ∈ [1, n]. K− ∪ pos(O+K) |= C (cid:8) ⊥ iff K ∪ O |= C (cid:8) ⊥ .Point 1 immediately follows. Next, note that normalization can be computed in polynomial time using an oracle for pos(O+K). This can be shown with a straightforward adaptation of the proof of Lemma 4.8 that takes into account the oracle queries in rule 7 (the details are left to the reader). Then Point 2 follows from the complexity of normalization and Point 1. (cid:2)5.3. Related tractability and intractability resultsPL knowledge bases are in OWL2-RL, a Horn fragment of OWL2; they are also in the extensions of EL and DL-lite with functional roles. Answering PL subsumption queries is equivalent to solving query containment problems with respect to PL knowledge bases, where the queries are the translation of PL concepts into formulae of first-order logic.25 Such formulae are instances of the class of queries investigated in [46], called extended faceted queries. Core faceted queries (or simply faceted queries, abbreviated with FQ) are formulae with one free variable, built from unary and binary predicates using ∨, ∧, and ∃; moreover, variables are restricted so that each faceted query equals the translation of a DL concept built from (cid:15), (cid:13), and ∃. A faceted query is conjunctive if it contains no occurrences of ∨; the set of conjunctive faceted queries is denoted by CFQ. The class of unions of faceted queries (UCFQ) consists of all the faceted queries where ∨ may occur only at the top level (i.e. it cannot be nested inside the other constructs). Extended faceted queries support a class Comp of operators for number comparison, a class of special predicates Agg for computing aggregates, and predicates Next, Nextfor traversing chains of binary relations. Different subclasses of extended FQ can be denoted by L[X ], where L ∈ {FQ, CFQ, UCFQ} specifies +} specifies which additional predicates are supported. For example, the restrictions on ∨, and X ⊆ {Comp, Agg, Next, Nextthe class of all extended faceted query is denoted by FQ[Comp,Agg,Next,Next]. Extended faceted queries are more general than the translation of PL subsumptions in the following ways:++• disjunctions can be nested within conjunctions;• queries may contain the special predicates for aggregates, Next, and Next+.The class of queries corresponding to PL concepts, where disjunction may occur only at the top level and the above special predicates are not allowed, is UCFQ[Comp] (unions of conjunctive faceted queries with comparison operators).The results of [46] show that deciding query containment in FQ (i.e. the class of faceted queries without special pred-icates nor comparison operators) is coNP-complete, even if the knowledge base is empty; hardness is proved by nesting disjunctions within conjunctions.Without such nesting (i.e. if we restrict to UCFQ), query containment may be tractable even if the knowledge base is can be reduced to query answering as follows: first introduce nonempty. In particular, the containment of a query Q in Qa fresh individual name a, then extend the knowledge base with a set of assertions that make Q (a) true (possibly by adding (cid:29)24 As usual, (cid:2)∗25 The translation of concepts into first-order formulae can be found in [4, Chapter 4] and [19].denotes the reflexive and transitive closure of (cid:2).22P.A. Bonatti, L. Ioffredo, I.M. Petrova et al.Artificial Intelligence 289 (2020) 103389additional fresh constants); finally evaluate Qand check whether a belongs to the answer [19]. Top-level disjunctions can be dealt with by exploiting convexity, as we do in this paper. The combined complexity of UCFQ answering is in P in many cases, see [6,5] for tractability results that apply to knowledge bases formulated in OWL2-EL and OWL2-QL, and to queries that are slightly more general than CFQ. Therefore the containment of UCFQ can be decided in polynomial time when the knowledge base belongs to these profiles.(cid:29)+The above reduction of containment, however, is not applicable to queries that contain special predicates.26 Indeed, [46, Lemma 5] proves that query containment in CFQ[Next,Next] is coNP-complete even if the knowledge base is empty. Ad-ditionally, due to the relationships between query containment and concept subsumption, our Theorem 4.1 implies that query containment in UCFQ[Comp] is coNP-hard, even if the knowledge base is empty and the leftmost query is conjunc-tive. Moreover, Theorem 4.12 shows that a constant bound on the number of comparisons per conjunctive query suffices to restore tractability, for all nonempty PL knowledge bases. Theorem 5.17 extends the tractability of UCFQ[Comp] with bounded intervals to all the combinations of PL knowledge bases with oracles formulated in any tractable fragment of Horn-SRIQ (under the restrictions of Definition 5.3).PL with oracles in EL+can also be regarded as a tractable extension of EL with functionality axioms and non-convex concrete domains in the queries. Unrestricted combinations of such constructs are generally intractable, when the knowledge base – as in our subsumption instances – is nonempty and contains unrestricted GCIs.More precisely, in the extension of EL with functional roles, subsumption checking is EXPTIME-complete, in general [3]. A tractability result for empty TBoxes is reported in [26, Fig. 4]; however, in the same paper, it is proved that even with acyclic TBoxes, subsumption is coNP-complete. Accordingly, OWL2-EL does not support functionality axioms, so PLknowledge bases cannot be encoded in this profile.The tractability of an extension of EL with non-convex concrete domains (like intervals) has been proved in [26], under the assumption that the TBox is a set of definitions of the form A ≡ C , where each A is a concept name and appears in the left-hand side of at most one definition.An extended analysis of the tractability threshold for the DL-lite family can be found in [2]. The results most closely related to our work are the following.The data complexity of query answering raises at the first level of the polynomial hierarchy if DL-liteHhorn is extended with functional roles. Knowledge base satisfiability becomes EXPTIME-complete (combined complexity). Under three syntactic restrictions [2, A1–A3] and the unique name assumption, both of the above reasoning tasks remain tractable. Nevertheless, OWL2-QL – that is founded on one of the simplest members of the DL-lite family – does not support functional roles, therefore it cannot be used to encode PL knowledge bases.PL knowledge bases with oracles in EL+Hhorn are in Horn-SHOIQ with (reuse)-safe roles [18,19]. This logic is tractable, and the role safety restriction replaces the modularity requirement of IBQ approaches.27 By means of the results Hof [18,19], PL knowledge bases with oracles in EL+horn can be translated into a Datalog program in polynomial time, preserving fact entailment. Then, subsumption checking can be reduced to conjunctive query answering as explained above. Recall, however, that this reduction does not apply to subsumptions with interval constraints; so the tractability results of [18,19] do not imply our results for PL subsumptions.and DL-liteor DL-liteThe most expressive knowledge representation language enjoying a complete structural subsumption algorithm – to the best of our knowledge – is CLASSIC [17], that supports neither concept unions ((cid:15)) nor qualified existential restrictions (∃R.C ). If unions were added, then subsumption checking would immediately become coNP-hard (unless concrete domains were restricted) for the same reasons why unrestricted subsumption checking is coNP-hard in PL (by Theorem 4.1). On the other hand, CLASSIC additionally supports qualified universal restrictions (that strictly generalize PL’s range restrictions), number restrictions, and role-value maps, therefore it is not comparable to PL. The complexity of the extensions of PLwith CLASSIC’s constructs is an interesting topic for further research.5.4. Compiling oracles into PL knowledge basesNote that pos(O+OOsuch knowledge compilation, PLRsubset of pos(O+K) queried by PLRK) might be compiled, i.e. computed once and for all, so as to reduce oracle queries to retrieval. After could run in polynomial time, no matter how complex O’s logic is, provided that the (i.e. the part of pos(O+K) that should be pre-computed) is polynomial, too.(cid:2)This is not always the case. The conjunctions of classes i Ai that may possibly occur in the left-hand side of subsump-tion queries are exponentially many in the signature’s size, and each of them may potentially occur in a query to the oracle. So, in order to limit the space of possible oracle queries and reduce the partial materialization of pos(O+K) to a manageable size, we have to limit the number of concepts that may occur in the left-hand side of subsumption queries.Fortunately, in SPECIAL’s use cases, the subsumption queries C (cid:8) D that implement compliance checks have always a business policy on the left-hand side, and the set of business policies of a controller is rather stable and not large. So the prerequisite for applying oracle compilation is satisfied. We are further going to show that the oracle can be compiled into 26 As far as Comp is concerned, the problem is that the arguments of comparison operators are numbers, so the idea of instantiating the atoms of Q with fresh individual names is not applicable.27 Of course, without modularity, query answering cannot be split among two specialized reasoners for the main part and the oracle, respectively.23P.A. Bonatti, L. Ioffredo, I.M. Petrova et al.Artificial Intelligence 289 (2020) 103389a plain, oracle-free PL knowledge base, therefore the IBQ framework can be implemented with the same efficiency as pure PL reasoning.We start the formalization of the above ideas by defining the restricted class of problem instances determined by the given set of business policies BP .Definition 5.21. For all sets of PL concepts BP , let PLSO(BP) be the set of all (cid:26)K, O, C (cid:8) D(cid:27) ∈ PLSO such that C ∈ BP .The first step of the oracle compilation consists in transforming business policies so as to collapse each conjunction of concept names into a single concept name. We say that the result of this transformation is in single-atom form, which is recursively defined as follows:Definition 5.22. A simple PL concept C is in single-atom form if eitherm∃ f i.[li, ui]) (cid:13) (1. C is of the form (i=1(cid:2)m2. C is of the form A (cid:13) (i=1(cid:2)k∃R i.Ci), where m, k ≥ 0, and each Ci is in single-atom form, ori=1(cid:2)k∃R i.Ci) where m, k ≥ 0, and each Ci is in single-atom form.∃ f i.[li, ui]) (cid:13) (i=1(cid:2)A full PL concept C1 (cid:15) . . . (cid:15) Cn is in single atom form if C1, . . . , Cn are all in single atom form.The given business policies can be transformed in single atom form in linear time:Proposition 5.23. For all finite sets of concepts BP there exist a set of concepts BP∗in single atom form, and a knowledge base O∗that belongs to both EL and DL-litehorn, such that for all (cid:26)K, O, C (cid:8) D(cid:27) ∈ PLSO(BP) there exists an equivalent problem instance (cid:26)K, O ∪ O∗, C∗ (cid:8) D(cid:27) ∈ PLSO(BP ∗), that is:K ∪ O |= C (cid:8) D iff K ∪ O ∪ O∗ |= C∗ (cid:8) D .Moreover, BP ∗and O∗can be computed in time O (|BP|).Proof. For all C ∈ BP , we obtain the corresponding concept Cin C with a single fresh concept name, whose definition is included in O∗j = 1, . . . , n, replace each∗by replacing each intersection of multiple concept names . More precisely, if C = C1 (cid:15) . . . (cid:15) Cn then for all n(cid:3)C j = (Ai) (cid:13) (i=m(cid:3)i=1∃ f i.[li, ui]) (cid:13) (k(cid:3)i=1∃R i.D i)such that n > 1 with∗jC= B (cid:13) (m(cid:3)i=1∃ f i.[li, ui]) (cid:13) (k(cid:3)i=1∃R i.D∗i ) ,where B is a fresh concept name and each DThe knowledge base O∗by the above transformations and ∗iis the set of all the definitions B ≡ (is obtained by recursively applying the same transformation to D i .(cid:2)ni= Ai) such that B is one of the fresh concepts introduced (cid:2)ni= Ai is the intersection replaced by B.∗(cid:15) . . . (cid:15) Cn obtained with the above procedure. Clearly, by construction, , for all C ∈ BP . Moreover, K ∪ O ∪ O∗is a conservative extension of K ∪ O. Thereforebe the set of concepts C∗∗ = C∗1Finally, let BP ∗K ∪ O ∪ O∗ |= C ≡ CK ∪ O |= C (cid:8) D iff K ∪ O ∪ O∗ |= C (cid:8) Diff K ∪ O ∪ O∗ |= Cand O∗∗ (cid:8) D .Concerning complexity, BP ∗the replacement of be computed in time O (|BP|). (cid:2)(cid:2)ni= Ai and the generation of the definition for B take linear time in |C j|. Therefore BP ∗can be computed with a single scan of BP ; the generation of the fresh concepts B, can and O∗By the above proposition, we can assume without loss of generality that BP is in single atom form. Note that the ontologies K and O, in a typical application scenario, do not change frequently. So we can fix them and assume that the concepts in BP are already normalized w.r.t. K and O. The set of problem instances with fixed K and O is defined as follows:PLSO(K, O, BP) = {(cid:26)K(cid:29), O(cid:29), C (cid:8) D(cid:27) ∈ PLSO | K(cid:29) = K, O(cid:29) = O, and C ∈ BP} .24P.A. Bonatti, L. Ioffredo, I.M. Petrova et al.Artificial Intelligence 289 (2020) 103389The compilation of K and O into a single PL knowledge base is defined as follows:comp(K, O) = K− ∪ { A (cid:8) B | ( A (cid:8) B) ∈ pos(O+K)} .The correctness of oracle compilation is proved by the next theorem.Theorem 5.24. Let K and O be two knowledge bases in PL and Horn-SRIQ, respectively, and let BP be a set of PL concepts in single atom form and normalized w.r.t. K and O. Then, for all (cid:26)K, O, C (cid:8) D(cid:27) ∈ PLSO(K, O, BP),PLRO(K, C (cid:8) D) = PLR(comp(K, O), C (cid:8) D) .Proof. Since C is already normalized w.r.t. K and O by hypothesis, line 3 of PLRcomputes the identity function (i.e. (cid:29) = C ). It is easy to see that line 2 of PLR does the same. First, note that the two versions of rules 4 and 6 (in Table 3Cand Table 4) apply to the same set of functionality and range axioms, since func(R) ∈ comp(K, O) ⇔ func(R) ∈ K−and range(R, A) ∈ comp(K, O) ⇔ range(R, A) ∈ K−(by definition of comp). So there are no additional axioms in comp(K, O)that may trigger rules 4 or 6 in PLR. Second, since C is in single atom form by hypothesis, rule 7 of Table 3 never applies. The other normalization rules are the same for PLRand PLR produce (cid:29)(cid:29) = splitD (C).the same concept CConsequently, the loops in lines 5–9 of PLRand lines 4–8 of PLR return the same result, too. To see this, it suffices to and PLR. We conclude that lines 2 and 3 of PLROOOOshow thatSTSO+K (Ci (cid:8) D j) = STS(comp(K, O), Ci (cid:8) D j) .O+(13)O+The only difference between STSall of the form ( A1 (cid:8) A) ∈ pos(O+atom form). For the same reason, STS in line 3 checks whether A1 (cid:8)∗therefore (13) holds and the theorem is proved. (cid:2)K and STS is in their line 3. The membership tests executed by STSK in line 3 are K), because C j is in single atom form (this follows from the hypothesis that C is in single A. The two tests are equivalent by definition of comp, Remark 5.25. Note that the size of comp(K, O) is at most quadratic in the size of K ∪ O, and that PLR runs in polynomial time if the number of interval constraints per simple policy is bounded. Therefore, under this assumption – and after comp(K, O) has been computed – subsumption queries can be answered in polynomial time. If O uses expressive constructs from Horn-SRIQ, then their computational cost is confined to the compilation phase only, that is essentially a standard classification of O+K. (cid:2)A caveat on the size of comp(K, O) is in order, here. If the given set of policies BP is not in single atom form, then O must be replaced by O ∪ O∗, as shown in Proposition 5.23, where the size of O∗is O (|BP|). Therefore the size of comp(K, O ∪ O∗) may grow quadratically with |BP|. This relationship shows the influence of BP ’s size on the complexity of the oracle compilation approach. So, unfortunately, oracle compilation is not always possible. For example, in the application of PL to data markets illustrated in the conclusions, we currently see no general criterion to restrict the space of possible queries as required by the compilation method.Remark 5.26. Using the compilation approach, the soundness and completeness of PLR follow easily from the soundness ∅(K, q) = true. So it suffices to show that and completeness of PLR∅(K, q). Note that comp(K, ∅) is simply the closure of K with respect to inclusions (that is, comp(K, ∅)PLR(K, q) = PLRpreserves the relation (cid:8)∗associated to K). This fact and Theorem 5.24, respectively, imply that, according to which K |= q holds if and only if PLRO∅PLR(K, q) = PLR(comp(K, ∅), q) = PLR(K, q).Similarly, the equality PLR(K, q) = PLR∅(K, q) and the correspondence between the closure (cid:8)∗of the inclusions in Kand those in comp(K, ∅), immediately imply the following corollary of Theorem 5.20:Corollary 5.27. Let K be a PL knowledge base.1. A PL concept C = C1 (cid:15) . . . (cid:15) Cn is unsatisfiable w.r.t. K iff Ci (cid:2) ⊥ for all i ∈ [1, n].2. PL concept satisfiability w.r.t. K can be checked in polynomial time.5.5. On the limitations posed on PLSOIn this section we briefly motivate the restrictions posed on PL subsumption problems with oracles (PLSO). We start with the requirements on the oracle. Recall that O should be convex w.r.t. QL and should not use nominals. Convexity w.r.t. QL is essential for tractability, as shown by the next result.25P.A. Bonatti, L. Ioffredo, I.M. Petrova et al.Artificial Intelligence 289 (2020) 103389Theorem 5.28. If O is not convex w.r.t. QL and enjoys the disjoint model union property, then there exists a PL knowledge base Ksuch that deciding whether K ∪ O |= C (cid:8) D holds, given an interval-safe PL subsumption query C (cid:8) D, is co-NP hard.Proof. We are proving coNP-hardness by reducing 3SAT to the complement of subsumption. By hypothesis, pos(O) contains an inclusionA1 (cid:13) . . . (cid:13) An (cid:8) B1 (cid:15) . . . (cid:15) Bm(14)such that none of the inclusions A1 (cid:13) . . . (cid:13) An (cid:8) B i belongs to pos(O), for i = 1, . . . , m. Without loss of generality, we can further assume that A1 (cid:13) . . . (cid:13) An (cid:8) B2 (cid:15) . . . (cid:15) Bm is not in pos(O) (if not, then discard some B i from (14) until the right-hand side is a minimal union entailed by A1 (cid:13) . . . (cid:13) An). Now let K be the following set of inclusions, where Aare fresh concept names:(cid:29) (cid:8) AiA(cid:29)B j (cid:8) BNote that K ∪ O |= Awith B1 and B, by construction of K and (14). We are going to represent the truth values true and false(i = 1, . . . , n)( j = 2, . . . , m) .(cid:29)(cid:29) (cid:8) B1 (cid:15) B, respectively.and B(cid:29)(cid:29)(cid:29)Let S be any instance of 3SAT, and let p1, . . . , pk be the propositional symbols occurring in S. We assume without loss of generality that p1, . . . , pk do not occur in K nor in O. Each positive literal pi is encoded by e(pi) = ∃pi.B1, while negative literals ¬pi are encoded by e(¬pi) = ∃pi.B. Then the negation of S is encoded by(cid:29)D =(cid:15){e(¯L1) (cid:13) e(¯L2) (cid:13) e(¯L3) | L1 ∨ L2 ∨ L3 ∈ S} .(where each ¯Li is the literal complementary to Li ). We claim that the non-entailment(cid:8) D(15)K ∪ O (cid:28)|=(cid:6) (cid:3)(cid:7)(cid:29)∃pi. Aiholds iff S is satisfiable (note that the above subsumption query is interval-free, hence trivially interval safe). To prove the “only if” part, assume that (15) holds, that is, there exists a pointed interpretation (I, d) such that I |= K ∪ O, d ∈(cid:6) (cid:2)(cid:29)) holds for each symbol pi , there exists di ∈ (cid:3)I. Since K ∪ O |=and d /∈ D∃pi. A(cid:6) (cid:2)(cid:7)I(cid:7)I(cid:29)i(cid:29)∃pi. A(cid:29))II1 or di ∈ (B(cid:8) (∃pi.B1) (cid:15) (∃pi.B. Construct a truth assignment σ for S by settingisuch that (d, di) ∈ p(cid:8)Ii and either di ∈ Bif di ∈ Bif di /∈ BtruefalseI1 ,I1 (therefore di ∈ (B(cid:29))I ) .σ (pi) =ISince d /∈ Dsatisfies the literal, by definition. It follows immediately that σ satisfies S., each clause L1 ∨ L2 ∨ L3 of S contains a literal pi or ¬pi such that, respectively, di ∈ BI1 or di ∈ (B(cid:29))I, so σConversely, suppose that S is satisfied by a truth assignment σ . We are going to construct a pointed interpretation (I, ¯d)that witnesses (15). Recall that neither A1 (cid:13) . . . (cid:13) An (cid:8) B1 nor A1 (cid:13) . . . (cid:13) An (cid:8) B2 (cid:15) . . . (cid:15) Bm belong to pos(O). Then O has two disjoint models M1 and M2 such that for some d1 ∈ (cid:3)M1 and d2 ∈ (cid:3)M2 ,di ∈ ( A1 (cid:13) . . . (cid:13) An)Mid1 /∈ Bd2 /∈ (B2 (cid:15) . . . (cid:15) Bm)M2 .M11(i = 1, 2)The union U = M1 (cid:25) M2 is still a model of O by hypothesis, and it can be extended to a model J of K ∪ O by setting:(cid:3)J = (cid:3)U(cid:29))J = ( A1 (cid:13) . . . (cid:13) An)J)J = (B2 (cid:15) . . . (cid:15) Bm)J .(cid:29)( A(BFinally, we extend J to the witness I as follows. First let (cid:3)I = (cid:3)Jand choose any ¯d ∈ (cid:3)J. For all symbols pi define:IiIipp= {(¯d, d1)}= {(¯d, d2)}if σ (pi) = false ,otherwise .(cid:7)(cid:2)Note that ¯d belongs to (in S contains a literal L satisfied by σ . If L = ¬pi , then pthen p= {(¯d, d2)}, therefore ¯d /∈ (∃pi.B(cid:29))I = e(¯L)I∃pi. A(cid:29)iIiIi= {(¯d, d1)}, therefore ¯d /∈ (∃pi.B1)I = e(¯L)I. It follows immediately that ¯d /∈ DI. (cid:2)by construction, so we are only left to prove that ¯d /∈ DI. By assumption, each clause . Similarly, if L = pi , 26P.A. Bonatti, L. Ioffredo, I.M. Petrova et al.Artificial Intelligence 289 (2020) 103389Note that the above theorem shows that reasoning can be intractable even if K and O are fixed.The requirement that nominals must not occur in oracles is needed for completeness. Our algorithm PLR– and the other IBQ methods where oracle queries are consistency tests of the form (10), or the equivalent inclusions of the form (9)– are generalized by the following definition, that accounts for the shifting of axioms from K to O.ODefinition 5.29. Let PI be a set of problem instances of the form (cid:26)K, O, q(cid:27), where K and O are knowledge bases and q is an inclusion. A shifting IBQ mechanism for PI is a pair of functions (s, r) such that for all (cid:26)K, O, q(cid:27) ∈ PI:1. s(K) ⊆ K,2. r(s(K), pos(O ∪ (K \ s(K))), q) = true iff K ∪ O |= q.Informally speaking, s determines which axioms are shifted from K to O, and r is the IBQ reasoner that decides entail-ment using the modified knowledge bases. Shifting IBQ mechanisms do not exist if O may use nominals.Theorem 5.30. Let DL be a description logic that supports nominals and disjointness axioms. Let PI be any set of problem instances that contains all (cid:26)K, O, q(cid:27) such that K = ∅, O is a DL knowledge base, and q is an EL inclusion.28 There exists no shifting IBQ mechanism for PI.Proof. Let K = ∅ and q = ∃R.( A (cid:13) B) (cid:13) ∃R.( A (cid:13) ¯B) (cid:8) A(cid:29). LetO1 = {disj(B, ¯B)} ,O2 = {disj(B, ¯B), A (cid:8) {a}} .Note that both (cid:26)K, O1, q(cid:27) and (cid:26)K, O2, q(cid:27) belong to PI.It can be easily verified that pos(O1) = pos(O 2); in particular, the two sets contain all the inclusions of the form A1 (cid:13). . . (cid:13) Am (cid:8) B1 (cid:15) . . . (cid:15) Bn such that:• either the inclusion is a tautology (i.e. some concept name occurs both in the left-hand side and in the right-hand side),• or both B and ¯B occur in the left-hand side.However, K ∪O1 (cid:28)|= q, while K ∪O2 |= q. The latter fact holds because due to the nominal {a}, both ∃R.( A (cid:13) B) and ∃R.( A (cid:13) ¯B)should have the same role filler, that cannot satisfy the disjoint concepts B and ¯B at the same time. It follows that q is trivially satisfied because its left-hand side is equivalent to ⊥.Now suppose that a shifting IBQ mechanism (s, r) for PI exists; we shall derive a contradiction. By condition 2 of Definition 5.29,r(s(K), pos(O1 ∪ (K \ s(K))), q) = falser(s(K), pos(O2 ∪ (K \ s(K))), q) = true .However, K = s(K) = ∅ and consequently:r(s(K), pos(O1 ∪ (K \ s(K))), q) = r(∅, pos(O1), q)= r(∅, pos(O2), q)= r(s(K), pos(O2 ∪ (K \ s(K))), q)which contradicts (16) and (17). (cid:2)(16)(17)Remark 5.31. The above result complements the analogous negative result [20, Theorem 4] that applies to knowledge bases K with infinity axioms (while PL knowledge bases have the finite model property). On the other hand, [20, Theorem 4]covers also more expressive oracle query languages.The proof of the above negative result is based on the limited expressiveness of the oracle query language QL. A similar consideration applies to the requirement that (cid:2)(O) may share only concept names with (cid:2)(K) and (cid:2)(q). Without this assumption, PLRis not complete. More generally:OTheorem 5.32. Let PI be a set of problem instances that contains all (cid:26)K, O, q(cid:27) such that K = ∅, O is an EL knowledge base and q is an EL inclusion (possibly sharing roles with O). There exists no shifting IBQ mechanism for PI.28 We use EL inclusions to strengthen our result, since they are a special case of PL subsumption queries.27P.A. Bonatti, L. Ioffredo, I.M. Petrova et al.Artificial Intelligence 289 (2020) 103389Proof. Let K = ∅, q = (∃R. A (cid:8) ∃S. A), O1 = ∅ and O2 = {q}. Note that• pos(O1) = pos(O2) (both contain all and only the tautological inclusions of the form (9));• K ∪ O1 (cid:28)|= q ;• K ∪ O2 |= q.Then the assumption that a shifting IBQ mechanism for PI exists leads to a contradiction, by the same argument used in Theorem 5.30. (cid:2)In the light of the above negative results, a natural question is whether an oracle query language more expressive than QL would remove the need for the restrictions on nominals and roles. Note that IBQ mechanisms for shared roles have already been introduced in [20]. For a fragment of EL, there exists an IBQ algorithm that terminates in polynomial time. Nominals are not allowed, but shared roles are, under suitable conditions.In order to support more expressive oracle queries, PLRK should be extensively changed, though. The proofs O+of the above negative results reveal that the simple treatment of existential restrictions in STSK should be replaced with a more complex computation, involving oracle queries, and it is currently not clear how significantly such changes would affect the scalability of reasoning and the possibility of compiling oracles into PL knowledge bases. Given that scalability is one of SPECIAL’s primary requirements, and that there is no evidence that shared roles are needed by SPECIAL’s application scenarios (cf. Remark 5.1), we leave this question as an interesting topic for further research.and STSOO+6. Experimental assessmentOIn this section we describe a Java implementation of PLR and compare its performance with that of other popular engines. We focus on PLR (as opposed to the more complex PLR) because SPECIAL’s application scenarios are compatible with the oracle compilation into a PL knowledge base illustrated in Section 5.4. The implementation and experimental evaluation of PLR, that may be interesting in other applications of PL, lie beyond the scope of this paper.SPECIAL’s engine is tested on two randomly generated sets of inputs. The first set is based on the knowledge base and policies developed for Proximus and Thomson Reuters. Consent policies are generated by modifying the business policies, mimicking a selection of privacy options from a list provided by the controller. This first set of test cases is meant to assess the performance of the engines in the application scenarios that we expect to arise more frequently in practice. The second set of experiments, that makes use of larger knowledge bases and policies, is meant to predict the behavior of the engines in more complex scenarios, should they arise in the future.OThe implementation of PLR and its optimizations are described in the next subsection. Then Section 6.2 illustrates the test cases used for the evaluation. Finally, Section 6.3 reports the results of the experiments.6.1. Prototype implementation and optimizationPLR is implemented in Java and it is distributed as a .jar file. The reasoner’s class is named PLReasoner, and supports the standard OWL APIs, version 5.1.7. The package includes a complete implementation of PLR, including the structural subsumption algorithm STS, and the preliminary normalization phases, based on the 7 rewrite rules and on the interval splitting method for interval safety.The interval splitting method has been refined in order to reduce the explosion of business policies. The reason for refinements can be easily seen: if a business policy contains interval [1, 10] and a consent policy contains [5, 10], then the method illustrated in (8) splits [1, 10] into the (unnecessarily large) set of intervals[1, 1], [2, 4], [5, 5], [6, 9], [10, 10] ,that cause a single simple policy to be replaced with 5 policies. Note that for interval safety the splitting [1, 4], [5, 10]would be enough. While (8) is convenient in the theoretical analysis – because it has a simpler definition and it does not increase asymptotic complexity – a more articulated algorithm is advisable in practice. Here we only sketch the underlying idea: each interval end point is classified based on whether it occurs only as a lower bound, only as an upper bound, or both. A singleton interval is generated only for the third category of endpoints, while the others are treated more efficiently. In particular, in the above example, 1 and 5 occur only as lower bounds; this allows to generate non-singleton sub-intervals that have 1 and 5 as their lower bound. Moreover, 10 occurs only as an upper bound; this allows to create a non-singleton sub-interval where 10 is the upper bound. Accordingly, the refined splitting algorithm generates only the two intervals [1, 4]and [5, 10].Several other optimizations have been implemented and assessed. The corresponding versions of PLR are described below:28P.A. Bonatti, L. Ioffredo, I.M. Petrova et al.Artificial Intelligence 289 (2020) 103389PLR cThe normalization steps (lines 2 and 3 of PLR) are one of the most expensive parts of the reasoner. In order to reduce their cost, two caches are introduced. The first cache stores the business policies that have already been normalized w.r.t. K (line 2 of PLR). In this way, the seven rewrite rules are applied to each business policy only once; when the policy is used again, line 2 simply retrieves the normalized concept from the cache. This optimization is expected to be effective in SPECIAL’s application scenarios because only business policies need to be normalized, and their number is limited. So the probability of re-using an already normalized policy is high, and the cache is not going to grow indefinitely; on the contrary its size is expected to be moderate.Similarly, a second cache indexed by the two policies C and D stores the concepts split D (C) already computed (thereby speeding up line 3 of PLR, that is, the interval splitting step needed for interval safety).PLR 2n, PLR c 2nPLR 2n normalizes both C and D with the seven rewrite rules, before computing splitD (C). Since the rewrite rules may merge and delete the intervals of D, this optimization potentially reduces the number of splitting points and, consequently, the size of splitD (C). We denote with PLR c 2n the version of PLR that exploits both the caches of PLR c and applies double normalization, as PLR pre.PLR pre, PLR pre 2nSometimes the two normalization phases can be pre-computed. When the set of business policies and the set of intervals that may occur in consent policies are known in advance, the seven rules and interval splitting can be applied once and for all before compliance checking starts. For example, intervals are available in advance when the minimum or maximum storage time are determined by law, or when the duration options available to data subjects when consent is requested are specified by the data controller. This version of the engine is designed for such scenarios. The given set of business policies is fully normalized before compliance checking starts, and stored in the caches supported by PLR c. During compliance checking, lines 2 and 3 only retrieve concepts from the caches. In this way the cost of a compliance check is almost exclusively the cost of STS. This version of PLR will be evaluated by measuring compliance checking time only; preliminary normalizations are not included.6.2. Test case generationThe first set of test cases is derived from the business policies developed for the pilots of Proximus and Thomson Reuters; these policies will be denoted with P PXS and P TR respectively.In each compliance check P B (cid:8) P C , P B is a union of simple business policies randomly selected from those occurring in the pilots’ policy ( P PXS or P TR). Since P B describes the activity of a business process of the data controller, the random choice of P B essentially corresponds to a random distribution of the controller’s data processing activities (abstracted by the simple policies) across its business processes.The consent policy P C is the union of a set of simple policies P iC (i = 1, . . . , n) randomly selected from the pilots’ policy, and randomly perturbed by replacing some vocabulary terms with a different term. The random selection mimicks the opt-in/opt-out choices of data subjects with respect to the various data processing activities modeled by the simple policies. Similarly, the random replacement of terms simulates the opt-in/opt-out choices of the data subject w.r.t. each component of the selected simple policies. More precisely, if the modified term occurring in P iC is a superclass (resp. a subclass) of the corresponding term in the original business policy, then the data subject opted for a broader (resp. more restrictive) permission relative to the involved policy property (e.g. data categories, purpose, and so on).In this batch of experiments, the knowledge base is always SPECIAL’s ontology, that defines policy roles and the tempo-rary vocabularies for data categories, purpose categories, etc. The size and number of this batch of experiments is reported in Table 5. The number of randomly generated business policies is higher in one case because P PXS has more simple poli-cies than P TR: the ratio is 20 generated policies per simple policy. Queries have been obtained by generating 100 consent policies for each business policy. Table 5 reports also the average number of simple policies per generated policy and its standard deviation. The size of each policy is limited by SPECIAL’s usage policy format: at most one interval constraint per simple policy, and nesting depth 2.In the second set of experiments, both the ontologies and PL subsumptions are completely synthetic, and have in-creasing size in order to set up a stress test for verifying the scalability of SPECIAL’s reasoner. Fifteen ontologies have been generated: five for each of the three sets of parameters O1–O3 reported in Table 6. The same table reports the parameters used to generate the PL concepts occurring in the queries, according to two size specifications: P1 and P2.Note that approximately half of the roles and concrete properties are functional, and half of the roles have a range axiom. Ontologies have been generated by randomly distributing classes over approximately log(#classes) layers. Then the specified number of disjointness axioms have been generated, by picking classes on the same layer. Finally, about 2 · #classesinclusions have been created, mostly across adjacent layers, in such a way that no class became inconsistent. The ratio 29P.A. Bonatti, L. Ioffredo, I.M. Petrova et al.Artificial Intelligence 289 (2020) 103389Table 5Size of the test cases inspired by the pilots.Proximus (PXS)Thomson Reuters (TR)Ontologyinclusionsdisjrangefuncclassification hierarchy heightBusiness policies# generated policiesavg. simple pol. per full pol.std. dev.Consent policies# generated policiesavg. simple pol. per full pol.std. dev.Test cases# generated queries1861110841202.711.7212,0003.772.0212,0001861110841002.391.8610,0003.422.0310,000Table 6Size of fully synthetic test cases.Ontology sizeclassesrolesconcrete propertiesfuncrangeavg. disjavg. inclusionsavg. classification hierarchy heightO1100101010532118O2O31,000502537253122241010,0001005075502982341814Concept sizemax #simple pol. per full pol.max #top-level inters. per simple subconceptmax depth (nesting)avg. #simple pol. per full pol.avg. depthSimple policy sizeavg. #intersectionsavg. #intervalsP1101046.82.4P210020950.1510.63.725.89between the number of inclusions and the number of classes is similar to the ratio that can be observed most frequently in real ontologies, cf. [36,35,33].We have generated 100 concepts of size P1 and 1000 of size P2, picking interval endpoints from [0, 365] (one year, in days). Each set has been split into business and consent policies (resp. 30% and 70% of the generated policies), that have been paired randomly to generate test queries. The number of queries of size P1 generated for each ontology is 50. Let #int be the maximum number of interval constraints per simple policy after normalization w.r.t. the 7 rules29 (for a given business policy). The number of queries of size P2 generated for each ontology and each business policy with #int ≤ 5 is 10. The maximum number of queries for each ontology and each #int > 5 has been limited to 40, in order to keep the length of the experiments within a reasonable range. In this case, we maximized the number of different business policies occurring in the selected queries.For each ontology K, the business policies have been selected from the available K-consistent policies. Furthermore, whenever possible, queries have been selected in such a way that the number of positive and negative answers are the same. Table 6 illustrates the average size of the generated policies for each parameter setting. We have not limited the number of interval constraints, in order to analyze the behavior of PLReasoner as the number of intervals per simple policy grows (if it is not bounded then PL subsumption query answering is coNP-hard). The maximum nesting level occurring in the generated policies is approximately log2(max disjuncts)!.6.3. Performance analysisThe experiments have been run on a server with an 8-cores processor Intel Xeon Silver 4110, 11M cache, 198 GB RAM, running Ubuntu 18.04 and JVM 1.8.0_181, configured with 32 GB heap memory (of which less than 700 MB have been actually used in all experiments). We have not exploited parallelism in the engine’s implementation.29 The reason for measuring #int after normalization is explained later.30P.A. Bonatti, L. Ioffredo, I.M. Petrova et al.Artificial Intelligence 289 (2020) 103389Fig. 1. Comparisons on small/medium policies.Fig. 2. Impact of interval number per simple policy – large policies.First we compare PLR with Hermit, the only reasoner – among those we selected for comparison – that directly supports subsumptions with intervals.30 We start by illustrating the results for the test cases with small and medium policies. Fig. 1shows that PLR is faster than Hermit, over these test sets, even if no optimization is applied. The size of the ontology affects the performance of Hermit more than PLR’s (see the results for O1, O2, and O3).The good performance of PLR over PXS and TR had to be expected, given that the policies involved in these test sets are SPECIAL’s usage policies, that by definition contain at most one interval constraint per simple policy, of the form ∃has_duration.[(cid:4), u]. Let #int denote the maximum number of intervals per simple policy after applying the rewrite rules, and recall that the size of split D (C) may grow exponentially with #int. We have not limited #int, while generating the synthetic policies in P1 and P2, to see how the number of intervals affects the performance of PLR (recall that if #intis unbounded, then PL subsumption is coNP-complete). We measured the value of #int after applying the rewrite rules, because they can collapse and delete intervals, thereby reducing the complexity of the subsequent interval splitting phase and the size of split D (C). After the application of the seven rules, the maximum #int over the business policies occurring in P1’s queries is 9. Fig. 1 shows that the potential combinatorial explosion of split D (C) does not frequently occur with these policies. The probability of splitting a single interval into many sub-intervals is evidently not high. On the contrary, a combinatorial explosion is clearly observable in the test sets with large policies (P2); Fig. 2 illustrates the results for the smallest synthetic ontologies (O1).Then we analyzed the effects of the optimizations described in Section 6.1. Their effectiveness over small and medium policies is illustrated by Fig. 3. The normalization of consent policies (2n) brings no benefits with small policies (actually, it slightly decreases the engine’s performance, compare PLR 2n with PLR, and PLR c 2n with PLR c). Its benefits start to be visible with medium policies. The cache of normalized policies (PLR c) is the best option on small policies. On medium policies, the combination of the caches with the normalization of consent policies (PLR c 2n) is the most effective optimization.Over large policies (P2), the normalization of consent policies (2n) is essential to mitigate the combinatorial explosion of splitD (C), as shown in Fig. 4. The versions of PLR that do not normalize D become impractical already for #int = 3, while the computation time of PLR 2n and PLR c 2n moderately increases. This behavior can be explained by observing the effects of normalization on this test set: after the application of the rewrite rules, the average number of intervals is about 10 times smaller, which reduces the probability of an exponential growth of split D (C).30 See also Remark 6.1 below.31P.A. Bonatti, L. Ioffredo, I.M. Petrova et al.Artificial Intelligence 289 (2020) 103389Fig. 3. Effectiveness of optimizations on small/medium policies.Fig. 4. Effectiveness of optimizations on large policies and small ontologies.Next, in Fig. 5, we compare the best version of the engine over medium/large policies (i.e. PLR c 2n) with Hermit. The optimizations delay the effects of combinatorial explosions until #int = 7. After this threshold, Hermit becomes faster.Finally, we analyzed the effectiveness of business policy pre-normalization (pre). Recall that this approach is feasible in practice only if both the business policies and the intervals that may occur in consent policies are known in advance, and do not change frequently. The effects of pre-normalization on small and medium policies is remarkable: PLR pre is approximately one order of magnitude faster than Hermit, as shown in Fig. 6. Over pilot-inspired tests, pre-normalization brings the average time per subsumption query well below 500 μ-seconds.The effects of pre-normalization quickly disappear over large policies. Fig. 7 shows that the explosion of split D (C) makes it necessary to apply also the normalization of consent policies to delay combinatorial effects (see PLR pre 2n). However, for #int = 8, PLR pre 2n is slower than Hermit, so pre-normalization does not deal with the combinatorial explosion better than PLR c 2n.32P.A. Bonatti, L. Ioffredo, I.M. Petrova et al.Artificial Intelligence 289 (2020) 103389Fig. 5. Hermit vs PLR with caches and double normalization.Fig. 6. Effectiveness of business policy pre-normalization on small/medium policies.PLR can also be compared with ELK – a specialized reasoner for the tractable profile OWL2-EL – by exploiting the simple structure of PXS. The policies in this test set do not contain any intervals and are natively normalized (they never contain more than one subconcept ∃R.C with the same role R). For these reasons, PXS can be correctly processed by ELK, although it supports neither intervals nor functionality axioms.Using ELK, the average time per subsumption query is 3.11 milliseconds; therefore all versions of PLR are significantly faster. Such difference in performance may be partially due to the cost of initializing and maintaining ELK’s indexing struc-tures for the efficient application of the inference rules illustrated in [33]. Moreover, the worst-case complexity of ELK’s algorithm is higher than PLR’s (O (n3) vs. O (n2)).In order to test GraphDB, each subsumption query C (cid:8) D has been translated as explained in Section 5.3, i.e. by asserting C(a) in the knowledge base (where a is a fresh individual), and transforming D is into a SPARQL query to check whether D(a) is entailed. Recall that this reduction is not applicable when C contains intervals, therefore GraphDB is tested on PXS 33P.A. Bonatti, L. Ioffredo, I.M. Petrova et al.Artificial Intelligence 289 (2020) 103389Fig. 7. Effectiveness of business policy pre-normalization on large policies.only.31 The cost of asserting C(a) in the KB, the cost of translating D into SPARQL, and the cost of parsing the SPARQL query are not included in the measurement. The average time per query calculated in this way is 16.84 ms, so PLR is significantly faster on this test set. It should be considered that GraphDB is optimized for relatively small, user-generated queries on large ABoxes, while SPECIAL’s scenarios involve a huge number of large, automatically generated queries on very small ABoxes.Next we processed PXS with RDFox, by Oxford Semantic Technologies. For this purpose, PL subsumptions have been translated into SPARQL queries with the same reduction used for GraphDB. Computation time does not include the cost of the assertions C(a) and the cost of the translation of D. On average, RDFox takes 1.03 ms per compliance check. Also in this case, it should be remarked that – similarly to GraphDB – RDFox is optimized for small, user-generated queries on large ABoxes, while SPECIAL’s scenarios exhibit opposite features.The response time of RDFox does not include the cost of computing the logical consequences of the KB, that are materi-alized when C(a) is asserted. On the other hand, measurements include the parsing of SPARQL queries. So the performance of RDFox can be improved by caching the queries, in order to parse them only the first time they are processed.Remark 6.1. According to Oxford Semantic Technologies, it may be profitable to leverage RDFox’s generality and replace the standard reduction to query answering used in our experiments with a Datalog meta-interpreter that implements the method for PL subsumption checking introduced in Section 4. Such meta-interpreter would process a reified representation of PL concepts and make use of Datalog extensions such as comparison operators, aggregates (for interval splitting), and equality (to encode functionality axioms). A first advantage of this implementation is that it can answer all PL queries (while the standard reduction is not applicable to subsumptions with intervals). Another potential advantage, in terms of performance, is that RDFox can materialize and incrementally update the subsumption predicate. A potential disadvantage is the expected size of the materialization as the number of business and consent policies grows. Concerning PLR, its , performance can be improved by adopting RDFox’s implementation choices, in particular (i) re-engineering PLR in Cand (ii) exploiting parallelism. Independently from performance considerations, our experimental results on PLR prove that real-time subsumption checking in PL can be achieved without necessarily resorting to complex proprietary technology. This fact fosters adoption – a topic that is further discussed in the conclusions.++We have also considered Konclude, a general reasoner that is very competitive on standard classification benchmarks [47]. Konclude does not support intervals, therefore it has been tried on PXS only. Konclude integrates a tableau algorithm with completion-based saturation – for pay-as-you-go behavior – and adopts a wide range of optimizations. The current 31 On the other hand, unlike GraphDB, PL is not able to express all SPARQL queries.34P.A. Bonatti, L. Ioffredo, I.M. Petrova et al.Artificial Intelligence 289 (2020) 103389version, however, is focused on classification tasks; streams of PL subsumptions can be processed only at the cost of repeating the classification of the knowledge base for each query. This prevents a fair comparison with Hermit and PLR (in our tests, Konclude is slower than both).7. ConclusionsWe have introduced the description logic PL in order to formalize the data usage policies adopted by controllers as well as the consent to data processing granted by data subjects. Checking whether the controllers’ policies comply with the available consent boils down to subsumption checking between PL concepts. PL can also formalize parts of the GDPR; then, by means of subsumption checking, one can automatically check several constraints on usage policies such as, for example:• Are all the required policy properties specified?• Are all the required obligations specified?• Is the policy compatible with GDPR’s constraints on cross-border data transfers?PL queries supports interval constraints of the form ∃ f .[(cid:4), u] in order to model limitations on data storage duration. This feature affects convexity, and hinders a direct use of the query answering techniques for Horn DLs.PL has been made as simple as possible in order to address two requirements. First, it should be usable by people with no logical or legal background. One of our industrial partners successfully assessed the usability of PL, by verifying that its employees can write correct business policies. Second, the frequency of compliance checks can be high, so PLquery answering should be extremely fast and scalable. Despite the simplicity of PL, general PL subsumption checking is coNP-complete, due to the interplay of interval constraints and concept union. However, reasoning becomes tractable by requiring that each simple policy on the left-hand side of the subsumption query should contain a bounded num-ber of interval constraints – a restriction that is naturally satisfied by SPECIAL’s usage policies, consent policies, and in the formalization of the GDPR. Under this assumption, subsumption checking can be split into a polynomial-time normal-ization phase and a subsequent subsumption check that can be carried out by a fast, structural subsumption algorithm (STS).The scalability of the complete algorithm (PLR) has been experimentally assessed. Some of the test sets consist of realistic policies and ontologies, derived from SPECIAL’s pilots. Such policies and ontologies are small, so we generated also synthetic stress tests, where policies and ontologies are significantly larger than what we expect in real GDPR compliance scenarios. Our tests show that PLR is significantly faster than Hermit on small and medium policies. This had to be expected, since Hermit is not specialized on PL and constructs a hypertableau at each subsumption check. The performance of PLR can be further improved by caching normalized policies (PLR c). With this solution, PLR takes around 500 μseconds per subsumption check, over the test sets inspired by SPECIAL’s pilots (PXS and TR). By pre-normalizing business policies (PLR pre), the average cost per subsumption check can be further reduced to 333 μsec (PXS) and 487 μsec (TR).32Over large policies (P2), the probability of observing a combinatorial explosion during interval splitting grows, and the performance of PLR exhibits an exponential decrease as #int grows (where #int is the average number of intervals per simple business policy measured after applying the seven rewrite rules). This phenomenon is unavoidable, unless P = NP, because PL subsumption checking is coNP-hard if #int is unrestricted. However, by normalizing also consent policies, combinatorial effects are mitigated (because normalization may merge different intervals), and PLR c 2n turns out to be faster than Hermit for #int < 8.PLR has been compared also with ELK, GraphDB, and Konclude, using only a subset of the test cases because these engines cannot answer PL queries with intervals. Being specialized on PL queries, PLR turns out to be faster than these engines, too. PLR is also faster than RDFox, when the standard reduction of subsumption to query answering is adopted.33Alternatively, it seems possible to implement PLR’s reasoning method in Datalog, and evaluate the Datalog program with RDFox (see Remark 6.1). Investigating this approach is an interesting topic for further research.In perspective, the expressiveness needed to encode the vocabularies of data categories, purposes, recipients, etc. is going to exceed the capabilities of PL. For this reason, we have shown how to integrate the compliance checking method based on PLR with reasoners for logics more expressive than PL. The integration is based on the import by query approach. If the “external” ontology O that defines vocabulary terms is in Horn-SRIQ, and if the main knowledge base K and the given subsumption query share only concept names with O, then algorithm PLR– an adaptation of PLR that calls a reasoner for O – is sound and complete. If O additionally belongs to a tractable DL, then subsumption checking is tractable in the IBQ framework, too. The restriction on roles can be partly lifted by allowing queries to mention the roles occurring in O, provided that if R ∈ (cid:2)(O), then the existential restrictions ∃R.C may contain only roles in (cid:2)(O).O32 This speed allows to process only about 20% of the base station events and 33% of the wi-fi probing events generated every second in the streaming scenario. SPECIAL addresses this issue by running multiple compliance checks in parallel, by means of a big data architecture; see for example [12,34] for more details.33 See also the optimization options discussed in Section 6.35P.A. Bonatti, L. Ioffredo, I.M. Petrova et al.Artificial Intelligence 289 (2020) 103389We have also illustrated a different implementation strategy, based on a pre-compilation of K and O into a single PLknowledge base comp(K, O), whose size is polynomial in the size of K ∪ O and in the number of business policies. Com-pliance checks are computed in polynomial time, after compilation, even if O belongs to an intractable logic. Moreover, pre-compilation allows to exploit the implementation of PLR, whose scalability has been assessed in Section 6. This ap-proach works well in SPECIAL’s use cases because the number of business policies is usually small, and K, O, and the business policies are relatively stable and persistent. Unfortunately, the above assumptions cannot be made in general, for all potential applications of PL.Such applications include also the representation of licenses, which constitute a fundamental aspect of data markets. The application context is in some respect analogous to SPECIAL’s: PL concepts should encode the usage restrictions that apply to datasets, multimedia content, and so on. In this case, however, the policies that can be reasonably assumed to belong to a limited set are those associated to sellers, that occur on the right-hand side of subsumptions, while the left-hand side can hardly be restricted. This hinders the compilation-based approach, and may require a direct implementation of PLR, that is, the general IBQ reasoner for PL. Such implementation and its experimental assessment are interesting topics for further research.PL can also naturally encode electronic health records (EHRs). In this case, the top-level properties of PL queries encode the sections of EHRs – according, say, to the HL7 standard – while some of the sections’ contents can be specified with SNOMED terms. The IBQ framework allows to process PL queries with PLR, and reduce the cost of SNOMED to oracle calls, consisting of linear time visits to its classification graph. The efficiency of the structural subsumption reasoner is very promising in this context, that is challenging for all engines due to the remarkable size of SNOMED. We plan to try PLROThe simplicity of PLR makes it possible to embed PL reasoning in objects with limited scripting capabilities. For exam-ple, one of SPECIAL’s partners has programmed PL compliance checking as a smart contract in an Ethereum blockchain. In this way, the creation of new entries in the blockchain is subject to compliance with a specified policy. This is also an example of how simplicity may foster adoption: SPECIAL’s policy framework is not tightly bound to any specific technology or components, and it can be easily integrated in a variety of systems.to increase the performance of the secure view construction reported in [15].OOSPECIAL’s deliverables comprise dashboards for controllers, data subjects, and data protection officers. We are going to support these user interfaces by developing explanation algorithms for helping data subjects in understanding policies and their decisions. The idea is leveraging the simple structure of PL concepts and axioms to generate high-level, user-friendly explanations.On the theoretical side, our results on the complexity of PL queries are novel, as discussed in Section 5.3, and extend the available tractability and intractability results for extended faceted queries. The negative result on oracles with nominals (Theorem 5.30) extends a result of [20] to logics that (like PL) enjoy the finite model property, and to IBQ mechanism where the axioms of the main knowledge base K may be shifted to the imported ontology O.There are further interesting topics for future work. For example, we currently do not know whether the requirement that ((cid:2)(K) ∪ (cid:2)(q)) ∩ (cid:2)(O) ⊆ NC can be relaxed without affecting tractability (under appropriate hypotheses).Another interesting line of research consists in tracing the tractability threshold in the family of logics obtained by extending PL with CLASSIC’s constructs, with particular attention to number restrictions, role-value maps, and nominals. Preliminary results have been published in [16].Last but not least, from a theoretical perspective, it will be interesting to see to what extent PLR’s pre-processing can be adapted to extend Horn DLs with interval constraints without affecting tractability. We expect the interplay of number restrictions and intervals to increase the complexity of reasoning.Declaration of competing interestWe wish to confirm that there are no known conflicts of interest associated with this publication and there has been no significant financial support for this work that could have influenced its outcome.AcknowledgementsThis research is funded by the European Union’s Horizon 2020 research and innovation programme under grant agree-ment N. 731601. The GDPR compliance use case – here sketched with (5), (6), and Example 3.2 – is due to Benedict Whittam Smith (Thomson Reuters).References[1] G. Antoniou, N. Dimaresis, G. Governatori, A modal and deontic defeasible reasoning system for modelling policies and multi-agent systems, Expert [2] A. Artale, D. Calvanese, R. Kontchakov, M. Zakharyaschev, The DL-lite family and relations, J. Artif. Intell. Res. 36 (2009) 1–69.[3] F. Baader, S. Brandt, C. Lutz, Pushing the EL envelope, in: IJCAI-05, Proceedings of the Nineteenth International Joint Conference on Artificial Intelligence, [4] F. Baader, D. Calvanese, D.L. McGuinness, D. Nardi, P.F. Patel-Schneider (Eds.), The Description Logic Handbook: Theory, Implementation, and Applica-Syst. Appl. 36 (2) (2009) 4125–4134.Professional Book Center, 2005, pp. 364–369.tions, Cambridge University Press, 2003.36P.A. Bonatti, L. Ioffredo, I.M. Petrova et al.Artificial Intelligence 289 (2020) 103389[5] M. Bienvenu, M. Ortiz, M. Simkus, G. Xiao, Tractability guarantees for DL-lite query answering, in: Eiter et al. [22], pp. 41–52.[6] M. Bienvenu, M. Ortiz, M. Simkus, G. Xiao, Tractable queries for lightweight description logics, in: IJCAI 2013, Proceedings of the 23rd International Joint Conference on Artificial Intelligence, Beijing, China August 3-9, 2013, 2013, pp. 768–774.[7] P.A. Bonatti, Datalog for security, privacy and trust, in: Datalog Reloaded - First International Workshop, Datalog 2010. Revised Selected Papers, Oxford, UK, March 16-19, 2010, in: Lecture Notes in Computer Science, vol. 6702, Springer, 2010, pp. 21–36.[8] P.A. Bonatti, Fast compliance checking in an OWL2 fragment, in: Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelli-gence, IJCAI 2018, July 13-19, 2018, ijcai.org, 2018, pp. 1746–1752.[9] P.A. Bonatti, B. Bos, S. Decker, J.D. Fernández, S. Kirrane, V. Peristeras, A. Polleres, R. Wenning, Data privacy vocabularies and controls: semantic web for transparency and privacy, in: Proceedings of the Workshop on Semantic Web for Social Good Co-Located with 17th International Semantic Web Conference, SW4SG@ISWC 2018, in: CEUR Workshop Proceedings, vol. 2182, CEUR-WS.org, 2018.[10] P.A. Bonatti, S. De Capitani di Vimercati, P. Samarati, An algebra for composing access control policies, ACM Trans. Inf. Syst. Secur. 5 (1) (2002) 1–35.[11] P.A. Bonatti, J.L. De Coi, D. Olmedilla, L. Sauro, A rule-based trust negotiation system, IEEE Trans. Knowl. Data Eng. 22 (11) (2010) 1507–1520.[12] P.A. Bonatti, S. Kirrane, Big data and analytics in the age of the GDPR, in: 2019 IEEE International Congress on Big Data, BigData Congress 2019, IEEE, 2019, pp. 7–16.[13] P.A. Bonatti, S. Kirrane, A. Polleres, R. Wenning, Transparent personal data processing: the road ahead, in: Computer Safety, Reliability, and Security -SAFECOMP 2017 Workshops, ASSURE, DECSoS, SASSUR, TELERISE, and TIPS, Proceedings, in: Lecture Notes in Computer Science, vol. 10489, Springer, 2017, pp. 337–349.[14] P.A. Bonatti, A. Peron, On the undecidability of logics with converse, nominals, recursion and counting, Artif. Intell. 158 (1) (2004) 75–96.[15] P.A. Bonatti, I.M. Petrova, L. Sauro, Optimized construction of secure knowledge-base views, in: Proceedings of the 28th International Workshop on Description Logics, in: CEUR Workshop Proceedings, vol. 1350, CEUR-WS.org, 2015.[16] P.A. Bonatti, I.M. Petrova, L. Sauro, A richer policy language for GDPR compliance, in: Proceedings of the 32nd International Workshop on Description Logics, in: CEUR Workshop Proceedings, vol. 2373, CEUR-WS.org, 2019.[17] A. Borgida, P.F. Patel-Schneider, A semantics and complete algorithm for subsumption in the CLASSIC description logic, J. Artif. Intell. Res. 1 (1994) 277–308.[18] D. Carral, C. Feier, B. Cuenca Grau, P. Hitzler, I. Horrocks, EL-ifying ontologies, in: Automated Reasoning - 7th International Joint Conference, IJCAR 2014, Held as Part of the Vienna Summer of Logic, VSL 2014, Proceedings, Vienna, Austria, July 19-22, 2014, 2014, pp. 464–479.[19] D. Carral, C. Feier, B. Cuenca Grau, P. Hitzler, I. Horrocks, Pushing the boundaries of tractable ontology reasoning, in: The Semantic Web - ISWC 2014 -13th International Semantic Web Conference, Proceedings, Part II, 2014, pp. 148–163.[20] B. Cuenca Grau, B. Motik, Reasoning over ontologies with hidden content: the import-by-query approach, J. Artif. Intell. Res. 45 (2012) 197–255.[21] B. Cuenca Grau, B. Motik, Y. Kazakov, Import-by-query: ontology reasoning under access limitations, in: IJCAI 2009, Proceedings of the 21st International Joint Conference on Artificial Intelligence, 2009, pp. 727–732.[22] T. Eiter, B. Glimm, Y. Kazakov, M. Krötzsch (Eds.), Informal Proceedings of the 26th International Workshop on Description Logics, Ulm, Germany, July 23-26, 2013, CEUR Workshop Proceedings, vol. 1014, CEUR-WS.org, 2013.[23] B. Glimm, I. Horrocks, B. Motik, G. Stoilos, Z. Wang, Hermit: an OWL 2 reasoner, J. Autom. Reason. 53 (3) (2014) 245–269.[24] G. Governatori, F. Olivieri, A. Rotolo, S. Scannapieco, Computing strong and weak permissions in defeasible logic, J. Philos. Log. 42 (6) (2013) 799–829.[25] R.H. Güting, Graphdb: modeling and querying graphs in databases, in: J.B. Bocca, M. Jarke, C. Zaniolo (Eds.), VLDB’94, Proceedings of 20th International Conference on Very Large Data Bases, Santiago de Chile, Chile, September 12–15, 1994, Morgan Kaufmann, 1994, pp. 297–308.[26] C. Haase, C. Lutz, Complexity of subsumption in the EL family of description logics: acyclic and cyclic tboxes, in: ECAI 2008 - 18th European Confer-ence on Artificial Intelligence, Proceedings, in: Frontiers in Artificial Intelligence and Applications, vol. 178, IOS Press, 2008, pp. 25–29.[27] R. Hoekstra, J. Breuker, M.D. Bello, A. Boer, LKIF core: principled ontology development for the legal domain, in: Law, Ontologies and the Semantic Web [28] I. Horrocks, O. Kutz, U. Sattler, The even more irresistible SROIQ, in: Proceedings, Tenth International Conference on Principles of Knowledge Represen-- Channelling the Legal Information Flood, 2009, pp. 21–52.tation and Reasoning, AAAI Press, 2006, pp. 57–67.[29] J.F. Horty, Agency and Deontic Logic, Oxford University Press, 2001.[30] S. Jajodia, P. Samarati, M.L. Sapino, V.S. Subrahmanian, Flexible support for multiple access control policies, ACM Trans. Database Syst. 26 (2) (2001) 214–260.[31] A.J.I. Jones, M.J. Sergot, On the characterization of law and computer systems: the normative systems perspective, in: J.-J.C. Meyer, R.J. Wieringa (Eds.), Deontic Logic in Computer Science: Normative System Specification, Wiley, 1993, pp. 275–307, chapter 8.[32] L. Kagal, T.W. Finin, A. Joshi, A policy language for a pervasive computing environment, in: 4th IEEE International Workshop on Policies for Distributed Systems and Networks, POLICY, IEEE Computer Society, June 2003, p. 63.[33] Y. Kazakov, M. Krötzsch, F. Simancik, The incredible ELK - from polynomial procedures to efficient reasoning with EL ontologies, J. Autom. Reason. 53 (1) (2014) 1–61.[34] S. Kirrane, J.D. Fernández, W. Dullaert, U. Milosevic, A. Polleres, P.A. Bonatti, R. Wenning, O. Drozd, P. Raschke, A scalable consent, transparency and compliance architecture, in: The Semantic Web: ESWC 2018 Satellite Events, Revised Selected Papers, in: Lecture Notes in Computer Science, vol. 11155, Springer, 2018, pp. 131–136.[35] N. Matentzoglu, S. Bail, B. Parsia, A corpus of OWL DL ontologies, in: Eiter et al. [22], pp. 829–841.[36] B. Motik, R. Shearer, I. Horrocks, Hypertableau reasoning for description logics, J. Artif. Intell. Res. 36 (2009) 165–228.[37] Y. Nenov, R. Piro, B. Motik, I. Horrocks, Z. Wu, J. Banerjee, Rdfox: a highly-scalable RDF store, in: M. Arenas, Ó. Corcho, E. Simperl, M. Strohmaier, M. d’Aquin, K. Srinivas, P.T. Groth, M. Dumontier, J. Heflin, K. Thirunarayan, S. Staab (Eds.), The Semantic Web - ISWC 2015 - 14th International Semantic Web Conference, Proceedings, Part II, Bethlehem, PA, USA, October 11-15, 2015, in: Lecture Notes in Computer Science, vol. 9367, Springer, 2015, pp. 3–20.[38] M. Ortiz, S. Rudolph, M. Simkus, Worst-case optimal reasoning for the horn-dl fragments of OWL 1 and 2, in: Principles of Knowledge Representation and Reasoning: Proceedings of the Twelfth International Conference, KR 2010, AAAI Press, 2010.[39] M. Ortiz, S. Rudolph, M. Simkus, Query answering in the horn fragments of the description logics SHOIQ and SROIQ, in: IJCAI 2011, Proceedings of the 22nd International Joint Conference on Artificial Intelligence, IJCAI/AAAI, 2011, pp. 1039–1044.[40] M. Palmirani, G. Governatori, Modelling legal knowledge for GDPR compliance checking, in: Legal Knowledge and Information Systems - JURIX 2018: the Thirty-First Annual Conference, Groningen, the Netherlands, 12–14 December 2018, 2018, pp. 101–110.[41] M. Palmirani, M. Martoni, A. Rossi, C. Bartolini, L. Robaldo, Legal ontology for modelling GDPR concepts and norms, in: Legal Knowledge and Informa-tion Systems - JURIX 2018: the Thirty-First Annual Conference, Groningen, the Netherlands, 12–14 December 2018, 2018, pp. 91–100.[42] M. Palmirani, M. Martoni, A. Rossi, C. Bartolini, L. Robaldo, Pronto: privacy ontology for legal reasoning, in: Electronic Government and the Information Systems Perspective - 7th International Conference, Proceedings, EGOVIS 2018, Regensburg, Germany, September 3-5, 2018, 2018, pp. 139–152.[43] C.H. Papadimitriou, Computational Complexity, Academic Internet Publ., 2007.37P.A. Bonatti, L. Ioffredo, I.M. Petrova et al.Artificial Intelligence 289 (2020) 103389[44] H. Prakken, G. Sartor, Law and logic: a review from an argumentation perspective, Artif. Intell. 227 (2015) 214–245.[45] M.J. Sergot, F. Sadri, R.A. Kowalski, F. Kriwaczek, P. Hammond, H.T. Cory, The British nationality act as a logic program, Commun. ACM 29 (5) (1986) 370–386.[46] E. Sherkhonov, B. Cuenca Grau, E. Kharlamov, E.V. Kostylev, Semantic faceted search with aggregation and recursion, in: The Semantic Web - ISWC 2017 - 16th International Semantic Web Conference, Proceedings, Part I, Vienna, Austria, October 21-25, 2017, 2017, pp. 594–610.[47] A. Steigmiller, T. Liebig, B. Glimm, Konclude: system description, J. Web Semant. 27–28 (2014) 78–85.[48] A. Uszok, J.M. Bradshaw, R. Jeffers, N. Suri, P.J. Hayes, M.R. Breedy, L. Bunch, M. Johnson, S. Kulkarni, J. Lott, KAoS policy and domain services: towards a description-logic approach to policy representation, deconfliction, and enforcement, in: 4th IEEE International Workshop on Policies for Distributed Systems and Networks, POLICY, IEEE Computer Society, June 2003, pp. 93–96.[49] T.Y.C. Woo, S.S. Lam, Authorizations in distributed systems: a new approach, J. Comput. Secur. 2 (2–3) (1993) 107–136.38