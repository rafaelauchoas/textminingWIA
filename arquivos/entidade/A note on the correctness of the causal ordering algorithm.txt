Artificial Intelligence 172 (2008) 1800–1808Contents lists available at ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintA note on the correctness of the causal ordering algorithmDenver Dash a,b,∗,1, Marek J. Druzdzel c,da Intel Research Pittsburgh, 4720 Forbes Avenue, Pittsburgh, PA 15213, USAb Department of Biomedical Informatics, School of Medicine, University of Pittsburgh, Pittsburgh, PA 15260, USAc Decision Systems Laboratory, School of Information Sciences and Intelligent Systems Program, University of Pittsburgh, Pittsburgh, PA 15260, USAd Faculty of Computer Science, Białystok Technical University, Wiejska 45A, 15-351 Białystok, Polanda r t i c l ei n f oa b s t r a c tArticle history:Received 28 October 2005Received in revised form 16 June 2008Accepted 19 June 2008Available online 28 June 2008Keywords:CausalityStructural equation modelsIn this paper we examine in detail the algorithm of Simon [H.A. Simon, Causal orderingand identifiability, in: W.C. Hood, T.C. Koopmans (Eds.), Studies in Econometric Method.Cowles Commission for Research in Economics, Monograph No. 14, John Wiley & Sons, Inc.,New York, 1953, pp. 49–74, Chapter III], called the causal ordering algorithm (COA), usedfor constructing the “causal ordering” of a system given a complete specification of thesystem in terms of a set of “structural” equations that govern the variables in the system.This algorithm constructs a graphical characterization of the model in a form that we calla partial causal graph. Simon argued in [H.A. Simon, Causal ordering and identifiability, in:W.C. Hood, T.C. Koopmans (Eds.), Studies in Econometric Method. Cowles Commission forResearch in Economics, Monograph No. 14, John Wiley & Sons, Inc., New York, 1953, pp. 49–74, Chapter III] and subsequent papers that a graph so generated explicates causal structureamong variables in the model. We formalize this claim further by proving that any causalmodel based on a one-to-one correspondence between equations and variables must beconsistent with the COA.© 2008 Elsevier B.V. All rights reserved.1. IntroductionThis note is concerned with a technique owing to Simon known as the causal ordering algorithm (COA). Given a self-contained system of simultaneous structural equations, COA will explicate asymmetries among variables in the system andproduce a (possibly partial) matching between variables and equations. In a classic article [24], Simon showed that COAgenerates a directed graph which we call a partial causal graph (PCG). In [24] and in subsequent writings [11,12,25,26] Simonet al. argue that if a set of equations E is self-contained and composed of causal mechanisms, COA will produce causal graphsthat are consistent with experts’ “intuitive” causal orderings. We show in this note that the COA provides a summary ofthe necessary mappings from variables to equations. That is, any one-to-one mapping from variables to equations will beconsistent with the COA. As a special case, when all clusters found by the COA contain only a single variable, then thereexists only one mapping from equations to variables and only one (acyclic) directed causal graph, which is given by COA.1.1. PreliminariesFor the purposes of this note, a causal model is defined as a set of equations together with a one-to-one mapping fromequations to variables in the model (see Fig. 1). Matching a variable to an equation is an assertion that the other variables* Corresponding author at: Intel Research Pittsburgh, 4720 Forbes Avenue, Pittsburgh, PA 15213, USA.E-mail addresses: denver.h.dash@intel.com (D. Dash), marek@sis.pitt.edu (M.J. Druzdzel).1 This work was performed while Denver Dash was a graduate student at the Intelligent Systems Program, University of Pittsburgh.0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.doi:10.1016/j.artint.2008.06.005D. Dash, M.J. Druzdzel / Artificial Intelligence 172 (2008) 1800–18081801Fig. 1. A causal model is specified by a set of equations and a one-to-one correspondence between equations and variables and defines a directed graphover the variables.present in that equation are causal parents of the matched variable. Such a specification of a system defines a directed graph(DiG) which is interpreted as a causal graph. This representation of causality has its roots in structural equation models inthe econometrics literature [8,10,24,30,36,37] and has been developed further within AI over the past decade [6,21,29]).It is frequently the case that we know the equations that govern a given system but we are unsure about the correctmapping from variables to equations. For example, any physical system typically has an associated set of physics equationsthat govern the processes in the system. Many socio-economic models have “laws” that are represented by equations thatmust be satisfied for a given set of assumptions. Given such a set of equations, in order to produce a causal model (asdefined in this note), one must be able to generate a one-to-one correspondence between variables in the system andequations. To do this in general requires detailed background knowledge about causal interactions in the system. In practicefor even modest systems it can become an intractable task by hand. It would thus be desirable to possess an automatedmethod by which the matching between equations and variables can be generated. Such a method would be especiallyvaluable for very large models possessing hundreds or thousands of variables. A central practical problem with such anautomated method is to ensure that the mapping generated has causal meaning.Our contributions here are to formally define a Partial Causal Graph (PCG) and define a notion of consistency between aDiG and a PCG. We then show that the mapping of equations to variables produced by COA will be consistent with any othermapping, and thus the PCG generated by COA will be consistent with any DiG that is consistent with E. By “consistent” wemean in essence that any arc present in the PCG must be present in the DiG, and any arc in the DiG must not be ruledout by the PCG. Our proof requires neither linear equations nor equations which can be solved for unique values for thevariables.We feel that this work is significant because it serves to validate decades of research which has shown COA to be apowerful tool for operating on causal models. One of the primary uses for causal graphs in general is to support the abilityto reason about the effects of manipulation on a real-world system and predict the resulting probability distribution. The Dooperator of Pearl [21] is a well-known case of an operator for modeling manipulation of a variable when such a manipula-tion breaks the connection between the variable and its parents. However, the COA has served as a generating function forall sorts of operations on causal models. For example, COA can be used to model the restructuring that occurs in a dynamiccausal system when it passes through equilibrium [2,3,11]. Yet another operation might be the replacement of some compo-nents with others that depend on qualitatively different factors, such as replacing a spring with a compressible gas piston.COA is capable of modeling manipulation when reversible mechanisms are present in the model [7]. This technique wasused in a model for strategic business planning by the administration at Carnegie Mellon University [23]. Given a library offundamental laws describing an arbitrary system, COA also provides a method to automate the process of model buildingby constructing causal graphs on the fly, depending on which devices are added to the system [16]. The validity of usingCOA for these purposes, however, rests on the existence of a proof of the correctness of COA. Thus, the key significance ofthis paper is that it converts an entire thread of research from a set of useful heuristics to provably correct techniques.1.2. Previous workMuch work on causality has been performed in the past decades in statistics and artificial intelligence. This work hasbeen concerned with representation (e.g., [13,14,19,33,34]), inference (e.g., [15,19]), causal reasoning (e.g., [20,28]), learningfrom data (e.g., [1,18,27,28]), among other topics. Most of this work has dealt with causal models that are very similar tothe type constructed with the COA; however, in their formulations, a causal model is assumed as a given or it is derivedfrom data, and the process of converting a set of equations to a causal model is not considered.Nayak [17] comes the closest to addressing the question that we pose here. He shows that all mappings between struc-tural equations and variables produce the same set of ancestor-descendant pairs. Similarly, we will show that all mappingspossess common features, but these common features will be in terms of direct causal connections rather than indirectancestral relations, and we provide the proof that COA provides a condensed representation of those necessary direct con-nections. Dash [2,3] shows that the causal interpretation of equilibrium systems is not straightforward due to the factthat underlying dynamics can lead to equilibrium independence graphs that are not causal. He terms this reason for non-causality “violation of Equilibration–Manipulation commutability.” We emphasize that the work presented here does notimply that models retrieved by COA are assured to obey the Equilibration–Manipulation commutability property. There existmany other concepts of causality that do not involve a mapping from equations to variables. Granger causality [9] uses1802D. Dash, M.J. Druzdzel / Artificial Intelligence 172 (2008) 1800–1808correlations across time to identify causal relations. The work by de Kleer and Brown [4] and that of Williams [35] addressthe problem of determining causality from a set of constraints by propagating disturbances on variables in the model. Thereis a debate as to whether the formalisms of de Kleer and Brown and Williams are consistent with the concept of causalityused in this note [5,12]. We make no claim that the proofs presented in this note apply to Granger causality or causal rep-resentations used by other work (cf. [22,31,32]), unless those other formalisms can be expressed as a one-to-one mappingbetween equations and variables.Iwasaki and Simon [11] extend the COA to construct dynamic causal models given a set of differential equations specify-ing the system. The addition of differential equations causes their modified version of the COA to add additional “integrationarcs” to the graph produced by the original COA. However, the graph obtained by their algorithm prior to the addition ofthese special arcs is identical to the graph that would be obtained by the COA on the given system of equations; therefore,the results that we present here apply equally well to the static portion of their dynamic causal ordering. Also, our resultdirectly applies to their demonstration of how equilibration affects the causal ordering of a system, again if one omits theintegration arcs from the analysis. We conjecture that our proofs can also be applied to the integration arcs if one considersthem to denote causation across time. To prove this, one needs to show how new variables can be introduced to the systemdenoting future versions of existing variables, and how a differential equation can be expanded to cover these new variables.1.3. NotationWe will use the following notation throughout the remainder of the note: When it does not conflict with other notation,we will denote elements of sets by lower case letters and sets by upper case letters. If G = (cid:3)V , A(cid:4) is a directed graph whereV is a set of vertices and A is a set of directed arcs, we will use Pa(v)G and Ch(v)G to denote the parents and children,respectively, in G, for some v ∈ V . We will use Anc(v)G and Des(v)G to denote the ancestors and descendants of v in G.In all cases, we may drop the subscript G if the graph is implied by the context. If e is an equation then we use Params(e)to denote the set of variables constrained by e. If E is a set of equations e1, e2, . . . , en, we use Params(E) to represent(cid:2)ei ∈E Params(ei).A partition X p of a set X is a set of disjoint sets X p = { X1, X2, . . . , Xn} such thati=1 Xi = X ; we call the disjoint setsof a partition the clusters. For example {{1, 3, 5}, {2, 4, 6}, {7}} is a partition of {1,2,3,4,5,6,7}, and {1,3,5} is a cluster. If X p isa partition of a set X and x ∈ X , then we use the notation Clust(x) X p to denote the cluster in which x lies in X p . We willdrop the subscript X p from Clust(x) X p if the partition is clear by the context.(cid:2)n1.4. Causal modeling and COA: ExamplesWe are considering causal models in the form of structural equation models (SEMs), whereby a system, summarized by aset of feature variables V , is specified by a set of equations E which determines a complete solution set for V , and eachvariable v ∈ V is associated with a single unique equation e ∈ E. Such a specification of a causal system defines a directedgraph over the variables by defining the parent set of v to be the remaining parameters of e which are also in V . Anexample of such a model is shown in Fig. 1.Some variables in V may be determined outside of the system, meaning that, although they are tied to the system insome way (because they appear in some e ∈ E), their values are determined either by external, uncontrollable influences(e.g., the weather) or they are under direct experimental control (e.g., the temperature of a gas). These variables are calledexogenous. Variables x and v in Fig. 1 are exogenous. A variable x is exogenous if and only if there exists an equation that canbe written in the form f (x) = 0, where f is some function. For example the equation x = x0 can be rewritten as x − x0 = 0.All variables in the model that are not exogenous are called endogenous, meaning that their values are determined withinthe system.Typically it is assumed that if an equation e is associated with a variable v, then v can be written as a function of theremaining parameters of e: v = f (Pa(v)). However, this restriction is not necessary in general. The alternative is that theequation e will form an implicit equation for v given values for Pa(v), and will thus constrain the outcomes of v withoutnecessarily determining a unique value.The causal ordering algorithm (COA) [24] is an automated method that, given a set of equations E over variables V ,produces a matching between equations and variables. In the process, it constructs a partial causal graph. COA generatesa matching by recursively associating to each variable v the smallest subset of equations that can be solved in order todetermine the value for v given the variables that have already been determined. An example is shown in Fig. 2: initially,the values of x and v can be determined by solving equations e2 and e5, each being an equation in one variable. Thus, x isassociated with e2 and v with e5. Now, given values for x and v, no remaining variables can be determined within a singleequation (because, for example, there is no equation like f (x, y) = 0). However, the equations e3 and e4 taken together asa subsystem can be simultaneously solved for all variables appearing in e3 and e4 together. Simon called {e3, e4} a minimalself-contained subset of equations, because there is no smaller subset of equations that can be solved for its parameters. Fora fixed value of x, this subset contains exactly two variables, y and z, which can both be simultaneously solved for in termsof x. Thus the set of variables { y, z} is associated with the set of equations {e3, e4}. The variables y and z are said to bestrongly coupled because neither one could be determined before the other, and they are collectively represented by a singleD. Dash, M.J. Druzdzel / Artificial Intelligence 172 (2008) 1800–18081803Fig. 2. The causal ordering algorithm takes an unordered set of equations as input and outputs a partial matching between variables and equations, whichdefines a directed cluster graph.(a)(b)Fig. 3. Two equation systems and the corresponding causal graphs obtained by the COA. Although both sets of equations are algebraically equivalent, thestructures obtained are different. N, kg m and s stand for the units Newtons, kilograms, meters and seconds, respectively.vertex in the PCG, as in Fig. 2. Since x appears in e3, it is a parent of the entire subset { y, z} in the graph. Finally, given x,v, and z, the value of w is determined in e1, so w is associated with e1, and x, v and z are parents of w in the graph.All graphs produced by COA will be acyclic, but they may possess strongly coupled vertices as in Fig. 2, which, if resolvedby manually associating all strongly-coupled variables with individual equations, could create cycles in the resulting directedgraph (e.g., see Fig. 1). The models and graphs produced by COA are thus not typically what is referred to as “causal models”and “causal graphs” in the literature on causality (Simon’s work excluded). On the contrary, a causal model typically requiresan association between single variables and single equations which in turn defines a DiG, where each vertex of the graphcorresponds to a single variable rather than a set of variables. Also note that, despite the fact that a PCG is a directed graphinvolving clusters of variables, it is not a typical clique graph. Although incoming arcs are associated with the entire cluster,the outgoing arcs are specified as variable-to-cluster arcs, not cluster-to-cluster.The ability of a causal model to represent the structure of a system of equations depends critically on the fact that eachequation is structural. A structural equation differs from a normal algebraic equation in that it is not considered identicalto all other equations logically entailed by it. Likewise, a system of structural equations is not considered identical to allsystems of equations entailed by it.This restriction prohibits a SEM from undergoing arbitrary algebraic manipulations, because this will in general alterthe causal ordering of the system by creating different structural equations. Thus, in SEMs, the algebraic arrangement ofequations in the system determines the causal structure. Consider, for example, the causal model for a mass undergoingacceleration due to Newton’s 2nd law in Fig. 3. In Fig. 3(a), the structural equation model and corresponding PCG are shownfor the case when the force F is set to a value of 10 Newtons and the mass M is set to a value of 5 kg. On the other hand,the model in Fig. 3(b) contains a set of equations that is algebraically equivalent to the set in Fig. 3(a); however, the onlyway to assign variables to the equations in Fig. 3(b) results in a totally different structure. As not all of the equations in thissystem are structural (the first equation in Fig. 3(b) is an algebraic combination of the first two equations in Fig. 3(a)), thestructure cannot be given a causal interpretation.If one is given the set of equations in Fig. 3(a), it is easy to see that the only way to map variables to equations resultsin the causal graph shown there, and it is intuitive that this is the correct causal ordering if the exogenous variables areinterpreted as being set to their particular values. At it’s core, COA is as simple as being able to match up equations tovariables that have not been determined by the system yet. In this example it is easy to see how to do that, but in large,complex systems, this task can quickly get overwhelming without an automated procedure.Our ultimate goal in this note is to compare the PCGs produced by COA with graphs produced by an arbitrary matchingof variables to equations (e.g., comparing the PCG of Fig. 2 with the DiG of Fig. 1). We will show that any fully-specifiedmatching must be consistent with the partial matching produced by COA. However, a comparison of the two methods is nottrivial if only because they produce different graphical structures. We therefore must go through some pains just to bringthe two methods onto the same level so that they can be compared. In Section 2, we present formal definitions that willbe used to facilitate a comparison of the two approaches.2. The causal ordering algorithmIn this section, we will present COA formally, which is necessary to understand our proof. We refer the reader to Simon[24] for a less concise treatment. We first define a set of restrictions that must apply to a set of equations that comprise amodel:1804D. Dash, M.J. Druzdzel / Artificial Intelligence 172 (2008) 1800–1808Definition 1 (self-contained structure). A set of equations E is self-contained iff |E| = |Params(E)|, and for every subset E|E(cid:6)| (cid:2) |Params(E(cid:6))|.(cid:6) ⊂ E,Note that by assuming that a structure is self-contained we (and COA) conveniently exclude problematic systems ofequations (e.g., those for which there are more equations than variables or visa-versa). Also, this definition only considersthe qualitative structure present in equations. Some self-contained structures make no sense as a causal system. For example,the following are self-contained structures:X = 2Y10 X = 20YObviously such a system of equations can never completely represent a real causal system. Apparently enough backgroundknowledge must exists to prevent the inclusion of equations that are similarly contradictory or non-independent, but ourtheorems apply regardless as long as the system is self-contained.Definition 2 (minimal self-contained set). If S is a self-contained structure, then S is a minimal self-contained set iff there doesnot exist a subset S(cid:6) ⊂ S such that Sis also self-contained.(cid:6)Note that an equation for a single variable such as x = x0 will form a (minimal) self-contained subset. If E is a self-contained structure, then E defines a unique set S of solutions over the variables in Params(E). If all variables have uniquesolutions, then |S| = 1. Our definition of a self-contained structure varies slightly from that in [24] because our formulationgeneralizes to non-linear equations with non-unique values, similarly to the work of Iwasaki and Simon. COA, as we defineit, does not need to actually solve equations for values. It is only concerned with variable dependencies. If a non-linearequation leads to an implicit solution to a variable, then the causal system can be viewed as simply constraining thatvariable based on causal parents rather than absolutely determining its value.COA recursively constructs derived subsets by finding minimal self-contained sets and reducing the set of equations bysubstituting out those variables found so far:Definition 3 (derived subset). Let E be a self-contained structure and let Esc be the set of all minimal self-contained subsetsof E. Let Esc =E i , and let E←(cid:2) denote the set of equations that are obtained when values of Params(E sc) consistentwith Esc are substituted into E \ Esc. E←(cid:2) is called the derived subset of E.E i ∈Esc(cid:2)We will use the notation that E(1) ≡ E←(cid:2) , E(2) ≡ Eset of equations with derived subset E(i), and if Ecorresponding to the equations remaining in E(cid:6)(1)←(cid:2), etc., where E(i) is called the derived subset of ith order. If E is ato denote the subset of E(cid:6) ⊆ E(i) is some subset of E(i), then we use ˆE(cid:6), i.e., the subset of original equations with no values substituted.Definition 4 (well-defined self-contained structure). If E is a self-contained structure, then E is well-defined iff the derivedsubset E(i) is self-contained, for all i.For our purposes, we assume that all self-contained structures are well-defined.In Fig. 2, COA constructed a mapping between sets of variables and sets of equations. The mapping could be writ-ten as a list of associations as follows: φ = {(cid:3){w}, {e1}(cid:4), (cid:3){x}, {e2}(cid:4), (cid:3){ y, z}, {e3, e4}(cid:4), (cid:3){v}, {e5}(cid:4)}. We say that the partitions{{w}, {x}, { y, z}, {v}} and {{e1}, {e2}, {e3, e4}, {e5}} are commensurate and φ defines a partial causal mapping:Definition 5 (commensurate partitions). Let A and B be two sets such that | A| = |B|. A partition P A over A is commensurate(i)A )|.with a partition P B over B iff there exists an onto mapping φ : P A → P B such that for each set S∈ P A , |S| = |φ(S(i)A(i)ACommensurate partitions are obviously one-to-one.Definition 6 (partial causal mapping). If E is a self-contained set of equations with V = Params(E), then a partial causalmapping Φ of E is a triple (cid:3)V p, E p, φ(cid:4), where V p is a partition of V , E p is a partition of E, and φ is a bijection, φ : V p → E p ,such that the following is true:(1) {V p} is commensurate with {E p}, and(2) For all sets V(i)pbijection φ(i) : V∈ V p we can match up each variable in V(i)p(i)p ) such that x ∈ Params(φ(i)(x)) for all x ∈ V→ φ(V(i)p .(i)p with a unique equation in φ(V(i)p ). That is, there exists aD. Dash, M.J. Druzdzel / Artificial Intelligence 172 (2008) 1800–18081805A partial causal mapping Φ = (cid:3)V p, E p, φ(cid:4) can also be written as a list of ordered pairs or associations: Φ =(1)(i)p ∈ E p are sets for all i, and n is the number of clus-p , E{(cid:3)Vters in V p . We will use these two representations of a partial causal mapping interchangeably.(i)p ∈ V p and E(n)p (cid:4)}, where V(2)p (cid:4), . . . , (cid:3)V(1)p (cid:4), (cid:3)V(2)p , E(n)p , ECOA takes a well-defined self-contained structure and converts it to a partial causal mapping:Definition 7 (Causal Ordering Algorithm). Given a well-defined self-contained structure E(0), the Causal Ordering Algorithmproduces a partial causal mapping Φ = (cid:3)V p, E p, φ(cid:4) over E(0) through the following procedure:(1) Define E (i)sc(2) For each set E ∈ E (i)(3) Let E(i+1) ≡ Eto be the set of all minimal self-contained subsets of E(i).sc add the association (cid:3)Params(E), ˆE(cid:4) to Φ.←(cid:2) and recurse this procedure until E(i+1) = ∅.(i)We use COA(E) to denote the partial causal mapping generated by applying COA to the equation set E.The partial causal mapping defined by COA in Fig. 2 also defined the directed graph shown in the figure. We call thistype of graph a partial causal graph:Definition 8 (partial causal graph). A partial causal graph is an ordered pair (cid:3)V p, A p(cid:4), where the set of vertices V p is a(i)p (cid:13)= Clust(v).partition of V and A p is a set of directed arcs v → V(i)p where v ∈ V is a variable, V(i)p ∈ V p is a cluster, and V(cid:3)VThe PCG associated with a partial causal mapping Φ = (cid:3)V p, E p, φ(cid:4) can be constructed as follows: For each association(i)(i)p , Ep , direct an edge from v to VA causal graph can be viewed as a special case of a PCG, where all associations of the partial causal mapping are(i)p and each v ∈ Params(e) \ V(cid:4) ∈ φ and for each e ∈ E(i)p .(i)pelementary:Definition 9 (elementary association). We will call an association (cid:3)VIf (cid:3)Vassociation as (cid:3)v, e(cid:4) rather than as (cid:3){v}, {e}(cid:4).(i)p | = 1.(cid:4) is an elementary association where V p = {v} and E p = {e}, for clarity of notation we will often write this(i)p (cid:4) an elementary association if |V(i)p | = |E(i)p , E(i)p , E(i)pDefinition 10 (total causal mapping). If E is a set of equations with V ≡ Params(E), then a total causal mapping over E is abijection φ : V → E.Nayak [17] proves that a set of independent equations is self-contained iff it possesses a total causal mapping. In thesame way that a partial causal mapping can be used to construct a PCG, a total causal mapping defines a directed (possiblycyclic) graph (DiG):Definition 11 (causal model). A structural equation model S is a triple S = (cid:3)E, V , φ(cid:4), where E is a self-contained structure overparameters V , and φ : V → E is a total causal mapping.We use the terms causal model and structural equation model interchangeably. We denote the DiG that corresponds to atotal causal mapping φt as DiG(φt) and the PCG that corresponds to a partial causal mapping Φp as PCG(Φp)3. Correctness of COAComparison between the causal ordering given by COA and that given by an arbitrary expert is complicated by the factthat both procedures produce different types of directed graphs. We, therefore, must define precisely what we mean whenwe say that a DiG is consistent with a PCG.Definition 12 (DiG/PCG consistency). If V is a set of variables, G p = (cid:3)V p, A p(cid:4) is a PCG over V , and G = (cid:3)V , A(cid:4) is a DiG overV , then G is consistent with G p if and only if the following are true:(1) If an edge v 1 → V p exists in A p then there exists a v 2 ∈ V p such that the edge v 1 → v 2 exists in A.(2) If an edge v 1 → v 2 exists in A, then either v 1 → Clust(v 2) exists in A p or Clust(v 1) = Clust(v 2).Condition 12.1 says that all arcs present in G p must be represented in G, and Condition 12.2 says that the only additionalarcs that are allowed must be between variables that were “strongly coupled” in G p . The DiG of Fig. 1 is consistent withthe PCG of Fig. 2.1806D. Dash, M.J. Druzdzel / Artificial Intelligence 172 (2008) 1800–1808Definition 13 (partial/total mapping consistency). Let Φp be a partial causal mapping over a self-contained structure E withV = Params(E), and let φt be a total causal mapping over E. φt is consistent with Φp iff the following hold:(1) For each association (cid:3)V(i)p ).e ∈ Φp(V(i)p , Φp(V(i)p )(cid:4) ∈ Φp , there exists for each v ∈ V(i)p an elementary association (cid:3)v, e(cid:4) ∈ φt , where(2) An elementary association (cid:3)v, e(cid:4) exists in φt but not in Φp only if the non-elementary association (cid:3)Clust(v), Clust(e)(cid:4)exists in Φp .The following lemma shows that mapping consistency implies DiG/PCG consistency:Lemma 1. Let E denote a well-defined self-contained structure. If a total causal mapping φt over E is consistent with a partial causalmapping Φp = (cid:3)V p, E p, φp(cid:4) over E, then DiG(φt) is consistent with PCG(Φp).Proof. Let G p = (cid:3)V p, A p(cid:4) denote PCG(Φp) and let Gt = (cid:3)V , A(cid:4) denote DiG(φt). Assume that conditions 13.1 and 13.2 aretrue.Satisfaction of condition 12.1:(2)Assume an edge v 1 → Vpexists in A p . Let (cid:3)V(2)p , φp(V(2)p )(cid:4) be the association corresponding to V(2)ption 13.1, there exists in φt an elementary association of the form (cid:3)v 2, e1(cid:4) where v 2 ∈ VDiG(φt) there exists an edge from all v i1that v 1 ∈ Params(e1) \ V∈ Params(e1) \ Vto some v 2 ∈ V(2)p(2)p . Finally, since v 1 → V(2)p(2)p .and e1 ∈ φp(V(2)pin φp . By condi-(2)p ). Therefore init must be the caseSatisfaction of condition 12.2:Assume an edge v 1 → v 2 exists in A, then the elementary association (cid:3)v 2, e1(cid:4) must exist in φt such that v 1 ∈Params(e1). Then by condition 13.2, either (cid:3){v 2}, {e1}(cid:4) ∈ φp or (cid:3)Clust(v 2), Clust(e1)(cid:4) ∈ φp . Either way the association(cid:3)Clust(v 2), Clust(e1)(cid:4) ∈ φp . Therefore in PCG(Φp) an arc will be directed from all v ∈ Params(Clust(e1)) \ Clust(v 2) toClust(v 2). Therefore since v 1 ∈ Params(Clust(e1)), either there will exist an edge v 1 → Clust(v 2) or v 1 ∈ Clust(v 2). (cid:2)Using this result, Theorem 1 shows that a DiG Gt generated by any total causal mapping φt over a set of equations E isconsistent with the PCG G p generated by applying COA to E:Theorem 1. Let E be a well-defined self-contained structure, let φt be an arbitrary total causal mapping over E and let Φp =(cid:3)V p, E p, φp(cid:4) ≡ COA(E). Then DiG(φt) is consistent with PCG(Φp).Proof. First we show that φt is consistent with Φp . The result follows from Lemma 1.Satisfaction of condition 13.1: We prove this result by induction. We label the associations in φp as (cid:3)Params(E(i)j ), ˆE(i)j(cid:4)where E(i)jis the jth minimal self-contained subset found by COA in the ith level of recursion (e.g., the equations for the(i)(k)l(k)l(k)l(k)l), ˆE), ˆE(0)1 , E(i)j(0)2 , etc.). If v is an arbitrary variable such that v ∈ Params(E. Let (cid:3)Params(Ej ), ˆEexogenous variables can be labeled as Ethat v gets mapped to some equation e ∈ ˆEcondition 13.1 holds for all associations (cid:3)Params(E(cid:3)Params(EParams(e) and, therefore, it must be the case that v ∈ Params( ˆEv ∈ Params( ˆETo complete the induction step, notice that for any association in the initial level of recursion (cid:3)Params(E) so for any (cid:3)v, e(cid:4) ∈ φt it must be the case that v ∈ Params(Ebe the case that Params(E(i)j ), we must show(cid:4) be an arbitrary association made by COA. Assume that(cid:4) with all i < k. We show that it must also hold for the association. By definition of a causal mapping, v ∈). However, according to the induction hypothesis, all) have already been assigned to equations; therefore it must be the case that v ∈ Params(E(cid:4). Let (cid:3)v, e(cid:4) ∈ φt be an arbitrary association such that e ∈ ˆE(k)).l(cid:4), it must) ≡ Params( ˆE) \ Params(ESatisfaction of condition 13.2: Let (cid:3)v, e(cid:4) be an elementary association in φt . Consider the association (cid:3)Clust(v),(cid:6) ∈ φp(Clust(v)). But(cid:6)) = Clust(e)). (cid:2)φp(Clust(v))(cid:4) ∈ φp . By condition 13.1, there exists an elementary association (cid:3)v, esince φt is one-to-one, there can be only one equation associated with v. Therefore e(cid:6)(cid:4) ∈ φt such that e(cid:6) = e (and Clust(e), ˆE).(0)l(0)l(0)l(0)l(0)l(k)l(k)l(k)l(k)l(i)jThe following corollary shows that if COA returns a total mapping then the causal graph is unique and acyclic:Corollary 1. Let E be a well-defined self-contained structure, let Φp = (cid:3)V p, E p, φp(cid:4) ≡ COA(E), and let φt be an arbitrary total causalmapping. The following are equivalent:(1) φp is a total causal mapping.(2) PCG(Φp) is isomorphic to DiG(φt).(3) DiG(φt) is acyclic.D. Dash, M.J. Druzdzel / Artificial Intelligence 172 (2008) 1800–18081807In this case COA produces necessary and sufficient edges for the system.4. ConclusionsA standard causal model requires the specification of a set of structural equations and a mapping from equations tovariables. COA requires only the former, and produces at least a partial version of the latter. Thus, COA provides a simple,tractable method to extract the causal features of the system that are necessary given the structural equations alone.Anyone who has attempted to specify the causal structure from a system of more than five or so equations understandsthat the task quickly gets intractable by hand. This fact is especially true when, as is typically the case, the system isunder-constrained. Such a system has several possible causal structures depending on which variables are made exogenous(cf. Fig. 3). For example, a system of N v variables and Ne < N v equations has in the worst case N v -choose-(N v − Ne) differ-ent ways to assign exogenous variables. Without the benefit of COA all of these combinations are viable. This fact restrictsthe utility of basing causal models on equations and has generally led research to focus on learning causal relations fromdata. This approach, however, wastes a huge repository of knowledge of physical, social, biological, economic, psychologi-cal, etc., relationships that have been discovered by decades of research. The presence of a provably sound causal orderingalgorithm provides a practical way to incorporate this wealth of existing knowledge into causal models.Aside from constructing models, COA provides us a flexible tool for specifying complex interactions with a system. Whatif we want to swap one part of our system with a new one that depends on different factors? What if we want to manipulatesome variables but release others? The standard Do operator does not address these complex types of manipulation, butCOA handles them seamlessly. COA thus serves as a generating function for arbitrary manipulations on a causal system.AcknowledgementsWe would like to thank Tsai-Ching Lu, Hans van Leijen and Jeroen Boegers for useful discussions on this topic. This re-search was supported by the National Aeronautics and Space Administration under the Graduate Students Research Program(GSRP), grant number S99-GSRP-085, the Air Force Office of Scientific Research under grants F49620-00-1-0122, F49620-03-1-0122 and FA9550-06-1-0243 to the University of Pittsburgh, by Intel Research and by the National Science Foundationunder Faculty Early Career Development (CAREER) Program, grant IRI-9624629.References[1] G.F. Cooper, E. Herskovits, A Bayesian method for the induction of probabilistic networks from data, Machine Learning 9 (4) (1992) 309–347.[2] D. Dash, Caveats for causal reasoning, PhD thesis, Intelligent Systems Program, University of Pittsburgh, Pittsburgh, PA, April 2003.[3] D. Dash, Restructuring dynamic causal systems in equilibrium, in: R.G. Cowell, Z. Ghahramani (Eds.), Proceedings of the Tenth International Workshopon Artificial Intelligence and Statistics (AIStats 2005), Society for Artificial Intelligence and Statistics, 2005, pp. 81–88.[4] J. de Kleer, J. Seely Brown, A qualitative physics based on confluences, Artificial Intelligence 24 (1–3) (December 1984) 7–83.[5] J. de Kleer, B.C. Williams, Reasoning about multiple faults, in: Proceedings of the 5th National Conference on Artificial Intelligence (AAAI-86), Philadel-phia, PA, American Association for Artificial Intelligence, 1986, pp. 132–139.[6] M.J. Druzdzel, H.A. Simon, Causality in Bayesian belief networks, in: Proceedings of the Ninth Annual Conference on Uncertainty in Artificial Intelligence(UAI-93), San Francisco, CA, Morgan Kaufmann Publishers, Inc., 1993, pp. 3–11.[7] M.J. Druzdzel, H. van Leijen, Causal reversibility in Bayesian networks, Journal of Experimental and Theoretical Artificial Intelligence 13 (1) (January2001) 45–62.[8] A.S. Goldberger, Structural equation methods in the social sciences, Econometrica 40 (6) (November 1972) 979–1001.[9] C.W.J. Granger, Investigating causal relations by econometric models and cross-spectral methods, Econometrica 37 (1969) 424–438.[10] T. Haavelmo, The statistical implications of a system of simultaneous equations, Econometrica 11 (1) (January 1943) 1–12.[11] Y. Iwasaki, H.A. Simon, Causality in device behavior, Artificial Intelligence 29 (1) (July 1986) 3–32.[12] Y. Iwasaki, H.A. Simon, Theories of causal ordering: Reply to de Kleer and Brown, Artificial Intelligence 29 (1) (July 1986) 63–67.[13] H. Kiiveri, T.P. Speed, Structural analysis of multivariate data: A review, in: S. Leinhardt (Ed.), Sociological Methodology 1982, Jossey-Bass Publishers,San Francisco, 1982, pp. 209–289, Chapter 6.[14] H. Kiiveri, T.P. Speed, J. Carlin, Recursive causal models, Journal of the Australian Mathematical Society 36 (1984) 30–52.[15] S.L. Lauritzen, D.J. Spiegelhalter, Local computations with probabilities on graphical structures and their application to expert systems, Journal of theRoyal Statistical Society, Series B (Methodological) 50 (2) (1988) 157–224.[16] T.-C. Lu, M.J. Druzdzel, T.-Y. Leong, Causal mechanism-based model construction, in: Proceedings of the Sixteenth Annual Conference on Uncertainty inArtificial Intelligence (UAI-2000), San Francisco, CA, Morgan Kaufmann Publishers, Inc., 2000, pp. 353–362.[17] P. Pandurang Nayak, Causal approximations, Artificial Intelligence 70 (1–2) (1994) 1–58.[18] J. Pearl, T.S. Verma, A theory of inferred causation, in: J.A. Allen, R. Fikes, E. Sandewall (Eds.), KR-91, Principles of Knowledge Representation andReasoning: Proceedings of the Second International Conference, Cambridge, MA, Morgan Kaufmann Publishers, Inc., San Mateo, CA, 1991, pp. 441–452.[19] J. Pearl, Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference, Morgan Kaufmann Publishers, Inc., San Mateo, CA, 1988.[20] J. Pearl, Causal diagrams for empirical research, Biometrika 82 (4) (1995) 669–710.[21] J. Pearl, Causality: Models, Reasoning, and Inference, Cambridge University Press, Cambridge, UK, 2000.[22] Q. Shen, T. Peng, R. Milne, Dimensional analysis based causal ordering, in: Proceedings of the 13th International Workshop on Qualitative Reasoning(QR-99), Loch Awe, Scotland, 1999, pp. 193–202.[23] H.A. Simon, J.R. Kalagnanam, M.J. Druzdzel, Performance budget planning: The case of a research university, Technical report, School of InformationSciences, University of Pittsburgh, Pittsburgh, PA, 2000.[24] H.A. Simon, Causal ordering and identifiability, in: W.C. Hood, T.C. Koopmans (Eds.), Studies in Econometric Method, in: Cowles Commission forResearch in Economics Monograph No. 14, John Wiley & Sons, Inc., New York, NY, 1953, pp. 49–74, Chapter III.[25] H.A. Simon, Spurious correlation: A causal interpretation, Journal of the American Statistical Association 49 (267) (September 1954) 467–479.[26] H.A. Simon, Nonmonotonic reasoning and causation: Comment, Cognitive Science 15 (2) (April–June 1991) 293–300.1808D. Dash, M.J. Druzdzel / Artificial Intelligence 172 (2008) 1800–1808[27] P. Spirtes, C. Glymour, An algorithm for fast recovery of sparse causal graphs, Social Science Computer Review 9 (1991) 62–72.[28] P. Spirtes, C. Glymour, R. Scheines, Causation, Prediction, and Search, Springer Verlag, New York, 1993.[29] P. Spirtes, C. Glymour, R. Scheines, Causation, Prediction, and Search, second ed., The MIT Press, Cambridge, MA, 2000.[30] R.H. Strotz, H.O.A. Wold, Recursive vs. nonrecursive systems: An attempt at synthesis; Part I of a triptych on causal chain systems, Econometrica 28 (2)(April 1960) 417–427.[31] J.L. Top, H. Akkermans, Computational and physical causality, in: Proceedings of the Twelfth International Joint Conference on Artificial Intelligence(IJCAI-1991), 1991, pp 1171–1176.[32] L. Travé-Massuyés, R. Pons, Causal ordering for multiple mode systems, in: Proceedings of the 11th International Workshop on Qualitative Reasoning(QR-97), 1997, pp. 203–214.[33] N. Wermuth, S.L. Lauritzen, Graphical and recursive models for contingency tables, Biometrika 72 (1983) 537–552.[34] N. Wermuth, Linear recursive equations, covariance selection and path analysis, Journal of the American Statistical Association 75 (1980) 963–972.[35] B.C. Williams, Qualitative analysis of MOS circuits, Artificial Intelligence 24 (1984) 281–346.[36] H. Wold, Causality and econometrics, Econometrica 22 (2) (April 1954) 162–177.[37] S. Wright, The method of path coefficients, Annals of Mathematical Statistics 5 (1934) 161–215.