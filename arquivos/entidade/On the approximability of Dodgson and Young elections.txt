Artificial Intelligence 187–188 (2012) 31–51Contents lists available at SciVerse ScienceDirectArtificial Intelligencewww.elsevier.com/locate/artintOn the approximability of Dodgson and Young elections ✩Ioannis Caragiannis a, Jason A. Covey b, Michal Feldman c,d, Christopher M. Homan b,Christos Kaklamanis a, Nikos Karanikolas a, Ariel D. Procaccia e,∗, Jeffrey S. Rosenschein fa Computer Technology Institute and Department of Computer Engineering and Informatics, University of Patras, 26504 Rio, Greeceb Department of Computer Science, Rochester Institute of Technology, 102 Lomb Memorial Drive, Rochester, NY 14623-5603, USAc School of Business Administration and Center for the Study of Rationality, The Hebrew University of Jerusalem, Jerusalem 91904, Israeld Microsoft Israel R&D Center, Israele School of Engineering and Applied Sciences, Harvard University, Cambridge, MA 02138, USAf School of Computer Science and Engineering, The Hebrew University of Jerusalem, Jerusalem 91904, Israela r t i c l ei n f oa b s t r a c tArticle history:Received 18 January 2011Received in revised form 8 April 2012Accepted 10 April 2012Available online 16 April 2012Keywords:Computational social choiceApproximation algorithmsThe voting rules proposed by Dodgson and Young are both designed to find an alternativeclosest to being a Condorcet winner, according to two different notions of proximity; thescore of a given alternative is known to be hard to compute under either rule. In this paper,we put forward two algorithms for approximating the Dodgson score: a combinatorial,greedy algorithm and an LP-based algorithm, both of which yield an approximation ratio ofHm−1, where m is the number of alternatives and Hm−1 is the (m − 1)st harmonic number.We also prove that our algorithms are optimal within a factor of 2, unless problems inN P have quasi-polynomial-time algorithms. Despite the intuitive appeal of the greedyalgorithm, we argue that the LP-based algorithm has an advantage from a social choicepoint of view. Further, we demonstrate that computing any reasonable approximation ofthe ranking produced by Dodgson’s rule is N P-hard. This result provides a complexity-theoretic explanation of sharp discrepancies that have been observed in the social choicetheory literature when comparing Dodgson elections with simpler voting rules. Finally, weshow that the problem of calculating the Young score is N P-hard to approximate by anyfactor. This leads to an inapproximability result for the Young ranking.© 2012 Elsevier B.V. All rights reserved.1. IntroductionThe discipline of voting theory deals with the following setting: there is a group of n agents and each of them ranks aset of m alternatives; one alternative is to be elected. The big question is: which alternative best reflects the social good?This question is fundamental to the study of multiagent systems, because the agents of such a system often need tocombine their individual objectives into a single output or decision that best reflects the aggregate needs of all the agentsin the system. For instance, web meta-search engines [12] and recommender systems [21] have used methods based onvoting theory.Reflecting on this question, the French philosopher and mathematician Marie Jean Antoine Nicolas de Caritat, marquis deCondorcet, suggested the following intuitive criterion: the winner should be an alternative that beats every other alternative✩A preliminary version of the results in this paper appeared in the Proceedings of the 20th Annual ACM–SIAM Symposium on Discrete Algorithms (SODA’09).* Corresponding author.E-mail addresses: caragian@ceid.upatras.gr (I. Caragiannis), jac8687@cs.rit.edu (J.A. Covey), mfeldman@huji.ac.il (M. Feldman), cmh@cs.rit.edu(C.M. Homan), kakl@ceid.upatras.gr (C. Kaklamanis), nkaranik@ceid.upatras.gr (N. Karanikolas), arielpro@seas.harvard.edu (A.D. Procaccia), jeff@cs.huji.ac.il(J.S. Rosenschein).0004-3702/$ – see front matter © 2012 Elsevier B.V. All rights reserved.http://dx.doi.org/10.1016/j.artint.2012.04.00432I. Caragiannis et al. / Artificial Intelligence 187–188 (2012) 31–51in a pairwise election, i.e., an alternative that a (strict) majority of the agents prefers over any other alternative. Sadly, it isfairly easy to see that the preferences of the majority may be cyclic, hence a Condorcet winner does not necessarily exist.This unfortunate phenomenon is known as the Condorcet paradox (see Black [5]).In order to circumvent this result, several researchers have proposed choosing an alternative that is “as close as pos-sible” to a Condorcet winner. Different notions of proximity can be considered, and yield different voting rules. One suchsuggestion was advocated by Charles Dodgson, better known by his pen name Lewis Carroll, author of “Alice’s Adventuresin Wonderland.” The Dodgson score [5] of an alternative, with respect to a given set of agents’ preferences, is the minimumnumber of exchanges between adjacent alternatives in the agents’ rankings one has to introduce in order to make the givenalternative a Condorcet winner. A Dodgson winner is any alternative with a minimum Dodgson score.Young [45] raised a second option: measuring the distance by agents. Specifically, the Young score of an alternative is thesize of the largest subset of agents such that, if only these ballots are taken into account, the given alternative becomesa Condorcet winner. A Young winner is any alternative with the maximum Young score. Alternatively, one can perceive aYoung winner as the alternative that becomes a Condorcet winner by removing the fewest agents.Though these two voting rules sound appealing and straightforward, they have been criticized because they fail to meetseveral well-studied classical fairness criteria [18,6]. However, impossibility results tell us that every voting rule likewisefails to satisfy some such criterion. Thus, there is no hope of finding a voting rule that is perfect for all situations. Instead,social choice theory has advanced our understanding of an ever-increasing body of voting rules, each of which has uniquefeatures, virtues, and vices. Practitioners can choose from this body whichever rules best apply to their particular situations.Dodgson and Young voting are two such rules, as are the two approximation algorithms introduced later in this article.A less ambiguous drawback of Dodgson and Young voting is that they are notoriously complicated to resolve. As early as1989, Bartholdi, Tovey and Trick [2] showed that the Dodgson score decision problem is N P -complete, and that pinpointinga Dodgson winner is N P -hard. This important paper was one of the first to introduce complexity-theoretic considerationsto social choice theory. Hemaspaandra et al. [23] refined the aforementioned result by showing that the Dodgson winnerdecision problem is complete for Θ p2 , the class of problems that can be solved by O(log n) queries to an N P set. Subse-quently, Rothe et al. [41] proved that the Young winner problem is also complete for Θ p2 .These complexity-theoretic results give rise to the agenda of approximately calculating an alternative’s score, under theDodgson and Young schemes. This is clearly an interesting computational problem, as an application area of algorithmictechniques.However, from the point of view of social choice theory, it is not immediately apparent that an approximation of avoting rule is satisfactory, since an “incorrect” alternative—in our case, one that is not closest to a Condorcet winner—mightbe elected. The key insight is that an approximation of a voting rule is a voting rule in its own right, and in some cases onecan argue that this new voting rule has desirable properties. We discuss this point at length, and justify our approach, inSection 7.1.1. Our resultsIn the context of approximating the Dodgson score, we devise a greedy algorithm for the Dodgson score which has anapproximation ratio of Hm−1, where m is the number of alternatives and Hm−1 is the (m − 1)st harmonic number. Wethen propose a second algorithm that is based on solving a linear programming relaxation of the Dodgson score and hasthe same approximation ratio. Although the former algorithm gives us a better intuition into the combinatorial structureof the problem, we show that the latter has the advantage of being score monotonic, which is a desirable property froma social choice point of view. We further observe that it follows from the work of McCabe-Dansted [30] that the Dodgsonscore cannot be approximated within sublogarithmic factors by polynomial-time algorithms unless P = N P . We prove amore explicit inapproximability result of (1/2 − (cid:3)) ln m, under the assumption that problems in N P do not have algorithmsrunning in quasi-polynomial time; this implies that the approximation ratio achieved by our algorithms is optimal up to afactor of 2.A number of recent papers [38,39,27–29] have established that there are sharp discrepancies between the Dodgsonranking and the rankings produced by other rank aggregation rules. Some of these rules (e.g., Borda and Copeland) arepolynomial-time computable, so the corresponding results can be viewed as negative results regarding the approximabilityof the Dodgson ranking by polynomial-time algorithms. We show that the problem of distinguishing between whether am) positions in any Dodgson ranking is N P -hard. Thisgiven alternative is the unique Dodgson winner or in the last O (theorem provides a complexity-theoretic explanation for some of the observed discrepancies, but in fact is much wider inscope as it applies to any efficiently computable rank aggregation rule.√At first glance, the problem of calculating the Young score seems simple compared with the Dodgson score (we discussin Section 6 why this seems so). Therefore, we found the following result quite surprising: it is N P -hard to approximate theYoung score within any factor. Specifically, we show that it is N P -hard to distinguish between the case where the Youngscore of a given alternative is 0, and the case where the score is greater than 0. As a corollary we obtain an inapproximabilityresult for the Young ranking. We also show that it is N P -hard to approximate the dual Young score within O (n1−(cid:3) ), forany constant (cid:3) > 0. We define the dual Young score below in the preliminaries section.I. Caragiannis et al. / Artificial Intelligence 187–188 (2012) 31–51331.2. Related workThe agenda of approximating voting rules was recently pursued by Ailon et al. [1], Coppersmith et al. [10], and Kenyon-Mathieu and Schudy [26]. These papers deal, directly or indirectly, with the Kemeny rank aggregation rule, which choosesa ranking of the alternatives instead of a single winning alternative. The Kemeny rule picks the ranking that has the maxi-mum number of agreements with the agents’ individual rankings regarding the correct order of pairs of alternatives. Ailon etal. improve the trivial 2-approximation algorithm to an involved, randomized algorithm that gives an 11/7-approximation;Kenyon-Mathieu and Schudy further improve the approximation, and obtain a polynomial-time approximation scheme(PTAS).Two recent papers study the approximability of Dodgson elections; both papers appeared after the conference versionof the current paper. Faliszewski, Hemaspaandra, and Hemaspaandra show that minimax as a scoring rule is an m2 approx-imation of the Dodgson score [16]. Caragiannis et al. [7] give a number of algorithms that approximate to Dodgson scoreand also have nice fairness properties, such as homogeneity and monotonicity, but whose approximations are either asymp-totically worse than ours or not polynomial-time computable. Moreover, their approximation algorithms are much morecomplex, both descriptionally and in running time. They also provide upper bounds such that any score-based voting rulewhose scoring rule approximates Dodgson scoring to within the bounds fails to meet certain fairness criteria. In Section 4we discuss further the latter results.Two recent papers have directly put forward algorithms for the Dodgson winner problem [24,32]. Both papers indepen-dently build upon the same basic idea: if the number of agents is significantly larger than the number of alternatives, andone looks at a uniform distribution over the preferences of the agents, with high probability one obtains an instance onwhich it is trivial to compute the Dodgson score of a given alternative. This directly gives rise to an algorithm that canusually compute the Dodgson score (under the assumption on the number of agents and alternatives). However, this isnot an approximation algorithm in the usual sense, since the algorithm a priori gives up on certain instances,1 whereas anapproximation algorithm is judged by its worst-case guarantees. In addition, this algorithm would be useless if the numberof alternatives is not small compared with the number of agents.2In a similar vein, McCabe-Dansted [31] suggested several new variations on Dodgson’s rule. These rules are shown togive an additive approximation to the Dodgson score. Specifically, they can underestimate the score by an additive term ofat most (m − 1)!(m − 1)e, where m is the number of alternatives. We note that this result would only be meaningful if thereare very few alternatives, and in addition it does not provide the tight worst-case multiplicative guarantees that we achievein this paper. McCabe-Dansted further shows that, similarly to the rules discussed above, the new rules usually select theDodgson winner under certain distributions.Betzler et al. [4] have investigated the parameterized computational complexity of the Dodgson and Young rules. Theauthors have devised a fixed parameter algorithm for exact computation of the Dodgson score, where the fixed parameteris the “edit distance”, i.e., the number of exchanges. Specifically, if k is an upper bound on the Dodgson score of a givenalternative, n is the number of agents, and m the number of alternatives, the algorithm runs in time O(2k · nk + nm). Noticethat in general it may hold that k = Ω(nm). In contrast, the Young score decision problem is W [2]-complete; this impliesthat there is no algorithm that computes the Young score exactly, and whose running time is polynomial in nm and onlyexponential in k, where the parameter k is the number of remaining votes. These results complement ours nicely, as weshall also demonstrate that computing the Dodgson score is in a sense easier than computing the Young score, albeit in thecontext of approximation.Putting computational complexity aside, some research by social choice theorists has considered comparing the rankingproduced by Dodgson, i.e., the ordering of the alternatives by nondecreasing Dodgson score, with elections based on simplervoting rules. Such comparisons have always revealed sharp discrepancies. For example, the Dodgson winner can appear inany position in the Kemeny ranking [38] and in the ranking of any positional scoring rule [39] (e.g., Borda or Plurality),Dodgson rankings can be exactly the opposite of Borda [29] and Copeland rankings [27], while the winner of Kemeny orSlater elections can appear in any position of the Dodgson ranking [28].More distantly related to our work is research that is concerned with exactly resolving hard-to-compute voting rulesby heuristic methods. Typical examples include papers regarding the Kemeny rule [9] and the Slater rule [8]. Another moreremotely related field of research is concerned with finding approximate, efficient representations of voting rules, by elicitingas little information as possible; this line of research employs techniques from learning theory [36].1 Technically speaking, this algorithm correctly computes the Dodgson score in worst-case polynomial time, but only when the domain is restricted tothose instances on which the algorithm does not give up, and there does not seem to be a characterization of this domain restriction that does not refer ina fairly direct way back to the algorithm itself. Thus, in many natural settings one cannot before an election is held guarantee that the algorithm will work.2 This would normally not happen in political elections, but can certainly be the case in many other settings. For instance, consider a group of agentstrying to reach an agreement on a joint plan, when multiple alternative plans are available. Specifically, think of a group of investors deciding whichcompany to invest in.34I. Caragiannis et al. / Artificial Intelligence 187–188 (2012) 31–511.3. Structure of the paperIn Section 2, we introduce some notations and definitions. In Section 3, we present our upper bounds for approximatingthe Dodgson score. We study the monotonicity properties of our algorithms in Section 4. In Section 5, we present our lowerbounds for approximating the Dodgson score and ranking. In Section 6, we prove that the Young score, dual Young score,and Young ranking are inapproximable. Finally, we discuss our approach in Section 7.2. PreliminariesLet N = {1, . . . , n} be a set of agents, and let A be a set of alternatives. We denote | A| by m, and denote the alternativesthemselves by letters, such as a ∈ A. Indices referring to agents appear in superscript. Each agent i ∈ N holds a binaryrelation R i over A that satisfies antisymmetry, transitivity and totality. Informally, R i is a ranking of the alternatives. LetL = L( A) be the set of all rankings over A; we have that each R i ∈ L. We denote R N = (cid:5)R1, . . . , Rn(cid:6) ∈ L N , and refer tothis vector as a preference profile. We may also use Q i to denote the preferences of agent i, in cases where we want todistinguish between two different rankings R i and Q i . For sets of alternatives B1, B2 ⊆ A, we write B1 R i B2 if for all a ∈ B1and b ∈ B2, aR ib. If B1 = {a} (respectively, B2 = {a}) for some a, we sometimes write aR i B2 (respectively, B1 R ia) instead of{a}R i B2 (respectively, B1 R i{a}).Let a, b ∈ A. Denote P (a, b) = {i ∈ N: aR ib}. We say that a beats b in a pairwise election if |P (a, b)| > n/2, that is, a ispreferred to b by a majority of agents. A Condorcet winner is an alternative that beats every other alternative in a pairwiseelection.The Dodgson score of a given alternative aexchanges between adjacent alternatives in R N needed to make aA = {a, b, c}, and let R N be given by:∗, with respect to a given preference profile R N , is the least number ofa Condorcet winner. For instance, let N = {1, 2, 3},∗R1abcR2bacR3acbwhere the top alternative in each column is the most preferred one.In this example, the Dodgson score of a is 0 (a is a Condorcet winner), the Dodgson score of b is 1, and the Dodgsonscore of c is 3. Bartholdi et al. [2] have shown that the Dodgson score decision problem—the problem of determining, fora given preference profile R N , alternative a, and natural number k, whether the Dodgson score of a in R N is at most k—isN P -complete.The Young score of awith respect to R N is the size of a largest subset of agents for whom ais a Condorcet winner.This is the definition given by Young himself [45], and used in subsequent articles [41]. If, for every nonempty subset ofis not a Condorcet winner, its Young score is 0. In the above example, the Young score of a is 3, the Young scoreagents, aof b is 1, and the Young score of c is 0.∗∗∗Equivalently, a Young winner is an alternative such that one has to remove the minimum number of agents in order tomake it a Condorcet winner. We call this number the dual Young score. Note that, in the context of approximation, thesetwo definitions are not equivalent; we employ the former (original, prevalent) definition, but touch on the latter as well.As the decision problem version of the Young winner problem (the decision problem is to determine, given a preferenceprofile and an alternative a, whether a is the Young winner in that profile) is known to be Θ P2 -complete [41], and thusN P -hard, the Young score problem must also be hard; otherwise, we would be able to calculate the scores of all thealternatives efficiently, and identify the alternatives with minimum score.Linear and integer programs are fundamental tools for solving optimization problems. See Cormen et al. [11] for a niceintroduction to the subject from a computer science perspective, which we summarize here. A linear program in its canonicalform consists of, for some p, q ∈ N, a p × q matrix M, a p-vector A and a q-vector B, and seeks to find a q-vector thatmaximizes B X (called the objective function) subject to the constraints M X (cid:2) A, where any X satisfying the constraints(though which may not necessarily be a maximum) is called feasible. An integer linear program is a linear program with theadditional restriction that X may only take integral values. As is commonly done, we will often write the linear programs weuse as seeking to minimize rather than maximize the objective function, and express some of the constraints as lower ratherthan upper bounds. Through simple algebraic manipulation, these expressions can always be translated into equivalent onesthat are in the canonical form defined above.For a linear program in the form given above, its dual is the linear program defined as the problem of finding a p-vectorY (cid:3) 0 that minimizes AY subject to the constraints MTY (cid:3) B (where MT is the transpose of M). It is easy to see that B Xof any feasible solution X to the original problem (known as the primal linear program) is a lower bound on AY of anyfeasible solution Y to its dual (or vice versa if the primal is expressed as a minimization problem), so X and Y are optimalsolutions to their respective problems whenever AY = B X . The converse is also true, though not as easy to see, and plays afundamental role in the analysis of algorithms for solving linear programs. We will use this fact in the paper.I. Caragiannis et al. / Artificial Intelligence 187–188 (2012) 31–5135R1bd1d2cd3∗ad4d5d6d7d8R2bd4d5∗acd1d2d3d6d7d8R3cbd6d7d8∗ad1d2d3d4d5R1bd1d2∗acd3d4d5d6d7d8R2bd4d5∗acd1d2d3d6d7d8R3cbd6d7d8∗ad1d2d3d4d5R1bd1d2∗acd3d4d5d6d7d8R2∗abd4d5cd1d2d3d6d7d8R3cbd6d7d8∗ad1d2d3d4d5R1bd1d2∗acd3d4d5d6d7d8R2∗abd4d5cd1d2d3d6d7d8R3c∗abd6d7d8d1d2d3d4d5(a) Initial profile.(b) After step 1.(c) After step 2.(d) After step 3.Fig. 1. An example of the execution of the greedy algorithm.Linear programs are widely used by engineers and computer scientists to solve a wide range of problems. They can besolved in polynomial time, though the degrees of these polynomials are so high that in practice worst-case superpolynomial-time algorithms are used instead.3. Approximability of Dodgson scoresWe begin by presenting our approximation algorithms for the Dodgson score. Let us first introduce some notation.Let a∗ ∈ A be a distinguished alternative, whose Dodgson score we wish to compute. Define the deficit of a∗∗with respectis clear, as the number of additional agents i whose ranking relationto a ∈ A, simply denoted def(a) when the identity of aR i must be changed from to aR iaR ia in order for a∗∗∗to beat a in a pairwise election. Equivalently,def(a) = max(cid:2)0, 1 + (cid:8)n/2(cid:9) − Pto a(cid:3)a(cid:4)(cid:5).∗, aFor instance, if four agents prefer a to aelection (namely aare alive. Alternatives that are not alive, i.e., those with def(a) = 0, are dead.∗beats a in a pairwiseis preferred to a by a majority of agents) then def(a) = 0. We say that alternatives a ∈ A with def(a) > 0to a, then def(a) = 2. If aand only one agent prefers a∗∗∗3.1. A greedy algorithmIn this section we present a combinatorial, greedy algorithm for approximating the Dodgson score of a given alternative., and recall that a live alternative is one with a positive deficit. In each step, thein the preference of some agent. The cost-effectiveness ofis moved upwards inovertakes as aConsider, once again, a special alternative aalgorithm selects an optimally cost-effective push of alternative apushing athe preference of i compared with the original profile R N , and the number of currently live alternatives that aresult of this push.in the preference of an agent i ∈ N is the ratio between the total number of positions a∗∗∗∗∗After selecting an optimally cost-effective push, i.e., the push with the lowest cost-effectiveness, the algorithm decreasesovertakes. Alternatives a ∈ A with def(a) = 0 become dead. The algorithmdef(a) by one for each live alternative a that aterminates when no live alternatives remain. The output of the algorithm is the total number of positions that alternativeais pushed upwards in the preferences of all agents.∗∗Greedy algorithm:(cid:10)1. Let A2. While Abe the set of live alternatives, namely those alternatives a ∈ A with def(a) > 0.(cid:10) (cid:11)= ∅:• Perform an optimally cost-effective push, namely push a∗the ratio between the total number of positions that acurrently live alternatives that a∗overtakes as a result of this push.∗in the preferences of agent i ∈ N in a way that minimizesmoves upwards in the preferences of i and the number of• Recalculate A(cid:10).3. Return the number of exchanges performed.An example of the execution of the algorithm is depicted in Fig. 1 (see also Fig. 2 and the related discussion in Section 4).has deficits def(b) = 2, def(c) = 1, and def(di) = 0. Hence, alternativesIn the initial profile of this example, alternative ab and c are alive and alternatives d1, . . . , d8 are dead. At the first step of the algorithm, there are several different ways ofpushing alternative aupwards in order to overtake one of the live alternatives b and c or both. Among them, the one withthe smallest cost-effectiveness is to push amoves two positions upwards andin the initial profile has cost-effectivenessovertakes the live alternative c for a cost-effectiveness of 2. Any other push of aat least 2.5 since ahas to be pushed at least three positions upwards in order to overtake one live alternative and at leastupwards in the preference R1. In this way, a∗∗∗∗∗∗36I. Caragiannis et al. / Artificial Intelligence 187–188 (2012) 31–51∗∗five positions upwards in order to overtake both b and c. After step 1, alternative c is dead. Then, in step 2, there are threeupwards so that it overtakes the live alternative b: either pushing it at the top of R 1 (this hasways to push alternative awould have moved five positions in total compared to the initial profile in R 1), or pushingcost effectiveness 5 because ait at the top of R2 (with cost-effectiveness 3), or pushing it four positions upwards in R 3 (with cost-effectiveness 4). Theat the top position of R1 oralgorithm picks the second option. Then, in step 3, the algorithm can either push alternative apush it four positions upwards in R3. The former has a cost-effectiveness of 5 (recall that cost-effectiveness is defined usingthe total number of positions awould move compared to its position at the initial profile) while the latter has a cost-effectiveness of 4 and is the push the algorithm picks. After step 3, all alternatives are dead and the algorithm terminatesby returning the total number of positions ais pushed upwards, i.e., 9.∗∗∗∗By the definition of the algorithm, it is clear that it produces a profile where ais a Condorcet winner. It is importantto notice that if ais initially a Condorcet winner then the algorithm calculates a score of zero, so as a voting rule thealgorithm satisfies the Condorcet criterion. Also, during each iteration of line 2 an optimally cost-effective push may notbe unique, in which case the algorithm chooses, in a manner that does not affect our approximation results, exactly one ofthese optimally cost-effective pushes.∗Theorem 3.1. For any input ascore of a, where for all natural numbers k, Hk =∗(cid:6)ki=1∗1k is the k-th harmonic number.and R N with m alternatives, the greedy algorithm returns an Hm−1-approximation of the DodgsonProof. We base our proof on the connection between our problem and the Constrained Set Multicover problem, for whichRajagopalan and Vazirani [37] give an approximation algorithm and use the dual fitting technique to prove its approximationratio (see also [44, pp. 112–116]).Constrained Set MulticoverInstance:A ground set A, a set of integers {ra}a∈ A , one for each element of a ∈ A, representing the covering requirement for a,an indexed collection S = {S j | S j ⊆ A} of subsets of A (crucially, the same subset may occur more than once in this}, one for each member of S, representingcollection, as long as each copy has a distinct index), and a set of integers {c S jthe cost of that member.Question: What is the smallest number ¯c for which there is a subcollection C of S such that(cid:6)S j ∈C c S j ,1. ¯c =2. each member of S appears at most once in C, and3. each element a ∈ A appears in at least ra members of C?We may view the problem of approximating the Dodgson score as a variation of Constrained Set Multicover. The∗}, its deficit def(a) is in fact its coveringground set is the set of live alternatives. For each live alternative a ∈ A \ {arequirement, i.e., the number of different sets it has to belong to in the final cover. For each agent i ∈ N that ranks ainplace ri , we have a group S i consisting of the sets S ik contains the (initially) livealternatives that appear in positions ri − k to ri − 1 in the preference of agent i. The set S ik has cost k. Now, the coveringproblem to be solved is the following. We wish to select at most one set from each of the different groups so that each∗} appears in at least def(a) sets and the total cost of the selected sets is minimized. The optimal costalternative a ∈ A \ {aand, hence, the cost of any approximate cover that satisfies the covering requirements and theis the Dodgson score of aconstraints is an upper bound on the Dodgson score.We can thus define this covering problem as:k for k = 1, . . . , ri − 1, where the set S i∗∗Set Multicover with Group ConstraintsInstance:A ground set A, a set of integers {ra}a∈ A , one for each element of a ∈ A, a collection S = {S j | S j ⊆ A} of subsetsof A, a set of integers {c S j}, and a partitioning of S into groups S i for i ∈ N.Question: What is the smallest number ¯c for which there is a subcollection C of S such that(cid:6)S j ∈C c S j ,1. ¯c =2. each member of S appears at most once in C,3. each element a ∈ A appears in at least ra members of C, and4. at most one member from each group S i appears in C?In terms of this covering problem, the greedy algorithm mentioned above can be thought of as follows. In each step,it selects an optimally cost-effective set where the cost-effectiveness of a set is defined as the ratio between the cost ofthe set and the number of live alternatives it covers that have not been previously covered by sets belonging to the samegroup. For these live alternatives, the algorithm decreases their covering requirements at the end of the step. The algorithmterminates when all alternatives have died (i.e., their covering requirement has become zero). The output of the algorithmconsists of the maximum-cost sets that were picked from each group.I. Caragiannis et al. / Artificial Intelligence 187–188 (2012) 31–5137We find it convenient to formulate the Dodgson score problem as the following integer linear program.(cid:7)ri −1(cid:7)minimizek=1subject to ∀a ∈ A \i∈Nk · xS ik(cid:5)(cid:2)a∗,(cid:7)S∈S i∀i ∈ N,x ∈ {0, 1}.(cid:7)(cid:7)S∈S i : a∈Si∈NxS (cid:2) 1xS (cid:3) def(a)The variable xS associated with a set S denotes whether S is included in the solution (xS = 1) or not (xS = 0). We relaxthe integrality constraint in order to obtain a linear programming relaxation and we compute its dual linear program.maximize(cid:7)a∈ A\{a∗}def(a) · ya −(cid:7)i∈Nzisubject to∀i ∈ N, k = 1, . . . , ri − 1,(cid:7)a∈S ikya − zi (cid:2) k∀i ∈ N,∀a ∈ A \zi (cid:3) 0(cid:5)(cid:2)∗a,ya (cid:3) 0.For a set S that is picked by the algorithm to cover alternative a ∈ A \ {a∗} for the j-th time (the j-th copy of a), we setp(a, j) to be equal to the cost-effectiveness of S when it is picked. Informally, p distributes equally the cost of S amongthe copies of the live alternatives it covers. When the algorithm covers a live alternative a by picking a set S that belongsto group S i , we use the notation ji(a) to denote the index of the copy of a the algorithm covers by picking this set. Denoteby T i the set of live alternatives covered by the sets of group S i that are picked by the algorithm throughout its execution.Now, we shall show that by settingya = p(a, def(a))Hm−1for each alternative a ∈ A \ {azi = 1Hm−1(cid:7)(cid:3)pa∈T i∗} and(cid:3)(cid:4)a, def(a)(cid:4)(cid:4)(cid:3)a, ji(a)− pfor each agent i ∈ N, the constraints of the dual linear program are satisfied. The variables ya are clearly non-negative.Since the algorithm picks a set of optimal cost-effectiveness at each step, the cost-effectiveness of the set picked does notdecrease with time. Hence, p(a, def(a)) (cid:3) p(a, j) for every alternative a with def(a) > 0 and j (cid:2) def(a). This implies that ziis non-negative as well.In order to show that the first constraint of the dual linear program is also satisfied, consider an agent i ∈ N and integerk such that 1 (cid:2) k (cid:2) ri − 1. We have(cid:3)(cid:4)a, def(a)ya − zi = 1(cid:8)(cid:7)(cid:7)p(cid:7)(cid:3)−(cid:3)(cid:4)a, def(a)p(cid:4)(cid:4)(cid:3)a, ji(a)− p(cid:9)a∈S ikHm−1(cid:2) 1Hm−1= 1Hm−1a∈S ik(cid:8)(cid:7)(cid:3)(cid:4)a, def(a)p−a∈T i(cid:7)(cid:3)(cid:3)(cid:4)a, def(a)p(cid:4)(cid:4)(cid:3)a, ji(a)− p(cid:9)a∈S ik(cid:8) (cid:7)a∈S ik\T ia∈S ik(cid:3)(cid:4)a, def(a)p+∩T i(cid:7)(cid:3)(cid:4)a, ji(a)p(cid:9).a∈S ik∩T i(1)Now, for each alternative a ∈ S ik, we define ν(a) as follows. If a ∈ S ikcovered alternative a by picking a set of group S i . Otherwise, if a ∈ S ikdied. Now, number the alternatives in S iorder. Consider alternative at with 1 (cid:2) t (cid:2) |S ikstep ν(at ) is performed, the alternatives at, at+1, . . . , a|S i∩ T i , ν(a) is the time step in which the algorithm\ T i , ν(a) is the time step in which alternative a| be thisk, after| have not died yet and the sets of group S i that have been pickedk in nondecreasing order of ν(·), breaking ties arbitrarily. Let a1, a2, . . . , a|S i|. Observe that, due to the definition of the order of alternatives in S ikk38I. Caragiannis et al. / Artificial Intelligence 187–188 (2012) 31–51by the algorithm so far (if any) do not contain any of them. Hence, at step ν(at ), the algorithm has the option to pick set S ikof cost k in order to cover at least these |S i| − t + 1 alternatives. So, the cost-effectiveness of the set that is actually pickedkkby the algorithm at step ν(at ) is at most|−t+1. This argument implies that|S ik(cid:4)(cid:3)at, ji(at)p(cid:2)k|S ik| − t + 1∩ T i , andif at ∈ S ik(cid:3)(cid:4)at, def(at)potherwise (if at ∈ S ikk| − t + 1(cid:2)|S ik\ T i ).Using (2) and (3) together with (1), we obtain that(2)(3)ya − zi (cid:2) 1Hm−1|(cid:7)|S ikk|S ik| − t + 1t=1=|kH|S ikHm−1(cid:2) k,(cid:7)a∈S ikimplying that the constraints of the dual linear program are always satisfied. The last inequality follows since, obviously,|S ik| (cid:2) m − 1.Now, denote by OPT the optimal objective value of the integer linear program. By duality, we have that any feasiblesolution to the dual of its linear programming relaxation has objective value at most OPT. Hence,Hm−1 · OPT (cid:3) Hm−1(cid:7)=(cid:10) (cid:7)def(a) · ya −(cid:7)zi(cid:11)a∈ A\{a∗}def(a) · p(cid:3)(cid:4)a, def(a)(cid:7)i∈N−(cid:7)(cid:3)(cid:3)(cid:4)a, def(a)p(cid:4)(cid:4)(cid:3)a, ji(a)− pa∈ A\{a∗}(cid:7)(cid:7)=i∈Na∈T i(cid:4)(cid:3)a, ji(a).pi∈Na∈T iThe theorem follows since the last expression is equal to the total cost of the sets picked at all steps of the algorithm andclearly upper-bounds the cost of the final solution. (cid:2)3.2. An LP-based algorithm∗without explicitly providing a way to push aThe analysis of the greedy algorithm suggests an LP-based algorithm for approximating the Dodgson score of an alter-becomes thenative aCondorcet winner. This algorithm uses the same LP relaxation of the Dodgson score that was used in the analysis of thegreedy algorithm. The algorithm computes the optimal objective value, and returns this value multiplied by Hm−1 as a score. The idea that the relaxation of the ILP for the Dodgson score induces a rule that is similar to Dodgsonof the alternative ais not new (see, e.g., [30]).upwards in the preference of some agents so that a∗∗∗For completeness, we reformulate the LP in a more detailed form that takes the preference profile as a parameter aswell; this shall be useful in the following section, where we discuss the monotonicity properties of the algorithm. Given aprofile R = R N with a set of agents N and a set of m alternatives A, we denote by ri(R) the rank of alternative ain thepreference of agent i. We use the notation def(a, R) for the deficit of aagainst an alternative a in the profile R. Recall thatalternatives a ∈ A \ {ain place ri(R), wedenote by S i(R) the subcollection that consists of the sets S ik(R) contains thelive alternatives that appear in positions ri(R) − k to ri(R) − 1 in the preference of agent i. We denote by S(R) the unionof the subcollections S i(R) for i ∈ N.∗} such that def(a, R) > 0 are said to be alive. For every agent i ∈ N that ranks ak(R) for k = 1, . . . , ri(R) − 1, where the set S i∗∗∗The LP-based algorithm uses the following LP relaxation of the Dodgson score of alternative ain the profile R:∗(cid:7)ri (R)−1(cid:7)minimizek=1subject to ∀a ∈ A \i∈Nk · xS i(cid:5)(cid:2)a∗,k(R)(cid:7)(cid:7)xS (cid:3) def(a, R)∀i ∈ N,(cid:7)S∈S i(R): a∈Si∈NxS (cid:2) 1S∈S i(R)∀S ∈ S(R),0 (cid:2) xS (cid:2) 1.I. Caragiannis et al. / Artificial Intelligence 187–188 (2012) 31–5139We remark that, as it is the case with the greedy algorithm, if ais initially a Condorcet winner then the algorithmcalculates a score of zero. In any other case, we can easily show that the score returned by the algorithm is betweenand its Dodgson score multiplied by Hm−1. Indeed, by the analysis in the proof ofthe Dodgson score of alternative aTheorem 3.1 (see the last derivation), we know that the score returned by the greedy algorithm and, consequently, theis not higher than the optimal objective value of the LP relaxation multiplied by Hm−1. Furthermore,Dodgson score of asince the optimal objective value of the LP relaxation is a lower bound on the Dodgson score of a, the LP-based algorithmreturns a score that is an Hm−1-approximation of the Dodgson score. This is formalized in the following theorem.∗∗∗∗Theorem 3.2. For any input ascore of a∗.∗and R N with m alternatives, the LP-based algorithm returns an Hm−1-approximation of the Dodgson4. Interlude: on the desirability of approximation algorithms as voting rulesSo far we have looked at Dodgson approximations through the algorithmic lens. We now wish to briefly explore thesocial choice point of view. We argue that a Dodgson approximation is equivalent to a new voting rule, which is guaranteedto elect an alternative that is not far from being a Condorcet winner. In other words, a perfectly sensible definition of a“socially good” winner, given the circumstances, is simply the alternative chosen by the approximation algorithm. Note thatthe approximation algorithm can be designed to satisfy the Condorcet criterion, i.e., always elect a Condorcet winner if oneexists. Since the Dodgson score of a Condorcet winner is zero, choosing such a winner when one exists has no impact onthe approximation ratio.Our approximation algorithms should therefore be compared according to two conceptually different, but not orthogonal,dimensions: their algorithmic properties and their social choice properties. From an algorithmic point of view, the greedyalgorithm gives us a better sense of the combinatorial structure of the problem. In the sequel we suggest, however, that theLP-based algorithm has some desirable properties from the social choice point of view.In most algorithmic mechanism design settings [34], such as combinatorial auctions or scheduling, one usually seeksapproximation algorithms that are truthful, i.e., the agents cannot benefit by lying. However, the well-known Gibbard–Satterthwaite Theorem [22,42] precludes voting rules that are both truthful and reasonable, in a sense. Therefore, otherdesiderata are looked for in voting rules. (Of course, other social choice properties are interesting to look at in their ownright, independent of the Gibbard–Satterthwaite Theorem).Let us reiterate that both the greedy algorithm and the LP-based algorithm satisfy the Condorcet property. Let us nowconsider the monotonicity property, one of the major desiderata on the basis of which voting rules are compared. Manydifferent notions of monotonicity can be found in the literature; for our purposes, a (score-based) voting rule is scoremonotonic if and only if making an alternative more preferable in the rankings of some agent cannot worsen the score ofthe alternative, that is, increase it when a lower score is desirable (as in Dodgson), or decrease it when a higher score isdesirable. All prominent score-based voting rules (e.g., positional scoring rules, Copeland, Maximin) are score monotonic; itis straightforward to see that the Dodgson and Young rules are score monotonic as well.We first claim that our LP-based algorithm is score monotonic.Theorem 4.1. The LP-based algorithm is score monotonic.: oneProof. We will consider two different inputs to the LP-based algorithm for computing the score of an alternative awith a profile R = R N and another with a profile ¯R that is obtained from R by pushing alternative aupwards in thepreferences of some of the agents (abusing notation somewhat, we will sometimes let R, respectively ¯R, denote the inputhaving profile R, respectively ¯R). Given an optimal solution x for R, we will construct a feasible solution ¯x for ¯R that doesnot exceed x. This is a sufficient condition for the assertion of the theorem.By the definition of profile ¯R, it holds that ri(R) (cid:3) ri( ¯R) for every i ∈ N. We partition the subcollection S i(R) into the∗∗following two disjoint subcollections:(cid:2)S i,1(R) =k(R): k = ri(R) − ri( ¯R) + 1, . . . , ri(R) − 1S i(cid:5)andS i,2(R) =(cid:2)(cid:5)k(R): k = 1, . . . , ri(R) − ri( ¯R)S i.For every i ∈ N, there is a one-to-one and onto correspondence between the sets in S i( ¯R) and the sets in S i,1(R), where(R) of S i,1(R) and vice versa. The solutionk( ¯R) of S i( ¯R) corresponds to the set S ifor k ∈ {1, . . . , ri( ¯R)} the set S i¯x for the second input is constructed by simply settingk+ri (R)−ri ( ¯R)¯xS ik( ¯R)= xS ik+ri (R)−ri ( ¯R)(R)for i ∈ N and k ∈ {1, . . . , ri( ¯R) − 1}.40I. Caragiannis et al. / Artificial Intelligence 187–188 (2012) 31–51R1a4a3a2a1.....∗aR2a4a3a2a1b1b2b3∗a..R3a4b4b5b6b7b8∗a...R4a3b9b10b11b12∗a....R5a2b13b14b15∗a.....R6a1b16b17∗a......(a) Original profile.R1a4a3a2a1.....∗aR2a4a3a2a1b1b2b3∗a..Q 3a4b4b5b6∗ab7b8...Q 4a3b9b10∗ab11b12....Q 6a1∗ab16b17......Q 5a2b13∗ab14b15.....∗(b) Improvement of a.Fig. 2. The voting rule corresponding to the greedy algorithm is not score monotonic: an example.We will first prove that the solution ¯x is a feasible solution for ¯R. The definition of the ¯x-variables clearly implies thatthe second and third sets of constraints are satisfied (since the solution x is feasible). Also, the first set of constraints istrivially satisfied for each alternative a with def(a, ¯R) = 0. Assume now that alternative a has def(a, ¯R) > 0. Let eia be 1if agent i ranks alternative a above aa be 0. Then, it can be easily seen thata > 0. Hence, by the correspondence between the sets in S i( ¯R) and the sets in S i,1(R), itdef(a, R) = def(a, ¯R) +follows that for every set S ∈ S i( ¯R) that contains alternative a, its corresponding set in S i,1(R) also contains a. Using thisobservation and the definition of the solution ¯x, we obtain thatin R and below it in ¯R; otherwise let eii∈N ei(cid:6)∗(cid:7)(cid:7)(cid:7)(cid:7)i∈NS∈S i ( ¯R): a∈S¯xS ==i∈N(cid:7)S∈S i,1(R): a∈S(cid:10) (cid:7)i∈NS∈S i(R): a∈SxSxS −(cid:7)(cid:11)xS.(cid:6)Let α =S∈S i,2(R): a∈S xS . Observe that if eiaS∈S i,2(R): a∈S= 0, then no set S ∈ S i,2(R) contains a, thus α = 0. Otherwise, if ei= 1,aa. Using thisthen the second constraint in the LP implies that α (cid:2) 1. In other words, in any case α is upper-bounded by eiobservation and, additionally, the fact that def(a, R) = def(a, ¯R) +(cid:6)(cid:7)(cid:7)(cid:7)(cid:7)(cid:7)¯xS (cid:3)xS −eia(cid:3) def(a, R) −i∈N ei(cid:7)a, we conclude that= def(a, ¯R),eiai∈NS∈S i ( ¯R): a∈Si∈NS∈S i(R): a∈Si∈Ni∈Nas desired.It is not hard to see that the objective of ¯R is upper bounded by the objective of R. Indeed, the coefficient of each¯x-variable in the objective of ¯R is at most equal to the coefficient of the x-variable of the corresponding set in S i,1(R)k( ¯R) is multiplied by k in the objective of ¯R while the variable xS iin R, i.e., the variable ¯xS i(R) is multiplied byk + ri(R) − ri( ¯R) (cid:3) k in R. (cid:2)k+ri (R)−ri ( ¯R)In contrast, let us now consider the greedy algorithm. We design a preference profile and a push of athat demonstratethat the algorithm is not score monotonic. Agents 1 through 6 vote according to the profile R N given in Fig. 2(a). The(cid:10) = {a1, . . . , a4} andpositions marked by “.” are placeholders for the rest of the alternatives, in some arbitrary order. Let A(cid:10)(cid:10) = {b1, . . . , b17}. Notice that def(a) = 1 for all a ∈ AA. The optimal sequence of exchangesmoves aall the way to the top of the preferences of agent 2, with a cost of seven. The greedy algorithm, given thispreference profile, indeed chooses this sequence.and def(b) = 0 for all b ∈ A(cid:10)(cid:10)∗(cid:10)On the other hand, consider the profile (R1, R2, Q 3, Q 4, Q 5, Q 6) given in Fig. 2(b) (where the position of awas im-proved by two positions in the preferences of agents 3 through 6). First notice that the deficits have not changed compared∗to the profile R N . The greedy algorithm would in fact push ato the top of the preferences of agents 6, 5, 4, and 3 (in thisorder), with a total cost of ten. Note that the optimal solution still has a cost of seven. In conclusion, the greedy algorithmis not score monotonic while the LP-based algorithm is score monotonic.∗∗It should be mentioned that the following stronger notion of monotonicity is often considered in the literature: pushinga winning alternative in the preferences of the agents cannot harm it, that is, cannot make it lose the election. We saythat a voting rule that satisfies this property is monotonic. Interestingly, Dodgson itself is not monotonic [6,19], a fact thatis considered by many to be a serious flaw. However, this does not preclude the existence of an approximation algorithmfor the Dodgson score that is monotonic as a voting rule. Additionally, there are other prominent social choice propertiesthat are often considered, e.g., homogeneity: a voting rule is said to be homogeneous if duplicating the electorate does notchange the outcome of the election.The existence of algorithms that approximate the Dodgson score well and also satisfy additional social choice propertiesis addressed by Caragiannis et al. [7]. Among other results, Caragiannis et al. show that a monotonic approximation algo-rithm for the Dodgson score cannot have an approximation ratio smaller than 2, and complement this result by designingI. Caragiannis et al. / Artificial Intelligence 187–188 (2012) 31–5141a monotonic exponential-time 2-approximation algorithm. Building on the results in this paper, they are able to constructa monotonic polynomial-time O(log m)-approximation algorithm. We nevertheless feel that our more preliminary discus-sion of score monotonicity is worthwhile: in this setting approximation algorithms should also be compared by their socialchoice properties.With respect to our approximations, Caragiannis et al. provide the following results (see [7,43] for definitions of theproperties discussed below).Theorem 4.2. (See [7].) Any homogeneous Dodgson approximation has approximation ratio at least Ω(m log m).Theorem 4.3. (See [7].) Let V be a Dodgson approximation. If V satisfies combinativity or Smith consistency, then its approxima-tion ratio is at least Ω(nm). If V satisfies mutual majority consistency, invariant loss consistency, or independence of closes, then itsapproximation ratio is at least Ω(n).As a corollary, we get the following result for our Dodgson approximationsTheorem 4.4. Neither the greedy Dodgson approximation nor the linear programming Dodgson approximation rule satisfies homo-geneity, combinativity, Smith consistency, mutual majority consistency, invariant loss consistency, or independence of clones.Caragiannis et al. [7] do propose a homogeneous Dodgson approximation (that is also monotonic), but its approximationratio of O(m log m) is inevitably worse than the ratio provided by the Dodgson approximations considered above.5. Lower bounds for the Dodgson rule∗) is the Dodgson score of a distinguished alternative aMcCabe-Dansted [30] gives a polynomial-time reduction from the Minimum Dominating Set problem to the Dodgsonscore problem with the following property: given a graph G with k vertices, the reduction creates a preference profile∗)(cid:9),with n = Θ(k) agents and m = Θ(k4) alternatives, such that the size of the minimum dominating set of G is (cid:8)k∗ ∈ A. We observe that since the Minimum Dominatingwhere scD (aSet problem is known to be N P -hard to approximate to within logarithmic factors [40], it follows that the Dodgson scoreproblem is also hard to approximate to a factor of Ω(log m). Due to the relation of Minimum Dominating Set to Minimum− (cid:3)) ln mSet Cover, using an inapproximability result due to Feige [17], the explicit inapproximability bound can become ( 14under the assumption that problems in N P do not have quasi-polynomial-time algorithms. This means that our algorithmsare asymptotically optimal.−2 scD (a5.1. Inapproximability of the Dodgson scoreIn the following, we present an alternative and more natural reduction directly from Minimum Set Cover that allows usto obtain a better explicit inapproximability bound. This bound implies that our greedy algorithm is optimal up to a factorof 2.Theorem 5.1. There exists a β > 0 such that it is N P -hard to approximate the Dodgson score of a given alternative in an election with− (cid:3)) ln m-approximation for them alternatives to within a factor of β ln m. Furthermore, for any (cid:3) > 0, there is no polynomial-time ( 12O(log log k), where k is the input size.Dodgson score of a given alternative unless all problems in N P have algorithms running in time kProof. We use a reduction from Minimum Set Cover (defined formally below, when we present our reduction) and thefollowing well-known statements of its inapproximability.Theorem 5.2. (See Raz and Safra [40].) There exists a constant α > 0 such that, given an instance (U , S) of Minimum Set Cover with|U | = n and an integer K (cid:2) n, it is N P -hard to distinguish between the following two cases:• (U , S) has a cover of size at most K .• Any cover of (U , S) has size at least α K ln n.Theorem 5.3. (See Feige [17].) For any constant (cid:3) > 0, given an instance (U , S) of Minimum Set Cover with |U | = n and an integerK (cid:2) n, there is no polynomial-time algorithm that distinguishes between the following two cases:• (U , S) has a cover of size at most K , and• Any cover of (U , S) has size at least (1 − (cid:3))K ln n,unless N P ⊆ DTIME(n O (log log n)).42I. Caragiannis et al. / Artificial Intelligence 187–188 (2012) 31–51The known inapproximability results for the problems that we use in our proofs are better understood by consideringtheir relation to a generic NP-hard problem such as Satisfiability (see [44], Chapter 29). For example, what Theorem 5.2essentially states is that there exists a polynomial-time reduction which, on input an instance φ of Satisfiability, constructsan instance (U , S) of Minimum Set Cover with the following properties: if φ is satisfiable, (U , S) has a cover of size atmost K , and if φ is not satisfiable, any cover of (U , S) has size at least α K ln n. This reduction implies that it is NP-hard toapproximate Minimum Set Cover within a factor of α ln n. The interpretation of the remaining inapproximability results thatare used or proved in the paper is similar.Given an instance of Minimum Set Cover consisting of a set of n elements, a collection of sets over these elements andan integer K (cid:2) n, we construct a preference profile with m = (1 + ζ )n + (cid:15)αζ K n ln n(cid:16) + 1 alternatives and a specific alternative∗ain which we show that if we could distinguish in polynomial time between the following two cases:∗∗• a• ahas Dodgson score at most (1 + ζ )K n, andhas Dodgson score at least αζ K n ln n,then we could have distinguished between the two cases of Theorems 5.2 and 5.3 for the original Minimum Set Coverinstance, contradicting the above inapproximability statements. Here, α is the inapproximability constant in Theorem 5.2or 5.3 (in the latter α = 1 − (cid:3)), and ζ is an arbitrarily large positive constant. In this way, we obtain an inapproximabilitybound of αζ2 ln m − O(ln ln m), and hence the inapproxima-bility bound for Dodgson score can be expressed in terms of the number of alternatives m as stated in Theorem 5.1.1+ζ ln n. Since m = (1 + ζ )n + (cid:15)αζ K n ln n(cid:16) + 1, it holds that ln n (cid:3) 1We now present our reduction. Given an instance (U , S) of Minimum Set Cover consisting of a set U of n elements,a collection S of sets S1, S2, . . . , S|S| and an integer K (cid:2) n, we construct the following preference profile. There are thefollowing alternatives:• A set of n basic alternatives, each corresponding to an element of U . Abusing notation, we also call this set U .• A set Z of ζ n alternatives where ζ is a positive constant.• A set F of (cid:15)αζ K n ln n(cid:16) alternatives, where α is the constant from Theorem 5.2.• A specific alternative a∗.There are the following 2|S| + 1 agents:• A critical agent (cid:10)i for each set S i ∈ S.• An indifferent agent ri for each set S i ∈ S.• A special agent v.∗The preferences of the agents are defined as follows:• The special agent v∗ranks a∗positions in arbitrary order (i.e., a∗∗R v(U ∪ Z ∪ F )).in the first position of its preferences and the rest of the alternatives occupy the remaining• We construct the ranking of the indifferent agents as follows. Initialize S• The critical agent (cid:10)i ranks the basic alternatives corresponding to the elements of S i in the first positions of its prefer-∗, next the alternatives of F , and, in the last positions of its∗ence (in arbitrary order), next the alternatives of Z , next apreference, the basic alternatives corresponding to the elements in U \S i (i.e., S i R(cid:10)i(cid:10)2, . . . , SS|S|. For each element u of U , choose arbitrarily j ∈ {1, 2, . . . , |S|} such that u ∈ SS(cid:10)ranks the basic alternatives corresponding to the elements in U \ Sthe alternatives of F , then a(cid:10)← S2, . . . , S|S| ←(cid:10)\ {u}. Denote byj(cid:10)|S| resulting after each u ∈ U has been processed in this way. The indifferent agent ri(cid:10)i in the first positions of its preference, followed, then the alternatives of Z , and then in the last positions of its preference the basic∗F R(cid:10)i(U \S i)).(cid:10)← S1, S2(cid:10)← SjZ R(cid:10)iR(cid:10)i(cid:10)(cid:10)|S| as S1(cid:10)j and set Sthe collection S(cid:10)2, . . . , S(cid:10)1, S(cid:10)1, Sa∗(cid:10)alternatives corresponding to elements in S(cid:10)i (if any)—i.e., (U \ Si)RriF RriaRriZ RriS(cid:10)i .∗∗Clearly, ais preferred to any alternative in Z by the special agent and by the |S| indifferent agents, i.e., by a majorityis preferred to any alternative in F by the special agent and by the |S| critical agents. Now, for eachof agents. Similarly, aelement of U , denote by f u the number of sets in S that contain u. Then, ais preferred to u by the special agent, by the|S| − f u critical agents corresponding to sets in S that do not contain u, and by the f u − 1 indifferent agents correspondingto sets in S(cid:10)has a deficit of exactly 1 with respect to each of thealternatives in U .that contain u (i.e., by |S| agents in total). Hence, a∗∗Theorem 5.1 follows by the next two lemmas that give bounds on the Dodgson score of alternative ain the two casesof interest: when (U , S) has a cover of size at most K (Lemma 5.4) and when any cover of (U , S) has size at least α K ln n(Lemma 5.5).∗Lemma 5.4. If (U , S) has a cover of size K , then a∗has Dodgson score at most (1 + ζ )K n.I. Caragiannis et al. / Artificial Intelligence 187–188 (2012) 31–5143∗Proof. Let H ⊆ S be a cover for (U , S) with |H| = K . By the definition of a cover, H covers all elements of U . Hence, bywill decrease its deficit withpushing arespect to each of the basic alternatives by 1, and hence it will become a Condorcet winner. The total number of positionsato the first position in the preference of the critical agent (cid:10)i such that S i ∈ H , arises is at most |H| · (| Z | + n) = (1 + ζ )nK . (cid:2)∗∗Lemma 5.5. If every cover of (U , S) has size at least α K ln n, then a∗has Dodgson score at least αζ K n ln n.Proof. We first assume that the minimum number of positions abecome a Condorcet winner includes raising a∗ato beat the basic alternatives. Its Dodgson score is thus at least |F | + n (cid:3) αζ K n ln n.rises |F | positions in the preference of ri in order to reach position |U \Shas to rise in order to beat the basic alternatives andby at least |F | positions in the ranking of some indifferent agent ri . Hence,| + 1 and at least n additional positions in order(cid:10)i∗Now, assume that the minimum number of positions ahas to rise in order to beat the basic alternatives does notby at least |F | positions in the ranking of some indifferent agent. We will show that if the Dodgson scoreis less than αζ K n ln n, then there exists a cover of (U , S) of size less than α K ln n, contradicting the assumption of∗∗∗include raising aof athe lemma.∗Let H be the set of critical agents in whose preferences ais pushed at least | Z | positions higher. Over all the preferencerises a total of |H| · | Z | positions in order to reach position |S i| + 1 in each list, plus at least nlists of all the agents in H , aadditional positions in order to decrease by 1 its deficit with respect to each of the alternatives in U . So, recalling | Z | = ζ n,∗ζ <aα K ln n. The proof is completed by observing that the union of the sets S i for each critical agent (cid:10)i belonging to H containsall the basic alternatives, i.e., H corresponds to a cover for (U , S) of size less than α K ln n. (cid:2)rises at least ζ |H|n + n positions. Denoting the Dodgson score of a∗), we thus have |H| (cid:2) 1ζ n scD (aby scD (a∗) − 1∗∗∗This completes the proof of Theorem 5.1. (cid:2)5.2. Inapproximability of Dodgson rankingsA question related to the approximability of Dodgson scores is the approximability of the Dodgson ranking, that is, theranking of alternatives given by ordering them by nondecreasing Dodgson score. To the best of our knowledge, no rankaggregation function, which maps preference profiles to rankings of the alternatives, is known to provably produce rankingsthat are close to the Dodgson ranking [38,39,27–29] (see the survey of related work in Section 1).Our next result establishes that efficient approximation algorithms for Dodgson ranking are unlikely to exist unlessP = N P . It does so by proving that the problem of distinguishing between whether a given alternative is the uniquem) positions is N P -hard. This result provides a complexity-theoretic explanation forDodgson winner or in the last O (the sharp discrepancies observed in the Social Choice Theory literature when comparing Dodgson elections with simpler,efficiently computable, voting rules.√Theorem 5.6. Given a preference profile with m alternatives and an alternative awinner or has rank at least m − 6m in any Dodgson ranking.√∗, it is N P -hard to decide whether a∗is a DodgsonProof. We use a reduction from Minimum Vertex Cover in 3-regular graphs, and exploit a result concerning its inapprox-imability that follows from the work of Berman and Karpinski [3]. Our approach is similar to the proof of Theorem 5.1,albeit considerably more involved. We use the following result.Theorem 5.7. (See Berman and Karpinski [3], see also [25].) Given a 3-regular graph G with n = 22t nodes for some integer t > 0 andan integer K in [n/2, n − 6], it is N P -hard to distinguish between the following two cases:• G has a vertex cover of size at most K .• Any vertex cover of G has size at least K + 6.Given an instance of Minimum Vertex Cover consisting of a 3-regular graph G with n = 22t nodes v 0, v 1, . . . , vn−1 andan integer K ∈ [n/2, n − 6], we construct in polynomial time a preference profile in which if we could distinguish whether aparticular alternative is a Dodgson winner or not very far from the last position in any Dodgson ranking, then we could alsodistinguish between the two cases mentioned in Theorem 5.7 for the original Minimum Vertex Cover instance. See page 46for an example of the construction. The Dodgson election has the following sets of alternatives:• A special alternative a• A set F of 4K n/11 + 3n/2 alternatives. These alternatives are partitioned into n disjoint blocks F 0, F 1, . . . , Fn−1 so that.∗each block contains either (cid:15)4K /11 + 3/2(cid:16) or (cid:8)4K /11 + 3/2(cid:9) alternatives.• A set A of n alternatives a0, a1, . . . , an−1.44I. Caragiannis et al. / Artificial Intelligence 187–188 (2012) 31–51• An alternative u j for each edge e j of G. Let U be the set of these 3n/2 alternatives. We denote by S i the set of thethree alternatives of U that correspond to the edges of G which are incident to node v i .For each node v i of G, there are two agents: one left agent (cid:10)i and one right agent ri . The preferences of the left agent(cid:10)i are as follows:• The three alternatives of S i are ranked by agent (cid:10)i in the first three positions of its preference (in arbitrary order).• From position 4 to position 4n/11 + 3, agent (cid:10)i ranks the alternatives ai, a(i+1) mod n, . . . , a(i+4n/11−1) mod n in this order.• In position 4n/11 + 4, agent (cid:10)i ranks a• From position 4n/11 + 5 to position 4K n/11 + 41n/22 + 4, agent (cid:10)i ranks the alternatives of F in the following order.The alternatives of F i are ranked in positions from 4n/11 + 5 to 4n/11 + 4 + |F i| (in arbitrary order). Next, agent (cid:10)iranks the alternatives of sets F 0, . . . , F i−1, F i+1, . . . , Fn−1 in this order (the relative order of the alternatives of the sameblock is arbitrary).• From position 4K n/11 + 41n/22 + 5 to position 4K n/11 + 5n/2 + 4, agent (cid:10)i ranks the alternatives a(i+4n/11) mod n,∗.a(i+4n/11+1) mod n, . . . , a(i−1) mod n in this order.• In the last 3n/2 − 3 positions, agent (cid:10)i ranks the alternatives of U \ S i (in arbitrary order).The preferences of the right agent ri are as follows:• In the first 3n/2 − 3 positions, agent ri ranks the alternatives of U \ S i in reverse relative order to the order (cid:10)i ranksthem.• From position 3n/2 − 2 to position 4K n/11 + 3n − |F i| − 3, agent ri ranks the alternatives of the blocks Fn−1, Fn−2, . . . ,F i+1, F i−1, . . . , F 0 in this order so that the alternatives of block F j are ranked in reverse relative order to the order (cid:10)iranks them.• From position 4K n/11 + 3n − |F i| − 2 to position 4K n/11 + 40n/11 − |F i| − 5, agent ri ranks the alternativesa(n−i−1) mod n, a(n−i−2) mod n, . . . , a(4n/11−i+2) mod n in this order.• In position 4K n/11 + 40n/11 − |F i| − 4, agent ri ranks a.• From position 4K n/11 + 40n/11 − |F i| − 3 to position 4K n/11 + 40n/11 − 4, agent ri ranks the alternatives of F i in∗• From position 4K n/11 + 40n/11 − 3 to position 4K n/11 + 4n − 2, agent ri ranks the alternatives a(4n/11−i+1) mod n,reverse relative order to the order (cid:10)i ranks them.a(4n/11−i) mod n, . . . , a(n−i) mod n in this order.• The three alternatives of S i are ranked in the last three positions in the preference of agent ri , in reverse relative orderto the order (cid:10)i ranks them.∗∗∗We observe that abeats all alternatives but the alternatives of U . In particular, aby n + 1 agents. Specifically, aagent ri . Also, the alternative ai is ranked below aand by the 4n/11 + 2 right agents r(i+7n/11−1) mod n, r(i+7n/11) mod n, . . . , ri . Hence, asince it is ranked above each of them by n + 2 agents. Also, ae j of G by the left agents (cid:10)i and (cid:10)iedge e j in G. Hence, ais preferred to each alternative of Fis ranked above an alternative belonging to the block F i by the n left agents and by the rightby the 7n/11 left agents (cid:10)(i+1) mod n, (cid:10)(i+2) mod n, . . . , (cid:10)(i+7n/11−1) mod nbeats all alternatives in set A as wellis ranked above the alternative u j corresponding to the edgeso that nodes v i and v i(cid:10) are the endpoints ofand by all right agents besides ri and rihas a deficit of 1 with respect to each of the alternatives in U .∗∗∗∗(cid:10)(cid:10)We also observe that the alternatives in F beat each alternative in A. Note that each agent other than ri who prefers ato an alternative in A also prefers an alternative in block F i to the alternative in A. Hence, each alternative of F beats eachalternative of A since it is ranked above it by n + 1 agents. Furthermore, similarly to a, each alternative in F is preferred to(cid:10)of F by agent (cid:10)i ,each alternative of U by n agents. Also, when an alternative f of F is ranked above another alternative fis ranked above f by agent ri . Hence, an alternative of F has a deficit of 1 with respect to U and each other alternativefin F , and a deficit of 2 with respect to a∗∗.(cid:10)∗(cid:10)Furthermore, observe that each alternative in A is ranked above the alternative u j corresponding to the edge e j of G bythe left agents (cid:10)i and (cid:10)iand by all right agents besides ri and riso that nodes v i and v i(cid:10) are the endpoints of edge e j inG, i.e., by n agents. Also, when an alternative a of A is preferred to another alternative ais preferredto a by agent ri . Hence, an alternative in A has a deficit of 1 with respect to each alternative in U and each remaining. This immediatelyalternative in A, a deficit of 2 with respect to each alternative in F , and a deficit of 3 with respect to ayields that the Dodgson score of each alternative in A is at least 8K n/11 + 11n/2 + 2.of A by agent (cid:10)i , a∗(cid:10)(cid:10)(cid:10)Similarly, when an alternative u of U is preferred to another alternative uis preferred to u byagent ri . Hence, an alternative in U has a deficit of 1 with respect to each of the alternatives in A and F , each other. This immediately yields that the Dodgson score of each alternative in U is at least 4K n/11 + 4n.alternative in U , and aA summary of the deficit of each alternative with respect to any other alternative is presented in Table 1.∗of U by agent (cid:10)i , u(cid:10)(cid:10)The next lemma gives upper and lower bounds on the Dodgson score of the alternatives in F .Lemma 5.8. Each alternative in F has Dodgson score between 4K n/11 + 3n + 1 and 4K n/11 + 37n/11 + 2K /11 + 3/4.I. Caragiannis et al. / Artificial Intelligence 187–188 (2012) 31–5145Table 1The deficit of each alternative (rows) against any other alternative (columns).∗aAny alt. in FAny alt. in AAny alt. in U∗a–231Any alt. in FAny alt. in AAny alt. in U012100111111Proof. Since each alternative in F has a deficit of 1 with respect to each alternative in U and each other alternative in F ,and a deficit of 2 with respect to a, its Dodgson score is at least |U | + |F | − 1 + 2 = 4K n/11 + 3n + 1.is at distance at most∗(cid:12)Now, consider an alternative f belonging to block F i . f|F i| + 12(cid:15)4K /11 + 3/2(cid:16) + 12|F i| − 12+ 1(cid:2)(cid:2)(cid:13)(cid:2) 2K /11 + 7/4∗(cid:10)(cid:10)be the subset of alternatives in F that are higher than fin the preferences of either the left agent (cid:10)i or the right agent ri . Hence, by raising f at most 2K /11 + 7/4 positions(cid:10) (cid:11)= i and∗. By pushing f to the first position(cid:10)| positions in addition to the 2K /11 + 7/4 positions mentioned above),, as well as with respect to the three alternatives of. In the preferences of ri, f is ranked(cid:10) − { f }. Hence, by pushing f to the first position(cid:10)| + 3n − 4 additional positions),f decreases its(cid:10) − { f } as well the alternatives of U \S i(cid:10) in the first 3n/2 − 3 positions infrom ain the preferences of either (cid:10)i or ri , its deficit with respect to alet Fin the preferences of agent (cid:10)if decreases its deficit by 1 with respect to each alternative of FS i(cid:10) in the first three positions in the preferences of (cid:10)ihigher than the alternatives in Fin the preferences of agent rideficit by 1 with respect to each alternative of F \Fthe preferences of ri . Hence, by pushing 4K n/11 + 37n/11 + 2K /11 + 3/4 positions, f becomes a Condorcet winner. (cid:2)and lower than the alternatives in F \F(cid:10) − { f }| + 3n/2 − 3 = 4K n/11 − |Fdecreases by 1. Consider a left agent (cid:10)i(cid:10). Now, consider the right agent riin the preferences of (cid:10)i(i.e., 4n/11 + 3 + |F(i.e., |F \Fwith iand a∗(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)The next two lemmas give bounds on the Dodgson score of alternative ain the two cases of interest: when G has avertex cover of size at most K (Lemma 5.9), and when any vertex cover of G has size at least K + 6 (Lemma 5.10).∗Lemma 5.9. If G has a vertex cover of size at most K , then the Dodgson score of a∗is less than 4K n/11 + 3n.(cid:14)Proof. Let H ⊆ V be a vertex cover of G with |H| = K . By the definition of the vertex cover, H covers all edges of G andi:v i ∈H S i = U . Hence, by pushing ato the first position in the preferences of each of the K left agents (cid:10)ithis implies thatsuch that v i ∈ H , adecreases it deficit with respect to each of the alternatives in U by 1, and becomes a Condorcet winner.The total number of positions arises is K (4n/11 + 3) < 4K n/11 + 3n. The last inequality is true since K < n. (cid:2)∗∗∗Lemma 5.10. If any vertex cover of G has size at least K + 6, then the Dodgson score of a3/4.∗is larger than 4K n/11 + 37n/11 + 2K /11 +beat the alternatives of U and become aProof. First assume that the minimum sequence of exchanges that makes a∗to one of the first 3n/2 − 3 positions in the preferences of some right agent ri .Condorcet winner includes pushing aby agent ri .Certainly, not all alternatives of U are beaten in this way since the three alternatives of S i are ranked below aSo, in order to beat the remaining 3 alternatives of S i , ahas to either be pushed to one of the first three positions of a(cid:10) (cid:11)= i. Hence, aleft agent or to one of the first 3n/2 − 3 positions of another right agent rimust be first pushed toposition 3n/2 − 2 of agent ri (i.e., |F \F i| + 7n/11 − 2 positions), to position 4 of a left agent (4n/11 additional positions) or(|F \F i(cid:10) | + 7n/11 − 2 additional positions), and then rise at least 3n/2 additional positionsto position 3n/2 − 2 of agent riin order to beat all alternatives of U . In total, arises at leastwith i∗∗∗∗(cid:10)(cid:10)∗(cid:5)+ 3n/24n/11, |F \F i(cid:10) | + 7n/11 − 2(cid:2)|F \F i| + 7n/11 − 2 + min(cid:3) |F | − |F i| + 5n/2 − 2(cid:3) 4K n/11 + 4n − (cid:15)4K /11 + 3/2(cid:16) − 2(cid:3) 4K n/11 + 4n − 4K /11 − 9/2= 4K n/11 + 37n/11 + n/11 + 6n/11 − 4K /11 − 9/2(cid:3) 4K n/11 + 37n/11 + 22/11 + 6(K + 6)/11 − 4K /11 − 9/2> 4K n/11 + 37n/11 + 2K /11 + 3/4positions. The fourth inequality holds since n (cid:3) 22 and n (cid:3) K + 6.46I. Caragiannis et al. / Artificial Intelligence 187–188 (2012) 31–51v 0e2v 3e7v 6e12v 9e16v 12e20e25v 15v 18e0e3e4v 1v 4e8e9e13e17e21e22e26e29v 7v 10v 13v 16e30v 19v 21e1e5e10e14e18e23e27e31e32v 2e6v 5e11v 8e15v 11e19e24v 14v 17e28v 20Fig. 3. A 3-regular graph with 22 nodes.Now, assume that the minimum sequence of exchanges for making ato any of the first 3n/2 − 3 positions of any right agent. We will show that if a37n/11 + 2K /11 + 3/4, then G has a vertex cover of size less than K + 6, contradicting the assumption of the lemma.∗∗a Condorcet winner does not include raising ahas Dodgson score at most 4K n/11 +∗∗Let H be the set of left agents where arises to one of the first three positions in order to beat all the alternativesrises 4|H|n/11 positions in order to reach position 4 in the preferences of each of the agents in Hof U . In total, aplus at least 3n/2 additional positions in order to decrease its deficit with respect to the alternatives in U by at least 1,∗), we have |H| (cid:2)i.e., at least 4|H|n/11 + 3n/2 positions in total. Hence, by denoting the Dodgson score of a114n (scD (aSincei:(cid:10)i ∈H S i = U , the set of nodes of G consisting of nodes v i such that agent (cid:10)i belongs to H is a vertex cover of G∗) − 3n/2).(cid:14)by scD (a∗of size |H|. Assuming that the Dodgson score of ais at most 4K n/11 + 37n/11 + 2K /11 + 3/4, we have∗∗(cid:4)∗(cid:3)a(cid:4)− 3n/2(cid:3)scD|H| (cid:2) 114n(cid:2) 114n< K + 6,(4K n/11 + 41n/22 + 2K /11 + 3/4)where the last inequality follows since K (cid:2) n − 6. (cid:2)By Lemmas 5.8, 5.9, and 5.10, we obtain that if G has a vertex cover of size at most K , then ais the unique Dodgsonwinner, while if every vertex cover of G has size at least K + 6, then ais below all alternatives in F in any Dodgsonranking. Denote by m the total number of alternatives and recall that m = |F | + | A| + |U | + 1 = 4K n/11 + 4n + 1. Then, therank of ain the second case is at least∗∗∗(cid:15)|F | + 1 = 4K n/11 + 3n/2 + 1 = m − 5n/2 = m −25n2/4(cid:16)(cid:16)(cid:3) m −25nK /2 (cid:3) m − 64K n/11 + 4n + 1 = m − 6√m,where the first inequality follows since K (cid:3) n/2. By Theorem 5.7, we obtain the desired result. (cid:2)An example. We present an example of the construction in the proof of Theorem 5.6. Consider an instance of MinimumVertex Cover with the 22-node 3-regular graph of Fig. 3, and K = 12.The corresponding preference profile has 185 alternatives and 44 agents. In particular, the set F has 129 alternativesf 0, f 1, . . . , f 128, which are partitioned into 22 blocks as follows. Block F 0 contains the six alternatives f 0, f 1, . . . , f 5, blockF 1 contains the six alternatives f 6, . . . , f 11, . . . , block F 18 contains the six alternatives f 108, . . . , f 113, block F 19 containsthe five alternatives f 114, . . . , f 118, . . . , and block F 21 contains the alternatives f 124, . . . , f 128. The set A has 22 alternativesa0, . . . , a21. The set U has 33 alternatives u0, . . . , u32, one alternative for each edge of the graph. The agents are partitionedinto 22 left agents and 22 right agents. In order to compute the preferences of an agent, say agent (cid:10)17, we first computethe set S17, which contains the alternatives corresponding to the edges incident to node v 17 of the graph, i.e., S17 ={u24, u27, u28}. Now, the preferences of agent (cid:10)17 are:S17 R(cid:10)17R(cid:10)17a17 R(cid:10)17F 18 R(cid:10)17 · · · R(cid:10)17a18 R(cid:10)17 · · · R(cid:10)17F 21 R(cid:10)17a1 R(cid:10)17a3 R(cid:10)17 · · · R(cid:10)17a2 R(cid:10)17R(cid:10)17aa16 R(cid:10)17F 17 R(cid:10)17(U \ S17).∗F 0 R(cid:10)17 · · · F 16Similarly, the preferences of agent r17 are:I. Caragiannis et al. / Artificial Intelligence 187–188 (2012) 31–5147←U \ S17)R(cid:10)17(a4 R(cid:10)17←F 21 R(cid:10)17a3 R(cid:10)17 · · · R(cid:10)17←←F 18 R(cid:10)17F 20 R(cid:10)17 · · · R(cid:10)17←∗F 17 a16 R(cid:10)17R(cid:10)17←F 16 R(cid:10)17 · · · R(cid:10)17←a5 R(cid:10)17S17,aa15 R(cid:10)17←F 0 R(cid:10)17where the symbol ← on top of a set of alternatives is used to denote that their order in the preferences of r17 is the reverseof the order (cid:10)17 ranks them.6. Inapproximability of Young scores and rankingsRecall that the Young score of a given alternative a∗ ∈ A is the size of the largest subset of agents for which a∗is aCondorcet winner.It is straightforward to obtain a simple ILP for the Young score problem. As before, let a∗ ∈ A be the alternative whoseYoung score we wish to compute. Let the variables of the program be xi ∈ {0, 1} for all i ∈ N; xi = 1 if and only if agent i∗}, which depend on the∈ {−1, 1} for all i ∈ N and a ∈ A \ {ais included in the subset of agents for a∗given preference profile; eihigher than a. The ILP that computes the Young score of aais given by:. Define constants eia∗= 1 if and only if agent i ranks a∗maximize(cid:7)xisubject toi∈N∀a ∈ A \(cid:5)∗(cid:2)a,(cid:7)∀i ∈ N,i∈Nxi ∈ {0, 1}.xieia(cid:3) 1(4)The ILP (4) for the Young score is seemingly simpler than the one for the Dodgson score. This might seem to indicatethat the problem can be easily approximated by similar techniques. Therefore, the following result is quite surprising.Theorem 6.1. It is N P -hard to approximate the Young score by any factor.Proof. This result becomes more self-evident when we notice that the Young score has the rare property of being non-monotonic as an optimization problem, in the following sense: given a subset of agents that make aa Condorcet winner,it is not necessarily the case that a smaller subset of the agents would satisfy the same property. This stands in contrastto many approximable optimization problems, in which a solution that is worse than an optimal solution is also a validsolution. Consider the Set Cover problem, for instance: if one adds more subsets to a valid cover, one obtains a valid cover.a Condorcet winner, introducing moreThe same goes for the Dodgson score problem: if a sequence of exchanges makes aexchanges on top of the existing ones would not undo this fact.∗∗In order to prove the inapproximability of the Young score, we define the following problem.Nonempty SubsetInstance: An alternative aQuestion: Is there a nonempty subset of agents C ⊆ N, C (cid:11)= ∅, for which a, and a preference profile R N ∈ L N .∗∗is a Condorcet winner?To prove Theorem 6.1, it is sufficient to prove that Nonempty Subset is N P -hard. Indeed, this implies that it is N P -hardto distinguish whether the Young score of a given alternative is zero or greater than zero, which directly entails that thescore cannot be approximated.Lemma 6.2. Nonempty Subset is N P -complete.Proof. The problem is clearly in N P ; a witness is given by a nonempty set of agents for which ais a Condorcet winner.In order to show N P -hardness, we present a polynomial-time reduction from the N P -hard Exact Cover by 3-Sets (X3C)problem [20] to our problem. An instance of the X3C problem includes a finite set of elements U , |U | = n (where n isdivisible by 3), and a collection S of 3-element subsets of U , S = {S1, . . . , Sk}, such that for every i, 1 (cid:2) i (cid:2) k, S i ⊆ U and|S i| = 3. The question is whether the collection S contains an exact cover for U , i.e., a subcollection S ∗ ⊆ S of size n/3 suchthat every element of U occurs in exactly one subset in S.∗We next give the details of the reduction from X3C to Nonempty Subset. Given an instance of X3C, defined by the set Uand a collection of 3-element sets S, we construct the following instance of Nonempty Subset.Define the set of alternatives as A = U ∪ {a} ∪ {a∗}. Let the set of agents be N = N(cid:10) ∪ N(cid:10)(cid:10), where N(cid:10)(cid:10)is composed of k agents, corresponding to the k subsets in S, such that for all i ∈ Nas follows. The set Nthe alternatives in U \ S i to ais composed of n3∗− 1 agents who prefer a to a, and prefers a∗to all the alternatives in S i ∪ {a} (i.e., (U \ S i) R i a∗and ato U (i.e., for all i ∈ N, aR iaR i U ).(cid:10)(cid:10)∗∗(cid:10)(cid:10)and N(cid:10)are defined, agent i prefers(cid:10)(cid:10)R i (S i ∪ {a})). Subset N∗48I. Caragiannis et al. / Artificial Intelligence 187–188 (2012) 31–51We next show that there is an exact cover in the given instance if and only if there is nonempty subset of agents foris a Condorcet winner in the constructed instance.∗which aSufficiency: Let S∗subsets S i ∈ S∗exists exactly one agent in N∗in Nprefer a(cid:10)(cid:10)It remains to show that a(cid:10)(cid:10)− 1 agents in Nare only n3∗∗. We show that abe an exact cover by 3-sets of U , and let Nis a Condorcet winner for C = Nto b and n3∗that prefers a∗ ⊆ N(cid:10)∗ ∪ N∗− 1 agents in Nbe the subset of agents corresponding to the n3. Since S∗(cid:10)(cid:10)is an exact cover, for all b ∈ U there− 1 agentsthat prefer b to a. In addition, all n3∗∗∗to b. Therefore, abeats b in a pairwise election.beats a in a pairwise election. This is true since all nwho prefer a to a. It follows that ais a Condorcet winner for N∗∗3 agents in N∗∗ ∪ Nprefer a(cid:10)(cid:10).∗to a, and thereNecessity: Assume the given instance of X3C has no exact cover. We have to show that there is no subset of agents forwhich ais a Condorcet winner. Let C ⊆ N, C (cid:11)= ∅, and let N. We distinguish among three cases.(cid:10)∗∗| = 0. It must hold that C ∩ NCase 1: |N∗prefer a to a.(cid:10)(cid:10) (cid:11)= ∅. In this case, a∗ = C ∩ N∗loses to a in a pairwise election, since all the agents in N(cid:10)(cid:10)Case 2: 0 < |N∗| (cid:2) nthat is ranked higher than a∗| + 1 agents from N|N∗| agents, and higher than a|N∗| > nCase 3: |N∗3 . Since there is no exact cover, the corresponding sets S i cannot cover U . Thus there exists b ∈ Uto beat b in a pairwise election, C must include at least(cid:10)(cid:10)byin a pairwise election (since a is ranked lower than a. However, this means that a beats aby all agents in N. In order for a∗∗∗∗∗by at least |N3 . Let us award each alternative b ∈ A \ {a∗| + 1 agents). It follows that a∗∗∗∗} a point for each agent that ranks it above a, and subtract a∗}, counted. ais a Condorcet winner only if for every subset B ⊆ A of alternatives, the totalis a Condorcet winner if and only if the score of every b ∈ A \ {a∗is not a Condorcet winner for C .point for each agent that ranks it below a∗this way, is negative. This implies that ascore of the alternatives in B is at most −|B|.We shall calculate the total score of the alternatives in U from the agents in N. Thus, every agent in N∗, we have that the total score of U from N∗. Every agent in N∗to 3contributes (n − 3) − 3 = n − 6 points∗|(n − 6). By∗prefers ais |N∗∗alternatives in U and prefers n − 3 alternatives in U to ato the total score of U . Summing over all the agents in N|N∗| > n3 , we have that∗|N∗|(n − 6) (cid:3)(cid:10)(cid:10)(cid:11)(cid:11)− 1+ 2(n − 6) =(cid:11)− 1n − 6.(cid:10)n3n3Recall that every agent in Nsubtract ( n3|U | = n > 6,3 a∗can only− 1)n from the total score of U . We conclude that the total score of U is at least −6. Since we can assume thatto all alternatives in U . However, since |N− 1, agents from Nprefers a(cid:10)(cid:10)| = n3(cid:10)(cid:10)(cid:10)(cid:10)∗cannot beat all the alternatives in U in pairwise elections. (cid:2)This concludes the proof of Theorem 6.1. (cid:2)A short discussion is in order. Theorem 6.1 states that the Young score cannot be efficiently approximated to any factor.The proof shows that, in fact, unless P = N P it is impossible to efficiently distinguish between a zero and a nonzero score.However, the proof actually shows more: it constructs a family of instances, where it is hard to distinguish between a scoreof zero and almost 2m/3. Now, if one looks at an alternative formulation of the Young score problem where all the scoresare scaled by an additive constant, it is no longer true that it is hard to approximate the score to any factor; however, theproof still shows that it is hard to approximate the Young score, even under this alternative formulation, to a factor of O(m).The strong inapproximability result for the Young score intuitively implies that the Young ranking cannot be approxi-mated. The following corollary, whose proof is a straightforward variation on the proof of Lemma 6.2, shows that this isindeed the case. It can be viewed as an analog of Theorem 5.6 for Young.Corollary 6.3. For any constant (cid:3) > 0, given a preference profile with m alternatives and an alternative ahas rank O(m(cid:3) ) or is ranked in place m (that is, ranked last) in any Young ranking.whether a∗∗, it is N P -hard to decideProof. Let (cid:3) > 0 be a constant. We perform the same reduction as before, with the following differences. Let A(cid:10) = | Aof alternatives constructed in the reduction of Lemma 6.2, and m(cid:10)(cid:10) ∪ N(cid:10) ∪ N(cid:10) + (mi.e., A = Aas before, and all these agents rank B at the bottom. All the agents in N∗that ranks b first and B just above abe the set(cid:10))1/(cid:3) additional alternatives,arerestricted to Aand N∗∗}, there is i ∈ Nlast; for each b ∈ A(cid:10)|; we add a set B of (m(cid:10)∗, the preferences of N∗(cid:10))1/(cid:3) . The set of agents is N(cid:10) ∪ B, m = | A| = m(cid:10)(cid:10)(cid:10) \ {arank a, i.e.,∗(cid:10)(cid:10)(cid:3)(cid:5)(cid:4)(cid:2)a∗, b(cid:10) \AbR i∗.R i B R ia∗For each c ∈ B, there is i ∈ N(cid:3)(cid:5)(cid:4)(cid:2)a∗R i(cid:3)(cid:10) \Ac R iB \ {c}R ia∗.that ranks c first and the rest of B just above a(cid:4)∗, namely3 X3C is obviously tractable for a constant n, as one can examine all the families S(cid:10) ⊆ S of constant size in polynomial time.I. Caragiannis et al. / Artificial Intelligence 187–188 (2012) 31–5149Notice that the Young score of the alternatives in A(cid:10) \ {a∗is at least 2n/3 − 1 (according to the proof of Lemma 6.2), so aexactly one, since exactly one agent (in NYoung score of athat is, in the top mzero by the same arguments as in Lemma 6.2, since the agents in Nranking. (cid:2)) does not rank A(cid:10) + 1 = O(m(cid:3) ) places. On the other hand, if there is no exact 3-cover, then the Young score of a∗∗∗(cid:10) \ {a∗} is at least one. The Young score of any alternative c ∈ B is∗} above c. Now, if there is an exact 3-cover, then theis ranked above all the alternatives in B,isis placed last in any Younglast. Hence aall rank a∗∗∗As noted in Section 2, one can imagine another alternative formulation of the Young score. Indeed, one might ask: givena preference profile, what is the smallest number of agents that must be removed in order to make aa Condorcet winner?This minimization problem, where the score is the number of agents that are removed, is referred to as the Dual Young scoreby Betzler et al. [4]. Of course, a Young winner according to the primal formulation is always a winner according to the dualformulation, and vice versa. Notice that it is easy to obtain an (cid:3)n-approximation under the dual formulation for any constant(cid:3) > 0 by enumerating all subsets of agents of size at least n − 1/(cid:3) and checking whether ais the Condorcet winner in thepreferences of these agents. Our next result states that the dual Young score is hard to approximate significantly better.∗∗Theorem 6.4. For any constant (cid:3) > 0, the dual Young score is N P -hard to approximate within O (n1−(cid:3) ).Proof. We rely on a statement regarding the inapproximability of Vertex Cover that is weaker than Theorem 5.7; the onewe used in the proof for the inapproximability of the Dodgson ranking.Theorem 6.5. (See Berman and Karpinski [3], see also [25].) Given a 3-regular graph G and an integer K (cid:3) 1, it is N P -hard todistinguish between the following two cases:• G has a vertex cover of size at most K .• Any vertex cover of G has size at least K + 2.(cid:10)(cid:10)(cid:10)Our reduction extends the one in the proof of Lemma 6.2. Consider a 3-regular graph G = (V 1, E) with p nodes and aninteger K (cid:3) 1. Also, let (cid:3) ∈ (0, 1) be a constant and let n = (cid:15)p1/(cid:3) (cid:16). Denote by H = (V 2, F ) the complete graph with n − pnodes.∗}. Let the set of agents be N = NDefine the set of alternatives as A = E ∪ F ∪ {a} ∪ {aare defined as follows. The set NNagent i prefers the alternatives in F ∪ E \ E i to anode i), and prefers aagents corresponding to the n − p nodes of H , such that for all i ∈ N(where the set F i consists of the edges of F which are incident to node i), and prefers a(i.e., ((E ∪ F ) \ F i)R iaR i(E ∪ F )).aR ia, and(cid:10)consists of p agents corresponding to the p nodes of G, such that for all i ∈ N,(where the set E i consists of the edges of E which are incident tocontains n − p∗, agent i prefers the alternatives in E ∪ F \ F i to ato all the alternatives in F i ∪ {a}∗to E ∪ F (i.e.,∗to all the alternatives in E i ∪ {a} (i.e., ((F ∪ E) \ E i)R iaconsists of n − p + K − 2 agents who prefer a to aR i(E i ∪ {a})). The set NR i(F i ∪ {a})). Subset N, where N(cid:10)(cid:10) ∪ N(cid:10) ∪ Nand a, N(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)(cid:10)∗∗∗∗∗∗(cid:10)(cid:10)Theorem 6.4 now follows by Theorem 6.5 and the next two lemmas.Lemma 6.6. If G has a vertex cover of size at most K , then the dual Young score of alternative a∗is at most n(cid:3) .Proof. Let C ⊆ V 1 be a vertex cover of G of size at most K . Consider the following sets of agents: a set Ncontains the agents that correspond to nodes in the vertex cover C , a set Nset Nof all the agents of Nthatbesides one, and the(cid:10)(cid:10)(cid:10)+(cid:10)(cid:10).Recall that Nhas size at most n − p + K − 1 while N∗+each alternative in E is ranked lower than aN(cid:10)(cid:10)(cid:10)considering the agents of Nscore is at most p − |C| + 1 (cid:2) p (cid:2) n(cid:3) . (cid:2)form a vertex cover of H . So, each alternative in F is ranked lower than a, a+ ∪ N∗ ∪ N∗by at least one agent of Nhas size n − p + K − 2. Since C is a vertex cover in G,. Also, the nodes corresponding to the agents in. Hence, bybeats any other alternative in their pairwise comparison and its dual Youngby at least one agent of N+∗∗∗ ∪ N+(cid:10)(cid:10)(cid:10)∗ ⊆ N(cid:10)Lemma 6.7. If G has no vertex cover of size less than K + 2, then the dual Young score of alternative a∗is n.Proof. We will show that there is no nonempty subset of agents that make acontradiction that there exists such a subset that contains the sets of agents Na Condorcet winner. Indeed, assume for, N+ ⊆ N(cid:10)(cid:10), and N− ⊆ N(cid:10)(cid:10)(cid:10).∗| < K + 2 then there exists an alternative of E or F which is not ranked lower than a∗∗∗ ⊆ N(cid:10)+| < n − p − 1 or |N+If |Nagent of Ntheir pairwise comparison. However, a. In both cases, N∗ ∪ N−must have size at least |N∗| + |Ndoes not beat a and cannot be a Condorcet winner.+| in order for a∗∗by anyto beat every alternative in E ∪ F inTherefore, it holds that |N∗+| ∈ {n − p − 1, n − p} and |N+ranked below aby at most one agent of N. It is also ranked above a∗| (cid:3) K + 2. If |N+| = n − p − 1, then some alternative of F isand below it by the agentsby the agents of N∗∗50I. Caragiannis et al. / Artificial Intelligence 187–188 (2012) 31–51−of Nagents. Hence, a∗. In total, it is ranked above a∗by at least n − p + K agents while it is ranked below a∗by at most n − p + K − 1If |N+| = n − p then each alternative in F is ranked below acannot be a Condorcet winner in this case.least n − p + K agents while it is ranked below a+by at most n − p + K agents. Again, aby two agents of N∗∗. In total, it is ranked above a∗by atcannot be a Condorcet winner. (cid:2)∗This concludes the proof of Theorem 6.4. (cid:2)The proof of Theorem 6.4 provides an alternative proof of Theorem 6.1. In terms of the Young score, it implies that,for every constant (cid:3) > 0, there are instances for which it is hard to distinguish between a score of zero and a score of atleast n − n(cid:3) . So, for the formulation of the Young score where all the scores are scaled by an additive constant, it providesadditional information which is complementary to the one provided by the proof of Theorem 6.1: it implies that it is hardto approximate the Young score, even under this alternative formulation, within a factor of O(n).7. DiscussionGenerally speaking, we have taken the following approach: winner determination under the Dodgson and Young votingrules is intractable, therefore we aim to approximate the Dodgson or Young score. Other goals may seem more natural.For example, one can ask for a randomized algorithm that selects the winner with high probability, or an algorithm thatselects an alternative that is ranked high by the voting rule in question. Note that our Theorem 5.6 rules out the latter goal.Nevertheless, a social choice justification for approximating a voting rule’s score is called for. Below we concentrate on theDodgson score because our positive results concern this rule.Dodgson’s reasoning in designing his voting rule is a special case of a more general framework called distance ratio-nalizability, which was proposed by Meskanen and Nurmi [33], and recently received some attention in the AI literature[13,15,14]. The reasoning behind this framework is that a voting rule should elect an alternative that is closest to being aconsensus winner, according to a natural notion of consensus and a natural notion of distance.Dodgson’s rule employs a very natural notion of consensus (Condorcet winner) and arguably a natural notion of distance(number of swaps between adjacent alternatives). These are normative statements, as is common in social choice theory.However, viewed through the distance rationalizability lens, an approximation of the Dodgson score is simply an approxi-mation of a natural distance function, much like approximations for other hard problems that involve distances, e.g., facilitylocation problems. In facility location problems there is a direct connection between distances and the quality of the so-lution (e.g., the larger the distances, the more costly it would be to build an appropriate infrastructure). Work in progressby Boutilier and Procaccia suggests that, similarly, in the distance rationalizability framework the distance function can beproportional to a direct quantitative measure of an alternative’s quality: the closer the alternative is to consensus accordingto the distance function, the faster it leads to consensus in a social choice model that involves dynamic preferences, as putforward by Parkes and Procaccia [35].Therefore, we can argue that an alternative is increasingly more socially desirable the smaller its Dodgson score, that is,the score itself is meaningful and not just the Dodgson ranking, and therefore a good approximation of the Dodgson scoremay also single out socially desirable winners. Moreover, as argued in Section 4, whenever approximation algorithms satisfyadditional social choice desiderata, they may ultimately be adopted as socially sensible voting rules in their own right.Interestingly, Dodgson’s rule is considered to be especially flawed from a social choice point of view, and this may beone of the reasons why it was never employed in real-world decision making. Some well-known voting rules like Copelandand Maximin are Condorcet-consistent, and in addition avoid the main drawbacks from which Dodgson suffers (e.g., theyare monotonic). Nevertheless, our thesis is that Dodgson approximations can in fact be superior to the original rule, fromboth the computational and the social choice points of view, and ultimately may serve as realistic choices for preferenceaggregation in human societies and in multiagent systems. The results given above are the starting point of this line ofinquiry; some of us make the point more forcefully in follow-up work [7], which directly builds on the results of this paper.AcknowledgementsThe authors wish to thank Felix Fischer and Nati Linial for helpful discussions. The work was done while Procaccia was atthe Hebrew University of Jerusalem, and was supported by the Adams Fellowship Program of the Israel Academy of Sciencesand Humanities. The work of Procaccia and Rosenschein was partially supported by Israel Science Foundation grant #898/05.The work of Feldman was partially supported by the Israel Science Foundation (grant #1219/09) and by the Leon RecanatiFund of the Jerusalem school of business administration. The work of Caragiannis, Kaklamanis, and Karanikolas was partiallysupported by the European Social Fund and Greek national funds through the Research Funding Program Heracleitus II.References[1] N. Ailon, M. Charikar, A. Newman, Aggregating inconsistent information: ranking and clustering, Journal of the ACM 55 (5) (2008) 23.[2] J. Bartholdi, C.A. Tovey, M.A. Trick, Voting schemes for which it can be difficult to tell who won the election, Social Choice and Welfare 6 (1989)157–165.I. Caragiannis et al. / Artificial Intelligence 187–188 (2012) 31–5151[3] P. Berman, M. Karpinski, On some tighter inapproximability results, in: Proceedings of the 26th International Colloquium on Automata, Languages, andProgramming (ICALP), 1999, pp. 200–209.[4] N. Betzler, J. Guo, R. Niedermeier, Parameterized computational complexity of Dodgson and Young elections, Information and Computation 208 (2)(2010) 165–177.[5] D. Black, Theory of Committees and Elections, Cambridge University Press, 1958.[6] F. Brandt, Some remarks on Dodgson’s voting rule, Mathematical Logic Quarterly 55 (4) (2009) 460–463.[7] I. Caragiannis, C. Kaklamanis, N. Karanikolas, A.D. Procaccia, Socially desirable approximations for Dodgson’s voting rule, in: Proceedings of the 11thACM Conference on Electronic Commerce (EC), 2010, pp. 253–262.[8] V. Conitzer, Computing Slater rankings using similarities among candidates, in: Proceedings of the 21st National Conference on Artificial Intelligence(AAAI), 2006, pp. 613–619.[9] V. Conitzer, A. Davenport, J. Kalagnanam, Improved bounds for computing Kemeny rankings, in: Proceedings of the 21st National Conference onArtificial Intelligence (AAAI), 2006, pp. 620–626.[10] D. Coppersmith, L. Fleischer, A. Rudra, Ordering by weighted number of wins gives a good ranking for weighted tournaments, in: Proceedings of the17th Annual ACM–SIAM Symposium on Discrete Algorithms (SODA), 2006, pp. 776–782.[11] T.H. Cormen, C.E. Leiserson, R.L. Rivest, C. Stein, Introduction to Algorithms, second edition, MIT Press, 2001.[12] C. Dwork, R. Kumar, M. Naor, D. Sivakumar, Rank aggregation methods for the web, in: Proceedings of the 10th International Conference on WorldWide Web (WWW 01), 2001, pp. 613–622.[13] E. Elkind, P. Faliszewski, A. Slinko, On distance rationalizability of some voting rules, in: Proceedings of the 12th Conference on Theoretical Aspects ofRationality and Knowledge (TARK), 2009, pp. 108–117.[14] E. Elkind, P. Faliszewski, A. Slinko, Good rationalizations of voting rules, in: Proceedings of the 24th AAAI Conference on Artificial Intelligence (AAAI),2010, pp. 774–779.[15] E. Elkind, P. Faliszewski, A. Slinko, On the role of distances in defining voting rules, in: Proceedings of the 9th International Joint Conference onAutonomous Agents and Multi-Agent Systems (AAMAS), 2010, pp. 375–382.[16] P. Faliszewski, E. Hemaspaandra, L.A. Hemaspaandra, Multimode control attacks on elections, Journal of Artificial Intelligence Research 40 (2011) 305–351.[17] U. Feige, A threshold of ln n for approximating set cover, Journal of the ACM 45 (4) (1998) 643–652.[18] P.C. Fishburn, Condorcet social choice functions, SIAM Journal on Applied Mathematics 33 (3) (1977) 469–487.[19] P.C. Fishburn, Monotonicity paradoxes in the theory of elections, Discrete Applied Mathematics 4 (2) (1982) 119–134.[20] M.R. Garey, D.S. Johnson, Computers and Intractability: A Guide to the Theory of NP-Completeness, W.H. Freeman and Company, 1979.[21] S. Ghosh, M. Mundhe, K. Hernandez, S. Sen, Voting for movies: The anatomy of recommender systems, in: Proceedings of the 3rd Annual Conferenceon Autonomous Agents (Agents 99), 1999, pp. 434–435.[22] A. Gibbard, Manipulation of voting schemes, Econometrica 41 (1973) 587–602.[23] E. Hemaspaandra, L.A. Hemaspaandra, J. Rothe, Exact analysis of Dodgson elections: Lewis Carroll’s 1876 voting system is complete for parallel accessto NP, Journal of the ACM 44 (6) (1997) 806–825.[24] C. Homan, L.A. Hemaspaandra, Guarantees for the success frequency of an algorithm for finding Dodgson-election winners, Journal of Heuristics 15 (4)(2009) 403–423.[25] M. Karpinski, Approximating bounded degree instances of NP-hard problems, in: Proceedings of the 13th International Symposium on Fundamentalsof Computation Theory (FCT), in: Lecture Notes in Computer Science, vol. 2138, Springer, 2001, pp. 24–34.[26] C. Kenyon-Mathieu, W. Schudy, How to rank with few errors, in: Proceedings of the 39th Annual ACM Symposium on Theory of Computing (STOC),2007, pp. 95–103.[27] C. Klamler, A comparison of the Dodgson method and the Copeland rule, Economics Bulletin 4 (8) (2003) 1–7.[28] C. Klamler, The Dodgson ranking and its relation to Kemeny’s method and Slater’s rule, Social Choice and Welfare 23 (1) (2004) 91–102.[29] C. Klamler, The Dodgson ranking and the Borda count: a binary comparison, Mathematical Social Sciences 48 (1) (2004) 103–108.[30] J.C. McCabe-Dansted, Approximability and computational feasibility of Dodgson’s rule, Master’s thesis, University of Auckland, 2006.[31] J.C. McCabe-Dansted, Dodgson’s rule: Approximations and absurdity, in: Proceedings of the 2nd International Workshop on Computational Social Choice(COMSOC), 2008, pp. 371–382.[32] J.C. McCabe-Dansted, G. Pritchard, A.M. Slinko, Approximability of Dodgson’s rule, Social Choice and Welfare 31 (2) (2008) 311–330.[33] T. Meskanen, H. Nurmi, Closeness counts in social choice, in: M. Braham, F. Steffen (Eds.), Power, Freedom, and Voting, Springer-Verlag, 2008.[34] N. Nisan, Introduction to mechanism design (for computer scientists), in: N. Nisan, T. Roughgarden, É. Tardos, V. Vazirani (Eds.), Algorithmic GameTheory, Cambridge University Press, 2007 (Chapter 9).[35] D.C. Parkes, A.D. Procaccia, Dynamic social choice: Foundations and algorithms, Manuscript, 2010.[36] A.D. Procaccia, A. Zohar, Y. Peleg, J.S. Rosenschein, The learnability of voting rules, Artificial Intelligence 173 (12–13) (2009) 1133–1149.[37] S. Rajagopalan, V.V. Vazirani, Primal-dual RNC approximation algorithms for set cover and covering integer programs, SIAM Journal on Computing 28(1999) 526–541.[38] T.C. Ratliff, A comparison of Dodgson’s method and Kemeny’s rule, Social Choice and Welfare 18 (1) (2001) 79–89.[39] T.C. Ratliff, A comparison of Dodgson’s method and the Borda count, Economic Theory 20 (2) (2002) 357–372.[40] R. Raz, S. Safra, A sub-constant error-probability low-degree test, and sub-constant error-probability PCP characterization of NP, in: Proceedings of the29th Annual ACM Symposium on Theory of Computing (STOC), 1997, pp. 475–484.[41] J. Rothe, H. Spakowski, J. Vogel, Exact complexity of the winner problem for Young elections, Theory of Computing Systems 36 (4) (2003) 375–386.[42] M. Satterthwaite, Strategy-proofness and Arrow’s conditions: Existence and correspondence theorems for voting procedures and social welfare func-tions, Journal of Economic Theory 10 (1975) 187–217.[43] N. Tideman, Collective Decisions and Voting: The Potential for Public Choice, Ashgate, 2006.[44] V.V. Vazirani, Approximation Algorithms, Springer, 2001.[45] H.P. Young, Extending Condorcet’s rule, Journal of Economic Theory 16 (1977) 335–353.