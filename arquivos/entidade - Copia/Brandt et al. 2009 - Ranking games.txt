Artiﬁcial Intelligence 173 (2009) 221–239

Contents lists available at ScienceDirect

Artiﬁcial Intelligence

www.elsevier.com/locate/artint

Ranking games
Felix Brandt a,∗

, Felix Fischer a, Paul Harrenstein a, Yoav Shoham b

a Institut für Informatik, Universität München, Oettingenstr. 67, 80538 München, Germany
b Computer Science Department, Stanford University, 353 Serra Mall, Stanford, CA 94305, USA

a r t i c l e

i n f o

a b s t r a c t

Article history:
Received 3 January 2008
Received in revised form 28 August 2008
Accepted 20 October 2008
Available online 29 October 2008

Keywords:
Multi-agent systems
Game theory
Strict competitiveness
n-player games
Solution concepts
Computational complexity

The outcomes of many strategic situations such as parlor games or competitive economic
scenarios are rankings of the participants, with higher ranks generally at least as desirable
as lower ranks. Here we deﬁne ranking games as a class of n-player normal-form games
with a payoff structure reﬂecting the players’ von Neumann–Morgenstern preferences
over their individual ranks. We investigate the computational complexity of a variety of
common game-theoretic solution concepts in ranking games and deliver hardness results
for iterated weak dominance and mixed Nash equilibrium when there are more than two
players, and for pure Nash equilibrium when the number of players is unbounded but the
game is described succinctly. This dashes hope that multi-player ranking games can be
solved eﬃciently, despite their profound structural restrictions. Based on these ﬁndings,
we provide matching upper and lower bounds for three comparative ratios, each of which
relates two different solution concepts: the price of cautiousness, the mediation value, and the
enforcement value.

© 2008 Elsevier B.V. All rights reserved.

1. Introduction

The situations studied by the theory of games may involve different levels of antagonism. On the one end of the spec-
trum are games of pure coordination, on the other those in which the players’ interests are diametrically opposed. In this
paper, we put forward a new class of competitive multi-player games whose outcomes are rankings of the players, i.e.,
orderings of the players representing how well they have done in the game relative to one another. We assume players to
weakly prefer a higher rank over a lower one and to be indifferent as to the other players’ ranks. This type of situation is
commonly encountered in parlor games, competitions, patent races, competitive resource allocation domains, social choice
settings, or any other strategic situation where players are merely interested in performing optimal relative to their oppo-
nents rather than in absolute measures. Formally, ranking games are deﬁned as normal-form games in which the payoff
function represents the players’ von Neumann–Morgenstern preferences over lotteries over rankings. A noteworthy special
case of particular relevance to game playing in AI are single-winner games where in any outcome one player wins and all
others lose.

While two-player ranking games form a subclass of zero-sum games, no such relationship holds for ranking games with
more than two players. Moreover, whereas the notion of a ranking is most natural in multi-player settings, this seems to
be less so for the requirement that the sum of payoffs in all outcomes be constant, as any game can be transformed into
a constant-sum game by merely introducing an additional player (with only one action at his disposal) who absorbs the
payoffs of the other players [41].

* Corresponding author. Tel.: +49 89 2180 9406; fax: +49 89 2180 9338.

E-mail addresses: brandtf@tcs.iﬁ.lmu.de (F. Brandt), ﬁscherf@tcs.iﬁ.lmu.de (F. Fischer), harrenst@tcs.iﬁ.lmu.de (P. Harrenstein), shoham@cs.stanford.edu

(Y. Shoham).

0004-3702/$ – see front matter © 2008 Elsevier B.V. All rights reserved.
doi:10.1016/j.artint.2008.10.008

222

F. Brandt et al. / Artiﬁcial Intelligence 173 (2009) 221–239

As with games in which both contrary and common interests prevail, it turns out that solving ranking games tends to
become considerably more complicated as soon as more than two players are involved. The maximin solution does not
unequivocally extend to general n-player games and numerous alternate solution concepts have been proposed to cope
with this type of situation. None of them, however, seems to be as compelling as maximin is for two-player zero-sum
games. In this paper we study and compare the properties of a variety of solution concepts in ranking games. The results
of this paper fall into two different categories. First, we investigate the complexity of a number of computational problems
related to common solution concepts in ranking games, particularly Nash equilibrium and iterated weak dominance. Second,
we study a number of comparative ratios in ranking games, each of which relates two different solution concepts: the price
of cautiousness, the mediation value, and the enforcement value.

The computational effort required to determine a solution is obviously a very important property of any solution concept.
If computing a solution is intractable, the solution concept is rendered virtually useless for large problem instances that do
not exhibit additional structure. The importance of this aspect has by no means escaped the attention of game theorists. In
an interview with Eric van Damme [39], Robert Aumann claimed: “My own viewpoint is that, inter alia, a solution concept
must be calculable, otherwise you are not going to use it.” It has subsequently been argued that this still holds if one
subscribes to a purely descriptive view of solution concepts: “I believe that the complexity of equilibria is of fundamental
importance in game theory, and not just a computer scientist’s afterthought. Intractability of an equilibrium concept would
make it implausible as a model of behavior” [28]. In computational complexity theory, the distinction between tractable
and intractable problems is typically one between membership in the class P of problems that can be solved in time
polynomial in the size of the problem instance versus hardness for the class NP of problems a solution of which can be
veriﬁed eﬃciently. A third class that will play an important role in the context of this paper is PPAD. Problems in PPAD are
guaranteed to possess a solution, and emphasis is put on actually ﬁnding it. Given the current state of complexity theory,
we cannot prove the actual intractability of most algorithmic problems, but merely give evidence for their intractability. NP-
hardness of a problem is commonly regarded as very strong evidence against computational tractability because it relates
the problem to a large class of problems for which no eﬃcient algorithm is known, despite enormous efforts to ﬁnd such
algorithms. To some extent, the same reasoning can also be applied to PPAD-hardness.

We study the computational complexity of common game-theoretic solution concepts in ranking games and deliver NP-
hardness and PPAD-hardness results, respectively, for iterated weak dominance and (mixed) Nash equilibria when there are
more than two players, and an NP-hardness result for pure Nash equilibria in games with an unbounded number of players.
This dashes hope that multi-player ranking games can be solved eﬃciently, despite their profound structural restrictions.
Remarkably, all hardness results hold for arbitrary preferences over ranks, provided they meet the requirements listed above.
Accordingly, even very restricted subclasses of ranking games such as single-winner games—in which players only care about
winning—or single-loser games—in which players merely wish not to be ranked last—are computationally hard to solve.

By contrast, maximin strategies [40] as well as correlated equilibria [5] are known to be computationally easy via linear
programming for any class of games. Against the potency of these concepts, however, other objections can be brought in.
Playing a maximin strategy is extremely defensive and a player may have to forfeit a considerable amount of payoff in order
to guarantee his security level. Correlation, on the other hand, may not be feasible in all practical applications, and may fail
to provide an improvement of social welfare in restricted classes of games [23]. Thus, we come to consider the following
comparative ratios in an effort to facilitate the quantitative analysis of solution concepts in ranking games:

• the price of cautiousness, i.e., the ratio between an agent’s minimum payoff in a Nash equilibrium and his security level,
• the mediation value, i.e., the ratio between the social welfare obtainable in the best correlated equilibrium vs. the best

Nash equilibrium, and

• the enforcement value, i.e., the ratio between the highest obtainable social welfare and that of the best correlated equi-

librium.

Each of these values obviously equals 1 in the case of two-player ranking games, as these form a subclass of constant-sum
games. Accordingly, the interesting question to ask concerns the bounds of these values for ranking games with more than
two players.

2. Introductory example

To illustrate the issues addressed in this paper, consider a situation in which Alice, Bob, and Charlie are to choose a
winner from among themselves by means of the following protocol. Each of them is either to raise or not to raise their
hand; they are to do so simultaneously and independently of one another. Alice wins if the number of hands raised,
including her own, is odd, whereas Bob is victorious if this number equals two. Should nobody raise their hand, Charlie
wins. The normal-form of this game is shown in Fig. 1. What course of action would you recommend to Alice? There is a
Nash equilibrium in which Alice raises her hand, another one in which she does not raise her hand, and still another one
in which she randomizes uniformly between these two options. In the only pure, i.e., non-randomized, equilibrium of the
game, Alice does not raise her hand. If the latter were to occur, we must assume that Alice believes that Bob will raise
his hand and Charlie will not. This assumption, however, is unreasonably strong as no such beliefs can be derived from the

F. Brandt et al. / Artiﬁcial Intelligence 173 (2009) 221–239

223

Fig. 1. Three-player single-winner game. Alice (1) chooses row a1 or a2, Bob (2) chooses column b1 or b2, and Charlie (3) chooses matrix c1 or c2. Outcomes
are denoted by the winner’s index. The dashed square marks the only pure Nash equilibrium. Dotted rectangles mark a quasi-strict equilibrium in which
Alice and Charlie randomize uniformly over their respective actions.

mere description of the game. Moreover, both Bob and Charlie may deviate from their respective strategies to any other
strategy without decreasing their chances of winning. After all, they cannot do any worse than losing.

This points at a weakness of pure Nash equilibrium as a solution concept inherent in ranking games, since in any
outcome some player has to be ranked last. On the other hand, it is very well possible that all the actions in the support
of a mixed equilibrium yield each player a strictly higher expected payoff than any action not in the support, mitigating
the phenomenon mentioned above. In other words, such equilibria can be quasi-strict, a property no pure equilibrium in a
ranking game has. While quasi-strict equilibria may fail to exist in ranking games with more than two players (see Fig. 4),
we conjecture, and prove for certain sub-cases, that every single-winner game possesses at least one non-pure equilibrium,
i.e., an equilibrium where at least one player randomizes. We note without proof that this property fails to hold for general
ranking games.

Returning to our example, it is unclear which strategy would maximize Alice’s chances of winning. By playing her
maximin strategy, Alice can guarantee a particular probability of winning, her so-called security level, no matter which
actions her opponents choose. Alice’s security level in this particular game is 0.5 and can be obtained by randomizing
uniformly between both actions. The same expected payoff is achieved in the worst quasi-strict equilibrium of the game
where Alice and Charlie randomize uniformly and Bob invariably raises his hand (see Fig. 1).

3. Related work

Game playing research in AI has largely focused on two-player games (see, e.g., [20]). As a matter of fact, “in AI, ‘games’
are usually of a rather specialized kind—what game theorists call deterministic, turn-taking, two-player, zero-sum games of
perfect information” [32, p. 161]. Notable exceptions include cooperative games in the context of coalition formation (see, e.g.,
Sandholm et al. [33]) and perfect information extensive-form games, a class of multi-player games for which eﬃcient Nash
equilibrium search algorithms have been investigated by the AI community (e.g., Luckhardt and Irani [19]; Sturtevant [35]).
In extensive-form games, players move consecutively and a pure (so-called subgame perfect) Nash equilibrium is guaranteed
to exist (see, e.g., Myerson [24]). Therefore, the computational complexity of ﬁnding equilibria strongly depends on the
actual representation of the game (see also Section 6.3). Normal-form games are more general than (perfect-information)
extensive-form games because every extensive-form game can be mapped to a corresponding normal-form game (with
potentially exponential blowup), while the opposite is not the case.

In game theory, several proposals for broader classes of games that maintain some of the quintessential properties of
two-player constant-sum games have been made. Aumann [4] deﬁnes almost strictly competitive games as the class of two-
player games in which a pair of strategies is an equilibrium point, i.e., no player can increase his payoff by unilaterally
changing his strategy, if and only if it is a so-called twisted equilibrium point, i.e., no player can decrease the payoff of his
opponent. These games permit a set of optimal strategies for each player and a unique value that is obtained whenever
a pair of such strategies is played. Moulin and Vial [23] call a game strategically zero-sum if it is best-response equivalent
to a zero-sum game. In the case of two players, and only in this case, one obtains exactly the class of games for which
no completely mixed equilibrium can be improved upon by a correlated equilibrium. A game is unilaterally competitive, as
deﬁned by Kats and Thisse [15], if any deviation by a player that (weakly) increases his own payoff must (weakly) decrease
the payoffs of all other players. Unilaterally competitive games retain several interesting properties of two-player constant-
sum games in the n-player case: all equilibria yield the same payoffs, equilibrium strategies are interchangeable, and, the set
of equilibria is convex provided that some mild conditions hold. It was later shown by Wolf [42] that pure Nash equilibria
of n-player unilaterally competitive games are always proﬁles of maximin strategies. When there are just two players, all of
the above classes contain constant-sum games and thus two-player ranking games. Neither is contained in the other in the
n-player case. The notion of competitiveness as embodied in ranking games is remotely related to spitefulness [8,22], where
agents aim at maximizing their payoff relative to the payoff of all other agents.

Most work on comparative ratios in game theory has been inspired by the literature on the price of anarchy [17,31], i.e.,
the ratio between the highest obtainable social welfare and that of the best Nash equilibrium. Similar ratios for correlated
equilibria, the value of mediation, i.e., the ratio between the social welfare obtainable in the best correlated equilibrium vs.
the best Nash equilibrium and the enforcement value, i.e., the ratio between the highest obtainable social welfare and that of
the best correlated equilibrium, were introduced by Ashlagi et al. [2]. It is known that the mediation value of strategically
zero-sum games is 1 and that of almost strictly competitive games is greater than 1, showing that correlation can be

224

F. Brandt et al. / Artiﬁcial Intelligence 173 (2009) 221–239

beneﬁcial even in games of strict antagonism [30]. To the best of our knowledge, Tennenholtz [36] was the ﬁrst to conduct
a quantitative comparison of Nash equilibrium payoffs and security levels. This work is inspired by an intriguing example
game due to Aumann [6], in which the only Nash equilibrium yields each player no more than his security level although
the equilibrium strategies are different from the maximin strategies. In other words, the equilibrium strategies yield security
level payoffs without guaranteeing them.

4. The model

A game form is a quadruple (N, ( Ai)i∈N , Ω, g), where N is a ﬁnite non-empty set of players, Ai a ﬁnite and non-empty set
of actions available to player i, Ω a set of outcomes, and g: ×i∈N Ai → Ω an outcome function mapping each action proﬁle
to an outcome in Ω . The set ×i∈N Ai of action proﬁles is denoted by A. We assume that each player entertain preferences
over lotteries over Ω that comply with the von Neumann–Morgenstern axioms [41]. Thus, the preferences of each player i
can be represented by a real valued payoff function pi on Ω . We arrive at the following deﬁnition of a normal-form game.

Deﬁnition 1 (Game in normal form). A game in normal form Γ is given by a quintuple (N, ( Ai)i∈N , Ω, g, (pi)i∈N ) where
(N, ( Ai)i∈N , Ω, g) is a game form and each pi: Ω → R is a real valued payoff function.

We generally assume the payoff functions pi to be extended so as to apply directly to action proﬁles a ∈ A by set-

ting pi(a) = pi(g(a)).

We say a game is rational if for all i ∈ N and all a ∈ A, pi(a) ∈ Q. A game is binary if for all i ∈ N and all a ∈ A, pi(a) ∈
{0, 1}. A game with two players will also be referred to as a bimatrix game. Unless stated otherwise, we will henceforth
assume that every player has at least two actions. Subscripts will be used to identify the player to which an action belongs,
j
superscripts to index the actions of a particular player. For example, we write ai for a typical action of player i and a
i for
his jth action. For better readability, we also use lower case roman letters from the beginning of the alphabet to denote the
players’ actions in such a way that a j = a

j

j

1, b j = a

2, c j = a

j
3, and so forth.

(cid:2)

The concept of an action proﬁle can be generalized to that of a mixed strategy proﬁle by letting players randomize over
their actions. We have S i denote the set Δ( Ai) of probability distributions over player i’s actions, the mixed strategies
available to player i, and S the set ×i∈N S i of mixed strategy proﬁles with s as typical element. Payoff functions naturally
extend to mixed strategy proﬁles, and we will frequently write pi(s) for the expected payoff of player i, and p(s) for the
i∈N pi(s) under the strategy proﬁle s. We have n stand for the number |N| of players. In the following, A−i
social welfare
and S−i denote the set of action proﬁles for all players but i and the set of strategy proﬁles for all players but i, respectively.
We use si for the ith strategy in proﬁle s and s−i for the vector of all strategies in s but si . Furthermore, s(ai) and si(ai)
stand for the probability player i assigns to action ai in strategy proﬁle s or strategy si , respectively. The pure strategy si
such that si(ai) = 1 we also denote by ai whenever this causes no confusion. Moreover, we use (s−i, ti) to refer to the
strategy proﬁle obtained from s by replacing si by ti . For better readability we usually avoid double parentheses and write,
e.g., p(s−i, ti) instead of p((s−i, ti)).

4.1. Rankings and ranking games

A ranking game is a normal-form game whose outcomes are rankings of its players. A ranking indicates how well each
player has done relative to the other players in the game. Formally, a ranking r = [r1, . . . , rn] is an ordering of the players
in N in which player r1 is ranked ﬁrst, player r2 ranked second, and so forth, with player rn ranked last. Obviously, this
limits the number of possible outcomes to n! irrespective of the number of actions the players have at their disposal. The
set of rankings over a set N of players we denote by R N . A game form (N, ( Ai)i∈N , Ω, g) is a ranking game form if the set of
outcomes is given by the set of rankings of the players, i.e., if Ω = R N .

We assume that all players weakly prefer higher ranks over lower ranks, and strictly prefer being ranked ﬁrst to being
ranked last. Furthermore, each player is assumed to be indifferent as to the ranks of the other players. Even so, a player
may prefer to be ranked second for certain to having a ﬁfty-ﬁfty chance of being ranked ﬁrst or being ranked third, whereas
other players may judge quite differently. Accordingly, we have a rank payoff function pi: R N → R represent player i’s von
Neumann–Morgenstern preferences over lotteries over R N . For technical convenience, we normalize the payoffs to the unit
(cid:5) ∈ R N :
interval [0, 1]. Formally, a rank payoff function pi over R N satisﬁes the following three conditions for all rankings r, r

(cid:5)), if rk = r
(cid:5)
(i) pi(r) (cid:2) pi(r
m
(ii) pi(r) = 1, if i = r1, and
(iii) pi(r) = 0, if i = rn.

= i and k (cid:3) m,

We are now in a position to formally deﬁne the concept of a ranking game.

Deﬁnition 2 (Ranking game). A normal form game Γ = (N, ( Ai)i∈N , Ω, g, (pi)i∈N ) is a ranking game if Ω is the set R N of
rankings over N and each pi: R N → R is a rank payoff function over R N .

F. Brandt et al. / Artiﬁcial Intelligence 173 (2009) 221–239

225

Fig. 2. A 2 × 2 × 2 ranking game form. One player chooses rows, another columns, and a third matrices. Each combination of actions results in a ranking.
For example, action proﬁle (a2, b2, c2) leads to the row player 1 being ranked ﬁrst, the matrix player 3 second and the column player 2 third.

Fig. 3. A ranking game associated with the ranking game form depicted in Fig. 2. The rank payoff for the three players are given by (cid:6)p1 = (1, 1
(cid:6)p2 = (1, 0, 0) and (cid:6)p3 = (1, 1, 0).

2 , 0),

ingly, for 1 (cid:3) k (cid:3) n, we have pk
payoff function of player i can then conveniently and compactly be represented by his rank payoff vector (cid:6)pi = (p1

Condition (i) above implies that a player’s payoff for a ranking r only depends on the rank assigned to him in r. Accord-
i denote the unique payoff player i obtains in any ranking r in which i is ranked kth. The rank
i , . . . , pn
i ).
In a binary ranking game, a player is completely satisﬁed up to a certain rank, and not satisﬁed at all for any lower rank.
The expected payoff of a player given a strategy proﬁle can then be taken as his chances of being satisﬁed. Thus, the use of
expected utility, and thus randomized strategies, is justiﬁed without relying on the von Neumann–Morgenstern axioms (see
also [7]). An interesting subclass of binary ranking games are so-called single-winner games, in which all players are only
interested in being ranked ﬁrst. Formally, a single-winner game is a ranking game in which (cid:6)pi = (1, 0, . . . , 0) for all i ∈ N.
When considering mixed strategies, the expected payoff in a single-winner ranking game equals the probability of winning.
Analogous to single-winner games, we can deﬁne single-loser games as ranking games in which the players’ only concern is
not to be ranked last, as for instance in a round of musical chairs. Formally, single-loser games are ranking games where
(cid:6)pi = (1, . . . , 1, 0) for each player i. For an example illustrating the deﬁnitions of a ranking game form and a ranking game
the reader is referred to Figs. 2 and 3, respectively.

At this point, a remark as to the relationship between ranking games and n-player constant-sum games is in order.
By virtue of conditions (ii) and (iii), two-player ranking games constitute a subclass of zero-sum games. If more than two
players are involved, however, any such relation with n-person constant-sum games no longer holds. A strategic game can
be converted to a zero-sum game via positive aﬃne transformations only if all outcomes of the game lie on an (n − 1)-
dimensional hyperplane in the n-dimensional outcome space. Clearly, there are ranking games (with non-identical rank
payoff vectors and more than two players) for which this is not the case. For example, consider a three-player ranking
game with rank payoff vectors (cid:6)p1 = (cid:6)p2 = (1, 0, 0) and (cid:6)p3 = (1, 1, 0) that has among its outcomes the rankings [1, 2, 3],
[2, 1, 3], [3, 1, 2], and [1, 3, 2]. As a consequence, ranking games are no subclass of (the games that can be transformed into)
constant-sum games. It is readily appreciated that the opposite inclusion does not hold either.

5. Solution concepts

In this section we review a number of well-known solution concepts and prove some properties speciﬁc to ranking

games.

On a normative interpretation, the solution concepts game theory has produced identify reasonable, desirable, or other-
wise signiﬁcant strategy proﬁles in games. Perhaps the most cautious way for a player to proceed is to ensure his security
level by playing his maximin strategy, the strategy that maximizes his payoff in case the other players were to conspire
against him and try to minimize his payoff.

Deﬁnition 3 (Maximin strategy and security level). A strategy s

∗
i

∈ S i is called a maximin strategy for player i ∈ N if

∗
i

s

∈ argmax
si ∈S i

min
s−i ∈S−i

pi(si, s−i).

The value v i = maxsi ∈S i mins−i ∈S−i pi(si, s−i) is called the security level of player i.

Given a particular game Γ , we will write v i(Γ ) for the security level of player i in Γ . In the game of Fig. 1, Alice can
achieve her security level of 0.5 by uniform randomization over her actions, i.e., by raising her hand with probability 0.5.
The security level for both Bob and Charlie is zero.

We will now move on to the next solution concept, namely that of the iterated elimination of weakly dominated actions.

226

F. Brandt et al. / Artiﬁcial Intelligence 173 (2009) 221–239

Fig. 4. Three-player single-winner game without quasi-strict equilibria. Dashed boxes mark all Nash equilibria (one player may mix arbitrarily in boxes that
span two outcomes).

Deﬁnition 4 (Weak dominance). An action di ∈ Ai is said to be weakly dominated by strategy si ∈ S i if

pi(a−i, di) (cid:3) pi(a−i, si)

for all a ∈ A,

and

pi(a−i, di) < pi(a−i, si)

for some a ∈ A.

After one or more dominated actions have been removed, other actions may become dominated that were not dominated
previously, and may subsequently be removed. In general, the result of such an iterative elimination process depends on the
order in which actions are eliminated, since the elimination of an action of some player may render an action of another
player undominated. We say that a game is solvable by iterated weak dominance if there is some sequence of eliminations
that leaves exactly one action per player.

Perhaps the best-known solution concept is Nash equilibrium [25], which identiﬁes strategy proﬁles in which no player
could increase his payoff by unilaterally deviating and playing another strategy. A Nash equilibrium is therefore often called
a strategy proﬁle of mutual best responses.

Deﬁnition 5 (Nash equilibrium). A strategy proﬁle s
si ∈ S i ,

∗

pi(s

) (cid:2) pi(s

∗
−i, si).

∗ ∈ S is called a Nash equilibrium if for each player i ∈ N and each strategy

A Nash equilibrium is called pure if it is a pure strategy proﬁle.

Nash [25] has shown that every normal-form game possesses at least one equilibrium. There are inﬁnitely many Nash

equilibria in the single-winner game of Fig. 1, the only pure equilibrium is denoted by a dashed square.

A weakness of Nash equilibrium as a normative solution concept is that, given particular strategies of the other players,
a player may be indifferent between an action he plays with non-zero probability and an action he does not play at all.
For example, in the pure Nash equilibrium of the game in Fig. 1, players 2 and 3 might just as well play any other strategy
without decreasing their chances of winning. To alleviate the effects of this phenomenon, Harsanyi [14] proposed to impose
the additional requirement that every best response be played with positive probability. Any Nash equilibrium that also
satisﬁes this latter restriction is called a quasi-strict equilibrium.1

Deﬁnition 6 (Quasi-strict equilibrium). A Nash equilibrium s
ai, a

∗(a

(cid:5)
i) = 0,

(cid:5)
i

∈ Ai with s
∗
−i, ai) > pi(s
pi(s

∗(ai) > 0 and s
∗
−i, a

(cid:5)
i).

∗ ∈ S is called quasi-strict equilibrium if for all i ∈ N and all

Fig. 1 shows a quasi-strict equilibrium of the game among Alice, Bob and Charlie.2 While quasi-strict equilibria have
been shown to always exist in two-player games [26], this is not generally the case for games with more than two players.
Fig. 4 shows that quasi-strict equilibria need not even exist in single-winner games.3

In ranking games, the stability of some Nash equilibria is especially questionable because they prescribe losing players
to play certain strategies even though they could just as well play any other strategy without a chance of decreasing their
payoff. In each outcome of a ranking game, there is at least one player that is ranked lowest and accordingly receives the
minimum payoff of zero. Consequently, any such player has no incentive to actually play the action prescribed by the Nash
equilibrium. It follows that all pure equilibria are weak in this sense. This problem is especially urgent in single-winner
games, where all players but the winner are indifferent over which action to play. Quasi-strict equilibrium can be used to
formally illustrate this weakness.

1 Harsanyi originally referred to quasi-strict equilibrium as “quasi-strong”. However, this term has been dropped to distinguish the concept from Aumann’s

strong equilibrium [3].

2 Observe that Charlie plays a weakly dominated action with positive probability in this equilibrium.
3 There are only few examples in the literature for games without quasi-strict equilibria (essentially there is one example by van Damme [38] and

another one by Cubitt and Sugden [11]). For this reason, the game depicted in Fig. 4 might be of independent interest.

F. Brandt et al. / Artiﬁcial Intelligence 173 (2009) 221–239

227

Fact 1. Quasi-strict equilibria in ranking games are never pure, i.e., in any quasi-strict equilibrium there is at least one player who
randomizes over some of his actions.

Although ranking games may have pure Nash equilibria, it seems as if most of them possess non-pure equilibria as well,
i.e., mixed strategy equilibria where at least one player randomizes. We prove this claim for three subclasses of ranking
games.

Theorem 1. The following classes of ranking games always possess at least one non-pure equilibrium:

(i) two-player ranking games,
(ii) three-player single-winner games where each player has two actions, and
(iii) n-player single-winner games where the security level of at least two players is positive.

∗

∗

∗

Proof. Statement (i) follows from Fact 1 and the existence result by Norde [26]. For reasons of completeness, we give
a simple alternative proof. Assume for contradiction that there is a two-player ranking game that only possesses pure
in which player 1 wins. Since player 2 must
equilibria and consider, without loss of generality, a pure equilibrium s
be incapable of increasing his payoff by deviating from s
, player 1 has to win no matter which action the second player
chooses. As a consequence, the strategies in s
remain in equilibrium even if player 2’s strategy is replaced with an arbitrary
randomization among his actions.

3), where s2

2, c1), where s1

As for (ii), consider a three-player single winner game with actions A1 = {a1, a2}, A2 = {b1, b2}, and A3 = {c1, c2}. Assume
for contradiction that there are only pure equilibria in the game and consider, without loss of generality, a pure equilibrium
∗ = (a1, b1, c1) in which player 1 wins. In the following, we say that a pure equilibrium is semi-strict if at least one player
s
strictly prefers his equilibrium action over all his other actions given that the other players play their equilibrium actions.
In single-winner games, this player has to be the winner in the pure equilibrium. We ﬁrst show that if s
is semi-strict,
i.e., player 1 does not win in action proﬁle (a2, b1, c1), then there must exist a non-pure equilibrium. For this, consider the
strategy proﬁle s1 = (a1, s1
2 is the uniform mixture of player 2’s actions b1 and b2, along with the strategy
proﬁle s2 = (a1, b1, s2
3 is the uniform mixture of the actions c1 and c2 of player 3. Since player 1 does not win in
(a2, b1, c1), he has no incentive to deviate from either s1 or s2 even if he wins in (a2, b2, c1) and (a2, b1, c2). Consequently,
player 3 must win in (a1, b2, c2) in order for s1 not to be an equilibrium. Analogously, for s2 not to be an equilibrium,
player 2 has to win in the same action proﬁle (a1, b2, c2), contradicting the assumption that the game is a single-winner
is
game. Thus, the existence of a semi-strict pure equilibrium implies that of a non-pure equilibrium. Now assume that s
not semi-strict. When any of the action proﬁles in B = {(a2, b1, c1), (a1, b2, c1), (a1, b1, c2)} is a pure equilibrium, this also
yields a non-pure equilibrium because two pure equilibria that only differ by the action of a single player can be combined
into inﬁnitely many mixed equilibria. For B not to contain any pure equilibria, there must be (exactly) one player for
every proﬁle in B who deviates to a proﬁle in C = {(a2, b2, c1), (a2, b1, c2), (a1, b2, c2)} because the game is a single-winner
is not semi-strict. Moreover, either player 1 or player 2 wins in (a2, b2, c1), player 2 or player 3 in
game and because s
(a1, b2, c2), and player 1 or player 3 in (a2, b1, c2). This implies two facts. First, the action proﬁle s3 = (a2, b2, c2) is a pure
equilibrium because no player will deviate from s3 to any proﬁle in C . Second, the player who wins in s3 strictly prefers
the equilibrium outcome over the corresponding action proﬁle in C , implying that s3 is semi-strict. The above observation
that every semi-strict equilibrium also yields a non-pure equilibrium completes the proof.

∗

∗

∗

As for (iii), recall that the payoff a player obtains in equilibrium must be at least his security level. Thus, a positive
security level for player i rules out all equilibria in which player i receives payoff zero, in particular all pure equilibria
in which he does not win. If there are two players with positive security levels, both of them have to win with positive
probability in any equilibrium of the game. In single-winner games, this can only be the case in a non-pure equilibrium. (cid:2)

We conjecture that this existence result in fact applies to the class of all single-winner games. It does not extend,
however, to general ranking games. Starting from the three-player game of van Damme [38] that possesses no quasi-strict
equilibrium and adding actions that are strongly dominated, it is possible to construct a ranking game with ﬁve players that
only has pure equilibria.

In Nash equilibrium the players randomize among their actions independently from each other. Aumann [5] introduced
the notion of a correlated strategy, where players are allowed to coordinate their actions by means of a device or agent
that randomly selects one of several action proﬁles and recommends the actions of this proﬁle to the respective players.
Formally, the set of correlated strategies is deﬁned as Δ( A1 × · · · × An). The corresponding equilibrium concept is then
deﬁned as follows.

Deﬁnition 7 (Correlated equilibrium). A correlated strategy μ ∈ Δ( A) is called a correlated equilibrium if for all i ∈ N and all
∗
i , ai ∈ Ai ,
a
(cid:3)

μ(a−i, a

a−i ∈ A−i

(cid:4)
∗
i )

pi(a−i, a

(cid:5)
∗
i ) − pi(a−i, ai)

(cid:2) 0.

228

F. Brandt et al. / Artiﬁcial Intelligence 173 (2009) 221–239

In other words, a correlated equilibrium of a game is a probability distribution μ over the set of action proﬁles, such
∗ ∈ A is chosen according to this distribution, and every player i ∈ N is only informed
∗
i , given that he only knows the conditional distribution
∗
−i . Correlated equilibrium assumes the existence of a trusted third party who can recommend behavior but

∗
i , it is optimal in expectation for i to play a

that, if a particular action proﬁle a
about his own action a
over values of a
cannot enforce it.

It can easily be seen that every Nash equilibrium naturally corresponds to a correlated equilibrium. Nash’s existence
result thus carries over to correlated equilibria. Again consider the game of Fig. 1. The correlated strategy that assigns prob-
ability 0.25 each to action proﬁles (a1, b1, c1), (a1, b2, c1), (a2, b1, c1), and (a2, b1, c2) is a correlated equilibrium in which
the expected payoff is 0.5 for player 1 and 0.25 for players 2 and 3. In this particular case, the correlated equilibrium is a
convex combination of Nash equilibria, and correlation can be achieved by means of a publicly observable random variable.
Perhaps surprisingly, Aumann [5] has shown that in general the (expected) social welfare of a correlated equilibrium may
exceed that of every Nash equilibrium, and that correlated equilibrium payoffs may in fact be outside the convex hull of the
Nash equilibrium payoffs. This is of course not possible if social welfare is identical in all outcomes, as is the case in our
example.

6. Solving ranking games

The question we will try to answer in this section is whether the rather speciﬁc payoff structure of ranking games
makes it possible to compute instances of common solution concepts more eﬃciently than in general games. For this
reason, we focus on solution concepts that are known to be intractable for general games, namely (mixed) Nash equilibria [9,
12], iterated weak dominance [10], and pure Nash equilibria in circuit form games [34]. Graphical games, in which pure Nash
equilibria are also known to be intractable [13], are of very limited use for representing ranking games. If two players are not
connected by the neighborhood relation, either directly or via a common player in their neighborhood, then their payoffs are
completely independent from each other. For a single-winner game with the reasonable restriction that every player wins in
at least one outcome, this implies that there must be one designated player who alone decides which player wins the game.
Similar properties hold for arbitrary ranking games. For iterated strong dominance [10] or correlated equilibria [28] eﬃcient
algorithms exist for general games, and a fortiori also for ranking games. Thus there is no further need to consider these
solution concepts here. When in the following we refer to the hardness of a game we mean NP-hardness or PPAD-hardness
of solving the game using a particular solution concept.

6.1. Mixed Nash equilibria

Let us ﬁrst consider Nash equilibria of games with a bounded number of players. Two-player ranking games only allow
outcomes (1, 0) and (0, 1) and thus constitute a subclass of constant-sum games. Nash equilibria of constant-sum games
can be found by linear programming (see, e.g., [37]), for which there is a polynomial time algorithm [16].

To prove hardness for the case with more than two players, it suﬃces to show that three-player ranking games are at
least as hard to solve as general rational bimatrix games. To appreciate this, observe that any n-player ranking game can be
turned into an (n + 1)-player ranking game by adding a player who has only one action at his disposal and who is invariably
ranked last, keeping relative rankings of the other players intact. Nash equilibria of the (n + 1)-player game then naturally
correspond to Nash equilibria of the n-player game. A key concept in our proof is that of a Nash homomorphism, a notion
introduced by Abbott et al. [1]. We generalize their deﬁnition to games with more than two players.

Deﬁnition 8 (Nash homomorphism). A Nash homomorphism is a mapping h from a set of games into a set of games, such that
there exists a polynomial-time computable function f that, when given a game Γ and an equilibrium s
of h(Γ ), returns
an equilibrium f (s

∗) of Γ .

∗

Obviously, the composition of two Nash homomorphisms is again a Nash homomorphism. Furthermore, any sequence
of polynomially many Nash homomorphisms that maps some class of games to another class of games provides us with a
polynomial-time reduction from the problem of ﬁnding Nash equilibria in the former class to ﬁnding Nash equilibria in the
latter. Any eﬃcient, i.e., polynomial-time, algorithm for the latter directly leads to an eﬃcient algorithm for the former. On
the other hand, hardness of the latter implies hardness of the former.

A very simple example of a Nash homomorphism is the one that scales the payoff of each player by means of a positive
aﬃne transformation. It is well-known that Nash equilibria are invariant under this kind of mapping, and f can be taken
to be the identity. We will now combine this Nash homomorphism with a more sophisticated function, which maps payoff
proﬁles of a two-player binary game to corresponding three-player subgames with two actions for each player, and obtain
Nash homomorphisms from rational bimatrix games to three-player ranking games with different rank payoff proﬁles.

Lemma 1. For every rank payoff proﬁle, there exists a Nash homomorphism from the set of rational bimatrix games to the set of
three-player ranking games.

F. Brandt et al. / Artiﬁcial Intelligence 173 (2009) 221–239

229

Proof. Abbott et al. [1] have shown that there is a Nash homomorphism from rational bimatrix games to bimatrix games
with payoffs 0 and 1 (called binary games in the following). Since a composition of Nash homomorphisms is again a Nash
homomorphism, we only need to provide a homomorphism from binary bimatrix games to three-player ranking games.
Furthermore, outcome (1, 1) is Pareto-dominant and therefore constitutes a pure Nash equilibrium in any binary game (no
player can beneﬁt from deviating). Instances containing such an outcome are easy to solve and need not be considered in
our mapping.

In the following, we denote by (1, p2

i is ranked ﬁrst, j is ranked second, and k is ranked last. First of all, consider ranking games where p2
i ∈ N, i.e., the class of all ranking games except single-loser games.

i , 0) be the rank payoff vector of player i, and by [i, j, k] the outcome where player
i < 1 for some player

Without loss of generality let i = 1. Then, a Nash homomorphism from binary bimatrix games to the aforementioned

class of games can be obtained by ﬁrst transforming the payoffs according to
(cid:5)

(x1, x2) (cid:7)−→

(cid:4)
(1 − p2

1)x1 + p2

1, x2

and then adding a third player who only has a single action and whose payoff is chosen such that the resulting game is a
ranking game (but is otherwise irrelevant). We obtain the following mapping, which is obviously a Nash homomorphism:

(0, 0) (cid:7)−→ (p2
1, 0) (cid:7)−→ [3, 1, 2]
(1, 0) (cid:7)−→ (1, 0) (cid:7)−→ [1, 3, 2]
(0, 1) (cid:7)−→ (p2

1, 1) (cid:7)−→ [2, 1, 3].

Interestingly, three-player single-loser games with only one action for some player i ∈ N are easy to solve because either

• there is an outcome in which i is ranked last and the other two players both receive their maximum payoff of 1 (i.e., a

Pareto-dominant outcome), or

• i is not ranked last in any outcome, such that the payoffs of the other two players always sum up to 1 and the game is

equivalent to a two-player constant-sum game.

If the third player is able to choose between two different actions, however, binary games can be mapped to single-loser
games. For this, consider the mapping from binary bimatrix games to three-player single-loser games shown in Fig. 5. As a
ﬁrst step, binary bimatrix games are mapped to three-player constant-sum games according to

(cid:6)

(cid:7)

(x1, x2) (cid:7)−→

1

2

(x1 + 1),

1

2

(x2 + 1), 1 − 1
2

(x1 + x2)

.

The ﬁrst two players and their respective sets of actions are the same as in the original game, the third player only has one
action c. It is again obvious that this constitutes a Nash homomorphism. Next, outcomes of the three-player constant-sum
game are replaced by three-player single-loser subgames. Let Γ be a binary game, and denote by Γ (cid:5)
the three-
player constant-sum game and the three-player single-loser game, respectively, obtained by applying the two steps of the
, respectively, and a1
mapping in Fig. 5 to Γ . We further write p
i
i for the two actions of player i in Γ (cid:5)(cid:5)
and a2

(cid:5)
i , and p
corresponding to an action ai in Γ (cid:5)
The second part of the mapping in Fig. 5 is chosen such that for all strategy proﬁles s, all players i and all actions ai ∈ Ai

for the payoff function of player i in Γ (cid:5)

and Γ (cid:5)(cid:5)

and Γ (cid:5)(cid:5)

(cid:5)(cid:5)
i

.

in Γ (cid:5)

we have
1

(cid:5)(cid:5)
i (a1

i , s−i) + 1

p

2

2

(cid:5)(cid:5)
i (a2

i , s−i) = p

(cid:5)
i

p

(cid:4)
ai, f (s)−i

(cid:5)
,

(1)

Fig. 5. Mapping from binary bimatrix games to three-player single-loser games.

230

F. Brandt et al. / Artiﬁcial Intelligence 173 (2009) 221–239

where for each strategy proﬁle s of Γ (cid:5)(cid:5)
action ai ∈ Ai

,

f (s)(ai) = si(a1

i ) + si(a2
i ).

f (s) is the strategy proﬁle in Γ (cid:5)

such that for each player i ∈ {1, 2, 3} and each

∗

∗

s

(a1

Let s

An important consequence of this fact is that each player can guarantee his payoff in Γ (cid:5)(cid:5)
other players, to be at least as high as his payoff under the corresponding strategy proﬁle in Γ (cid:5)
on ai uniformly on a1

i and a2
i .
be a Nash equilibrium in Γ (cid:5)(cid:5)
∗
−i) + s

(cid:5)(cid:5)
i (a1

(cid:5)(cid:5)
i (a2

. We ﬁrst prove that for every player i ∈ {1, 2, 3} and each action ai of player i in Γ (cid:5)
∗
−i) =
Recall that we write s(ai) for the probability of action ai in strategy proﬁle s, so f (s
is played in strategy proﬁle f (s
∗
in equilibrium s
contradiction that for some player i and some action ai ∈ Ai ,
(a2

(2)
∗)(ai) is the probability with which ai
i and a2
i
. To see this, ﬁrst assume for

. The above equation thus states that the expected joint payoff from a1

equals that from ai under the corresponding strategy proﬁle f (s

(cid:4)
ai, f (s

(cid:5)
)(ai)

∗) of Γ (cid:5)

∗) of Γ (cid:5)

, for any strategy proﬁle of the
, by distributing the weight

i )p

i )p

i , s

i , s

(cid:5)
,

(a2

(a1

(cid:5)
.

(cid:4)
ai, f (s

)−i

)−i

f (s

f (s

p

(cid:4)

(cid:4)

(cid:5)
i

s

∗

∗

∗

∗

∗

∗

∗

,

(cid:5)(cid:5)
i (a2

i , s

∗
−i) <

∗
−i) + s

(cid:5)(cid:5)
i (a1

i , s

i )p

i )p

i and a2
such that si(a1

i

is strictly smaller than the expected payoff from ai in Γ (cid:5)
i )) and si(a

(cid:5)
i) for all actions a

. Deﬁne si
(cid:5)
∈ Ai
i

i ) = 1

(cid:5)
i) = s

i ) + s

∗(a1

∗(a2

∗(a

2 (s

(cid:5)
i

p

(cid:5)
)(ai)
in Γ (cid:5)(cid:5)
i ) = si(a2

∗

s

(a1

i . It then holds that

i.e., that the expected joint payoff from a1
to be the strategy of player i in Γ (cid:5)(cid:5)
i and a2
distinct from a1
∗
−i) + s
i , s
(cid:4)
(cid:5)
(cid:5)
ai, f (s
)(ai)
p
i
(cid:5)
(cid:4)
∗
(cid:5)
i ) + s
(a2
i )
ai, f (s
p
i
(cid:6)
(cid:5)
(a2
i )

(cid:5)(cid:5)
i (a2
i , s
(cid:5)
)−i

(cid:5)(cid:5)
i (a1
∗
f (s
∗

i )p
(cid:4)
<

i ) + s

i )p
∗

(cid:5)(cid:5)
i (a1

∗
−i)

i , s

(a2

(a1

(a1

=

=

1

p

(cid:5)

(cid:4)

(cid:4)

s

s

∗

∗

∗

∗

2

∗

)−i
−i) + 1
2
(cid:4)

(cid:7)

(cid:5)(cid:5)
i (a2

i , s

∗
−i)

p

(cid:4)

∗

s

= 1
2
= si(a1

(a1

∗

i ) + s
(cid:5)(cid:5)
i (a1

i , s

∗

p

(cid:5)
(a2
i )

(cid:5)(cid:5)
i (a1
∗
−i) + si(a2

−i) + 1
i , s
(cid:5)(cid:5)
i (a2
i , s

i )p

2
∗
−i).

∗

s

i )p

(a1

i ) + s

∗

(cid:5)
(a2
i )

(cid:5)(cid:5)
i (a2

i , s

∗
−i)

p

The second and last step follow from the deﬁnition of f and si , respectively. The third step follows from (1). We conclude
∗
that player i obtains a higher payoff by playing si instead of s
is a Nash equilibrium.
i , contradicting the assumption that s
In particular we have shown that for all i ∈ N and every ai ∈ Ai ,
(cid:5)(cid:5)
i (a2

(cid:4)
ai, f (s

(cid:5)
)(ai)

∗
−i) + s

∗
−i) (cid:2)

(cid:5)(cid:5)
i (a1

i )p

i )p

i , s

i , s

(a1

(a2

(cid:5)
.

)−i

f (s

(3)

p

(cid:4)

(cid:5)
i

s

∗

∗

∗

∗

∗

Now assume, again for contradiction, that for some player i and some action ai ∈ Ai ,
(cid:4)

∗

∗

∗

s

(a2

(a1

i , s

i , s

i )p

i )p

(cid:5)(cid:5)
i (a1

(cid:5)(cid:5)
i (a2

∗
−i) >

∗
−i) + s
i and a2
i.e., that the expected joint payoff to i from a1
than the expected payoff from ai
∗) cannot be greater than the
in Γ (cid:5)
. It follows from (3) that the expected payoff player i receives from any action under f (s
(cid:5)
∗)). Since Γ (cid:5)
∗) > p
i( f (s
are
expected joint payoff from the corresponding pair of actions under s
∗)
∗
both constant-sum games, there exists some player j (cid:8)= i who receives strictly less payoff under s
in Γ (cid:5)

is strictly greater under s

(cid:5)
i
in Γ (cid:5)(cid:5)

than under f (s

, and thus p

and Γ (cid:5)(cid:5)

in Γ (cid:5)(cid:5)

(cid:5)(cid:5)
i (s

)−i

f (s

p

∗

∗

∗

i

(cid:5)
)(ai)

(cid:4)
ai, f (s

(cid:5)
,

. In particular, there has to be an action a j ∈ A j such that
(cid:5)(cid:5)
j (a2

(cid:5)
)(a j)

∗
− j) + s

∗
− j) <

(cid:5)(cid:5)
j (a1

(cid:4)
a j, f (s

j )p

j )p

j , s

j , s

(a1

(a2

f (s

(cid:5)
j

p

(cid:4)

s

∗

∗

∗

(cid:5)
,

∗

)− j

contradicting (3).

We are now ready to prove that the mapping in Fig. 5 is indeed a Nash homomorphism. To this end, let s

Nash equilibrium of Γ (cid:5)(cid:5)
be a player i and some action ai ∈ Ai such that p
(cid:5)(cid:5)
i (si, s−i) = p
that si(a1
(cid:5)
i( f (s
p

, and assume for a contradiction that f (s
∗)). Deﬁne si to be the strategy of i in Γ (cid:5)(cid:5)
∗)−i) > p
(cid:5)(cid:5)
∗)−i). It further follows from (2) that for all players i, p
i (s

∗) is not a Nash equilibrium of Γ (cid:5)
(cid:5)
i( f (s

(cid:5)
i(ai, f (s
(cid:5)
i(ai, f (s

2 . Then, by (1), p

i ) = si(a2

be a
. Then there has to
such
∗) =

i ) = 1

∗

∗)). Thus,
∗
(cid:5)(cid:5)
i (s

) = p

p

(cid:5)
i

(cid:4)

(cid:5)
)

∗

f (s

< p

(cid:5)
i

(cid:4)
ai, f (s
∗

(cid:5)

∗

= p

(cid:5)(cid:5)
i (s

(cid:5)
)−i
i, s
is a Nash equilibrium in Γ (cid:5)(cid:5)

∗
−i),

. (cid:2)

contradicting the assumption that s

The ground has now been cleared to present the main result of this section concerning the hardness of computing
Nash equilibria of ranking games. Since every normal-form game is guaranteed to possess a Nash equilibrium in mixed
strategies [25], the decision problem as to the existence of Nash equilibria is trivial. However, the associated search problem

F. Brandt et al. / Artiﬁcial Intelligence 173 (2009) 221–239

231

Fig. 6. Iterated weak dominance solvability in two-player ranking games.

turns out to be not at all trivial. In fact, it has recently been shown to be PPAD-complete for general bimatrix games [9,12].
TFNP (for “total functions in NP”) is the class of search problems guaranteed to have a solution. As Daskalakis et al. [12]
put it, “this is precisely NP with an added emphasis on ﬁnding a witness.” TFNP is further divided into subclasses based on
the mathematical argument used to establish the existence of a solution. PPAD (for “polynomial parity argument, directed
version”) is one such subclass that is believed not to be contained in P. For this reason, the PPAD-hardness of a particular
problem can be seen as “a rather compelling argument for intractability” [29, p. 39].

Theorem 2. Computing a Nash equilibrium of a ranking game with more than two players is PPAD-hard for any rank payoff proﬁle.
If there are only two players, equilibria can be found in polynomial time.

Proof. According to Lemma 1, ranking games with more than two players are at least as hard to solve as general two-player
games. We already know that solving general games is PPAD-hard in the two-player case [9].

Two-player ranking games, on the other hand, form a subclass of two-player zero-sum games, in which Nash equilibria

can be found eﬃciently via linear programming. (cid:2)

6.2. Iterated weak dominance

We now turn to iterated weak dominance. If there are only two players, the problem of deciding whether a ranking

game can be solved via iterated weak dominance is tractable.

Theorem 3. For two-player ranking games, iterated weak dominance solvability can be decided in polynomial time.

∗
1, a

Proof. First we recall that if an action in a binary game is weakly dominated by a mixed strategy, it is also dominated by
a pure strategy [10]. Accordingly, we only have to consider dominance by pure strategies. Now consider a path of iterated
∗
2). Without loss of generality we may assume that player 1 (i.e.,
weak dominance that ends in a single action proﬁle (a
∗
1, a2) for any a2 ∈ A2, i.e., in the entire
the row player) is the winner in this proﬁle. This implies that player 1 wins in (a
row. For a contradiction, assume the opposite and consider the particular action a1
2) and
2 such that player 2 wins in (a
a1
2 is eliminated last on the path that solves the game. It is easy to see that a1
2 could not have been eliminated in this case.
∗
An elimination by player 1 would also eliminate a
1, while an elimination by player 2 could only take place via another
action a2
2 such that player 2 also wins in (a
2 is eliminated last. We now claim
∗
that a ranking game with two players is solvable by iterated weak dominance if and only if there exists a unique action a
1
∗
of player 1 by which he always wins, and an action a
2 of player 2 by which he wins for a strictly maximal set of actions
of player 1. More precisely, the latter property means that there exists a set of actions of player 1 against which player 2
∗
always wins when playing a
2 and loses in at least one case for every other action he might play. This is illustrated in Fig. 6,
and can be veriﬁed eﬃciently by ordering the aforementioned sets of actions of player 1 according to strict inclusion. If the
ordering does not have a maximal element, the game cannot be solved by means of iterated weak dominance. If it does,
∗
2 can eliminate all
we can use a
∗
1 eliminates player 1’s remaining actions and solves the game.4 (cid:2)
other actions of player 2, until ﬁnally a

∗
1 to eliminate all actions a1 ∈ A1 such that player 2 does not win in (a1, a

2), contradicting the assumption that a1

∗
2), whereupon a

∗
1, a1

∗
1, a2

4 Since two-player ranking games are a subclass of constant-sum games, weak dominance and nice weak dominance [21] coincide, making iterated weak
dominance order independent up to payoff-equivalent action proﬁles. This fact is mirrored by Fig. 6, since there cannot be a row of 1s and a column of 2s in
the same matrix.

232

F. Brandt et al. / Artiﬁcial Intelligence 173 (2009) 221–239

Theorem 4. For ranking games with more than two players, and for any rank payoff proﬁle, deciding iterated weak dominance solv-
ability is NP-complete.

Proof. Membership in NP is immediate. We can simply guess a sequence of eliminations and then verify in polynomial time
that this sequence is valid and solves the game.

For hardness, we ﬁrst reduce eliminability in binary bimatrix games, which asks whether there exits a sequence of elim-
inations that contains a given action and has recently been shown to be NP-hard [10], to the same problem in ranking
games. A game Γ of the former class is mapped to a ranking game Γ (cid:5)

as follows:

• Γ (cid:5)
features the two players of Γ , denoted by 1 and 2, and an additional player 3.
• Players 1 and 2 have the same actions as in Γ , player 3 has two actions c1 and c2.
• Payoffs of Γ are mapped to rankings of Γ (cid:5)

according to

(0, 0) (cid:7)−→ [3,2,1]

[3,1,2]

(1, 0) (cid:7)−→ [1,2,3]

[3,1,2]

(0, 1) (cid:7)−→ [3,2,1]

[2,1,3]

(1, 1) (cid:7)−→ [1,2,3]

[2,1,3]

In the following, we write p and p

(cid:5)

for the payoff functions of Γ and Γ (cid:5)

, respectively.

First observe that we can restrict our attention to dominance by pure strategies. This property holds for binary games by
Lemma 1 of Conitzer and Sandholm [10], and thus also for actions of player 3, who receives a payoff of either 0 or 1 in
any outcome. For players 1 and 2 we can essentially apply the same argument, because each of them can obtain only two
different payoffs for any ﬁxed action proﬁle of the remaining two players.

We now claim that irrespective of the rank payoffs pi = (1, p2

(cid:5)
1(a1, a2, c1) = p1(a1, a2), whereas player 2 receives a payoff of p2

i , 0), and for any subsets of the actions of players 1 and 2,
a particular action of these players is dominated in the restriction of Γ (cid:5)
to these subsets if and only if the corresponding
action is dominated in the restriction of Γ to the same subsets. To see this, observe that if player 3 plays c1, then for any
action proﬁle (a1, a2) ∈ A1 × A2, player 1 receives the same payoff he would receive for the corresponding action proﬁle
2. If on the other hand player 3 plays c2, then
in Γ , i.e., p
1, and the payoff of player 2 for any action proﬁle (a1, a2) ∈ A1 × A2 is the same as that for
player 1 obtains a payoff of p2
(cid:5)
2(a1, a2, c2) = p2(a1, a2). Moreover, the implication from left to right still holds if one
the corresponding proﬁle in Γ , i.e., p
of the actions of player 3 is removed, because this leaves one of players 1 and 2 indifferent between all of his remaining
actions but does not have any effect on dominance between actions of the other player. We have thus established a direct
correspondence between sequences of eliminations in Γ and Γ (cid:5)
, which in turn implies NP-hardness of deciding whether a
particular action of a ranking game with at least three players can be eliminated.

It also follows from the above that Γ can be solved by iterated weak dominance if Γ (cid:5)

can. The implication in the other
direction does not hold, however, because it may not always be possible to eliminate an action of player 3. To this end,
assume without loss of generality that some player of Γ (cid:5)
has at least two actions, and that this player is player 1. Otherwise
both Γ and Γ (cid:5)
by introducing to player 1’s action set A1 = {a1, . . . , am} an additional
action am+1 of player 1 such that for every action b j of player 2, g(am+1, b j, c1) = [3, 2, 1] and g(am+1, b j, c2) = [2, 1, 3].
The structure of the resulting game is shown in Fig. 7.

are trivially solvable. We augment Γ (cid:5)

It is easily veriﬁed that the above arguments about Γ (cid:5)

still apply, because player 1 never receives a higher payoff
from am+1 than from any other action, and player 2 is indifferent between all of his actions when player 1 plays am+1.
Now assume that Γ can be solved. Without loss of generality we may assume that (a1, b1) is the remaining action proﬁle.
Clearly, for Γ to be solvable, player 1 must be ranked ﬁrst in some outcome of Γ (cid:5)
, and it must hold that p1(a1, b1) = 1 or
p2(a1, b1) = 1. We distinguish two cases. If p1(a1, b1) = p2(a1, b1) = 1, then Γ (cid:5)
can be solved by performing the elimina-
tions that lead to the solution of Γ , followed by the elimination of c2 and am+1. Otherwise we can start by eliminating am+1,
which is dominated by the action for which player 1 is sometimes ranked ﬁrst, and proceed with the eliminations that

Fig. 7. Three-player ranking game Γ (cid:5)

used in the proof of Theorem 4.

F. Brandt et al. / Artiﬁcial Intelligence 173 (2009) 221–239

233

solve Γ . In the two action proﬁles that then remain Player 3 is ranked ﬁrst and last, respectively, and he can eliminate one
of his actions to solve Γ (cid:5)

. (cid:2)

6.3. Pure Nash equilibria in games with many players

We now consider the situation in which players do not randomize but choose their actions deterministically. Nash equi-
libria in pure strategies can be found eﬃciently by simply checking every action proﬁle. As the number of players increases,
however, the number of proﬁles to check, as well as the normal-form representation of the game, grows exponentially. An
interesting question is whether pure equilibria can be computed eﬃciently given a succinct representation of a game that
only uses space polynomial in n.

We proceed to show that this is most likely not the case. More precisely, we show NP-completeness of deciding whether
there is a pure Nash equilibrium in ranking games with eﬃciently computable outcome functions, which is one of the most
general representations of multi-player games one might think of. Please note that, in contrast to Theorems 2 and 4, we
keep the number of actions ﬁxed and let the number of players grow.

Theorem 5. For ranking games with an unbounded number of players and a polynomial-time computable outcome function, and for
any rank payoff proﬁle, deciding the existence of a pure Nash equilibrium is NP-complete, even if the players have only two actions at
their disposal.

Proof. Since we can check in polynomial time whether a particular player strictly prefers one rank over another, membership
in NP is immediate. We can guess an action proﬁle s and verify in polynomial time whether s is a Nash equilibrium. For
the latter, we check for each player i ∈ N and for each action ai ∈ Ai whether pi(s−i, ai) (cid:3) pi(s).

For hardness, recall that circuit satisﬁability (CSAT), i.e., deciding whether for a given Boolean circuit ϕ with n inputs
and 1 output there exists an input such that the output is true, is NP-complete (see, e.g. [27]). We deﬁne a game Γ in
circuit form for a Boolean circuit ϕ, providing a polynomial-time reduction of satisﬁability of ϕ to the problem of ﬁnding a
pure Nash equilibrium in Γ .

Let m be the number of inputs of ϕ. We deﬁne game Γ with m + 2 players as follows:

• Let N = {1, . . . , m} ∪ {x, y}, and Ai = {0, 1} for all i ∈ N.
• The outcome function of Γ is computed by a Boolean circuit that takes m + 2 bits of input i = (a1, . . . , am, ax, a y), cor-
responding to the actions of the players in N, and computes two bits of output o = (o1, o2), given by o1 = ϕ(a1, . . . , am)
and o2 = (o1OR(axXORa y)).

• The possible outputs of the circuit are identiﬁed with permutations (i.e., rankings) of the players in N such that

· the permutation π00 corresponding to o = (0, 0) and the permutation π11 corresponding to o = (1, 1) rank x ﬁrst and

y last,

· the permutation π01 corresponding to o = (0, 1) ranks y ﬁrst, and x last, and
· all other players are ranked in the same order in all three permutations.
It should be noted that no matter how permutations are actually encoded as strings of binary values, the encoding of
the above permutations can always be computed using a polynomial number of gates.

We claim that, for arbitrary rank payoffs, Γ has a pure Nash equilibrium if and only if ϕ is satisﬁable. This can be seen as
follows:

• If (a1, . . . , am) is a satisfying assignment of ϕ, only a player in {1, . . . , m} could possibly change the outcome of the
game by changing his action. However, these players are ranked in the same order in all the possible outcomes, so
none of them can get a higher payoff by doing so. Thus, every action proﬁle a = (a1, . . . , am, ax, a y) where (a1, . . . , am)
satisﬁes ϕ is a Nash equilibrium.

• If in turn (a1, . . . , am) is not a satisfying assignment of ϕ, both x and y are able to switch between outcomes π00 and
π01 by changing their individual action. Since every player strictly prefers being ranked ﬁrst over being ranked last, x
strictly prefers outcome π00 over π01, while y strictly prefers π01 over π00. Thus, a = (a1, . . . , am, ax, a y) cannot be a
Nash equilibrium in this case, since either x or y could play a different action to get a higher payoff. (cid:2)

7. Comparative ratios

Despite its conceptual elegance and simplicity, Nash equilibrium has been criticized on various grounds (see, e.g., [18]
for a discussion). In the common case of multiple equilibria, it is unclear which one should be selected. Also, coalitions
might beneﬁt from jointly deviating, and there might exist no polynomial-time, i.e., eﬃcient, algorithms for ﬁnding Nash
equilibria, a problem we discussed in the previous section. Moreover, players may be utterly indifferent among equilibrium
and non-equilibrium strategies, which we saw is pervasive in ranking games.

234

F. Brandt et al. / Artiﬁcial Intelligence 173 (2009) 221–239

Fig. 8. Three-player ranking game Γ1 used in the proof of Theorem 6.

7.1. The price of cautiousness

A compelling question is how much worse off a player can be when if he were to revert to his most defensive course of
action—his maximin strategy—instead of hoping for an equilibrium outcome. This difference in payoff can be represented by
a numerical value which we refer to as the price of cautiousness. In what follows, let G denote the class of all normal-form
games, and for Γ ∈ G, let N(Γ ) be the set of Nash equilibria of Γ . Recall that v i(Γ ) denotes player i’s security level in
game Γ .

Deﬁnition 9. Let Γ be a normal-form game with non-negative payoffs, i ∈ N a player such that v i(Γ ) > 0. The price of
cautiousness for player i in Γ is deﬁned as

PCi(Γ ) = min{pi(s) | s ∈ N(Γ )}

v i(Γ )

.

For any class C ⊆ G of games involving player i, we further write PCi(C) = supΓ ∈C PCi(Γ ). In other words, the price
of cautiousness of a player is the ratio between his minimum payoff in a Nash equilibrium and his security level. It thus
captures the worst-case loss the player may incur by playing his maximin strategy instead of a Nash equilibrium.5 For a
player whose security level equals his minimum payoff of zero, every strategy is a maximin strategy. Since we are mainly
interested in a comparison of normative solution concepts, we will only consider games where the security level of at least
one player is positive.

As we have already mentioned in Section 1, the price of cautiousness in two-player ranking games equals 1 in virtue of

the Minimax Theorem of von Neumann [40]. In general ranking games, however, the price of cautiousness is unbounded.

Theorem 6. Let R be the class of ranking games with more than two players that involve player i. Then, the price of cautiousness is
unbounded, i.e., PCi(R) = ∞, even if R only contains games without weakly dominated actions.

Proof. Consider the game Γ1 of Fig. 8, which is a ranking game for rank payoff vectors (cid:6)p1 = (1, (cid:7), 0), (cid:6)p2 = (1, 0, 0), and
(cid:6)p3 = (1, 1, 0), and rankings [2, 3, 1], [1, 3, 2], [1, 2, 3], [2, 1, 3], and [3, 1, 2]. It is easily veriﬁed that none of the actions
of Γ1 is weakly dominated and that v 1(Γ1) = (cid:7). Let further s = (s1, s2, c1) be the strategy proﬁle where s1 and s2 are
uniform mixtures of a1 and a2, and of b1 and b2, respectively. We will argue that s, is the only Nash equilibrium of Γ1.
For this, consider the possible strategies of player 3. If player 3 plays c1, the game reduces to the well-known matching
pennies game for players 1 and 2, the only Nash equilibrium being the one described above. If on the other hand player 3
plays c2, action b1 strongly dominates b2. If b1 is played, however, player 3 will deviate to c1 to get a higher payoff. Finally,
if player 3 randomizes between actions c1 and c2, the payoff obtained from both of these actions must be the same. This
can only be the case if either player 1 plays a1 and player 2 randomizes between b1 and b2, or if player 1 plays a2 and
player 2 plays b2. In the former case, player 2 will deviate to b1. In the latter case, player 1 will deviate to a1. Since the
payoff of player 1 in the above equilibrium is 0.5, we have PC(Γ1) = 0.5/(cid:7) → ∞ for (cid:7) → 0. (cid:2)

We proceed to show that, due to their structural limitations, the price of cautiousness in binary ranking games is bounded

from above by the number of actions of the respective player. We also derive a matching lower bound.

Theorem 7. Let Rb be the class of binary ranking games with more than two players involving a player i with exactly k actions. Then,
PCi(Rb) = k, even if Rb only contains single-winner games or games without weakly dominated actions.

Proof. By deﬁnition, the price of cautiousness takes its maximum for maximum payoff in a Nash equilibrium, which is
bounded by 1 in a ranking game, and minimum security level. It being required that the security level is strictly positive,
for every opponent action proﬁle s−i there is some action ai ∈ Ai such that pi(ai, s−i) > 0, i.e., pi(ai, s−i) = 1. It is then

5 In our context, the choice of whether to use the worst or the best equilibrium when deﬁning the price of cautiousness is merely a matter of taste. All

results in this section still hold when the best equilibrium is used instead of the worst one.

F. Brandt et al. / Artiﬁcial Intelligence 173 (2009) 221–239

235

Fig. 9. Three-player ranking game Γ2 used in the proof of Theorem 7.

easily veriﬁed that player i can ensure a security level of 1/k by uniform randomization over his k actions. This results in a
price of cautiousness of at most k.

For a matching lower bound, again consider the single winner game depicted in Fig. 4. We will argue that all Nash
equilibria of this game are mixtures of the action proﬁles (a2, b1, c2), (a2, b2, c2) and (a1, b2, c2). Each of these equilibria
yields payoff 1 for player 1, twice as much as his security level of 0.5. To appreciate this, consider the strategies that are
possible for player 3. If player 3 plays c1, the game reduces to the well-known game of matching pennies for players 1
and 2, in which they will randomize uniformly over both of their actions. In this case, player 3 will deviate to c2. If player 3
plays c2, we immediately obtain the equilibria described above. Finally, if player 3 randomizes between actions c1 and c2,
the payoff obtained from both of these actions should be the same. This can only be the case if either player 1 plays a2 and
player 2 randomizes between b1 and b2, or if player 1 randomizes between a1 and a2 and player 2 plays b2. In the former
case, player 2 will play b2, causing player 1 to deviate to a1. In the latter case, player 1 will play a1, causing player 2 to
deviate to b1.

The above construction can be generalized to k > 2 by virtue of a single-winner game with actions A1 = {a1, . . . , ak}, A2 =

{b1, . . . , bk}, and A3 = {c1, c2}, and payoffs
⎧
⎨

(0, 1, 0)

p(ai, b j, c(cid:8)) =

(0, 0, 1)

⎩

if (cid:8) = 1 and i (cid:8)= k − j + 1,
if (cid:8) = 2 and i = j = 1,

(1, 0, 0) otherwise.

It is easily veriﬁed that the security level of player 1 in this game is 1/k while, by the same arguments as above, his
payoff in every Nash equilibrium equals 1. This shows tightness of the upper bound of k on the price of cautiousness for
single-winner games.

Now consider the game Γ2 of Fig. 9, which is a ranking game for rank payoff vectors (cid:6)p1 = (cid:6)p2 = (1, 0, 0) and (cid:6)p3 = (1, 1, 0),
and rankings [2, 3, 1], [1, 2, 3], [2, 1, 3], and [1, 3, 2]. It is easily veriﬁed that none of the actions of Γ2 is weakly dominated
and that v 1(Γ2) = 0.5. On the other hand, we will argue that all Nash equilibria of Γ2 are mixtures of action proﬁles
(a2, b1, c2) and (a2, b2, c2), corresponding to a payoff of 1 for player 1. To see this, we again look at the possible strategies
for player 3. If player 3 plays c1, players 1 and 2 will again randomize uniformly over both of their actions, causing player 3
to deviate to c2. If player 3 plays c2, we immediately obtain the equilibria described above. Finally, assume that player 3
randomizes between actions c1 and c2, and let α denote the probability with which player 1 plays a1. Again, player 3 must
be indifferent between c1 and c2, which can only hold for 0.5 (cid:3) α (cid:3) 1. In this case, however, player 2 will deviate to b1.

This construction can be generalized to k > 2 by virtue of a game with actions A1 = {a1, . . . , ak}, A2 = {b1, . . . , bk}, and

A3 = {c1, c2}, and payoffs

p(ai, b j, c(cid:8)) =

⎧

⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎩

(0, 1, 1)

(1, 0, 0)

(1, 0, 1)

if i = j = (cid:8) = 1,
if (cid:8) = 1 and i = k − j + 1,
or (cid:8) = 2, i = 1 and j > 1,
if (cid:8) = 2 and j > 2,

(0, 1, 0) otherwise.

Again, it is easily veriﬁed that the security level of player 1 in this game is 1/k while, by the same arguments as above, his
payoff is 1 in every Nash equilibrium. Thus, the upper bound of k for the price of cautiousness is tight as well for binary
ranking games without weakly dominated actions. (cid:2)

Informally, the previous theorem states that the payoff a player with k actions can obtain in Nash equilibrium can be at

most k times his security level.

7.2. The value of correlation

We will now turn to the question whether, and by which amount, social welfare can be improved by allowing players
in a ranking game to correlate their actions. Just as the payoff of a player in any Nash equilibrium is at least his security
level, social welfare in the best correlated equilibrium is at least as high as social welfare in the best Nash equilibrium. In
order to quantify the value of correlation in strategic games with non-negative payoffs, Ashlagi et al. [2] recently introduced
the mediation value of a game as the ratio between the maximum social welfare in a correlated versus that in a Nash

236

F. Brandt et al. / Artiﬁcial Intelligence 173 (2009) 221–239

equilibrium, and the enforcement value as the ratio between the maximum social welfare in any outcome versus that in
a correlated equilibrium. Whenever social welfare, i.e., the sum of all players’ payoffs, is used as a measure of global
satisfaction, one implicitly assumes the inter-agent comparability of payoffs. While this assumption is controversial, social
welfare is nevertheless commonly used in the deﬁnitions of comparative ratios such as the price of anarchy [17]. For Γ ∈ G
and X ⊆ Δ(S), let C(Γ ) denote the set of correlated equilibria of Γ and let v X (Γ ) = max{ p(s) | s ∈ X }. Recall that N(Γ )
denotes the set of Nash equilibria in Γ .

Deﬁnition 10. Let Γ be a normal-form game with non-negative payoffs. The mediation value MV(Γ ) and the enforcement
value EV(Γ ) of Γ are deﬁned as
MV(Γ ) = v C(Γ )(Γ )
v N(Γ )(Γ )

and EV(Γ ) = v S (Γ )
v C(Γ )(Γ )

.

If both numerator and denominator are 0 for one of the values, the respective value is deﬁned to be 1. If only the
denominator is 0, the value is deﬁned to be ∞. For any class C ⊆ G of games, we further write MV(C) = supΓ ∈C MV(Γ )
and EV(C) = supΓ ∈C EV(Γ ).

Ashlagi et al. [2] have shown that both the mediation value and the enforcement value cannot be bounded for games
with an arbitrary payoff structure, as soon as there are more than two players or some player has more than two actions.
This holds even if payoffs are normalized to the interval [0, 1]. Ranking games also satisfy this normalization criterion, and
here social welfare is also strictly positive for every outcome of the game. Ranking games with identical rank payoff vectors
j for all i, j ∈ N and 1 (cid:3) k (cid:3) n, are constant-sum games. Hence, social welfare is the
for all players, i.e., ones where pk
i
same in every outcome so that both the mediation value and the enforcement value are 1. This in particular concerns all
ranking games with two players. In general, social welfare in an arbitrary outcome of a ranking game is bounded by n − 1
from above and by 1 from below. Since the Nash and correlated equilibrium payoffs must lie in the convex hull of the
feasible payoffs of the game, we obtain trivial lower and upper bounds of 1 and n − 1, respectively, on both the mediation
and the enforcement value. It turns out that the upper bound of n − 1 is tight for both the mediation value and the
enforcement value.

= pk

Theorem 8. Let R(cid:5)
more than two actions. Then, MV(R(cid:5)) = n − 1.

be the class of ranking games with n > 2 players, such that in games with only three players at least one player has

∗

Proof. It suﬃces to show that for any of the above cases there is a ranking game with mediation value n − 1. For n = 3,
consider the game Γ3 of Fig. 10, which is a ranking game for rank payoff vectors (cid:6)p1 = (cid:6)p3 = (1, 0, 0) and (cid:6)p2 = (1, 1, 0).
First of all, we will show that every Nash equilibrium of this game has social welfare 1, by showing that there are no Nash
equilibria where c1 or c2 are played with positive probability. Assume for contradiction that s
is such an equilibrium. The
must either be (i) c1 or c2 as a pure strategy, (ii) a mixture of c1 and c3 or between c2 and
strategy played by player 3 in s
c3, or (iii) a mixture where both c1 and c2 are played with positive probability. If player 3 plays a pure strategy, the game
reduces to a two-player game for players 1 and 2. In the case of c1, this game has the unique equilibrium (a1, b1), which
in turn causes player 3 to deviate to c2. In the case of c2, the unique equilibrium is (a2, b2), causing player 3 to deviate
to c1. Now assume that player 3 mixes between c1 and c3, and let α and β denote the probabilities with which players 1
and 2 play a1 and b1, respectively. Since player 3’s payoff from c1 and c3 must be the same in such an equilibrium, we
must either have α = β = 1, in which case player 3 will deviate to c2, or 0 (cid:3) α (cid:3) 0.5 and 0 (cid:3) β (cid:3) 0.5, causing player 2 to
deviate to b1. Analogously, if player 3 mixes between c2 and c3, we must either have α = β = 0, in which case player 3 will
deviate to c1, or 0.5 (cid:3) α (cid:3) 1 and 0.5 (cid:3) β (cid:3) 1, causing player 2 to deviate to b2. Finally, if both c1 and c2 are played with
positive probability, we must have α + β = 1 for player 3 to get an identical payoff of αβ (cid:3) 1/4 from both c1 and c2. In
this case, however, player 3 can deviate to c3 for a strictly greater payoff of 1 − 2αβ. Thus, a strategy proﬁle s
as described
above cannot exist.

∗

∗

Now let t

be the correlated strategy where action proﬁles (a1, b1, c1), (a2, b2, c1), (a1, b1, c2), and (a2, b2, c2) are played
with probability 0.25 each. This correlation can for example be achieved by tossing two coins independently. Players 1 and
2 observe the ﬁrst coin toss and play a1 and b1, respectively, if the coin falls on heads, and a2 and b2 otherwise. Player 3
observes the second coin toss and plays c1 if the coin falls on heads and c2 otherwise. The expected payoff for player 2
is 1, so he cannot gain by changing his action. If player 1 observes heads, he knows that player 2 will play b1, and
under t

∗

∗

Fig. 10. Three-player ranking game Γ3 used in the proof of Theorem 8.

F. Brandt et al. / Artiﬁcial Intelligence 173 (2009) 221–239

237

Fig. 11. Four-player ranking game Γ4 used in the proof of Theorem 8.

Fig. 12. Three-player ranking game Γ5 used in the proof of Theorem 9.

∗

that player 3 will play c1 and c2 with probability 0.5 each. He is thus indifferent between a1 and a2. Player 3 knows that
players 1 and 2 will play (a1, b1) and (a2, b2) with probability 0.5 each, so he is indifferent between c1 and c2 and strictly
prefers both of them to c3. Hence, none of the players has an incentive to deviate, t
is a correlated equilibrium. Moreover,
is 2, and thus MV(Γ3) = 2.
the social welfare under t

Now consider the four-player game Γ4 of Fig. 11, which is a ranking game for rank payoffs (cid:6)p1 = (cid:6)p3 = (1, 0, 0, 0), (cid:6)p2 =
(1, 1, 0, 0), and (cid:6)p4 = (1, 1, 1, 0), and rankings [1, 2, 4, 3], [1, 3, 2, 4], [3, 2, 4, 1], [2, 3, 1, 4], and [4, 1, 2, 3]. It is easily veriﬁed
that none of the action proﬁles with social welfare 2 is a Nash equilibrium. Furthermore, player 4 strictly prefers action d2
over d1 as soon as one of the remaining action proﬁles for players 1 to 3 (i.e., those in the upper half of the game where
the social welfare is 1) is played with positive probability. Hence, d1 is not played with positive probability in any Nash
equilibrium of Γ4, and every Nash equilibrium of Γ4 has social welfare 1. In turn, consider the correlated strategy μ∗
where
actions proﬁles (a1, b1, c1, d1), (a2, b2, c1, d1), (a1, b1, c2, d1), and (a2, b2, c2, d1) are played with probability 0.25 each. It is
easily veriﬁed that none of the players can increase his payoff by unilaterally deviating from μ∗
is a correlated
equilibrium with social welfare 3, and MV(Γ4) = 3.

. Hence, μ∗

∗

For n > 4, we can restrict our attention to games where the additional players only have a single action. We return to
the game Γ4 of Fig. 11 and transform it into a game Γ n
4 with n > 4 players by assigning to players 5, . . . , n a payoff of 1
in the four action proﬁles (a1, b1, c1, d1), (a2, b2, c1, d1), (a1, b1, c2, d1), and (a2, b2, c2, d1) that constitute the correlated
equilibrium with maximum social welfare, and a payoff of zero in all other action proﬁles. Since the additional players
cannot inﬂuence the outcome of the game, this construction does not affect the equilibria of the game. To see that the
resulting game is a ranking game, consider the rank payoff vectors (cid:6)p1 = (cid:6)p3 = (1, 0, 0, . . . , 0), (cid:6)p2 = (1, 1, . . . , 0), rk
= 1 if
m
k (cid:3) m − 1 and 0 otherwise, for m (cid:2) 4. It is easily veriﬁed that we can retain the original payoffs of players 1 to 4 and
at the same time assign a payoff of 0 or 1, respectively, to players 5 to n by ranking the latter according to their index
and placing either no other players or exactly one other player behind them in the overall ranking. More precisely, Γ n
4 is a
ranking game by virtue of the above rank payoffs and rankings [1, 2, 4, 5, . . . , n, 3], [1, 3, 2, 4, 5, . . . , n], [3, 2, 4, 5, . . . , n, 1],
[2, 3, 1, 4, 5, . . . , n], and [4, 1, 2, 3, 5, . . . , n]. Furthermore, MV(Γ n

4 ) = n − 1. (cid:2)

Theorem 9. Let R be the class of ranking games with n > 2 players. Then, EV(R) = n − 1, even if R only contains games without
weakly dominated actions.

Proof. It suﬃces to show that for any n (cid:2) 3 there is a ranking game with enforcement value n − 1 in which no action
is weakly dominated. Consider the ranking game Γ5 of Fig. 12, which is a ranking game by virtue of rank payoff vectors
(cid:6)p1 = (1, 1, 0), (cid:6)p2 = (1, 0, 0), and (cid:6)p3 = (1, (cid:7), 0) and rankings [1, 2, 3], [2, 3, 1], [3, 1, 2], [3, 2, 1], and [1, 3, 2]. Obviously, all
of the actions of Γ5 are undominated and v S (Γ5) = 2. It remains to be shown that the social welfare in any correlated
equilibrium of Γ5 is at most (1 + (cid:7)), such that v C(Γ5)(Γ5) → 1 and EV(Γ5) → 2 for (cid:7) → 0.

Finding a correlated equilibrium that maximizes social welfare constitutes a linear programming problem constrained by
s∈ A μ(a) = 1 and μ(a) (cid:2) 0 for all a ∈ A. Feasibility of this
the inequalities of Deﬁnition 7 and the probability constraints
problem is a direct consequence of Nash’s existence theorem. Boundedness follows from boundedness of the quantity being
maximized. To derive an upper bound for social welfare in a correlated equilibrium of Γ5, we will transform the above linear
program into its dual. Since the primal is feasible and bounded, the primal and the dual will have the same optimal value, in

(cid:2)

238

F. Brandt et al. / Artiﬁcial Intelligence 173 (2009) 221–239

our case the maximum social welfare in a correlated equilibrium. The latter constitutes a minimization problem and ﬁnding
a feasible solution with objective value v shows that the optimal value cannot be greater than v. Since there are three
∗
i ) − pi(a−i, ai)) (cid:2) 0.
players with two actions each, the primal has six constraints of the form
For j ∈ {1, 2}, let x j , y j , z j , denote the variable of the dual associated with the constraint for the jth action of player 1, 2,
a∈ A μ(a) = 1 of the
and 3, respectively. Furthermore, let v denote the variable of the dual associated with constraint
primal. Then the dual reads

∗
i )(pi(a−i, a
(cid:2)

μ(a−i, a

a−i ∈ A−i

(cid:2)

minimize

v

subject to −x1 + y1 + z1 + v (cid:2) 1,

x2 − y1 + v (cid:2) 1 + (cid:7),
x1 − y2 + v (cid:2) 1 + (cid:7),
−x2 + y2 + ((cid:7) − 1)z1 + v (cid:2) 2,
x1 − z2 + v (cid:2) 1,
−x2 + v (cid:2) 1 + (cid:7),
v (cid:2) 1 + (cid:7),
(1 − (cid:7))z2 + v (cid:2) 1 + (cid:7),
x1 (cid:2) 0, x2 (cid:2) 0, y1 (cid:2) 0, y2 (cid:2) 0, z1 (cid:2) 0, and z2 (cid:2) 0.

Now let x2 = y1 = z2 = 0, x1 = y2 = ((cid:7) − 1)2/(cid:7), z1 = (1 − 2(cid:7))/(cid:7), and v = 1 + (cid:7), and observe that for every (cid:7) > 0, this is a
feasible solution with objective value 1 + (cid:7). However, the objective value of any feasible solution to the dual is an upper
bound for that of the optimal solution, which in turn equals v C(Γ5)(Γ5).
The above construction can easily be generalized to games Γ n

5 with n > 4 by adding additional players that receive
payoff 1 in action proﬁle a if a1 = a2, a2 = b2, and a3 = c1, and payoff 0 otherwise. This can for example be achieved by
means of rank payoff vectors (cid:6)p1 = (1, 0, . . . , 0), (cid:6)p2 = (1, 1, 0, . . . , 0), (cid:6)p3 = (1, (cid:7), 0, . . . , 0), and (cid:6)pk
= 1 if k (cid:3) m − 1 and 0
m
otherwise for m (cid:2) 4. By the same arguments as in the proof of Theorem 8, this does not affect the maximum social welfare
achievable in a correlated equilibrium. It is thus easily veriﬁed that EV(Γ k1×···×k4

) → n − 1 for (cid:7) → 0. (cid:2)

5

8. Conclusion

We proposed a new class of strategic games, so-called ranking games, which model settings in which players are merely
interested in outperforming their opponents. Despite the structural simplicity of these games, various solution concepts
turned out to be just as hard to compute as in general normal-form games. In particular we obtained hardness results for
mixed Nash equilibria and iterated weak dominance in games with more than two players and pure Nash equilibria in games
with an unbounded number of players. As a consequence, the mentioned solution concepts appear to be of limited use in
large instances of ranking games that do not possess additional structure. This underlines the importance of alternative,
eﬃciently computable, solution concepts for ranking games such as maximin strategies or correlated equilibrium.

Based on these ﬁndings, we have quantiﬁed and bounded comparative ratios of various solution concepts in ranking
games. It turned out that playing one’s maximin strategy in binary ranking games with only few actions might be a prudent
choice, not only because this strategy guarantees a certain payoff even when playing against irrational opponents, but also
because of the limited price of cautiousness and the inherent weakness of Nash equilibria in ranking games.

We also investigated the relationship between correlated and Nash equilibria. While correlation can never decrease social
welfare, it is an important question which (especially competitive) scenarios permit an increase. In scenarios with many
players and asymmetric preferences over ranks (i.e., non-identical rank payoff vectors) overall satisfaction can be improved
substantially by allowing players to correlate their actions. Furthermore, correlated equilibria do not suffer from the equi-
librium selection problem since the equilibrium to be played is selected by a mediator.

Acknowledgements

The authors thank Vincent Conitzer, Markus Holzer, Samuel Ieong, Eugene Nudelman, and Rob Powers, and the anony-
mous referees for valuable comments. This article is based upon work supported by the Deutsche Forschungsgemeinschaft
under grants BR 2312/1-1 and BR 2312/3-1, and by the National Science Foundation under ITR grant IIS-0205633. Research
on this topic was initiated during a post-doctoral stay of the ﬁrst author at Stanford University.

Preliminary versions of parts of this work have appeared in the proceedings of the 21st National Conference on Artiﬁcial
Intelligence (AAAI) and the 20th International Joint Conference on Artiﬁcial Intelligence (IJCAI), and have been presented at
the 17th International Conference on Game Theory.

F. Brandt et al. / Artiﬁcial Intelligence 173 (2009) 221–239

239

References

[1] T. Abbott, D. Kane, P. Valiant, On the complexity of two-player win-lose games, in: Proceedings of the 46th Symposium on Foundations of Computer

Science (FOCS), IEEE Computer Society Press, 2005, pp. 113–122.

[2] I. Ashlagi, D. Monderer, M. Tennenholtz, On the value of correlation, in: Proceedings of the 21st Annual Conference on Uncertainty in Artiﬁcial Intelli-

gence (UAI), AUAI Press, 2005, pp. 34–41.

[3] R.J. Aumann, Acceptable points in general n-person games, in: A.W. Tucker, R.D. Luce (Eds.), Contributions to the Theory of Games IV, in: Annals of

Mathematics Studies, vol. 40, Princeton University Press, 1959, pp. 287–324.

[4] R.J. Aumann, Almost strictly competitive games, Journal of the Society of Industrial and Applied Mathematics 9 (4) (1961) 544–550.
[5] R.J. Aumann, Subjectivity and correlation in randomized strategies, Journal of Mathematical Economics 1 (1974) 67–96.
[6] R.J. Aumann, On the non-transferable utility value: A comment on the Roth–Shafer examples, Econometrica 53 (3) (1985) 667–678.
[7] R.J. Aumann, Game theory, in: J. Eatwell, M. Milgate, P. Newman (Eds.), The New Palgrave: A Dictionary of Economics, vol. 2, MacMillan, 1987, pp. 460–

482.

[8] F. Brandt, T. Sandholm, Y. Shoham, Spiteful bidding in sealed-bid auctions, in: M. Veloso (Ed.), Proceedings of the 20th International Joint Conference

on Artiﬁcial Intelligence (IJCAI), 2007, pp. 1207–1214.

[9] X. Chen, X. Deng, Settling the complexity of 2-player Nash-equilibrium, in: Proceedings of the 47th Symposium on Foundations of Computer Science

(FOCS), IEEE Press, 2006, pp. 261–272.

[10] V. Conitzer, T. Sandholm, Complexity of (iterated) dominance, in: Proceedings of the 6th ACM Conference on Electronic Commerce (ACM-EC), ACM

Press, 2005, pp. 88–97.

[11] R. Cubitt, R. Sugden, Rationally justiﬁable play and the theory of non-cooperative games, Economic Journal 104 (425) (1994) 798–803.
[12] C. Daskalakis, P. Goldberg, C. Papadimitriou, The complexity of computing a Nash equilibrium, in: Proceedings of the 38th Annual ACM Symposium on

the Theory of Computing (STOC), ACM Press, 2006, pp. 71–78.

[13] G. Gottlob, G. Greco, F. Scarcello, Pure Nash equilibria: Hard and easy games, Journal of Artiﬁcial Intelligence Research 24 (2005) 195–220.
[14] J.C. Harsanyi, Oddness of the number of equilibrium points: A new proof, International Journal of Game Theory 2 (1973) 235–250.
[15] A. Kats, J.-F. Thisse, Unilaterally competitive games, International Journal of Game Theory 21 (1992) 291–299.
[16] L. Khachiyan, A polynomial algorithm in linear programming, Soviet Mathematics Doklady 20 (1979) 191–194.
[17] E. Koutsoupias, C. Papadimitriou, Worst-case equilibria, in: Proceedings of the 16th International Symposium on Theoretical Aspects of Computer

Science (STACS), in: Lecture Notes in Computer Science (LNCS), vol. 1563, Springer-Verlag, 1999, pp. 404–413.

[18] R.D. Luce, H. Raiffa, Games and Decisions: Introduction and Critical Survey, John Wiley & Sons Inc., 1957.
[19] C. Luckhardt, K. Irani, An algorithmic solution of n-person games, in: Proceedings of the 5th National Conference on Artiﬁcial Intelligence (AAAI), AAAI

Press, 1986, pp. 158–162.

[20] A.T. Marsland, J. Schaeffer (Eds.), Computers, Chess, and Cognition, Springer-Verlag, 1990.
[21] L.M. Marx, J.M. Swinkels, Order independence for iterated weak dominance, Games and Economic Behavior 18 (1997) 219–245.
[22] J. Morgan, K. Steiglitz, G. Reis, The spite motive and equilibrium behavior in auctions, Contributions to Economic Analysis & Policy 2 (1) (2003)

1102–1127.

[23] H. Moulin, J.-P. Vial, Strategically zero-sum games: The class of games whose completely mixed equilibria cannot be improved upon, International

Journal of Game Theory 7 (3–4) (1978) 201–221.

[24] R.B. Myerson, Game Theory: Analysis of Conﬂict, Harvard University Press, 1991.
[25] J.F. Nash, Non-cooperative games, Annals of Mathematics 54 (2) (1951) 286–295.
[26] H. Norde, Bimatrix games have quasi-strict equilibria, Mathematical Programming 85 (1999) 35–49.
[27] C.H. Papadimitriou, Computational Complexity, Addison-Wesley, 1994.
[28] C.H. Papadimitriou, Computing correlated equilibria in multi-player games, in: Proceedings of the 37th Annual ACM Symposium on the Theory of

Computing (STOC), ACM Press, 2005, pp. 49–56.

[29] C.H. Papadimitriou, The complexity of ﬁnding Nash equilibria, in: N. Nisan, T. Roughgarden, E. Tardos, V. Vazirani (Eds.), Algorithmic Game Theory,

Cambridge University Press, 2007, pp. 29–78, Chapter 2.

[30] T.E.S. Raghavan, Non-zero-sum two-person games, in: R.J. Aumann, S. Hart (Eds.), Handbook of Game Theory with Economic Applications, vol. III,

North-Holland, 2002, pp. 1687–1721, Chapter 17.

[31] T. Roughgarden, Selﬁsh Routing and the Price of Anarchy, MIT Press, 2005.
[32] S.J. Russell, P. Norvig, Artiﬁcial Intelligence. A Modern Approach, second ed., Prentice Hall, 2003.
[33] T. Sandholm, K. Larson, M. Andersson, O. Shehory, F. Tohmé, Coalition structure generation with worst case guarantees, Artiﬁcial Intelligence 111 (1–2)

(1999) 209–238.

[34] G. Schoenebeck, S. Vadhan, The computational complexity of Nash equilibria in concisely represented games, in: Proceedings of the 7th ACM Confer-

ence on Electronic Commerce (ACM-EC), ACM Press, 2006, pp. 270–279.

[35] N. Sturtevant, Current challenges in multi-player game search, in: Proceedings of the 4th International Conference on Computers and Games (CG), in:

Lecture Notes in Computer Science (LNCS), vol. 3846, Springer-Verlag, 2004, pp. 285–300.

[36] M. Tennenholtz, Competitive safety analysis: Robust decision-making in multi-agent systems, Journal of Artiﬁcial Intelligence Research 17 (2002) 363–

378.

[37] S. Vajda, Theory of Games and Linear Programming, John Wiley & Sons Inc., 1956.
[38] E. van Damme, Reﬁnements of the Nash Equilibrium Concept, Springer-Verlag, 1983.
[39] E. van Damme, On the state of the art in game theory: An interview with Robert Aumann, Games and Economic Behavior 24 (1998) 181–210.
[40] J. von Neumann, Zur Theorie der Gesellschaftspiele, Mathematische Annalen 100 (1928) 295–320.
[41] J. von Neumann, O. Morgenstern, The Theory of Games and Economic Behavior, second ed., Princeton University Press, 1947.
[42] O.D. Wolf, Optimal strategies in n-person unilaterally competitive games, Discussion Paper 9949, Center for Operations Research and Econometrics,

Université catholique de Louvain, 1999.

