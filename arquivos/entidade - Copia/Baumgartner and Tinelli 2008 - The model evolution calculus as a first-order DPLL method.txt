Artiﬁcial Intelligence 172 (2008) 591–632

www.elsevier.com/locate/artint

The model evolution calculus as a ﬁrst-order DPLL method

Peter Baumgartner a,∗, Cesare Tinelli b,1

a NICTA, Canberra, ACT, Australia
b Department of Computer Science, The University of Iowa, Iowa City, IA, USA

Received 31 January 2007; received in revised form 14 September 2007; accepted 19 September 2007

Available online 26 September 2007

Abstract

The DPLL procedure is the basis of some of the most successful propositional satisﬁability solvers to date. Although originally
devised as a proof-procedure for ﬁrst-order logic, it has been used almost exclusively for propositional logic so far because of its
highly inefﬁcient treatment of quantiﬁers, based on instantiation into ground formulas. The FDPLL calculus by Baumgartner was
the ﬁrst successful attempt to lift the procedure to the ﬁrst-order level without resorting to ground instantiations. FDPLL lifts to
the ﬁrst-order case the core of the DPLL procedure, the splitting rule, but ignores other aspects of the procedure that, although not
necessary for completeness, are crucial for its effectiveness in practice.

In this paper, we present a new calculus loosely based on FDPLL that lifts these aspects as well. In addition to being a more
faithful lifting of the DPLL procedure, the new calculus contains a more systematic treatment of universal literals, which are crucial
to achieve efﬁciency in practice. The new calculus has been implemented successfully in the Darwin system, described elsewhere.
The main results of this paper are theoretical, showing the soundness and completeness of the new calculus. In addition, the paper
provides a high-level description of a proof procedure for the calculus, as well as a comparison with other calculi.
© 2007 Elsevier B.V. All rights reserved.

Keywords: DPLL procedure; First-order logic; Sequent calculi; Model generation

1. Introduction

In propositional satisﬁability the DPLL procedure, named after its authors: Davis, Putnam, Logemann, and Love-
land [13,14], is the dominant method for building (complete) SAT solvers. Its popularity is due to its simplicity, its
polynomial space requirements, and the fact that, as a search procedure, it is amenable to powerful but also relatively
inexpensive heuristics for reducing the search space. Thanks to these heuristics and to very careful engineering, the
best SAT solvers today can successfully attack real-world problems with hundreds of thousands of variables and of
clauses [28,37]. These solvers are so powerful that many developers of automated reasoning-based tools are starting
to use them as back-ends to solve ﬁrst-order satisﬁability problems, albeit often in an incomplete way, by means of
ingenious domain speciﬁc translations into propositional logic [30,31,45].

* Corresponding author.

E-mail addresses: Peter.Baumgartner@nicta.com.au (P. Baumgartner), tinelli@cs.uiowa.edu (C. Tinelli).

1 Partially supported by Grant No. 237422 from the National Science Foundation.

0004-3702/$ – see front matter © 2007 Elsevier B.V. All rights reserved.
doi:10.1016/j.artint.2007.09.005

592

P. Baumgartner, C. Tinelli / Artiﬁcial Intelligence 172 (2008) 591–632

Interestingly, the DPLL procedure was actually devised in origin as a proof-procedure for ﬁrst-order logic. Its
treatment of quantiﬁers is highly inefﬁcient, however, because it is based on enumerating all possible ground instances
of an input formula’s clause form, and checking the propositional satisﬁability of each of these ground instances one
at a time. Because of its primitive treatment of quantiﬁers the DPLL procedure, which predates Robinson’s resolution
calculus by a few years, was quickly overshadowed by resolution as the method of choice for automated ﬁrst-order
reasoning, and its use has been conﬁned to propositional satisﬁability ever since.2

Given the great success of DPLL-based SAT solvers today, two natural research questions arise. One is whether the
DPLL procedure can be properly lifted to the ﬁrst-order level—in the sense ﬁrst-order resolution lifts propositional
resolution, say. The other is whether those powerful search heuristics that make DPLL so effective at the propositional
level can be successfully adapted to the ﬁrst-order case. We answer the ﬁrst of these two questions afﬁrmatively in this
paper, providing a complete lifting of the DPLL procedure to ﬁrst-order clausal logic by means of a new sequent-style
calculus, the Model Evolution calculus, or ME for short. The ME calculus can be used to answer the second question
afﬁrmatively as well, as we show in a companion paper [5] describing a recent implementation of the calculus.

The FDPLL calculus by Baumgartner [4] was the ﬁrst successful attempt to lift the DPLL procedure to the ﬁrst-
order level without resorting to ground instantiations. FDPLL lifts to the ﬁrst-order case the core of the DPLL
procedure, the splitting rule, but ignores another major aspect, unit propagation [50], that although not necessary
for its completeness is absolutely crucial to its effectiveness in practice. The calculus described in this paper lifts this
aspect as well. While the ME calculus borrows many fundamental ideas from FDPLL and generalizes it, it is not
an extension of FDPLL proper but of DPLL [47], a simple propositional calculus modeling the main features of the
DPLL procedure. As we will see, the Model Evolution calculus is a direct lifting of DPLL in the sense that it consists
of appropriate ﬁrst-order versions of DPLL’s rules, plus one additional rule speciﬁc to the ﬁrst-order case.

A very useful feature of the DPLL procedure—and of most propositional proof procedures for that matter—is that
it is able to provide a (Herbrand) model of the input formula whenever that formula is satisﬁable. The procedure,
and by extension the DPLL calculus, generates this model incrementally during a derivation. The Model Evolution
calculus can be seen as lifting this model generation process to the ﬁrst-order level. We could say that the purpose of
the Model Evolution calculus is, like the DPLL calculus, to construct a Herbrand model of a given set (cid:2) of clauses, if
any such model exists.

At each step of a derivation the calculus maintains a context (cid:3), that is, a ﬁnite set of (possibly non-ground) literals.
The context (cid:3) is a ﬁnite—and compact—representation of a Herbrand interpretation I(cid:3) serving as a candidate model
for (cid:2). The induced interpretation I(cid:3) might not be a model of (cid:2) because it might not satisfy some clauses in (cid:2). The
purpose of the main rules of the calculus is to detect this situation and either repair I(cid:3), by modifying (cid:3), so that it
becomes a model of (cid:2), or recognize that I(cid:3) is unrepairable and fail. In addition to these rules, the calculus contains a
number of simpliﬁcation rules whose purpose is, again like in DPLL, to simplify the clause set and, as a consequence,
to speed up the computation.

We call our calculus Model Evolution calculus because it starts with a default candidate model, one that satisﬁes
no positive literals, and “evolves it” as needed until it becomes an actual model of the input clause set (cid:2), or until it
is clear that (cid:2) has no models at all. Note that the DPLL calculus can be seen as doing exactly the same thing, but for
ground formulas only. The Model Evolution calculus simply extends this behavior to non-ground formulas as well.
An important by-product of this model evolution process is that every terminating derivation of a satisﬁable clause set
(cid:2) produces a context whose induced interpretation is indeed a model of (cid:2). This makes the calculus well suited for
all applications in which it is important to also provide counter-examples of invalid statements, as opposed to simply
proving their invalidity.

The Model Evolution calculus is refutationally sound and complete: an input clause set (cid:2) is unsatisﬁable if and
only if the calculus (ﬁnitely) fails to ﬁnd a model for (cid:2). The calculus is obviously non-terminating for arbitrary,
satisﬁable input sets. With some of these clause sets, the calculus might go on repairing their candidate model forever,
without ever turning it into an actual model. The calculus is however terminating for the class of ground clauses (of
course), and for the class of clauses resulting from the translation of conjunctions of Bernays–Schönﬁnkel formulas
into clause form.3 The termination for ground clause sets is a direct consequence of the fact that with such inputs the

2 But see Section 6 for a brief overview of ﬁrst-order reasoning systems that use the procedure to help them focus their search.
3 Such clauses contain no function symbols, but no other restrictions apply.

P. Baumgartner, C. Tinelli / Artiﬁcial Intelligence 172 (2008) 591–632

593

Model Evolution calculus reduces to the DPLL calculus, as we will show. The reasons for termination for Bernays-
Schönﬁnkel formulas are similar to those given in [4] for FDPLL.

As mentioned, the Model Evolution calculus is already a signiﬁcant improvement over FDPLL because it is a more
faithful lifting of the DPLL procedure, having additional rules for simplifying the current clause set and the current
context. Another advantage over FPDLL is that it contains a more systematic and general treatment of universal
literals, one of FDPLL’s optimizations. As we will see, adding literals with universal variables to a context imposes
stronger restrictions on future modiﬁcation of that context. This has the consequence of greatly reducing the non-
determinism in the calculus, and hence the potential of leading to much faster implementations.

The paper is organized as follows. After some formal preliminaries, given below, we brieﬂy describe in Section 2
the DPLL procedure, and deﬁne the DPLL calculus, a declarative version of the procedure. We then deﬁne and discuss
the Model Evolution calculus, in Section 3, showing how it extends DPLL. We prove the calculus’ correctness in
Section 4. In Section 5 we brieﬂy describe a proof procedure for the calculus as implemented in the Darwin theorem
prover [5]. Then we discuss in Section 6 how the calculus compares to other calculi in related work. We conclude the
paper in Section 7 with directions for further research. The more technical results needed in Section 4 are proved in
detail in the appendix.

1.1. Formal preliminaries

In this paper, we use two disjoint, inﬁnite sets of variables: a set X of universal variables, which we will refer to
just as variables, and another set V , which we will always refer to as parameters. The reason for having two types of
variables will be explained later. We will use, possibly with subscripts, u, v to denote elements of V , x, y to denote
elements of X, and w to denote elements of V ∪ X. We ﬁx a signature (cid:4) throughout the paper. We denote by (cid:4)sko
the expansion of (cid:4) obtained by adding to (cid:4) an inﬁnite number of (Skolem) constants not already in (cid:4). By (cid:4)-term
((cid:4)sko-term) we mean a term of signature (cid:4) ((cid:4)sko) over V ∪ X. In the following, we will simply say “term” to mean
a (cid:4)sko-term. If t is a term we denote by Var(t) the set of t’s variables and by Par(t) the set of t’s parameters. A term
t is ground iff Var(t) = Par(t) = ∅. Two terms are variable-disjoint (parameter-disjoint) iff they have no variables
(parameters) in common. They are disjoint iff they are both variable- and parameter-disjoint. We extend the above
notation and terminology to literals and clauses in the obvious way.

We adopt the usual notion of substitution over (cid:4)sko-expressions or sets thereof. We also use the standard notion of
uniﬁer and of most general uniﬁer. We will denote by {w1 (cid:5)→ t1, . . . , wn (cid:5)→ tn} the substitution σ such that wiσ = ti for
all i = 1, . . . , n and wσ = w for all w ∈ X ∪ V \ {w1, . . . , wn}. Also, we will denote by Dom(σ ) the set {w1, . . . , wn}
and by Ran(σ ) the set {w1σ, . . . , wnσ }.

If σ is a substitution and W a subset of X ∪ V , the restriction of σ to W , denoted by σ|W is the substitution that
maps every w ∈ W to wσ and every w ∈ (V ∪ X) \ W to itself. A substitution ρ is a renaming on W ⊆ (V ∪ X) iff
ρ|W is a bijection of W onto W . For instance ρ := {x (cid:5)→ u, v (cid:5)→ u, u (cid:5)→ v} is a renaming on V . Note however that ρ is
not a renaming on V ∪ X as it maps both x and v to u. We call a substitution simply a renaming if it is a renaming on
V ∪ X. We call a substitution σ parameter-preserving, or p-preserving for short, if it is a renaming on V . Similarly,
we call σ variable-preserving if it is a renaming on X. Note that a renaming is parameter-preserving iff it is variable-
preserving. For example, the renaming {x (cid:5)→ y, y (cid:5)→ x, u (cid:5)→ v, v (cid:5)→ u} is both variable- and parameter-preserving,
wheres the renaming {x (cid:5)→ v, v (cid:5)→ x} is neither variable-preserving nor parameter-preserving.

If s and t are two terms, we say that s is more general than t, and write s (cid:2) t, iff there is a substitution σ such that
sσ = t.4 We say that s is a variant of t, and write s ≈ t, iff s (cid:2) t and t (cid:2) s or, equivalently, iff there is a renaming ρ
such that sρ = t. We write s (cid:2) t if s (cid:2) t but s (cid:10)≈ t. We say that s is parameter-preserving more general than t, and
write s (cid:3) t, iff there is a parameter-preserving substitution σ such that sσ = t. When s (cid:3) t we will also say that t is a
p-instance of s. Since the empty substitution is parameter-preserving and the composition of two parameter-preserving
substitutions is also parameter preserving, it is immediate that the relation (cid:3) is, like (cid:2), both reﬂexive and transitive.
We say that s is a parameter-preserving variant, or p-variant, of t, and write s (cid:11) t, iff s (cid:3) t and t (cid:3) s; equivalently,
iff there is a parameter-preserving renaming ρ such that sρ = t. We write s (cid:3) t if s (cid:3) t but s (cid:10)(cid:11) t. Note that both (cid:11)
and ≈ are equivalence relations.

4 The uniﬁcation literature would write s (cid:4) t in the case above.

594

P. Baumgartner, C. Tinelli / Artiﬁcial Intelligence 172 (2008) 591–632

All of the above about substitutions is extended from terms to literals, that is, atomic formulas or negated atomic
formulas, in the obvious way. We denote literals in general by the letters K, L. We denote by L the complement of a
literal L. As usual, a clause is a disjunction L1 ∨ · · · ∨ Ln of zero or more literals. We denote clauses by the letters
C and D and the empty clause by (cid:2). We write L ∨ C to denote a clause obtained as the disjunction of a (possibly
empty) clause C and a literal L. When convenient, we will treat a clauses as the set of its literals.

A Skolemizing substitution is a substitution θ with Dom(θ ) ⊆ X that replaces each variable in Dom(θ ) by a fresh
Skolem constant and every remaining element of X ∪ V by itself. A Skolemizing substitution for a literal L (clause
C) is a Skolemizing substitution θ with Dom(θ ) = Var(L) (Dom(θ ) = Var(C)). We write Lsko (Csko) to denote the
result of applying to L (C) some Skolemizing substitution for L (C).

A (Herbrand) interpretation I over some signature (cid:8) is a set of ground (cid:8)-literals that contains either L or L,
but not both, for every ground (cid:8)-literal L. Satisﬁability of (cid:8)-literals and (cid:8)-clauses in I is deﬁned as follows. The
interpretation I satisﬁes (or is a model of) a ground literal L, written I |= L, iff L ∈ I ; I satisﬁes a ground clause C,
iff I |= L for some L in C; I satisﬁes a clause C, iff I |= C(cid:13) for all ground instances C(cid:13) of C; I satisﬁes a clause
set (cid:2), iff I |= C for all C ∈ (cid:2) in C. The interpretation I falsiﬁes a literal L (a clause C) if it does not satisfy L (C).
Sometimes we will also say that a clause C is valid in I to mean that I |= C.

2. The DPLL calculus

The DPLL procedure can be used to decide the satisﬁability of ground (or propositional) formulas in conjunctive
normal form or, more precisely, the satisﬁability of ﬁnite sets of ground clauses. The three essential operations of the
procedure are (i) unit resolution with backward subsumption, (ii) unit subsumption, and (iii) recursive reduction to
smaller problems. The procedure can be roughly described as follows.5

Given an input clause set (cid:2), whose satisﬁability is to be checked, apply unit propagation to it, that is, close (cid:2)
under unit resolution with backward subsumption, and eliminate in the process (a) all non-unit clauses subsumed
by a unit clause in the set and (b) all unit clauses whose atom occurs only once in the set. If the closure (cid:2)∗ of (cid:2)
contains the empty clause, then fail. If (cid:2)∗ is the empty set, then succeed. Otherwise, choose an arbitrary literal L
from (cid:2)∗ and check recursively, and separately, the satisﬁability of (cid:2)∗ ∪ {L} and of (cid:2)∗ ∪ {L}, succeeding if and
only if one of the two subsets is satisﬁable.

The essence of this procedure can be captured by a sequent-style calculus, the DPLL calculus, ﬁrst described in

[47], consisting of the derivation rules in Fig. 1.

The calculus manipulates sequents of the form (cid:3) (cid:14) (cid:2), where (cid:3), the context of the sequent, is a ﬁnite set of ground

literals and (cid:2) is a ﬁnite (multi)set of ground clauses.6

The intended goal of the calculus is to derive a sequent of the form (cid:3) (cid:14) ∅ from an initial sequent ∅ (cid:14) (cid:2)0, where (cid:2)0
is a clause set to be checked for satisﬁability. If that is possible, then (cid:2)0 is satisﬁable; otherwise, (cid:2)0 is unsatisﬁable.
Informally, the purpose of the context (cid:3) is to store incrementally a set of asserted literals, i.e., a set of literals in (cid:2)0
that must or can be true for (cid:2)0 to be satisﬁable. When (cid:3) (cid:14) ∅ is derivable from ∅ (cid:14) (cid:2)0, the context (cid:3) is indeed a
witness of (cid:2)0’s satisﬁability as it describes a (Herbrand) model of (cid:2)0: one that satisﬁes an atom p in (cid:2)0 iff p occurs
positively in (cid:3).

The context is grown by the Assert and the Split rules. The Assert rule models the fact that every literal occurring
as a unit clause in the current clause set must be satisﬁed for the whole clause set to be satisﬁed. The Split rule
corresponds to the decomposition in smaller subproblems of the DPLL procedure. This rule is the only don’t-know
non-deterministic rule of the calculus. It is used to guess the truth value of an undetermined literal L in the clause set
(cid:2) of the current sequent (cid:3) (cid:14) (cid:2), where by undetermined we mean such that neither L nor L is in the context (cid:3). The
guess allows the continuation of the derivation with either the sequent (cid:3), L (cid:14) (cid:2) or with the sequent (cid:3), L (cid:14) (cid:2).

The other two main operations of the DPLL procedure, unit resolution with backward subsumption and unit sub-
sumption, are modeled respectively by the Resolve and the Subsume rule. The Resolve rule removes from a clause all

5 See the original papers [13,14], among others, for a more complete description.
6 As customary, we write (cid:3), L (cid:14) (cid:2), C, say, to denote the sequent (cid:3) ∪ {L} (cid:14) (cid:2) ∪ {C}.

P. Baumgartner, C. Tinelli / Artiﬁcial Intelligence 172 (2008) 591–632

595

Fig. 1. The DPLL calculus.

literals whose complement has been asserted—which corresponds to generating the simpliﬁed clause by unit resolu-
tion and then discarding the old clause by backward subsumption. The Subsume rule removes all clauses that contain
an asserted literal—because all of these clauses will be satisﬁed in any model in which the asserted literal is true.

The DPLL calculus is easily proven sound, complete and terminating. It can be shown [47] that the calculus main-
tains its completeness even if one constrains the Split rule to split only on positive literals.7 In other words, there is no
loss of completeness if Split is replaced by the rule:

Split’

(cid:3) (cid:14) (cid:2), L ∨ C
(cid:3), L (cid:14) (cid:2), L ∨ C (cid:3), L (cid:14) (cid:2), L ∨ C

⎧
⎪⎨

if

⎪⎩

L is positive,
C (cid:10)= (cid:2),
L /∈ (cid:3),
L /∈ (cid:3)

Another change that does not alter the calculus in any fundamental way is the replacement of the Assert and Empty
rules by the following more powerful versions:

Assert’

(cid:3) (cid:14) (cid:2), L1 ∨ · · · ∨ Ln ∨ L
(cid:3), L (cid:14) (cid:2), L1 ∨ · · · ∨ Ln ∨ L

Close

(cid:3) (cid:14) (cid:2), L1 ∨ · · · ∨ Ln
(cid:3) (cid:14) (cid:2)

if

(cid:6)

⎧
⎪⎨

if

⎪⎩

n (cid:3) 0,
L1, . . . , Ln ∈ (cid:3),
L /∈ (cid:3),
L /∈ (cid:3)

(cid:2) (cid:10)= ∅ or n > 0,
L1, . . . , Ln ∈ (cid:3)

Note that Assert’ and Close reduce respectively to Assert and Empty given earlier when L1 ∨ · · · ∨ Ln has no literals
(i.e., if n = 0). The reason Assert’ and Close do not really change the calculus is that each application of Assert’,
respectively Close, can be simulated by n applications of Resolve followed by one application of Assert, respectively
Empty. We point out that with Close the Resolve rule becomes superﬂuous for completeness.

We mention the Split’, Assert’ and Close rules here because they will facilitate our comparison between the Model

Evolution calculus and DPLL.

3. The model evolution calculus

The Model Evolution calculus is a direct lifting of the DPLL calculus to the ﬁrst-order level. The lifting is achieved
with a suitable ﬁrst-order version of the rules Split’, Assert’, Subsume, Resolve and Close of DPLL, with the addition
of an extra rule, Compact, which is a simpliﬁcation rule speciﬁc to the ﬁrst-order case.

Similarly to DPLL, the derivation rules of the Model Evolution calculus apply to and produce sequents of the form
(cid:3) (cid:14) (cid:2). This time, however, (cid:3) is a ﬁnite set of literals possibly with variables and parameters, called again a context,
and (cid:2) is a set of clauses possibly with variables.

7 This fact is known in the SAT literature and is used as an optimization some DPLL-based SAT solvers.

596

P. Baumgartner, C. Tinelli / Artiﬁcial Intelligence 172 (2008) 591–632

As mentioned in the introduction, the context (cid:3) in a sequent (cid:3) (cid:14) (cid:2) determines an interpretation I(cid:3) meant to be a
model of (cid:2). The purpose of the main rules of the calculus is to recognize when I(cid:3) is not a model of (cid:2), and repair it so
that it can become one. The repairs are both localized and incremental, and based on the computation of most general
uniﬁers. The progressive repair process or evolution of the candidate model starts with a default interpretation and
continues until an actual model is found or no further repairs are possible. The calculus is non-deterministic because
in some cases the current interpretation can be repaired in two alternative ways, neither of which can be ruled out a
priori. With an initial sequent (cid:3)0 (cid:14) (cid:2)0 then, this gives rise to a search space of possible evolution sequences for I(cid:3)0 ,
the initial candidate model for (cid:2)0.

To ease the technical presentation it comes handy to work with a pseudo-literal ¬v, where v is a parameter that

ranges over atoms. The intention is to have ¬v stand by default for all negative literals.

We will show that when (cid:2)0 is unsatisﬁable and (cid:3)0 is just {¬v} all possible evolution sequences are ﬁnitely
failed—making the calculus complete. We will also show that, conversely, if all evolution sequences for I{¬v} are
ﬁnitely failed, then (cid:2)0 is guaranteed to be unsatisﬁable—making the calculus sound as well. In the process, we will
also show that non-failed ﬁnite sequences that cannot be grown further end with a context whose candidate model is
indeed a model of (cid:2)0.

3.1. Contexts and interpretations

The deﬁning aspect of the calculus, modeled after FDPLL, is the way contexts are extended to the ﬁrst-order case,
and the rôle they play in driving the derivation and the model generation process. Therefore, we start our description
of the calculus with them.

Deﬁnition 3.1 (Context). A context is a set of the form {¬v} ∪ S where v ∈ V and S is a ﬁnite set of literals.

Where L is a literal and (cid:3) a context, we will write L ∈≈ (cid:3) if L is a variant of a literal in (cid:3), L ∈(cid:11) (cid:3) if L is a

p-variant of a literal in (cid:3), and L ∈(cid:2) (cid:3) if L is a p-instance of a literal in (cid:3).

The calculus works only with non-contradictory contexts.

Deﬁnition 3.2 (Contradictory). A literal L is contradictory with a context (cid:3) iff Lσ = Kσ for some K ∈(cid:11) (cid:3) and
some p-preserving substitution σ . A context (cid:3) is contradictory iff it contains a literal that is contradictory with (cid:3).

Example 3.3. Let (cid:3) := {¬v, p(x1, y1), ¬q(v1)}. Then ¬p(h(x), u), ¬p(v, u), and q(y) are all contradictory with (cid:3).
However, q(f (v)) and r(x), say, are not. (Recall that x, x1, y1 are variables while v, v1, u are parameters.)

A non-contradictory context induces a unique Herbrand interpretation by means of the next three notions.

Deﬁnition 3.4 (Shields). Let K, L be literals with K (cid:2) L. A literal K (cid:13) strongly shields L from K iff K (cid:2) K (cid:13) (cid:2) L,
and K (cid:13) shields L from K iff K (cid:2) K (cid:13)(cid:13) (cid:2) L for some literal K (cid:13)(cid:13) with K (cid:13) (cid:3) K (cid:13)(cid:13). A context (cid:3) (strongly) shields L from
K iff it contains a literal that (strongly) shields L from K.

Equivalently, (cid:3) shields L from K iff K (cid:2) K (cid:13)(cid:13) (cid:2) L, for some K (cid:13)(cid:13) ∈(cid:2) (cid:3).

Deﬁnition 3.5 (Covers). Let L be a literal and (cid:3) a context. A literal K strongly covers L in (cid:3) iff K (cid:2) L and (cid:3) does
not shield L from K, and K covers L in (cid:3) iff K (cid:2) L and (cid:3) does not strongly shield L from K.

Deﬁnition 3.6 (Productivity). Let L be a literal, C a clause, and (cid:3) a context. A literal K produces L in (cid:3) iff

(1) K covers L in (cid:3), and
(2) there is no K (cid:13) ∈ (cid:3) that

(a) strongly covers L in (cid:3) and
(b) shields L from K.

P. Baumgartner, C. Tinelli / Artiﬁcial Intelligence 172 (2008) 591–632

597

Fig. 2. Illustrations of the notions “shields”, “covers” and “produces”. See Deﬁnitions 3.4, 3.5 and 3.6 for notation.

The context (cid:3) produces L iff it contains a literal K that produces L in (cid:3). The context (cid:3) produces C iff it produces
one of C’s literals.

From this deﬁnition it follows that any non-contradictory context containing a parameter-free literal K produces
all instances of K and does not produce any instance of K. This is a special case of a more general result, saying that
any literal K produces all its p-instances in that context and does not produce any p-instance of K (cf. Lemma A.6
below).

To help clarify their relationship, the concepts of shielding, covering and producing are illustrated in Fig. 2.

Example 3.7. Consider the context (cid:3) = {¬v, ¬p(x, u, a), p(v, a, x)}. Now, p(u, u, w) produces p(a, a, a) in (cid:3),
because p(u, u, w) covers p(a, a, a) in (cid:3) and there is no K (cid:13) ∈ (cid:3) that strongly covers ¬p(a, a, a) in (cid:3) and that
shields p(a, a, a) from p(u, u, w). In fact, the only candidate literal for K (cid:13) is ¬p(x, u, a). That literal does shield

598

P. Baumgartner, C. Tinelli / Artiﬁcial Intelligence 172 (2008) 591–632

p(a, a, a) from p(u, u, w)—which means that p(u, u, w) does not strongly cover p(a, a, a) in (cid:3); however, it does
not strongly cover p(a, a, a) = ¬p(a, a, a) in (cid:3) because p(v, a, x) ∈ (cid:3) shields ¬p(a, a, a) from ¬p(x, u, a).

The context (cid:3) produces p(a, a, b) because p(v, a, x) (cid:2) p(a, a, b) and (cid:3) does not shield p(a, a, a) from
p(v, a, x). But (cid:3) does not produce ¬p(v, a, a). Although ¬p(x, u, a) (cid:2) ¬p(v, a, a) holds, there is a literal in (cid:3),
namely p(v, a, x), that strongly covers p(v, a, a) in (cid:3) and that shields ¬p(v, a, a) from ¬p(x, u, a).

A consequence of the presence of the pseudo-literal ¬v in every context (cid:3) is that (cid:3) produces L or L for every

literal L. We can use this fact to associate to (cid:3) a unique Herbrand interpretation.

Deﬁnition 3.8 (Induced interpretation). Let (cid:3) be a non-contradictory context with signature (cid:4)sko. The interpretation
induced by (cid:3), denoted by I(cid:3), is the Herbrand (cid:4)-interpretation that satisﬁes a positive ground (cid:4)-literal L iff L is
produced by (cid:3).

For simplicity, we will sometimes say that a context satisﬁes/falsiﬁes a literal or a clause if its induced interpretation

does so.

Note that while a context can contain literals with Skolem constants with respect to some original signature (cid:4),
the induced interpretation is over the original signature only. Also note that since it is possible for a context (cid:3) to
produce both a positive ground literal L and its complement L, the above deﬁnition is asymmetric, because in that
case I(cid:3) always chooses to satisfy L over L. Contrapositively, this means that if I(cid:3) satisﬁes a ground literal L and
L is positive, then L and possibly also L are produced by (cid:3). If on the other hand L is negative, then L but not L is
produced by (cid:3).

It should be clear now that the purpose of the pseudo-literal ¬v in a context (cid:3) is to provide a default truth-value to
those ground literals whose value is not determined by the rest of the context. In fact, consider a ground (cid:4)-literal L
such that neither L nor L is produced by (cid:3) \ {¬v}. If L is positive, then it is false in I(cid:3) because it is not produced by
(cid:3) at all. If L is negative, then it is true in I(cid:3) because it is produced by ¬v.

At this point a clariﬁcation on the complexity of the deﬁnition of productivity is perhaps in order. One might think

that the more intuitive deﬁnition stating that

K produces L in (cid:3) iff K strongly covers L in (cid:3),

is good enough to support Deﬁnition 3.8. While simpler, this deﬁnition is however not adequate for our purposes. The
reason is that there exist (somewhat complicated) contexts (cid:3) and ground literals L such that (cid:3) produces neither L
or L according to the simpler deﬁnition above.8 Now, the requirement that any context (cid:3) produce L or L for every
ground literal L is fundamental for us, because it is used in the calculus to identify context literals that cause ground
clause instances to be falsiﬁed by the current induced interpretation (see later). This requirement is indeed satisﬁed by
the given Deﬁnition 3.6: should a candidate literal K ∈ (cid:3) cover L in (cid:3) but not produce L in (cid:3), then there will be a
literal K (cid:13) ∈ (cid:3) that shields L from K and produces L in (cid:3) (cf. Fig. 2-(e)).

We refer the reader to [19] for a study on the complexity of basic reasoning tasks on contexts9 and their relation to

other model representation formalisms.

For a given sequent (cid:3) (cid:14) (cid:2) the interpretation induced by the context (cid:3) may falsify a clause of (cid:2). This situation is

detectable through the computation of context uniﬁers.

Deﬁnition 3.9 (Context uniﬁer). Let (cid:3) be a context and

C = L1 ∨ · · · ∨ Lm ∨ Lm+1 ∨ · · · ∨ Ln

a parameter-free clause, where 0 (cid:5) m (cid:5) n. A substitution σ is a context uniﬁer of C against (cid:3) with remainder
Lm+1σ ∨ · · · ∨ Lnσ iff there are fresh p-variants K1, . . . , Kn ∈(cid:11) (cid:3) such that

8 In essence, this is possible because context literals may shield each other in a cyclic way, preventing each one from producing L or L.
9 However, note that the context literals in [19] are all variable-free or parameter-free. The “mixed” setting, where context literals may contain
both variables and parameters is being introduced with this paper.

P. Baumgartner, C. Tinelli / Artiﬁcial Intelligence 172 (2008) 591–632

599

(1) σ is a most general simultaneous uniﬁer of {K1, L1}, . . . , {Kn, Ln},
(2) for all i = 1, . . . , m, (Par(Ki))σ ⊆ V ,
(3) for all i = m + 1, . . . , n, (Par(Ki))σ (cid:4) V .

We say, in addition, that σ is productive iff Ki produces Liσ in (cid:3) for all i = 1, . . . , n.

For i = 1, . . . , n, we call Ki a context literal of σ . A context uniﬁer σ of C against (cid:3) with remainder Lm+1σ ∨

· · · ∨ Lnσ is admissible (for Split) iff for all distinct i, j = m + 1, . . . , n, Var(Liσ ) ∩ Var(Lj σ ) = ∅.

Note that each context uniﬁer has a unique remainder. If σ is a context uniﬁer of a clause C with remainder D we

call each literal of D a remainder literal of σ .

Example 3.10. Let (cid:3) := {¬v, p(v1, u1), ¬p(x1, g(x1)), q(v2, g(v2))} and C1 = r(x) ∨ ¬p(x, y). Then, the substitu-
tions

σ1 := {v (cid:5)→ r(x), v1 (cid:5)→ x, u1 (cid:5)→ y}
σ2 := {v (cid:5)→ r(v1), x (cid:5)→ v1, u1 (cid:5)→ y}

are both context uniﬁers of C1 against (cid:3) with respective remainders r(x) ∨ ¬p(x, y) and r(v1) ∨ ¬p(v1, y). While
both σ1 and σ2 are productive, only σ2 is admissible. The context uniﬁer σ1 is not admissible because its remainder
literals are not variable-disjoint. By contrast, the substitution

σ3 :=

(cid:7)
v (cid:5)→ r(v1), x (cid:5)→ v1, y (cid:5)→ u1

(cid:8)

is a context uniﬁer of C1 against (cid:3), this time with remainder r(v1), that is both productive and admissible.

Consider now the clause C2 = ¬p(x, y) ∨ ¬q(x, y). The substitution

σ4 :=

(cid:8)
(cid:7)
v1 (cid:5)→ v2, u1 (cid:5)→ g(v2), x (cid:5)→ v2, y (cid:5)→ g(v2)

is a context uniﬁer of C2 against (cid:3) with remainder ¬p(v2, g(v2)). This context uniﬁer is admissible but it is not pro-
ductive because the literal p(v1, u1) of (cid:3) chosen to unify with ¬p(x, y) does not produce ¬p(x, y)σ4 = p(v2, g(v2)).

We point out for later comparisons with the DPLL calculus that when, in Deﬁnition 3.9, C is ground and ¬v is the
only non-ground literal of (cid:3), the substitution σ is a context uniﬁer of C against (cid:3) with remainder (Lm+1σ ∨ · · · ∨
Lnσ ) = (Lm+1 ∨ · · · ∨ Ln) iff

(1) for all i = 1, . . . , m, Ki = Li and
(2) for all i = m + 1, . . . , n, Li is a positive literal and Ki is a p-variant of ¬v.

Admissible context uniﬁers are fundamental in the Model Evolution calculus. In fact, with a context (cid:3) and a
clause C, the existence of an admissible context uniﬁer of C against (cid:3) is a sign that I(cid:3) might not be a model of C.
This is because it is possible to compute an admissible context uniﬁer of C against (cid:3) whenever (cid:3) is non-contradictory
and I(cid:3) falsiﬁes C. The discovery by the calculus of an admissible context uniﬁer σ of C against the current context
(cid:3) prompts a modiﬁcation of (cid:3) that involves adding a literal of Cσ , with the goal of making C valid in the new I(cid:3).
This literal is chosen only among the remainder literals of σ , the reason being essentially that non-remainder literals
can be ignored with no loss of completeness.

Note that while the existence of an admissible context uniﬁer σ of C against (cid:3) is necessary for the unsatisﬁability
of C in I(cid:3), it is not sufﬁcient unless σ is also productive. As a matter of fact, for completeness the calculus needs
to add to the context only remainder literals of admissible uniﬁers that are also productive. For greater ﬂexibility,
however, we allow it to add remainder literals of non-productive admissible uniﬁers as well. The reason is mostly
practical and twofold: ﬁrst, when implementing the calculus, insisting on computing only productive context uniﬁers
can be considerably more expensive than computing context uniﬁers that are usually, although not always, productive;
second, sometimes “repairing” candidate models with remainder literals from non-productive context uniﬁers can
produce more constrained contexts, as illustrated in the example that follows.

600

P. Baumgartner, C. Tinelli / Artiﬁcial Intelligence 172 (2008) 591–632

Example 3.11. Consider the context (cid:3) := {¬v, p(u), ¬q(g(y))} and the clause C := p(x) ∨ q(x). The substitution

σ := {v (cid:5)→ p(g(y)), x (cid:5)→ g(y)}

is a context uniﬁer of C against (cid:3) with remainder p(g(y)), but it is not productive. As a matter of fact, I(cid:3) satisﬁes
C, and so Cσ , because (cid:3) produces every ground instance of p(x). This means that there is no need to repair I(cid:3) with
the addition of p(g(y)) to (cid:3). However, as we explain in Section 3.2, having the universal literal p(g(y)) in (cid:3) along
with p(u) considerably constrains further repairs involving instances of p(u), with a corresponding reduction in the
search space.

Productivity issues aside, we point out that although context uniﬁers for a given clause C and context (cid:3) are
easily computable (they are just simultaneous most general uniﬁers), they are not unique and may not be admissible.
Nevertheless, the calculus does not need to search for all admissible context uniﬁers. For completeness purposes any
admissible context uniﬁer of C against (cid:3) will do. Furthermore, and more important, admissible context uniﬁers are
easily derived from non-admissible ones. In fact, let σ be a context uniﬁer of C against (cid:3) with remainder D. If σ
has a remainder literal L that shares variables with another remainder literal, one can compose σ with a substitution
that moves the variables of L to fresh parameters and ﬁxes everything else. It is easy to see that a repeated application
of this process leads to an admissible context uniﬁer σρ of C whose remainder is included in Dρ. For instance, the
non-admissible context uniﬁers σ1 in Example 3.10 can be turned into the admissible one σ3 by this kind of process.
Now, while the choice of an admissible context uniﬁer over another is irrelevant for completeness, some context
uniﬁers are better than others for efﬁciency purposes. A context uniﬁer with an empty remainder for instance is always
preferable to one with an non-empty remainder, because it lets the calculus stop the derivation right away, as we will
see. In general, context uniﬁers with a smaller remainder are preferable over context uniﬁers with a longer remainder
because offer less choices for repairing the current model. Also, context uniﬁers with parameter-free remainder literals
are preferable over context uniﬁers with variable-free remainder literals only. As we explain later, the addition of a
parameter-free literal to a context imposes more constraints on later additions than the addition of a variable-free
literal, leading in principle to shorter derivations.

3.2. Parameters vs. variables

Before moving to describe the rules of the Model Evolution calculus, it is important to clarify the respective rôles

that parameters and variables play in it.

We said that the calculus manipulates sequents of the form (cid:3) (cid:14) (cid:2), where (cid:2) is a clause set and (cid:3) is a context pro-
viding a candidate model for (cid:2). Each derivation in the calculus starts with a sequent of the form ¬v (cid:14) (cid:2)0, where (cid:2)0
contains only standard clauses, i.e., clauses with no parameters—but possibly with variables. Similarly, all sequents
generated during a derivation have clause sets consisting of standard clauses only. Variables then can appear both in
clause sets and in contexts. Parameters instead can appear only in contexts.

The rôle of variables within a clause is the usual one: they stand for all ground terms. In contrast, the rôle of

variables and parameters within a context is to constrain, in different ways, how a candidate model can be repaired.

The current context (cid:3) needs repairing whenever it falsiﬁes a clause C in (cid:2). As we observed earlier, in that case
there is an admissible context uniﬁer σ of C against (cid:3) such that (cid:3) falsiﬁes Cσ as well. To satisfy C it is then necessary
to modify (cid:3) so that it satisﬁes (at least) Cσ . One way to do that is to pick from Cσ a literal Lσ non-contradictory
with (cid:3) and add it to (cid:3). When Lσ contains no parameters, that is, is a universal literal in FDPLL terminology, the
addition of Lσ will indeed make all ground instances of Lσ satisﬁed by the new context. Moreover, it will make such
instances permanently satisﬁed in the sense that any further additions of literals to the context that do not make it
contradictory will preserve the satisﬁability of those instances.

In contrast, when Lσ contains parameters, the assertion of all the ground (cid:4)-instances of Lσ is provisional: it can
be retracted later, in whole or in part. With the addition of Lσ to the context, the calculus is in essence making the
assumption that there is a model of C that satisﬁes all ground instances of Lσ . This assumption, however, is just a
working hypothesis, subject to be revised when evidence against it is found. That happens if the calculus, to satisfy

P. Baumgartner, C. Tinelli / Artiﬁcial Intelligence 172 (2008) 591–632

601

some other clause, later adds to the current context (cid:3)(cid:13) a literal K (cid:13) that is a (proper) instance of Lσ .10 After the
addition, the new context satisﬁes only those instances of Lσ that are not an instance of Lσ (cid:13).

We observe that the less parameters a context literal has, the more of its instances are parameter preserving—with
the extreme cases of variable-free literals on one side, having no p-instances other than p-variants, and parameter-free
literals on the other, having only p-instances. This means that the less the parameters in a context literal the more
difﬁcult it is to change the truth value of its instances by extending the context. That can be seen with the following
simple example.

Example 3.12. Consider a signature (cid:4) containing a constant symbol a, and the contexts (cid:3)1 = {¬v, L1}, (cid:3)2 =
{¬v, L2}, and (cid:3)3 = {¬v, L3}, where L1 = p(u, v), L2 = p(x, v), and L3 = p(x, y). All ground (cid:4)-instances of Li
are true in I(cid:3)i for i = 1, . . . , 3. In the ﬁrst context, since p(u, v) is variable-free, it is possible to change the truth of all
literals of the form p(a, t) or p(t, a), with t a ground term, by adding to (cid:3)1 the literals ¬p(a, v) and ¬p(u, a). In the
second context, this is already not possible because the literal ¬p(a, v) is contradictory with p(x, v). Nevertheless, it is
still possible to change the truth value of all the instances of p(x, v) of the form p(t, a), with the addition of ¬p(u, a).
In the last context, nothing can be done with either ¬p(a, v) or ¬p(u, a) because they are both contradictory with
p(x, y).

Because of the stronger restrictions they impose on the possible evolutions of a context, variables in effect help
prune the search space during derivations. However, they cannot be added indiscriminately in place of parameters in
context literals without making the calculus incomplete. By using admissible context uniﬁers the ME calculus is able
to introduce a fair amount of variables in contexts without loss of completeness.

3.3. Derivation rules

The ME calculus consists of three basic derivation rules: Split, Assert and Close, and three optional rules: Resolve,
Subsume, and Compact. We deﬁne and discuss them in the following. In the process, We also compare them with
the rules of the DPLL calculus to show that, modulo a technicality, ME reduces to DPLL when the input clause set
is ground.11 The technicality is simply that, contrary to DPLL, contexts in our calculus contain the pseudo literal ¬v.
Except for that, the two calculi operate on the same kind of sequents in the ground case, and stepwise simulate each
other.

The Splitrule

Split

sko (cid:14) (cid:2), C ∨ L

(cid:3) (cid:14) (cid:2), C ∨ L
(cid:3), Lσ (cid:14) (cid:2), C ∨ L (cid:3), (Lσ )
C (cid:10)= (cid:2),
σ is an admissible context uniﬁer of C ∨ L against (cid:3)
with remainder literal Lσ ,
neither Lσ nor (Lσ )

(∗) =

⎧
⎪⎨

(∗)

⎪⎩

sko

if

where

is contradictory with (cid:3)
We say that the clause C ∨ L above is the selected clause, the literal L is the selected literal, and σ is the context

uniﬁer of Split.

The Split rule is the analog of the Split’ rule in DPLL. As in DPLL, this is the only (don’t-know) non-deterministic
rule of the calculus, the one that drives the search for a model for the input clause set. Split is the rule that discovers
when the current candidate model falsiﬁes one of the clauses in the current clause set. It does that by computing a
context uniﬁer σ with a non-empty remainder for a clause with at least two literals. The rule attempts to repair the
candidate model by selecting a remainder literal Lσ and adding either Lσ or its complement to the context. The

must be an non-parameter-preserving instance of Lσ , otherwise the new context would be contradictory, which is not permitted.

10 More generally, it happens if the calculus adds a literal K one of whose p-preserving instances K(cid:13)
K(cid:13)
11 More precisely, it reduces to the version of DPLL, described at the end of Section 2, that uses the rules Split’, Assert’ and Close in place of Split,
Assert, and Empty, respectively.

is an instance of Lσ . Note that in any case,

602

P. Baumgartner, C. Tinelli / Artiﬁcial Intelligence 172 (2008) 591–632

reason for adding the complement of Lσ in alternative to Lσ is of course that the current clause set may have no
models that satisfy Lσ . Obviously, the addition of Lσ ’s complement to the context will not make the selected clause
C ∨ L valid in the new candidate model. But it will make sure that no context uniﬁer of C ∨ L has Lσ in its remainder,
forcing the calculus to select other remainder literals, if any, to make C ∨ L valid.

Note that Split does not exactly add the complement of Lσ to the current context, but rather a suitably Skolemized
version of it: one that replaces every variable of Lσ by a fresh Skolem constant.12 This is in accordance with our
treatment context literals as universally quantiﬁed wrt their variables, which essentially become existentially quantiﬁed
after negation, thus leading to fresh Skolem constants.

Example 3.13. If P (x, f (x), y, v, w) is the selected literal of a Split inference with, say, empty context uniﬁer, then
this literal P (x, f (x), y, v, w) will be added to the context in the left sequent, and the literal ¬P (c, f (c), d, v, w) will
be added to the context in the right sequent, where c and d are fresh constants.

We point out that a Split inference cannot be followed on either branch by another Split inference with the same
literal Lσ (or a p-variant of it) because then either Lσ or (Lσ )
will be contradictory with the context. Since Split
is the only rule that introduces Skolemized literals into contexts, this implies in particular that no context can contain
more than one Skolemized version of the same literal. It is not too difﬁcult to check that these properties hold even in
presence of the Compact rule below, which removes literals from a context.

sko

In the ground case—that is, when both (cid:3) \ {¬v} and (cid:2) ∪ {C ∨ L} are ground—the Split rule reduces exactly
to the Split’ rule of DPLL in Section 2. To see that it is enough to recall that in the ground case, if Lσ = L is a
remainder literal of a context uniﬁer σ of C ∨ L against (cid:3), then L must have been uniﬁed by σ with a variant of
sko = L) is contradictory with (cid:3), in the sense of
¬v, which implies that L is positive. Moreover, L (respectively, (Lσ )
Deﬁnition 3.2, iff L ∈ (cid:3) (respectively, L ∈ (cid:3)).

The Assertrule

Assert

(cid:3) (cid:14) (cid:2), C ∨ L
(cid:3), Lσ (cid:14) (cid:2), C ∨ L

if

⎧
⎪⎪⎪⎨
⎪⎪⎪⎩

σ is a context uniﬁer of C against
(cid:3) with an empty remainder,
Lσ is parameter-free and
non-contradictory with (cid:3),
there is no K ∈ (cid:3) s.t. K (cid:3) Lσ

We say that the clause C ∨ L above is the selected clause, and L is the selected literal of Assert.
As in DPLL, the Assert rule is extremely useful in reducing the non-determinism of the calculus. When the ﬁrst of
its side conditions holds, the candidate model induced by (any extension of) (cid:3) must make Lσ valid to become a model
of (cid:2) ∪ {C ∨ L}. The Assert rule achieves just that by adding Lσ to the context. Note that since Lσ is parameter-free,
its addition to the context is not retractable. Also note that the rule does not apply if the permanent validity of Lσ
has been already established. This is the case when (cid:3) contains a—necessarily parameter-free—literal K such that
K (cid:3) Lσ . The rule does not apply also if Lσ is contradictory with (cid:3). In that case, however, the candidate model is
unrepairable. The Close rule, described later, will detect that and cause the calculus to stop working on (cid:3) (cid:14) (cid:2), L ∨ C.
When C = (cid:2), that is, when the selected clause of Assert is just a unit clause L, the empty substitution is a context
uniﬁer of C against (cid:3) with an empty remainder. In that case, the effect of the rule is simply to add L to the context.
For greater ﬂexibility, the Assert rule is deﬁned for clauses with an arbitrary number of literals. As we will see in
Section 4.3, however, for completeness purposes it is enough to restrict its applications to unit clauses only.

In the ground case, Assert reduces exactly to Assert’ in DPLL. The reason is that, in the ground case (i) σ is a context
uniﬁer of C against (cid:3) with an empty remainder iff σ is the empty substitution and (cid:3) contains the complement of
each literal of C, (ii) Lσ is trivially parameter-free, (iii) there is no K ∈ (cid:3) s.t. K (cid:3) Lσ iff L /∈ (cid:3), and (iv) Lσ is not
contradictory with (cid:3) iff L /∈ (cid:3).

12 More precisely, one that does not occur in the current context yet.

P. Baumgartner, C. Tinelli / Artiﬁcial Intelligence 172 (2008) 591–632

603

The Closerule

(cid:9)

Close

(cid:3) (cid:14) (cid:2), C
(cid:3) (cid:14) (cid:2)

if

(cid:2) (cid:10)= ∅ or C (cid:10)= (cid:2),
there is a context uniﬁer σ of C against (cid:3)
with an empty remainder

We say that the clause C above is the selected clause of Close, and σ is the context uniﬁer of Close.
The idea behind Close is that when its precondition holds there is no way to repair the current candidate model
to make it satisfy C. The replacement of the current close set by the empty clause signals that the calculus has given
up on that candidate model. Note that, because of Resolve below, it is possible for the calculus to generate a sequent
containing an empty clause. The Close rule recognizes such sequents and applies to them as well. To see that it is
enough to observe that, for any context (cid:3), the empty substitution is a context uniﬁer of (cid:2) against (cid:3) with an empty
remainder.

In the ground case, the Close rule reduces to its namesake in DPLL, because then C has a context uniﬁer against (cid:3)

with an empty remainder iff L ∈ (cid:3) for every literal L of C.

The Subsumerule

Subsume

(cid:3), K (cid:14) (cid:2), L ∨ C
(cid:3), K (cid:14) (cid:2)

if K (cid:3) L

We say that the clause L ∨ C above is the selected clause of Subsume.
The purpose of Subsume is the same as in DPLL: to get rid of clauses that are valid in the current candidate model,
and are guaranteed to stay so.13 These are exactly those clauses one of whose literals is a p-instance of a literal in the
current context. Although Subsume is not needed for completeness, it is potentially useful in practice since it reduces
the size of the current clause set.

In the ground case, the Subsume rule reduces to its namesake in DPLL because, then, K (cid:3) L iff K = L.

The Resolverule

(cid:9)

Resolve

(cid:3) (cid:14) (cid:2), L ∨ C
(cid:3) (cid:14) (cid:2), C

if

there is a context uniﬁer σ of L
against (cid:3) with an empty remainder
such that Cσ = C

We say that the clause L ∨ C above is the selected clause and L is the selected literal of Resolve.
This rule is similar to Subsume in that it is not needed for completeness but is useful to reduce the complexity of
the current clause set. Since Resolve is in a sense dual to Subsume, it would be reasonable to expect its precondition
to be simply that there is a literal K ∈ (cid:3) such that K (cid:3) L. This precondition, however, is a special case of the one
provided. The given precondition makes Resolve more widely applicable, allowing for more frequent simpliﬁcations.
Observe that Resolve is a special case of unit resolution (with backward subsumption): the one in which the resolvent
of a unit clause K and a clause L ∨ C is exactly C—as opposed to a proper instance of C.

In the ground case, the Resolve rule as well reduces to its namesake in DPLL. To see why it is enough to observe

that in that case Resolve’s precondition holds iff σ is the empty substitution and L ∈ (cid:3).

The Compactrule

Compact

(cid:3), K, L (cid:14) (cid:2)
(cid:3), K (cid:14) (cid:2)

if K (cid:3) L

We say that the literal L above is the selected literal and the literal K is the subsuming literal of Compact.14
The Compact rule is another simpliﬁcation rule that is not needed for completeness but is useful in practice. Its
intended application is after the addition of a literal K that is parameter-preserving more general than other literals in
the context. After this addition, all such literals become superﬂuous since they can be replaced by K for all purposes.
Hence Compact allows their elimination.

There is no rule in DPLL corresponding to Compact. However, it is easy to see that Compact never applies in the

ground case.

13 Note that, as L is parameter-free, a necessary condition for K (cid:3) L is that K be parameter-free, which implies that none of its instances can
made false by subsequent contexts.
14 The literals K and L are meant to be distinct.

604

P. Baumgartner, C. Tinelli / Artiﬁcial Intelligence 172 (2008) 591–632

3.4. Derivation examples

For a better idea on how the various rules of the calculus apply, we now describe informally a couple of examples

of derivations—a formal deﬁnition of derivation will be given in the next section.

In the ﬁrst example we consider a satisﬁable clause set from the Bernays–Schönﬁnkel class, showing how the cal-
culus computes a model of the clause set. In the second example we consider an unsatisﬁable set whose unsatisﬁability
can be proven in the calculus deterministically—that is, without applying Split, thanks to the Assert rule.

Example 3.14. Consider the following initial sequent:

¬v (cid:14) p(x) ∨ q(x), ¬p(y) ∨ q(y) ∨ ¬p(c), ¬p(z) ∨ ¬q(z)

One rule (in fact, the only rule) that applies to this sequent is Split, with selected clause p(x) ∨ q(x). In fact, with the
fresh variants ¬v1 and ¬v2 of the context literal ¬v, the substitution

σ = {v1 (cid:5)→ p(x), v2 (cid:5)→ q(x)}

is a context uniﬁer of p(x) ∨ q(x) with remainder p(x) ∨ q(x). While this context uniﬁer is not admissible (because
the remainder literals share a variable), we can generate an admissible one from it by composition with the substitution
{x (cid:5)→ u}, say. The new context uniﬁer σ (cid:13) := σ {x (cid:5)→ u} has remainder p(u) ∨ q(u). Since the remainder literal p(u)
and its complement are both non-contradictory with the context, we can add p(u) to the context by (the left conclusion
of) one application of Split, obtaining

¬v, p(u) (cid:14) p(x) ∨ q(x), ¬p(y) ∨ q(y) ∨ ¬p(c), ¬p(z) ∨ ¬q(z)

Note that σ (cid:13) is a context uniﬁer of p(x) ∨ q(x) against the new context as well, and p(u) and q(u) are still remainder
literals for σ (cid:13). However, Split does not apply with selected literal p(x) anymore, because the complement of p(u) =
p(x)σ (cid:13) is now contradictory with the context. The Split rule does apply with selected literal q(x), but in a sense this
application is useless because p(x) ∨ q(x) is now satisﬁed by the current context, which makes every ground instance
of p(u) true. The uselessness of applying Split with selected literal q(x) is witnessed by the fact that σ (cid:13) is a non-
productive context uniﬁer. In fact, the literal ¬v1, the context literal variant paired with p(x) by the uniﬁer, does not
produce ¬p(x) anymore because of the presence of p(u) in the context.

We point out that using a fresh variant p(u1) of the context literal p(u), there are now context uniﬁers of the
subclause ¬p(z1) of ¬p(z) ∨ ¬q(z). Hence, we could think of applying Assert with selected clause ¬p(z) ∨ ¬q(z)
and selected literal ¬q(z). However, that is not possible because all these uniﬁers either have a non-empty remainder,
like for instance the uniﬁer {u1 (cid:5)→ z}, or instantiate ¬q(z) to a non-parameter-free literal, like for instance the uniﬁer
{z (cid:5)→ u1}.

Now, using the context literal variants p(u1), ¬v1 and p(u2), the substitution

σ = {y (cid:5)→ u1, v1 (cid:5)→ q(u1), u2 (cid:5)→ c}

say, is an admissible context uniﬁer of ¬p(y) ∨ q(y) ∨ ¬p(c) with remainder q(u1) ∨ ¬p(c). Since neither q(u1) nor
its complement is contradictory with the context, we can apply Split with selected clauses ¬p(y) ∨ q(y) ∨ ¬p(c) and
literal q(y).15 Choosing again the left conclusion of Split, which adds q(y)σ to the context, we then obtain
q(u1) (cid:14) p(x) ∨ q(x), ¬p(y) ∨ q(y) ∨ ¬p(c), ¬p(z) ∨ ¬q(z)

¬v, p(u),

Now the Close rule applies with selected clause ¬p(z) ∨ ¬q(z). In fact, using the context literal variants p(u2) and
q(u3), the substitution

σ = {z (cid:5)→ u2, u3 (cid:5)→ u2}

is a context uniﬁer of ¬p(z) ∨ ¬q(z) with an empty remainder. Let’s consider then the right conclusion of the last
Split application. With that conclusion we get the sequent

¬v, p(u), ¬q(u1) (cid:14) p(x) ∨ q(x), ¬p(y) ∨ q(y) ∨ ¬p(c), ¬p(z) ∨ ¬q(z).

15 The substitution {u1 (cid:5)→ y, v1 (cid:5)→ q(y), u2 (cid:5)→ c} is also a context uniﬁer of ¬p(y) ∨ q(y) ∨ ¬p(c), but it is not admissible because its remainder
is ¬p(y) ∨ q(y) ∨ ¬p(c).

P. Baumgartner, C. Tinelli / Artiﬁcial Intelligence 172 (2008) 591–632

605

Using now the context literal variants p(u2) and ¬q(u3), the substitution

σ = {y (cid:5)→ u2, u3 (cid:5)→ u2}

is a context uniﬁer with an empty remainder of the subclause ¬p(y) ∨ q(y) of ¬p(y) ∨ q(y) ∨ ¬p(c). Moreover,
¬p(c) = ¬p(c)σ is parameter-free and non-contradictory with the context. Finally, there is no context literal K such
that K (cid:3) ¬p(c).16 Hence Assert applies with selected clause ¬p(y) ∨ q(y) ∨ ¬p(c) and literal ¬p(c), yielding the
sequent

¬v, p(u), ¬q(u1), ¬p(c) (cid:14) p(x) ∨ q(x), ¬p(y) ∨ q(y) ∨ ¬p(c), ¬p(z) ∨ ¬q(z)
to which Subsume immediately applies with selected clause ¬p(y) ∨ q(y) ∨ ¬p(c), yielding the sequent

¬v, p(u), ¬q(u1), ¬p(c) (cid:14) p(x) ∨ q(x), ¬p(z) ∨ ¬q(z).

At this point, because of the context literal ¬p(c), we can apply Assert with selected clause p(x) ∨ q(x), obtaining

¬v, p(u), ¬q(u1), ¬p(c),

q(c) (cid:14) p(x) ∨ q(x), ¬p(z) ∨ ¬q(z).

It is easy to see that no rules apply to this sequent. For Split in particular the reason is that every possible remainder
literal is contradictory with one of the context literals or their complements—for Assert the argument is similar.

For any signature (cid:4) that includes the symbols of the original clause set, the ﬁnal context induces a Herbrand (cid:4)-
interpretation in which all ground instances of p(u) except p(c) are true, and all ground instances of q(u1) except q(c)
are false. For illustration purposes, if (cid:4) contains only the symbols of the original clause set, the induced interpretation
is simply {q(c)}. If (cid:4) also contains a functions symbols f of arity 1, say, the induced interpretation is {q(c)} ∪
{p(f n(c))|n > 0}. We leave it to the reader to verify that these interpretations are indeed a model of the original
clause set.

Example 3.15. Now consider the following initial sequent, where we use the usual mathematical notation for greater
clarity:

¬v (cid:14)

¬(x (cid:3) y) ∨ ¬(y (cid:3) z) ∨ (x (cid:3) z), (x (cid:3) 0) ∨ (0 (cid:3) x), |x| (cid:3) 0, 0 (cid:3) −|x|,
¬(x (cid:3) 0) ∨ (|x| (cid:3) x), ¬(0 (cid:3) x) ∨ (|x| (cid:3) x), ¬(|c| (cid:3) c) ∨ ¬(|c| (cid:3) −|c|)

Recalling an earlier observation on the applicability of Assert to unit clauses, we can immediately add each unit
clause in the clause set to the context by means of Assert, and then remove it from the set by means of Subsume. This
results in the sequent:

¬v, |x| (cid:3) 0, 0 (cid:3) −|x| (cid:14)

¬(x (cid:3) y) ∨ ¬(y (cid:3) z) ∨ (x (cid:3) z), (x (cid:3) 0) ∨ (0 (cid:3) x),
¬(x (cid:3) 0) ∨ (|x| (cid:3) x), ¬(0 (cid:3) x) ∨ (|x| (cid:3) x),
¬(|c| (cid:3) c) ∨ ¬(|c| (cid:3) −|c|)

Now consider the clause ¬(x (cid:3) y) ∨ ¬(y (cid:3) z) ∨ (x (cid:3) z) and its subclause ¬(x (cid:3) y) ∨ ¬(y (cid:3) z). With the context
literal variants |x1| (cid:3) 0 and 0 (cid:3) −|x2|, the substitution

σ = {x (cid:5)→ |x1|, y (cid:5)→ 0, z (cid:5)→ −|x2|}

is an admissible context uniﬁer of ¬(x (cid:3) y) ∨ ¬(y (cid:3) z) with an empty remainder. Moreover, the literal |x1| (cid:3) −|x2| =
(x (cid:3) z)σ is parameter-free and non-contradictory with (cid:3). Finally, there is no context literal K such that K (cid:3) (|x1| (cid:3)
−|x2|). Hence, we can add |x1| (cid:3) −|x2| to the context by one application of Assert.

With this new literal we can then simplify ¬(|c| (cid:3) c) ∨ ¬(|c| (cid:3) −|c|) to ¬(|c| (cid:3) c) with Resolve, obtaining

¬v, |x| (cid:3) 0, 0 (cid:3) −|x|,
|x1| (cid:3) −|x2|

(cid:14)

¬(x (cid:3) y) ∨ ¬(y (cid:3) z) ∨ (x (cid:3) z), (x (cid:3) 0) ∨ (0 (cid:3) x),
¬(x (cid:3) 0) ∨ (|x| (cid:3) x), ¬(0 (cid:3) x) ∨ (|x| (cid:3) x),
¬(|c| (cid:3) c)

We can then move ¬(|c| (cid:3) c) to the context by means of Assert and Subsume, obtaining

¬v, |x| (cid:3) 0, 0 (cid:3) −|x|,
|x1| (cid:3) −|x2|, ¬(|c| (cid:3) c)

(cid:14)

¬(x (cid:3) y) ∨ ¬(y (cid:3) z) ∨ (x (cid:3) z), (x (cid:3) 0) ∨ (0 (cid:3) x),
¬(x (cid:3) 0) ∨ (|x| (cid:3) x), ¬(0 (cid:3) x) ∨ (|x| (cid:3) x),

16 The literal ¬p(c) is an instance of the context literal ¬v, but it is not a p-instance of ¬v.

606

P. Baumgartner, C. Tinelli / Artiﬁcial Intelligence 172 (2008) 591–632

With ¬(|c| (cid:3) c) in the context, we can apply Assert with selected clause ¬(x (cid:3) 0) ∨ (|x| (cid:3) x) and substitution σ1 =
{x (cid:5)→ c}, adding ¬(|c| (cid:3) 0) to the context. Similarly, we can apply Assert with selected clause ¬(0 (cid:3) x) ∨ (|x| (cid:3) x)
and add ¬(0 (cid:3) |c|), obtaining:

. . . , ¬(|c| (cid:3) 0), ¬(0 (cid:3) |c|) (cid:14) . . . , (x (cid:3) 0) ∨ (0 (cid:3) x), . . .

With ¬(|c| (cid:3) 0) in the context, the substitution σ2 = {x (cid:5)→ |c|} is a context uniﬁer of (x (cid:3) 0) with an empty remainder.
Note that we cannot apply Resolve with selected clause (x (cid:3) 0) ∨ (0 (cid:3) x) and substitution σ2 because (0 (cid:3) x)σ (cid:10)=
(0 (cid:3) x). Similarly, we cannot apply Assert either with selected clause (x (cid:3) 0) ∨ (0 (cid:3) x) and substitution σ2 because
(0 (cid:3) x)σ is contradictory with the context literal ¬(0 (cid:3) |c|). However, we can apply Close with selected clause
(x (cid:3) 0) ∨ (0 (cid:3) x) and substitution σ2, obtaining the sequent

. . . (cid:14) (cid:2).

This is because, thanks to the context literals ¬(|c| (cid:3) 0) and ¬(0 (cid:3) |c|), σ2 is a context uniﬁer of (x (cid:3) 0) ∨ (0 (cid:3) x)
with an empty remainder.

Note that other sequences of rule applications are possible for the given clause set. However, as we will prove in
Section 4, since the described one contained no applications of Split, all those other sequences too are guaranteed to
lead to an application of Close. But then, as we will also prove in Section 4, we can conclude that the original clause
set is unsatisﬁable.

3.5. Derivations

We now provide a formal deﬁnition of derivation in the Model Evolution calculus. As customary in sequent-
style calculi, derivations in ME are deﬁned in terms of derivation trees where each node corresponds to a particular
application of a derivation rule, and each of the node’s children corresponds to one of the conclusions of the rule.

Deﬁnition 3.16 (Derivation tree). A derivation tree (in ME ) is a labeled tree inductively deﬁned as follows:

(1) a one-node tree is a derivation tree iff its root is labeled with a sequent of the form (cid:3) (cid:14) (cid:2), where (cid:3) is a context

and (cid:2) is a clause set;

(2) A tree T(cid:13) is a derivation tree iff it is obtained from a derivation tree T by adding to a leaf node N in T new children
nodes N1, . . . , Nm so that the sequents labeling N1, . . . , Nm can be derived by applying a rule of the calculus to
the sequent labeling N . In this case, we say that T(cid:13) is derived from T.

We say that a derivation tree T is a derivation tree of a clause set (cid:2) iff its root node tree is labeled with ¬v (cid:14) (cid:2).
Let us call a non-leaf node in a derivation tree a Split node if the sequents labeling its children are obtained by
applying the Split rule to the sequent labeling the node. (Similarly for nodes to which other rules are applied.) Observe
that every non-leaf node in a derivation tree has only one child unless it is a Split node, in which case it has two
children. When it is convenient and it does not cause confusion, we will identify the nodes of a derivation tree with
their labels.

Deﬁnition 3.17 (Open, closed). A branch in a derivation tree is closed if its leaf is labeled by a sequent of the form
(cid:3) (cid:14) (cid:2); otherwise, the branch is open. A derivation tree is closed if each of its branches is closed, and it is open
otherwise.

We say that a derivation tree (of a clause set (cid:2)) is a refutation tree (of (cid:2)) iff it is closed.
In the rest of the paper, the letters i and n will denote ﬁnite ordinal numbers, whereas the letter κ will denote an
ordinal smaller than or equal to the ﬁrst inﬁnite ordinal. For every κ then, we will denote a possibly inﬁnite sequence
a0, a1, a2, . . . of κ elements by (ai)i<κ .

Deﬁnition 3.18 (Derivation). A derivation (in ME ) is a possibly inﬁnite sequence of derivation trees (Ti)i<κ , such
that for all i with 0 < i < κ, Ti is derived from Ti−1.

P. Baumgartner, C. Tinelli / Artiﬁcial Intelligence 172 (2008) 591–632

607

We say that a derivation D = (Ti)i<κ is a derivation of a clause set (cid:2) iff T0 is a one-node tree with label {¬v} (cid:14) (cid:2).

We say that D is a refutation of (cid:2) iff D is ﬁnite and ends with a refutation tree of (cid:2).

We show in the next sections that the Model Evolution calculus is sound and complete in the following sense: for

all sets (cid:2)0 of (cid:4)-clauses with no parameters, (cid:2)0 is unsatisﬁable iff (cid:2)0 has a refutation in the calculus.

To prove the calculus’ completeness we will introduce the notion of an exhausted branch, a derivation tree branch
that cannot be extended any further by the calculus. A by-product of the completeness proof will be to show that the
interpretation induced by the context in the leaf of an open exhausted branch is a model of the clause set in the branch’s
root. This means that whenever a derivation of a clause set (cid:2)0 produces a tree with an open exhausted branch, it is
possible not only to state that (cid:2)0 is satisﬁable, but also to provide (a ﬁnite description) of a model of (cid:2)0.

4. Correctness of the calculus

In this section, we prove the soundness and completeness of the Model Evolution calculus.

4.1. Soundness

To prove that the calculus is sound we ﬁrst prove that each of its derivation rules preserves a particular notion of

satisﬁability that we call a-satisﬁability, after [4].

Let us ﬁx a constant a from the signature (cid:4)sko\(cid:4) and consider the substitution α := {v (cid:5)→ a|v ∈ V } mapping
every parameter to a.17 Given a literal L, we denote by La the literal Lα. Note that La is ground if, and only if, L
is variable-free. Similarly, given a context (cid:3), we denote by (cid:3)a the set of unit clauses obtained from (cid:3) by removing
the pseudo-literal ¬v, replacing each literal L of (cid:3) with La, and considering it as a unit clause. Finally, if σ is
a substitution, we denote by σ a the composed substitution σ α. We point out for later that for all literals L and
substitutions σ such that (Par(L))σ ⊆ V (which includes all parameter-preserving substitutions), Lσ a = Laσ a.

We say that a sequent (cid:3) (cid:14) (cid:2) is a-(un)satisﬁable iff the clause set (cid:3)a ∪ (cid:2) is (un)satisﬁable in the standard sense—

that is, it has (no) Herbrand models.

Lemma 4.1. For each rule of the ME calculus, if the premise of the rule is a-satisﬁable, then one of its conclusions is
a-satisﬁable as well.

Proof. We prove the claim only for the rules Split, Assert, Resolve, and Close. For the other rules the claim holds
trivially.

Split) The premise of Split has the form (cid:3) (cid:14) (cid:11), while its conclusions have respectively the form (cid:3), K (cid:14) (cid:11) and
sko (cid:14) (cid:11). Suppose that (cid:3) (cid:14) (cid:11) is a-satisﬁable. Now let (cid:16)x := (x1, . . . , xn) be an enumeration of all the variables
(cid:3), K
of K and note that K and K a have exactly the same variables. Then consider the unit clause K a (or, more explicitly,
∀(cid:16)xK a) and its negation ¬∀(cid:16)xK a. Clearly, one of the two sets

S1 := (cid:3)a ∪ {K a} ∪ (cid:11) and S2 := (cid:3)a ∪ {¬∀(cid:16)xK a} ∪ (cid:11)

must be satisﬁable. If S1 is satisﬁable, we have immediately that (cid:3), K (cid:14) (cid:11) is a-satisﬁable. If S2 is satisﬁable, then
its Skolemized form (cid:3)a ∪ {(K a)
, as one can easily see, we then
have that (cid:3), K

sko} ∪ (cid:11) is also satisﬁable. Since (K a)

sko (cid:14) (cid:11) is a-satisﬁable.

sko = (K

sko

Assert) The premise of Assert has the form (cid:3) (cid:14) (cid:2), L1 ∨ · · · ∨ Ln ∨ L, while its conclusion has the form (cid:3), Lσ (cid:14)
(cid:2), L1 ∨ · · · ∨ Ln ∨ L, where Lσ is parameter-free and not contradictory with (cid:3), n (cid:3) 0, and σ is a context uniﬁer of
L1 ∨ · · · ∨ Ln against (cid:3) with an empty remainder. This means that there are fresh K1, . . . , Kn ∈(cid:11) (cid:3) such that σ is a
simultaneous uniﬁer of {{K1, L1}, . . . , {Kn, Ln}} and (Par(Ki))σ ⊆ V for all i = 1, . . . , n.

Suppose (cid:3) (cid:14) (cid:2), L1 ∨ · · · ∨ Ln ∨ L is a-satisﬁable, that is, (cid:3)a ∪ (cid:2) ∪ {L1 ∨ · · · ∨ Ln ∨ L} is satisﬁable. Observing
that (Par(Ki))σ ⊆ V and Li is parameter-free for each i, it is easy to see that σ a is a simultaneous uniﬁer of
{{K1

a, L1}, . . . , {Kn

a, Ln}}.

)

a

17 Strictly speaking, α is not a substitution in the standard sense because Dom(α) is not ﬁnite. But this will cause no problems here.

608

P. Baumgartner, C. Tinelli / Artiﬁcial Intelligence 172 (2008) 591–632

Since Ki

a ∈(cid:11) (cid:3)a for each i, it follows from the soundness of resolution that (cid:3)a ∪ (cid:2) ∪ {L1 ∨ · · · ∨ Ln ∨ L, Lσ a}

is satisﬁable. Noting that Lσ a = (Lσ )a, we can then conclude that (cid:3), Lσ (cid:14) (cid:2), L1 ∨ · · · ∨ Ln ∨ L is a-satisﬁable.

Resolve) The premise of Resolve has the form (cid:3) (cid:14) (cid:2), L ∨ C, while its conclusion has the form (cid:3) (cid:14) (cid:2), C, and
there is a most general uniﬁer σ of {K, L} for some K ∈(cid:11) (cid:3) such that (i) (Par(K))σ ⊆ V , and (ii) Cσ = C. Suppose
(cid:3) (cid:14) (cid:2), L ∨ C is a-satisﬁable, which means that (cid:3)a ∪ (cid:2) ∪ {L ∨ C} is satisﬁable. It is easy to see that because of
point (i) above and the fact that L is parameter-free, σ a is a uniﬁer of {K a, L}. Observing that K a ∈(cid:11) (cid:3)a, it follows
by the soundness of standard resolution that (cid:3)a ∪ (cid:2) ∪ {L ∨ C, Cσ a} is also satisﬁable. By point (ii) above and the
fact that C is parameter-free, we have that Cσ a = (Cσ )a = Ca = C. But this entails that (cid:3)a ∪ (cid:2) ∪ {C} is satisﬁable,
and so (cid:3) (cid:14) (cid:2), C is a-satisﬁable.

Close) The premise of Close has the form (cid:3) (cid:14) (cid:2), C, while its conclusion has the form (cid:3) (cid:14) (cid:2), and there is a
context uniﬁer σ of C against (cid:3) with an empty remainder. As (cid:3) (cid:14) (cid:2) is a-unsatisﬁable, we must show that (cid:3) (cid:14) (cid:2), C
is a-unsatisﬁable as well. We do that by proving that (cid:3)a ∪ {C} is unsatisﬁable.

Let C = L1 ∨ · · · ∨ Ln for some n (cid:3) 0. Since σ is a context uniﬁer σ of C against (cid:3) with an empty remain-
der, we know that there are fresh variants K1, . . . , Kn ∈(cid:11) (cid:3) such that σ is a most general simultaneous uniﬁer of
{K1, L1}, . . . , {Kn, Ln}, and (Par(Ki))σ ⊆ V for all i = 1, . . . , n. Let us ﬁx the literals K1, . . . , Kn.

Clearly, σ a is a simultaneous uniﬁer of {K1, L1}, . . . , {Kn, Ln}. By an earlier observation we know that Kiσ a =
aσ a for all i = 1, . . . , n. It follows that σ a is a simultaneous uniﬁer of

Ki

{K1

a, L2}, . . . , {Kn
a, L1}, {K2
This entails that {K1
a, . . . , Kn
mediately follows that (cid:3)a ∪ {C} is unsatisﬁable. (cid:2)

a, Ln}.

a, L1 ∨ · · · ∨ Ln} is unsatisﬁable. From the fact that K1

a, . . . , Kn

a ∈(cid:11) (cid:3)a it then im-

Proposition 4.2 (Soundness). For all sets (cid:2)0 of parameter-free (cid:4)-clauses, if (cid:2)0 has a refutation tree, then (cid:2)0 is
unsatisﬁable.

Proof. Let T0 be a refutation tree of (cid:2)0. We prove below by structural induction that the root of any subtree of a
refutation tree is a-unsatisﬁable. This will entail in particular that ¬v (cid:14) (cid:2)0, the root of T0, is a-unsatisﬁable. The
claim will then follow from the immediate fact that the sequent ¬v (cid:14) (cid:2)0 is a-unsatisﬁable iff (cid:2)0 is unsatisﬁable.

Let T be a subtree of a refutation tree and let N be its root. If T is a one-node tree, N can only have the form
(cid:3) (cid:14) (cid:2), which is trivially a-unsatisﬁable. If T has more than one node, we can assume by induction that all the children
nodes of N are a-unsatisﬁable. But then we can conclude that N is a-unsatisﬁable as well by the contrapositive of
Lemma 4.1. (cid:2)

4.2. Fairness

As customary, we will prove the completeness of the calculus with respect to fair derivations. The speciﬁc notion
of fairness that we adopt is deﬁned formally in the following. For that, it will be convenient to describe a tree T as the
pair (N, E), where N is the set of the nodes of T and E is the set of the edges of T.

Each derivation D in the Model Evolution calculus determines a limit tree with respect to all the derivation trees

in D.

Deﬁnition 4.3 (Limit tree). Let D = (Ti)i<κ be a derivation, where Ti = (Ni, Ei) for all i < κ. We say that

(cid:10) (cid:11)

(cid:12)

(cid:11)

Ni,

Ei

T :=

i<κ

i<κ

is the limit tree of D.

It is easy to show that a limit tree of a derivation D is indeed a tree. But note that it will not be a derivation tree

unless D is ﬁnite.

Deﬁnition 4.4 (Persistency). Let T be the limit tree of some derivation, and let B = (Ni)i<κ be a branch in T with κ
nodes. Let (cid:3)i (cid:14) (cid:2)i be the sequent labeling node Ni , for all i < κ. We deﬁne the following sets of persistent context
literals and persistent clauses, respectively:

P. Baumgartner, C. Tinelli / Artiﬁcial Intelligence 172 (2008) 591–632

609

(cid:11)

(cid:13)

(cid:3)B :=

(cid:3)j

(cid:2)B :=

(cid:11)

(cid:13)

(cid:2)j

i<κ

i(cid:2)j <κ

i<κ

i(cid:2)j <κ

In words, a context literal is persistent in the considered branch B iff it appears in the context of some node and in

the context of all the node’s descendants (and similarly for persistent clauses).

Where (cid:4) is the signature of the ﬁrst clause set of a derivation, we will also consider the set (cid:3)(cid:4)
B of all the (cid:4)-literals
in (cid:3)B (which excludes any literal with Skolem constants). Although, strictly speaking, (cid:3)B and (cid:3)(cid:4)
B are not contexts
because they may be inﬁnite, for the purposes of the completeness proof we can treat them as such. We note that all
the deﬁnitions introduced in Section 3.1 can be applied without change to (cid:3)B and (cid:3)(cid:4)
Fair derivations in the ME calculus are deﬁned in terms of exhausted branches.

B as well.

Deﬁnition 4.5 (Exhausted branch). Let T be a limit tree, and let B = (Ni)i<κ be a branch in T with κ nodes. For all
i < κ, let (cid:3)i (cid:14) (cid:2)i be the sequent labeling node Ni . The branch B is exhausted iff for all i < κ, all of the following
hold:

(i) For all C ∈ (cid:2)B, if Split is applicable to (cid:3)i (cid:14) (cid:2)i with selected clause C and productive context uniﬁer σ such
B for every context literal K of σ , then there is a remainder literal L of σ and a j with i (cid:5) j < κ

that K ∈(cid:11) (cid:3)(cid:4)
such that (cid:3)j produces L but does not produce L.

(ii) For all unit clauses L ∈ (cid:2)B, if Assert is applicable to (cid:3)i (cid:14) (cid:2)i with selected clause L, selected literal L and
empty context uniﬁer, then there is a j with i (cid:5) j < κ such that for any literal K with L (cid:3) K, (cid:3)j produces K
but does not produce K.

(iii) For all C ∈ (cid:2)B, Close is not applicable to (cid:3)i (cid:14) (cid:2)i with selected clause C and a context uniﬁer σ such that

K ∈(cid:11) (cid:3)B for every context literal K of σ .

(iv) (cid:2)i (cid:10)= {(cid:2)}.

It is worth noticing that Point (i) in Deﬁnition 4.5 does not require that Split be eventually applied with selected
clause C and context uniﬁer σ , for the branch to be exhausted. It only requires that the intended effect of applying Split
with selected clause C and context uniﬁer σ be achieved, namely that some literal L of Cσ is permanently produced
and L is not produced. Only with the latter property it is guaranteed that the interpretation induced by the limit context
assigns true to every ground (cid:4)-instance of L and hence to every ground (cid:4)-instance of Cσ . A similar observation can
be made about Point (ii) and the effect of applying Assert with selected unit clause L, namely that all (cid:4)-instances of
L and no (cid:4)-instance of L is produced. To make Point (ii) operational, Lemma A.6 below can be used to provide a
sufﬁcient condition. According to that lemma it is enough to add L to a context to achieve the desired effect.

Furthermore, as stated in Point (i) in Deﬁnition 4.5, concerning the context uniﬁer σ mentioned there it sufﬁces
to consider only a persistent clause C and as context literals of σ only persistent context (cid:4)-literals (and similarly
in Point (iii) in Deﬁnition 4.5). That only (cid:4)-literals from (cid:3)B need to be considered is justiﬁed, intuitively, by the
fact that in order to determine the satisﬁability of a input clause, which is built over the signature (cid:4), it is enough to
ﬁnd a Herbrand (cid:4)-model for it.18 That only persistent literals from (cid:3)B need to be considered results in an important
consequence for the design of proof procedures: for completeness purposes, neither clauses nor contexts need to be
stored over time; instead, it sufﬁces to maintain a current context and a current clause set—in addition to backtracking
information for recovering from Split applications that have led to a closed branch. See [5] for a proof procedure along
these lines.

Deﬁnition 4.6 (Fairness). A limit tree of a derivation is fair iff it is a refutation tree or it has an exhausted branch.
A derivation is fair iff its limit tree is fair.

We point out that fair derivations as deﬁned above do exist and are computable for any set of (parameter-free)
(cid:4)-clauses. A proof of this fact can be given by adapting a technique used in [4] to show the computability of fair
derivations in FDPLL. Moreover, and similarly to FDPLL, fair derivations need not be searched. As we will see,

18 Notice, however, that Close cannot be restricted to work with (cid:4)-literals from the context only.

610

P. Baumgartner, C. Tinelli / Artiﬁcial Intelligence 172 (2008) 591–632

the calculus is proof convergent, that is, if a set (cid:2) of (cid:4)-clauses is unsatisﬁable, then every fair derivation of (cid:2) is a
refutation.

4.3. Completeness

Our proof that the Model Evolution calculus is complete is based on showing that the set (cid:3)(cid:4)

B of persistent context
(cid:4)-literals along an exhausted branch B in a limit tree denotes a model of the clause set at the root of the tree. We
provide below only a sketch of the completeness proof by proving just the main results. A complete proof of all the
auxiliary results on properties of contexts and derivation rules stated here can be found in the appendix.

4.3.1. Properties of contexts

We start with some general properties of contexts that we will use in the following.

Lemma 4.7. Let (cid:3) be a non-contradictory context. Then, for any literal L, (cid:3) produces L or (cid:3) produces L (or both).

This lemma is needed in the proof of the following proposition.

Proposition 4.8. Let (cid:3) be a non-contradictory context and L a ground literal. If I(cid:3) satisﬁes L then (cid:3) produces L.

Observe that the converse of this proposition does not hold in general. This can be seen by considering the context
{¬v, P (a, u), ¬P (v, b)}. While the context produces both P (a, b) and ¬P (a, b), its induced interpretation satisﬁes
only P (a, b). The converse of Proposition 4.8 does hold for positive literals however.

Proof. If L is a positive literal then the claim follows trivially from Deﬁnition 3.8. Hence suppose that L is a negative
literal. It is impossible that (cid:3) produces L, which is a positive literal, because then again by Deﬁnition 3.8 the inter-
pretation I(cid:3) would satisfy L, and thus not satisfy L. Now, since (cid:3) does not produce L, it follows by Lemma 4.7 that
(cid:3) produces L. (cid:2)

4.3.2. Properties of inference rules

The following lemmas provide sufﬁcient conditions for the applicability of the main rules of the calculus to a given

context. We will refer to these conditions to prove the completeness of the calculus.

We need to characterize conditions under which Split is applicable. Their proof will be facilitated by the next two
general lemmas. The ﬁrst one shows how uniﬁcation can be used to identify clause instances that are false in the
interpretation induced by the current context.

Lemma 4.9 (Lifting lemma). Let (cid:3) be a non-contradictory context. Let C = L1 ∨ · · · ∨ Ln be a (cid:4)-clause and Cγ a
ground (cid:4)-instance. If (cid:3) produces L1γ , . . . , Lnγ , then there are fresh variants K1, . . . , Kn ∈(cid:11) (cid:3)(cid:4) and a substitution
σ such that

(1) σ is a most general simultaneous uniﬁer of {K1, L1}, . . . , {Kn, Ln},
(2) for all i = 1, . . . , n, Li (cid:2) Liσ (cid:2) Liγ ,
(3) for all i = 1, . . . , n, Ki produces Liσ in (cid:3).

In Section 3 we mentioned that the calculus does not need to search for admissible context uniﬁers, and that
any context uniﬁer can be composed with a renaming substitution, obtained deterministically, such that the resulting
context uniﬁer is admissible. This fact is expressed by the following lemma.

Lemma 4.10 (Existence of admissible context uniﬁers). Let (cid:3) be a context, C a clause and σ a context uniﬁer of C
against (cid:3). Then, there is a renaming ρ such that σ (cid:13) := σρ is an admissible context uniﬁer of C against (cid:3) with the
same context literals as σ .

P. Baumgartner, C. Tinelli / Artiﬁcial Intelligence 172 (2008) 591–632

611

It should be mentioned that the purpose of this lemma is just to show the existence of an admissible context uniﬁer
based on a possibly non-admissible context uniﬁer. A realistic implementation would compute a clever renaming, one
that tries to maximize the parameter-free literals in the resulting remainder.19 For completeness purposes, however,
any renaming that yields an admissible context uniﬁer will do, as it will be clear from the proof of Proposition 4.16
below.

Now we can turn to the lemma stating conditions under which the Split rule is applicable. Roughly, Split is applica-
ble if its selected clause admits a context uniﬁer, it does not overlap with Assert, and Close is not applicable with the
selected clause.

Lemma 4.11 (Split applicability). Let (cid:3) (cid:14) (cid:11), C be a sequent with a non-contradictory context (cid:3), where C contains
at least two literals. If all context uniﬁers of C against (cid:3) have a non-empty remainder, and σ is an admissible context
uniﬁer of C against (cid:3) such that (cid:3) produces L for every remainder literal L of σ , then Split is applicable to (cid:3) (cid:14) (cid:11), C
with selected clause C and context uniﬁer σ .

The next lemma provides sufﬁcient conditions for the applicability of Assert to unit clauses, which is enough for

completeness.

Lemma 4.12 (Assert applicability). Let (cid:3) (cid:14) (cid:11), L be a sequent with a non-contradictory context (cid:3). If all context
uniﬁers of L against (cid:3) have a non-empty remainder and there is an instance Lσ of L such that (cid:3) produces Lσ ,
then Assert is applicable to (cid:3) (cid:14) (cid:11), L with selected clause L, selected literal L and the empty substitution as context
uniﬁer.

4.3.3. Main result

In this section, let (cid:2) be a set of parameter-free (cid:4)-clauses and assume that D is a fair derivation of (cid:2) that is not a
refutation. Observe that D’s limit tree must have at least one exhausted branch. We denote this branch by B = (Ni)i<κ .
Then, by (cid:3)i (cid:14) (cid:2)i , we will always mean the sequent labeling the node Ni in B, for all i < κ. (As a consequence, we
will also have that (cid:3)0 = {¬v} and (cid:2)0 = (cid:2).)

Quite often we will appeal to the following compactness property of (cid:3)B. By deﬁnition, L ∈ (cid:3)B holds iff there is

an i < κ such that L ∈ (cid:3)j for all j (cid:3) i with j < κ.

Similarly, if L ∈(cid:11) (cid:3)B (meaning, by deﬁnition, that L (cid:11) K for some literal K ∈ (cid:3)B), then there is an i < κ such
that K ∈ (cid:3)j for all j (cid:3) i with j < κ, which entails that L ∈(cid:11) (cid:3)j , for all j (cid:3) i with j < κ. More generally then,
if L1, . . . , Ln ∈ (cid:3)B (or L1, . . . , Ln ∈(cid:11) (cid:3)B) for some n (cid:3) 0, then there is an i < κ such that L1, . . . , Ln ∈ (cid:3)j (or
L1, . . . , Ln ∈(cid:11) (cid:3)j ) for all j (cid:3) i with j < κ.20

Being non-contradictory is a fundamental property of the contexts manipulated by the calculus. Essentially, be-
cause the derivation rules can produce only non-contradictory contexts from non-contradictory contexts we obtain the
following result:

Lemma 4.13. (cid:3)B is not contradictory.

The following lemma reduces productivity in the limit for the given branch to productivity in contexts within the

branch.

Lemma 4.14. Let K, L be two literals with K ∈ (cid:3)B. If K produces L in (cid:3)B, then there is an i such that for all j (cid:3) i
with j < κ, K ∈ (cid:3)j and K produces L in (cid:3)j .

Lemma 4.15 (Close applicability). Let C ∈ (cid:2)B and i < κ such that Close is applicable to (cid:3)i (cid:14) (cid:2)i with selected
clause C. Then, for some j with i (cid:5) j < κ, Close is applicable to (cid:3)j (cid:14) (cid:2)j with selected clause C and a context
uniﬁer σ such that K ∈(cid:11) (cid:3)B for each context literal K of σ .

19 See [21] for a discussion of how to compute such a renaming.
20 It is easy to see that this index i can be determined by taking the maximum of the i-indices associated individually to the literals L1, . . . , Ln,
as just described.

612

P. Baumgartner, C. Tinelli / Artiﬁcial Intelligence 172 (2008) 591–632

The following proposition is fundamental as it states that the calculus computes a model, in the limit, for any

persistent clause set not containing the empty clause.

Proposition 4.16. If (cid:2) /∈ (cid:2)B, then I(cid:3)B is a model of (cid:2)B.

Proof. Suppose ad absurdum that (cid:2)B does not contain the empty clause, but I(cid:3)B is not a model of (cid:2)B. This means
that there is a ground (cid:4)-instance Cγ of a clause C = L1 ∨ · · · ∨ Ln with n (cid:3) 1 from (cid:2)B that is not satisﬁed by I(cid:3)B .
Since Cγ is not satisﬁed by I(cid:3)B , the literals L1γ , . . . , Lnγ are all satisﬁed by I(cid:3)B . By Lemma 4.13, (cid:3)B is non-

contradictory, and so by Proposition 4.8 it follows that (cid:3)B produces L1γ , . . . , Lnγ .

We distinguish two complementary cases below, depending on whether n = 1 or n > 1, and show that they both
lead to a contradiction. In both cases we need the fact that Close is not applicable to (cid:3)i (cid:14) (cid:2)i with selected clause C,
for any i < κ. This follows immediately from Lemma 4.15: for, if Close were applicable to (cid:3)i with selected clause
C, for some i < κ, then Close would be also applicable to (cid:3)j , for some j (cid:3) i with j (cid:5) κ and such that K ∈(cid:11) (cid:3)B for
each context literal K of its context uniﬁer. This, however, would contradict Deﬁnition 4.5(iii).

(n = 1) In this case, C consists of the single literal L1. For (cid:3)B to produce L1γ it must contain a literal K that

produces L1γ in (cid:3)B. By Lemma 4.14 then there is an i such that

for all j (cid:3) i with j < κ, K ∈ (cid:3)j and K produces L1γ in (cid:3)j .

(1)
Since L1 is a (unit) clause from (cid:2)B, there is a i(cid:13) such that L1 ∈ (cid:2)j (cid:13) for all j (cid:13) (cid:3) i(cid:13). Without loss of generality assume
that i (cid:3) i(cid:13) (otherwise i(cid:13) can be used instead of i in the sequel).

As shown above, Close is in particular not applicable to (cid:3)i (cid:14) (cid:2)i with selected clause L1. Since L1 ∈ (cid:2)i , all
context uniﬁers of L1 against (cid:3)i have a non-empty remainder. Together with (1), this implies by Lemma 4.12 that
Assert is applicable to (cid:3)i (cid:14) (cid:2)i with selected clause L1, selected literal L1 and empty context uniﬁer.

According to Deﬁnition 4.5(ii) then, there is a j (cid:3) i with j < κ such that for any literal L with L1 (cid:3) L, (cid:3)j
produces L but does not produce L. Recall that clauses in sequents are parameter-free, which implies that L1 (cid:3) L1γ .
But then, taking L = L1γ we have a contradiction with assertion (1) above which implies that (cid:3)j produces L1γ .

(n > 1) By the Lifting Lemma (Lemma 4.9), there are fresh p-variants K1, . . . , Kn ∈(cid:11) (cid:3)(cid:4)

B and a substitution σ

such that

(1) σ is a most general simultaneous uniﬁer of {K1, L1}, . . . , {Kn, Ln},
(2) for all k = 1, . . . , n, Lk (cid:2) Lkσ (cid:2) Lkγ ,
(3) for all k = 1, . . . , n, Kk produces Lkσ in (cid:3)B.

By Deﬁnition 3.9, σ is a productive context uniﬁer of C against (cid:3)B.

By Lemma 4.10, an admissible context uniﬁer of C against (cid:3)B can be obtained as σ (cid:13) = σρ, for some renaming

ρthat has the same context literals K1, . . . , Kn as σ .

Let k ∈ {1, . . . , n} and observe that a literal K produces a literal L in a context (cid:3) iff K produces a variant of L in (cid:3).
From the fact that Kk produces Lkσ in (cid:3)B, we have that Kk produces Lkσ (cid:13) in (cid:3)B as well. By applying Lemma 4.14
to every Kk and Lkσ (cid:13) individually (for k = 1, . . . , n), and taking the maximum of the indices i mentioned in the
lemma’s statement, we conclude that there is an i such that

for all j (cid:3) i with j < κ, Kk ∈(cid:11) (cid:3)(cid:4)

(2)
By assumption, C is a clause of (cid:2)B. Hence, there is a i(cid:13) such that C ∈ (cid:2)j (cid:13) for all j (cid:13) (cid:3) i(cid:13). Without loss of generality
suppose that i (cid:3) i(cid:13) (otherwise i(cid:13) can be used instead of i in the sequel).

j and Kk produces Lkσ (cid:13) in (cid:3)j .

As shown above, Close is in particular not applicable to (cid:3)i (cid:14) (cid:2)i with selected clause C. Therefore, all context

uniﬁers of C against (cid:3)i must have a non-empty remainder.

By (2) and the generality of k we have that Kk ∈(cid:11) (cid:3)(cid:4)

i produces Lkσ (cid:13) in (cid:3)i for all k = 1, . . . , n, and so, in
particular, (cid:3)i produces all remainder literals of σ (cid:13). By Lemma 4.11 then, Split is applicable to (cid:3)i (cid:14) (cid:2)i with selected
clause C and productive context uniﬁer σ (cid:13). Recall that each literal Kk has a p-variant in (cid:3)(cid:4)
B , and by (2) it has one in
(cid:3)i as well. Because of Deﬁnition 4.5(i), there is a remainder literal L of σ (cid:13) and a j (cid:3) i such that (cid:3)j produces L but
j produces L. (cid:2)
(cid:3)j does not produce L. However, this contradicts conclusion (2) above which also entails that (cid:3)(cid:4)

P. Baumgartner, C. Tinelli / Artiﬁcial Intelligence 172 (2008) 591–632

613

The completeness of the calculus is a consequence of Proposition 4.16. We state it here in its contrapositive form

to underline the model computation abilities of ME .

Theorem 4.17 (Completeness). Let (cid:2) be a parameter-free (cid:4)-clause set, and let D be a fair derivation of (cid:2) with limit
tree T. If T is not a refutation tree, then (cid:2) is satisﬁable; more speciﬁcally, for every exhausted branch B of T, I(cid:3)B is
a model of (cid:2).

Let (cid:18) be the universally true clause. For every clause C ∈ (cid:2), we deﬁne C0 := C, and for all i > 0

⎧

⎪⎪⎪⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩

Ci :=

D

(cid:18)

if Ci−1 is of the form L ∨ D and Resolve is applied
with selected clause Ci−1 and selected literal L to
(cid:3)i−1 (cid:14) (cid:2)i−1 to obtain (cid:3)i (cid:14) (cid:2)i
if Ci−1 is of the form L ∨ D and Subsume is applied
with selected clause Ci−1 and selected literal L to
(cid:3)i−1 (cid:14) (cid:2)i−1 to obtain (cid:3)i (cid:14) (cid:2)i

Ci−1

otherwise
Observe that for all i (cid:3) 0, {Ci | C ∈ (cid:2)} = (cid:2)i ∪ {(cid:18)}.

Proof. Let C be any clause in (cid:2) and B an exhausted branch of T.

It is enough to show that I(cid:3)B is a model of C. Now, it is easy to see that there is a smallest j such that Ci = Ci−1
for all i > j with i < κ, which means that Cj is either (cid:18) or a persistent clause of B. Let us ﬁx that j . We show below
by induction on i that I(cid:3)B is a model of Ci for all i (cid:5) j , from which it will immediately follow that I(cid:3)B is a model of
C = C0.

(i = j ) If Ci is (cid:18), I(cid:3)B is trivially a model of Ci . Hence assume that Ci is a persistent clause of B, that is, Ci ∈ (cid:2)B.
By Proposition 4.16, it is enough to show that (cid:2)B does not contain the empty clause. Assume by contradiction that it
does, i.e., that (cid:2)B = (cid:2)(cid:13) ∪ {(cid:2)} for some clause set (cid:2)(cid:13).

That (cid:2)B contains the empty clause entails trivially that (cid:2)k contains the empty clause, for some k (cid:3) 0 with k <
k, (cid:2). That (cid:2)(cid:13)
= ∅ holds is impossible by
(cid:10)= ∅. But then, since the empty substitution is certainly a context uniﬁer of
k, (cid:2) with selected clause (cid:2), which is impossible

κ. That is, there must be a k such that (cid:3)k (cid:14) (cid:2)k has the form (cid:3)k (cid:14) (cid:2)(cid:13)
Deﬁnition 4.5(iv). Hence suppose that (cid:2)(cid:13)
k
(cid:2) against (cid:3)k with an empty remainder, Close is applicable to (cid:3)k (cid:14) (cid:2)(cid:13)
by Deﬁnition 4.5(iii). It follows that I(cid:3)B is a model of Cj .

(i < j ) Assume by induction hypothesis that I(cid:3)B is a model of Ci+1, and consider the following three cases,

k

depending on the deﬁnition of Ci+1.

(i) If Ci = Ci+1, we can conclude immediately that I(cid:3)B is a model of Ci .
(ii) If Ci is of the form L ∨ D and Resolve is applied with selected literal L to (cid:3)i (cid:14) (cid:2)i to obtain (cid:3)i+1 (cid:14) (cid:2)i+1,

then Ci+1 = D. It follows immediately that I(cid:3)B is a model of Ci .

(iii) If Ci is of the form L ∨ D and Subsume is applied with selected clause Ci to (cid:3)i (cid:14) (cid:2)i to obtain (cid:3)i+1 (cid:14) (cid:2)i+1,
then Ci+1 = (cid:18). By the deﬁnition of Subsume, there is a K ∈ (cid:3)i such that K (cid:3) L. By Lemma A.15, there is a K (cid:13) ∈ (cid:3)B
such that K (cid:13) (cid:3) K. It follows that there is a K (cid:13) ∈ (cid:3)B such that K (cid:13) (cid:3) L.

Recalling that C ∈ (cid:2) is a parameter-free (cid:4)-clause and that, by deﬁnition, Ci is a sub-clause of C, we have that Ci
is a parameter-free (cid:4)-clause and that L is a parameter-free (cid:4)-literal. From the fact that K (cid:13) (cid:3) L, it follows that K (cid:13)
is also parameter-free and that K (cid:13) (cid:3) Lγ , for any grounding substitution γ . Let Lγ be any such ground (cid:4)-instance.
Now, since K (cid:13) ∈ (cid:3)B and K (cid:13) (cid:3) Lγ , we have by Lemma A.6 that (cid:3)B produces Lγ but does not produce Lγ . It follows
by deﬁnition of I(cid:3)B that I(cid:3)B satisﬁes Lγ . Because Lγ was an arbitrary ground (cid:4)-instance of L, we can deduce that
I(cid:3)B is a model of L, and so of Ci . (cid:2)

When the branch B in Theorem 4.17 is ﬁnite, (cid:3)B coincides with the context (cid:3)n, say, in B’s leaf. From a model
computation perspective, this is a crucial point because it means that a model of the original clause set—or rather, a
ﬁnite representation of it, (cid:3)n—is readily available at the end of the derivation; it does not have to be computed from
the branch, as in other model generation calculi.

614

P. Baumgartner, C. Tinelli / Artiﬁcial Intelligence 172 (2008) 591–632

The calculus is proof conﬂuent [10]: any derivation of an unsatisﬁable clause set extends to a refutation. In fact,
because of the strong completeness result in Theorem 4.17, the calculus satisﬁes an even stronger property, which we
refer to as proof convergence.

Corollary 4.18 (Proof convergence). Let (cid:2) be a parameter-free clause set over the signature (cid:4). If (cid:2) is unsatisﬁable,
then every fair derivation of (cid:2) is a refutation.

In practical terms, the above corollary implies that as long as a derivation strategy guarantees fairness, the order
of application of the rules of the calculus is irrelevant for proving an input clause set unsatisﬁable, giving to the ME
calculus the same kind of ﬂexibility enjoyed by the DPLL calculus at the propositional level.

5. Implementation

At the theoretical level, the development of the ME calculus was motivated by the desire to close an existing
gap in the theorem proving landscape and provide a proper lifting to ﬁrst-order logic of a popular refutation method
for propositional logic, DPLL. At a practical level, the calculus was also motivated by the conjecture that the very
successful improvements developed by the SAT community for DPLL could be lifted to a suitable ﬁrst-order version
of it, and prove themselves similarly effective. To verify such a conjecture we have devised a proof procedure for the
ME calculus and turned it into an implementation, the Darwin theorem prover.21

We have evaluated Darwin experimentally over the TPTP problem library [46], comparing it with state-of-the-art
theorem provers based on other calculi for ﬁrst-order logic. Our experiments have shown that the ME calculus lends
itself to competitive implementations for ﬁrst-order logic without equality. In particular, Darwin is currently very
competitive for input problems with a large percentage of non-Horn clauses. Furthermore, it is the best prover for
function-free clause sets, which correspond to problems belonging to Bernay–Schönﬁnkel class, for which Darwin is
in fact a decision procedure.

In this section we describe the main aspects of Darwin’s proof procedure and implementation. For a more detailed
account of Darwin’s general architecture, proof procedure, heuristics, and implementation details, as well as a detailed
experimental evaluation, we refer the reader to [5].

Iterative deepening proof procedure

Similarly to the DPLL procedure, Darwin’s proof procedure can be seen as exploring in a depth-ﬁrst fashion the
limit tree of a derivation in the calculus. Since the ME calculus is refutationally complete only for fair derivations, the
proof procedure must make sure it gives rise only to fair derivations. This is achieved by performing a sort of iterative
deepening search, however not on the depth of the search tree but of the term depth of certain literals, a complexity
measure based on the depth of a term’s tree representation.

Speciﬁcally, at any moment Darwin maintains a current context and clause set, corresponding to a node of the
derivation tree, and a current set of candidate literals, literals that can be added to the context by an Assert or Split
application. The proof procedure chooses for addition to the context only among those candidate literals whose term
depth does not exceed a current term depth bound. Since by design of the inference rules it is impossible for a context
to contain two or more p-variants of the same literal, this selection strategy implies the termination of any exhaustive
sequence of inference rule applications under the term depth bound.22

After applying exhaustively all inferences rules with respect to the current bound without being able to close the
current branch of the derivation tree, Darwin’s proof procedure checks whether the branch is incomplete. This is the
case if during the generation of the branch a candidate literal was computed that exceeded the current depth bound.
If the current branch is not incomplete it denotes a model of the input set, and the proof procedure reports that.
Otherwise, the procedure behaves according to one of several strategies, as initially speciﬁed by the user. With the
simplest of these strategies, the procedure just restarts the derivation from scratch, but with an increased depth bound.

21 This latter work was in collaboration with Alexander Fuchs, Darwin’s main developer.
22 This termination property is not immediately obvious because of the inﬁnite supply of Skolem constants that can be used in Split inferences.
Referring back to Example 3.13, however, where we argued that no branch can contain more than one Skolemized version of the same literal, one
can see that Split inferences are not problematic in this regard.

P. Baumgartner, C. Tinelli / Artiﬁcial Intelligence 172 (2008) 591–632

615

Backtracking

In exploring a derivation tree, Darwin’s proof procedure generates a choice point for each (left) application of
the Split rule. The depth-ﬁrst exploration, within the term depth bound, of the derivation tree is then achieved by
backtracking to a previous choice point every time a branch is closed. Instead of always going back to the most recent
choice point, Darwin implements backjumping, a more effective form of chronological backtracking that takes into
account dependencies between choice points. The idea of backjumping is best explained in terms of the calculus:
suppose the derivation subtree below a left node introduced by a Split rule application is closed and the literal added
on the left conclusion by that application is not needed to establish that the subtree is closed. Then, the Split rule
application can be viewed as not being carried out at all. The proof procedure thus may skip the corresponding choice
point on backtracking and proceed to the previous one.

Backjumping is well known to be one of the most effective improvements for DPLL-based SAT solvers. Its imple-
mentation for ME is not too difﬁcult and relies on keeping track of which context literals and clauses are involved in
particular in Assert and Close rule applications. Backjumping is an example of a successful propositional technique
that directly lifts to the proof procedure of Darwin.

Darwin also features dynamic backtracking [26], a sophisticated form of non-chronological backtracking. See [5]

for more details.

Conﬂict-based learning

Another major conceptual improvement in DPLL-based solvers in the last years has been lemma learning, a mech-
anism for generating new propositional clauses that prevent later in the search combinations of split decisions that
have already led to closed subtrees in the derivation.

Something similar can be done in ME -based prover by analyzing the sequence of rule applications of a closed
branch. The analysis determines which of the Split inferences along the branch were really relevant in allowing the
application of Close and saves this information so that the same split choices, or similar choices that would also lead
to a conﬂict, are avoided later in the search. As in DPLL SAT solvers, a convenient way to save such information is in
the form of a clause added to the clause set so that applications of Assert with this clause block prevent the repetition
later of the Split inference that caused the conﬂict.

In contrast to backjumping, adapting DPLL learning methods to an ME -based prover is not immediate, ﬁrst be-
cause one needs to lift properly to the ﬁrst-order level the lemma generation process so that it generates lemmas that
do prune the search space, and second because any such process, when carried over at a ﬁrst-order level, is bound
to add a signiﬁcant computational overhead that can offset in practice the advantages of pruning. On the other hand,
working at the ﬁrst-order level offers the enticing possibility of achieving learning in the more proper sense of word,
with lemmas helping prune also areas of the search space that do not duplicate previously explored ones.

Darwin successfully implements two variants of a learning mechanism that lifts the main features of learning
methods for DPLL procedures. In both variants, lemmas are generated by a guided resolution process that starts with
the selected clause of the Close inference closing a branch and uses a selected number of clauses involved in Assert
inference along the branch. A description of these variants and their positive effects on Darwin’s performance is given
in [6].

Context uniﬁers and selection heuristics

The central operation in Darwin’s proof procedure is the computation of all possible context uniﬁers of current
clauses against the current context. The system computes context uniﬁers of current clauses to identify literals that
can be added to the context by the Split rule (Split candidates), and context uniﬁers of subsets of input clauses to
identify literals that can be added by the Assert rule (Assert candidates). The set of such context uniﬁers is built
incrementally, but exhaustively, as the context grows. With this technique, all possible Assert candidates can be ea-
gerly added to a context, which correspond to the eager unit propagation mechanism of DPLL. Also, all theoretically
necessary Split candidates at any point are available for inspection, allowing the implementation of a heuristic selec-
tion mechanisms for choosing the best literals to split with. The current selection heuristics in Darwin is based on
several considerations, such as whether a candidate contains variables only or whether adding it will cause no proper
branching in the derivation tree.

Darwin uses special data structures and a few dynamic programming techniques to compute and store context
uniﬁers, with the goal of limiting runtime and memory requirements. In addition, it uses term indexing techniques

616

P. Baumgartner, C. Tinelli / Artiﬁcial Intelligence 172 (2008) 591–632

on context to support fast checking of the preconditions of the Split, Assert, and Subsume rules.23 More details on
context uniﬁcation in Darwin can be found again in [5].

6. Related work

Approaches that have features in common with ME come from the following four categories: ﬁrst-order DPLL

methods, instance-based methods, Resolution methods and Tableau methods.

6.1. First-order DPLL methods

A “lifted” version of the DPLL method has been described in the early textbook on automated reasoning by Chang
and Lee [12]. It uses the device of pseudosemantic trees which, like ME , realize splits at the non-ground level.
Nevertheless, the pseudosemantic tree method is very different from our approach: in sharp contrast to ME , a variable
is treated rigidly there, i.e. as a placeholder for a (one) not-yet-known term.24 Section 6.4 below discusses rigid
variable methods, and what is said there applies to the method in [12] as well.

A more recent attempt to incorporate ﬁrst-order reasoning into DPLL has been made in [27,39]. Instead of instan-
tiating the input clauses into ground ones before applying a DPLL method, the modiﬁed DPLL method in [27,39]
directly takes advantage of the (ﬁrst-order) clauses of the input clause set. More speciﬁcally, these clauses are used for
unit propagation on the basis of the current partial (propositional) model candidate. In our terms, this corresponds to
working with ground contexts and using the Assert rule similarly as in ME , but always adding a ground instance of
the Assert literal to the context. In [27,39] it is proven that unit propagation of this kind itself includes an NP-complete
search problem (which, of course, also applies to ME ). However, it is argued that at the same time the much more
compact representations enabled by using ﬁrst-order logic may well pay off. A more fundamental difference between
our approach and that in [27,39] is that the latter is restricted to checking the satisﬁability of quantiﬁer formulas in
ﬁnite models only, whereas ME works with full ﬁrst-order logic.

The closest relative of the ME calculus is the FDPLL calculus developed by one of us [4]. As mentioned in the
introduction, ME is loosely based on FDPLL. More precisely, the ME calculus can be specialized to the core FDPLL
calculus by

(1) removing the Subsume, the Resolve and the Compact inference rules (which are optional in ME ), and
(2) restricting Split to use only admissible context uniﬁers with a variable-free remainder.25

In terms of the present paper, the core calculus of FDPLL does not have simpliﬁcation rules and does not deal with
variables—it just uses parameters. However, in [4] an extension of the core FDPLL calculus to include reasoning with
variables is sketched. Contrary to ME , mixed literals are not allowed, and so the literals used there for splits are of
the same type—variable-free or parameter-free (or both). Even ignoring this aspect, ME is much stronger than that
version of FDPLL. Expressed in ME terms, the rules mentioned under (1) above are still not available in FDPLL.
Furthermore, admissible context uniﬁers are deﬁned to be those that either satisfy the restriction (2) above or have a
unit remainder and use only parameter-free context literals. In resolution terminology, FDPLL mimics unit-resulting
resolution, roughly, on the Horn clause subset of the input clause set.

The impact of the more limited capabilities of FDPLL can be seen by looking at some examples. For instance,
if the current context is just (cid:3) = {¬v} and there is a given clause P (x) ∨ Q(y) ∨ R(z), FDPLL will consider the
clause instance P (u) ∨ Q(v) ∨ R(w) and split based on its literals, which contain parameters. In contrast, ME will
in essence carry out a case analysis according to the three literals P (x), Q(y) and R(z), which have the advantage of
containing variables instead of parameters.26

23 These preconditions require, in essence, to search the context for literals that unify with, subsume, or are subsumed by a given literal.
24 However the term “rigid” is not used there, as it had not been yet introduced at the time the book [12] was written.
25 Using only such admissible context uniﬁers preserves completeness in ME .
26 As discussed in Section 3, the more variables a context literal has in place of parameters, the more constraints it imposes on a derivation.

P. Baumgartner, C. Tinelli / Artiﬁcial Intelligence 172 (2008) 591–632

617

As another example consider the context (cid:3) = {¬v, P (u1, u2), Q(x, a, z)} and the clause R(y, z) ∨ ¬P (x, x) ∨
¬Q(x, y, z). Based on the admissible context uniﬁer σ = {v (cid:5)→ R(a, z), u1 (cid:5)→ u2, x (cid:5)→ u2, y (cid:5)→ a}27 whose sole
remainder literal is R(a, z), the Split rule is applicable in ME . A comparable inference step is not possible with
FDPLL, as one of the involved context literals (namely, P (u1, u2)) is not parameter-free.

In conclusion, due to the presence of the simpliﬁcation inference rules Subsume, Resolve and Compact and the

better treatment of variables, the ME calculus improves signiﬁcantly on FDPLL.

6.2. Instance-based methods

Besides the FDPLL calculus, ME is related to the family of instance-based methods. Proof search in instance-based
methods relies on maintaining a set of instances of input clauses and analyzing it for satisﬁability until completion.
We point out that ME is not an instance-based method in this sense, as clause instances are used only temporarily
within the Split inference rule and can be forgotten after the split has been carried out.

The contemporary stream of research on instance-based methods was initiated with the Hyperlinking calculus (HL)
[32]. This calculus is based on the idea of steadily growing a set of instances of input clauses in an intelligent way,
and regularly testing it for propositional unsatisﬁability by an integrated DPLL procedure. An important conceptual
difference between ME and HL is that the latter includes a DPLL procedure but does not (directly) extend it to
ﬁrst-order clause logic.

The current successor of HL is the Ordered Semantic Hyperlinking calculus (OSHL) [41,42]. OSHL has many
interesting features, for instance “semantical guidance” by assuming a procedural representation of an (any) inter-
pretation, that just has to be capable to decide if a given ground literal is true in the interpretation. As in ME , the
main operation in OSHL is to detect an instance of a clause that is false in a current interpretation, and then repair the
interpretation (in the sense given here). However, unlike ME , the repairs are carried out through ground literals.

Some instance-based calculi have been formulated within the (clausal) tableau framework. Similar to ME , and
unlike HL and its successors, they extend a propositional method—this time propositional clausal tableaux—to the
ﬁrst order level without resorting to a separate propositional solver.

The initial work in this direction is Billon’s disconnection method [11], followed by the calculus described in [3]
which relates to the disconnection method pretty much in the same way as the hyper-resolution calculus relates to the
resolution calculus.

The disconnection method has been picked up by Letz and Stenz for further improvements and efﬁciently imple-
mented into a competitive prover [43]. The disconnection calculus, as they call it, uses clausal tableau as the primary
data structure. The tableau structure represents an exhaustive search through all possible connections between literals
in clauses; the (single) inference rule extends the current tableau by two clause instances found via a connection on
the branch. Thus, the disconnection calculus is conceptually rather different to ME in that the main derivation rule
there is based on resolving pairs of complementary literals from two clauses, whereas ME ’s splitting rule is based on
evaluating all literals of a single clause against a candidate model.

In [34], further improvements on the disconnection calculus are discussed. Among them is a dedicated inference
rule for deriving unit clauses. Interestingly, all variables in such a derived unit clause have to be identiﬁed for sound-
ness reasons. Still, this inference rule represents a limited and local form of “lemma learning” that does not have
a direct counterpart in the ME calculus. Directly comparable to ME are the more recent developments introduced
in [44]. The disconnection calculus there works with two kinds of variables: shared and local ones. The shared
variables correspond to what we call parameters—which are present in one form or the other in all instance-based
methods. A variable qualiﬁes as a local variable if it occurs in just one literal of a clause instance considered for
tableau expansion. There is a roughly corresponding requirement in what we call admissible context uniﬁers, where
a variable occurring in a (remainder) literal must not occur in another remainder literal. The correspondence is not
perfect, however, as clause instances for tableau expansion are derived differently from ME in [44]. Nevertheless, the
concepts are comparable, and their use in subsumption tests is similar.

Two variants of an instance-based method are described by Hooker et al. [29]. One of them, the “Primal Approach”
seems to be very similar to the disconnection method although, unfortunately, the relation with this method is not made

27 For simplicity, and without loss of generality in this case, we are not taking fresh variants of the context literals in computing the context
uniﬁers.

618

P. Baumgartner, C. Tinelli / Artiﬁcial Intelligence 172 (2008) 591–632

explicit in [29]. The other variant, the “Dual Approach”, differs from the former by the presence of auxiliary clauses
of the form K → L generated during the proof search, where (K, L) is a connection of literals occurring in the current
clause set. No simpliﬁcation mechanisms is described, such as for instance those based on unit propagation rules. Both
methods compare to ME in the same way as the disconnection method, discussed above.

Finally, a rather abstract framework for instance-based calculi which also admits simpliﬁcation techniques is de-
scribed in [22]. The underlying idea is to work with a propositional abstraction of a candidate model for the input
clause set. That abstraction is used to guide the search for a refutation in a rather ﬂexible way. As with the Hyper-
linking calculi, the perhaps most signiﬁcant difference between ME (or the disconnection calculus for that matter)
and the framework in [22] is that the latter relies on the execution of propositional satisﬁability tests. This has the
advantage that off-the-shelf SAT solvers can be readily used for those tests. On the other hand, it is unclear how to
exploit ﬁrst-order features like our variables (or the “local variables” of the disconnection calculus) when relying on
a propositional solver. However, as shown in [22] by treating certain variable occurrences in a special way it is some-
times possible to replace the SAT solver by a decision procedure for some fragment of ﬁrst-order logic. This way,
such a decision procedure can sometimes be lifted to work on input formulas outside its fragment.

6.3. Resolution methods

Resolution calculi are conceptually very different from the ME calculus, which makes a comparison difﬁcult.
A common feature is model generation. Modern completeness proofs for resolution calculi provide a method for con-
structing a model of any saturated clause set not containing the empty clause (see [2]). However, this is a conceptual
construction, and non-trivial postprocessing is necessary to extract a model in practice from a failed refutation (but
see [23]). Typically, a model is computed by enumerating all true ground literals, thereby interleaving this enumeration
with calls to the resolution procedure again in order to determine the “next” ground literal [16,17].

6.4. Tableau methods

Apart from clausal tableau methods that are also instance-based methods, which we have already discussed, clausal
tableau calculi in general are related to ME for encoding, like ME , a model of the given clause set in an exhausted
open branch. For comparison purposes, it is useful to classify these calculi according to whether they treat their
variables rigidly or they instantiate them by ground terms.

In tableau calculi with rigid variables, a variable in a tableau is a placeholder for a (one) not-yet-known term
(see e.g. [20] for a basic version). The meaning of rigid variables can also be captured by constraints [24,40,48].
Although (most) tableau calculi are proof conﬂuent, practically usable fair strategies to achieve proof convergence
(cf. Corollary 4.18) are hard to devise (but see [9]).

Another drawback of the rigid variables is that they make it difﬁcult to ﬁnd useful redundancy mechanisms such
as, for instance, one that would in general prevent to have an unbounded number of variants of the same literal along a
branch. More concretely, given the unit clause P (x), say, there seems to be no simple justiﬁcation for not enumerating
variants P (x), P (x(cid:13)), P (x(cid:13)(cid:13)), . . . of P (x) along a branch. In fact, in general, and contrary to ME , one variant is not
enough for completeness, and it is difﬁcult to (automatically) determine sharp bounds on their number—a discussion
on various options in the design of rigid tableau calculi, including constraint-based approaches, can be found in [25].
Ground-level tableau calculi avoid the problems with rigid variables by resorting to the propositional level. While
analytic tableau with the classical γ -rule do not seem a suitable basis to build competitive theorem provers, there are
structural reﬁnements for clause logic that are also related to hyper resolution [7,36] or to Ordered Semantic Hyper
Tableaux [49]. However, these methods suffer from an, generally unavoidable, don’t-know non-determinism, which
can lead to an enumeration of the whole Herbrand base along a branch.

Finally, in contrast to ME , tableau calculi (which includes the disconnection calculus) branch on subformulas, or,
the literals of a clause in the clausal case, as opposed to complementary literals. For the propositional case it is easy
to see that branching on complementary literals as done in ME is more general than branching on clauses. In fact,
each branching on a clause with n literals can be simulated by n splits with complementary literals. Furthermore,
some improvements like factoring (see [33]) are automatically realized by the branching on complementary literals
approach. A systematic investigation on how this fact exactly carries over to the ﬁrst-order case—i.e. ME vs. certain
clausal tableau calculi—is left for future work.

P. Baumgartner, C. Tinelli / Artiﬁcial Intelligence 172 (2008) 591–632

619

7. Conclusions

In this paper we introduced the Model Evolution (ME ) calculus, a refutation calculus for ﬁrst-order clausal logic.
The ME calculus extends the well-known (propositional part of the) DPLL procedure to ﬁrst-order logic by means
of uniﬁcation-based, ﬁrst-order versions of DPLL’s main inference rules. In fact, the calculus is a lifting of DPLL to
the ﬁrst-order level and reduces to DPLL in case of ground clause sets. Compared to its most immediate predecessor,
FDPLL [4], ME is a more faithful lifting of DPLL because it also lifts DPLL’s inference rules for unit propagation.
Except for termination, which is unachievable in the general ﬁrst-order case, the calculus enjoys the same theoretical
properties of DPLL: it is sound, complete for fair derivations, and proof convergent. The latter property in particular
implies that any fair proof procedure for ME is guaranteed to produce a refutation for unsatisﬁable input clause sets.
Also like DPLL, the calculus is such that terminating derivations of a satisﬁable clause set effectively compute a model
of the set.

Our experience with implementing the ME calculus conﬁrms the validity of the idea of lifting DPLL, and its im-
provements, to the (full) ﬁrst-order level. The performance of the Darwin theorem prover for ME compares favorably
with much more mature state-of-the-art provers over the whole class of TPTP problems without equality, and is supe-
rior than most of them over selected non-trivial subclasses. Furthermore, much of the potential of the lifted DPLL idea
is still untapped given that at the moment Darwin implements only some of the major improvements developed for
DPLL. In general, there is still room for further research on how to properly lift and adapt more DPLL improvements
to ﬁrst-order logic, and or on devising new improvements directly for the ﬁrst-order level.

7.1. Further research

We envision several directions for future theoretical work on the ME calculus and its implementations. A few of

them are listed below.

Semantical guidance

As presented here, the ME calculus always starts with an interpretation that assigns false to all ground atoms. By
simply replacing the pseudo-literal ¬v by v, it is possible to have the calculus start instead with a complementary
initial interpretation. The kind of semantic guidance achieved in OSHL [42] by means of a user-deﬁned initial in-
terpretation, is trivially achievable in ME when this interpretation is denotable by a context: one simply starts the
derivation with that context. More work is needed, however, to allow ME to start with arbitrary interpretations, in
particular, ones that cannot be encoded into a (ﬁnite) context.

Equational theories and equality

In many theorem proving applications, an explicit treatment of equality is mandatory. To our knowledge there are
only two instance-based methods that have been extended with dedicated equality inference rules for full equational
clausal logic. One is the disconnection calculus in [35] and the other is the instance-based method in [22]. Both of
the extended calculi are based on superposition-style inference rules [1], with the second one also including rather
powerful redundancy criteria. Our initial results on extension of ME with inference rules for equality reasoning are
presented in [8]. Further work will concentrate on building an efﬁcient and competitive implementation of the new
calculus.

ME as a decision procedure

A deduction system capable of deciding relevant classes of formulas is usually of greater practical interest than a

mere refutation system (e.g., to disprove false “theorems” in a software veriﬁcation context).

The ME calculus is guaranteed to terminate for clauses resulting from the translation to clausal form of con-
junctions of Bernays–Schönﬁnkel formulas28 and hence gives a decision procedure.29 The same holds for many
instance-based methods (see Section 6.2), but, interestingly, not for any known reﬁnement of the resolution calculus.

28 Such clauses contain no function symbols, but no other restrictions apply.
29 This is an easy consequence of the fact that there are no two p-variants of a literal on any sequent derivable by ME (cf. Lemma A.14).

620

P. Baumgartner, C. Tinelli / Artiﬁcial Intelligence 172 (2008) 591–632

On the other hand, there are reﬁnements of the resolution calculus that decide (see [18]) classes of formulas not obvi-
ously decidable by ME or other instance based methods. It would be interesting to investigate ways to reﬁne ME so
that it can decide some of these classes or other classes not currently decided by resolution methods.

Acknowledgements

We thank Alexander Fuchs for his helpful comments on this paper and for all his outstanding work on the Darwin
prover. We are also thankful to Thomas Hillenbrand, Yevgeny Kazakov and Konstantin Korovin for being always open
for discussions on ME .

Appendix A

This appendix contains auxiliary lemmas, their proofs, and proofs of the results stated in the main part of this
paper. It is structured in three parts. Section A.1 is a collection of results about contexts in general, not necessarily
about contexts as they evolve in derivations. The latter is the subject of Section A.2. The subsequent Section A.3
then contains lemmas stating conditions under which the mandatory inference rules of ME are applicable. The results
collected up to then were employed in Section 4.3 to prove our main theorem, the completeness of ME .

A.1. Properties of contexts

The ﬁrst lemma is not concerned with contexts; it will be needed, however, for some proofs below.

Lemma A.1. For any literal L, the sets {K | K (cid:3) L} / (cid:11) and {K | K (cid:2) L} / (cid:11) are ﬁnite.

That is, for a given literal L, there are only ﬁnitely many more general literals wrt (cid:3) of L modulo p-variantship,

and similarly for (cid:2). A similar result formulated in terms of (cid:2) and ≈ is proven in [15].

Proof. Since K (cid:2) L whenever K (cid:3) L, it is enough to show that the set {K | K (cid:2) L} / (cid:11) is ﬁnite.

In the following argumentation we will prove the claim using a tree representation of literals: if L is a literal, its tree
representation is the (ordered) tree, the root of which is labeled with the predicate symbol of the literal, inner nodes
are labeled with function symbols, and leaf nodes are labeled with constant or variable symbols, all in the obvious
way.

Recall that K (cid:3) L means there is a (p-preserving) substitution σ such that Kσ = L. This means that the tree for L
is obtained by replacing each variable leaf node x in the tree for K by the tree for xσ , and similarly for parameters.
Clearly, the number of nodes in K is less than or equal to the number of nodes in L.

Now let {x1, . . . , xn} ⊂ X and {u1, . . . , un} ⊂ V be ﬁnite sets of any n pairwise different variables and any n

pairwise different parameters, respectively,where n is the number of nodes of the tree representation of L.

Let K be any literal such that K (cid:2) L and such that K contains variables and parameters from the ﬁnite sets just

mentioned only.

Because the number of nodes in K is less than or equal to the number of nodes in L, it follows together with the
assumed ﬁnite sets of variables and parameters that only ﬁnitely many such literals K (cid:2) L exist. Let K be the ﬁnite
set of all these literals.

Notice that K is ﬁnite also if the signature under consideration contains inﬁnitely many function symbols. This
holds, because K cannot contain any function symbol not occurring in L (because then K could not be instantiated to
L), and there occur only ﬁnitely many function symbols in L.

Clearly, every literal K with K (cid:2) L is a (cid:11)-variant of some literal in K. Therefore, with K being ﬁnite, so is

{K | K (cid:2) L} / (cid:11). (cid:2)

Lemma A.2. Let (cid:3) be a context and let K, L be literals. If K (cid:3) L and L ∈(cid:2) (cid:3), then K is contradictory with (cid:3).

In words, if the complement of some literal from (cid:3) and K admit a common p-instance, then K is contradictory

with (cid:3). Most of the times this lemma is used only in a weaker form, where K = L.

P. Baumgartner, C. Tinelli / Artiﬁcial Intelligence 172 (2008) 591–632

621

Since the calculus works on non-contradictory contexts only, the lemma above implies that no context contains a

literal and the complement of one of its p-instances.

Proof. Suppose that K (cid:13) ∈ (cid:3), K (cid:13) (cid:3) L and K (cid:3) L. Let K (cid:13)(cid:13) (cid:11) K (cid:13) be a fresh p-variant of K (cid:13). With K (cid:13) (cid:3) L it follows
K (cid:13)(cid:13) (cid:3) L. Let σ be a p-preserving substitution such that K (cid:13)(cid:13)σ = L. Since K (cid:13)(cid:13) is fresh, σ may be assumed to move
only the variables and parameters of K (cid:13)(cid:13). Therefore σ will not modify L, and so L = Lσ follows. Altogether then
K (cid:13)(cid:13)σ = Lσ .

Because of K (cid:3) L there is a p-preserving substitution σ (cid:13) such that Kσ (cid:13) = L. This implies Kσ (cid:13)σ = Lσ . Since
K (cid:13)(cid:13) is fresh, σ (cid:13) may be assumed not to modify K (cid:13)(cid:13), and K (cid:13)(cid:13) = K (cid:13)(cid:13)σ (cid:13) follows. With K (cid:13)(cid:13)σ = Lσ from above it follows
K (cid:13)(cid:13)σ (cid:13)σ = Lσ . Together with Kσ (cid:13)σ = Lσ it follows K (cid:13)(cid:13)σ (cid:13)σ = Kσ (cid:13)σ . But then, since both σ (cid:13) and σ are p-preserving
and because of K (cid:13)(cid:13) ∈(cid:11) (cid:3), K is contradictory with (cid:3). (cid:2)

Lemma A.3. Let (cid:3) be a context, K ∈ (cid:3) and K (cid:13), L literals. If K (cid:3) L and K (cid:13) shields L from K then K (cid:13) is contradictory
with (cid:3).

The previous lemma implies that no literal in a context produced by the ME calculus can shield a p-instance of

another literal in the context. This fact easily entails the next two results below.

Proof. Suppose that K (cid:3) L and K (cid:13) shields L from K. This means there is literal K (cid:13)(cid:13) such that K (cid:13) (cid:3) K (cid:13)(cid:13) and K (cid:2)
K (cid:13)(cid:13) (cid:2) L. Let σ , σ (cid:13) be p-preserving substitutions such that Kσ = L and K (cid:13)σ (cid:13) = K (cid:13)(cid:13). Without loss of generality assume
that K (cid:13)(cid:13) does not contain a single variable. (If this is not the case, let ρ be a (p-preserving) substitution that maps each
of K (cid:13)(cid:13)’s variables to a fresh parameter, and observe that K (cid:13) (cid:3) K (cid:13)(cid:13)ρ and K (cid:2) K (cid:13)(cid:13)ρ (cid:2) L hold; in the sequel K (cid:13)(cid:13) itself
will be used to denote K (cid:13)(cid:13)ρ then.)

We distinguish two exhaustive cases, where the ﬁrst case will directly lead to a proof of the conclusion, while the

second case will be shown to be impossible.

If K (cid:3) K (cid:13)(cid:13), this implies K (cid:13)(cid:13) ∈(cid:2) (cid:3), and so with K (cid:13) (cid:3) K (cid:13)(cid:13) it follows immediately with Lemma A.2 that K (cid:13) is

contradictory with (cid:3).

If K (cid:10)(cid:3) K (cid:13)(cid:13), then from K (cid:2) K (cid:13)(cid:13) and K (cid:13)(cid:13) (cid:2) L conclude that there are substitutions δ and δ(cid:13) such that Kδ = K (cid:13)(cid:13) and

K (cid:13)(cid:13)δ(cid:13) = L, where δ is not p-preserving. For later use note Kδδ(cid:13) = L.

Let U := {u1, . . . , un} = Par(K) be the (pairwise different) parameters of K, for some parameters u1, . . . , un and
n (cid:3) 0. With Kσ = L from above, and since σ is p-preserving, there is a subset {v1, . . . , vn} of L’s parameters that σ
maps U onto, for some parameters v1, . . . , vn. Without loss of generality assume that uiσ = vi , for i = 1, . . . , n. Of
course, the parameters in {v1, . . . , vn} must be pairwise different, too.

From Kδδ(cid:13) = L and Kσ = L it follows uiδδ(cid:13) = vi . Clearly, uiδ is a variable or a parameter, because otherwise
uiδδ(cid:13) = vi would be impossible. However, K (cid:13)(cid:13) was assumed above to contain no single variable. With Kδ = K (cid:13)(cid:13)
it follows the stronger result that uiδ is a parameter. Now, it is impossible that a bijection from U onto U δ exists,
because then, with U being the set of all parameters in K, this substitution, say, δU , and the substitution δ|X could be
combined as the p-preserving substitution δU δ|X, and K(δU δ|X) = K (cid:13)(cid:13) would follow, contradicting the current case
K (cid:10)(cid:3) K (cid:13)(cid:13). This implies that δ identiﬁes at least two parameters in U , say u1 and u2. But then, with u1δ = u2δ it is
impossible to have (u1δ)δ(cid:13) = v1, (u2δ)δ(cid:13) = v2 and v1 (cid:10)= v2. Hence the case K (cid:10)(cid:3) K (cid:13)(cid:13) is impossible, which remained to
be shown. (cid:2)

Lemma A.4. Let (cid:3) be a non-contradictory context and K ∈ (cid:3). Then, for any literal L with K (cid:3) L, K strongly covers
L in (cid:3).

Proof. Let L be a literal with K (cid:3) L. It follows immediately K (cid:2) L. If K does not strongly cover L in (cid:3), then there
is a literal K (cid:13) ∈ (cid:3) that shields L from K in (cid:3). But then, by Lemma A.3 K (cid:13) is contradictory with (cid:3). Since (cid:3) is given
as non-contradictory, there is no such literal K (cid:13) ∈ (cid:3), and so K strongly covers L in (cid:3). (cid:2)

Lemma A.5. Let (cid:3) be a non-contradictory context and K, L be literals. If K strongly covers L in (cid:3) then K produces
L in (cid:3).

622

P. Baumgartner, C. Tinelli / Artiﬁcial Intelligence 172 (2008) 591–632

This lemma states that the “strongly covers” relation is stronger than the “produces” relation. That the converse of

the lemma does not hold can be seen from Example 3.7.

Proof. Suppose that K strongly covers L in (cid:3). It follows that K covers L in (cid:3). If there is a K (cid:13) ∈ (cid:3) that shields L
from K, then by Lemma A.3 K (cid:13) is contradictory with (cid:3). Since (cid:3) is given as non-contradictory, there is no such literal
K (cid:13) ∈ (cid:3), and so K produces L in (cid:3). (cid:2)

Lemma A.6. Let (cid:3) be a non-contradictory context and K ∈ (cid:3). Then, for any literal L with K (cid:3) L,

(i) K produces L in (cid:3), and
(ii) (cid:3) does not produce L.

Proof. Let L be a literal such that K (cid:3) L. That K produces L in (cid:3) follows immediately with Lemmas A.4 and A.5.
To show that (cid:3) does not produce L, let K (cid:13) ∈ (cid:3) be any literal such that K (cid:13) (cid:2) L.30 We will show that K (cid:13) does not
produce L in (cid:3). From the given assumption K (cid:3) L it follows (a) with Lemma A.4 that K strongly covers L in (cid:3),
and (b) that K shields L from K (cid:13). Together with K (cid:13) ∈ (cid:3) this implies that K (cid:13) does not produce L in (cid:3). (cid:2)

Lemma 4.7. Let (cid:3) be a non-contradictory context. Then, for any literal L, (cid:3) produces L or (cid:3) produces L (or both).

Proof. Let L be any literal. We will directly prove that (cid:3) produces L or (cid:3) produces L.

Due to the presence of the pseudo-literal ¬v in (cid:3), (cid:3) covers L (the case that ¬v covers L in (cid:3) is possible). More
precisely, there is a K ∈ (cid:3) such that there is no literal K (cid:13)(cid:13) ∈ (cid:3) with K (cid:2) K (cid:13)(cid:13) (cid:2) L or K (cid:2) K (cid:13)(cid:13) (cid:2) L. This is possible,
because there are only ﬁnitely many literals K (cid:13)(cid:13) (modulo renaming) such that K (cid:13)(cid:13) (cid:2) L or K (cid:13)(cid:13) (cid:2) L (cf. Lemma A.1),
and because the relation (cid:2) is a strict, partial ordering, and hence does not admit cycles.

For reasons of symmetry we consider in the sequel only the case where K (cid:2) L and there is no K (cid:13)(cid:13) ∈ (cid:3) with

K (cid:2) K (cid:13)(cid:13) (cid:2) L. Observe this just means that K covers L in (cid:3).

By condition (2) in Deﬁnition 3.6, if there is no K (cid:13) ∈ (cid:3) that strongly covers L in (cid:3) and that shields L from K,
then K produces L in (cid:3). Otherwise, if there is such a K (cid:13) ∈ (cid:3), then by Lemma A.5 K (cid:13) produces L in (cid:3). Together we
have thus shown that (cid:3) produces L or (cid:3) produces L. (cid:2)

Lemma A.8. Let (cid:3) be a context and K, K (cid:13), L literals. If K produces L in (cid:3) and K (cid:2) K (cid:13) (cid:2) L then K produces K (cid:13)
in (cid:3).

Proof. Suppose that K produces L in (cid:3) and K (cid:2) K (cid:13) (cid:2) L. We will show that K produces K (cid:13) in (cid:3).

Clearly, K cover K (cid:13) in (cid:3) (for, if it did not, K would not cover L in (cid:3) either, contradicting that K produces L in
(cid:3)). Now, if K would not produce K (cid:13) in (cid:3), then there is a K (cid:13)(cid:13) ∈(cid:2) (cid:3) such that K (cid:2) K (cid:13)(cid:13) (cid:2) K (cid:13). But with K (cid:13) (cid:2) L it
would follow K (cid:2) K (cid:13)(cid:13) (cid:2) L, and so K would not produce L in (cid:3) either. (cid:2)

The next two lemmas complement each other. Their prerequisites mean that L is contradictory with (cid:3), as witnessed
by a literal K ∈(cid:11) (cid:3). The ﬁrst lemma considers the case that L is parameter-free, and the second lemma considers the
case that L is variable-free. Both lemmas express how a literal K (cid:13) (cid:11) K can take the rôle of K.

A.2. Evolving contexts

Derivations are about stepwise modiﬁcations of sequents. This subsection contains lemmas mainly describing
constraints on how contexts in sequents can evolve in a derivation. One such constraint, for instance, is that it is
impossible to derive a sequent with a context that contains two p-variants of the same literal.

For the rest of this section, we make the same assumptions as stated in the beginning of Section 4.3.3. In particular
thus let (cid:2) be a set of parameter-free (cid:4)-clauses and assume that D is a fair derivation of (cid:2) that is not a refutation.

30 If such a literal does not exist, (cid:3) cannot produce L.

P. Baumgartner, C. Tinelli / Artiﬁcial Intelligence 172 (2008) 591–632

623

Furthermore, let B = (Ni)i<κ be an exhausted branch of D’s limit tree and let (cid:3)i (cid:14) (cid:2)i denote the sequent labeling
the node Ni in B, for all i < κ.

Lemma A.9. For all i < κ, (cid:3)i is not contradictory.

Being non-contradictory is a fundamental property of the contexts manipulated by the calculus. Lemma A.9 essen-

tially says that rule applications produce non-contradictory contexts from non-contradictory contexts.

Proof. The proof is by induction on i. For the base we have (cid:3)0 = {¬v} and this set is trivially not contradictory.
For the induction step we take as induction hypothesis the claim of the lemma. Observe that each inference rule that
extends a context includes as an applicability condition that the resulting context(s) is (are) not contradictory. With
this observation the induction step follows immediately. (cid:2)

The next lemma extends the previous one to the limit case.

Lemma 4.13. (cid:3)B is not contradictory.

Proof. Suppose that (cid:3)B is contradictory. Then there are literals L ∈ (cid:3)B and K ∈(cid:11) (cid:3)B and there is a p-preserving
substitution σ such that Lσ = Kσ . By the compactness property, there is a j such that both L ∈ (cid:3)j and K ∈(cid:11) (cid:3)j .
By virtue of the substitution σ , (cid:3)j is contradictory then. However, this is impossible by Lemma A.9. (cid:2)

Lemma A.11. The sequent (cid:3), L (cid:14) (cid:11) is not derivable from a sequent (cid:3) (cid:14) (cid:11) in B if L ∈(cid:2) (cid:3) or L ∈(cid:2) (cid:3).

Lemma A.11 states that the inference rules of the ME calculus never add a literal to a context in presence of a

more general one (wrt (cid:3)). One could say that this fact expresses a kind of loop check.

Proof. It sufﬁces to consider potential applications of the Split or the Assert inference rule to (cid:3), because these are the
only rules that can extend a context.

By the applicability conditions of both the Split and the Assert inference rules, the context (cid:3) can be extended with
the literal L only if L is not contradictory with L. Now, if L ∈(cid:2) (cid:3) then by Lemma A.2 L is contradictory with (cid:3) and
so in this case neither Split nor Assert is applicable. Hence it only remains to be shown that the sequent (cid:3), L (cid:14) (cid:11) is
not derivable from (cid:3) (cid:14) (cid:11) if L ∈(cid:2) (cid:3).

Split) Recall that the Split rule is applicable only if neither K nor K

is contradictory with (cid:3), where K is the
remainder literal to split with. We consider two cases, corresponding to the case that the literal L in the lemma
statement is K or is K
is
contradictory with (cid:3).

. In both cases we will show that Split is not applicable by showing that K or K

In the ﬁrst case the literal L in the lemma statement is K. That K ∈(cid:2) (cid:3) holds means there is a literal K (cid:13) ∈ (cid:3) and

sko

sko

sko

a p-preserving substitution σ such that K (cid:13)σ = K.

Let μ be the Skolemizing substitution used, i.e. the substitution μ such that Kμ = K sko. From K (cid:13)σ = K it follows
trivially that K (cid:13)σ μ = Kμ. Since σ μ is p-preserving, we then have that K (cid:13) (cid:3) Kμ. With Kμ = K sko we get K (cid:13) (cid:3) K sko,
or equivalently K (cid:13) (cid:3) K
is
contradictory with (cid:3). This completes the proof for the ﬁrst case.
In the second case the literal L in the lemma statement is K

. Since K (cid:13) ∈ (cid:3), this means in other words K

sko ∈(cid:2) (cid:3) holds means there is a literal

sko ∈(cid:2) (cid:3). But now, by Lemma A.2, K

. That K

sko

sko

sko

K (cid:13) ∈ (cid:3) and a p-preserving substitution σ such that K (cid:13)σ = K

sko

.

Let μ be the Skolemizing substitution used, i.e. the substitution μ such that Kμ = K sko. It can be written as
μ = {x1 (cid:5)→ a1, . . . , xn (cid:5)→ an}, where x1, . . . , xn are all the variables occurring in K, and a1, . . . , an are fresh constants.
Now, because the constants a1, . . . , an are fresh, none of them will occur in K. This means that we can consider
the “substitution” μ(cid:13) = {a1 (cid:5)→ x1, . . . , an (cid:5)→ xn} and have that K = Kμμ(cid:13) = K skoμ(cid:13). From K (cid:13)σ = K
it follows
trivially K (cid:13)σ μ(cid:13) = K

μ(cid:13).

sko

sko

624

P. Baumgartner, C. Tinelli / Artiﬁcial Intelligence 172 (2008) 591–632

Recall that the substitution σ is p-preserving. We may assume that all the variables moved by σ are just the variables
of K (cid:13), and each variable in K (cid:13) is moved by σ to some Skolem constant ai , so that K (cid:13)σ = K
holds. It follows that
the substitution σ μ(cid:13) is a renaming on V and each variable in K (cid:13) is moved to some variable xi (not necessarily in an
injective way). More formally, K (cid:13) (cid:3) K (cid:13)σ μ(cid:13) holds.

sko

Now, from K (cid:13)σ μ(cid:13) = K

sko

μ(cid:13) and with K = K skoμ(cid:13) we get easily K (cid:13)σ μ(cid:13) = K. Since K (cid:13) ∈ (cid:3) this means in other

words K ∈(cid:2) (cid:3). But now, by Lemma A.2, K is contradictory with (cid:3). This completes the proof for the second case.
is contradictory with (cid:3), which remained to be shown.

Together, thus, K or K
Assert) The proof is immediate from the applicability condition from Assert, which explicitly demands that there

sko

is no K ∈ (cid:3) such that K (cid:3) L. (cid:2)

In the course of the development of a branch, a literal in a sequent’s context may be deleted by means of the
Compact rule. Such a deletion is only possible in presence of a p-subsuming literal, which takes the rôle of the deleted
literal. This process may continue and is formalized in the following deﬁnition.

Deﬁnition A.12. Let K be a literal. For all i < κ, if L ∈ (cid:3)i then the trace of L from (cid:3)i is the sequence (Lj )i(cid:2)j <κ ,
where Lj := L if j = i, and for all j > i,

⎧
⎨

Lj :=

⎩

K

Lj −1

if Compact is applied with selected literal Lj −1 and
subsuming literal K to (cid:3)j −1 (cid:14) (cid:2)j −1 to obtain (cid:3)j (cid:14) (cid:2)j
otherwise

Lemma A.13. Let i < κ and L ∈ (cid:3)i . For every j with i (cid:5) j < κ, there is a K ∈ (cid:3)j such that K (cid:3) L.

While growing a branch, the ME calculus can delete a literal from the current context by means of the Compact
rule. Such a deletion is only possible after the addition of a p-subsuming literal, which takes the rôle of the deleted
literal. The p-subsuming literal itself may be deleted later, in a similar way. Lemma A.13 is a formal statement of this
process.

Proof. Consider the trace (Lj )i(cid:2)j <κ of L from (cid:3)i . Each literal Lj from the trace, where i (cid:5) j < κ, is contained in
(cid:3)j , and Lj (cid:3) L holds by construction of the trace. (cid:2)

Lemma A.14. For all distinct literals K, L ∈

(cid:14)

i<κ (cid:3)i it holds that K (cid:10)(cid:11) L.

Lemma A.14 states that if some context in the branch B contains a literal K, then neither this nor any other context

can contain a p-variant L of K. This holds even if K is deleted at some point along the branch.

(cid:14)

Proof. Assume by way of contradiction that K (cid:11) L for some different literals K, L ∈
i<κ (cid:3)i . Notice ﬁrst that not
both K and L can be pseudo-literals, i.e. of the form ¬v, because the context (cid:3)0 contains exactly one such pseudo-
literal and the calculus has no inference rules to add (or to delete) those. If only one of K and L is a pseudo-literal,
the lemma holds trivially. Hence, from now on assume that neither K nor L is a pseudo-literal.

There must be ﬁnite ordinals j and k such that L ∈ (cid:3)j and K ∈ (cid:3)k. W.l.o.g. assume that j (cid:3) k. Furthermore j and
k may be chosen minimal, i.e. L /∈ (cid:3)j −1 and K /∈ (cid:3)k−1. This means that some inference rule is applied to the node
Nj −1 that extends the context (cid:3)j −1 with L to obtain (cid:3)j (and similarly for K). Observe that the inference rules of ME
extend the given context by at most one literal. In particular, K cannot have been added to (cid:3)j −1 by the considered
inference rule application. Thus, not only j (cid:3) k but also j > k must hold.

But then, by Lemma A.13 there is a literal K (cid:13) ∈ (cid:3)j −1 such that K (cid:13) (cid:3) K. Together with K (cid:11) L it follows imme-
diately that K (cid:13) (cid:3) L. However, according to Lemma A.11 the considered inference rule application that extends (cid:3)j −1
by L is not possible. A plain contradiction. Thus, we must have K (cid:10)(cid:11) L. (cid:2)

Lemma A.15. For all i < κ and L ∈ (cid:3)i there is a K ∈ (cid:3)B such that K (cid:3) L.

P. Baumgartner, C. Tinelli / Artiﬁcial Intelligence 172 (2008) 591–632

625

Lemma A.15 essentially states that the set of persistent context literals of the branch B contains generalizations of

all the context literals along B.

Proof. Consider the trace (Lj )i(cid:2)j <κ of L from (cid:3)i . All its consecutive different elements Lj and Lj +1 are those
where the Compact rule is applied to the sequent (cid:3)j (cid:14) (cid:2)j labeling the node Nj . That Compact is applied means
Lj +1 (cid:3) Lj . Of course, both Lj +1 ∈ (cid:3)j and Lj ∈ (cid:3)j must hold as well. By Lemma A.14 we can conclude that
Lj +1 (cid:10)(cid:11) Lj . Together with Lj +1 (cid:3) Lj this entails that Lj +1 (cid:3) Lj .

In other words, the considered consecutive different elements from the trace determine a sequence of increasing
literals wrt (cid:3). With Lemma A.1 it follows immediately that this sequence is ﬁnite. If the sequence is non-empty, let
K be its last element. Otherwise, let K = L. In both cases it is easy to see that K ∈ (cid:3)B and K (cid:3) L. (cid:2)

Lemma A.16. If L ∈ (cid:3)B and L ∈ (cid:3)i , for some i < κ, then L ∈ (cid:3)j , for all j (cid:3) i with j < κ.

This means if a persistent literal of a context is present at some time i, then it is present from that time on.
This is not trivial, as it does not follow from the deﬁnition of “persistency” alone: that deﬁnition is consistent with
having, say, L ∈ (cid:3)i , L /∈ (cid:3)i+1 and L ∈ (cid:3)j +2 for j (cid:3) i. The result above instead really expresses a property of ME
calculus.

Proof. Suppose L ∈ (cid:3)B and L ∈ (cid:3)i for some i as stated. Suppose, to the contrary of the lemma conclusion, there is a
j (cid:3) i such that L /∈ (cid:3)j . By Lemma A.13 there is a K ∈ (cid:3)j such that K (cid:3) L. By induction we now show that L /∈ (cid:3)k
for all k (cid:3) j with k < κ. Once shown, this completes the proof, because this results contradicts the given assumption
L ∈ (cid:3)B. We further take the invariant that, for every k as stated, there is a literal K ∈ (cid:3)k such that K (cid:3) L.

k = j ) Trivial, as L /∈ (cid:3)j and K ∈ (cid:3)j with K (cid:3) L is assumed.
k (cid:5)→ k + 1) We consider the possible inference rule applications to derive (cid:3)k+1 (cid:14) (cid:2)k+1 from (cid:3)k (cid:14) (cid:2)k, thereby

concentrating on the non-trivial cases.

If Compact is applied to (cid:3)k (cid:14) (cid:2)k with selected literal K, both (cid:3)k and (cid:3)k+1 must contain a literal K (cid:13) (cid:3) K. By the

invariant we know K (cid:3) L, and so K (cid:13) (cid:3) L follows. Therefore chose now K := K (cid:13) to preserve the invariant.

If some inference rule is applied to extend (cid:3)k to (cid:3)k+1, L(cid:13), for some literal L(cid:13), then with Lemma A.11 it follows

K (cid:10)(cid:3) L. This implies L /∈ (cid:3)k+1. The invariant is trivially preserved.
This completes the induction, and hence the whole proof. (cid:2)

Lemma A.17. Let K, L be two literals. If K does not strongly cover L in (cid:3)B, then there is an i < κ such that for all
j with i (cid:5) j < κ, K does not strongly cover L in (cid:3)j .

Proof. Suppose that K does not strongly cover L in (cid:3)B. We will directly prove the conclusion.

If K (cid:10)(cid:2) L then the lemma holds trivially (take i = 0). Hence assume K (cid:2) L from now on. That K does not strongly
cover L in (cid:3)B then implies that (cid:3)B shields L from K. This means, there is a K (cid:13) ∈ (cid:3)B and a p-preserving substitution
σ such that K (cid:2) K (cid:13)σ (cid:2) L. Since K (cid:13) ∈ (cid:3)B there is a k < κ such that K (cid:13) ∈ (cid:3)k. By Lemma A.15 there is a K (cid:13)(cid:13) ∈ (cid:3)B
with K (cid:13)(cid:13) (cid:3) K (cid:13). Since K (cid:13)(cid:13) ∈ (cid:3)B there is an i < κ such that K (cid:13)(cid:13) ∈ (cid:3)j , for all j (cid:3) i with j < κ.

Let σ (cid:13) be a p-preserving substitution such that K (cid:13)(cid:13)σ (cid:13) = K (cid:13). From this, K (cid:2) K (cid:13)(cid:13)σ (cid:13)σ (cid:2) L follows immediately.
Because both σ (cid:13) and σ are p-preserving, σ (cid:13)σ is p-preserving as well. Thus, K (cid:13)(cid:13) shields L from K. Since K (cid:13)(cid:13) ∈ (cid:3)j ,
for all j with i (cid:5) j < κ, (cid:3)j shields L from K, and so K does not strongly cover L in (cid:3)j . (cid:2)

Lemma 4.14. Let K, L be two literals with K ∈ (cid:3)B. If K produces L in (cid:3)B, then there is an i < κ such that for all
j (cid:3) i with j < κ, K ∈ (cid:3)j and K produces L in (cid:3)j .

Proof. Assume that K produces L in (cid:3)B. We will directly prove the conclusion.

Since K ∈ (cid:3)B there is a k < κ such that K ∈ (cid:3)k, for all j (cid:3) k. However, there is no guarantee that k is the index
i we are looking for. Informally, it might be the case that a literal K (cid:13) shielding L from K and strongly covering L
is present in (cid:3)k or some successor context. While there is no way then of preventing any such context to shield L
from K, we will show that necessarily none of the ﬁnitely many literals K (cid:13) shielding L from K will strongly cover L
from some timepoint on (Lemma A.17 will be used for this). More formally, let

626

P. Baumgartner, C. Tinelli / Artiﬁcial Intelligence 172 (2008) 591–632

M = {K

(cid:13) | there is an m (cid:3) k with m < κ such that K (cid:13) ∈(cid:2) (cid:3)m and K (cid:2) K

(cid:13) (cid:2) L}

be those literals in (cid:3)m that shield L from K, for some m (cid:3) k.
(cid:14)

Since K (cid:13) (cid:2) L for each K (cid:13) ∈ M, the set M / (cid:11) must be ﬁnite by Lemma A.1. Moreover, M is trivially a subset of
i<κ (cid:3)i . Therefore Lemma A.14 is applicable, and it gives us K (cid:13)
∈ M.
This means that each element of M / (cid:11) is a singleton. In sum, M / (cid:11) is a ﬁnite set of (singleton) equivalence classes.
Therefore M itself is ﬁnite.

2 for any two different literals K (cid:13)

1, K (cid:13)

(cid:10)(cid:11) K (cid:13)

1

2

Let

M

(cid:13) = M ∩ (cid:3)B

be the set of persistent literals of (cid:3)B and of M that shield L from K. Clearly, with M being a ﬁnite set, M (cid:13) also is. Let
k(cid:13) < κ be the smallest index such that M (cid:13) ⊆ (cid:3)j (cid:13) , for all j (cid:13) (cid:3) k(cid:13) (such a k(cid:13) must exist by the compactness property).

It is impossible that (cid:3)k(cid:13) is extended later with a new literal that shields L from K. More formally, for all j (cid:13) (cid:3) k(cid:13), any
literal K (cid:13)(cid:13) ∈ (cid:3)j (cid:13) that shields L from K is contained in M (cid:13). This is, because for any such literal K (cid:13)(cid:13), by Lemma A.15
there is a K (cid:13) ∈ (cid:3)B, with K (cid:13) (cid:3) K (cid:13)(cid:13). It is easy to see that then K (cid:13) shields L from K, and hence K (cid:13) is contained in M (cid:13),
and so is contained in (cid:3)k(cid:13) .

Because of this property, that any literal in (cid:3)j (cid:13) (for any j (cid:13) (cid:3) k(cid:13)) that shields L from K is already contained in M (cid:13),
to prove the claim it sufﬁces by deﬁnition of productivity to show that from some timepoint on equal or later than k(cid:13),
none of the literals in M (cid:13) strongly produces L in that contexts.

More precisely, for any literal K (cid:13) ∈ M (cid:13), from K (cid:13) ∈ (cid:3)B, the fact that K (cid:13) shields L from K, and the assumption that
K produces L in (cid:3)B, conclude by the deﬁnition of productivity that K (cid:13) does not strongly cover L in (cid:3)B. Then, by
applying Lemma A.17 to each literal K (cid:13) ∈ M (cid:13), we can conclude from the ﬁniteness of M (cid:13) that there is an index i (cid:3) k(cid:13)
such that for all j (cid:3) i and for each K (cid:13) ∈ M (cid:13), K (cid:13) does not strongly cover L in (cid:3)j . Together with the conclusion above
that any literal in (cid:3)j (cid:13) (for any j (cid:13) (cid:3) k(cid:13)) that shields L from K is already contained in M (cid:13), this implies that K produces
L in (cid:3)j , for all j (cid:3) i. To complete the proof it is enough to recall that K ∈ (cid:3)j for all j (cid:3) k with j < κ and that
i (cid:3) k(cid:13) (cid:3) k. (cid:2)

A.3. Properties of inference rules

The following lemmas provide sufﬁcient conditions for the applicability of the main rules of the calculus to a given

context.

Lemma 4.9 (Lifting Lemma). Let (cid:3) be a non-contradictory context. Let C = L1 ∨ · · · ∨ Ln be a (cid:4)-clause and Cγ a
ground (cid:4)-instance. If (cid:3) produces L1γ , . . . , Lnγ , then there are fresh variants K1, . . . , Kn ∈(cid:11) (cid:3)(cid:4) and a substitution
σ such that

(1) σ is a most general simultaneous uniﬁer of {K1, L1}, . . . , {Kn, Ln},
(2) for all i = 1, . . . , n, Li (cid:2) Liσ (cid:2) Liγ ,
(3) for all i = 1, . . . , n, Ki produces Liσ in (cid:3).

Proof. Let i ∈ {1, . . . , n} and assume that (cid:3) produces Liγ . Then, there are literals K (cid:13)
i produces Liγ
i
in (cid:3). Let Ki (cid:11) K (cid:13)
i . It is easy to see that Ki ∈(cid:11) (cid:3) produces Liγ in (cid:3). Because all the Ki ’s are
fresh, they are pairwise disjoint, and each Ki is disjoint from C. Furthermore, each Ki must be a (cid:4)-literal (and not
a (cid:4)sko-literal), because if Ki contains some Skolem constant, Ki (cid:2) Liγ would not hold (recall that Liγ is a ground
(cid:4)-literal) and thus Ki would not produce Liγ in (cid:3).

i be fresh variants of K (cid:13)

∈ (cid:3) such that K (cid:13)

By deﬁnition of productivity, Ki (cid:2) Liγ , that is, there is a substitution πi such that Kiπi = Liγ . Since Ki is variable
disjoint from C, we can assume that πi moves only the variables and the parameters of Ki . Now, since Ki is disjoint
from Kj for j ∈ {1, . . . , n} distinct from i, and πi is a ground substitution for Ki , we have that Kiπi = Kiπ where
π := π1 · · · πi · · · πn. Since Liγ is ground, it follows immediately that Liγ = Liγ π .

We may assume that all variables moved by γ occur in C only (otherwise restrict γ respectively). Together with

the assumptions made it follows that Ki = Kiγ , which implies trivially that Kiπ = Kiγ π .

P. Baumgartner, C. Tinelli / Artiﬁcial Intelligence 172 (2008) 591–632

627

Putting together all results obtained so far together, we get that Kiγ π = Liγ π for all i = 1, . . . , n. In other words,
γ π is a simultaneous uniﬁer of {K1, L1} . . . , {Kn, Ln}. It follows that {K1, L1} . . . , {Kn, Ln} admits a simultaneous
mgu σ , which proves item 1 in the statement of the lemma.

Now, to prove item 2 observe that since Liγ is ground, Liγ π = Liγ . Since σ is a more general substitution than
γ π we know that γ π = σ δ for some substitution δ. It follows that Liσ δ = Liγ π = Liγ . In other words, Liσ (cid:2) Liγ .
But then L (cid:2) Liσ (cid:2) Liγ as desired.

To prove item 3 ﬁrst observe that Ki (cid:2) Liσ because Kiσ = Liσ . By item 2 we then have that Ki (cid:2) Liσ (cid:2) Liγ .

Recalling that the literal Ki produces Liγ in (cid:3), it follows by Lemma A.8 that Ki produces Liσ in (cid:3) as well. (cid:2)

Lemma 4.10 (Existence of admissible context uniﬁers). Let (cid:3) be a context, C a clause and σ a context uniﬁer of C
against (cid:3). Then, there is a renaming ρ such that σ (cid:13) := σρ is an admissible context uniﬁer of C against (cid:3) with the
same context literals as σ .

Proof. Let C = L1 ∨ · · · ∨ Ln for some n (cid:3) 0. By Deﬁnition 3.9 of context uniﬁer, for all i = 1, . . . , n there is a
Ki ∈(cid:11) (cid:3) such that Kiσ = Liσ . Moreover, there is an m ∈ {1, . . . , n} such that (Par(Ki))σ ⊆ V for all i = 1, . . . , m
and (Par(Ki))σ (cid:4) V for all i = m + 1, . . . , n.

We are going to construct a renaming substitution ρ as stated. Let x1, . . . , xk be the variables such that
{x1, . . . , xk} = Var(Lm+1σ ∨· · ·∨Lnσ ), i.e. all variables occurring in the remainder. Deﬁne ρ := {x1 (cid:5)→ u1, . . . , xk (cid:5)→
uk, u1 (cid:5)→ x1, . . . , uk (cid:5)→ xk}, where u1, . . . , uk are pairwise different and fresh parameters.31

Clearly, ρ is a renaming. It remains to show that σρ is admissible for Split. Recall that (Par(Ki))σ ⊆ V holds,
for i = 1, . . . , m. By construction, all the parameters moved by ρ are fresh parameters, none of which therefore can
occur in Ki . In other words, (Par(Ki))ρ = Par(Ki) holds, which entails (Par(Ki))σρ = (Par(Ki))σ . (However,
(Par(Ki))σρ (cid:4) V , for i = m + 1, . . . , n, will in general not hold.) Therefore, there is a m(cid:13) with m (cid:5) m(cid:13) (cid:5) n such that
(Par(Ki))σρ ⊆ V , for i = 1, . . . , m(cid:13) and (Par(Ki))σρ (cid:4) V , for i = m(cid:13) + 1, . . . , n.

None of the remainder literals Kiσρ, for i = m + 1, . . . , n, contains a single variable. Hence the disjointness
requirement in the deﬁnition of admissible context uniﬁer is trivially satisﬁed. This concludes the proof of existence
of a renaming ρ as claimed. (cid:2)

The following lemma applies (in particular) to remainders of admissible context uniﬁers. The lemma implies that
if a clause has an admissible context uniﬁer, against a given context, with a remainder all of whose literals are indi-
vidually contradictory with the context, then the clause has a context uniﬁer with an empty remainder.

Lemma A.21. Let (cid:3) be a context, L1 ∨ · · · ∨ Ln be a clause, where n (cid:3) 0, possibly containing mixed literals, and
such that for all distinct i, j = 1, . . . , n, Var(Li) ∩ Var(Lj ) = ∅. If for all i = 1, . . . , n, Li is contradictory with (cid:3)
then there are fresh literals K1, . . . , Kn ∈(cid:11) (cid:3) and a substitution δ such that the following holds:

(1) δ is a simultaneous uniﬁer of {K1, L1}, . . . , {Kn, Ln},
(2) for all i = 1, . . . , n, Dom(δ) ∩ Par(Li) = ∅ (i.e. δ does not move any single parameter in the given clause),
(3) for all i = 1, . . . , n, (Par(Ki))δ ⊆ V .

Proof. Let (cid:3) and L1 ∨ · · · ∨ Ln be as stated, and such that the condition in the lemma result is satisﬁed. The conclu-
sions, items 1–3, are proven by induction on n. Base) If n = 0 then the result follows trivially by choosing for δ the
empty substitution.

Step) Suppose n > 0 and consider the clause L1 ∨ · · · ∨ Ln−1. Clearly, for all distinct i, j = 1, . . . , n − 1,
Var(Li) ∩ Var(Lj ) = ∅ holds. Therefore, by the induction hypothesis there are fresh literals K1, . . . , Kn−1 ∈(cid:11) (cid:3)
and a substitution δ(cid:13) such that

31 That is, every variable in the remainder is renamed by ρ to a parameter. From a practical point of view this is absurd, and it is better to compute
a renaming that keeps as many variables in the remainder as possible. For the purpose of the completeness proof, however, the renaming ρ as
constructed will do.

628

P. Baumgartner, C. Tinelli / Artiﬁcial Intelligence 172 (2008) 591–632

1. δ(cid:13) is a simultaneous uniﬁer of {K1, L1}, . . . , {Kn−1, Ln−1},
2. for all i = 1, . . . , n − 1, Dom(δ(cid:13)) ∩ Par(Li) = ∅,
3. for all i = 1, . . . , n − 1, (Par(Ki))δ(cid:13) ⊆ V .

Now let σ (cid:13)(cid:13) := σ (cid:13)

Since Ln is contradictory with (cid:3), there is a literal K ∈(cid:11) (cid:3) and a p-preserving substitution σ such that Lnσ = Kσ .
Let Kn be a fresh p-variant of K. Let ρ be a renaming substitution such that Knρ = K. Let ρ(cid:13) = ρ|Var(Kn)∪Par(Kn)
It follows easily Knρ(cid:13) = K. Since Kn is fresh, ρ(cid:13) will not move variables or parameters in Ln, i.e. Ln = Lnρ(cid:13) holds.
From Lnσ = Kσ it follows Lnρ(cid:13)σ = Kσ = Knρ(cid:13)σ . Since σ is p-preserving, σ|V is a renaming on the parameters,
and (σ|V )−1 exists. This implies trivially Par(Ln)σ (σ|V )−1 = Par(Ln), i.e. σ (σ|V )−1 does not move any parameter
in Ln. With Ln = Lnρ(cid:13) it follows that the substitution σ (cid:13) := ρ(cid:13)σ (σ|V )−1 does not move any parameter in Ln. From
Lnρ(cid:13)σ = Knρ(cid:13)σ it follows trivially Lnρ(cid:13)(σ σ|V )−1 = Kρ(cid:13)(σ σ|V )−1, i.e. Lnσ (cid:13) = Knσ (cid:13).

|Var(Ln)∪Var(Kn)∪Par(Kn). From Lnσ (cid:13) = Knσ (cid:13) it follows Lnσ (cid:13)(cid:13) = Knσ (cid:13)(cid:13) (recall that σ (cid:13) does not

move any parameter in Ln and hence Par(Ln) need not be included in the domain restriction of σ (cid:13) deﬁning σ (cid:13)(cid:13)).

Let δ := σ (cid:13)(cid:13)δ(cid:13) be the substitution to prove the induction step. We have to show items 1 to 3 to hold. Since all the
variables moved by σ (cid:13)(cid:13) occur in Ln or Kn, Kn is fresh and Ln is variable disjoint with Li , for i = 1, . . . , n − 1, σ (cid:13)(cid:13)
will not move any variable in any Li or in any Ki . Since Kn is fresh, and all parameters moved by σ (cid:13)(cid:13) occur in Kn,
σ (cid:13)(cid:13) will not move any parameter in any Li or in any Ki (nor in Ln, as concluded above). This implies that Liσ (cid:13)(cid:13) = Li
and Kiσ (cid:13)(cid:13) = Ki , for i = 1, . . . , n − 1. With Kiδ(cid:13) = Liδ(cid:13) from the induction hypothesis conclude Kiσ (cid:13)(cid:13)δ(cid:13) = Liσ (cid:13)(cid:13)δ(cid:13),
i.e. Above we concluded Lnσ (cid:13)(cid:13) = Knσ (cid:13)(cid:13), which implies trivially Lnσ (cid:13)(cid:13)δ(cid:13) = Knσ (cid:13)(cid:13)δ(cid:13). Together and using the identity
δ = σ (cid:13)(cid:13)δ(cid:13) this gives the proof for item 1 for the induction step.

That item 2 to be proven carries over from the induction hypothesis to the induction step follows immediately from

the deﬁnition of σ (cid:13)(cid:13) (recall that the parameters moved by σ (cid:13)(cid:13) is a subset of Par(Kn)).

It is not difﬁcult to see that all parameters moved by σ (cid:13)(cid:13) are moved to parameters: since σ (cid:13)(cid:13) is obtained from σ (cid:13) be
restricting the domain of σ (cid:13), it sufﬁces to consider σ (cid:13). Recall that σ (cid:13) = ρ(cid:13)σ (σ|V )−1, where all the parameters moved
by ρ(cid:13) are moved to parameters. The substitution σ (cid:13) is p-preserving. Together this implies that all the parameters moved
by σ (cid:13) are moved to parameters. But then, item 3 to be proven immediately carries over from the induction hypothesis
to the induction step. (cid:2)

Lemma 4.11 (Split applicability). Let (cid:3) (cid:14) (cid:11), C be a sequent with a non-contradictory context (cid:3), where C contains
at least two literals. If all context uniﬁers of C against (cid:3) have a non-empty remainder, and σ is an admissible context
uniﬁer of C against (cid:3) such that (cid:3) produces L, for every remainder literal L of σ , then Split is applicable to (cid:3) (cid:14) (cid:11), C
with selected clause C and context uniﬁer σ .

sko

Proof. Suppose the condition of the lemma statement holds. The proof of the conclusion consists of two parts: in
a ﬁrst part, we will show that there is a remainder literal that is not contradictory with (cid:3). Then, in a second part
we will show that for each remainder literal L, L
is not contradictory with (cid:3). This will immediately give a proof
that Split is applicable to (cid:3) (cid:14) (cid:11), C with selected clause C, context uniﬁer σ and that mentioned remainder literal.
Let C = L1 ∨ · · · ∨ Lm ∨ Lm+1 ∨ · · · ∨ Lm, where 0 (cid:5) m (cid:5) n (and n (cid:3) 2), where the remainder D is (Lm+1 ∨
· · · ∨ Lm)σ . Suppose, to the contrary of the statement for the ﬁrst part that every literal Lj σ , for j = m + 1, . . . , n
is contradictory with (cid:3). Since σ is admissible, all prerequisites to apply Lemma A.21 to D are satisﬁed. By this
lemma then, there are fresh literals Km+1, . . . , Kn ∈(cid:11) (cid:3) and there is a simultaneous uniﬁer δ of {Km+1, Lm+1σ }, . . . ,
{Kn, Lnσ } (Lemma A.21, item 1) such that for all j = m + 1, . . . , n, it holds Dom(δ) ∩ Par(Lj ) = ∅ (item 2), and
(Par(Kj ))δ ⊆ V (item 3). We may assume that δ is restricted so that each parameter moved by it occurs only in some
literal Kj , where m + 1 (cid:5) j (cid:5) n. Otherwise restrict δ respectively by excluding from its domain all the parameters
that do not occur in any Kj , and items 1–3 will still hold. In particular, δ will still be a simultaneous uniﬁer as stated
in item 1, because the unrestricted δ does not move the parameters in Lj anyway.

In the sequel let the index j always ranges from m + 1, . . . , n.
Since each literal Kj is fresh, we may assume that σ does not modify Kj , i.e. Kj = Kj σ holds. Therefore,
δ is a simultaneous uniﬁer of {Km+1σ, Lm+1σ }, . . . , {Knσ, Lnσ }. Equivalently, σ δ is a simultaneous uniﬁer of
{Km+1, Lm+1}, . . . , {Kn, Ln}.

Furthermore, from (Par(Kj ))δ ⊆ V and Kj = Kj σ it follows (Par(Kj ))σ δ ⊆ V .

P. Baumgartner, C. Tinelli / Artiﬁcial Intelligence 172 (2008) 591–632

629

We are given that σ is an (admissible) context uniﬁer. This means in particular that σ is a simultaneous uniﬁer of

{K1, L1}, . . . , {Km, Lm}. Trivially, σ δ is a simultaneous uniﬁer of these literals as well.

Above we assumed that δ is restricted so that each parameter moved by it occurs in some literal Kj , where m + 1 (cid:5)
j (cid:5) n. Since each literal Kj is fresh, δ will not move any parameter in any literal Kiσ , for all i = 1, . . . , m. Since σ
is a context uniﬁer, we know (Par(Ki))σ ⊆ V , for all i = 1, . . . , m. Together this implies (Par(Ki))σ δ ⊆ V .

Summing up, there is a simultaneous uniﬁer σ δ (of {K1, L1}, . . . , {Kn, Ln} – we will omit in the sequel the men-

tioning of these pairs if just these are meant) such that (Par(Ki))σ δ ⊆ V , for all i = 1, . . . , n.

However, there is no guarantee yet that σ δ will be a simultaneous most general uniﬁer. We will show next that a
simultaneous most general uniﬁer exists, that, moreover will be a context uniﬁer of C against (cid:3) with empty remainder,
contradicting the lemma statement.

Since σ δ is a simultaneous uniﬁer, there is a most general simultaneous uniﬁer σ (cid:13) and a substitution δ(cid:13) such
that σ (cid:13)δ(cid:13) = σ δ. The same arguments as in the proof of the Lifting lemma, Lemma 4.9, can be applied to show this.
However, there is no guarantee that (Par(Ki))σ (cid:13) ⊆ V , for all i = 1, . . . , n. But it must hold (Par(Ki))σ (cid:13) ⊆ X ∪ V ,
for all i = 1, . . . , n, because otherwise there would be a parameter u in some literal Ki , where 1 (cid:5) i (cid:5) n and that
would be moved to a term uσ (cid:13) /∈ X ∪ V , which implies uσ (cid:13)δ(cid:13) /∈ V . However, we know uσ (cid:13)δ(cid:13) = uσ δ ∈ V .
Let x1, . . . , xk be all the variables in (Par(K1))σ (cid:13) ∪ · · · ∪ (Par(Kn))σ (cid:13) and deﬁne the renaming

ρ = {x1 (cid:5)→ u1, . . . , xk (cid:5)→ uk, u1 (cid:5)→ x1, . . . , uk (cid:5)→ xk},

where u1, . . . , uk are fresh parameters. By this construction, each variable in (Par(Ki))σ (cid:13) is moved to a parameter,
and because u1, . . . , uk are fresh, each parameter in (Par(Ki))σ (cid:13) is moved to itself, for all i = 1, . . . , n. This proves
(Par(Ki))σ (cid:13)ρ ⊆ V , for all i = 1, . . . , n. Furthermore, with σ (cid:13) being a most general simultaneous uniﬁer and ρ being
a renaming, σ (cid:13)ρ is a most general simultaneous uniﬁer, too. In other words, σ (cid:13)ρ is a context uniﬁer of C against (cid:3)
with empty remainder. Since this plainly contradicts what is given in the lemma statement, the assumption that every
literal Lj σ , for j = m + 1, . . . , n, is contradictory with (cid:3) must be withdrawn. Hence, as claimed, there is a remainder
literal Lσ that is not contradictory with (cid:3). This completes the ﬁrst part of the proof.
For the second part, let L ∈ D be any remainder literal. We have to show that L

is not contradictory with (cid:3).
is contradictory with (cid:3). Then, there is a K ∈(cid:11) (cid:3) and a p-preserving substitution σ

sko

sko

Suppose to the contrary that L
such that L

σ = Kσ .

sko

Since σ is p-preserving, σ|V exists and is a renaming on V . Therefore, also ρ := (σ|V )−1 exists, and so u = uσρ
sko
σρ, and with

is variable-free. This implies L

for any parameter u follows. Because of Skolemization, L
L

sko
σ = Kσ , it follows easily L
Let μ = {x1 (cid:5)→ a1, . . . , xn (cid:5)→ an} be the Skolemizing substitution used, for some n (cid:3) 0. Now, because the constants
a1, . . . , an are fresh, none of them will occur in L. This means, we can consider the “substitution” μ(cid:13) = {a1 (cid:5)→
x1, . . . , an (cid:5)→ xn} and it will hold L = Lskoμ(cid:13).

sko = Kσρ.

sko = L

sko

The substitution σρ is p-preserving, because both σ and ρ are. We may assume that all the variables moved by σρ
sko = Kσρ
are just the variables of K, and each variable in K is moved by σρ to some Skolem constant ai , so that L
holds. It follows that the substitution σρμ(cid:13) is a renaming on V and each variable in K is moved to some variable xi
sko = Kσρ it follows trivially
(not necessarily in an injective way). More formally, K (cid:3) Kσρμ(cid:13) holds. Now, from L
μ(cid:13) = Kσρμ(cid:13), and with L = Lskoμ(cid:13) we get L = Kσρμ(cid:13). With K (cid:3) Kσρμ(cid:13) it follows K (cid:3) L. With K ∈(cid:11) (cid:3) and
L
Lemma A.6, K produces L in (cid:3) and (cid:3) does not produce L. This contradicts the lemma statement according to which
is contradictory with (cid:3) is false, and so no remainder literal is
(cid:3) does produce L. Therefore, the assumption that L
contradictory with (cid:3). Since this is all that remained to be proven, the proof is complete now. (cid:2)

sko

sko

Lemma 4.12 (Assert applicability). Let (cid:3) (cid:14) (cid:11), L be a sequent with a non-contradictory context (cid:3). If all context
uniﬁers of L against (cid:3) have a non-empty remainder and there is an instance Lσ of L such that (cid:3) produces Lσ , then
Assert is applicable to (cid:3) (cid:14) (cid:11), L with selected clause L, selected literal the empty substitution as context uniﬁer.

Proof. Suppose that all context uniﬁers of L against (cid:3) have a non-empty remainder and there is an instance Lσ of
L such that (cid:3) produces Lσ . To show that Assert is applicable as stated, we ﬁrst have to show that there is no literal
K ∈ (cid:3) such that K (cid:3) L. Suppose there were such a literal K. Recall that the clauses in the sequents are parameter-

630

P. Baumgartner, C. Tinelli / Artiﬁcial Intelligence 172 (2008) 591–632

free. With L being therefore parameter-free, it follows easily that L (cid:3) Lσ . Together with K (cid:3) L conclude K (cid:3) Lσ .
But then, Lemma A.6 can be applied to conclude that (cid:3) produces Lσ but (cid:3) does not produce Lσ plainly contradicting
to what was supposed. Therefore, there is no literal K ∈ (cid:3) such that K (cid:3) L.

Next, we have to show that L is not contradictory with (cid:3). Suppose, to the contrary, there is a literal K ∈(cid:11) (cid:3) and
a p-preserving substitution δ such that Lδ = Kδ. Since δ is a uniﬁer for L and K, there is a most general uniﬁer σ (cid:13)
and a substitution δ(cid:13) such that σ (cid:13)δ(cid:13) = δ. The same arguments as in the proof of the Lifting lemma, Lemma 4.9, can be
applied to show this. However, there is no guarantee that (Par(K))σ (cid:13) ⊆ V . But it must hold (Par(K))σ (cid:13) ⊆ X ∪ V ,
because otherwise there would be a parameter u in K that would be moved to a term uσ (cid:13) /∈ X ∪ V , which implies
uσ (cid:13)δ(cid:13) /∈ V . However, we know uσ (cid:13)δ(cid:13) = uδ ∈ V since δ is p-preserving.

Let x1, . . . , xk be all the variables in (Par(K))σ (cid:13) and deﬁne the renaming

ρ = {x1 (cid:5)→ u1, . . . , xk (cid:5)→ uk, u1 (cid:5)→ x1, . . . , uk (cid:5)→ xk},

where u1, . . . , uk are fresh parameters. By this construction, each variable in (Par(K))σ (cid:13) is moved to a parameter,
and because u1, . . . , uk are fresh, each parameter in (Par(K))σ (cid:13) is moved to itself. This proves (Par(K))σ (cid:13)ρ ⊆ V .
Furthermore, with σ (cid:13) being a most general uniﬁer and ρ being a renaming, σ (cid:13)ρ is a most general uniﬁer, too. In other
words, σ (cid:13)ρ is a context uniﬁer of L against (cid:3) with an empty remainder. This, however, plainly contradicts what was
supposed above.

Finally, in reference to the deﬁnition of the Assert inference rule, the clause L to be selected can also be written as
(cid:2) ∨ L. Because, trivially, the empty substitution is a context uniﬁer of (cid:2) against any context with an empty remainder,
this concludes the proof that Assert is applicable as stated. (cid:2)

Lemma 4.15 (Close applicability). Let C ∈ (cid:2)B and i < κ such that Close is applicable to (cid:3)i (cid:14) (cid:2)i with selected
clause C. Then, for some j (cid:3) i with j (cid:5) κ, Close is applicable to (cid:3)j (cid:14) (cid:2)j with selected clause C and a context
uniﬁer σ such that K ∈(cid:11) (cid:3)B for each context literal K of σ .

Proof. Assume that Close is applicable to (cid:3)i (cid:14) (cid:2)i with selected clause C. We will directly prove the conclusion.

Suppose that C is of the form L1 ∨ · · · ∨ Ln. Let σ (cid:13) be the context uniﬁer of the considered Close rule application
∈(cid:11) (cid:3)i be the context literals of σ (cid:13). With Lemma A.15 it follows there are literals K1, . . . , Kn ∈(cid:11)
k, for k = 1, . . . , n. With C ∈ (cid:2)B and K1, . . . , Kn ∈ (cid:3)B it follows easily from the compactness

and let K (cid:13)
(cid:3)B such that Kk (cid:3) K (cid:13)
property that there is an j (cid:3) i with j < κ such that C ∈ (cid:2)j and Kk ∈(cid:11) (cid:3)j , for k = 1, . . . , n.

1, . . . , K (cid:13)

n

With this, it is enough to show that there is a context uniﬁer σ of C against (cid:3)j with an empty remainder and
context literals K1, . . . , Kn. Without loss of generality assume that K1, . . . , Kn have been chosen as fresh p-variants
of literals in (cid:3)j . In the sequel let the index k always ranges from 1, . . . , n.
From the existence of the context uniﬁer σ (cid:13) and the fact Kk (cid:3) K (cid:13)

k it follows there is a most general simultaneous
uniﬁer σ (cid:13)(cid:13) of {K1, L1}, . . . , {Kn, Ln}. The same arguments as in the proof of the Lifting lemma, Lemma 4.9, can be
applied to show this. However, there is no guarantee that (Par(Kk))σ (cid:13)(cid:13) ⊆ V . Using the same construction as in the
proof of Lemma 4.11, it can be shown that there is a renaming substitution ρ such that (Par(Kk))σ (cid:13)(cid:13)ρ ⊆ V . Setting
σ := σ (cid:13)(cid:13)ρ thus gives the desired substitution. (cid:2)

References

[1] L. Bachmair, H. Ganzinger, Equational reasoning in saturation-based theorem proving, in: W. Bibel, P.H. Schmitt (Eds.), Automated Deduc-
tion. A Basis for Applications, vol. I: Foundations. Calculi and Reﬁnements, Kluwer Academic Publishers, 1998, pp. 353–398 (Chapter 11).
[2] L. Bachmair, H. Ganzinger, Resolution theorem proving, in: A. Robinson, A. Voronkov (Eds.), Handbook of Automated Reasoning, North

Holland, 2001.

[3] P. Baumgartner, Hyper tableaux—The next generation, in: H. de Swaart (Ed.), Automated Reasoning with Analytic Tableaux and Related

Methods, in: Lecture Notes in Artiﬁcial Intelligence, vol. 1397, Springer Verlag, Berlin, Heidelberg, New York, 1998, pp. 60–76.

[4] P. Baumgartner, FDPLL—A first-order Davis–Putnam–Logeman–Loveland procedure, in: D. McAllester (Ed.), CADE-17—The 17th Inter-
national Conference on Automated Deduction, in: Lecture Notes in Artiﬁcial Intelligence, vol. 1831, Springer Verlag, Berlin, Heidelberg,
New York, 2000, pp. 200–219.

[5] P. Baumgartner, A. Fuchs, C. Tinelli, Implementing the model evolution calculus, International Journal of Artiﬁcial Intelligence Tools 15 (1)

(2006) 21–52.

[6] P. Baumgartner, A. Fuchs, C. Tinelli, Lemma learning in the model evolution calculus, in: M. Hermann, A. Voronkov (Eds.), Proceedings of
the 13th International Conference on Logic for Programming, Artiﬁcial Intelligence and Reasoning (LPAR’06), Phnom Penh, Cambodia, in:
Lecture Notes in Computer Science, vol. 4246, Springer, 2006, pp. 572–586.

P. Baumgartner, C. Tinelli / Artiﬁcial Intelligence 172 (2008) 591–632

631

[7] P. Baumgartner, U. Furbach, I. Niemelä, Hyper tableaux, in: Proc. JELIA 96. European Workshop on Logic in AI, in: Lecture Notes in

Artiﬁcial Intelligence, vol. 1126, Springer, 1996.

[8] P. Baumgartner, C. Tinelli, The model evolution calculus with equality, in: [38], 2005, pp. 392–408.
[9] B. Beckert, Depth-ﬁrst proof search without backtracking for free-variable clausal tableaux, Journal of Symbolic Computation 36 (2003)

117–138.

[10] W. Bibel, Automated Theorem Proving, Vieweg, 1982.
[11] J.-P. Billon, The Disconnection Method, in: P. Miglioli, U. Moscato, D. Mundici, M. Ornaghi (Eds.), Theorem Proving with Analytic Tableaux
and Related Methods, in: Lecture Notes in Artiﬁcial Intelligence, vol. 1071, Springer Verlag, Berlin, Heidelberg, New York, 1996, pp. 110–
126.

[12] C. Chang, R. Lee, Symbolic Logic and Mechanical Theorem Proving, Academic Press, 1973.
[13] M. Davis, G. Logemann, D. Loveland, A machine program for theorem proving, Communications of the ACM 5 (7) (Jul. 1962) 394–397.
[14] M. Davis, H. Putnam, A computing procedure for quantiﬁcation theory, Journal of the ACM 7 (3) (Jul. 1960) 201–215.
[15] E. Eder, Properties of substitutions and uniﬁcations, Journal of Symbolic Computation 1 (1) (March 1985).
[16] C. Fermüller, A. Leitsch, Model building by resolution, in: E. Börger, G. Jäger, H. Kleine-Büning, S. Martini, M. Richter (Eds.), Computer
Science Logic—CSL’92, in: Lecture Notes in Computer Science, vol. 702, Springer Verlag, Berlin, Heidelberg, New York, 1993, pp. 134–148.

[17] C. Fermüller, A. Leitsch, Hyperresolution and automated model building, Journal of Logic and Computation 6 (2) (1996) 173–230.
[18] C. Fermüller, A. Leitsch, U. Hustadt, T. Tammet, Resolution Decision Procedures, Elsevier and MIT Press, 2001, pp. 1791–1850.
[19] C. Fermüller, R. Pichler, Model representation via contexts and implicit generalizations, in: [38], 2005, pp. 409–423.
[20] M. Fitting, First Order Logic and Automated Theorem Proving, Texts and Monographs in Computer Science, Springer, 1990.
[21] A. Fuchs, Darwin: A theorem prover for the model evolution calculus, Master’s thesis, University of Koblenz-Landau, 2004.
[22] H. Ganzinger, K. Korovin, New directions in instance-based theorem proving, in: LICS—Logics in Computer Science, 2003.
[23] H. Ganzinger, C. Meyer, C. Weidenbach, Soft typing for ordered resolution, in: W. McCune (Ed.), Automated Deduction—CADE 14, in:

Lecture Notes in Artiﬁcial Intelligence, vol. 1249, Springer-Verlag, Townsville, North Queensland, Australia, 1997, pp. 321–335.

[24] M. Giese, Incremental closure of free variable tableaux, in: Proc. International Joint Conference on Automated Reasoning, in: Lecture Notes

in Artiﬁcial Intelligence, vol. 2083, Springer Verlag, Berlin, Heidelberg, New York, 2001.

[25] M. Giese, A model generation style completeness proof for constraint tableaux with superposition, in: U. Egly, C.G. Fermüller (Eds.), Proc.
Intl. Conf. on Automated Reasoning with Analytic Tableaux and Related Methods, Copenhagen, Denmark, in: Lecture Notes in Computer
Science, vol. 2381, Springer Verlag, 2002.

[26] M.L. Ginsberg, Dynamic backtracking, Journal of Artiﬁcial Intelligence Research 1 (1993) 25–46.
[27] M.L. Ginsberg, A.J. Parkes, Satisﬁability algorithms and ﬁnite quantiﬁcation, in: A.G. Cohn, F. Giunchiglia, B. Selman (Eds.), Principles
of Knowledge Representation and Reasoning: Proceedings of the Seventh International Conference (KR’2000), Morgan Kauffman, 2000,
pp. 690–701.

[28] E. Goldberg, Y. Novikov, Berkmin: A fast and robust sat solver, 2002.
[29] J. Hooker, G. Rago, V. Chandru, A. Shrivastava, Partial instantiation methods for inference in ﬁrst order logic, Journal of Automated Reason-

ing 28 (4) (2002) 371–396.

[30] D. Jackson, Automating ﬁrst-order relational logic, in: Proceedings of the ACM SIGSOFT Conference on Foundations of Software Engineer-

ing, 2000, pp. 130–139.

[31] R. Joshi, G. Nelson, K. Randall, Denali: A goal-directed superoptimizer, Tech. rep., Compaq SRC, July 2001.
[32] S.-J. Lee, D. Plaisted, Eliminating Duplicates with the Hyper-Linking Strategy, Journal of Automated Reasoning 9 (1992) 25–42.
[33] R. Letz, K. Mayr, C. Goller, Controlled integrations of the cut rule into connection tableau calculi, Journal of Automated Reasoning 13 (1994).
[34] R. Letz, G. Stenz, Proof and model generation with disconnection tableaux, in: R. Nieuwenhuis, A. Voronkov (Eds.), Logic for Programming,
Artiﬁcial Intelligence, and Reasoning, 8th International Conference, LPAR 2001, Havana, Cuba, in: Lecture Notes in Computer Science,
vol. 2250, Springer Verlag, Berlin, Heidelberg, New York, 2001.

[35] R. Letz, G. Stenz, Integration of equality reasoning into the disconnection calculus, in: U. Egly, C.G. Fermüller (Eds.), TABLEAUX, in:

Lecture Notes in Computer Science, vol. 2381, Springer Verlag, Berlin, Heidelberg, New York, 2002, pp. 176–190.

[36] R. Manthey, F. Bry, SATCHMO: A theorem prover implemented in Prolog, in: E. Lusk, R. Overbeek (Eds.), Proceedings of the 9th Conference
on Automated Deduction, Argonne, Illinois, May 1988, in: Lecture Notes in Computer Science, vol. 310, Springer Verlag, Berlin, Heidelberg,
New York, 1988, pp. 415–434.

[37] M.W. Moskewicz, C.F. Madigan, Y. Zhao, L. Zhang, S. Malik, Chaff: Engineering an efﬁcient SAT solver, in: Proceedings of the 38th Design

Automation Conference (DAC’01), Jun. 2001.

[38] R. Nieuwenhuis (Ed.), Automated Deduction—CADE-20, Lecture Notes in Artiﬁcial Intelligence, vol. 3632, Springer, 2005.
[39] A.J. Parkes, Lifted search engines for satisﬁability, Ph.D. thesis, University of Oregon, June 1999.
[40] N. Peltier, Pruning the search space and extracting more models in tableaux, Logic Journal of the IGPL 7 (2) (1999) 217–251.
[41] D.A. Plaisted, Y. Zhu, Ordered semantic hyper linking, in: Proceedings of Fourteenth National Conference on Artiﬁcial Intelligence (AAAI-

97), 1997.

[42] D.A. Plaisted, Y. Zhu, Ordered semantic hyper linking, Journal of Automated Reasoning 25 (3) (2000) 167–217.
[43] G. Stenz, DCTP 1.2—System abstract, in: U. Egly, C.G. Fermüller (Eds.), Automated Reasoning with Analytic Tableaux and Related Methods,
International Conference, TABLEAUX 2002, Copenhagen, Denmark, July 30–August 1, 2002, Proceedings, in: Lecture Notes in Computer
Science, vol. 2381, Springer Verlag, Berlin, Heidelberg, New York, 2002, pp. 335–340.

[44] G. Stenz, R. Letz, Generalized handling of variables in disconnection tableaux, in: Proc. International Joint Conference on Automated Rea-

soning, in: Lecture Notes in Artiﬁcial Intelligence, vol. 3097, Springer Verlag, Berlin, Heidelberg, New York, 2004, pp. 289–306.

[45] O. Strichman, S. Seshia, R. Bryant, Deciding separation formulas with sat, in: Proceedings of the Computer Aided Veriﬁcation Conference

(CAV’02), 2002.

632

P. Baumgartner, C. Tinelli / Artiﬁcial Intelligence 172 (2008) 591–632

[46] G. Sutcliffe, C. Suttner, The TPTP problem library: CNF release v1.2.1, Journal of Automated Reasoning 21 (2) (1998) 177–203.
[47] C. Tinelli, A DPLL-based calculus for ground satisﬁability modulo theories, in: G. Ianni, S. Flesca (Eds.), Proceedings of the 8th European
Conference on Logics in Artiﬁcial Intelligence, Cosenza, Italy, in: Lecture Notes in Artiﬁcial Intelligence, vol. 2424, Springer Verlag, Berlin,
Heidelberg, New York, 2002.

[48] J. van Eijck, Constrained hyper tableaux, in: L. Fribourg (Ed.), Computer Science Logic, 15th International Workshop, CSL 2001, in: Lecture

Notes in Computer Science, vol. 2142, Springer, 2001, pp. 232–246.

[49] A. Yahya, D. Plaisted, Ordered semantic hyper-tableaux, Journal of Automated Reasoning 29 (1) (2002) 17–57.
[50] H. Zhang, M.E. Stickel, An efﬁcient algorithm for unit propagation, in: Proceedings of the Fourth International Symposium on Artiﬁcial

Intelligence and Mathematics (AI-MATH’96), Fort Lauderdale, Florida, USA, 1996.

