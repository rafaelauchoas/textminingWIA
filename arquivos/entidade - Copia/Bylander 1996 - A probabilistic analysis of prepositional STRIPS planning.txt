Artificial Intelligence 81 (1996) 241-271 

Artificial 
Intelligence 

A  probabilistic  analysis  of  propositional  STRIPS 
planning  * 

Tom  Bylander  * 
Division of Computer Science,  The  University of  Texas at San Antonio,  San Antonio,  7X  78249, USA 

Received May 1994; revised April 1995 

Abstract 

I  present  a  probabilistic  analysis  of  propositional  STRIPS  planning.  The  analysis  considers  two 
assumptions.  One  is  that  each  possible  precondition  (likewise  postcondition)  of  an  operator  is 
selected  independently  of other  pre-  and  postconditions.  The  other is  that each  operator  has  a fixed 
number  of  preconditions  (likewise  postconditions).  Under  both  assumptions,  I  derive  bounds  for 
instance  can  be  efficiently  solved,  either  by  finding  a 
when  it  is  highly  likely  that  a  planning 
plan  or  proving  that  no  plan  exists.  Roughly,  if  planning  instances  under  either  assumption  have 
n  propositions  (ground  atoms)  and  g  goals,  and  the number  of operators  is  less  than  an  0(  n In g) 
bound,  then  a  simple,  efficient  algorithm  can  prove  that  no  plan  exists  for  most  instances.  If 
the  number  of  operators  is  greater  than  an  a(  n Ing)  bound,  then  a  simple,  efficient  algorithm 
can  find  a  plan  for  most  instances.  The  two  bounds  differ  by  a  factor  that  is  exponential  in  the 
number  of  pre-  and  postconditions.  A  similar  result  holds  for  plan  modification,  i.e.,  solving  a 
planning  instance  that  is  close  to  another  planning  instance  with  a  known  plan.  Thus  it  appears 
that  propositional  STRIPS  planning,  a  PSPACE-complete  problem,  exhibits  a  easy-hard-easy 
pattern  as  the  number  of  available  operators  increases  with  a  narrow  range  of  hard  problems.  An 
empirical  study  demonstrates  this  pattern  for  particular  parameter  values.  Because  propositional 
STRIPS  planning  is PSPACE-complete,  this extends  previous  phase transition  analyses,  which  have 
focused  on  NP-complete  problems.  Also,  the  analysis  shows  that  surprisingly  simple  algorithms 
can  solve  a  large  subset  of  the  planning  problem. 

keywords: Planning; STRIPS; Average-case analysis; PSPACE-comple@ 

* This paper is a revised and extended version of  [ 31. 
* E-mail: bylander@ringer.cs.utsa.edu. 

0004-3702/96/$15.00 @  1996 Elsevier Science B.V. All rights reserved 
SSDIOOO4-3702(95)00055-O 

242 

i?  Bylander/Artificial 

Intelligence  81  (1996)  241-271 

1.  Introduction 

Lately,  there  has been  a number  of  worst-case  complexity  results  for planning,  showing 
that  the  general  problem  is  hard  and  that  several  restrictions  are  needed  to  guarantee 
A  criticism  of  such  worst-case  analyses  is  that 
polynomial  time  [ 1,2,4,5,10,11,21]. 
they  do  not  apply  to  the  average  case  [7,17].  Recent  work  in  AI  has  shown  that  this 
criticism  has  some  merit.  Several  experimental  and  theoretical  results  have  shown  that 
specific  NP-complete  problems  are  hard  only  for  narrow  ranges  [6,9,18,19,26] 
and 
suggests  that  even  the  instances  within  these  ranges  can  usually  be  efficiently  solved 
[24,25]. 

This  paper  extends  these  results  by  providing  a probabilistic  analysis  of  propositional 
STRIPS  planning  [ 221.  In  contrast  to  the  above  work,  propositional  STRIPS  planning 
is  a  PSPACE-complete  problem  [4],  a  much  harder  complexity  class  [ 131.  PSPACE 
problems  are  those  that  can  be  solved  by  algorithms  with  space  requirements  that  are 
bounded  by  a  polynomial  on  the  size  of  the  input.  PSPACE-complete  problems  are  the 
hardest  problems  in this class.  Satisfiability  of  quantified  Boolean  expressions  belongs  to 
this  class.  Naturally,  because  PSPACE-complete  problems  are  harder  than  NP-complete 
problems,  ’  they  should  also  have regions  of hard problems.  See  [ 131 for  an introduction 
to  NP-  and  PSPACE-completeness. 

One  way  to  think  of  the  difference  between  PSPACE-complete  and  NP-complete 
problems  is that NP-complete  problems  are restricted  to  a polynomial  number  of  nonde- 
terministic  choice  points,  while  PSPACE-complete  problems  can  have  in  effect  an expo- 
nential  number  of  choice  points.  This  is  because  nondeterministic  algorithms  restricted 
to polynomial  space  (NPSPACE  algorithms)  can  be reduced  to PSPACE algorithms,  and 
these  nondeterministic  algorithms  can  require  exponential  time.  In propositional  STRIPS 
planning,  this means  that  the  shortest  solution  plan  might  have  exponential  length.  Thus, 
each  choice  in  a  PSPACE-complete  problem  is  potentially  a  much  smaller  component 
of  a solution  as compared  to  a NP-complete  problem.  Similarly,  each  modification  to  an 
instance  of  a  PSPACE-complete  problem  might  have  a  small  effect.  This  might  explain 
the  smooth  transitions  between  easy  and  hard  instances  in  our  empirical  study. 

In  common  with  previous  work  on  NP-complete  problems,  I  make  strong  indepen- 
dence  assumptions  about  the  distribution  of  instances.  I  assume  that  the  probability  that 
a  given  operator  is  in  a  planning  instance  is  independent  of  what  other  operators  are 
in  the  instance.  Two  variations  of  this  theme  are  explored.  One  is  that  each  possible 
precondition  (likewise  postcondition) 
is  selected  independently  of  the  other  pre-  and 
postconditions  in  the  operator.  The  other  is  that  each  operator  has  a  fixed  number  of 
preconditions  (likewise  postconditions).  Under  these  assumptions,  I  derive  bounds  for 
when  it is highly  likely  that specific  algorithms  will efficiently  solve  a planning  instance, 
either  by  finding  a plan  or  proving  that  no  plan  exists. 

Musick  and  Russell  [20]  also  analyze  a  problem  similar  to  planning.  They  approx- 
imate  a  restricted  kind  of  search  (each  operator  has  one  postcondition)  with  Markov 
chains,  which  in  turn  leads  to  polynomial-time  solutions  on  average  under  certain  con- 

’ Actually,  PZ  PSPACE  has not yet been proven, but I  shall make the standard assumptions that P#  NP  and 

NP #  PSPACE. 

I:  Bylander/Art@ial intelligence 81 (1996) 241-271 

243 

ditions.  In  contrast,  my  analysis  provides  rigorous  probabilistic  bounds  in  terms  of  five 
parameters:  the  number  of  propositions,  the  number  of  operators,  the  number  of  pre- 
and  postconditions  per  operator,  and  the  number  of  goals.  These  parameters  characterize 
a  full  range  of  planning  problems. 

The  algorithms  analyzed  by  this  paper  are  all  variations  of  simple  hill  climbing,  i.e., 
hill  climbing  with  no  backtracking.  Clearly,  this  type  of  search  is  far  removed  from 
the  sophisticated  partial  planning  algorithms  that  are  the  subject  of  much  current  study, 
e.g.,  TWEAK  [5],  SNLP  [ 161,  and  UCPOP  [23],  and  is  impoverished  compared  to 
almost  any  other  planning  algorithm  ever  proposed.  There  are  three  reasons  to  consider 
algorithms  of  such  simplicity:  they  permit  formal  analysis,  they  are  efficient,  and,  as 
noted  below,  they  cover  a  very  large  portion  of  the  planning  problem.  The  results  for 
these  algorithms  should  provide  a  baseline  for  analyzing  and  empirically  comparing 
more  sophisticated  algorithms  on  random  planning  instances. 

Specifically,  given  that  randomly-generated  planning  instances  have  n  propositions 
(ground  atoms)  and g goals,  and that operators  have  r  preconditions  and s postconditions 
on  average,  I  derive  the  following  results.  If  the  number  of  operators  is  at  most 

((2n  -  s)/s)(lng 

-  lnln  l/S), 

then  a  simple,  efficient  algorithm  can  prove  that  no  plan  exists  for  at  least  1 -  S of  the 
instances.  If  the  number  of  operators  is  at  least 

e’eSRIn(2n/s+ 

l)(lng/S), 

then  a  simple,  efficient  algorithm  can  find  a  plan  for  at  least  1 -  6  of  the  instances.  If 
T, s,  and  S  are  held  constant  as  n  and  g  increase,  then  the  bounds  are  0(  it lng)  and 
IZ( n In g) , respectively.  They  differ  by  a factor  that  is exponential  in  the  number  of  pre- 
and  postconditions. 

A  similar  result  holds  for  plan  modification.  If  the  initial  state  or  goals  are  different 
by  one  condition  from  that of  another  planning  instance  with  a known  plan,  and  if  there 
are  at least  er+$ (2n/s)  (In l/6)  operators,  then  it  is likely  ( 1 -  8)  that  a  single  operator 
converts  the  old  plan  into  a  solution  for  the  new  instance. 

Thus,  it appears  that propositional  STRIPS  planning  is easy  if  the  number  of  operators 
is  below  one  threshold  or  above  a  somewhat  higher  threshold.  Conjecturing  that  some 
range  of  problems  between  the  thresholds  are  hard,  then  propositional  STRIPS  planning 
exhibits  a  easy-hard-easy  pattern  similar  to  NP-complete  problems.  An  empirical  study 
demonstrates  this  pattern  for  particular  parameter  values.  However,  the  empirical  study 
shows  smooth  transitions  between  easy  and  hard  instances,  and  so  would  not  normally 
be  considered  a  phase  transition.  Despite  this,  the  theoretical  analysis  can  be  said  to 
demonstrate  an  “asymptotic”  phase  transition.  Larger  random  planning  instances  are 
hard  only  if  the  number  of  operators  is  O(n  lng).  Outside  this  asymptote,  larger  in- 
stances  become  easy.  In  any  case,  future  work  is  needed  to  narrow  the  gap between  the 
bounds  and  to  analyze  more  realistic  distributional  assumptions  and  more  sophisticated 
algorithms. 

The  rest  of  the  paper  is  organized  as  follows.  First,  definitions  and  key  inequalities 
are  presented.  Then,  the  results  of  the  analysis  are  derived.  Finally,  empirical  results  are 
displayed. 

244 

7:  Bylander/Artijicial  Intelligence  81  (1996)  241-271 

2.  Preliminaries 

This  section  defines  propositional  STRIFS  planning,  describes  the  distributions  of 

instances  to  be  analyzed,  and  presents  key  inequalities. 

2.1.  Propositional  STRIPS  planning 

An  instance  of  propositional  STRIPS  planning  is  specified  by  a  tuple  (P,  L3,2, G), 

where: 

l P  is  a  finite  set  of  ground  atomic  formula,  called  the  propositions;  a  proposition 
is  also  called  a  positive  condition;  its  negation  is  called  a  negative  condition;  a 
state  is  a  satisfiable  set  of  conditions  of  which  each  proposition  or  its  negation  is 
a  member; 

l  0  is a finite  set of  operators; the  preconditions  and postconditions  of  each  operator 

are  satisfiable  sets  of  conditions; 

l Z  is  the  initial  state;  and 
l  &?, the  goals,  is  a  satisfiable  set  of  conditions. 
If  the  preconditions  of  an  operator  are  satisfied  by  a  state,  then  the  operator  can  be 
applied  to  that  state,  and  the  resulting  state  is determined  by  adding  the  postconditions, 
deleting  those  conditions  that  conflict  with  the  postconditions  (cf.  [ 121).  A  solution 
plan  is  a  sequence  of  operators  that  transforms  the  initial  state  into  a  goal  state,  i.e.,  a 
state  that  satisfies  the  goals. 

For  example,  a  blocks-world 

instance  can  be  represented  using  propositions  like 
to  represent  “block  A  has  a  clear  top”,  and  on( A, B)  to  represent  “block  A  is 
clear(A) 
on  top  of  block  B”.  The  set  of  preconditions  of  an  operator  to  move  A  from  on  top  of 
B  to  on  top  of  C  can  be  represented  as: 

{clear(A), 

clear(C),  on(A,B)}. 

That  is,  blocks  A  and  C  are  clear,  and  block  A  is  on  top  of  block  B.  Its  postconditions 
are: 

{clear(B), 

4ear(C), 

lon(A,B), 

on(A,C)}. 

If  the  preconditions  are  true  before  the  operator  is  applied,  then  after  the  operator  is 
applied,  block  B  becomes  clear,  block  C  is  no  longer  clear,  block  A  is  no  longer  on 
block  B,  and  block  A  is  now  on  block  C. 

2.2.  Distributional  assumptions 

Let  n  be  the  number  of  propositions.  Let  o  be  the  number  of  operators.  Let  r  and  s 
respectively  be  the  expected  number  of  pre-  and  postconditions  within  an  operator.  Let 
g  be  the  number  of  goals. 

For  given  n, o, r,  s, and g, I assume that  random planning  instances under  the  variable 

model  ace distributed  by  generating  each  operator  as follows: 

l For  each  proposition  p  E  P,  p  is  a  precondition  of  the  operator  with  probability 
r/ (2n)  ; alternatively  -p  is a precondition  with probability  r/ (2n).  These  probabil- 

T.  Byhder/Art$icial 

Intelligence  81  (19%)  241-271 

245 

ities  are  independent  of  other  pre-  and  postconditions.  For  postconditions,  s/(2n) 
is  the  relevant  probability. 

l For  each  proposition  p  E  P,  p  E  Z  (the  initial  state)  is  as likely  as  -up E  Z. 
For  the  goals,  g propositions  are  selected  at random  and  are  set  to positive  or  negative 
so  that  no  goal  is  satisfied  in  the  initial  state.  This  latter  restriction  is made  for  ease  of 
exposition. 

The  only  difference  between  the  variable  model  and  the fixed  model  is  that: 
l Each  operator  has  exactly  r  preconditions  and  s  postconditions.  Any  legal  set  of  r 

preconditions  or  s postconditions  is equally  likely. 

It  must  be  admitted  that  these  assumptions  do  not  approximate  certain  aspects  of 
planning  domains  very  well.  For  example,  there  are  only  b  clear  conditions  for  a 
blocks-world  instance  of  b  blocks  compared  to  0(b2)  on  conditions.  However,  every 
blocks-world  operator  refers  to one  or more  clear  conditions,  i.e., a given  clear  condition 
appears  more  often  within  the  set  of  ground  operators  than  a  given  on  condition.  Also, 
there  are  correlations  between  the  conditions,  e.g.,  clear(A) 
is  more  likely  to  appear 
with  on( A,  B) 
than  with  on(C,  D).  Similar  violations  can  be  found  for  any  of  the 
standard  toy  domains. 

Ultimately,  the  usefulness  of  these  assumptions  will  depend  on  how  well  the  threshold 
bounds  of  the  analysis  classify  easiness  and  hardness  of  real  planning  domains.  Even 
so,  it  is  worth  noting  that  the  fixed  model  provides  a  uniform  distribution  over  the  set 
of  instances  defined  by  the  parameters.  Because  the  results  show  that  such  planning 
instances  are  usually  easy  except  for  a  narrow  range  of  the  number  of  operators  o,  it 
follows  that  the  vast  majority  of  planning  instances  are  indeed  easy. 

2.3.  Algorithm  characteristics 

Each  algorithm  in this paper  is incomplete  but sound,  i.e.,  each  algorithm  returns  cor- 
rect  answers  when  it returns  “yes”  or  “no”,  but might  answer  “don’t  know”.  Specifically, 
“success”  is  returned  if  the  algorithm  finds  a  solution  plan,  “failure”  is  returned  if  the 
algorithm  determines  that  no  plan  exists,  and  “don’t  know”  is returned  otherwise. 

The  performance  of  a  given  algorithm  is  characterized  by  an  accuracy  parameter  8, 
0  <  6  <  1. Each  result  below  shows  that  if  the  number  of  operators  o  is  greater  than 
(or  less  than)  a  formula  on  n,  r,  s,  g,  and  6,  then  the  accuracy  of  the  algorithm  on 
the  corresponding  distribution  (see  Section  2.2  on  distributional  assumptions)  will  be 
at  least  1 -  6. 

2.4.  Inequalities 

I  freely  use  the  following  inequalities.  For  nonnegative  x  and  y: 

e -x/C1-X)< 

l-n 

forO<x< 

1, 

1 -x<eeX, 

XY 
-<l-(l-x)y 
1 +xy 

forO<x<l. 

(1) 

(2) 

(3) 

246 

T. Bylander/Art@cial  Intelligence  81  (1996)  241-271 

Inequalities  ( 1)  and  (2)  are  easily  derivable  from  [ 81. Inequality  (3)  is derivable  from 
inequalities  ( 1)  and  (2).  The  logarithmic  forms  of  these  inequalities  are  sometimes  used. 
A  particular  form  of  Bonferroni’s  inequality  shall  be  used.  If  Ei,  E2,.  . . , E,,,  are  m 

events  and  the  probability  of  each  event  is  greater  than  or  equal  to  1 -  S/m,  then: 

P(E,  A E2 A . . . A E,,,)  2  1 -  8. 

(4) 

Finally,  the  following  recurrence  relation  is  useful  in  analyzing  the  fixed  model.  Its 
justification  is described  in the proof  for  Lemma  4.  Let  f(  s, n, k)  be  the  probability  that 
s  conditions  that  are  randomly  generated  from  n  propositions  are  consistent  with  some 
particular  set  of  k  conditions.  Then,  for  nonnegative  integers  n,  s  <  n  and  k  6  n: 

f(  s, n, k) 

n-k 

=Yf(s-l.n-l,k)+$f(s-l,n-l,k-1). 

The  base  cases  are  f(0,  n, k)  = 1, f(s,  n, 0)  =  1, f(  S, n, n)  = 2+  and  f(  II, n, k)  = 2-k. 
In  the  appendix,  the  following  inequalities  are  demonstrated: 

e -skln  6  f(s,n,k) 

<  &. 

3.  Efficiently  proving  plan  non-existence 

If  there  are  few  operators,  it becomes  unlikely  that  the  postconditions  of  the  operators 
cover  all  the  goals,  i.e.,  it is likely  that  some  goal  is not  a postcondition  of  any  operator. 
Recall  that  random  planning  instances  are  defined  so  that  no  goal  is  true  of  the  initial 
state.  So  if  some  goal  is  not  a  postcondition  of  any  operator,  then  the  instance  has  no 
solution  plan.  This  leads  to  the  following  simple  algorithm: 

POSTS-COVER-GOALS 
for  each  goal 

if  the  goal  is  not  in  the  postconditions  of  any  operator 

then  return  failure 

return  don’t  know 

While  POSTS-COVER-GOALS might  be  considered  a  trivial  algorithm,  the  following 
two  theorems  show  that  POSTS-COVER-GOALS works  for  a  substantial  range  of  the 
planning  problem. 

Theorem  1.  For  random planning  instances  under  the  variable  model,  if 

O<  q(lng 

-  lnlnl/S), 

then  POSTS-COVER-GOALS will  determine  that  no plan  exists for  at  least  1 -  S of  the 
instances. 

Proof.  The  probability  that  there  exists  a goal  that is not  a postcondition  of  any  operator 
can  be  developed  as  follows.  Consider  a particular  goal  and  operator: 

I:  Bylander/ArtQicial 

intelligence  81  (1996)  241-271 

247 

s/2n 

1 -  s/2n 

probabiiity  that  the  goal  is a  postcondition  of  the 
operator;  2 
probability  that  the  goal  is  not  a  postcondition  of  the 
operator; 

(1  -  s/2n)O  probability  that  the  goal  is  not  a  postcondition  of  any 

1 -  ( 1 -  s/2n)” 

( 1 -  ( 1 -  s/2n)“)g 

operator; 
probability  that  the  goal  is  a postcondition  of  some 
operator; 
probability  that  every  goal  is  a  postcondition  of  some 
operator. 

The  inequality  of  the  theorem  implies  that  the  above  probability  is  less  than  or  equal 

to  8.  Suppose  that  the  inequality  of  the  theorem  is true: 

oQ  v(lng--lnlnl/S). 

This  is  equivalent  to: 

OS 
-<ln- 
2n  -  s 

g 
In l/S 

In 

> 

OS 

-z- 

ln l/6 
-* g 
ln( 1 -  s/2n)  2  -s/(2n 

-  s)  by  inequality  (l),  which  implies: 

oln(1  -s/2n) 

2  ln- 

In l/S 

g 

. 

This  is  equivalent  to: 

( 1 -  s/2n)”  3  - 

In l/S 

g 

and: 

-(l- 

s/2n)”  <  $Y 

In( 1 -  (1  -  s/2n)O)  Q  -(  1 -  s/2n)O  by  inequality  (2),  which  implies: 

14 1 -  (1  -  s/2n)“)  <  y. 

This  is  equivalent  to: 

g ln( 1 -  ( 1 -  s/2n)“)  6  In 6 

* For arithmetic expressions within this paper, multiplication has highest precedence, followed by  division, 

logarithm, subtraction, and addition. E.g.,  I -  s/2n  is equivalent to  1 -  (s/(2n)  ). 

248 

7:  Bylander/Art#icial  Intelligence  81  (1996)  241-271 

and  finally: 

(l-(l-s/2nW<6, 

which  is  the  desired  inequality. 

Thus,  if  the  inequality  of  the  theorem  is  satisfied,  then  the  probability  that  some  goal 

is  not  a postcondition  of  any  operator  is at  least  1 -  S.  0 

Theorem  2.  For  random planning  instances  under  the fixed  model,  if 

o<  v(lng--lnlnl/@, 

\ 

then  POSTS-COVER-GOALS will  determine  that  no plan  exists for  at  least  1 -  6  of  the 
instances. 

Proof.  The  derivation  in the  previous  proof  holds  for  the  fixed  model  to  the  point  where 
1 -  (1  -  s/2n)O  is  the  probability  that  a  particular  goal  is  a  postcondition  of  some 
operator.  However,  if  this  goal  is a postcondition  of  some  operator,  then  this reduces  the 
probability  that  other  goals  will  be  postconditions  of  that  operator,  i.e.,  the  number  of 
“available”  postconditions  is  reduced  from  s  to  s -  1. Although  ( 1 -  ( 1 -  s/2n)O)s  is 
not  the  probability  that  every  goal  is  a  postcondition  of  some  operator,  this  expression 
does  remain  an  upper  bound.  Thus,  the  same  inequality  holds  for  the  fixed  model.  0 

For  fixed  6 and  increasing  n and g, the  above  bound  approaches  (2n -  s) (In g) /s.  If  s 
is  also  fixed,  the  bound  is  0(  n In g) . In  general  then,  planning  instances  with  a  number 
of  operators  linear  in  n  (or  linear  in  n  times  logarithmic  in  g  times  a  small  constant) 
will  not  have  plans.  Fortunately  though,  it  is  usually  easy  in  such  cases  to  prove  that  a 
plan  does  not  exist. 

Naturally,  more  complex  properties  that  are  efficient  to  evaluate  and  imply  plan 
non-existence  could  and  should  be  used,  e.g.,  the  above  algorithm  does  not  look  at 
preconditions  or  consider  how  postconditions  conflict  with  the  goals.  Nevertheless,  the 
analysis  of  POSTS-COVER-GOALS provides  a strong  bound  on  when  it  is easy  to  prove 
plan  non-existence. 

4.  Efficiently  finding  plans 

With  a sufficient  number  of  operators,  it becomes  likely  that  some  operator  will  make 
progress  towards  the  goal.  In  this  section,  I  consider  four  algorithms.  One  is  a  simple 
forward  search  from  the  initial  state  to  a  goal  state,  at  each  state  searching  for  an 
operator  that  decreases  the  number  of  goals  to  be  achieved.  The  second  is  a  backward 
search  from  the  goals  to  the  initial  state,  The  third  is  also  a  backward  search  from  the 
goals,  but tries  finds  a plan  that  will  reach  the  goals  from  any  initial  state.  The  fourth  is 
a  very  simple  algorithm  for  when  the  initial  state  and  goals  differ  by just  one  condition. 

To  illustrate  the  algorithms  the  following  instance  is  used: 

‘I: Bylander/Amjkial 

Intelligence  81  (1996)  241-271 

249 

P={ 
O={ 

al,a2.a3,a4}, 

al Au2  *  la3 Aa4, 

a2 Aa4  =s (13, 
la1 Au2  +  a3 A  a4, 

a2 A  Ta4 +  lal, 

Ta2 =P- a3 A  a4, 

*  --a2}, 

al, a2,la3, 

-4). 

a3,a4). 

Z={ 
G={ 

The  notation  pre +  post is used  for  operators;  the  preconditions  are  represented  by  a 
conjunction  of  conditions  before  the  arrow;  the  postconditions  are  after  the  arrow.  This 
instance  would  be possible  under  the  variable  model  for  II = 4,  o = 6,  g = 2,  and  r  and  s 
set  to  any  positive  number  between  1 and  3, inclusive,  though  it  would  be  an especially 
unlikely  instance  for  r  = 3  or  s = 3. 

4.1.  Forward search 

Consider  the  following  algorithm: 

PLAN-FORWARD ( S) 
if  6  is  satisfied  by  S 
then  return  success 
else  if  some  operator  can  be  applied  to  S and  satisfies  more  goals 

then  let  S’ be  the  result  of  applying  the  operator  to  S 

return  PLAN-FORWARD(S) 

else  return  don’t  know 
end  if 

end  if 

If  PLAN-FORWARD(Z)  is  called,  then  it  searches  for  an  operator  that  increases  the 
number  of  satisfied  goals.  If  there  is  such  an  operator,  the  current  state  S  is  updated. 
PLAN-FORWARD succeeds  if  it  reaches  a goal  state  and  is  noncommittal  otherwise. 

For  the  example  instance,  a  plan  of  the  first  two  operators  might  be  generated.  The 
first  operator  achieves  the  goal  LQ from  the  initial  state,  leaving  the  other  propositions 
unchanged.  The  second  operator  achieves  the  remaining  goal  a3. 

PLAN-FORWARD just  performs  simple  hill  climbing.  I  do  not  claim  that  this  is  a 
practical  algorithm  for  planning  in  general,  but  the  analysis  is  greatly  simplified  by 
avoiding  backtracking  and  partial  plans.  The  probability  that  the  algorithm  will  succeed 
can  be  bound  by  considering  the  probability  that  an  additional  goal  can  be  satisfied  by 
some  operator.  Certainly,  a  more  systematic  search  algorithm  that  efficiently  includes 
PLAN-FORWARD would  exceed  its  probability  of  success. 3 

‘One  such  algorithm  would  be  A*  search  from  the  initial  state  using  a  heuristic  equal  to  the  number  of 
unsatisfied  goals  times  any  constant  greater  than  1. The  constraint  on  the  constant  ensures that the number 
of  goals achieved are considered more valuable than the number of  operators applied. However, this  heuristic 
might  not  lead  to  optimal  plans. 

250 

I:  Bylander/Arti$cial 

Intelligence  81  (1996)  241-271 

Despite  its  handicaps,  PLAN-FORWARD is  surprisingly  robust  under  certain  condi- 
tions.  First,  I  demonstrate  two  lemmas  for  the  number  of  operators  that  need  to  be 
considered  to  increase  the  number  of  satisfied  goals.  One  lemma  is  for  the  variable 
model,  and  the  other  for  the  fixed  model. 

Lemma  3.  Consider  random  planning  instances  under  the  variable  model  except  that 
d  of  the  g  goals  are  not  satisfied.  If 

0 

>  &&5-w 
/ 

2  + 1 

(  1 

1’) 

f 

, 

then, for  at least  1 -  6 of  the  instances,  applying  some  operator  will increase  the number 
of  satisjied goals. 

Proof.  The  expression  for  the  probability  that  some  operator  will  increase  the  number 
of  satisfied  goals  can  be  developed  as  follows: 

( 1 -  r/2n)” 

(1  -  s/2n)sVd 

(1  -  s/2n)d 

1 -  ( 1 -  s/2n)d 

probability  that  a  state  satisfies  the  preconditions  of  an  ope- 
rator,  i.e.,  each  of  n  propositions  is  not  a  precondition  with 
probability  1 -  r/n;  alternatively,  a  proposition  is  a  match- 
ing precondition  with  probability  r/2n; 
probability  that  the  postconditions  of  an  operator  are  consis- 
tent  with  the  g -  d  goals  already  achieved; 
probability  that  the  postconditions  do  not  achieve  any  of  the 
d  remaining  goals,  i.e.,  for  each  goal,  it  is  not  a  postcondi- 
tion  with  probability  1 -  s/2n; 
probability  that  the  postconditions  achieve  at  least  one  of 
the  d  remaining  goals. 

Thus,  the  probability  p  that  a particular  operator  can  be  applied,  will  not  clobber  any 

satisfied  goals,  and  will  achieve  at  least  one  more  goal,  is: 

P=  (l-  $)” (1- 

;)“-” 

(1- 

(1-  &)“). 

1 -  p  is the  probability  that  the  operator  is missing  one  or  more  of  these  properties,  and 
( 1 -  p)”  is  the  probability  that  o  operators  are  unsatisfactory. 

If  ( 1 -p)” 

6  6,  then  there  will be  some  satisfactory  operator  with probability  at  least 

1 -  6.  This  inequality  is  satisfied  if  o  2  ( 1 /p)  (In 1 /a)  because  in  such  a case: 

(1  -p)“<e--po<e-l”‘/s=S. 

All  that  remains  then  is  to  determine  an  upper  bound  on  l/p, 

i.e.,  a  lower  bound  on 

p.  For  each  term  of  p: 

(I  -  r/&)” 

2  e-ml(2n-r)  >  e-‘, 

(1  _  s/2n)e” 

2  e-kd)l(*n-s) 

>  e-sW)ln, 

T.  Byhnder/ArtQicial 

Intelligence  81  (1996)  241-271 

251 

I- 

(1  -s/2& 

2  -. 

sd 

2n  +  sd 

Inverting  these  terms  leads  to  the  bound  of  the  lemma.  Cl 

Lemma  4.  Consider  random  planning  instances  under  the fixed  model  except  that  d 
of  the  g  goals  are  not  satisjied.  If  at  least 

operators  are  considered,  then, for  at  least  1 -  6 of  the  instances,  PLAN-FORWARD will 
find  an  operator  that increases  the  number  of  satisfied goals. 

Proof.  Just  as  in  the  previous  lemma,  the  approach  is  to  show  that  the  probability  p 
that  a  particular  operator  can  be  applied,  will  not  clobber  any  satisfied  goals,  and  will 
achieve  at  least  one  more  goal,  satisfies: 

p  >  e-re-GwWn 

sd 
2n+ 

The  probability  that  a particular  operator  can  be  applied  is  2-’  >  e-‘. 
The  probability  that  the  postconditions  of  an  operator  are  consistent  with  the  g  -  d 
goals  already  achieved  can  be  described  with  a  recurrence  equation.  Let  f  (s,  n, k)  be 
the  probability  that  s  conditions  can  be  randomly  generated  from  n  propositions  so  that 
they  are  consistent  with  some  particular  set  of  k conditions.  If  a  condition  is  randomly 
generated  from  the  n  propositions,  there  is  a  (n  -  k)/n  probability  that  it  is  neither 
identical  to  nor  the  negation  of  one  of  the  k conditions;  this  leaves  s -  1 conditions  to 
be generated  from  n-  1 propositions  and to be consistent  with k conditions.  Alternatively, 
there  is a  k/2n  probability  that  it is identical  to one  of  the  k conditions;  this  leaves  s -  1 
conditions  to be  generated  from  n -  1 propositions  to  be  consistent  with  k -  1 conditions. 
The  remaining  k/2n  probability  is  when  it  conflicts  with  one  of  the  k  conditions.  This 
leads  to  the  following  recurrence  equation: 

f  (s,  n, k)  = 

n-k 
yf(s- 

l,n- 

1,k)  +&f(s- 

l,n- 

l,k- 

I), 

which  was  introduced  as Eq.  (5). 
In  the  base  cases,  f(O,n,k) 

=  1,  f(s,n,O) 

=  1  (the  probability  is  1  if  there  are 
no  conditions  to  select  or  no  conditions  to  be  consistent  with),  f  (s,  n, n)  =  2-”  (each 
condition  to  select  must  have  a particular  sign),  and  f  (n,  n, k)  = 2-k  (each  condition  to 
be  consistent  with  must  be  selected).  For  this recurrence  equation  and  these  base  cases, 
inequality  (6)  holds,  in  this  case,  f  (s,  n, g  -  d)  2  e-s(s-d)ln. 

The  probability  of  achieving  at  least  one  more  of  the  d  remaining  goals  is one  minus 
the  probability  that  none  of  the  d  goals  are achieved,  i.e.,  1 -  f  (s,  n, d).  Inequality  (6) 
implies  that  f(s,n,d) 
follows. 

from  which  1 -  f(s,n,d) 

6  2n/(2n+sd), 

2  sd/(2n+sd) 

The  probability  that  the  postconditions  of  an  operator  are  consistent  with  the  g  -  d 
goals  already  achieved  is  not  independent  of  the  probability  of  achieving  at  least  one 

252 

T  Bylander/Artijkial  Intelligence 81 (19%)  241-271 

more  of  the  d  remaining  goals.  Fortunately,  the  two  events  have  an additive  dependency 
relationship,  i.e.,  either  event  “increases”  the probability  of  the  other  event.  For  example, 
if  the  postconditions  of  an  operator  are  consistent  with  the  goals  already  achieved, 
then  this  increases  the  probability  of  achieving  one  of  the  remaining  goals  because 
there  are  fewer  conditions  to  choose  from,  and  because  any  of  the  goals  can  still  be 
chosen. 

This  completes  the  proof.  0 

The  maximum  value  of  the  expression  in  the  lemmas  can  be  used  to  describe  PLAN- 

FORWARD, which  leads  to  the  following  theorem: 

Theorem  5.  For  random  planning  instances  under  either  the  variable  or  the  jT_xed 
model,  if 

o>ee  r  dn 

~+l 

2n (  > 

In;, 

then  PLAN-FORWARD will find  a plan for  at  least  1 -  6  of  the  instances. 

Proof.  For  g  goals,  the  number  of  satisfied  goals  will  be  increased  at  most  g  times. 
If  each  increase  occurs  with  probability  at  least  1 -  6/g,  then  g  increases  (the  most 
possible)  will  occur  with  probability  at  least  1 -  S  (this  follows  from  Bonferroni’s 
inequality). 

Thus,  Lemmas  3  and  4  can  be  applied  using  S/g  instead  of  S.  Maximizing  over  the 

g  goals  leads  to: 

The  bound  is  exponential  in  the  expected  numbers  of  pre-  and  postconditions.  Natu- 
rally, as operators  have more  preconditions,  it becomes  exponentially  less  likely  that  they 
can  be  applied.  Similarly,  as  operators  have  more  postconditions,  it  becomes  exponen- 
tially  less  likely  that  the  postconditions  are  consistent  with  the  goals  already  achieved. 
Note  though  that  if  g  <  n/s,  then  e sg/n <  e,  so  the  expected  number  of  postconditions  s 
is  not  as  important  a  factor  if  the  number  of  goals  is  small. 

For  fixed  6, r, and  s, and increasing  n and g, the above  bound  is Q( n In g) . Taking  into 
account  the  result  for  POSTS-COVER-GOALS, it  is  clear  that  two  sides  of  the  random 
planning  problem  are  easy.  Below  an  0(  n lng)  bound  on  the  number  of  operators, 
bound  on 
it  is  usually  easy  to  prove  that  a  plan  does  not  exist;  above  an  n(nlng) 
the  number  of  operators,  it  is  usually  easy  to  find  a  plan.  Remaining  is  a  gap  of  a 
constant  between  the  two  bounds,  which  is  exponential  in  the  number  of  pre-  and 
postconditions.  It  is  a  safe  conjecture  that  some  range  of  instances  within  the  gap  is 
hard,  so  I  conclude  that  random  planning  instances  exhibit  the  easy-hard-easy  pattern 
of  other  NP-hard  problems,  with  the  hard  problems  occupying  a  narrow  range  of  the 
number  of  operators.  The  empirical  study  in  a  following  section  displays  the  results  of 
using  this  algorithm. 

7I Bylander/Art$cial Intelligence 81 (19%) 241-271 

253 

4.2.  Backward 

search 

One  could  also perform  a backward  search  from  the  goals to  the  initial  state.  Consider 

the  following  algorithm: 

PLAN-BACKWAFW( G) 
if  G  is consistent  with  1, 
then  return  success 
else  if  there  is  a  an operator  with  R  and  S 

as  its  pre-  and  postconditions  such  that 
G  is  consistent  with  S, 
R  is consistent  with  G -  S, and 
+R)  -21 
IG-21  >  [((G-S) 

then  return  PLAN-BACKWARD( (G  -  S)  +  R) 
else  return  don’t  know 

Initially,  PLAN-BACKWARD(G)  is  invoked.  PLAN-BACKWARD then  chooses  an  op- 
erator  if  it  can  achieve  a  goal  state  from  another  state  that  has  fewer  conflicts  with 
the  initial  state  Z.  The  postconditions  S  of  such  an  operator  must  be  consistent  with 
the  current  set  of  goals  G,  its  preconditions  R  must  be  consistent  with  the  goals  not 
achieved  by  the  postconditions,  and  the  new  set  of  goals  (G  -  S)  +  R  must  have  fewer 
conditions  that  are  not  in  the  initial  state. 

In  the  example  instance,  the  third  operator  la1  A a2  +  ag A a4  achieves  the  goals 
{as,  ad},  leaving  {-al,  a2)  as the  new goals.  a2 is consistent  with the  initial state,  so this 
reduces  the  number  of  unsatisfied  goals by one.  Now the fourth  operator  a2 A -a4  +  Tal 
achieves  the  unsatisfied  goal  la],  and  the  new  set  of  goals  will  be  (a2. lab}.  which  is 
consistent  with  the  initial  state. 

The  disadvantage  of  PLAN-BACKWARD is  that  the  number  of  current  goals  G  can 
increase  steadily  to  the  number  of  propositions  n  because  each  new  set  of  goals  (G  - 
S)  +  R  can  be  r  -  1  larger  than  the  previous  set  of  goals  (under  the  fixed  model). 
First,  I  present  an  analysis  for  the  general  case,  then  I  consider  two  special  cases 
in  which  the  performance  of  PLAN-BACKWARD will  be  more  comparable  to  PLAN- 
FORWARD. 

Lemma  6.  Consider  random  planning  instances  under  the  variable  or  jixed  model 
except  that  d  goals  are  not  satisjied.  If 

0 2  e’+’ 

;+l 

2n (  > 

In;, 
6 

then,  for  at  least  1 -  S of  the  instances,  some  operator  will  achieve  a  goal  state from 
another  state  that  has faoer  conflicts  with  the  initial  state. 

Proof.  The  expression  for  the  probability  for  the  variable  model  can  be  developed  as 
follows: 

254 

‘T  Bylander/Ar:tjkiai 
I 

intelligence  81  (1996)  241-271 

(1  -  r/2n)” 

1 -  (1  -s/2# 

(1  -  s/2n)” 

a  lower  bound  on  the  probability  that  the  preconditions  of 
an operator  are  consistent  with  the  goals  minus  the  postcon- 
ditions,  and  all  preconditions  not  in  the  goals  minus  the 
postconditions  are  consistent  with  the  initial  state; 
probability  that  the  postconditions  achieve  at  least  one  of 
the  d  remaining  goals; 
a  lower  bound  on  the  probability  that  the  postconditions  of 
an operator  are  consistent  with  the  goals,  i.e.,  each  of  at 
most  n  goals  is  not  negated  with  probability  1 -  s/2n. 

The  last  two  probabilities  are  not  independent,  but  their  interaction  is  additive,  i.e., 
an  operator  that  is consistent  with  the  remaining  goals  is more  likely  to  achieve  one  of 
the  remaining  goals.  Thus,  the  probability  p  that  some  operator  will  reduce  the  number 
of  goals  that  are  not  true  of  the  initial  state  is  bounded  by 

p  2  (1  -  r/2n)n(  1 -  s/2n)“(  1 -  (1  -  $249. 

is the probability  that  the operator  is unsatisfactory,  and  ( 1 -p)” 

1 -p 
that  o  operators  are  unsatisfactory.  If  o  >  ( l/p)  (In l/6), 
satisfactory  operator  with  probability  at  least  1 -  6. 

is the  probability 
then  there  will  be  some 

For  each  term  of  p: 

(I  -  r/2n)”  3  e-ml(2n-r)  2  e-‘, 

( 1 -  s/2n)”  >  e-snl(2n-s)  2  eeS, 

l-(l-s/2n)d>---- 

sd 

2n+sd’ 

Inverting  these  terms  leads  to  the  bound  under  the  variable  model. 

Under  the  fixed  model,  let  f  be  recurrence  equation  (5).  Then,  the  probability  of 
suitably  consistent  pre-  and  postconditions 
is  at  least  f(r,  n,n)  =  2-’  >  e-’  and 
f(  S, n, n)  = 2-”  >  eeS,  respectively.  The  probability  that  the  postconditions  achieve  at 
least  one  of  the  d  remaining  goals  is  1 -  f(  S, n, d)  >  sd/(  2n+sd).  The  probability  that 
the postconditions  are  consistent  with the  goals  is not  independent  of  the  probability  that 
the  postconditions  achieve  at  least  one  of  the  d  remaining  goals,  but  their  interaction 
is  additive.  Thus,  the  probability  p  that  some  operator  reduces  the  number  of  goals  not 
true  of  the  initial  state  under  the  fixed  model  is  also  bounded  by: 

p  >  e-‘e-’ 

sd 

- 
2n+sd’ 

which  leads  to  the  inequality  of  the  theorem.  Cl 

As for  PLAN-FORWARD, to determine  a bound  for  PLAN-BACKWARD, the maximum 
value  of  the  expression  in  the  above  lemma  needs  to  be  determined.  This  is  done  to 
prove  the  following  theorem: 

Theorem  7.  For  random  planning  instances  under  either  the  variable  or  the  jixed 
model,  if 

T. Bylander/Artijicial  Intelligence 81 (1996) 241-271 

255 

then  PLAN-BACKWARD will$nd  a plan  for  at  least  1 -  6  of  the  instances. 

Proof.  For  g  goals,  the  number  of  unsatisfied  goals  will  be  decreased  at  most  g  times. 
If  each  decrease  occurs  with  probability  at  least  1 -  6/g,  then  g  decreases  (the  most 
possible)  will  occur  with  probability  at  least  1 -  6. 

Thus,  the  expression  in  the  previous  lemma  can  be  used  substituting  S/g  instead  of 

6.  Maximizing  over  the  g decreases  leads  to: 

The  difference  between  this  bound  for  PLAN-BACKWARD and  the  bound  for  PLAN- 
FORWARD is  that  the  PLAN-BACKWARD bound  has  an  es  term  instead  of  e’s/“.  This 
the  PLAN-BACKWARD bound  larger  by  a  factor  of  e’(“-s)/“,  so  if  the  number 
makes 
of  goals  g  is small  relative  to  the  number  of  propositions  n,  and  if  the  expected  number 
of  postconditions  s  is large,  then  the  increase  is  substantial. 

This  suggests  that  PLAN-FORWARD will  outperform  PLAN-BACKWARD when  g  is 
small  relative  to  n.  This  performance  difference  should  become  more  pronounced  for 
larger  s.  However,  if  r,  s,  and  S  remain  constant  as  g  and  n  increase,  the  order  of 
the  PLAN-BACKWARD bound  will  be  a(  n In g),  which  is  identical  to  the  order  of  the 
PLAN-FORWARD bound.  Also,  the  following  analysis  suggests  that  the  difference  will 
be  smaller  than  suggested  by  Theorem  7. 

4.3.  Backward  search  with fav  goals 

The  above  analysis  of  PLAN-BACKWARD assumes  the  worst  case  regarding  the  size 
of  the  current  set  of  goals  G,  namely  that  ICI  is  always  close  to  n.  However,  if  the 
number  of  goals  is  small enough,  specifically  g  <  n/r,  then  ICI can  never  reach  n  under 
the  fixed  model,  and  is  very  unlikely  to  reach  n  under  the  variable  model.  The  analysis 
for  the  fixed  model  is  much  more  tractable,  and  is given  below. 

Lemma  8.  Consider  random  planning  instances  under  the  fixed  model  except  that  d 
goals  are  not  satisjied,  and  there  are  no  more  than gr  -  dr  +  d  <  n  goals.  If 

o 

/ 
>  er,&gr-dr+d)ln 

then, for  at  least  1 -  S  of  the  instances,  some  operator  will achieve  a  goal  state from 
another  state  that has fewer  conjlicts  with the  initial state. 

Proof.  The  only  difference  from  the  proof  for  Lemma  6  is  that  the  postconditions 
must  be  consistent  with  at  most  gr  -  dr  +  d  goals  rather  than  at  most  n  goals.  The 
is 
probability  of  this  is  bounded  by  f  (s,n,gr 

-  dr  +  d)  3  e-s(sr-dr+d))l”,  where  f 

256 

T. Bylander/Artifcial 

Intelligence  81  (1996)  241-271 

recurrence  equation  (5),  and  the  inequality  follows  from  inequality  (6).  Substituting 
e-s(gr-dr+d)/n 
in  the  proof  for  Lemma  6  leads  to  the  bound  of  this  lemma.  Cl 

e-s 

for 

Theorem  9.  For  random  planning  instances  under  the jixed  model,  with gr  6  n  and 
r  >  1, if 

Q 

>  erewln 
I 

2n 
s+l 

(  > 

lni, 

then  PLAN-BACKWARD will$nd  a plan  for  at  least  1 -  6  of  the  instances. 

Proof.  For  g  goals,  the  number  of  unsatisfied  goals  will  be  decreased  at  most  g  times. 
If  each  decrease  occurs  with  probability  at  least  1 -  S/g,  then  g  decreases  (the  most 
possible)  will  occur  with  probability  at  least  1 -  8. 

Also,  satisfying  a goal  results  in increasing  the  total  number  of  goals  by  at most  r -  1. 
Thus,  when  there  are  d  goals  left  to  achieve,  there  are  at  most  g +  (g  -  d)  (r  -  1)  = 
gr  -  dr  +  d  goals. 

Thus,  the  expression  in  the  previous  lemma  can  be  used  substituting  S/g  instead  of 

S. Maximizing  over  the  g  decreases  leads  to: 

2” 

(sd+l)lni] 

<e’e”/‘($+l)ln~. 

Cl 

In  the  case  where  r  =  1, this  bound  for  PLAN-BACKWARD is the  same  as  for  PLAN- 
FORWARD. For  fixed  r  and  s  and  increasing  g and  n,  if  sgr  remains  small  relative  to  n, 
then  there  is  little  difference  between  the  two  bounds,  but  the  PLAN-FORWARD bound 
will  still be  smaller  for  r  >  1, though  it should  be  noted  that both  bounds  are  fl(n  lng). 

4.4.  Backward  search  independent  of  the  initial state 

Consider  the  following  variation  of  PLAN-BACKWARD: 

PLAN-BACKWAKDz( G) 
ifG=@ 
then  return  success 
else  if  there  is  a  an  operator  with  R  and  S 

as its  pre-  and  postconditions  such  that 
G  is  consistent  with  S, and 
I(G-  S)  +Rl  <  IGI 

then  re$mn  PLAN-BACKWARDz( (G  -  S)  +  R) 
else  return  don’t  know 

Like  the  previous  algorithm,  PLAN-BACKWARD2 looks  for  operators  that  reduce  the 
number  of  goals,  but  unlike  PLAN-BACKWARD, PLAN-BACKWARD2 does  not  depend 
on  the  initial  state,  and  it  repeatedly  looks  for  an  operator  that  reduces  the  number  of 
goals  until  there  are  no  goals  left.  If  PLAN-BACKWARD:! succeeds,  then  it  will  have 
discovered  a  sequence  of  operators  that  achieves  a  goal  state  from  any  initial  state, 

I:  Bylander/Artificial  Intelligence  81  (1996)  241-271 

251 

although  note  that  the  first  operator  in  this  sequence  (the  last  operator  selected  by 
PLAN-BACKWARD)  must  not  have  any  preconditions;  otherwise  [(G  -  S)  +  RI would 
be  nonzero.  Having  such  an  operator  is  probably  unrealistic;  it  is  impossible  under  the 
fixed  model  if  r  2  1. Nevertheless,  the  analysis  below  suggests  that  reducing  a  set  of 
goals  into  a  much  smaller  set  of  goals  is  often  possible,  which,  of  course,  can  then  be 
followed  by  forward  search  or  a more  general  backward  search. 

In  the  example  instance,  the  fifth  operator  7~2  =+ as A a4  achieves  the  goals  leaving 
the  single  new  goal  722.  The  sixth  operator  +  1~12 achieves  the  new  goal  without  any 
preconditions. 

I first  introduce  a lemma  for  the  number  of  operators  needed  to  find one  operator  that 

reduces  the  number  of  goals. 

Lemma  10.  For  random  planning  instances  under  the  variable  model,  with r  <  n/2 
and  s  <  n/2,  if 

0 

>  e2redn 
/ 

(  > 

z+l 
sg 

ln$, 

then, for  1 -  6  of  the  instances,  some  operator  reduces  the  number  of  goals. 

Proof.  The  preconditions  should  not  refer  to  any  condition  that  is  not  a  goal  or  the 
It  does  not  matter  what  the 
negation  of  a  non-goal.  This  has  probability  ( 1 -  r/n)n-g. 
postconditions  do  to  these  conditions. 

The  preconditions  and  postconditions  should  be  consistent  with  the  g  goals.  This  has 

probability 

However,  the  case  in  which  every  goal  equal  to  a  postcondition  is  also  equal  to  a 
precondition  must  be  avoided.  The  probability  that  this occurs  for  a  given  goal  is a  sum 
of  the  following: 

( 1 -  r/n)  ( 1 -  s/n) 

(r/2n) 

( 1 -  s/n) 

(r/2n) 

(s/2n) 

probability  that  the  goal  and  its  negation  is  not  in  the 
pre-  and  postconditions; 
probability  that  the  goal  is in  the  preconditions,  but  it 
(as  well  as its  negation)  is  not  in  the  postconditions; 
probability  that  the  goal  is  in  both  the  pre-  and  postcon- 
ditions. 

Using  the  sum  of  these  probabilities,  the  probability  of  this  case  happening  for  all  g 
goals  is: 

]_$I,$ 

( 

n 

g 
> 

( 

Thus,  the  probability  p  that  a random  operator  will  satisfy  the  stated  requirements  is: 

p=(l-r/n)“-g 

(l-&--&+2)‘- 

( 

258 

T. Bylander/Artijicial 

Intelligence  81  (1996)  241-271 

Now  recall  from  the  previous  proofs  that  if  the  number  of  operators  considered 
exceeds  ( 1 /p)  (In  1 /a), 
then  the  probability  that  some  operator  is satisfactory  is at  least 
1 -  6. What  remains  then  is to  demonstrate  an upper  bound  on  1 /p  (lower  bound  on p)  . 

For  the  first  term  of  p, 

(1  _  r/n)w? 

2  ,-rhN(~-r)* 

Because  I  6  n/2, 

e-r(n-g)l(n--r)  >  e-w-8f/n 

Regarding  the  second  term  of  p: 

6 &L$T-+$ 

=  &&+sg 

( 

6_ )  (  r 

1-g-;+4n2 

s 

3rs  g 

>) 

I-_ 

2n 

4n2 

)( 

= 

I- (  2rn+2sn-rs 

4n2 

g  1 _ 

H 

2rng  +  2sng  -  rsg 

>  exp 

g 
4n2  -  2m  -  4sn  +  3rs 
4n2  -  2rn  -  2sn  +  rs  >> 
1 _ 

2sn  -  2rs 

&t 

4n2  -  2rn  -  2sn  +  rs >) 

2sng  -  2rsg 

( 

( 

{ 

-  4n2  -  2rn  -  2sn  +  rs  1  4n2  -  2rn  -  4sn  +  rs  +  2sng  -  2rsg 

=exp 

- 

{ 

(2n-s)rg+(2n-r)sg+rsg 

(2n  -  r)(2n  -  s) 

2sg(  n -  r) 
>  (n-r)(2n+2sg-s)+n(2n-s)’ 

The  first  term  of  this  expression  can  be  further  simplified  using  r  <  n/2  and  s  <  n/2: 

exp 

- 

{ 

(2n-s)rg+(2n-r)sg+rsg 

(2n  -  r)  (2n  -  s) 

1 

rg 
2n  -  r 

=exp  1 

---- 

2,“” 

s 

- 

(2n  -  r;;g2n  -  S)  1 

2sg 

3n 

4rsg 

9n2  1 

bexp 

_y--- 

>exp 

{ 

{ 

--T-~-K 

2sg 

2sg 

1 

At  this  point,  the  following  lower  bound  for  p  has  been  derived: 

P  >  e-2r(n-s)lne-rglne-sg/n 

/ 

2sg(n  -  r) 

(n-r)(2n+2sg-s)+n(2n-s)’ 

This  can  be  further  simplified  using  e-2r(n--g)~ne--rg’n 3  e-2r. 

Finally,  an  upper  bound  for  (l/p) 

(In l/S) 

is derived: 

T 

Bylander/Artijicial 

Intelligence 

81 

(1996) 

241-271 

259 

L ln  1. < e2rewln 
P 

6‘ 

( 2n+2sg-s 

2sg 

(~2r&l~(~+~)1*; 

+  n(2n-$1 

2sg(  n -  I)  > 

1,; 

=  e2resgln  3n 
-v 
(cid:144)i 

which  proves  the  lemma. 

ln  1 
S’ 

Similar  to previous  theorems,  the  maximum  of  this expression  needs  to  be determined. 

This  is  done  to  prove  the  next  theorem. 

Theorem  11.  For  random  planning  instances  under  the  variable  model,  with  r  <  n/2 
and  s  <  n/2,  if 

then  PLAN-BACKWARD2 willjind  a plan  that achieves  the  goals from  any  initial state 
for  at  least  1 -  S of  the  instances. 

Proof.  For  g  goals,  the  number  of  remaining  goals  will  be  decreased  at  most  g  times. 
If  each  decrease  occurs  with  probability  1 -  S/g,  then  g  decreases  (if  necessary)  will 
occur  with  probability  at  least  1 -  6. 

Thus,  Lemma  10  can  be  applied  using  S/g  instead  of  6.  Maximizing  over  the  g 

decreases  leads  to: 

e”dlnn/sd  has  one  minimum  for  positive  d,  i.e.,  when  d  =  n/s.  So: 

As  a  result: 

e2r In $ 

esgin +  3 t&x  esdin : 

<  e2r ln 5 

esgln +  ?j!  +  7 

, 

( 

[ 

1) 

( 

> 

which  proves  the  theorem. 

0 

Comparing  the two bounds  for PLAN-FORWARD and PLAN-BACKWARDS, the  bound 
for  PLAN-BACKWARD2 is  worse  in  that  it  has  a  larger  constant  and  has  an  e2r 
to  an  e’  term  for  the  PLAN-FORWARD bound.  Because  PLAN- 
term  as  opposed 
BACKWARD2 does  not  use  the  initial  state,  some  increase  would  be  expected.  How- 
ever,  the  PLAN-BACKWARD2 bound  is  better  in  that  one  component  is  additive,  i.e., 
O(e”  + n/s)  ; whereas  the  corresponding  subexpression  for  the  PLAN-FORWARD bound 

260 

T.  Bylander/Artijicial 

Intelligence 

81 

(1996) 

241-271 

is  O(e”‘“n/s).  The  reason  is  that  in  the  maximization  of  the  PLAN-BACKWARD2 
bound,  esdln  is  maximum  when  d  is  at  its  maximum,  while  the  maximum  value  for 
n/sd  is when  d  is at its minimum.  In  the  maximization  for  the  PLAN-FORWARD  bound, 
es(gWd)/” attains  its maximum  at the  same  time  as n/sd  does,  when  d  is at  its  minimum. 
However,  for  fixed  r,  s,  and  8,  and  increasing  n  and  g,  both  bounds  are  fi (n In g) . 

4.5.  Plan  modi$cation 

So  far  I  have  considered  the  problem  of  generating  a  plan  from  scratch.  In  many 
cases,  however,  the  current  planning  instance  is  close  to  a  previously  solved  instance, 
e.g.,  [ 14,151. 

Consider  a  simplified  version  of  plan  modification,  specifically,  when  the  initial  state 
or set of  goals  of  the current  planning  instance  differs  by one  condition  from  a previously 
solved  instance.  In  this  case,  the  new  instance  can  be  solved  by  showing  how  the  new 
initial  state  can  reach  the  old  initial  state,  or  how  the  old  goal  state  can  reach  a  new 
goal  state.  Within  the  framework  of  random  planning  instances  then,  I  shall  analyze  the 
problem  of  reaching  one  state  from  another  when  the  two  states  differ  by  one  condition, 
i.e.,  there  are  n  goals,  and  all  but  one  goal  is  true  of  the  initial  state. 

The  worst-case  complexity  of  this problem,  like  the problem  of  planning  from  scratch, 
is  PSPACE-complete  [ 211.  However,  the  following  theorem  shows  that  efficient  plan 
modification  does  not  appear  to  require  as  many  operators  as  efficient  planning  from 
scratch. 

Theorem  12.  For  random  planning  instances  under  either  the  variable  or  the  jixed 
model  in  which  there are  n goals,  where  n -  1 goals  are  true of  the  initial  state,  if 

2n 
0 >  eres-ln 
s 

1 
-, 
s 

then, for  at  least  1 -  6 of  the  instances,  some  operator  solves  the  instance  in  one  step. 

Proof.  First,  I develop  the probability  p  that a random  operator  solves  a random  instance 
for  the  variable  model.  The  probability  that  the  preconditions  are  consistent  with  the 
initial  state  is  (1  -  r/2n)“.  The  probability  that  the  postconditions  are  consistent  with 
the  n -  1 goals  already  achieved  is  (1  -  s/2n)“-‘. 
In  addition,  the  probability  that  the 
goal  is achieved  by  a postcondition  is  s/2n.  T~us:~ 

p  = (1  -  r/2n)“(  1 -  s/2n)“-‘$. 

Lower  bounds  for  p  are: 

>  e-m~(2n-r)e-sn/(2n-s) 

PA 

_s_  2  e-‘e-ss* 
2n 

2n 

4 This  does  not  scale  up  to  the  case  of  attaining g  goals  by  a  single  operator. The  probability that the 
i.e.,  exponentially small in the number 

postconditions of  a random operator contain the g  goals is  (s/2n)g, 
of goals. 

T.  Bylander/Artificial 

Intelligence  81  (19%)  241-271 

261 

The  probability  that  none  of  o  operators  solves  the  instance  is  ( 1 -  p)“.  If  o  satisfies 

the  inequality  stated  in  the  theorem,  then: 

which  proves  the  bound  for  the  variable  model. 

For  the  fixed  model,  the  probability  that  the  preconditions  are  true  of  the  initial 
is 

state  is  2~’  >  e-‘.  The  probability  that  the  goal  is  achieved  by  a  postcondition 
s/2n  (it  is  selected  with  probability  s/n  and  has  the  right  sign  with  probability  l/2). 
The  probability  that  the  remaining  s -  1 postconditions  are  consistent  with  the  n  -  1 
goals  already  achieved  is  f(  s -  1, n -  1, n -  1)  >  2-‘+’  >  e-‘,  where  f  is defined  by 
recurrence  equation  (5).  Thus,  the probability  p  that  a random  operator  solves  a random 
instance  in  the  fixed  model  has  a lower  bound  of  e-‘eAss/2n,  and  the  inequality  of  the 
theorem  follows.  0 

Thus,  for  fixed  r,  s,  and  6,  n(n)  operators  suffice  to  solve  planning  instances  that 
differ  by  one  condition  from  previously  solved  instances.  So,  for  at least  the  distributions 
of  planning  instances  considered  here,  the  number  of  operators  needed  for  efficient  plan 
modification  appears  to  be  a  factor  of  O(lng) 
lower  than  that  needed  for  efficient 
planning  from  scratch. 

As  a corollary,  consider  any  state  sequence  of  length  g +  1 from  the  initial  state  to  a 
goal  state,  where  each  successive  state  in  the  sequence  differs  by  just  one  condition.  If 
g/S  is substituted  for  S in the  theorem,  and  the inequality  is satisfied,  then  any particular 
transition  in  the  sequence  can  be  accomplished  with  probability  1 -  S/g.  Consequently, 
all  transitions  can  be  performed  with probability  1 -  6. Thus,  n  (n in g)  planning  can  be 
accomplished  even  if  the  transitions  from  the  initial  state  to  a  goal  state  are  chosen  in 
advance. 

5.  Empirical 

study 

The  formal  analysis  provides  rigorous  probabilistic  bounds  on  when  random  planning 
instances  can  be  efficiently  solved,  either  by  proving  that  no  plan  exists  or  by  finding 
a  solution  plan.  However,  the  derivation  of  the  bounds  in  the  above  theorems  depends 
on  rather  crude  inequalities.  In  this  section,  I  display  the  empirical  results  when  two 
of  the  above  algorithms,  POSTS-COVER-GOALS and  PLAN-FORWARD, are  applied  to 
randomly-generated  planning  instances. 

Note  that  there  are  five parameters  to  choose  (the  number  of  operators  o,  the  number 
of  propositions  n,  the  number  of  pre-  and  postconditions  r  and  s,  and  the  number  of 
goals  g)  as  well  as  the  choice  of  variable  model  (on  average,  operators  have  I  and 
s  pre-  and  postconditions)  or  fixed  model  (each  operator  has  exactly  r  and  s  pre- 
and  postconditions).  As  a  result,  it  is  not  feasible  to  empirically  cover  many  of  the 
possibilities.  Any  choice  of  values  will  be  arbitrary  to  some  extent. 

I  chose  the  following  values  for  this  study:  n  = 100  and  n  =  1000,  r  =  2  and  s  =  2 
under  the  fixed  model,  g  ranging  from  low  values  up  to  n,  and  o  varying  over  where 
the  algorithms’  performance  changes.  The  two  values  for  n  allow  g  to  vary  over  many 

262 

7:  BylanderIArtificial 

Intelligence  81  (1996)  241-271 

1%  A 
10%  x 
50%  q 
90%  + 
99%  o 

00 

0  q 

++ 

oooo 

+  + 
0 

.a0 

10 

20 

Goals 

L 
100 

50 

x 

200  - 

0 

o-= 
2 

q 

+ 

0 

f 
o” 

0 

+ 

Oa 

5 

Fig.  I. Empirical effectiveness of  POSTS-COVER-GOALS for 100 propositions. The x-axis  is  logarithmically 
scaled. 

values,  and  also  show  how  the  transitions  change  from  a  lower  value  to  a  higher  value. 
The  values  of  r  and  s  are  the minimum  values that  make  propositional  STRIPS  planning 
PSPACE-complete  [ 41.  The  fixed  model  ensures  efficiency  in  generating  an  operator. 5 
Different  values  for  g  will  test  the  lng  asymptote. 

For  each  trial,  it is  assumed  that  there  is an unbounded  stream  of  randomly-generated 
operators  that  can  be  used.  For  the  POSTS-COVER-GOALS 
algorithm,  it  can  be  de- 
termined  when  the  stream  of  operators  covers  all  the  goals.  At  this  number  of  oper- 
fails  to  solve  the  problem.  In  my 
ators  (call  the  number  a),  POSTS-COVER-GOALS 
implementation  of  PLAN-FORWARD,  whenever  an  additional  goal  is  achieved,  the  al- 
gorithm  reverts  to  the  beginning  of  the  stream,  attempting  to  achieve  remaining  goals 
it  can  be  determined 
with  previously  generated  operators.  For  this  implementation, 
to  solve  the  problem.  At 
how  much  of  the  stream  was  used  by  PLAN-FORWARD 
this  number  of  operators  (call  this  number  b),  PLAN-FORWARD 
solves  the  prob- 
lem. 

1000 trials  were  performed  for  each  value  of  n  and g considered.  This  will,  as shown 
below,  give  a  good  indication  of  where  these  algorithms  solve  from  1% to  99%  of  the 
instances.  I.e.,  if  99%  of  the  a  values  are  greater  than  100, then  POSTS-COVER-GOALS 
empirically  solves  at  least  99%  of  the  instances  when  o  <  100. If  1%  of  the  b  values 
are  less  than  or  equal  to  1000, then  PLAN-FORWARD  empirically  solves  at  least  1% of 
the  instances  when  o  2  1000. 

5 It takes constant time to  generate two  random numbers. For the variable model, generating an operator 
would take time linear in n because each condition must be independently considered. 

I:  Bylander/ArtQicial  Intelligence  81  (1996)  241-271 

263 

r 

6000’ 

99%  O 
90% 
+ 
50% 
10%  x 
1%  * 

q 

o 

0-S 

ooQ 
0 

0 

+ 

+  +. 
+ 

+  ++ 

0 

0  ooOQ 
0 

Ooo 

Ooo 0 

oQoOQ 

oooQ 

IL 
0 

20 

40 

60 

80 

100 

Goals 
Fig. 2. Empirical effectiveness of PLAN-FORWARD  for 100 propositions. 

Fig.  1 displays  the  empirical  results  for  POSTS-COVER-GOALS when  IZ =  100.  The 
x-axis  is  the  number  of  goals  (even  numbers  from  2  to  100)  on  a  logarithmic  scale, 
and  the  y-axis  is the  number  of  operators.  Each  point  on  the  graph  indicates  the  number 
of  operators  where  POSTS-COVER-GOALS solves  a  certain  percentage  of  instances  for 
a  given  number  of  goals.  The  five  kinds  of  points  correspond  to  five  isolevels.  The 
diamond  points  indicate  99%  effectiveness;  the plus  points  90%  effectiveness;  the  square 
points  50%;  the  x  points  10%; and  the  triangle  points  1%. The  POSTS-COVJZR-GOALS 
algorithm  has  higher  effectiveness  for  lower  number  of  operators.  For  a  given  level  of 
effectiveness,  the  logarithmic  scaling  makes  it  clear  that  the  number  of  operators  varies 
logarithmically  with  g,  which  is  consistent  with  the  theoretically  derived  bound.  Also, 
the  theoretical  bound  is remarkably  close  to  the  empirical  results,  e.g.,  for  g  =  100 and 
6  =  0.01,  the  theoretical  bound  gives  305  operators;  the  empirical  result  is  311.  This 
closeness  is  also  true  for  n =  1000. 

Fig.  2 displays  the results  for  PLAN-FORWARD when  IZ =  100. The  x-axis  is displayed 
on  a  linear  scale  in  this  graph.  In  this  case,  PLAN-FORWARD has  higher  effectiveness 
for  higher  number  of  operators.  In  apparent  contradiction  to  the  analysis  for  PLAN- 
FORWARD, the  effect  of  the  number  of  goals  appears  to  be  linear.  For  example,  the 
99%  effectiveness  level  appears  to  vary  linearly  from  about  2000  for  g  =  2  to  about 
6000  for  g  =  100. The  apparent  contradiction  can  be  resolved  by  looking  closer  at  the 
theoretical  bound  of  Theorem  5,  i.e.,  e’esgin(2n/s  +  1) (lng/6),  where  for  this  data 
r=s=2andn= 
100.  As  the  number  of  goals  g  increases  from  2  to  100,  lng/6  with 
6  =  0.01  only  doubles,  but  note  that  e ‘gin increases  by  more  than  a  factor  of  7,  with 
most  of  the  increase  occurring  for  g  >  50. This  is more  than  sufficient  to account  for  the 
three-fold  increase  observed  for  the  99%  effectiveness  level.  Because  e’gl”  more  than 
doubles  when  g  >  n/2  while  In g does  not  even  increment  by  1  (no  matter  what  n  is), 

264 

I:  Bylander/Aritjkial Intelligence 81 (3996) 241-271 

1001 + Ooo ’ 
20 

0 

40 

60 

80 

1 

100 

Goals 
Fig.  3.  Combined  empirical  effectiveness  of  POSTS-COVER-GOALS  and  PLAN-FORWARD  for  100 proposi- 
tions.  The  ),-axis  is  logarithmically  scaled. 

a  similar  effect  should  be  present  for  higher  values  of  n.  In  this  case,  the  theoretical 
bound  (which  is  over  50,000  for  g =  100 and  6  =  0.01)  exceeds  the  empirical  values 
by  a  very  pessimistic  margin.  This  is  also  true  for  n =  1000. 

Fig.  3  shows  the  combined  performance  of  the  two  algorithms  for  n  =  100.  For 
this  graph,  the  y-axis  is  given  a  logarithmic  scaling  and  is  cut  off  at  100  to  increase 
readability.  There  is more  than 99% effectiveness  at the top  and bottom  of  the  graph with 
minima  in  the  middle.  The  minimum  effectiveness  of  the  algorithms  steadily  decreases 
as more  goals  are  added,  indicating  that  the problem  becomes  progressively  harder  with 
additional  goals.  The  middle  right  of  the  graph  contains  a  region  where  the  combined 
effectiveness  of  the  algorithms  is  less  than  1%. There  is  no  point  in  the  empirical  data 
where  the combined  effectiveness  is 0%.  The  points  where  100% empirical  effectiveness 
occurs  are  similarly  spaced  on  the  graph  from  the  99%  points.  Le.,  the  distance  on  the 
graph  between  the  100%  points  and  the  99%  points  is  similar  to  the  distance  between 
the  99%  points  and  the  90%  points.  The  100%  points  have  high  variability,  which  is 
why  they  are  not  displayed. 

The  results  for  n =  1000 propositions  are  displayed  in  Figs.  4,  5,  and  6.  This  exper- 
iment  took  over  one  CPU-week  on  a  Spare  5  running  Lucid  Common  Lisp.  The  most 
significant  differences  are  as  follows. 

l There  is  about  a  ten-  to  twenty-fold  increase  in  the  number  of  operators  for  high 
levels  of  effectiveness.  For  the  99%  effectiveness  level  for  POSTS-COVER-GOALS 
(comparing  Fig.  4  versus  Fig.  l),  the  n =  1000 data  starts  at  about  1500 operators 
for  g  =  20,  and  goes  up  to  over  5000  operators  for  g  =  1000;  the  n  =  100  data 
has  about  150 operators  for  g = 20,  up  to  about  300  operators  for  g =  100. For  the 
(comparing  Fig.  5  versus  Fig.  21,  the 
99%  effectiveness  level  for  PLAN-FORWARD 

I:  Bylander/Artificial 

Intelligence  81  (1996)  241-271 

265 

A 

A 

hA 

8000  -A 

;3 
9 E!  6000 

- 

8 

x 

4000  - 

0 

2000-+ 

0 

x 

0 

+ 
0 

x 

0 

+ 

o 

xXxXx 

xxx 

x  x  x  xx 

0 

+ 
0 

20 

50 

100 

200 

500 

1000 

Goals 

Fig.  4. Empirical  effectiveness  of  POSTS-COVE&GOALS 
scaled. 

for  1000 propositions.  The x-axis  is  logarithmically 

0 

0 

I 

200 

I 

400 

600 

800 

1000 

Goals 

Fig.  5. Empirical  effectiveness  of  PLAN-FORWARD  for  1000 propositions. 

n  =  1000  data  starts  at  about  30,000  operators  and  goes  up  to  80,000.  The  n  =  100 
data  starts  at  about  2000  operators,  going  up  to  about  6000  operators.  This  closely 
corresponds 
in  the  number  of  propositions 
and  a  50%  increase 

of  a  ten-fold 
in  Ing  from  g  =  100  to  g  =  1000. 

to  a  combination 

increase 

266 

7:  Bylander/Artificial  Intelligence  81  (1996)  241-271 

2000-+" 

0 

1000 

0 

1 

200 

I 

600 

I 

800 

I. 

1000 

400 

Goals 

Fig.  6.  Combined empirical effectiveness of  POSTS-COVER-GOALS and PLAN-FORWARD for  1000  proposi- 
tions. The ,v-axis is logarithmically scaled. 

l  The  effectiveness 

levels  for  PLAN-FORWARD 

again  appears 
exponential 
is  explained  by  the  e ‘p/n  term  in  the  theoretical 

in  the  number  of  goals,  perhaps  even  mildly 
goals.  This 
above. 

to  be  primarily 
linear 
for  large  numbers  of 
analysis  as  described 

l  Fig.  6  displays  a  much 

larger  region  of  hard  instances 

for  II  =  1000,  as  compared 
to  the  left  side  of  the 
to  pt =  100.  The  1%  effectiveness 
harder  as  g  increases.  Roughly, 
graph.  Again, 
the  contour  where  0%  empirical  effectiveness 
spaced  from 
the  1%  points  on  the  graph.  The  0%  points,  as  might  be  expected,  are  highly 
variable,  and  so,  are  not  displayed. 

the  instances  become  progressively 

region  now  extends  almost 

takes  hold  is  similarly 

For  both  algorithms 

and  both  values  of  the  number  of  propositions 

appears  smooth;  nevertheless, 

pattern.  This  is  shown 

and 

there 

increase, 

is  an  easy-hard-easy 

tion  from  1%  to  99%  effectiveness 
operators 
parameter  values  n  =  1000  and  g  =  500.  The  x-axis 
number  of  operators 
tiveness  or  probability 
of  the  instances 
ators.  The  effectiveness 
of  the  instances 
from  0  M  13,000 
o  M  19,000.  Finally 

to  0  x  16,000.  PLAN-FORWARD 
99%  of  the 

are  solved  by  POSTS-COVER-GOALS 

of  POSTS-COVER-GOALS 

at  o  M  52,000, 

is  logarithmically 

the  y-axis 
of  a  definitive  answer  by  the  algorithms. 

scaled; 

in  the  figure  corresponds 
is  the  empirical 
Initially, 

to  the 
effec- 
at  least  99% 
there  are  o  M  4700  oper- 
drops  to  1%  at  o  =  10,500.  None 

until 

solves  1%  of  the  instances 

at 
are  solved  by  PLAN- 

instances 

are  solved  by  either  POSTS-COVER-GOALS 

and  PLAN-FORWARD 

FORWARD. 

A  valuable  addition 

to  Fig.  7  would  be  a  display  of  the  probability 

plan  dependent  on  the  number  of  operators,  showing 

the  location  of  the  transition 

of  a  solution 
from 

II,  the  transi- 
as  the  number  of 
in  Fig.  7  for  the 

b  Bylander/Artifcial 

Intelligence  81  (1996)  241-2  71 

267 

0.8 

8 
2  0.6 
9 
‘3 
8 
w 

0.4 

0.2 

0.0 

2000 

5000 

10000 

20000 

50000 

100000 

Operators 

Fig.  7.  Empirical  effectiveness  of  POSTS-COVER-GOALS and PLAN-FORWARD for 1000 propositions  and 
500 goals.  The  x-axis  is  logarithmically  scaled. 

planning  instances  with  no  solution  plans  to those  with solution  plans.  Unfortunately,  the 
empirical  data  from  running  the  algorithms  are  clearly  insufficient  to  determine  whether 
the  transition  is  sharp  or  not  and  to  determine  the  location  of  the  50%  transition  point. 
Also  unknown  are  the  lengths  of  the  shortest  solution  plan  for  those  instances  that  have 
solution  plans.  Determining  this information  appears  infeasible  even  for  n =  100 because 
it  would  be  slow  to  use  any  systematic  search  to  find  a  possibly  very  long  plan  in  a 
search  space  of  size  2’O”. 

6.  Remarks 

I  have  shown  that  determining  plan  existence  for  propositional  STRIPS  planning  is 
usually  easy  if  the  number  of  operators  satisfy  certain  bounds,  and  if  each  possible  pre- 
condition  and  postcondition  is equally  likely  to appear  within  an operator,  independently 
of  other  operators.  Assuming  that  the  expected  numbers  of  pre-  and  postconditions  are 
fixed,  then  it is usually  easy  to show  that no plan exists  for  instances  with it propositions, 
g  goals,  and  the  number  of  operators  below  an O( n In g)  bound,  and it is usually  easy  to 
find plans  for  instances  with  n propositions,  g goals,  and  the  number  of  operators  above 
an  Q (n In g)  bound.  In  addition,  plan  modification  instances  are  usually  easy  to  solve  if 
there  are  0  (n)  operators.  The  constants  for  the  latter  two  results  are  exponential  in  the 
expected  numbers  of  pre-  and  postconditions. 

The  0  (n In g)  result  was demonstrated  for  three  simple planning  algorithms.  Searching 
from  the  initial  state  to  the  goals  appears  to  have  a  slight  advantage  over  searching 
backward  from  the goals.  However,  it appears  possible  in many  cases  to  search  backward 

268 

T. Bylander/Artifcial 

Intelligence  81  (1996)  241-271 

from  the  goals  to  find  a  plan  that  is  largely  independent  of  the  initial  state.  Of  course, 
it  should  be  mentioned  that  rather  crude  inequalities  are  used  in  the  analysis  to  derive 
simplified  expressions.  The  empirical  behavior  of  the POSTS-COVER-GOALS and PLAN- 
FORWARD algorithm  corresponded 
to  the  theoretical  terms;  however,  the  theoretical 
bounds  for  PLAN-FORWARD are  very  conservative. 

This  work  complements  and  extends  previous  average-case  analyses  for  NP-complete 
problems.  It  complements  previous  work  because  it  suggests  that  random  planning 
instances  are  hard  only  for  a  narrow  range  of  a  particular  parameter,  in  this  case,  the 
number  of  operators.  It  extends  previous  work  because  the  worst-case  complexity  of 
propositional  STRIPS  planning  is  PSPACE-complete,  thus,  suggesting  that  PSPACE- 
complete  problems  exhibit  threshold  phenomena  similar  to  NP-complete  problems.  The 
empirical  study  also  resulted  in  the  easy-hard-easy  pattern  characteristic  of  random 
instances  of  hard  problems,  though  with  smooth  transitions. 

This  work  also  provides  theoretical  and  empirical  support  for  reactive  behavior.  A 
main  tenet  of  reactive  behavior  is  that  sound  and  complete  planning,  besides  being 
too  inefficient,  is  often  unnecessary,  i.e.,  states  can  be  mapped  to  appropriate  operators 
without  much  lookahead.  The  analysis  of  the  PLAN-FORWARD algorithm,  which  only 
does  a one-step  lookahead,  shows that  this tenet  is true  for  a large  subset  of  the  planning 
problem. 

Further  work  is  needed  to  narrow  the  gap  between  the  bounds  derived  by  this  paper 
and  to  analyze  more  realistic  distributions.  In  particular,  the  assumption  that  operators 
are  independently  selected  is  clearly  wrong.  Nevertheless,  it  would  be  interesting  to 
empirically  test  how  well  the  bounds  of  this  paper  classify  the  hardness  of  realistic 
planning  problems. 

Also,  more  sophisticated  algorithms  should  be  analyzed  and  empirically  tested.  It  will 
be  a challenge  to  develop  planning  algorithms  that  are  sufficiently  efficient  and effective 
to  compare  against  the  empirical  results  in  this  paper. 

Acknowledgements 

Comments  from  anonymous  reviewers  and  Tad  Hogg  led  to  the  empirical  study  that 
was performed,  which  in  turn  led  to  improved  theoretical  results.  Jerry  Keating  pointed 
out  the  use  of  Bonferroni’s  inequality  to  me. 

Appendix  A.  Proofs  of  some  inequalities 

The  proof  of Lemma  4 depends  on upper  and lower  bounds  for  the recurrence  relation: 

f(s,  n,  k) 

n-k 

=~f(s-l,~-l,k)+~f(s-l,n-l,k-l), 

for  a  positive  integer  n  and  nonnegative  integers  s  and  k,  s  <  n  and  k  <  n,  where  the 
base  cases  are  f(0,  n, k)  =  1,  f(s,n,O) 
=  2-k. 
See  the  proof  of  Lemma  4  for  a justification  of  this  equation. 

=  2-‘,  and  f(n,n,k) 

=  1,  f(s,n,n) 

T. Bylander/Art@cial  Intelligence 81  (19%)  241-271 

269 

Lemma  A.l. 

f(  s, n, k)  2  evskJn. 

Proof. 

In  the  base  cases: 

f(0, 

n,  k)  =  1 =  e”, 

f(s,  n,  0)  =  1 =  e”, 

f(  s,  n,  n)  =  2-’  2  e-‘, 

f(n,  n, k)  = 2-k  >  evk. 

Using  mathematical 

induction, 

assume 

that  (s,  n,  k)  is  not  a  base  case,  and  that  the 

inequality  holds  for  all  tuples 

less  than  (s,  n,  k).  Then: 

f(s,n,k) 

n-k 
,fW,n-l,k)+&f(s-l,n-l&l) 

= 

~~e~p{-‘r_‘:k}+te~p{-‘~-~~~-l’}. 

For  each  exponential: 

exp{-(h~ll)k}=e-SkJnexp{~~~slk)}, 

(s- 

l)(k- 
n-l 

1) 

=e-sk,nexp 

nk-sk+ns-n 

> 

Using  eX >  1 +  X: 

=e 

=e 

_skln  2n3 -  2n2 +  kn2 -  kns  -  knk  + ksk 

2n2(n  -  1) 

-$k/,, 

1 +  k(n-s)(n-k) 

2n2(n  -  1) 

The  final  inequality 

follows  because  n  3  s  and  n  3  k.  0 

Lemma  A.2. 

f(s,n,k) 

<  - 

2n 
2n+sk’ 

Proof. 

In  the  base  cases: 

nk  -  sk  + ns  -  n 

270 

T  Bylander/Art@cial 

intelligence  81  (19%)  241-271 

f(O,n,k)  =  1=  A, 

2n+Ok 
2n 

2n+Os’ 

=  1=  - 

f(s,n,O) 

f(s,n,n) 

=2-S=e-S’“2  <ee-s/2 <  2 

‘2=s= 

2n 

f(n,n, 

k)  =2-k  <  L. 

2n  +  nk 

Using  mathematical  induction,  assume  that  (s,n,  k)  is  not  a  base  case,  and  that  the 

inequality  holds  for  all  tuples  less  than  (s,n,  k).  Then: 

f(  s,  It, k) 

n-k 

=Tf(s-l,n-l,k)+$f(s-l,n-l,k-l) 

n-k 

,<- 

n 

( 

2(n  -  1) 
2(n  -  1)  +  (s  -  1)k 

2(n  -  1) 

2(n-l)+(s-l)(k-1) 

>  ’ 

A  lot  of  tedious  algebra  leads  to: 

f(  s, n, k) 

2n 

<-. 

2n  +  sk 

l+2kn(s-n)(s-1)+k3s(s-1)(1-n)+2k2(-sn2+3sn-n-s2) 

( 

2n*(n- 

1)(2(n- 

1) +  (s- 

l)k)(2(n- 

1)  +  (s- 

l)(k- 

1)) 

>  ’ 

Considering  the  numerator  of  the  large  fraction,  2kn(s 

-  n)  (s  -  1)  <  0  because 
s  -  n  6  0  and  the  other  terms  are  nonnegative.  Also,  k3s(  s  -  1) ( 1 -  n)  <  0  because 
1 -  n  <  0  and  the  other  terms  are  nonnegative.  This  leaves  2k2(  -sn*  +  3sn  -  n  -  s*) 
to  consider.  If  n  2  3,  then  -sn*  +  3sn  =  sn(3  -  n)  <  0,  and  the  remaining  -n  -  s*  is 
negative.Ifn=2,s=2ands=Oarebasecases,andifs=1,-sn2+3sn-n-s2=0. 
n  =  1  and  n  =  0  must  be  base  cases,  i.e.,  at  least  one  of  s  =  0,  k  =  0,  s  =  n, 
or  k  =  n  must  be  true.  Thus,  the  numerator  must  be  nonpositive,  which  implies  that 
f(s,n,k) 

<2n/(2n+sk). 

(cid:144)i 

References 

[ I 1 C.  Backstrom  and  1. Klein,  Parallel non-binary  planning  in  polynomial  time,  in:  Proceedings  IJCAI-91, 

Sydney,  Australia  (1991)  268-273. 

12 I T.  Bylander,  Complexity  results  for  planning,  in:  Proceedings  IJCAI-91,  Sydney,  Australia  (1991) 

274-279. 

13 I T. Bylander,  An  average  case. analysis  of  planning,  in:  Proceedings  AAAI-93,  Washington,  DC  ( 1993) 

480-485. 

141 T. Bylander,  The  computational  complexity  of  propositional  STRIPS  planning,  Artij  Intell.  69  (1994) 

161-204. 

] 51  D.  Chapman,  Planning  for  conjunctive  goals,  Arti$  Intell.  32  (3)  ( 1987)  333-377;  also  in:  J.  Alien, 
J.  Hendler  and  A.  Tate, eds.,  Readings  in  Planning  (Morgan  Kaufmann,  San  Mateo,  CA,  1990). 

7:  Byhnder/Art$icial 

Intelligence  81  (1996)  241-271 

271 

16 1 I? Cheeseman,  B.  Kanefsky  and  W.M.  Taylor, Where  the  really  hard  problems  are,  in:  Proceedings 

IJCAI-91,  Sydney,  Australia  ( 199 1) 33 l-337. 

17 1 P.R. Cohen,  A  survey  of  the  Eighth  National  Conference  on  Artificial  Intelligence:  pulling  together  or 

pulling  apart?, AI  Msg.  12 (1)  (1991)  17-41. 

[ 8 1 T.H. Cormen,  C.E.  Leiserson  and  R.L. Rivest,  Introduction  to Algorithms  (MIT  Press,  Cambridge,  MA, 

1990). 

( 9 ] J.M.  Crawford  and  L.D.  Auton,  Experimental  results  on  the  crossover  point  in  satisfiability  problems, 

in:  Proceedings  AAAI-93,  Washington,  DC  ( 1993) 46-51. 

1 IO]  K.  Erol,  D.S.  Nau  and  V.S.  Subrahmanian,  On  the  complexity  of  domain-independent  planning,  in: 

Proceedings  AAAI-92,  San Jose,  CA  (1992)  381-386. 

[ I1 I  K.  Brol,  D.S.  Nau  and  VS.  Subrahmanian,  When  is  planning  decidable?,  in:  Proceedings  First 

International  Conference  on  AI  Planning  Systems  (1992)  222-227. 

1 12 1 R.E. Rkes  and  N.J.  Nilsson,  STRIPS: a new  approach to the  application  of theorem  proving  to problem 
( 1971)  189-208;  also in: J.  Allen, J.  Hendler  and  A.  Tate, eds.,  Readings 

solving,  Artit  Intell.  2  (3/4) 
in Plunning  (Morgan  Kaufmann,  San  Mateo,  CA,  1990). 

[ 13 I  M.R.  Gamy  and  D.S.  Johnson,  Computers  and  Intractability (Freeman,  New York,  1979). 
[ 141 K.J.  Hammond,  Explaining  and  repairing  plans  that  fail, Arh$  Intell.  45  (l-2) 
[ 15 1 S.  Kambhampati  and  J.A.  Hendler,  A  validation-structure-based  theory  of  plan  modification  and  reuse, 

(1990)  173-228. 

ArtiJ  Inrell.  55  (2-3) 

(1992)  193-258. 

[ 16 I  D.  McAllester  and  D.  Rosenblitt,  Systematic  nonlinear  planning,  in:  Proceedings  AAAI-91,  Anaheim, 

CA  (1991)  634-639. 

1 I7 I  M.  Minsky,  Logical  versus  analogical  or  symbolic  versus  connectionist  or  neat  versus  scruffy, AI  Msg. 

12  (2)  (1991)  34-51. 

[ 18 1 S.  Minton,  M.D.  Johnston,  A.B.  Philips  and  P  Laird,  Minimizing  conflicts:  a  heuristic  repair  method 

for  constraint  satisfaction  and  scheduling  problems,  Art$  Intell.  58  (1992)  161-205. 

1 I9 I  D. Mitchell,  B. Selman and H.J. Levesque,  Hard and easy distributions  of SAT problems,  in: Proceedings 

AAAI-92,  San Jose,  CA  ( 1992)  459-465. 

1201 R.  Musick  and  S.  Russell,  How  long  will  it  take?,  in:  Proceedings  AAAI-92,  San  Jose,  CA  ( 1992) 

466-47  1. 

12 I j B.  Nebel  and  J.  Koehler,  Plan  modification  versus  plan  generation:  a  complexity-theoretic  perspective, 

in:  Proceedings  NCAI-93,  Chambery,  France  (1993)  1436-1441. 

I22 I  N.J.  Nilsson,  Principles  of Art@cial  Intelligence  (Tioga,  Palo  Alto,  CA,  1980). 
I23 I J.S.  Penberthy  and  D.S.  Weld,  UCPOP:  a  sound,  complete,  partial  order  planning  for  ADL,  in: 
Proceedings  Third International  Conference  on  Principles  of Knowledge  Representation  and  Reasoning, 
Cambridge,  MA  (1992)  103-l  14. 

I24 I  B.  Selman  and  H.A.  Kautz,  An  empirical  study  of  greedy  local  search  for  satisfiability  testing,  in: 

Proceedings  AAAI-93,.  Washington,  DC  ( 1993) 46-51. 

I25 I  B.  Selman,  H.  Levesque  and  D.  Mitchell,  A  new  method  for  solving  hard  satisfiability  problems,  in: 

Proceedings  AAAI-92,  San Jose,  CA  ( 1992) 440446. 

I26 I C.P. Williams  and T. Hogg,  Using  deep  structure to  locate hard problems,  in: Proceedings  AAAI-92,  San 

Jose,  CA  (1992)  412-477. 

