Artificial  Intelligence  89  ( 1997)  173-217 

Artif’icial 
Intelligence 

Permissive  planning: 
extending  classical  planning  to  uncertain  task 
domains 

Gerald  F.  DeJongayb-*,  Scott  W.  Bennett  c 
a Department  of  Computer  Science,  University of  Illinois at  Urbana-Champaign,  405  North  Matthews Ave., 
Urbana,  IL  61801,  USA 
h Beckman  Instihde,  University of  Illinois at  Urbana-Champaign,  405  North  Matthews  Ave., 
Urbana,  IL  61801,  USA 
’  SRA  Corporation,  2000  15th  St.  North,  Arlington,  VA,  USA 

Received  May  1995; revised  July  1996 

Abstract 

Uncertainty, 

inherent 

significant, 

even  prohibitive, 

plans.  On  the  other  hand,  reasoning  with  representations 
engender 
novel  approach 
is  employed 
planning.  Machine 
Thus,  the  classical  planner  is  conditioned 
in  the  world. 

to  planning 
learning 

in  most  real-world  domains,  can  cause  failure  of  apparently  sound  classical 
can 
a 

costs.  This  paper  contributes 

additional  computational 

reflect  uncertainty 

that  explicitly 

in  uncertain  domains.  The  approach 

is  an  extension  of  classical 
failures. 
to  adjust  planner  bias  in  response 
to  execution 
towards  producing  plans  that  tend  to  work  when  executed 

ability 

domain 

learning.  The  user-supplied 

The  planner’s  representations 

are  simple  and  crisp;  uncertainty 

only  during 
the  planner’s  projection 
of  the  planner’s  bias  space 
The  learning  converges  using  no  more  than  a  polynomial  number  of  examples.  The  system 
probabilistically 
that  adequate  planning 
system 

is  represented  and  reasoned  about 
theory  is  left  intact.  The  operator  definitions  and 
them.  Some  structuring 
scales  well. 
then 
that  either  the  plans  produced  will  achieve  their  goal  when  executed  or 
robotic 

is  required.  But  with  suitable  structuring 

theory  provided.  An  implemented 

is  not  possible  with  the  domain 

remain  as  the  domain  expert 

the  approach 

is  described. 

guarantees 

intended 

Keywords:  Planning;  Learning;  Uncertainty;  Machine  learning;  Explanation-based 

learning;  Planning  bias 

* Corresponding 

author.  E-mail:  dejong@cs.uiuc.edu. 

0004-3702/97/$17.00 
PIISOOO4-3702(96)00031-8 

Copyright  @  1997  Elsevier  Science  B.V.  All  rights  reserved 

174 

G.E DeJong, SW! Bennett/Artijicial  Intelligence  89  (1997)  173-217 

1.  Introduction 

We  seek  a  formal  bridge  between 

classical  planning 

and  real-world 
is  wide  and  deep.  Classical  planners 

hypothetical  worlds 

to  be  spanned 

in  micro-worlds, 

to  achieve  a  micro-world 

ment.  The  chasm 
with  behavior 
Classical  plans  are  often 
proven 
when  executed.  We  can  trust  that  the  micro-world 
if  the  planner’s 
only 
performance 
of  the  real  world.  This  is  seldom 
only  approximate 
may  conspire 

to  invalidate 

a  plan  in  the  real  world. 

goal  only  to  produce  an  unacceptable 

thwarted  by  the  real  world;  a  sequence  of  actions  may  be 
state 
behavior 
is  indicative  of  real-world 
perfectly  capture  all  relevant  details 
the  planner’s  domain 

representations 
the  case.  Often, 

representations 

real-world 

their  real-world  changes.  Combinations 

of  apparently 

innocuous 

flaws 

that  can  be  flawlessly 

goal  achieve- 
are  concerned 
formalized. 

One  cause  of  this  difficulty 

is  the  qualification 

problem 

[46],  which 

is  succinctly 

stated  by  Genesereth 

and  Nilsson 

[ 271: 

Most  universally 
qualifications 

quantified 

statements  will  have  to  include  an  infinite  number  of 

if  they  are  to  be  interpreted 

as  accurate  statements  about  the  world. 

Classical 

operator  definitions 
can,  therefore,  only  imperfectly 
initial  world  state  may  also  be  imperfect.  Thus, 
encounter 

are  universally 

situations 

capture  most  real-world  changes.  Representations 

quantified 

first  order  expressions 

and 
of  the 
that  a  planner  may 

it  is  inescapable 

in  which  its  conclusions  will  contradict 

the  real  world. 

ingredients:  milk, 

Permissive  planning 

is  a  learning  approach 

and  so  on.  There  are  many  possible 

the  simple  problem  of  making  breakfast 
includes  many  standard  cooking 

to  planning  under  uncertainty.  To  illustrate 
in  the  morning.  The  initial  state 
it,  consider 
flour,  eggs,  butter, 
of  our  kitchen 
of  hot  and  cold  cereal,  syrup,  a  selection  of  fresh  and  dried  fruit,  etc.  The 
containers 
include  pouring,  measuring,  mixing, 
goal  is  to  reduce  our  morning  hunger.  Operators 
heating, 
in  principle 
produce  for  us.  It  could  make  pancakes,  crepes,  Belgian  waffles,  hot  oatmeal,  cold  raisin 
bran,  sausage  and  eggs,  gravy  and  biscuits,  eggs  Benedict,  etc.  We  call  the  set  of  all 
solutions 
for  the 
problem. 
it  will  construct 
just  one.  This  designated 
of  the  planner 
from  the  competence 
of  planning, 
Suppose 

set  we  call  the  performance 
for  a  particular  performance 
set  the  planner’s  bias.  As  we  shall  see,  bias  is  an  inescapable 
is  at  the  heart  of  permissive  planning. 

element  of  the  competence 
for  the  problem.  We  call  the  preference 

that  could 
In  fact,  of  course, 

the  planner  will  not  generate  all  solutions; 

item  for  the  breakfast  problem 

that  the  planner’s  performance 

solutions  our  planner  could 

in  principle  be  produced 

set  of  the  planner 

and  its  adjustment 

item 
item 
facet 

the  cdmpetence 

is,  of  course,  entailed 

in  the  real  world  may  be  quite  unsatisfactory.  A  perfectly 
sauce  reducing 

in  lumpy  and  separated  hollandaise 
tasteless  mess.  The  problem 

eggs  Benedict.  Goal  achievement 
the  result 
plan  might  result 
dish  to  a  disgusting 
internal 
Perhaps  some  initial  state  representations 
represented 
incomplete, 
believed  or  the  beating  may  result 

or  the  butter 
or  based  upon 

representations 

are  not  sufficiently 

in  the  planner’s  micro-world, 

is  to  prepare 
but 
looking 
reasonable 
the  eggs  Benedict 
is  that  one  or  more  of  the  system’s 
to  succeed. 
for  the  plan 
than 
are  incorrect, 

eggs  are  warmer 

the  operators 

faithful 

to  reality 
are  subtly  wrong-the 

false  suppositions-the 

blender  may  not  beat  as  fast  as 
in  an  unmodeled  heating  of  the  mixture.  Most  likely 

is  too  low  a  grade,  or  perhaps 

G.E  DeJong,  S. WI Bennett/Art@cial  Intelligence  89  (1997)  173-217 

the  blame  cannot  be  laid  at  a  single  representation.  Usually  multiple  discrepancies, 
of  which  is  slight,  conspire 

the  failure. 

to  produce 

together 

175 

each 

Permissive 

planning,  when  confronted  with  an  unacceptable 

the  solutions 

planner  bias.  This  shifts 
different  eggs  Benedict 
prepared.  There  are  nearly  always  planning 
work;  few  problems  admit  to  only  a  single  solution. 
eggs  Benedict 

It  is  foolish 
ignoring  all  the  attractive  other  breakfast  options. 

to  different  performance 

recipe  might  be  attempted  or  perhaps  a  different  dish  entirely 
alternatives  within 

the  micro-world 

failure  rate,  adjusts 
the 
items.  For  breakfast  a 
is 
frame- 
foul 

to  persist  making 

Why  might  preserving 

the  micro-world  be  desirable?  The  system’s  operator  represen- 
the  expert  did  his 
of 

conceptualization 

idiosyncratic 

problem  assures  us  that  imperfections 

upon  one  is  to  be  expected  and  is  hardly  evidence 

tations  are  typically  provided  by  a  human  domain  expert.  Presumably, 
best  at  capturing  his  own  coherent  although  possibly 
world  change.  The  qualification 
Stumbling 
prove  upon  the  work  of  the  domain  expert.  Furthermore, 
knowledge  may  corrupt 
latent 
inconsistencies 
is  likely 
or  no  understanding 
planner’s 
the  domain 
A  major 

It  is  supplied  by  the  planner 
of  the  domain.  And  yet  each  bias  has  grave 

representations. 
issue  raised  by  permissive 

It  may  be  more  prudent 

in  particular  domains. 

to  be  quite  arbitrary. 

its  faithfulness 

implementor 

success 

to  the  expert’s  conceptualization 

of  a  far  worse  nature.  On  the  other  hand,  the  planner’s 

and  introduce 
intial  bias 
and  reflects  little 
for  the 
to  alter  the  bias  over 

implications 

are  unavoidable. 

that  the  system  can  im- 

tinkering  with  human-supplied 

planning 

of  the 
for 
at  once.  It  may  be  that  the  solutions  generated  with  the  old  bias  were 
failures.  Permissive 

the  bias  may  shift  the  performance 

the  plans  now  produced 

element  produced 

is  a  characteristic 

to  real-world 

is  that  bias 

lead 

some  guarantee 

of  global  acceptable 

behavior.  Much  of  our 

planner  as  a  whole.  Altering 
many  problems 
quite  acceptable 
planning  must  provide 
research  concerns 

this  point. 

but 

fall  into 

includes  Bayesian 

reasoning 
theoretic  approaches 

Let  us  briefly  examine  how  permissive  planning 
certainty.  These 
three  general  categories. 
provided  with  some  explicit  account  of  uncertainty 
general  approach 
fuzzy  logic  [ 871,  and  decision 
in  this  general  area  are  given  representations 
than  required  by  conventional 
characterization 
takes  such  variabilities 
can  view  each  representation 
each  representation 
is  less  likely 
cost  in  reasoning  with  augmented 

of  possible  discrepancies 

to  other  approaches 

relates 
In  the  first,  reasoning 
and  how  it  is  propagated 
[ 15,661,  planning  with  error  balls 

to  un- 
systems  are 
[ 181.  This 
[ 251, 
[ 19,30,3  1,741.  Systems 
of  the  world  that  are  more  sophisticated 
some 
to  be  encountered.  The  planner 
in  the  world.  We 
large  disjunction  of  facts.  Thus, 
there  is 

in  the  real  world.  Importantly, 

to  be  violated 
representations  which  can  be  quite  high 

in  deciding  how  best  to  behave 

classical  planning.  These 

that  are  likely 

representations 

as  specifying 

into  account 

a  potentially 

to  planning 

include 

is  employed 

In  the  second  approach,  machine 
sentations.  As  in  classical  planning, 
simple  and  precise  but  possibly 
through 
information 
into  line  with  the  observed  world  behavior.  This  can  be  seen  as  an  induction  problem: 
The  hypothesis 
the  initial  domain 

repre- 
learning 
are 
the  system’s  action  and  object  representations 
incorrect.  As  the  system  interacts  with  the  world,  it  gains 
it 

alterations  of 
real-world  behaviors.  The  task  is 

theory.  Examples  are  the  observed 

space  consists  of  some  (usually 

its  observations.  The  domain 

theory  is  suitably  modified 

large)  set  of  well-formed 

to  bring 

[ 731. 
to  refine  the  offending 

176 

G.E  DeJong, S. W  Bennett/Artijicial  Intelligence 89 (1997) 173-217 

the  hypothesis 
to  locate 
finement  and  discovery 
and  refinement 
with  theories  of  action 

(e.g. 

that  best  fits  the  examples.  This  may  involve  general 
(e.g. 
[ 28,35,83] 

theory  re- 
learning 
).  The  reasearch  connecting  belief  revision  and  update 

)  or,  more  conservatively, 

[ 61,64,65,70] 

operator 

[ 11,23,40] 

is  also  relevant. 

the  sequence  of  the  planner-specified 

[ 1,12,49,60,76].  While  conventional 

The  third  approach  relies  on  reactivity 

plan  ex- 
operators,  a  reactive  system 
to  include  some  degree  of  world  monitoring 
is  reduced  or  eliminated; 
at  planning 

ecution  blindly  applies 
achieves 
robustness  by  extending  execution 
and  decision  making.  Reliance  on  action  projection 
as  anticipated 
to  behave  precisely 
is  not  assumed 
little  resemblance 
what-if  decisions 
perhaps  better 
from  the  interactions 
tial,  machine 
construction 

the  world 
time.  The  “plan”  bears 
it  is  composed  of  a  large  number  of 
It  is 
emerges 
for  acting  rather  than  a  plan.  Goal  achievement 
of  this  policy  with  the  dynamics  of  the  world.  While  not  essen- 
can  be  incorporated 

that  specify  actions  for  the  world  states  likely 

for  the  purpose  of  automating 

to  a  classical  plan.  Typically, 

learning 
[ 7,16,29,36,54,80]. 
Each  of  these  three  general  approaches 

suggests  a  different  class  of  solutions 

to  the 

to  be  encountered. 

termed  a  policy 

plan/policy 

learning 

Solutions 

concludes 

are  enhanced 

to  these  uncertainties. 

In  the  first  one,  representations 

to  encode  uncertainty 
(perhaps  even  minimally 

the  lumpy  sauce  or  perhaps 
the  “whip” 
that 

are  produced  which  are  less  sensitive 
For  eggs  Benedict 

breakfast  problem. 
information. 
the  system  might  have  selected  a 
sensitive) 
less  exacting  but  less  tasty  initial  hollandaise 
sauce  recipe  from  the  Anyone  can  Cook 
cookbook.  Or  perhaps  it  would  make  a  fool-proof  breakfast  of  cold  cereal  with  milk.  The 
second  approach  employs  machine 
the  faulty  world  knowledge.  By 
examining 
the  system 
than  previously 
insufficiently 
with  observed 
eggs  Benedict.  Third, 
is  chosen 
next  action 
the  melted  butter 
to  add  oil  or  to  heat  the  mixture  or  to  go  next  door  to  borrow 
super  blender.  Crucially, 
it  attempts 

eggs  Benedict  experiences, 
slower 
is 
into  line 
it  may  be  able  to  produce  a  more  satisfactory 
the  world  after  each  operator  execution.  The 
the  observed  world  closer  to  a  goal  state.  After  pouring 
in  the  sauce.  It  may  decide 
the  neighbor’s  BlenzAll 
the  system  does  not  anticipate  and  plan  around  failures.  Rather 

homogenized. 
reality.  With  the  refinement 
reactivity  monitors 
to  bring 

to  revise 
through  additional 
speed  of  this  blender 

In  any  case,  its  internal  projection  ability  is  brought 

to  recover  from  them  as  they  are  detected. 

the  system  observes  undesirable 

that  the  brand  of  butter  used 

believed.  Or  perhaps 

is  significantly 

it  determines 

lumps 

Permissive 

planning 

no  information 

in  that  the  representations 
encoding 
domain  knowledge-the 
it  is  unlike 
Finally, 
plays  an  important 
decisions. 

Permissive  planning 

about  expected  uncertainty.  Unlike 

is  cast  from  a  somewhat  different  mold. 

the  first 
of  world  objects  and  actions  are  crisp,  simple,  and  precise 
the 
never  altered. 
the  notion  of  a  classical  plan.  Projection 
action 
and  there  are  no  execution-time 

system’s  represented  beliefs  about  the  world-are 

the  third  in  that  it  preserves 
role  in  permissive  planning 

the  second  approach, 

It  is  unlike 

treatment  of  uncertainty  will  most 
But  permissive  planning 

is  a  promising 

and  as  yet  little  explored  direction. 

is  not  the  final  word  in  planning  under  uncertainty.  The  ultimate 
aspects  of  all  of  these  approaches. 

likely  combine 

The  permissive 

approach  can  be  briefly  summarized 

characterized 

as  having  parameters 

that  influence 

as  follows:  A  planner  can  be 
its  search  for  a  solution.  Each  combi- 

G.E  DeJong,  S.W  Bennett/Artificial 

Intelligence  89  (1997)  173-217 

177 

Goa1 

-----b 

Initial  State 

I 

-& 

Plan 

Domain  Theory 

Fig.  1. Classical  planning. 

for  these  parameters 

nation  of  settings 
The  collection  of  all  biases  forms  the  planner’s  bias  space.  Machine 
to  search 
the  kinds  of  problems 
because 
edge. 

that  yields  acceptable  planner  performance 

for 
is  so  named 
to  be  permissive  of  less  than  perfect  domain  knowl- 

finds  itself  solving.  Permissive  planning 

causes  some  bias  to  be  exhibited  by  the  planner. 
is  employed 

this  space  for  a  bias  element 

the  planner 

the  planner 

is  adjusted 

learning 

Many 

tradeoffs  and  alternatives 

ideal  permissive  planning, 

and  prove 

fine 
versions, 
embodying 
Finally  we  illustrate 
ner. 

a  particular 

are  possible  within 

that  it  cannot  be  computed.  We  then 
set  of  restrictions  which  yields 

this  general  approach.  We  de- 
one  of  the  least  restrictive  and  most  naively  appealing 
investigate  one  alternative 
tractable  permissive  planning. 
plan- 

approach  applied 

to  a  real-world 

the  permissive 

planning 

2.  A  model  of  classical  planning 

In  Sections  5  and  7  we  build  upon  a  particular  characterization 

For  our  purposes,  a  classical  planner 

that 

an  initial 
(b)  outputs  a  set  of  constraints  with  the  property 

inputs  operator  definitions, 

(a) 

defined  by  the  operators.  See  Fig.  1.  Note 

set  achieves 

that  characterization. 

algorithm 
and, 

Here  we  present 
recursive 
description 
of  ground  operators  consistent  with  the  constraint 
state 
requirement 
internal  quantification, 
is  deterministic 

that  the  operators  be  STRIPS-like 

in  the  micro-world 

[67,85] 
etc.  (see 
but  is  only  approximated 
(be 
through  a  tree  of  constraint 

linear,  nonlinear, 

).  We  assume 
by  the  micro-world. 

they 

[ 591.  They  may  have  conditional 

that  the  real-world 

of  classical  planning. 
is  a  partially 
state,  and  a  goal 
that  any  sequence 
the  goal  from  the  initial 
is  no 
that  there 
effect, 
counterpart 

All  classical  planners 
a  search 

the  search 

in  which 
a  constraint 

as  conducting 
conventional 
one 
861.  We  interpret 
temporally  ordered  set  of  ground  operators) 
set.  A  constraint 
planning 
the  collection 
one  or  more  action  sequences 
tree  of  constraint 

set  itself  is  inconsistent 

sets  (see  Fig.  2). 

set  as  denoting 

hierarchical, 

sets.  This  view 

is  through  a  space  of  plans 

etc.)  can  be  viewed 
to  the 
is  close 
[ 14,38,47,5  1,68, 
(each  a 
that  are  consistent  with  the  constraints  of  the 
iff  it  denotes  no  action  sequence.  Each  abstract 
to 

the  set  of  all  action  sequences 

adds  a  nontrivial 

constraint 

step  (each  significant  decision  of  the  planner) 

to  generate  a  novel  set  of  constraints.  Each  nontrivial  constraint  eliminates 

that  were  consistent  with  the  parent  set.  This  defines  a 

While  classical  planning 
that  every  classical  planning 

can  be  abstractly  characterized 

algorithm  must  be  overtly  implemented 

in  this  way,  we  do  not  mean 
as  a  search  through 

178 

G.E  Dehng,  S. W  Bennett/Artificial 

Intelligence  89  (1997)  173-217 

NO: (] 

/\\ 

No Constraints  - denotes  all 
possible  action  sequences 

All acceptable 
l l l  first constraints 

All acceptable 
second  constraints 

. 

. . 

All acceptable 
third  constraints 

\ 

(c3,c31,c312...) 

(failure) 

(cl,c13,c132...) 

N2: 
(c2,~21,~215,~2153...) 
(success) 

.,:/ 

\ 

\ 

lw/yll) 

N4: 
(cl,c12,c128...] 
(success) 

(c2,c21,c215,c2153  ,... c21538.v) 

(success) 

/\ 

Fig.  2.  The  constraint 

tree  for  a  planning  problem. 

a  constraint 
the  behavior  of  any  classical  planner  can  be  accurately  captured  as  such  a  search. 

space,  or  even  that  the  constraints  need  be  explicitly 

represented.  However, 

In  this  view,  the  only  difference  between  planners 
and  their  method  of  exploring  a planning  problem’s 
which  node  of  the  tree  to  expand  next).  Although  such  difference 
planners, 
statements 

lies  in  their  vocabulary  of  constraints 
(selecting 
tree  of  possible  constraints 
results  in  quite  different 
that  our 

In  doing  so,  we  are  assured 

to  all  classical  planners. 

to  ignore  such  details. 

are  general-applying 

it  will  be  useful 

of  constraints 

Once  a  vocabulary 

is  adopted,  a  constraint 

tree  such  as  that  in  Fig.  2 
can  be  associated  with  each  planning  problem.  The  root  node  (e.g.,  NO)  is  the  empty  set 
it  denotes  all  sequences  of  actions.  The  descendants  of  each  node  are  the 
of  constraints; 
consistent 
to 
the  parent’s  constraint 
than  does  its  parent.  A  leaf  node  is  one  to  which  no  consistent  nontrivial 
be  added. 

set.  Thus,  each  child  node  denotes  strictly  fewer  action  sequences 
constraint  can 

sets  that  can  be  formed  by  adding  a  single  nontrivial 

constraint 

constraint 

A  node  is  a  “success”  node  if  the  projection  of  the  initial  state  through  each  and  every 
action  sequence  denoted  by  its  constraint 
in  a  goal  state.  In  other  words,  the 
goal  must  be  entailed  by  the  initial  state,  the  system’s  world  knowledge,  and  the  node’s 
that  are  formed 
constraints.  N2  is  a  success  node.  Success  nodes  may  have  descendants 
in  the  same  manner  as  other  children  nodes.  Every  descendent  of  a  success  node  (e.g., 
N3) 
the  child  node’s  additional 
constraint 

and  all  the  action  sequences  denoted  by 

can  only  remove  action  sequences, 

is  also  a  success  node.  This 

is  necessarily 

set  results 

the  case: 

GE  DeJong,  S.W  Bennett/Artificial  Intelligence 

89  (1997)  173-217 

179 

solve 

the  planning 

if  it  has 
the  parent  already 
no  success  descendants.  An  example  of  a  failure  node 
is  Nl.  Of  course,  many  nodes, 
including  NO,  are  neither  success  nor  failure  nodes.  We  call  the  set  of  all  success  nodes 
the  competence 

is  a  “failure”  node 

problem.  A  node 

set  for  the  planning  problem. 
Some  planners  may  appear  not  to  fit  this  characterization. 

the  boundaries 

of  the  constraint 

as  extending 
and  inconsistency 
constraints, 

beyond 
computation 
redundancy 
add  redundant 
it  may  happily  accrete  additional 
inconsistent 
be  viewed  as  implementation 
point  of  view,  all  of  the  planner’s  behavior 
to  a  constraint 

the  inconsistency 

until 

Some  apparently 

the  search  tree:  It  can  be  computationally 

tree.  However,  we  need  not 

search 
such 
to  determine 
of  constraints.  An  implemented  planner  may  unknowingly 
that  they  have  no  effect.  Similarly, 
to  be  already 
two  behaviors  can 

to  a  constraint 
is  more  readily  apparent.  These 

simply  not  appreciating 
constraints 

set  unknown 

interpret 

difficult 

details  outside  our  formal  treatment.  From  a  computational 
its  plan  is  confined 

to  constructing 

relevant 

search  tree  such  as  that  shown  in  Fig.  2. 

3.  Real-world  planning  and  real-world  adequacy 

Can  we  capture 

some  notion  of  real-world 

planning 

adequacy  within 

this  general 
for  a 

it  means 

framework?  To  do  so  we  must 

planning 
planner 
if  its  user  is  satisfied  with  the  real-world  performance. 

to  be  “adequate”. 

first  define  precisely  what 

Informally,  we  might  say  that  a  planning 

system 

is  adequate 

informal  definition 

point  becomes  clear: 

sheds  no  light  on  how  to  attain  planner 

This 
important 
internal  workings.  Adequacy 
A  user  who  cares  about  stacking  blocks  in  a  simulated 
planner  completely 
rail  freight  deliveries  might  find  the  same  planner  quite  inadequate. 

adequacy  but  an 
than 
its 
its  user. 
robot  world  might  find  a particular 
adequate.  On  the  other  hand,  someone  who  schedules  nation-wide 

the  adequacy  of  a  planner  depends  on  more 
that  concern 

is  measured  against 

those  problems 

Intuitively  we  also  prefer  that  a  planner  appreciate 

the  point  of  view  of  a  user  is  that  when  given  a  problem, 

its  own  limitations.  The  best  state 
the  planner 

of  affairs  from 
produces  a  solution 
solution 
is  somewhere 
of  course,  neither 

that  actually 

that  works  when  executed.  The  worst  is  that  the  planner  produces  a 
fails  in  the  world.  The  planner  deciding  not  to  attempt  the  problem 
its  output  although, 

for  then  the  planner  does  not  misrepresent 

in  between, 

is  the  problem  solved. 

We  want  a  notion  of  planner  adequacy  consistent  with  the  informal  notions  above. 
to  solve  a  planning  problem. 
sequence  of  actions 
that 
that  gave  rise  to  it.  Of 
a 
in  general,  designate 
to  say 
action 

We  begin  with  two  different  definitions  of  what  it  means 
For  the  moment  we  assume 
the  planning 
course,  minimal 
single  ground 
about 
sequence. 

that  a  plan  denotes  a  particular 
problem 
the  planning 

We  will  have  more 
is  an  individuated 

section.  For  the  moment  a  plan 

system  claims  will  solve 

[ 14,39,45,68,75,81,86]. 

this  in  the  conclusion 

planners  do  not, 

and  nonlinear 

commitment 

sequence 

action 

A  plan  produced  by  a  planning 

system  ISolves 

(solves  according 

model  of  the  world)  a  planning  problem 
satisfies 

the  problem’s 

goal.  We  say  that  the  plan  ESolves 

(solves  according 

if  the  initial  state  projected 

to  its  own  internal 
the  plan 
to  the 

through 

180 

G.E  Dehng,  S. W  Bennett/Arf$cinl 

Intelligence  89  (1997)  173-217 

a  planning 

external  world) 
the  plan  in  the  problem’s 
say  a planning 
by  the  system  ISolves 

system ISolves 

problem 

if  the  real-world 

initial  state  satisfies 

state  that  results 

from  executing 
the  problem’s  goal.  As  shorthand  we  will 
item  produced 

if  the  performance 

(or  ESolves)  a  problem 
the  problem. 

(or  ESolves) 

We  assume 

the  following  operating  protocol:  A  planning 

system  is  called  upon  to  solve 

is  unlimited-there 

that  the  problems 

available  on  which 

are  drawn  according 

a  succession  of  problems  given  to  it  one  at  a  time.  This  succession 
is  always  another  problem 
we  assume 
over  a  universe  of  well-formed 
expended  on  deliberation, 
to  the  planning 
problem 
outputting 
the  subterfuge  of  forcing  an  output  of  n  after  a  resource  bound 
world  systems  cannot  deliberate 

the  special  symbol  JI).  Planning 

the  real-world  planning 

in  this  framework 

(by  outputting 

forever. 

are 
system  must  either  offer  a  solution 
(by 
is  decidable  but  only  by 
in  the  real 

is  reached; 

to  test  the  planner’s  behavior.  Further, 
to  a  fixed  but  unknown  distribution 

problems.  After  some  fixed  amount  of  resources 

a  plan)  or  choose  not  to  offer  a  solution 

We  can  now  more  precisely  define  the  adequacy  of  a  planning 

system: 

Definition  1.  The  adequacy  of  a  planning 
randomly 

sampled  according 

to  a  distribution  D  is: 

system  P  over  a  universe  of  problems  U 

. a, 

if  P  ISolves 

i  and  P  ESolves 

i, 

./3, 

if  P  does  not  ISolve 

i, 

(1) 

AuDCP) 

= 

iEU 

xPro(i) 

I c Pro(i) 

I c b(i) 

iEU 

iEU 

where  a,  p,  and  y  are  constants 
of  occurrence  of  problem 

i  according 

to  distribution  D. 

y, 

if  P  ISolves 

i  but  does  not  ESolve 

i, 

satisfying  y  6  p  6  0  <  CY and  Pro(i) 

is  the  probability 

(via 

above  others 

it  is  sensitive 

to  the  pre-theoretic 

for  some  problems 

the 
to  distinguish  between  a  plan  failing  and  the 
notions 
to  a  planner’s 
in  the  real  world  accrues  a  posi- 
a 
that  does 

for  not  producing 

in  the  universe  of  problems 
that  works 
a  plan 
(p),  which  may  be  zero,  is  assessed 

contributes 

This  definition 

reflects  a  user’s  concern 

expressive 

above.  Each  problem 
as  follows:  Producing 

distribution) 
and  is  sufficiently 
planner  choosing  not  to  offer  a  plan.  Thus, 
discussed 
adequacy 
tive  reward 
( CX). A  penalty 
plan.  A  possibly  more  severe  penalty 
is  assessed 
not  work  in  the  real  world.  Each  problem  contribution 
that  the  problem  will  be  encountered 
equal,  adequacy 
producing 
all.  Without 
equal 
tions  of  adequacy  are  also  possible  but  this  one  is  simple, 
our  purposes. 

to  1.  But  this  somewhat  obscures 

a  bad  plan  cannot  be  better 

loss  of  generality 

(and  may  be  worse) 

(y) 

for  producing 
is  weighted  by  the  probability 
to  the  distribution.  Other  things  being 
is  higher  if  offered  plans  actually  work  in  the  real  world.  Furthermore, 

according 

a  plan 

the  definition  could  be  simplified  by  setting  cx identically 
in  the  analysis.  Other  formaliza- 

its  influence 

intuitive,  and  sufficient 

for 

than  producing  no  plan  at 

G.R  DeJong,  SW.  Bennett/Artijicinl  Intelligence  89  (I 997)  173-217 

181 

4.  Properties  of  planner  adequacy 

There  are  several 

interesting 

properties 

that  follow  from 

the  definition  of  adequacy 

given  above. 

(1)  The  adequacy  of  any  planning 

system 

is  finite.  In  fact,  it  is  bounded  above  by  (Y 

and  below  by  y. 
(2)  No  classical  planner 

adequacy 

rating. 

in  the  traditional  AI  sense  can  be  assigned  a  meaningful 

(3)  Some 

form  of  machine 

learning 

is  required 

to  insure  adequacy 

for  a  domain- 

independent 

planner. 

The  first  property 

from  the  convention 
follows  directly 
verse  sum  to  1.  If  all  problems  ever  asked  of  the  planning 
will  have  an  adequacy  of  (Y. If  they  are  all  solved  incorrectly, 
be  y.  This  makes  direct  comparisons 
operating 

over  a  uni- 
it 
rating  will 
between  planners  possible,  even  if  the  planners  are 

that  probabilities 
system  are  correctly  solved 

in  different  domains  and  for  different  users. 

the  adequacy 

is  only  one  factor 

in  the  adequacy 

of  the  problem  distribution, 

is  philosophically  more  interesting. 
real-world  performance. 

ignored 

In  domain-independent 

It  hints  at  how  AI  planning 
planning, 
assessment.  Properties  of  the  domain, 
from  the  user  all  contribute 
(2) 
is  quite  intuitive: 
adequacy  only  when 
the  real  world  so  that  ESolve  and  ISolve  become 

and  preferences 

adequacy  evaluation.  With  this  in  mind,  property 
reasonable 

can  guarantee 

planning 

theory  perfectly  captures 

The  second  property 

has  so  successfully 
a  planner 
characteristics 
to  a  meaningful 
classical  domain-independent 
the  domain 
the  same  relationship. 
The  third  property 

is  related  to  the  second  and  stems  from  the  qualification  problem.  A 

characterize 

their  corresponding 

(rather  than  machine 

is,  among  other  things,  a  characterization 

adequacy 
planner’s 
operator 
representations 
using  prior  knowledge 
world  behavior.  Only  a  set  of  operator 
the  real  world  would  be  sufficient 
planning.  The  qualification  problem  assures  us  that,  in  general, 
knowledge  of  operator  deficiencies  with  respect 
a  priori.  A  characterization 
observations 
of  instances 
observed 

learning) 
representations 
to  support  guaranteed 

of  real-world 
is  one  definition  of  machine 

instances 

learning 

[48,53]. 

to  the  real  world  cannot, 
of  a  planner’s  adequacy  must  be  a  posteriori, 

this  is  not  possible.  Thus, 
in  general,  be 
formed  from 

plan  executions.  Automatically 

characterizing 

of  how  well  the  planner’s 
real-world  behaviors.  Consider 
to  characterize 
real- 
that  include  no  discrepancy  with 
adequate  domain-independent 

the  operators’ 

5.  Bias  and  bias  accommodation 

Any  reasonable 

the  characteristics 

this  be  the  case?  Consider 

embodies  a  strong  planning 

classical  planner  necessarily 

should 
tion  it  must  avoid  expressing  any  preference 
and  across  all  domains.  There  are  only 
the  lack  of  bias  must  hold  for  all  problems 
two  unbiased  behaviors  possible.  The  first  is  to  return  all  elements  of  the  competence 
set  at  the  same 
lution  exists.  It  is  clear 

regardless  of  whether  a  so- 
that  both  options  are  in  most  cases  not  reasonable.  Resources 

bias.  Why 
of  an  unbiased  planner.  By  defini- 
for  one  solution  over  another.  Furthermore, 

is  to  return  n  (failure) 

time.  The  second 

182 

G.F:  DeJong,  S. W  Bennett/ArtQicial  Intelligence  89  (1997)  173-217 

Search  tree  for 

Universe  of 
Planning  Problems 

I 
Problem  R 
\ 

Search  tree  for 

Fig.  3.  The  effect  of  altering  a  planner’s  bias. 

should  not  be  wasted 
ner  capriciously 
grasp. 

finding 

solutions 

fail  to  solve  problems  when  at  least  one  solution 

that  will  not  be  executed.  Nor  should  a  plan- 
its 

is  easily  within 

Possessing 

a  bias  is  not  a  disadvantage.  Quite 
that  minimizes  planning 

to  the  contrary:  by  its  judicious 
time,  minimizes 

use, 

one  may  prefer  a  solution 
during  execution, 
successful 
classical  planning 

execution.  However, 
even  without 

or  in  the  case  of  permissive 

planning, 

it  should  be  clear  that  bias 
taking  real-world  adequacy 

into  account. 

resources  consumed 
the  likelihood 

improves 
is  an  unavoidable 

of 
facet  of 

function 

is  illustrated 

of  one  preference 

Consider 

the  effect  of  altering 

trees.  We  defer  until  later  a  mechanistic 

the  bias  of  a  planner.  We  will  view  bias  change 
in  the  search  across 
for  another 
account  of  how  such  an 
in  Fig.  3.  Each 

abstractly  as  the  substitution 
all  problems’  constraint 
alteration  may  be  realized.  The  effect  of  such  a  substitution 
in  the  space  labeled  “Universe  of  Planning  Problems” 
element 
problem 
that  might  be  given  to  a  classical  planner.  For  each  problem, 
its  original  bias,  conducts  some  search  through  the  problem’s  constraint 
search  path  is  represented 
as  a  light  line 
tree.  Using 
constraint 
quite  different.  Some 
(like 
may  change  as  well.  Since  classical  planners  are  sound  but  not  necessarily 
problem 
another. 

the  planner,  with 
tree.  The  original 
the  problem’s 
(like  the  one  for  problem  P)  will  be 
that  of  problem  R)  may  be  only  partially  changed.  Others 
the  tree  for  problem  Q)  may  remain  unchanged.  The  solvability  of  the  problem 

complete,  a 
function  may  be  unsolvable  under 

the  new  bias,  most  searches 
(like 

solved  by  one  preference 

represents  a  well-formed 

that  is  successfully 

in  the  triangle 

that  represents 

The  important  point  for  us  is  that  by  changing 

the  planner’s 
the  preference 
the  planner’s  bias  we  may  exert  some  control  over  which 
is  found.  This  shift  can  be  quite  dramatic.  The  change  of  a  single  search  choice 

bias  is  altered.  By  altering 
solution 
can  lead  to  a  previously  untouched  portion  of  the  constraint 
Now  consider  a  space  of  possible  biases.  The  notion, 

is  well  formed: 
the  behavior  of  each  planner  can  be  described  as  the  application  of  a particular  preference 

tree. 
though  abstract, 

function, 

G.E  DeJong.  S.W. Bennett/Artijicial Intelligence  89  (1997)  173-217 

183 

to  a  constraint 

function 
planners.  A  set  of  such  preference 
planner. 

tree.  Alternative  preference 

functions 

functions 

result  in  different  classical 
forms  a  space  of  potential  biases  for  the 

Given  a  bias  space,  a  planner,  and  some  utility  function  defined  over  the  universe  of 
that  some  planners  will 
the  bias 
search 
is  optimal,  or  nearly  optimal,  or  at 

possible  problems, 
be  of  higher  utility 
space  we  might  hope  to  find  a  planner  whose  utility 
least  higher 

(indeed  quite  likely) 
it  is  entirely  possible 
than  others.  By  some  form  of  systematic 

than  the  utility  of  the  original  planner. 

through 

We  call  such  a  search  “accommodation” 
search  changes  none  of  the  human-supplied 
constraint  vocabulary, 
planning  is  bias  accommodation 
utility. 

supplied  by  the  planner’s 

bias.  Note 

that  such  a 
of  the  planner’s 
information.  The  original  operator  set  and 
are  not  altered.  Permissive 
adequacy  as  the  measure  of 

implementor, 

using  real-world  planning 

Its  internal 

the  planning 

representations 

Importantly, 
of  its  actions. 
is  not  altered.  Rather  permissive  planning 
whose  real-world  behavior 
iors.  Execution 
around. 

remain  as  they  were,  and  its  projection 

system  does  not  become  better  at  anticipating 

the  effects 
ability 
in  the  generation  of  action  sequences 
tends  to  more  closely  follow  the  sequences’  projected  behav- 
into  line  with  projected  effects  rather  than  the  other  way 

effects  come 

results 

6.  Ideal  permissive  planning 

There  are  many  different  ways 
permissive  planning.  Unfortunately, 
planning 
is  computationally 
unrestricted.  There  are  no  known  a  priori  constraints 
make  up  the  space  and  the  bias  space  may  be  infinite: 

to  instantiate 

the  straightforward, 

untenable. 

the  above  abstract  characterization 

of 

ideal  realization  of  permissive 

In  ideal  permissive  planning 

the  bias  space 

upon 

the  individual 

biases 

is 
that 

Definition  2.  Ideal  permissive  planning  is  a  recursive  procedure, 

that  given: 

0  a  planner, 
l a  bias  space, 
l  adequacy  values  CY, /3,  y, 
l a  threshold  of  required  adequacy,  T,,  between  CY and  p, 
l a  source  of  planning  problems, 

produces  a  new  planner 

l  if  the  bias  space  contains 

adequacy 

is  adopted, 

through  bias  accommodation 

that  has  the  following  properties: 
any  bias  of  adequacy  2  T,,  the  bias  with  the  highest 

l if  the  space  contains  no  bias  of  adequacy  2  T,,  the  new  planner 

refuses 

to  offer 

solutions 

to  any  further  problem. 

of  the  procedure 

The  recursiveness 

that  the  algorithm  always  halt.  Therefore, 
only  a  finite  number  of  example  problems  can  be  examined  before  either  selecting  a  bias 
or  guaranteeing 
with  permissive  planning: 

that  no  adequate  bias  exists.  Under 

are  incompatible 

these  conditions 

requires 

184 

G.E  DeJong,  S. W  Bennett/Art@cial  Intelligence  89  (1997)  173-217 

Theorem  3. 

Ideal  permissive  planning  cannot  be  realized. 

from  a  lemma 

ideal  permissive  planning, 

theorem 

simpli’ed 

follows  directly 

This 
concerns 
formulation. 
biases.  After  attempting 
the  two  biases  must  be  selected.  Problems 
counted  as  failures 

In  simplified 

(y  =  /3). 

ideal  permissive  planning, 
to  solve  a  finite  number  of  example  problems, 

a  greatly 

turn.  The 

to  which  we  now 

lemma 
restricted  version  of  the  ideal 
the  bias  space  contains  exactly  two 
the  better  of 
for  which  the  planner  offers  no  solution,  are 

Lemma  4.  The  simplijed 

formulation  of  ideal  permissive  planning  cannot  be  realized. 

The  proofs  are  given 

somewhat  unenlightening. 

are  themselves 
useful 
to  develop  an  intuition 
easily  appreciate  how  the  upcoming 
A  successful  permissive  planning 

in  the  appendix.  The  proofs  of  these  results, 

like  many  proofs, 
it  is 
results 
for  why  in  particular  Lemma  4  holds.  We  can  then  more 

Before  proceeding 

to  the  positive 

theorems  avoid  the  computational 
algorithm 

for  the  simplified 

pitfalls. 

or  a  failure 

is  then  executed 

by  the  planner  under 

(if  no  solution  was  proposed,  or  if  executing 
the  goal). 

formulation  must  begin 
a  first  sample  problem  using  one  of  the  two  possible  biases.  The  solu- 
by  solving 
the  sampled  bias 
in  the  real 
tion  constructed 
the  case  that  the  goal  was  actually 
(in 
world.  The  outcome  will  either  be  a  success 
in  the 
achieved) 
that  one  bias  was  always 
world  does  not  achieve 
then  one  sample  problem, 
regard- 
successful 
the  better  bias  once  and  for  all: 
less  of  its  outcome,  would  be  sufficient 
select 
if  it  is  unsuccessful, 
if  the  sample  plan 
(a) 
the  alternate  bias  and  quit.  But  such  knowledge 
the  bias 
above.  Even 
need  only  do  better,  on  average, 
than  the  alternative  bias.  This  decision  can  be  made 
to  be  arbitrarily  difficult  and  thus  no  algorithm  can  in  general  guarantee  a  final  correct 
decision. 

the  better  bias  may  often  yield  a  failing  plan.  To  be  optimal, 

the  other  was  always  unsuccessful, 

If  only  we  could  know 

the  bias  and  quit; 

under  condition 

is  disallowed 

is  successful, 

to  choose 

the  plan 

select 

and 

to  a 
successes  and 
is  entirely  due  to  the  sequence  of  world  problems.  Since  these  are,  by  hypothesis, 

of  the  success/failure 
the  sequence  of  experienced 

sequence  due 

is  binomial 

What  can  we  say  about 

(though,  of  course,  according 

the  description 
particular  bias?  With  the  bias  held  constant, 
failures 
drawn  randomly 
outcome  of  sampling 
outcome  distribution 
of  two  possible  outcomes: 
are  said  to  be  Bernoulli.  A  Bernoulli  variable 
if  the  likelihood  of  one  outcome 
(failure) 
of  the  other 
first  bias  and 
let  its  probability 
and  p2  for  the  second  bias.  The  parameters 
reflect 
of  the  first  bias 
is  &a 
adequacy 

fixed  distribution 

the  underlying 

real-world 

PI  3  p2. 

a  particular  bias  can  be  viewed  as  a  random  variable.  Since 

to  some  unknown 

fixed  distribution), 

the 
the 
(each  observation  of  the  bias’s  performance  yields  one 
the  bias  variables 
is  characterized  by  a  single  probability: 
is  p  (with  0  <  p  <  1)  then  the  likelihood 

success  or  real-world 

(success) 

failure) 

is  1 -  p.  Let  BI  be  the  random  variable  associated  with 

the 
of  a  successful  outcome  be  ~1.  Similarly  define  B2 
p1  and  p2  are  unknown  but  fixed; 
they 
over  the  universe  of  problems.  The  adequacy 
the  second  bias’s 
the  first  bias  is  an  optimal  bias  iff 

is  plcv  +  (1  -  p~)y  or  p1  ( LY -  y)  +  y.  Similarly 

-  y)  +  y.  Thus,  and  intuitively, 

for  a  decision 
the  expected  payoff 

G.F: DeJong,  S. WI Bennetf/Ar@ciul  helligence  89 (I 997) 173-217 

185 

arms 

(neither 

by  analogy 

two  Bernoulli 

the  arm  randomly 

[9]  can  be  conceptualized 

time,  finite  horizon,  minimax 

to  play  N  trials  (hence  discrete 

this  as  a  bandit  problem.  The  discrete 

We  now  view 
to  a 
bandit  problem  with 
gambling  machine.  Suppose  we  are  required 
time  with 
a  finite  horizon  of  N).  At  each  trial  we  must  pull  one  or  the  other  arm  of  the  two-arm 
succeeds  yielding  a  fixed  reward,  or  fails 
bandit.  After  being  pulled 
yielding  no  reward 
the  amount  of  the  reward  nor  the  possible  existence  of  a 
the  arms  are  Bernoulli 
fixed  penalty 
for  pulling 
additional 
variables.  The  probability 
trials. 
knowledge 
for  selecting  Arm1  or  Arm2  at 
We  wish  to  discover  a  strategy 
step  i  possibly  making  use  of  the  results  of  steps  1  through 
i  -  1)  that  maximizes  our 
expected  wealth  at  the  end  of  the  N  trials  regardless  of  the  payoff  probabilities.  Clearly, 
of 
this  is  a  problem  of  incomplete 
both  arms,  then  the  solution, 
arm. 

the  arm  affects 
of  payoff  of  each  arm,  though  fixed,  is  unknown; 

for  any  N,  is  simply  always  to  pull  the  higher  probability 

for  if  we  knew  the  payoff  probabilities 

of  each  arm’s  characteristics 

(a  decision  procedure 

the  analysis).  Thus, 

to  the  observations 

knowledge, 

is  limited 

of  prior 

The  regret 

function 

strategy  applied 

to  a  bandit 

is  the  accumulated 

comtunt 
the  regret  function 
fi 

(the  average  over  repeatedly 

following  of  the 

strategy,  so  the  regret  function  must  clearly  be  nonnegative 

If  some  realizable 

difference  between 
strategy  up  to  N)  and  the  omniscient 
arm  N  times).  By  definition, 
optimal 
strategies. 
finite  number  of  trials  m  (less 
be  flat  from  the  mth  through 
function  would  accumulate 
successful  permissive  planning 
of  the  two  biases  after  observing 
bandit  strategy,  a  permissive  planning 

than  N) 

strategy  could  always  discover 

the  Nth  trial.  Indeed 

no  further  deficit  compared 

no  strategy  can,  on  average,  win  against 

optimal  payoff 

then  we  would  expect 

(playing 

the  higher  probability 
the  omniscient 
for  all  realizable 
the  better  arm  after  some 
to 
the  regret  function 
for  any  N’  larger  than  N,  the  regret 
strategy.  A 
the  better 
as  a 
that  is 
is  that 
strategy  cannot  be  flat.  In  fact  it  grows  as 

to  the  omniscient 

to  apply 

a  finite  number  of  samples.  When  considered 
algorithm  would  result  in  a  regret  function 
literature 
result  from  the  bandit 

algorithm  would  select  and  continue 

as  N  grows  beyond  m. The  established 

for  the  optimal 

realizable 

as  N  grows  without  bound 
feature 

For  us,  the  significant 
the  requirement 

[ 31. 
is  that  the  regret  function  cannot  be  flat.  This  follows 
of  one  arm 

in  the  superiority 

between 

of  global  optimality.  Any  belief 

to  an  arm  to  play  for  all  the  remaining  opportunities, 
it  is  the  wrong  arm.  In  the  unbounded 
the  accumulated 

but  it  cannot  be  guaranteed 
two  bandit  arms  may 
the  comparative  evaluation  arbitrarily  difficult. 
there  will  always 
(the  number 
the  regret 
can  grow  without  bound.  On  the  other  hand,  if  we  never  select  an  arm  to  play 
often 

from 
becomes  more  certain  with  more  confirming  observations, 
by  any  finite  sample  set.  The  average  payoff  probabilities 
be  slight  but  with  high  variances,  making 
If  one  commits 
be  some  chance 
of  trials  we  care  about) 
function) 
once  and  for  all,  then  we  condemn  ourselves 
(including 
large  deficit.  Thus,  under 
as  the  horizon 
permissive  planning 
planning  must  sidestep 

to  grow 
flat  regret  function,  no  successful 
viable,  permissive 

the  less  desirable  arm,  whichever  one  it  is).  Again  we  incur  an  unboundedly 

algorithm  can  be  realized.  To  be  computationally 

case,  where  horizon 
(and 
deficit 

recedes.  Without  an  asymptotically 

to  sample  both  arms  unboundedly 

the  regret  function  must  continue 

these  assumptions 

these  difficulties. 

is  infinite, 

therefore 

186 

G.E  DeJong,  S. WI  Bennett/Artificial 

Intelligence 

89  (I  997)  173-217 

7.  With  restrictions,  permissive  planning 

is  tractable 

Fortunately 

these  negative 
now  show  that  a  particularly 
permissive  planning, 
are  two  features 
optimality 

results  are  not  the  last  word  on  permissive  planning.  We 
that  we  call  restricted 
simple  kind  of  permissive  planning, 
there 
is  tractable.  While  we  give  only  a  single 
insist  on  global 

approaches  must  share:  we  cannot 

tractable  method, 

that  all  tractable 

and  some  structure  must  exist  within 

the  bias  space. 

an  indifference 

guaranteed  optimality 

is  a  necessary  step.  We  will  content  ourselves  with 
Abandoning 
specified  adequacy.  Furthermore,  we  allow  a  small  nonzero  adequacy 
some  sufficient 
thresh- 
tolerance  parameter  E that  establishes 
is  that  if  the  adequacy  of  the  best  bias  in  the  space 
old.  Our  interpretation 
of  this  region 
falls  within 
to  the  outcome.  The  procedure  may 
either  adopt  the  bias  as  adequate  or  the  planner  may  decide  there  is  no  adequate  bias  and 
restricted  permissive  planning  need  meet 
choose  not  to  solve  further  problems.  Finally, 
In  particular  we  include  a  confidence  parameter  S 
its  goals  only  with  a  high  probability. 
that  the  permissive  planning  algorithm 
that  specifies  an  acceptable  probability 
as  adequate.  More  formally: 
with  an  inadequate  bias  which  it  misrepresents 

fs  of  the  threshold  we  are  indifferent 

region  about  the  adequacy 

terminates 

Definition  5.  Restricted  permissive  planning 

is  a  recursive  procedure, 

that  is  given: 

0  a  planner, 
l  a  bias  space, 
l  adequacy  values  CY, /3,  y, 
a  a  threshold  of  required  adequacy,  TO, between  a  and  p, 
l  a  source  of  planning  problems, 
l  two  parameters,  E and  6  both  between  0  and  1, 

produces  a  new  planner 
has  the  following  properties: 

through  bias  accommodation 

that  with  probability 

at  least  1 -  S 

l  if  the  bias  space  contains  any  bias  of  adequacy  >  T,  +  E,  some  bias  with  adequacy 

of  at  least  T,  -  E  will  be  adopted, 

l  if  the  space  contains  no  bias  of  adequacy  >  T,, -F, 

the  new  planner 

refuses 

to  offer 

solutions 

to  any  further  problem, 

l  if  the  best  bias  in  the  space  falls  within 

the  indifference 

range  of  T,  f  E  then  the 

planner  may  either  adopt  a  bias  of  adequacy  >  T,, -  E, or  refuse  to  offer  solutions 
to  further  problems. 

The  e/a 

employed 
understand 
From 

is  borrowed 

arrangement 
in  [4].  From 

this  point 
it  to  mean  probabilistic 

from 

the  PAC 

[82]  and  also  earlier 
in  the  paper  on,  when  we  mention  adequacy  we  will 
attainment  of  an  e-adequacy 

threshold. 

literature 

( 1)  it  is  clear 

that  the  meaningful 

values  <  p,  adequacy 
other  side,  values  >  a  are  not  realizable. 
normalized  utility  parameter  0  in  place  of  T,.  It  takes  on  values  over  the  interval 
as  T,,  varies  between  p  and  LY. 

values  of  TO are  between  cy and  p.  For 
that  always  returns  A.  On  the 
to  consider  a 
(0,  1) 

is  no  higher  than  the  trivial  planner 

It  will  occasionally 

be  useful 

Definition  6.  The  normalized  utility  parameter,  0,  is  (T,,  -  j3) /  (a  -  /3) 

GE  DeJong,  S. W. Bennett/ArtQicial  intelligence  89  (1997)  173-217 

187 

7.1.  Schema-based  planners 

The  lack  of  structure  among  bias  space  elements 

that  evidence 

foe  of  tractability, 
Inde- 
the  adequacy  of  one  bias 
any 
independence, 
search  of  the  bias  space  has  an  algorithmic  complexity  bounded  below  of  lin- 
in  the  size  of  the  bias  space.  This  is  well  within 
bound 

for  or  against  another  bias.  Thus,  under 

is  another 
for  or  against 

the  accepted  computational 

is  polynomial 

(which 

growth).  However, 

the  size  of 
large,  even  unbounded.  Even  with  an  efficient 
this  may  be  unacceptable.  To  be  more  realistic,  we 
than  linearly  with  the  size  of 

grow  much  slower 

pendence  of  bias  elements  means 
cannot  count  as  evidence 
reasonable 
ear  growth 
complexity 
the  bias  space  may 
algorithm  yielding  a  small  constant, 
will  insist 
the  bias  space. 

for  tractability 

that  the  search  complexity 

itself  be  extremely 

Interdependence 

often  complicates 

system  analysis,  but  a  bias  space  is  a  special  kind 
flexibility  exists  for  bias  adjustment.  The  assumption  of 

of  system.  It  captures  whatever 
independence 
With  an  advantageous 
bias  might  be  informative 
design  bias  flexibility 
carefully 
a  particularly 

structuring 

flexible  bias  structure. 

interdependence, 

here  is  overly  general,  and  preserves  a  costly  but  nearly  useless  simplicity. 
the  observation  of  a  planning  outcome  using  one 
to 
any  way  we  like.  We  may  hope  to  derive  some  advantage  by 
[ 26 ]  provide 

about  many  others.  We,  the  implementors, 

our  flexibility.  Schema-based 

(or  skeletal)  planners 

are  at  liberty 

In  a  schema  planner,  planning 

techniques  are  encoded  as  generalized 

it  to  fit  the  particular  problem.  To  illustrate,  consider 

(called 
schemata).  The  system  solves  problems  by  retrieving  an  appropriate  general  pattern  and 
instantiating 
to 
a  distant  city.  The  system  might  have  three  schemata 
take-a-commercial-airplane, 
knowledge 
might  have  many  additional 
breakfast, 

These  encode  general 
their  respective  methods  of  transportation.  The  system 
goal  (for  making 
to  the  transportation 

the  goal  of  getting 
to  this  goal,  take-a-bus, 

schemata  not  relevant 
for  removing 

about  how  to  employ 

take-a-private-car. 

for  doing 

solutions 

laundry, 

relevant 

and 

for  supplying  a  set  of  constraints 
initial  state  and  goal.  The  constraints  are  sufficient 

snow  from  ones  sidewalk,  ans  so  on). 
of  classical  planning  given  in  Section  3,  a  schema 
in  part  on 
an  action 

that  depend 
to  individuate 

Building  upon  the  characterization 

can  be  viewed  as  a  mechanism 
the  problem’s 
sequence 

intended 

to  solve  the  problem.  Thus,  we  can  define  a  schema  as  follows: 

Definition  7.  A  schema,  SC,  is  a  set  of  constant  constraints  Csc  on  action  sequences 
together  with  a  function  FSC : P  4  C”  U  A  that  maps  a  planning  problem 
set  of  additional 

constraints  or  the  special  symbol  A. 

into  either  a 

The  symbol  A  is  interpreted 

as  indicating 

satisfied  by  the  problem. 
problem.  Otherwise  we  interpret 
straints  as  embodying 

a  solution  guaranteed 

If  the  preconditions 

that  the  schema’s  preconditions 

are  violated,  no  solution 
the  union  of  a  schema’s  constant  and  functional 

are  not 
is  offered  for  the 
con- 
the  planning  problem  given  to  it. 

to  ISolve 

7.1.1.  Schema  planner  adequacy 
that  problems  naturally 

Notice 

is  by  problem  class 
cluster 

domain 

theory,  common 

initial  state  features,  etc.  involved 

in  getting 

into  problem  classes.  The  potential  goals, 

the 
to  a  distant  city 

188 

G.E  Dehng,  S. WI Bennett/Artificial  Intelligence  89  (I 997)  173-217 

and  desirable 

It  is  convenient 

than  those  involved 

in  having  clean  clothes. 

to  tell  which  class  a  problem 

planner.  We  will  assume  problem  classes  are  pre-existing 

are  different 
to  allow  a  place  for  this  knowledge.  The  class  of  a  problem  can  be  very  useful 
schema-based 
easy  for  the  planner 
necessarily 
determined  by  the  satisfiability  of  each  schema’s  preconditions.  The  pre-existing 
into  which  problems 
natural  problem 
assume,  however, 
class  with  a  finite  nonzero  probability. 

to  a 
and  that  it  is 
is  from.  This  is  not  to  say  that  it  is 
is 
classes 
fall  reflect  whatever  a  priori  knowledge  we  desire  to  express  about 
from  a  single  class.  We  will 
appear  from  each  problem 

types.  We  may  view  all  problems  as  coming 
problems 

easy  to  know  which  schemata  apply 

to  a  problem.  Schema  applicability 

that  in  the  world’s  distribution, 

It  is  desirable 

to  take  problem  classes 

into  account 

on  others.  The  system  might  unfairly 

(like  block  stacking) 

as  applying 

is  free  to  balance  poor  performance 

adequacy 

classes 
If  we  interpret 

Some  problem 
building). 
system 
performance 
difficulty 
make  up  for  creating  piles  of  rubble 
world  adequacy 
we  require 
independently. 

though 
that  each  individual 

achieving  over-all  adequacy 

even 

are  much  easier 

in  computing  planner  adequacy. 
(like  bridge 
the 
then 
on  some  problem  classes  against  excellent 
in  problem 

exploit  a  discrepancy 

to  the  planner 

as  a  whole, 

than  others 

through 

instead  of  bridges.  This  violates 

flawless  execution  of  block  stacking 

to 
the  spirit  of  real- 
to  the  letter  of  the  definition.  Thus, 
requirement 

the  user’s  adequacy 

it  may  be  faithful 

problem  class  achieve 

7.1.2.  The  bias  of  schema-based  planners 
of  all 

The  collection 

the  system’s 

schemata 

the 

library 

is  its  schema 

library.  The  bias  of  a 
it  possesses.  Any  schema 
from 
that  originally 

planner 
the  bias,  even 

a  different  planning 
few  (and  necessarily 

is  only  slightly  different 
schema 

is  determined  by  the  particular 
if  the  replacement 

bias.  Note,  however, 
similar)  problems  are  susceptible 

schema-based 
schema 
change  shifts 
the  original.  For  example, 
take-a-commercial-airplane 
prefers  Fly  By  Night  Airways  may  be  replaced  with  one  that  prefers  Reliable  Air.  The 
schema 
planner  now  has  a  different  collection  of  schemata  and,  therefore,  a  different 
is 
library  yielding 
local.  Relatively 
to  the  change. 
Other  tasks  (making  breakfast,  getting  groceries, 
stacking  blocks,  etc.)  are  all  handled 
in  the  very  same  way  under 
With  the  bias  of  a  planner 

the  bias  space  exhibits 
for.  The  bias  space  grows  exponentially  with 

the 
the 
kind  of  interdependence 
number  of  problem  classes,  but  evidence  against  one  bias  element  counts  as  evidence 
against  all  other  biases 
to  Reliable 
Air  results 
one’s  own  car,  the  Whippet  bus  line  is  preferred 
preferred 
to  waffles,  then  it  is  also  likely 
bus,  and  breakfast  preferences 

in  higher  adequacy  within  a  bias  in  which,  say,  rental  cars  are  preferred 

to 
eggs  are 
if  the  car, 

to  be  a  desirable  airline  substitution 

to  Pathways,  and  scrambled 

the  effect  of  the  change 

are  resolved  differently. 

supplied  by  a  schema 

the  new  bias. 

If  the  switch 

the  offending 

that  contain 

we  hoped 

schema. 

library, 

7.1.3.  An  EBL-dejined  bias  space 

We  wish  to  consider 

551  over  problems 
been  explored 

sampled 

libraries  composed  of  schemata  acquired 

through  EBL  [ 20,22, 
from  the  planner’s  distribution.  A  number  of  systems  have 
The 

and  problem-solving 

[56,77,78]. 

schemata 

for  acquiring  planning 

G.F: DeJong,  S. W. Bennett/Arti$cial  Intelligence  89  (I 997) 173-217 

189 

proves 

problem 

initial  state 

the  problem’s 

that  the  commitments 

the  training  example 

is  a  sample  planning 

state  and  background 

together  with  characteristics 

example 
that  ISolves 

required  by  EBL 
it.  EBL  proceeds  by  explaining 

training 
plan 
background  world  knowledge.  The  explanation 
The  training  example’s  explanation 
the  root  of  the  tree  is  the  achieved 
elements 
from 
actions.  The  explanation 
with  aspects  of  the  initial 
This  explanation 
subgoals  within 
be  realized 
example,  a  training  example  might  illustrate  a  particular 
by-Night  Airways  was  taken  after  purchasing 
Farms  Mini-Mall 
obtained 
of  possessing  money 
destination, 
necessary  background  knowledge  constraints 
in  a  generalized 
This  transformation 

together  with  any 
in  terms  of  its 
into  a  new  schema. 
is  then  generalized 
can  be  viewed  as  a  proof  tree  [ 52,55,57] 
in  which 
instance  of  the  problem’s  goal,  and  the  leaves  are 
of  the  relevant 
together 
instance. 
certain 
that  these  subgoals  need 
to  be  achieved  by  the  training  example.  For 
in  which  Fly- 
flight  to  Baltimore 
from  the  Old 
a  ticket  with  money  obtained 
the  money  be 
requiring 
leaving 
the  subgoal 
to  application.  The 
to 

is  generalized  by  pruning  subtrees.  This  amounts 
the  proof  tree  and  removing 

taken  on  by  the  planner 
the  goal 
to  identifying 

cash  machine 
from  this  (or  any)  mini-mall 

cash  machine  can  be  pruned 
prior 

(e.g.,  that  the  airline  serve  the  destination). 
solution  schema. 
that  the  EBL  training  example 

airline  selected,  and  so  on  can  also  be  generalized 

to  be  solved  as  a  schema  precondition 

For  our  purposes,  we  will  assume 

the  previous  day.  The  constraints 

the  commitment 

they  happened 

in  the  manner 

the  particular 

knowledge 

is  derived 

subject 

results 

entail 

from  a 

planning  problem  drawn  by  the  planner  according 
The  problem 
that  expends 
problem  can  be  solved,  EBL  generalization 
schema. 

is  then  given  to  a  sound  constraint-searching 
resources  up  to  some  fixed  limit  in  attempting 

is  applied 

to  the  world’s  underlying  distribution. 
planner  within  the  EBL  system 
If  the 
in  a  new 

to  the  solution  yielding 

to  solve  the  problem. 

Thus,  we  will  view 

the  EBL  system  as  a  partial 

to 
that  must  be  discussed.  First,  a  number  of  quite 
that 
to  the  EBL  system  will  fail  to  ISolve  the  problem  so  that  no  schema 
to  this  latter  problem,  call  the  expected  proportion  of  solvable 

schemata.  There  are  several  wrinkles 
different  schemata  might  result  from  any  one  problem.  Second, 
the  planner 
is  constructed. 
problems 
non-decreasing 

for  the  world’s  distribution  of  problems  p.  We  require 

function  mapping  problems 

in  the  resource  bound,  R. 

that  p  be  monotonically 

there  is  a  possibility 

In  regards 

internal 

solutions  may  exist  to  a  planning  problem, 

Now  let  us  consider  how  a  single  problem  can  lead  to  several  different 

schemata. 
in  quite  different 
there 
there 
pair 
for  a  single  explanation.  Thus,  a  problem 
to  a  set  of  schemata  any  one  of  which  may  be  produced  by  the  EBL  system 

Several  distinct 
EBL  training  examples 
may  be  alternative 
may  be  alternative 
corresponds 
depending  on  the  internal  arbitrary  choices  made  during  processing. 

(composed  of  the  problem  and  its  solution).  Furthermore, 
[ 721.  Finally, 

explanations 
generalizations 

for  a  single  problem-solution 

resulting 

possible 

7.1.4.  Honest  EBL  and  conformable  schema  application 

When  given  a  problem,  we  will  require 

from 
at  random  one  of  the  schemata 
generation 
process  must  be  somewhat 
principle  be  produced  will  be  produced 

that  the  underlying  EBL  system  produce 
the 
the  set  of  possible 
fair.  We  require 
in 
from  the  problem  with  no  less  than  some  finite 

schemata.  Furthermore, 

that  any  schema 

that  can 

190 

G.F: DeJong, S. W; Bennett/Artificial  Intelligence 89  (I 997) 173-217 

pmin.  That 

class  of  schemata 

small  construction 

in  fact  no  more  than  l/p,i,. 

is,  we  exclude  EBL  systems 

probabilities.  From  this  it  follows 

that  can  hide  schemata 
that  a  problem 
This  is  usually 
is  not  met  by  an  important  but 
in  which  real-valued  parameters  appear.  For  now,  we 
in  which  a  single  problem  may 
large  number  of  schemata.  When  we  refer  to  an  EBL  system 
it  has  this  property.  Note  that  this  places  no  upper  bound  on  the  number  of 

minimal  probability, 
behind  vanishingly 
can  lead  to  only  a  finite  number  of  schemata, 
the  case  in  EBL  applications.  However, 
less  well-studied 
simply  note  that  our  results  do  not  hold  for  domains 
lead  to  an  unboundedly 
we  assume 
schemata 
number  of  different  problems 
schemata. 

that  might  be  built  from  the  domain’s  problems.  There  may  be  an  unlimited 
a  finite  number  of  novel 

each  of  which  can 

the  requirement 

introduce 

We  also  insist 

that  a  schema’s  preconditions 
the  capabilities 
to  ISolve  general  grocery  shopping  problems 

not  be  artificially 
the  precon- 
of  the  schema’s  body.  For  example,  a 
to  claim 
there  cannot  exist 

is  not  allowed 

specific; 

to  ISolve  problems  of  acquiring  dairy  products.  More  formally, 

the  precondition 
state  requirement 

ditions  must  accurately  portray 
schema  sufficient 
only 
within 
initial 
will  call  such  a  schema  “honest” 
ing  its  applicability.  We  will  say  an  EBL  system 
schemata.  Note 
A  schema’s  preconditions 
problem. 

language 
that  accurately 
since 

that  we  have  already 

falsely  claim 

cannot 

a  more  general  goal  pattern  nor  a  less  constraining 

the  applicability 
capture 
it  can  commit  no  sin  of  omission 

of  the  schema.  We 
in  advertis- 
if  it  produces  only  honest 
the  sin  of  commission. 
if  it  will  not  ISolve 

the 

is  honest 

forbidden  EBL  systems 
it  is  applicable 

Our  EBL  system, 

then,  is  assumed 

to  have  the  following  characteristics:  We  provide 

it 

set  of  problems 

with  a  resource  bound  R  and  access  to  an  unlimited 
according 
schema  with  probability  p.  With  probability 
that  no  schema  will  be  forthcoming.  When  a  schema  is  produced, 
from  the  finite  set  of  schemata 
appears  with  probability 
their  preconditions 

randomly  generated 
to  the  domain’s  distribution  D.  When  given  a  problem,  EBL  produces  some 
the  EBL  system  produces  A,  indicating 
it  is  a  random  selection 
is  an  illustration.  Each  element 
characterize 

for  which  this  problem 
no  less  than  Pmin.  Only  schemata 

are  produced.  For  us,  an  EBL  system 

that  honestly 

1 -p, 

is  characterized  by  Pmin and  p. 
is  embedded.  This  is 

Now  we  turn  briefly 

to  the  planner 

in  which  the  EBL  system 

goal  pattern 

to  a  problem  only 

if  a  schema  can  be  applied 

the  simple  problem  goal  “ON(Blkl,Blk3)” 

schemata.  We  will  say  that  a  schema-based 

“ON(  ?x,  ?y)  A  ON(  ?y,  ?z)“.  This  schema 

planner 
the  consumer  of  the  EBL-acquired 
is  “conformable” 
if  the  problem’s  goals 
require  all  of  the  schema’s  goal  pattern.  To  illustrate,  consider  a  schema  for  achieving 
the  conjunctive 
is  sufficient 
to  achieve 
but  such  a  use  would  not  be 
conformable 
ON  relation. 
to  produce  a  solution  altogether.  However,  a  schema  selection 
information 
This  information 
often  inefficient)  manner. 

achieve  an  unneeded 
to  apply  an  overly  specific  schema  than  to  fail 
important 
planner. 
(and 

failure  conveys 
about  the  abilities  of  the  schema-based 

since  the  schema 
It  might  seem  more  desirable 

instantiation  would  also  necessarily 

if  schemata  can  be  employed 

to  the  learning  component 

in  a  non-conformable 

is  obscured 

These  concepts  point  to  one  path  around  the  difficulties  with  ideal  permissive  planning. 
that  some  form  of  permissive 
tractability 

can  be  made  tractable.  We  can  now  assemble 

there  are  alternatives.  For  our  purposes 

it  is  enough 

the  formal 

Clearly 
planning 

result: 

G.E  Dehg,  S. W. Bennett/Art@_ictl Intelligence  89  (1997)  173-217 

191 

Lemma  8.  The  probability 
problem  of  the  appropriateproblem 

that  a  schema  which  has  adequacy  T,  ESolves  a  random 

class  is at  least  0,  or  equivalently, 

(TO-B),/<  a-B). 

Lemma  9.  The  probability 
of  the  appropriate 

that  a  schema  of  adequacy  T,,  ISolves  a  random  problem 

class  is  at  least  0,  or  equivalently, 

(T,  -  B)  /(a 

-  B). 

Lemmas  8  and  9  provide  a  basis  for  a  statistical  adequacy 

test  used  by  the  permissive 

planning 

algorithm. 

Lemma  10.  Given  an  honest  EBL  schema  acquisition 
schema  application  planner,  A, 
ISolved  by  A  using  a  schema,  SC,  then  SC  is  acquirable  by  L from  P. 

it  is  the  case  that  if  a  planning  problem  P  can  be 

system,  L,  and  a  conformable 

Thus,  there  is  a  two-way  bridge  between  problems  and  schemata, 

is  many-to-many. 
the  planner 

This  is  important 

in  providing 

a  link  from  the  problems 

to  a  set  of  candidate 

schemata  worth  evaluating. 

though  the  mapping 
sampled  by 

If  a planner  contains  a  schema,  SC,  acquirable 

through  honest  EBL  which 
Lemma  11. 
has  adequacy  T,,  or  higher  for  a  problem  class,  then  the  probability 
that  EBL  will  in 
fact  construct  SC  from  an  arbitrary  problem  of  the  appropriate  class  is  at  least  pmin@, 
-  PI,  w h ere  0  is  the  normalized  utility  threshold,  a  and  B  are 
factor 
from  Definition  1 and  pmin is  minimum  schema  probability 

or  ptin(T,, 
-  P)/<a 
adequacy  parameters 
of  the  EBL  system. 

Lemma  1 I  will  play  an  important 

role  in  our  tractability 

it  specifies 
schema  can  hide  from  random  probing.  The 

results.  Informally, 

an  adequate 

to  how  successfully 

a  limit 
permissive  planning 

algorithm  exploits 

this  limit. 

7.2.  Single-schema  planning 

We  now  wish  to  consider  a  very  simple  conformable 

planner,  called  a 
It  is  given  problems  drawn  from  just  one  problem  class  and  it 

single-schema 
may  acquire  at  most  one  schema  from  its  bias  set  by  applying  honest  EBL  to  problems 
drawn  from  the  world’s  fixed  unknown  distribution. 

schema-based 

planner. 

Definition 
which  the  planner 

is  a  single-schema 

planner. 

12.  Single-schema 

permissive  planning 

is  restricted  permissive  planning 

in 

Theorem  13.  Single-schema  permissive  planning 
SSPP 

is  pegormed 

tractably  by  algorithm 

By  “tractable”  we  mean 

that  the  sample  complexity-the 

number  of  problems 

con- 

sumed  by  the  permissive  planning 
that  none  exists-is 
independent 
ally  bounded 

algorithm 
of  the  cardinality 

in  selecting  an  adequate  bias  or  determining 
of  the  bias  space  and  is  polynomi- 

in  other  relevant  parameters 

( 1 /O,  (Y, p,  y,  p,  1 /ptin,  1 /E,  1 /a).  From 

the 

192 

G.F:  DeJong,  S. W  Bennett/Arttjicial  Intelligence  89  (I 997)  173-217 

definition 
probability,  halt  with  a  correct  answer. 

of  permissive 

planning, 

single-schema 

permissive  planning  must,  with  high 

Algorithm  SSPP(&,  6,  T,). 

GLOBAL: 

a,  ,&  y 

(*  Constants 

for  adequacy  computation 

*) 

GLOBAL:  p,  pmin 

(*  Expected  characteristic  SEBL  solution 

rate  reflecting 

resource  choice  *) 

Set  0  =  (T,,  -  p)/(a 
Set  M  =  max(  [(3/(pti@) 

-  p) 

ln(6/S)]) 

(*  number  of  schema  hypotheses  needed  *) 

Set  K  =  [(SpM  +  3  +  dm)/(6p2)1 

(*  number  of  problems 
Set  N  =  [M.  2((r  -  r)/(e26)l 

to  reliably  generate  M  schemata  *) 

(*  number  of  problems  needed 

to  test  a  hypothesis  *) 

Set  Tried  =  0 
Set  Schemas  =  0 
WHILE 

(Tried  <  K)  and  (Schemas  <  M)  DO 

Set  Tried  =  Tried  +  1 
Get  a  problem  Ph 
(*  a  problem 
Set  SC  =  SEBL(  4) 

for  hypothesis  generation  *) 

Set  Asc  =  0 
IF  SC  #  A  BEGIN 

Set  Schemas  =  Schemas  +  1 
REPEAT  N  times 

Get  a  problem  P, 
(*  a  problem 

for  hypothesis 

Apply  SC  to  Pt  to  yield  PLAN 

testing  *> 

IF  PLAN  =  A  THEN  Asc  = Asc  +  /? 

ELSE  IF  Execute(PLAN) 
ELSE  Asc  =  Asc  +  y 

END  REPEAT 
IF 

END  BEGIN 

achieves  Goal(  P,)  THEN  Asc  = Asc  f  a 

Asc  =  &c/N 
IF  Asc  >  T,  THEN  Exit  SSPP  with  SC 

END  WHILE 
Exit  SSPP  with  A 

Informally, 

the  algorithm  attempts 
M  is  chosen  so  that  if  an  adequate  schema  exists, 
trials.  Each  resulting 
schema 
sample  problems 

to  construct  and  evaluate  as  many  as  M  schemata. 
in  all  M 
test  composed  of  N 
for  which  solutions  are  generated  and  tested  in  the  world.  N  is  chosen 

to  a  statistical  adequacy 

to  be  missed 

it  is  unlikely 

is  subjected 

G.E  DeJong,  S. W. Bennett/Artijicial Intelligence  89  (1997)  173-217 

193 

adequacy 

so  that  the  measured 
true 
adequacy.  Since  some  problems  may  not  yield  schemata,  a  larger  number,  K,  problems 
must  be  used 
least  M  schemata  will  result. 

to  differ  very  much  from  the  schema’s 

the  M  schemata.  K  is  chosen 

to  probabilistically 

is  unlikely 

guarantee 

to  build 

at 

It  is  somewhat 

surprising 

that  the  higher 

missive  planning.  One  might  expect 
than  a  mediocre  one.  Upon  reflection 
adequacy  must  correctly  apply 
problems  can  give  rise  to  the  schema 
affords  many  more  opportunities 
marginally 
quite  certain 

adequate.  On  the  other  hand, 

threshold, 

take  longer 

the  adequacy 

the  easier  for  per- 
that  it  would 
to  find  a  good  schema 
the  true  becomes  quite  intuitive.  A  schema  of  high 
to  many  problems  and,  from  Lemma  10,  each  of  these 
random  probing 
than  one 

through  EBL.  Thus,  statistically, 
schema 

that  is 
if  a  few  random  probings  all  fail,  we  can  be 

to  learn  a  highly  adequate 

that  no  extremely  adequate  schema  exists. 

7.3.  The  DBl  planner 

Consider  a  slightly  more  complicated  planner  called  a  DBl  planner 

that  may  have  at 
for  each  of  a  finite  number  of  problem  classes  and  whose  bias  space, 

through  honest  EBL  over  its  distribution 

of  problems. 

most  one  schema 
as  above, 

is  define 

Definition  14.  DBl  permissive  planning 
planner 

is  a  DBl  planner. 

is  restricted  permissive  planning 

in  which  the 

Theorem  15.  DBI  permissive  planning 
each  problem  class  with  some  nonzero 

is  tractable  provided 

that  problems  appear  for 

lower  bound  probability  plb. 

7.4.  The  bias  space  complexi 

We  now  turn  to  considerations 

to  develop  an  intuition 
should  be 
planning  where  adequacy 
over  a  fixed  but  unknown  distribution 

tractable.  We  confine 

of  the  intrinsic  complexity  of  the  bias  space.  We  wish 
for  why  permissive  planning  under  the  conditions  outlined  above 
permissive 
planning 

to  single-schema 

single-schema 

investigation 

this  brief 

is  the  measure  of  effective  real-world 
of  problems. 

The  difficulty  of  a  learning 

task  is  associated  with  its  Vapnik-Chervonenkis 

but  in  learning 

[ 101.  The  VC  dimension 

dimension 
ested  not  in  classification 
machinery,  we  define  a  classification 
The  classification 
probability, 
the  VC  dimension 
A  classification 

task  is  designed 

also  a  solution 

to  a  single-schema 
for  this  related  classification 
learning 

is  defined  for  classification 

to  plan  adequately.  To  employ 

task  that  is  closely 

related 

to  have  the  property 

that  any  solution 

(VC) 
learning.  We  are  inter- 
this  complexity 
task. 
is,  with  high 
task.  We  show  that 

to  our  planning 

permissive  planning 
task  is  low, 

that  illustrate 
some  target  concept  along  with  a  space  of  concept  hypotheses.  The  task  is  to  select  an 
that 
space,  through  examination 
element 
is  likely 

the  hypothesis 
from 
to  be  a  good  approximation 

a  source  of  labeled  examples 

of  the  labeled  examples, 

to  the  underlying 

target  concept. 

task  requires 

We  augment  a  standard 

single-schema 

provisions: 

( 1)  all  problems  are  ISolvable 

permissive  planning 
task  with  two  additional 
(so  that  each  problem  can  be  unambiguously 

194 

C.F:  DeJong,  S. WI Bennett/Artijicial 

Intelligence 

89  (1997)  173-217 

(2) 

and 

planner’s 

example) 

task,  CT(n) 

task  be  the  permissive 

as  a  positive  or  negative 

some  adequate 
as  follows:  Let  the  example 

labeled 
We  define  a  classification 
classification 
hypothesis 
EBL  to  n  initial  planning 
partitions 
supplies  a  plan 
schema  supplies  no  plan  or  whose  plan  does  not  ESolve 
the  CT(n) 
desired  adequacy  T,. 

schema  exists. 
for  our 
source 
the 
problems.  Let 
space  be  a  set  of  n  candidate  bias  schemata  constructed  by  applying  honest 
source.  Each  hypothesis 
the  schema 
for  which  the 
to 
the 

the  problem).  A  solution 
space  that  achieves 

the  space  of  examples 
that  ESolves 

task  is  any  element  of  the  hypothesis 

instances 
and  negative 

for  which 
(those 

(those 
instances 

source  of  planning 

from  the  example 

problems  drawn 

the  problem) 

into  positive 

classification 

Lemma  16.  Let 

1 

-In 
lzo =  Prni”@ 

1 
r] 

0 

. 

Then  with  probability  1 -v  any  solution 
single-schema  permissive  planning 

task. 

to  CT(  no)  yields  a  solution 

to  the  corresponding 

Lemma  16  assures  us  that  the  classification 

task  has  the  desired 

relation 

schema  permissive  planning.  Remember 
actually 
hypothesis 

the  classification 

solves 

set.  This  is  provided  by  Theorem  17: 

that  we  are  not  interested 

in  an  algorithm 

task,  but  in  characterizing 

the  VC  dimension 

to  single- 
that 
of  the 

Theorem  17.  The  VC  dimension  of  the  CT(na) 

task  is  no  greater 

than 

1% (&&))- 

difficult 

learning 

planning 

to  efficient 

tasks,  a  low  VC  dimension 

learning.  The  implication 
itself  may  be  tractable.  This  result 

The  log  of  a  polynomial 
is  associated  with  intrinsically 
that  the  task  may  admit 
restricted  permissive 
generality 
it  conveys 
hidden  within 
vocabulary 
be  insignificant 
has  a  very  modest  VC  dimension.  One  can  reasonably 
algorithms 

function  grows  only  quite  slowly.  While  a  high  VC  dimension 
indicates 
of  Theorem  17  is  that 
lends  strength  and 
is  the  assurance 
the  SSPP  algorithm  nor  any  subtleties 
the 
to 
itself 
to  find  many  alternative 

to  results  stated  in  Theorems  13  and  15.  Equally 
that  there 

details.  By  Theorem  17  we  see  that  the  problem 

that  would  perform  similarly. 

to  fully  appreciate  because 

features  may  first  appear 

can  be  difficult 

implementation 

special  about 

it.  Computer 

is  extremely 

expressive. 

is  nothing 

algorithms 

employed 

Important 

important 

expect 

8.  Permissive  planning 

in  the  real  world 

All  forma1  results 

including 
until  confirmed  with  empirical 

suspicion 
theorem  or  lemma  does  not  hold,  but  only 

support.  This 

is  not 

that  its  statement, 

should  be  treated  with 
to  say  that  a  proven 
though  correct,  may  be 

those  of  the  previous 

section 

GE  DeJong, SW  Bennett/Art$iciul  Intelligence 89 (1997)  173-217 

195 

irrelevant 
typically 
requires 
the  coefficients 
more  observations 
running 
This 

in  the  real  world.  From  a  formal  point  of  view,  “tractable” 
taken 
reasonable 

values  of  the  complexity 

to  mean  “polynomially 

bounded  growth”. 

are  sufficiently 

large,  an  algorithm’s 
than  the  real  world  can  reasonably 
the  algorithm  grows  very  slowly,  it  may  be  prohibitively 
is  particularly 

though 
expensive. 
true  in  the  case  of  robotic  planning.  Here  we  may 

function  as  well  as  reasonable  growth. 

If 
example  complexity  may  require 
the  cost  of 

supply.  Even 

In  the  real  world,  “tractable” 

complexity 

is 

or  even  hundreds  of  learning  episodes.  But  training  a  physical 
to  be  expensive 
of  examples  begins 
regardless  of  how  flat  the  complexity 

and  a  million 
function 

is  at  that  point. 

robot  experiences 

robot  through 

tolerate 

tens 
thousands 
is  far  too  many 

Yet,  one  million 

is  a  very  small  number 

behavior.  Even  a  modest 
states.  An  action  sequence  may  involve  selecting 
times. 

robot  arm  can  exist 

in  the  context  of  the  richness  of  robotic 
in  well  over  ten  billion  distinguishable 

from  this  set  hundreds  or  thousands  of 

learning 

including 

of  a  consistent 

point  concerns 

the  determination 

in  the  theoretical 

through  machine 

that  random  probing 

can  benefit  a  real-world 

combined  with  empirical 

those  of  the  previous  section  depend  on  efficiently 

In  this  section  we  examine  how  permissive  planning 

space  that  is  consistent  with  the  known  data.  The  previous 

planner  bias 
tem.  Where  might  real-world  difficulties  be  lurking 
troublesome 
results 
from  the  hypothesis 
establishes 
for  tiny  hypothesis 
intractable 

and  the  view  of  alteration  of 
sys- 
robotic  planning 
results?  The  first 
hypothesis.  Many  PAC 
finding  an  element 
section 
fine 
is 
from  a  practical  point  of  view  for  hypothesis  spaces  that  are  large  and  sparse. 
between  observed  problems 
probability, 
can 

and  potential 
pkn.  As  noted 
to  no  more 
for  schemata 
involves 
joint  speeds,  etc.  may  take  on  many  different  values,  and  each  combination 
values  embodies  a  distinct  bias  for  that  schema’s  problems. 

lead 
is  violated 
schema  often 
forces,  friction  coefficients,  preferred 
of  preferred 

l/pmin  schemata.  We  also  noted  that  such  an  assumption 

spaces  or  ones  dense  with  acceptable  elements, 

just  such  real-valued  parameters.  Gripper 

schemata.  We  assumed  a  finite  minimal 

appear.  A  robot  planning 

testing  suffices.  While 

in  which  real-valued 

in  the  last  section, 

A  second  difficulty 

schema  production 

random  probing 

this  assumption 

that  a  problem 

the  important 

relationship 

parameters 

concerns 

implies 

than 

The  existence  of  such  continuities 
finite  ptin  allows  SSPP  to  test  schemata 
did  not  need  to  understand 

There 

is  no  analog 

to  the  Pmin  requirement 

in  isolation  while  maintaining 

implies  an  infinitesimal  Pmin.  The  requirement  of  a 
“tractability”.  We 
the  implication  of  one  schema’s  failure  to  any  other  schema. 
in,  say,  PAC  learning  of  DNF  concepts. 
in  PAC  learning  can  be  seen 
In  DNF 
it  supports. 
at 

against  many  hypotheses 

of  information 

representation 

generalization 

language 

The  success  of  DNF  as  a  concept 
as  due  in  part  to  the  straightforward 
concept 
once. 

learning, 

a  single  example  can  provide  evidence 

To  be  freed  of  the  ptin  assumption  we  must  support  a  method  by  which  the  rejection 
candidate 

in  the  elimination 

results 

of  one  schema 
schemata 

for  that  problem  class,  analogous 

of  a  large  number  of  additional 
to  DNF  concept 

learning. 

The  approach  we  have  taken 

is  to  diagnose 

is  used  both  to  guide  the  selection  of  the  next  hypothesis 
from  consideration 

other  schemata 

to  which  the  failure  diagnosis  applies.  In  this  way  the 

the  failure  of  a  schema.  The  diagnosis 
schema  and  also  to  eliminate 

196 

G.F  DeJong.  S. W  Bennett/Artificial 

Intelligence  89  (1997)  173-217 

Obstacle 
Fig.  4.  Plan to reach over an obstacle. 

Target 

system  can  be  more  directed 
on  the  confining 

assumption  of  ptin. 

than  simple 

random  probing,  eliminating 

the  dependence 

While  constructing 

the  conventional 

explanation, 

explanation 

for  the  schema.  Qualitative 

can 

then  be  drawn.  When  a  schema  proves  empirically 

all  other  schemata  which  are  qualitatively 
These  are  schemata  whose  parameter  values  qualitatively 

dominated 

for  which  the  schema  was  rejected  according 

the  EBL  system  also  constructs 
the  interaction 
inferences 

about 

to  be 
by  it  can  also  be 
the 
exacerbate 
to  the  qualitative  explanation. 

a  qualitative 
of  schema  parameters 
inadequate, 
eliminated. 
problem 

the  situation  depicted 

on  a  table.  We  will  suppose 

in  Fig.  4.  Here,  a  gantry-style 

Consider 
past  an  obstacle 
positioned 
including  MOVE-UP(x) 
world  changes 
augmented 
argument 
value  the  final  distance  of  the  gripper 

robot  arm  is  to  reach 
in  order  to  grasp  a  target  block.  World  objects  are  modeled  as  polygons 
that  the  system  has  a  set  of  planning  operators 
to  specify  how  the 
are 
the 
in 

OPEN-GRIPPER(x) 
to  its  actions.  Further,  we  require 
characterization 

that  the  operators 
effects.  Thus, 
increases 

to  the  ceiling  monotonically 

decreases. 

in  response 
by  a  qualitative 

than  zero,  and  as  the  argument 

to  MOVE-UP  must  be  greater 

of  their  parameterized 

,  MOVE-LEFT(x), 

The  planning  problem 

is  a  simple  one.  A  solution,  depicted  by  the  dotted  line  trajec- 

tory,  is  quite  easily  constructed 

from  the  initial  state: 

Initial  state 

Solution 

HEIGHT(  OBST,  4.7) 

MOVE-UP(  2.4) 

HEIGHT(TARG, 

2.2) 

MOVE-RIGHT( 

8.3) 

WIDTH(  OBST,  2.6) 

OPEN-GRIPPER( 

1 .O) 

WIDTH(TARG, 

1 .O) 

MOVE-DOWN(  3.7) 

POSITION(  OBST,  4.5) 

CLOSE-GRIPPER( 

1 .O) 

POSITION(  TARG,  10.9) 

GRIPPER-AT(2.6,2.1) 

and  this  solution 
problems: 

is  readily  generalized 

via  EBL  into  a  schema 

for  a  class  of  similar 

G.E  DeJong  SW  Bennett/Artijiciul  Intelligence  89  (1997)  173-217 

197 

Obstacle 
Fig.  5.  Execution  of  the  reach  plan. 

Target 

Initial  state 

Solution 

HEIGHT(  ?Obstacle,  ?OH) 

MOVE-UP(  ?OH  -  ?GY) 

HEIGHT  ( ?Target,  ?TH ) 

MOVE-RIGHT( 

?TP  -  ?GX) 

WIDTH(  ?Obstacle,  ?OW) 

OPEN-GRIPPER( 

?TW) 

WIDTH  ( ?Target  , ?TW) 

MOVE-DOWN( 

?OH  -  ?TH) 

POSITION( 

?Obstacle,  ?OP) 

CLOSE-GRIPPER( 

?TW) 

POSITION( 

?Target,  ?TP) 

GRIPPER-AT( 

?GX,  ?GY) 

The  real-world 

execution  of  the  plan  will  look  more 
failures  manifested 

two  distinct 

5.  Here, 
the  plan  suffers 
with  world  objects.  Each  collision 
beliefs: 
obstacle  block  is  taller  than  believed  and  (b) 
than  expected  and  the  target  block  is  located  closer  than  believed. 

arises  because  of  a  combination 

the  MOVE-RIGHT 

the  MOVE-UP 

(a) 

like  the  one  depicted 

by  collisions 

of  slightly 

in  Fig. 
of  the  gripper 
incorrect 
the 
the  arm  farther 

action  fails  to  raise  the  arm  as  high  as  expected  while 

extends 

The  planning 

bias  of  the  schema  above  includes  minimally  missing 

the  target.  The  impracticality 

is  not  so  important.  The  relevant  point 

the  obstacle  and 
of  such  a  bias  is  obvious.  However, 
is 
in  the  class 
to  solve.  No  matter  what  the  initial  bias,  we  can 

based  on  very  little  experience 

to  us  is  that  some  bias 

and  it  is  unavoidably 

that  the  schema  claims 

surrounding 
bias 
embodied 

minimally 
the  particular 
necessarily 
of  problems 
have  little  confidence 

in  its  expected  performance. 
the  first  failure  of  Fig.  5  is  encountered, 

When 

permissive  planning  dictates 

that  the 
the  alteration  can  be 

rather 
the  observed 

schema’s  bias  be  altered.  With  the  additional  qualitative  knowledge 
directed 
First, 

than  random. 
is  that  the  MOVE- 
failure 
RIGHT  ended  prematurely.  The  failure  observation 
force. 
But  there  is  no  way  to  know  the  identity  of  the  collising  object.  The  system  embodies 
is  approximate.  This  says  that  the  real  world 
the  assumption 
from  the  represented  world  than  a  large  one. 
is  more  likely 
is 
The  collision 

could  be  with  the  target  block  or  the  table  but  since  the  obstacle  block 

that  represented  knowledge 
to  be  a  small  perturbation 

is  diagnosed.  All  the  system  knows 

is  of  an  unexpected 

collision 

198 

G.F:  Dehng,  S. cl!  Bennett/Art@cial 

Intelligence 

89  (1997)  173-217 

the  observed  collision  point, 

nearest 
explanation. 

it  is  selected  as  the  first  candidate 

in  the  collision 

relevant  plan  parameters 

Second,  a  set  of  qualitatively 

is  identified.  These  are  constants 
employed 
in  the  executed  whose  values  were  not  fully  entailed  during  planning.  As  such 
they  represent  part  of  the  planner’s  bias;  the  collection  of  all  possible  parameter  settings 
in  light  of  the  explanation 
forms  the  planner’s  bias  space.  Each  constant 
to 
the  failure.  Here,  there  is  only 
identify 
those  whose  value  may  qualitatively 
one  such  constant. 
to 
be  at  least  ?OH  -  ?GY  to  satisfy 
MOVE-RIGHT.  The  argument  ?OH  -  ?GY  was  believed  adequate 
observed  not  to  be  contingent 

of  a  clear  path  for  the  interrupted 

upon  this  first  failure  explanation 

to  the  first  action  MOVE-UP 

is  examined 
influence 

It  is  the  argument 

for  that  purpose. 

the  precondition 

being  correct. 

It  is  entailed 

It  is 

is  noted 

as  the  argument 

to  the  action  MOVE-UP 

to  be  too  small.  The  schema 

the  bias  is  adjusted.  Qualitatively 

the  likelihood  of  a  collision  with  the  obstacle 
Finally, 
is  maximized.  The  value  ?OH  - 
is  minimized 
and  a 
?GY, 
the  fact  that  the  MOVE-UP  argument  must  be  greater 
preference.  The  constraint  encodes 
that 
is  qualitative 
than 
improves  as  the  argument  value  is  increased.  From  now  on  the  system 
expected  utility 
will  have  a  bias  of  moving  as  high  as  possible  when  reaching  over  an  obstacle.  Together 
constraints 
to 
influence 

constitute  a  generalized  memory  of  the  failure  experience 

and  preferences 
future  processing. 

the  value  ?OH  -  ?GY.  The  preference 

is  amended  by  adding  a  constraint 

in  nature  and  specifies 

Such  constraints 

and  preferences 

can  focus  attention 

away 

failure 

different 

that  was 

is  encountered 

later  qualitatively 

that  no  additional 

is  the  generalization 

the  one  evaluated.  This 

type  of  failure  may  occur 

that  can  be  explained  by 
In  that  case  it  has  reached  an  adequate  value.  On  the  other  hand, 
the 
the  new  and  quite 
that  the  MOVE-UP  argument  be  less  than  the 
that  the  argument  be 

schemata  besides 
discussed  earlier. 
It  may  happen 
this  plan  parameter. 
some 
arm  is  now  reaching 
different  explanation  will  post  a  constraint 
discovered  maximal  bound.  It  will  also  post  a  qualitative  preference 
as  small  as  possible.  The  utility 
convex. 
end.  Qualitatively 
constraints 
best  value  of  the  MOVE-UP 

interval  but  decreases  at  the  high 
failures  would  post  further 
in  pinning  down  the 

and  preferences.  Thus,  a  rough  binary  search  is  realized 

It  increases  at  the  low  end  of  the  allowable 

too  high.  When  such  a  failure 

is  then  seen  as  qualitatively 

is  the  best  choice.  Further 

for  the  reason 

is  encountered, 

the  argument 

the  midpoint 

for  selecting 

argument. 

that 

The  system  may  also  encounter 

to  grasp  the  target  (the 
second  collision  of  Fig.  5).  In  a  similar  way  the  bias  is  adjusted  so  that  the  gripper  opens 
as  wide  as  possible  when  approaching 
permissive  planning 
like  the  one  shown 
produces  a  solution 
Fig.  7  diagrams 

a  grasp  target.  Eventually 
in  Fig.  6. 
the  improved  ESolve  behavior  of  the  reach-over-obstacle 

a  collision  while  attempting 

the  obstacle  and  minimally 
is  extremely 

limited.  After  permissive  planning 

schema.  The 
open  to  grasp  the 

schema 

success, 

tries  to  minimally  miss 

original 
target.  Its  real-world 
the  schema  applies  much  more  broadly. 
produced  by  a  planner  which  incorporates 
be  the  case,  however. 
ESolve  coverage  will  contain 

therefore, 

In  permissive  planning 

In  this  example 
explicit  uncertainty 

to  that 
is  similar 
reasoning.  This  need  not 
that  the  improved 
the  ESolve  coverage  of  the  original.  Nor  is  there  any 

there  is  no  guarantee 

the  result 

from  many  additional 
of  experience 

G.E  Dehng,  S. W Bennett/Art@ciul 

Intelligence 

89  (1997)  173-217 

199 

Obstacle 

Target 
Fig.  6. A  conservative  solution. 

[Solve  Universe 

ESolve 

Fig.  7.  Permissive  versus  original  reach  schema  coverage. 

States  of  Interest 

ISolve  Univserse 

- 

Permissive 
ESolve 

Fig.  8. More  typical  result  of  permissive  planning. 

the  ESolve  coverage  will  be  larger 

than 

that  of  the  original 

schema, 

that 

guarantee 
although  often  this  is  the  case. 
typical 

Fig.  8  shows  a  more 

after  adjustment, 

the  ESolve  behavior  will  better  match 

the  user’s  needs.  Here, 

relationship.  The  permissive  planning 

guarantee 

is  that 
the 

200 

G.F:  Dehng, 

SW  Bennett/Artijkinl 

Intelligence  89  (1997)  173-217 

Fig.  9.  The  GRASPER 

system. 

overlap  between 
improved  over 
contained 

in  the  adjusted  set. 

the  permissive  ESolve  behavior 

and 
schema,  although 

the  states  of  interest 
the  original  ESolve 

is  much 
set  is  not 

that  of  the  original 

An  important  characteristic 

of  permissive  planning 

is  that  it  does  not  try  to  eliminate 

planner  weaknesses. 
qualification 
away  from  the  kinds  of  problems 
strengths  are  brought  more  into  line  with  the  user’s  needs. 

Such  an  approach  would  be  doomed;  no  planner 
In  permissive  planning,  planner  weaknesses 

the 
remain  but  are  moved 
that  the  user  asks  the  system  to  solve.  Likewise,  planner 

can  solve 

problem. 

9.  The  GRASPER 

system 

In  this  section  we  present  a  brief  overview  of  GRASPER, 

permissive  planning 
of  freedom  Prab  RTX  scara-type  manipulator, 
an  IBM  RT  computer 

running  Lucid  Common  Lisp. 

real-world 
robotic  system.  The  system,  shown  in  Fig.  9,  consists  of  a  six  degree 
an  overhead  camera,  a  frame  grabber,  and 

an  implemented 

sequences 

GRASPER 

plans  action 

to  grasp  and 

lift  novel  objects  placed 

to  the  overhead  camera.  The  pixel  patterns 

its 
(Fig.  10).  No  a  priori  model 
such  as  plastic  pieces  from  a  children’s  puzzle 
workspace, 
they 
of  the  objects  are  given  to  the  system.  They  are  known  only  through 
present 
into 
simple  polygons.  Fig.  11  shows  a  typical  object,  its  contour  edges  as  found  by  the  vision 
are 
system,  and  its  polygonal 
used  for  drawing 
(like  any 
internal 
representation 
to  the  actual  objects. 

the  silhouette 
from  the  camera  are  converted 

representation.  The  polygon  object  representations 

about  spatial  occupancy.  This  representation 

is  flawed,  being  only  an  approximation 

of  a  real  physical  object) 

conclusions 

internal 

in 

G.E  DeJong,  SW.  Bennett/Art(ficial 

Intelligence  89  (1997)  173-217 

Fig.  10. The  workspace  with  gripper  and pieces. 

Solid  blacklinesegmem 

show 

Fig.  11. An  object,  the  sensed  contour,  and the  represented  polygon 

The  system 

includes  a  typical  axiomatization 

the  gripper  applies  a  friction 

about  how  objects  can  be  surrounded, 
the  object, 
the  fingers  and 

force  between 

friction  establishes 

a  grasp,  how  a  grasped  object  can  be  manipulated, 

like  the  represented 

sensory  data,  captures 

The  coefficients 

of  friction  between 

the  fingers  and  various  objects 

as  a  single  scalar.  This  is  a  simplification.  Operators 

the  real  world  only 
is 
to  move  the  arm  only 

how  closing 
how  sufficient 
etc.  The  axiomatization, 
approximately. 
represented 

Fig.  13.  A  horizontal 

slipping 

failure 

approximate 
to  a  surrounded  object  also  only  approximate 

the  motions 

they  claim 

the  operator’s  effects. 

to  perform.  The  forces  that  the  robot  fingers  apply 

its  initial  knowledge, 

Using 
surprisingly, 
of  the  failure  modes  observed. 

the  initial  plan  usually 

a  plan 

is  constructed 

to  lift  a  designated 

fails  in  the  real  world.  Figs.  12  and  13  illustrate 

object.  Not 
two 

Following 

the  planning  process, 

the  principle  of  permissive  planning, 

is  blamed 
over  several  failures, 

rather  than  the 
for  the  shortcoming.  The  planning  bias  is  adjusted.  Through 
domain 
theory, 
to 
the  real-world 
bias  adjustment 
conform 
schema 
to  the  projection  of  the  original  action  sequence.  The  final  PICK-UP 
can  be  interpreted  as  ( 1)  squeezing  harder  than  the  world  knowledge  claims  is  necessary, 
(2)  selecting  grasp  points  along  faces  that  are  more  nearly  parallel, 
(3)  selecting  grasp 
points  closer  to  the  object’s  center  of  geometry 
than  believed  necessary,  and  (4)  opening 
the  gripper  wider  than  believed  necessary  while  appoaching 

effects  of  the  schema  are  made 

the  target  object. 

Figs.  14  and  15  illustrate  a  typical  application  of  the  schema  after  learning.  After  bias 
is  correctly  grasped 

like  most  novel  2D  objects, 

has  occurred, 

this  object, 

adjustment 
and  lifted  on  the  first  attempt. 

illustrates 

Fig.  16  quantitatively 
schema.  The  solid  region 
the  grasp  to  fail  before  and  after  permissive 
planning 
for  schema  after  permissive 
larger 

robustness  of  GRASPER’s  PICK-UP 
indicates  how  far  the  real  world  can  vary  without  causing 
is  much 
can  vary 

adjustment.  The  ESolve  envelope 

that  these  attributes 

the  increased 

indicating 

G.E  DeJong,  S. WI Bennett/Artificial 

Inrelli~ence  89  (1997)  173-217 

203 

&rows 

illumate  planned 
fmger  pcsiticas  --- 

.&ighter gray  point.5 are cam 
era-sensedccmtcnlrp 

Fig.  14.  Target  object  with  planned 

finger  positions. 

Fig.  15. A  successful grasp after permissivization 

Weig 

0.4 

0.3 
0.2 

0.1 

0 

Weig 

0.4 

0.3 
0.2 

0.1 

0 

EtT0r 

8 

a)  Before  Permissive  Planning 

b)  After  Permissive  Planning 

Fig.  16.  ESolve  envelopes. 

much  more  widely  and  still  be  successfully 
weight,  excess  width,  and  orientation.  Other  attributes 
faces,  and  the  distance 
the  grasped 
the  angle  between 
selected  grasp  points)  would  also  show  improved 

picked  up.  Three  attributes  are  represented: 
(X  &  Y  position  on  the  table, 
from  the  center  of  mass  of  the 

tolerance. 

The  object  being  grasped 

attempted  by  the  schema 

is  similar 
it  eventually 

to  the  one  in  Fig.  15.  As  heavier 

target  objects  are 
fails  with  the  target  slipping  out  of  the  gripper. 

204 

G.E  DeJong,  S. W Bennett/Art$ciul  Intelligence  89 (I 997) 173-217 

errors.  As  the  true  width 

adjusted  schema.  More  interesting 
increases 
is  shown  on  the  axis  extending 
(the  axis  perpendicular 

twice  the  mass  in  the 
As  shown  by  the  vertical  axis  this  failure  occurs  at  approximately 
the  width  and 
permissively 
the  true  width 
orientation 
the  schema’s 
and  the  represented  width 
to  the  page)  quickly  decreases. 
tolerance  of  orientation 
(about 
is  ~tO.09  radians 
Before  permissive  planning 
5  degrees)  with  an  object  just  1 cm  wider  than  believed.  After  permissive  planning 
an 
object  4  cm  wider  than  believed  can  still  be  successfully  grasped  when  approached  with 
an  orientation 

is  the  interaction  between 
(the  difference  between 

error  of  ~tO.64  radians 

the  tolerated  variation 

(over  30  degrees). 

to  the  right), 

in  orientation 

errors 

The  GRASPER 

system  satisfies  the  requirements  of  Theorem  13.  It  is  a  single-schema 

its  only  goal  is  to  pick  up  objects.  Exactly  one  schema 

planner 

family  was  defined 

simple 

family  of  planners,  GRASPER  demonstrates 

for  this 
is  constructed 
to  establish  a  formal  result,  and 
that  it  is 

planner; 
purpose.  The  single-schema 
while 
not  without 

it  is  a  particularly 

interesting 

performance?  We  could  have 

that  would  support  a  more  certain  domain 

that  a  grasping  episode  would 

fall  within 

invested 

in 
theory. 
the  origi- 
the  GRASPER 

the  hardware 

supporting 

real-world  members. 
to  GRASPER’s 

increase 

the  chance 

is  far  from 

crafted  planning 

is  learning 
robotics  hardware 

How  central 
more  expensive 
This  would 
nal  ESolve  envelope  of  Fig.  16(a).  Certainly 
system 
state-of-the-art 
and  with  carefully 
made  permissive 
defer  the  problem.  With  better  hardware 
size.  Manipulating 
lem  as  manipulating  GRASPER’s 
an  expensive 
with  higher  precision 
“solution”  misses 
enue  to  achieving  adequate 
expensive  hardware. 

option  and 

planning 

the  state  of  the  art.  With 

the  best  available 

robot  arm,  with  a 

vision  system,  with  a  more  sophisticated 

internal  object  representation, 

necessary 

the  pitfalls 

the  same  phenomenon 

high  precision  parts  is  just  as  susceptible 

operators  we  could  have  avoided 
for  the  GRASPER 

that 
system.  But  this  would  only 
arises  at  a  smaller  grain 
prob- 
is 
improving 
to  users.  Hardware  costs  skyrocket 
such  a 
the  point  of  the  research.  Permissive  planning  opens  a  different  av- 
buying  more 

real-world  performance.  One  that  complements 

requirements.  Most  importantly, 

puzzle  pieces.  Furthermore, 

and  better  reproducibility 

is  not  always  available 

to  the  qualification 

accuracy 

Finally,  we  are  making  no  claims 

that  the  GRASPER 
grasping  problem.  This  is  an  exceedingly 

model-based 
in  robotics.  Our  claim  is  only  that  bias  adjustment 
interact  with  a  real  world.  Robotic  grasping 
is  crucial.  Thus,  GRASPER 
adjustment 

through  permissive  planning. 

is  an  implemented 

system  solves  the  general  non- 
difficult  and  still  open  problem 
that 

tool  for  planners 

is  an  important 

is  one  task  where  a  real-world 

connection 

existence  proof  of  the  tractability  of  bias 

For  additional 

details  of  the  GRASPER 

system 

see 

task 

to  which 

applied  can  be  found 

[5].  Another 
in  [61. 

permissive  planning  has  been  successfully 

10.  Summary  and  conclusions 

We  have  outlined 

world  performance.  We  introduced 
finding 

that  works  according 

a  plan 

to  the  planner’s  micro-world, 

ISolving  a  planning  problem- 
and  ESolving 

a 

an  extension  of  the  classical  planning  paradigm 
a  distinction  between 

to  embrace 

real- 

G.F: Dehng,  S.W  Bennett/Artificiul Intelligence 89 (1997) 173-217 

20.5 

to  define 

planner  adequacy  by  purposeful 

the  goal  in  the  real  world.  We  used  these  concepts 

is  not  a  facet  of  traditional 
the  system’s 

the 
the  planning  bias  of  a  planner  and  argued  that 
facet  of  classical  planning.  We  introduced  permissive  planning 
alteration  of  planner  bias. 
classical  planning,  which  allows  no  formal  connec- 
and  any  real  world.  Permissive  planning 

problem-achieving 
notion  of  planner  adequacy.  We  discussed 
bias 
is  an  inescapable 
as  a  method  of  improving 
This 
tion  between 
necessarily 
that 
real-world  behavior  not  captured  by  the  planner’s  micro-world  definition  can  be  known. 
Thus  permissive  planning  can  be  viewed  as  an  empirically  driven  search  through  a  space 
of  possible  planning 
the  projections  of 
action  sequences  and  their  real-world  effects.  While  adequacy 
planning, 
unchanged. 

is  enhanced  by  permissive 
remain 

behavior  and  the  projection 

component.  For  it  is  only 

the  discrepancy  between 

abilities  of  the  planner 

biases  so  as  to  reduce 

internal  micro-world 

through  observation 

the  micro-world 

an  empirical 

contains 

In  its  ideal  form,  permissive  planning 

is  impossible.  However,  with  modest  constraints, 
is  both  possible  and  tractable.  We  are  able  to  establish  a  slightly 
something 
bounded.  But,  an  algorithm  whose  running 

form  of  tractability.  By  convention 
if  its  growth 

in  computational 

is  polynomially 

complexity, 

that  is  known 
system  as  surely  as  hyper-polynomial 

planning 

in  a  feature 

is  polynomial 

permissive 
strengthened 
is  “tractable” 
time 
implemented 
planning 
to  such  characteristics 
this  concern.  First,  we  can  guarantee 
is  independent 
permissive  planning 
results  can  be  realized 

of  the  cardinality 

robotic  planning 

liable 

in  a  real-world  planner. 

to  be  extremely 

large  can  paralyze 

an 

is  the  bias  space.  We  offer  two  points 

growth.  The  one  feature  of  permissive 
to  redress 
complexity  of  permissive  planning 
of  the  bias  space.  Second,  we  cite  an  implemented 
system  as  an  existence  proof  that  the  theoretical 

the  algorithmic 

We  show 

schematic  planners 

planners  provide  a  convenient  method 

that  schema-based 
In  particular, 

to  realize  bias 
adjustment. 
a 
changing 
schema  results  in  alternation  of  the  planner’s  bias  only  in  the  local  context  of  the  schema. 
among  elements  of  the  bias  space, 
This  yields  a  desirable 
adequacy.  However,  an  important 
a  key  requirement 
topic 
can 
take. 

is  to  investigate  what  other  forms 

exhibit  a  locality  property: 

form  of  interdependence 

the  bias  adjustment 

for  tractably 

for  future 

achieving 

research 

planner 

corollary  of 
is 

Regardless  of  how  the  bias  space  is  realized,  one  somewhat 

surprising 

cease 

planning 

commitment 

for  executing 

is  that  minimal 

plans  may  not  be  desirable.  This 

the  plan  refinement  process  when  all  plan  completions 

is  incompatible  with  permissive  planning. 
is  not.  It  is  the  form  of  the  output  plan  that  causes  difficulty.  These 
the  goal 
into  a  single  action 
ceases 
process  proper.  Thus,  only  a 

permissive 
not  to  say  that  minimal  commitment  planning 
It  most  assuredly 
planners 
[ 14,  17,45,68,75,86]. 
sequence 
and 
portion  of  the  bias 
Any  permissive 
of  a  minimal 
that  portion  of  the  bias  exhibited  by  plan  linearization.  To  remedy 
decisions  must  also  be  subject 
planning-like 
and  potentially 

But  the  planner’s  output  must  be  linearized 
in  most  real-world  domains.  This  is  done  after  planning 
planning 
action  sequence 
planner 

this,  the  linearizing 
to  exert  a  permissive 
the  artificial 
the  two 

control  over  both  the  planner  and  linearizer,  but  this  introduces 

commitment 
in  the  executed 

to  the  planner. 
influence  over 

to  bias  control.  One  might  attempt 

is  not  part  of  the  minimal 

bias  adjustment  between 

is  due 
is  denied 

difficult  complication 

of  coordinating 

commitment 

adjustment 

inherent 

entail 

206 

G.b?  Dehng,  s. W  Bennett/Artificial 

Intelligence 

89  (1997)  173-217 

is  produced. 
is,  in  essence, 
learning 

bias  spaces.  A  preferable 

interacting 
into  the  planner.  The  planner  may  still  employ  minimal  commitment  principles 
planning  decisions,  but  it  would  not  be  allowed 
ordered  action  sequence 

decisions  back 
in  making 
to  cease  making  decisions  until  a  totally 

is  to  put  the  linearization 

solution 

Permissive 

planning 
of  machine 

centrality 
as  planning 
backchaining 

sets  it  apart  from  most  conventional 

an  approach 

to  planning  with  uncertainty.  The 
such 
preimage 

[ 19,31,32], 

approaches 

for  sensing 
[25,42,43  1, and  disjunctive  planning 

decision 

[34,63], 

theoretic  planning 

[ 69,76  J 

Its  close  tie  to  classical  planning  makes  it  quite  different  from  the  reactive  approaches 
[ 8,241.  As  in 
There  are 

and  it  has  little  in  common  with  the  fuzzy  control  approach 

is  done  using  “crisp” 

representations. 

[ 1,29,44], 
conventional 
no  fuzzification 

symbolic  AI,  everything 
or  de-fuzzification 

steps. 

Much  previous 
learning 

research  has  applied  machine 
is  employed 

to  planning.  Usually, 
the  accuracy  of  a  planner’s  mode1  of  the  world. 

techniques 

learning 

includes 

acquiring 

to  improve 

[37,X$79,84], 

or  adjusting 
and  scientific  discovery 

machine 
This 
learning 
projection 
881)  can  be  viewed  as  altering  planner  bias  as  can  some  case-based  approaches 
though 
there  is  no  formal  connection 
central 

This  alters 
rather  than  its  bias.  The  chunking  of  control  knowledge 

in  these  systems 
to  permissive  planning. 

operator  definitions 

[ 13,21,35], 

[62,71]. 

ability 

reinforcement 
the  planner’s 
(e.g.,  [41,50, 
[ 2,331 
is 

to  planner  adequacy,  which 

to  surround 

the  gripper  wider 

is  necessarily  preferable 

(2)  a  single  adjustment 

unmodelable 
several  domain 

are  ( 1)  it  offers  a  forma1  connection 

This  is  not  to  say  that  permissive  planning 

real  world, 
theory  flaws,  for  example 

to  other  uncertainty 
are  different,  each  has  its  strengths  and  weaknesses.  Some 
to  a 
of  the 

strengths  of  permissive  planning 
and  fundamentally 
bias  can  mitigate 

approaches.  The  approaches 
important 
complex 
planning 
system,  opening 
about 
such  as  domain 
the  benefit 
it  preserves 
embody  a  deep  coherence  based  upon  his  own  hard-fought 

its  position,  orientation, 
independence 
from 
the  extensive 
the  representations 

in  the  GRASPER 
the  object  helps  alleviate  uncertainties 
features  of  classical  planning, 
correctness 

and  shape, 
(3)  desirable 
are  retained  as  is 
and  guarantee  of  (ISolve) 
literature  and  prior  research  on  classical  planning, 
(4) 
supplied  by  the  human  domain  expert  which  may  well 
experiences  with  the  world. 
it  requires  a  declar- 
to 

this  adds  a  new  and  potentially 
failures  must  be  experienced, 
costly  real-world 
the  acquired  knowledge  does  not  apply  in  different  contexts.  Unlike  approaches 
to  identify  and 
the  underlying 

ative  treatment  of  planner  bias; 
the  design  of  a  planner, 
and  (3) 
that  refine 
avoid  contexts 
discrepancies.  This  is  the  flip  side  of  advantage 

also  exhibits  some  notable  weaknesses: 

learns 
than  fixing 

permissive  planning 

Permissive  planning 

difficult  dimension 

internal  domain 

representations, 

(2)  potentially 

to  problematic 

that  lead 

(1) 

interactions 

rather 
(2)  above. 
can  be  viewed  as  learning 

In  a  broad  sense,  permissive  planning 

to  begin  with?  The  answer 
to  the  pragmatics  of  the  situation  and  to  empirical 

choosing  actions.  Why  not  simply  build  a  preference 
planner 
sensitive 
cannot  be  properly  specified  without  examining 
workspace  GRASPER 
approaching 

in 
into  the 
It  is 
in  the  world.  These 
in  a  sparse 
its  gripper  as  wide  as  possible  before 
a  target  piece.  In  a  cluttered  workspace,  however,  excessive  opening  may 

to  be  conservative 
choices 

the  real  world.  For  example, 

is  that  being  conservative 

is  context  dependent. 

for  conservative 

is  conservative 

if  it  opens 

tradeoffs 

G.R  DeJong,  XI+?  Bennett/Art$ciul 

Intelligence 

89  (1997)  173-217 

207 

is 
toward 

planning 

permissive 
ing  operator  definitions, 
acceptable  planning 
through 
only 
output  can  be  trusted 
also  the  crucial 
internal 
refining 
Permissive  planning 

faithfulness 

new  collisions  with  other  objects.  To  be  most  conservative 

to 
failures.  Likewise,  closing  more  tightly 
is  low. 

it  learns 

to  open 

in  case  the  believed  coefficient  of  friction 

cause 
an  intermediate 
than  believed  necessary 
But  squeezing  harder  can  be  destructive 

amount  guided  by  the  observed 
is  conservative 

Finally,  we  wish  to  offer  a  more  abstract 

if  the  objects  are  fragile. 
(and  more  speculative) 

approach.  Let  us  consider 
object  descriptions, 
behavior?  For  a  conventional 

the  role  of  the  domain 
etc.  What  kind  of  domain 

planner,  accuracy 

interpretation 
theory, 
theory 
is  paramount. 

of  the 
includ- 
leads  to 
It  is 

of  the  domain 

theory 
to  achieve  what  it  claims 

to  the  external  world  that  the  planner’s 
to  achieve.  Domain 

theory  accuracy 

theory 

theory 

planner 

procedure 

in  crafting 

theory  and 

issue  arises 

are  detected. 

permissive  planning 

is  most  often  directed 

that  would  be  pernicious 

theory  when  discrepancies 

theory 
the  domain 

the  dictates  of  the  domain 

in 
the  domain 

adjustment  may  be  more  desirable 

for  the  domain 
reflect  both 

for  a  permissive  planner?  The  best  domain 

to  represent  object  shapes.  These  are  known 

to  be  used  as  a  guide 
are  employed 

the  permissivized 
affords  a  degree  of  freedom 

to  do.  But  this  no  longer 
to  be  accurate.  The  plans  constructed 

of  the  domain 
this.  The  primary  concern 
it  claims 

issue  for  many  learning  planners.  Learning 
representations 
is  still  that  the  planner’s  out- 
changes 
translates  directly 
put  do  in  the  real  world  what 
by  a 
into  a  requirement 
changes 
permissivized 
in 
to  the  planner’s  bias.  The  permissivization 
theory.  What  makes  a  good 
the  planner’s  behavior  beyond 
that  rc- 
domain 
is  the  one 
theory 
sults  in  the  best  behavior  after  permissive  bias  adjustment.  An  inaccurate  domain 
than  a  more 
that  allows  more  effective  permissive 
little  adjustment.  The  shift  may  seem  small  but 
theory 
accurate  domain 
that  allows 
[ 211.  Correctness 
the  implications 
is  now 
can  be  profound.  A  similar 
but  a  heuristic 
theory.  In  the  GRASPER 
system  simple  polygons 
be  inaccurate 
in  ways 
GRASPER’s 
exhibits  much  more  effective 
complexities 
gether  with  the  conservative 
both  efficient  and  effective 
axioms  can  greatly  simplify 
mentor  shoulders 
In  reality 
their  mutual  negative 
of  inference 
to  anticipate).  Using  permissive  planning, 
tent  inconsistencies, 
planning 
with  gibberish 
kind  of  inconsistencies 
model 
use  in  helping 
expertise 
investigations. 

than  if  it  were  reasoning  about  the  intricate 
to- 
that  is 
less  than  perfect 
implementor.  Without 
it  the  imple- 
a  perfectly  accurate  set  of  axioms. 
so  that 
the  imperfections 
lines 
is  now  forced 
one  can  adopt  domain  axiom  sets  with  la- 
for  adequate 
start 
that  the 
to  sort  things  out.  We  hope 
the  kind  one  tends  to  get  as  the  initial  world 
If  this  is  the  case  permissive  planning  may  be  of  great 
their 
for  later 

in  the  real  world.  This  ability 
the  task  of  the  system 
task  of  producing 

relying  on  empirical 
behavior.  Not  all  types  of  inconsistencies 

to  be  discovered  by  the  anticipated 
the  implementor 

to 
planner.  However, 
representations) 

than  necessary  yield  planning 
to  tolerate 

to  select  preferences 
can  be  tolerated;  one  cannot 

true  silhouettes.  The  simplicity  of  the  data  representations 

language.  But  this  is  as  yet  only  a  hope  and  a  question 

to  understand  what  experts  mean  when  they  are  forced 

to  a  conventional 
the  same  simplified 

that  the  system  will  likely  explore 

from  a  domain  expert. 

and  expect  permissive 

to  spread  and  hide 

bias  to  open  wider 

(which  employs 

this  degenerates 

the  impossible 

final  behavior 

into  a  game 

in  a  formal 

are  unlikely 

of  objects’ 

interactions 

to  express 

refinement 

tolerated 

planning 

include 

(which 

208 

G.F:  DeJung,  S. W  Bennett/Arrificial 

Intelligence 

89  (1997)  173-217 

Acknowledgements 

The  authors  are  indebted 

to  Lenny  Pitt  for  helpful  discussions, 

comments 

for  invaluable 
comments  greatly 
part  by  the  Office  of  Naval  Research  under  grant  NOOO14-94-l-0684. 

on  earlier  drafts,  and 

to  two  anonymous 

improved 

the  clarity  of  presentation.  This  research  was  supported 

to  Renee  Baillargeon 
reviewers  whose 
in 

Appendix  A.  Proofs  of  lemmas  and  theorems 

Lemma  4.  The  simplified formulation  of  ideal permissive  planning  cannot  be  realized. 

problems 

of  simplified 

to  the  user’s 

the  conditions 

ideal  permissive 

according 
the  discrete 

random  variables.  We  can  know 

planning, 
their  characteristics 

Proof,  Under 
independent  Bernoulli 
sampling 
This  is  precisely 
is  any  decision 
the  horizon  N  grows  without  bound.  A  permissive  planning 
procedure  which  after  a  finite  sampling  of  the  two  biases  selects,  once  and  for  all,  the 
better  of  the  two.  This  correspond 
flat  in  N. 
to  a  regret  function 
An  important 
regret  function  grows 
result 
at  least  as  a. 
flat,  no  algorithm  can  realize  simplified  permissive  planning. 

the  biases  are 
only  by 
success  or  failure. 
arms  as 

time  minimax  bandit  problem  with  two  Bernoulli 

Since  no  regret  function  can,  under 

these  conditions,  be  asymptotically 

interest  and  observing 

that  is  asymptotically 

is  that  the  optimal 

from  the  bandit 

algorithm 

literature 

0 

Theorem  3.  Ideal  permissive  planning  cannot  be  realized. 

Proof.  The 
cardinality 
satisfies 
lemma’s 

theorem 

follows  directly 

from  Lemma  4.  By  choosing 

a  bias  space  of 

two,  and  choosing  y  =  /3,  any  ideal  permissive  planning  algorithm  necessarily 
the  more  restrictive  conditions  of  the  lemma.  Since  no  algorithm  can  satisfy  the 
restrictive  conditions, 

the  more  general  case  is  also  impossible 

to  realize. 

0 

Lemma  8.  The  probability  that  a  schema  which  has  adequacy  T,  ESolves  a  random 
problem  of  the  appropriateproblem 

class  is at  least  0,  or  equivalently, 

(T,-/3)/(a-p). 

a  schema  of  adequacy  TO applied 

Proof.  Consider 
priate  class  drawn 
that  such  a  problem 
attempted  by  the  schema,  and  4  be  the  probability 
(1)  can  be  written  as 
The  definition  of  adequacy 

from  the  universe  and  distribution 

to  a  random  problem  of  the  appro- 
of  (1).  Let  r  be  the  probability 

that  it  is  not 
that  it  is  ISolved  but  not  ESolved. 

is  both  ISolved  and  ESolved,  p  be  the  probability 

T,, =  ra  +  p/I  +  qy. 

(Al) 

Suppose 

the  lemma 
w  lc 

is  violated 
can  be  rewritten 

h’  h 

-  P) 

P)/<a 
rcu+p/?+py>ra+(l--r)florqr> 
probabilities 
contradicts 

the  definitional 

exhaust 

for  some  schema.  Then 

for  that  schema 

as  T,  >  rLy +  ( I  -  r)/3.  With 

(I-p-r)P.Butr+p+q=l 

r  < 

(cl  - 
(A.1)  we  have 
becausethese 

the  possible  outcomes.  So  it  must  be  the  case  that  y  >  p.  This 
that  y  6  p  <  0  <  a  proving 

requirement 

the  lemma. 

0 

G.F:  DeJong,  S. W  Bennetf/Art@cial 

Intelligence  89  (1997)  173-217 

209 

Lemma  9.  The  probability 
the  appropriate 

class  is  at  least  0,  or  equivalently, 

that  a  schema  of  adequacy  T,  ISolves  a  random  problem  of 
(T,!  -  B)/(a 

-  B). 

Proof.  This  follows  from  the  proof  of  Lemma  8  which  established 
on  problems 
are  ISolved  without 

regard  to  being  ESolved.  q 

that  are  both  ISolved  and  ESolved.  There  can  be  no  fewer  problems 

this  as  a  lower  bound 
that 

Lemma  10.  Given  an  honest  EBL  schema  acquisition 
schema  application  planner,  A, 
ISolved  by  A  using  a  schema,  SC,  then  SC  is  acquirable  by  L from  P. 

it  is  the  case 

that  if  a  planning  problem  P  can  be 

system,  L,  and  a  conformable 

(Sketch).  We  can 

Proof 
that  can  be  applied  directly,  without  recourse 
planning 

schemata 

think  about  each  schema  as  embodying 

to  searching 

the  constraint 

a  planning 

strategy 
tree.  Acquiring 

through  EBL  can  be  viewed  as  the  process  of 
strategy, 
that  illustrates  an  unknown 

( 1)  observing 
an  instance 
(2)  explaining  why  the  instance  works, 
(3)  abstracting 

away  unneeded  and  easily  rederivable  details  of  the  example 

to  yield 

strategy  suffices 

a  general  characterization 

(by  the  planner  underlying 

of  the  illustrated 
to  solve  a  problem, 

strategy. 
then  some  from-scratch  plan  can  be 
If  a  planning 
the  EBL  component)  which  is  an  example  of  the 
constructed 
strategy.  This  plan,  suitably  explained,  can  therefore  be  generalized  back  into  the  original 
lead  to  other  strategies,  and, 
strategy.  Of  course,  alternate 
from  the  planning  problem 
therefore,  other  schemata.  But  among  the  schemata  acquirable 
this  informal 
must  be  the  originally  postulated 
into  a  proof  is  to  insure  a  tight  fit  between 
the 
argument 
problem 
is 
solution  must  necessarily 
enforced  by  the  honesty  and  conformability 

illustrate  all  facets  of  the  strategy.  This  property 

the  problem  and  the  strategy: 

schema.  The  only  wrinkle 

solutions  might 

in  transforming 

requirements. 

from-scratch 

0 

through  honest  EBL  which 
Lemma  11.  If  a  planner  contains  a  schema,  SC,  acquirable 
has  adequacy  T,  or  higher  for  a  problem  class, 
that  EBL  will  in 
fact  construct  SC  from  an  arbitrary  problem  of  the  appropriate  class  is  at  least  pminO, 
-  P>,  w h ere  0  is  the  normalized  utility  threshold,  a  and  B  are 
factor 
from  Definition  1 and  pin 

is  minimum  schema  probability 

then  the  probability 

or  pti,U, 
-  P>/<a 
adequacy  parameters 
of  the  EBL  system. 

is  at  least 

(TO -  B)/(a 

the  planner  contains  a  schema  of  adequacy  at  least  T,,.  Call  that 
Proof.  By  hypothesis, 
rate  of  SC  over  relevant 
solution 
schema  SC.  From  Lemma  9  the  expected 
problems 
that  each  of  the 
in  principle  give  rise  to  the  acquisition  of  SC  through  honest 
ISolvable  problems  could 
EBL.  Thus, 
in 
fraction  of  problems  of  the  appropriate 
the  expected 
principle  give  rise  to  SC  is  (Z,  -  p)/(  cy -  /3).  F or  us,  the  minimum  probability  with 
which  EBL  produces  a  particular 
that  SC  is  produced  by  EBL  on  a  random  problem  of  the  appropriate 

-  B).  F rom  Lemma  10  we  know 

is  pmin.  Thus,  the  probability 

schema  from  a  problem 

type  is  at  least 

that  could 

ISolve 

class 

pmin(T, 

-  P>/(a 

-PI, 

or  by  the  definition  of  0,  ptinO. 

!I 

210 

G.E  DeJong,  S. W  Bennett/Artijiiciul 

htelligence 

89  (1997)  173-217 

Theorem  13.  Single-schema 
SSPP 

permissive  planning 

is  pelformed 

tractably  by  algorithm 

the  algorithm’s 

that  are  independent 

(1)  it  may  output  A,  failing 

the  inner  loop  is  executed  N  times  drawing  one  problem 

time  com- 
Proof.  The  algorithm  always  halts:  From  the  loop  structure, 
is  0(  KN).  As  many  as  K  problems  are  drawn  in  the  outer  loop.  For  as  many  as 
plexity 
in 
M  (with  M  <  K)  iterations, 
is  bounded  by  K  +  MN.  The  parameters  M, 
each  iteration.  Thus,  the  sample  complexity 
of  the  cardinality  of  the  bias  space 
K,  and  N  are  assigned  values 
in  the  other  relevant  parameters.  There  are  two  ways  the  algorithm  might 
and  polynomial 
to  find  an  adequate  schema  when 
yield  an  incorrect  aswer: 
(whether  or  not  an  adequate 
one  exists  or  (2) 
schema 
one  exists).  The  first  error  is  a  false  negative.  The  second 
It  suffices 
is  a  false  positive. 
to  show  that  Pr(false  negative)  <  6/2  and  Pr(false  positive)  <  6/2.  A  false  positive 
results 
to  be  adequate. 
6;  <  S/2  where  6i  is  the  independent  prob- 
To  avoid  a  false  positive, 
as  adequate.  Thus, 
ability 
to  N 
it  suffices 
sample  problems 
the  variance 
over  a  randomly 
inequality  provides  a  useful 
relation 

test  applies 
is  computed.  Provided 

from  which 
sampled  distribution 

schema  will  be  falsely  confirmed 

if  any  one  of  the  M  hypothesized 

it  may  halt  with  an  inadequate 

that  the  ith  hypothesized 

for  PAC-style  proofs: 

is  finite,  Chebyshev’s 

the  sample  adequacy 

that  Si  6  S/(2M) 

it  suffices  that  c, 

for  each  i.  Each 

is  incorrectly 

its  schema 

schemata 

to  show 

judged 

Pr(lp-_l 

3  A)  <  ~ 

2 
A2N 

(A.21 

where  m  and  g2  are  the  true  mean  and  true  variance 
X,  and  the  symbol  x  represents 
The  relation  quantifies 
the  true  mean. 

respectively  of  a  random  variable 
the  measured  mean  of  N  samples  of  X.  A  is  positive. 
from 

the  probability  of  observing  a  measured  mean  very  different 

Let 
l  SC  be  a  hypothesized 
l  A,Y be  the  computed 
l  A,  be  the  (unknown) 
The  underlying  distribution  of  adequacies 

schema  under  evaluation, 

is  cy, p,  or  y.  So  p2  is  also  finite  and  Chebyshev’s 
of  SC.  For  any  positive  A 

sample  adequacy  of  SC  over  N  random  problems, 

true  adequacy  of  SC  over  the  underlying  distribution. 

is  trinomial:  each  sample  problem  adequacy 
to  the  adequacy 

inequality 

applies 

Pr(IA, 

-  AtI  3  A)  <  3. 

(A.3) 

A  necessary 
sample  adequacy 
adequacy 
sufficient  condition 

and  sufficient 

is  that  its 
threshold  but  its  true 
is  less  than  the  threshold  by  at  least  e:  (A,  >  T,)  A  (AI  <  T,  -  E).  Thus,  a 

to  be  at  least  the  desired  adequacy 

for  SC  to  be  judged 

a  false  positive 

is  measured 

condition 

for  avoiding  a  false  positive 

is  that  for  each  test 

IA,  -  A,1  <  e 

(A.4) 

Chebyshev  provides  a  bound  on  the  probability 

that  inequality 

(A.4) 

is  violated: 

Pr(  lA,s -  AtI  >  E)  <  3. 

G.E:  Dehng,  S. W  Bennett/Art$icral  Intelligence  89  (1997)  173-217 

211 

It  suffices 

to  choose  N  according 

to 

N>M,2(-P) 

/ 

&2S 

to  arise 

schemata) 

The  probability 

of  the  cardinality 
and  that  it  is  polynomially 

is  respected  by  the  algorithm.  N  is  independent 
(the  number  of  entertainable 

which 
space 
the  other  parameters  provided  M  is  likewise  bounded  which  will  be  established 

of  the  bias 
in 
bounded 
shortly. 
of  a  false  negative  must  also  be  bounded  by  S/2.  For  a  false  negative 
the  algorithm 
condition 
there  must  exist  at  least  one  adequate 
claims  none  exists.  There  are  three  ways  the  algorithm  might  result  in  a  false  negative. 
First, 
that  fewer  than  M  can  be 
solved. 
schemata.  Call  this  false  negative 
no  adequate  schema 
is  entertained 
it  is  possible 
to  be  inadequate 
other  ways  a  false  negative  can  occur.  Thus,  we  require 

the  requisite  M  random  hypothesis 
in  case 
type  of  failure  results 
the  A4 hypotheses.  We  call  this  Ff,,2. Finally, 
that  one  or  more  adequate  schemata  are  hypothesized  but  they  are  judged 
tests.  Call  this  failure  Ffn3. There  are  no 

the  K  sampled  problems  may  be  sufficiently  difficult 

In  this  case,  the  algorithm  cannot  construct 

by  the  statistical  adequacy 

failure  Fn,i.  The  second 

schema  but 

among 

that 

Pr(%) 

+Pr(%) 

+Pr(%) 

<  f 

through  EBL,  we  will  be  probabilistically 

to  show  Pr(  Ff,,, )  <  S/6  and  Pr(  Ffn2)  <  6/6  and  Pr(  Ff,3)  6  6/6.  First, 
It  suffices 
we  consider  Ff,l.  We  show  for  the  given  method  of  selecting  K  that  with  probability 
at  least  M  of  the  K  sampled  problems  are  solvable.  Since  every  solvable  problem 
1 -a/6 
yields  a  schema 
the 
requisite  number  of  schemata.  We  assume 
property  of  the  problem.  Provided 
right  ballpark 
reasonable.  Let  us  define  a  new  random  variable  S.  Si  is  1  if  problem 
allowed  and  0  if  it  is  not.  The  mean  of  S,  of  course, 
the  resources 
proportion  of  problems 
even  chance 
good  enough.  We  must 
S/6.  Let  fi  be  the  observed 

to  the  EBL  planner  are  in  the 
seems 
this  assumption 
i  is  solved  within 
is  p,  the  expected 
then  there  is  an 
is  not 
to 

the  chance  of  getting 
solution 

for  the  intrinsic  difficulties  of  the  problem  class, 

that  can  be  solved.  If  we  choose  K  to  be  M/p 

to  entertain 
is  an  independent 

are  solvable.  But  an  even  chance 

fewer  than  M  solvable  problems 

that  at  least  M  of  the  problems 

to  the  true  rate,  p.  We  require 

the  difficulty  of  a  problem 

the  resources  allocated 

rate  corresponding 

guaranteed 

limit 

Pr 

p  -  pr  3  ~ 

Kp  -  M 

K 

(A.5) 

If  we  let  the  number  of  samples  be  K,  define  A  =  (Kp  -  M)/K, 

and  note  that  the 

variance  of  S  is  at  most  1,  then  Chebyshev 

assures  us  that 

(A.61 

212 

G.E  DeJon~, S. W Bennetr/Art$ciul lnrelligence 89 (1997)  173-217 

The  left-hand 

side  of  (A.5) 

is  weaker 

than  that  of  (A.6) 

an  unneeded  bound  on  how  much  higher  the  observed  solution 
true  rate,  p.  We  require  only 
can  choose  K  so  that 

that  the  observed 

since  Chebyshev  provides 
rate,  K,  can  be  than  the 
If  we 

rate  not  often  be  much  smaller. 

1 

<C 

or  K>6pM+3+&JGG 

Kp-M 

2K16 

’ 

G2 

( 

K 

> 

chooses  K  consistent  with 

the  SSPP  algorithm 
the  size  of  the  bias  space  and  polynomial 
appears 
low  probability 

of  Fr”t  again  on  the  tractability  of  M. 

this  bound  which 

of 
in  the  other  parameters.  However,  M  again 
guarantee  a 

is  independent 

linearly.  Thus,  a  tractable  number  of  examples  can  probabilistically 

that  this  probability 

Next  we  turn  to  the  possibility 

that  no  adequate  schema  is  among 

the  M  hypothesized 
though  one  exists.  We  require 
the  bound 
6  6/6.  Let  SC  be  an  adequate  schema.  We  know  an  adequate  schema  exists 
is 
schema 
that  the 

schemata 
Pr(&T) 
or  the  false  negative  condition 
acquired  using  a  randomly 
will  be  the  adequate 
randomly 
Repeated 
M  attempts  all  fail  to  acquire  SC  is  no  greater  than 

schema 
is  not  SC  is  no  greater 
acquired  schemata  are  independent 

could  not  arise.  By  Lemma  11,  if  a  random  schema 

that  the  constructed 
the  probability 

schema  SC  is  at  least  pm;“@.  Conversely, 

events.  Thus,  the  probability 

than  1 -  p,i,(T, 

-  p)/( 

acquired 
randomly 

(Y -  j?). 
that 

sampled  problem, 

the  probability 

also  respect 

_  prnin(Tct -P)  M 

l 

ff-P 

> 

which  we  wish  to  be  bounded  by  S/6.  Solving 

for  M,  this  constraint 

is  met  by 

(A.7) 

M3 

This  establishes 
there 

Finally, 

judged 

the  tractability  of  M  which  was  also  required  previously. 
that  an  entertained 
is  the  possibility 

is  that  a  schema’s 

test  and  is  incorrectly 

the  threshold:  A,  <  A,  -  F.  Again,  a  sufficient  condition 

mation 
and  sufficient  Ffn3  failure  condition 
necessary 
to  be  less  than  the  desired  adequacy 
measured 
E  greater 
than 
this  form  of  false  positive 
condition.  There  we  required  a  sufficiently 
each  test  by  6/(2M). 
The  algorithm  chooses  M  to  be  at  least  3.  Thus,  the  probability 
the  probability 
algorithm  produces 
0 
proof. 

fails  its  confir- 
adequate  schema 
to  be  inadequate.  We  require  Pr(Fr”s)  <  S/6.  A 
is 
is  at  least 
for  avoiding 
the  false  positive  error 
of 
the  error  probability 
the  error  probability  of  each  test  by  S/6. 
for  a  false  negative  and 
than  6/2,  so  the 
the 

(A.4).  This  is  precisely 
large  N  to  bound 

for  a  false  positive  are  each  required 

the  correct  answer  with  probability 

threshold  but  its  true  adequacy 

at  least  1 -  6,  completing 

Here  we  need  to  bound 

sample  adequacy 

to  be  no  greater 

is  inequality 

Theorem  15.  Class-wise  DBI  permissive  planning 
appear  for  each  problem  class  with  some  nonzero 

is  tractable  provided 

that  problems 

lower  bound  probability  p/t,. 

G.E  DeJong,  S. W. Bennett/Artijicinl 

Intelligence  X9  (1997)  173-217 

213 

tractability 

after  consuming 

(Sketch).  Again, 

only  a  polynomial 

that  it  believes  no  adequate 

to  succeed,  a  permissive  planning 

requires 
and  polynomial 

requirements. 
theorem’s  proof 

planner 
for  permissive  planning 

though  none  with  less  than  a  fixed  minimum  probability,  p/b.  Recall 

either  outputs  A,  indicating 
for  the  class,  or  it  adopts  a  single  schema 
Each  such  schema 

Proof 
of  the  bias  space  cardinality 
planner  adds  the  complication 
probabilities, 
the  adequacy  of  a  schema-based 
predefined.  Thus, 
must  terminate 
the  planner 
constructed 
adequacy 
The 
start  C  independent 
of  problems 
correct  with  confidence 
to  meet 
converging 
algorithm 
is  no  worse 
instance’s  complexity 
sample  complexity  by  only  polynomial 
still  plynomially 
algorithm 
to  the  number  of  classes,  C,  and  the  lower  bound  class  probability  occurrence, 

to  be  independent 
the  sample  complexity 
in  the  other  relevant  parameters.  The  DBl 
of  C  classes  whose  problems  may  appear  with  different 
that 
is  by  problem  class,  that  problem  classes  are 
algorithm 
number  of  examples.  For  each  class 
schema  can  be 
the 
to  all  problems  of  its  class. 
13.  For  C  classes,  we  simply 
each  class 
funneling 
algorithms 
instance  of  the  algorithm.  The  planner’s  behavior  must  be 
instance 
is  required 
if  each  algorithm 
rate  of  the  slowest 
bound  6’  =  6/C.  The  convergence 
algorithm.  That 
factor 
that 
the 

factors.  The  sample  complexity  of  the  composite 
it  is,  of  course,  now  sensitive 
bounded, 
,o//~.  0 

the  composite 
inflated  by  a  factor  of  1 /JQ,.  These  alterations 

instance  can  expect  to  see  a  diluted  stream  of  examples  whose  dilution 

from  Theorem 
permissive  planning 

than  P&.  Thus, 
further 

that  probabilistically  meets 

the  tighter  confidence 

instance  determines 

than 
increase 

sample  complexity 

for  the  composite 

follows  directly 

is  then  applied 

to  a  separate 

single-schema 

is  no  worse 

1 -  6.  This 

is  therefore 

is  assured 

the  bound 

algorithm 

though 

Lemma  16.  Let 

no  = 

a-P 
Pmi”(T,,  -PI 

In  L 
0 

71 

Then  with  probability 
single-schema 

permissive  planning 

task. 

1 -v  any  solution 

to  CT(  no)  yields  a  solution  to  the  corresponding 

Proof.  The  derivation  of  this  bound 
probability 
greater 

that  IZO attempts  all  fail  to  acquire 

is  analogous 

to  the  derivation  of  Eq.  (A.7).  The 
the  assumed  adequate  schema  SC  is  no 

than 
_  Pmin(T, -PI  no 
. 

ff-P 

> 

1 

We  are  interested 

in  characterizing 

no  such  that 

which  simplifies 

to 

a-P 

110  3 

pmin(T,-PI 

In 

1 

’ 0 

i 

214 

G.E  DeJong,  S. W. Bennett/Artijicml 

Intelligence  89  (1997)  173-217 

Theorem  17.  The  VC  dimension  of  the  CT(  no)  task  is  no  greater 

than 

Proof.  The  IZO elements 
examples.  By  definition, 
by  the  set  of  hypotheses. 

References 

in  the  hypothesis  concept  can  shatter  a  set  of  at  most  log,  (no) 
is  the  cardinality  of  the  largest  set  shattered 
the  VC  dimension 

0 

] I ]  P.  Agre  and  D.  Chapman,  PENGI:  an  implementation 

of  a  theory  of  activity, 

in:  Proceedings  AAAI-87, 

Seattle,  WA  ( 1987)  268-272. 

] 21  J.  Allen  and  P.  Langley, 

Integrating  memory 

and  search 

in  planning, 

in:  Proceedings  Workshop  on 

Innovutive  Approaches 
[ 31  J.A.  Bather,  The  minimax 
Theory  and  Algorithms 

I-  Il. 
]4]  R.  Bechhofer,  A  single-sample  multiple  decision  procedure 

(Springer,  Bad  Honnef,  1982) 

to  Planning  Scheduling  and  Control,  San  Diego,  CA  ( 1990)  301-3  12. 

risk  for  the  two-armed  bandit  problem, 

in:  Mathematical  Learning  Models: 

for  ranking  means  of  normal  populations 

with  known  variances,  Ann.  Math.  Stat.  25  ( 1954)  16-39. 

15 ]  SW.  Bennett,  Permissive  planning: 

real-world 
domains,  Tech.  Rept.,  Electrical  &  Computer  Engineering  Department,  University  of  Illinois,  Urbana, 
IL  (1993). 
]6]  S.W.  Bennett 

and  CF.  DeJong,  Comparing 

to  the  acquisition 

learning  approach 

to  planning 

in  complex 

increasingly 

a  machine 

stochastic 

planning 

of 

in:  Proceedings  Eighth  International  Coqference 

on 

permissive  plans  for  complex  uncertain  domains, 
IL  ( 1991)  S86-590. 
Machine  Learning,  Evanston, 
learning  of  reactive  action  models, 

Inductive 

17 ]  S.  Benson, 

in:  Proceedings 

of  the  Twelfth  International 

Conjtirence  on  Machine  Leoming,  Tahoe  City,  CA  ( 1995)  47-54. 

[ 8 I  H.  Berenji,  Fuzzy 
Appliuitions 

logic  controllers, 

in:  E.R.  Yager  and  L.  Zadeh,  eds.,  An  fntmduction 

to  Fuzzy  Logic 

in  Intelligent  Systems  (Kluwer  Academic  Publishers,  Dordrecht,  1990)  69-96. 

19 I  D.A.  Berry  and  B.  Fristedt,  Bandit  problems: 

sequential  alloction  of  experiments, 

in:  D.  Cox  et  al.,  eds., 

Monographs  on  Statistics  and  Applied  Probabili@ 

(Chapman 

and  Hall,  London,  1985). 

and  the  Vapnik-Chervoninkis 

dimension,  L  ACM  36  (1990)  929-965. 

to  plausible 

causes:  an  event-based  model  of  belief  update,  ArtijI  Intell.  83 

layered  control  system  for  a  mobile  robot,  IEEE  J.  Rob.  Automut.  2  ( 1986). 

and  Y. Gil,  Learning  by  experimentation: 

the  operator 

refinement  method, 

in:  Y.  Kodratoff 
(Morgan  Kaufmann,  Los 

and  R.  Michalski,  eds.,  Muchine  Learning:  An Artijicial  Intelligence  Approuch 
Altos,  CA,  1990)  191-213. 

for  conjunctive  goals,  Artif 

fntell.  32  (1987)  333-378. 

[ 141  D.  Chapman,  Planning 
I 151  P.  Cheeseman,  Probabilistic 
Artijicicd  Intelligence 
1161  S.  Chien,  M.  Gervasio 

vs.  fuzzy  reasoning, 

in:  L.N.  Kanal  and  J.E  Lemmer,  eds.,  Uncertainty 

in 

(North-Holland,  Amsterdam, 

1986)  85  102. 
to 

uncertain  planning  and  scheduling  problems, 

and  G.F.  DeJong,  Learning 

in 
in:  Proceedings  AA41  Spring  Symposium  Series:  Pructicul 

and  deliberation 

reactiveity 

integrate 

Approuches 

1171  G.  Collins  and  L.  Pryor,  Achieving 

to  Scheduling  and  Planning,  Palo  Alto,  CA  ( 1992)  1 17-  12 1. 
the  functionality 

of  filter  conditions 

in  a  partial  order  planner, 

in: 

Proceedings  AAAI-92,  San  Jose,  CA  (1992)  375-380. 
of  Commonsense  Knowledge 

[ IS]  E.  Davis,  Representations 
1 191  T.A.B.  Dean  and  M.  Lejter,  Planning  and  active  perception, 

(Morgan  Kaufmann,  San  Mateo,  CA,  1990). 

in:  Proceedings  Workshop  on  Innovative 

Approaches 

to  Planning  Scheduling  and  Control  ( 1990)  271-276. 

[ 20  I G.E DeJong,  ed.,  Investiguting  Exphnution-Bused  Learning  (Kluwer  Academic  Publishers,  Boston,  MA, 

1993). 

12 1 ]  CF.  DeJong,  Learning 

to  plan  in  continuous  domains,  Artif:  fntell.  6.5 ( 1994)  71-141. 

] IO]  A.  Blumer  et  al.,  Learnability 
[ 111  C.  Boutilier,  Abduction 
(1996)  143-166. 

1 121  R.  Brooks,  A  robust 
[ 13 1 J.  Carbonell 

1241 

1251 

1261 

1271 

1281 

1291 

1301 

1311 

1321 

1331 

1341 

G.E  DeJong,  S. W. Bennett/Artificial 

Intelligence  R9  (1997)  173-217 

215 

1221 

G.F.  DeJong  and  R.  Mooney,  Explanation-based 

leaming:  an  alternative  view,  Mach.  Learn.  1 (1986) 

1231 

145-176. 
A.  de1  Val  and  Y.  Shoham,  Deriving  properties  of  belief  update  from  theories  of  action, 
AAAI-92,  San  Jose,  CA  (1992)  584-589. 
D.  Driankov,  H.  Hellendoom 

and  M.  Reinfrank.  An  Introduction 

to  Fuzzy  Control 

in:  Proceedings 

(Springer,  Berlin, 

1993). 
M.  Erdmann,  Using  backprojections 

for  fine  motion  planning  with  uncertainty, 

fnt. J.  Rob.  Res.  5  ( 1986) 

19-45. 
P.E.  Friedland,  Knowledge-based 
Science  Department,  Stanford  University,  Stanford,  CA  ( 1979). 
M.R.  Genesereth 

and  N.J.  Nilsson,  Logical  Foundations 

experiment 

design 

in  molecular 

of  Artificial 

genetics,  Tech.  Rept.,  Computer 

Intelligence 

(Morgan  Kaufmann. 

Palo  Alto,  CA,  1986). 
Y.  Gil,  Learning 
Proceedings 

Eleventh 

by  experimentation: 
International 

incremental 

refinement 

Conference  on  Machine 

of 

incomplete 

in: 
Learning,  New  Brunswick,  NJ  ( 1994) 

domains, 

planning 

87-95. 
D.  Gordon,  An  enhancer 

for  reactive  plans,  in:  Proceedings  Eighth 

International 

Conference  on  Machine 

approach 

to  adaptive  problem  solving,  Artif: 

Intel/. 

(to 

Ithaca,  NY  ( 1991)  505-508. 

Learning, 
J.  Gratch  and  G.F.  DeJong,  A  decision-theoretic 
appear). 
P.  Haddawy 

and  S.  Hanks,  Representations 

International 
(1992)  71-82. 
I?  Haddawy 
Proceedings  Second 

(1994)  266-271. 
K.  Hammond,  T.  Converse  and  C.  Martin, 
in:  Proceedings  AAAI-90,  Boston,  MA  ( 1990)  292-297. 
S.A.  Hutchinson 
environments,  AI  Magazine  11 ( 1990) 30-6 I. 

Conference  on  Principles 

of  Knowledge  Representation 

for  decision-theoretic 

in:  Proceedings 
planning, 
Third 
and  Reasoning,  Cambridge,  MA 

and  M.  Suwandi,  Decision-theoretic 

refinement  planning  using  inheritance 

International 

Conference  on  Artificial 

Intelligence 

abstractions, 
Planning  Systems,  Chicago. 

in: 
IL 

Integrating  planning  and  acting 

in  a  case-based 

framework, 

and  A.C.  Kak,  Spar:  a  planner  that  satisfies  operational  and  geometric  goals  in  uncertain 

135 1 CM.  Kadie,  Continuous 

conceptual 

set  covering: 

learning  robot  operators 

from  examples, 

in:  Proceedings 

Eighth 

International 
136  1 L.P.  Kaelbling,  An  architecture 

Conference  on  Machine  Learning, 
for  intelligent 

About  Actions  and  Plans,  Timberline,  OR  ( 1986)  395-4  IO. 

Ithaca,  NY  ( 199 I ) 6 I S-61  9. 

reactive  systems, 

in:  Proceedings  Workshop  on  Reasoning 

[ 37  1 L.  Kaelbling,  Learning 
On 
I38  1 S.  Kambhampati, 
commitment 
in  partial-order 
I39  1 S.  Kambhampati 

Art{fi 

Intell.  55  (1992) 

193-258. 

to  achieve  goals, 
the  utility  of  systematicity: 

in:  Proceedings 

IJCAI-93,  Chambery 

understanding 

tradeoffs  between 

and 

( 1993)  1094-1098. 
redundancy 
( 1993)  1380-  1385. 

planning, 

in:  Proceedings 

IJCAI-93,  Chambery 

and  J.  Hendler,  A  validation-structure-based 

theory  of  plan  modification 

and  reuse, 

140  1 H.  Katsuno  and  A.  Mendelzon,  On  the  difference  between  updating  a  knowledge  database  and  revising 
and 

of  Knowledge  Representation 

Conference  on  Principles 

it,  in:  Proceedings  Second 
Reasoning,  Cambridge,  MA  ( 1991)  387-394. 
J.  Laird,  A.  Newell  and  P  Rosenbloom,  SOAR:  an  architecture 

International 

for  general 

intelligence,  Art$ 

Intell.  33 

l-64. 

(1987) 
J.-C.  Latombe.  Robot  Motion  Planning 
T.  Lozano-Perez,  M.T.  Mason  and  R.H.  Taylor,  Automatic 

(Kluwer  Academic  Publishers,  Boston,  MA,  I991  ). 
strategies 

synthesis  of  fine-motion 

for  robots, 

Int.  J.  Rob.  Res.  3  (  1984)  3-24. 

P.  Maes  and  R.A.  Brooks,  Learning 
( 1990)  796-802. 

to  coordinate 

behaviors, 

in:  Proceedings  AAAI-90,  Boston,  MA 

145  1 D.  McAllester.  Systematic  nonlinear  planning, 
I46  1 J.  McCarthy,  Circumscription-a 
I47  I  D.  McDermott,  Robot  planning,  AI  Magazine  13  ( 1992)  ~5.5-79. 
[ 48  I  R.S.  Michalski,  Understanding 

form  of  non-monotonic 

the  nature  of  learning: 

in:  Proceedings  AAAI-91,  Anaheim,  CA  ( 199 I ) 634-639. 

reasoning,  Arti$ 

Intell.  13  ( 1980)  27-39. 

issues  and  research  directions, 

Intelligence  Approach 

in:  R.S.  Michalski, 
(Morgan 

J.G.  Carbonell  and  T.M.  Mitchell,  eds.,  Machine  Learning:  An  Artificial 
Kaufmann,  Los  Altos,  CA,  1986)  3-26. 

141 

142 
143 

144 

in  the  PRODIGY 
Irvine,  CA  ( 1987) 

216 

G. F: DeJong,  S. W  Bennett/Art$cial 

Intelligence  89  (1997)  173-217 

1491  D.P  Miller  et  al.,  Reactive  navigation 

through 

rough 

terrain:  experimental 

results, 

in:  Proceedings 

AAAI-92,  San  Jose,  CA  ( 1992)  823-828. 

1501  S.  Minton,  Learning  Search  Control  Knowledge:  An  Explanation-Based  Approach  (Kluwer  Academic 

Publishers,  Norwell,  MA,  1988). 

[ 51  1 S.  Minton,  J.  Bresina  and  M.  Drummond,  Commitment 
in:  Proceedings  AAAI-91,  Anaheim,  CA  ( 199 1). 

strategies 

in  planning:  a  comparative 

analysis, 

[ 52  1 S.  Minton  et  al.,  Acquiring 

effective  search  control 

rules:  explanation-based 

learning 

in:  Proceedings  Fourth  International  Conference  on  Machine  Learning, 

system, 
122-133. 

153 1 T.M.  Mitchell,  Generalization 
1541  T.M.  Mitchell,  Becoming 

as  search,  Artif:  Intell.  18  ( 1982)  203-226. 

increasingly 

reactive, 

in:  Proceedings  AAAI-90,  Boston,  MA  ( 1990)  1051- 

1058. 

I55  1 T.  Mitchell,  R.  Keller  and  S.  Kedar-Cabelli,  Explanation-based 

generalization: 

a  unifying  view,  Mach. 

Learn.  1  (1986)  47-80. 

[ 561  R.J.  Mooney,  A  General  Explanation-Based  Learning  Mechanism  and  its  Application  to  Narrative 

Understanding  (Pitman,  London,  1990). 

[ 57  1 R.J.  Mooney  and  S.W.  Bennett,  A  domain 
PA  ( 1986)  551-555. 

AAAI-86,  Philadelphia, 

independent 

explanation-based 

generalizer, 

in:  Proceedings 

[ 58  I  A.  Moore,  Variable 

resolution  dynamic  programming: 

in  multivariate 
in:  Proceedings  of  the  Eighth  International  Conference  on  Machine  Learning, 

learning  action  maps 

efficiently 

state-spaces, 

real-valued 
Evanston, 

IL  (1991)  333-337. 

[ 59  1 N.J.  Nilsson,  Principles  of Art$cial  Intelligence  (Tioga,  Palo  Alto,  CA,  1980). 
[ 60  1 N.  Nilsson,  Teleo-reactive 
[ 61  I  B.  Nordhausen 
(1987) 
[ 62  1 B.  Nordhausen 
17-47. 
(1993) 

and  P  Langley,  Towards  an  integrated  discovery 

and  P.  Langley,  An  integrated 

for  agent  control, 

framework 

programs 

198-200. 

system, 

.I. Art$  Intell.  Res.  1  ( 1994)  139-158. 

in:  Proceedings  IJCAI-87,  Milan 

for  empirical  discovery,  Mach.  Learn.  12 

[ 63  1 D.  Olawsky  and  M.  Gini,  Deferred  planning  and  sensor  use,  in:  Proceedings  Workshop on  Innovative 

Approaches  to Planning,  Scheduling  and  Control,  San  Diego,  CA  ( 1990)  166-174. 

I64  I  D.  Ourston  and  R.  Mooney,  Changing 

the  rules:  a  comprehensive 

approach 

to  theory 

refinement, 

in: 

Proceedings  AAAI-90,  Boston,  MA  ( 1990)  8 15-820. 

(65  I  M.J.  Pazzani, 

Integrated 

learning  with  incorrect 

and  incomplete 

theories, 

in:  Proceedings  of  the  Fifth 

International  Conference  on  Machine  Learning,  Ann  Arbor,  MI  ( 1988)  291-297. 

[ 66  1 J.  Pearl,  Probabilistic  Reasoning  in  Intelligent  Systems:  Networks  of  Plausible  Inference 

(Morgan 

Kaufmann,  Los  Altos,  CA,  1988). 

[ 67  1 E.  Pednault,  Generalizing 

nonlinear  planning 

to  handle  complex  goals  and  actions  with  context-dependent 

effects, 
[ 68  1 J.  Penberthy 

in:  Proceedings  IJCAI-91,  Sydney 

( 1991)  240-245. 

and  D.  Weld,  UCPOP:  a  sound,  complete,  partial  order  planner 

for  ADL,  in:  Proceedings 
Third  International  Conference  on  the  Principles  of  Knowledge  Representation  and  Reasoning, 
Cambridge,  MA  (1992) 

103-l  14. 

169 I  M.  Peot  and  D.  Smith,  Conditional  non-linear  planning, 

in:  Proceedings  First  International  Conference 

on  Artificial Intelligence  Planning  Systems  ( 1992)  189-197. 

1701  S.A.  Rajamoney,  A  computational 

eds., 
to  theory 
Computational  Models  of  Scientific  Discovery  and  Theory  Formation  (Lawrence  Earlbaum,  Hillsdale, 
NJ,  1990). 

in:  J.  Shrager  and  P.  Langley, 

approach 

revision, 

[ 7 1 I  S.A.  Rajamoney,  The  design  of  discrimination 
[ 72  1 S.A.  Rajamoney 
problem, 
(1988)  242-255. 

and  G.F.  DeJong,  Active  explanation 

reduction:  an  approach 

to  the  multiple  explanations 

in:  Proceedings  of  the  Fifth  International  Conference  on  Machine  Learning,  Ann  Arbor,  MI 

experiments,  Mach.  Learn.  12  ( 1993)  185-203. 

( 73 ]  D.  Roth,  On  the  hardness  of  approximate 
[ 741  S.  Russell  and  E.  Wefald,  Do  the  Right  Thing  (MIT  Press,  Cambridge,  MA,  1991). 
175 1 E.D.  Sacerdoti,  The  nonlinear  nature  of  plans, 
1761  M.  Schoppers,  Universal  plans  for  reactive  robots  in  unpredictable 

in:  Proceedings  IJCAI-75,  Tblisi  (1975)  206-214. 
environments, 

reasoning,  Artif  Intell.  82  ( 1996)  273-302. 

in:  Proceedings  IJCAI- 

87,  Milan  (1987) 

1039-1046. 

G.E  DeJong,  S.W  Bennett/Artijiclal 

Intelligence  R9  (1997)  173-217 

217 

I77  ]  A.  Segre,  Machine  Learning 

of  Robot  Assembly  Plans 

(Kluwer  Academic  Publishers,  Notwell,  MA, 

1988). 

[ 78  ] J.W.  Shavlik,  Extending  Explanation-Based 

Leoming 

by  Generalizing 

the  Structure  oj  Explanatwns 

(Pitman,  London,  1990). 

[79]  R.  Sutton, 

programming, 

Integrated  architectures 
in:  Proceedings 

for  learning,  planning,  and  reacting  based  on  approximating 

dynamic 
Conference  on  Machine  Learning,  Austin, 

of  the  Seventh 

International 

TX  (1990)  216-224. 

1801  R.  Sutton,  The  challenge  of  reinforcement 
18 11 A.  Tate,  Generating 

project  networks, 

learning,  Mach.  Learn.  8  ( 1992)  225-227. 

in:  J.  Hendler,  A.  Tate  and  J.  Allen,  eds.,  Readings 

in  Planning 

(Morgan  Kaufmann,  Los  Altos,  CA,  1990)  291-296. 

[ 82  1 L.  Valiant,  A  theory  of  the  learnable,  Commun.  ACM  27  (  1984)  1134-I  142. 
approach 
1831  X.  Wang,  Learning 

by  observation 

and  practice: 

incremental 

an 

operator 
Conference  on  Machine  Learning,  Tahoe  City,  CA 

for  planning 

acquisition, 
(1995)  549-557. 

in:  Proceedings 

Twelffh 

Internutioncd 

[ 841  C.  Watkins  and  P  Dayan,  Q-learning,  Mach.  Learn.  8  ( 1992)  279-292. 
[ 851  D.  Weld,  An  introduction 
[ 86  1 D.E.  Wilkins,  Practical  Planning 
[ 87 1 L.  Zadeh,  Commonsense 

to  least  commitment 

and  fuzzy  logic, 

(Morgan  Kaufmann,  San  Mateo,  CA,  1988). 

planning,  AI  Magazine  15 ( 1994)  27-61. 

in:  The  Knowledge  Frontier:  Essays  in  the  Representation 

oj 

Knowledge 

(Springer,  New  York,  1987)  103-136. 

[ 88  I  M.  Zweben,  E.  Davis,  B.  Daun,  E.  Drascher,  M.  Deale  and  M.  Eskey,  Learning 
Intell.  58  ( 1992)  27  I-296. 

based  scheduling,  ArtiJ 

to  improve  constraint- 

