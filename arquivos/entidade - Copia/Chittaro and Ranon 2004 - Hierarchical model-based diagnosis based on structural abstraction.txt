Available online at www.sciencedirect.com

R

Artiﬁcial Intelligence 155 (2004) 147–182

www.elsevier.com/locate/artint

Hierarchical model-based diagnosis based on
structural abstraction

Luca Chittaro ∗, Roberto Ranon

Department of Mathematics and Computer Science, University of Udine, via delle Scienze 206,
33100 Udine, Italy

Received 9 December 2002; received in revised form 20 June 2003

Abstract

Abstraction has been advocated as one of the main remedies for the computational complexity
of model-based diagnosis. However, after the seminal work published in the early nineties, little
research has been devoted to this topic. In this paper, we consider one of the types of abstraction
commonly used in diagnosis, i.e., structural abstraction, investigating it both from a theoretical
and practical point of view. First, we provide a new formalization for structural abstraction that
generalizes and extends previous ones. Then, we present two new different techniques for model-
based diagnosis that automatically derive easier-to-diagnose versions of a (hierarchical) diagnosis
problem on the basis of the available observations. The two proposed techniques are formulated
as extensions of the well-known Mozetic’s algorithm [I. Mozetic, Hierarchical diagnosis, in:
W.H.L. Console, J. de Kleer (Eds.), Readings in Model-Based Diagnosis, Morgan Kaufmann, San
Mateo, CA, 1992, pp. 354–372], and experimentally contrasted with it to evaluate the obtained
efﬁciency gains.
 2003 Elsevier B.V. All rights reserved.

Keywords: Model-based diagnosis; Abstraction; Hierarchical reasoning

1. Introduction

In the last decade, Model-Based Diagnosis (MBD) [4,6,9,18] has been a very active area
of research in Artiﬁcial Intelligence that has led also to signiﬁcant industrial projects (e.g.,
[16,20,22]).

* Corresponding author.

E-mail addresses: chittaro@dimi.uniud.it (L. Chittaro), ranon@dimi.uniud.it (R. Ranon).

0004-3702/$ – see front matter  2003 Elsevier B.V. All rights reserved.
doi:10.1016/j.artint.2003.06.003

148

L. Chittaro, R. Ranon / Artiﬁcial Intelligence 155 (2004) 147–182

Computational complexity of multiple fault diagnosis is one of the well-known

problems that needs to be tackled in order to deploy real-world applications of MBD.

Since the late eighties, some researchers (e.g., [10,12,14,19]) advocated abstraction
as one of the main remedies for this problem. The proposed approaches are typically
hierarchical: they represent the problem at multiple levels of detail, and then isolate faults
one level at a time, starting at the most abstract possible level and using the results at one
level to focus reasoning at more detailed levels, thus reducing the overall computational
cost of diagnosis.

Two kind of abstractions are commonly employed in MBD: structural abstraction [5,
10], which aggregates components to describe the system at different levels of structural
detail, and behavioral abstraction [12,14,19], which applies simpliﬁcation operators to
describe the system at different levels of behavioral detail (e.g., moving from quantitative
to qualitative values in describing the functioning of components).

In this paper, we build on seminal work on abstraction in MBD, and investigate

structural abstraction both from a theoretical and practical point of view.

First, we provide a new logical formalization for structural abstraction that generalizes
and extends previous ones [1,14,19]. Our proposal builds on the well-known consistency-
based theory of diagnosis [8] and on a general framework (the semantic theory of
abstraction [15]) for the representation of abstraction between ﬁrst-order theories. Unlike
previous formalizations of structural abstraction, our proposal allows one to represent
components with multiple behavioral modes (e.g., valves). Thus, it can be employed
with a wider class of physical systems. Moreover, the proposed formalization allows
one to easily prove some properties of structural abstraction that are useful in diagnostic
reasoning.

Second, we present two new techniques for hierarchical model-based diagnosis that are
able to automatically derive easier-to-diagnose versions of a given diagnosis problem on
the basis of the available observations. The goal of our research is to move from simply
using abstraction in diagnosis to using a good abstraction for the situation at hand, i.e.,
using context to choose it. Indeed, one limit to the effectiveness of current approaches
to hierarchical diagnosis is the fact that a single, pre-set hierarchical representation is
employed, regardless of the currently available diagnostic information. In some cases, this
leads to suboptimal or even counterproductive results in terms of efﬁciency (some detailed
examples will be illustrated in the paper). Unfortunately, most abstractions are usually
manually engineered, and thus building a suitable abstract system representation for each
diagnostic scenario is not a viable solution. We tackle the problem by using the idea of
automatically tailoring an existing multi-level abstraction hierarchy (that may come from
design) to the particular problem at hand. The two techniques (called REARRANGE and
BOTTOM-UP) we developed for this purpose:

• are based on different strategies, and can be easily combined together to sum up their

respective advantages;

• build on the seminal work on hierarchical diagnosis by Mozetic [14], and are presented

as extensions to that approach.

L. Chittaro, R. Ranon / Artiﬁcial Intelligence 155 (2004) 147–182

149

To evaluate the efﬁciency gains that can be obtained, we present a detailed experimental
evaluation using a set of different hydraulic systems, considering the original Mozetic’s
approach, the two techniques in isolation, and the two techniques in combination.

The techniques presented in the paper are general, and can be easily adopted by any
model-based approach that follows the widely adopted consistency-based paradigm. The
paper illustrates in detail the algorithms that implement the proposed techniques to allow
interested readers to easily include them and experiment with them in their systems.

Finally, this work builds also on previous approaches we proposed in the domain of
Flow-Based Functional Models [3,17] and, more generally, in the context of structural
abstraction [2]. This paper extends and improves the latter in several directions, in
particular:

• it proposes a proper theoretical framework, i.e., the formalization for structural

abstraction mentioned above;

• it discusses (using also detailed examples) why using the same hierarchical represen-
tation regardless of the currently available diagnostic information can limit or even
eliminate the efﬁciency gains of abstraction;

• it reﬁnes the REARRANGE technique and proposes a new technique for hierarchical

diagnosis (i.e., the BOTTOM-UP technique);

• it presents a detailed experimental comparison of the proposed techniques and the

reference approach of Mozetic.

The paper is structured as follows: Section 2 summarizes background work on which we
build; Section 3 deﬁnes a formalization of structural abstraction in diagnosis and illustrates
its properties, discussing also related work; Section 4 considers the problem of diagnostic
reasoning with structural abstraction by illustrating the state of the art, proposing methods
to improve it by automatically tailoring existing abstractions to the situation at hand, and
ﬁnally illustrating the experimental activity that has been carried out. Section 5 concludes
the paper by presenting some possibilities for further work.

2. Background

In this section, we brieﬂy illustrate those aspects of the consistency-based theory of
diagnosis [8] and the semantic theory of abstraction [15] that are relevant to illustrate
our work, and add some minor extensions to them. Moreover, we clarify the concepts
by introducing detailed examples taken from the hydraulic domain that will be followed
throughout the paper.

2.1. Representing diagnosis problems

Following [8], a diagnosis problem D in a language L is deﬁned as a triple (SD, OBS,
COMPS) where SD and OBS are ﬁrst-order theories in language L, representing the system
description and observations, respectively, and COMPS is a subset of the object constants
of L, i.e., the names of the system components.

150

L. Chittaro, R. Ranon / Artiﬁcial Intelligence 155 (2004) 147–182

In order to explicitly separate structural knowledge (i.e., how components are connected
together) from behavioral knowledge (i.e., how components behave), we divide SD in the
following way:

SD = CD ∪ BD ∪ Γ

where BD (behavioral description) represents the behavior of the components in the
system, CD (compositional description) represents the structure of the system, and Γ
represents general knowledge (e.g., hydraulic laws) that is not speciﬁc to the considered
system.1

Deﬁnition 1 (behavioral description of a component). The behavioral description of a
component c (denoted BDc) in a diagnosis problem D, is a set of sentences of the form

(cid:1)
m(c) ⊃ σc( (cid:5)zc)

(cid:2)

Tc(c, (cid:5)zc) ⊃

where

• Tc(c, (cid:5)zc) is the component type predicate for c, and (cid:5)zc lists the ports of the component,
• m is a predicate identifying one of the behavioral modes of c,
• σc( (cid:5)zc) is a ﬁrst-order formula with free variables (cid:5)zc describing the behavioral mode m

of c with respect to its ports.

The behavior of a component is thus represented as a set of ﬁrst-order sentences, each
one corresponding either to a normal or a faulty behavior, which is deﬁned by a predicate
over the component ports.

Deﬁnition 2 (behavioral description). The behavioral description BD of a diagnosis
problem D is the union of the behavioral descriptions of the components in COMPS.

Deﬁnition 3 (compositional description). The compositional description CD of a diagnosis
problem D = (SD, OBS, COMPS) is a ﬁrst-order sentence of the form
(cid:3) (cid:4)

(cid:5)

T (S, (cid:5)zS) ≡ ∃z1, z2, . . . , zn

Tc(c, (cid:5)zc)

where

c∈COMPS

• S is the system’s name,
• every variable in (cid:5)zS appears in one of the tuples (cid:5)zc, for any c ∈ COMPS, and other

variables in the tuples are z1, z2, . . . , zn.

The right-hand part of compositional description CD contains one component type
predicate for each component in the system. A connection between two components is

1 A similar separation of structural and behavioral knowledge was proposed in [1]. Here we extend it to

components with multiple behavioral modes.

L. Chittaro, R. Ranon / Artiﬁcial Intelligence 155 (2004) 147–182

151

represented by using the same variable name for the two connected ports (one belonging to
the ﬁrst component, the other to the second one). The left hand part of CD is composed by
a component type predicate for the whole system, which lists those component ports which
do not connect two components, but connect a component to the system’s environment.

In general, we assume that observations on the system are taken at component’s ports.
We adopt the following standard deﬁnitions employed in consistency-based diagnosis.
Given a diagnosis problem D, a candidate C is a formula that assigns to each component
of D one of its behavioral modes, while a partial candidate is a formula assigning a
behavioral mode only to some components of D. A (partial) candidate C is a (partial)
diagnosis if it is logically consistent with both SD and OBS, i.e., there is an assignment I
of values to the ports of the system such that

I |= SD ∧ OBS ∧ C

In this case, we will call I a model of D; similarly, we will say that D is inconsistent if it
has no models. To solve the diagnosis problem, one should ﬁnd all diagnoses, or a compact
characterization for them (such as the kernel diagnoses described in [8]).

Finally, we will use the notation CANDS(D, B), where B ⊆ COMPS, to denote the set
of all (partial) candidates for the diagnosis problem D that can be built using all and only
the components in set B. The cardinality of CANDS(D, COMPS) depends both on the
cardinality of COMPS, and on the number of possible behavioral modes which are deﬁned
for the components in BD. If a component ci of a diagnosis problem has Mi possible
behavioral modes, then

(cid:6)
(cid:6)CANDS(D, COMPS)

(cid:6)
(cid:6) =

(cid:7)

Mi

ci ∈COMPS

resulting in a number of candidates which is exponential in |COMPS|. Considering the
simplest case where each component has only two behavioral modes (ok and faulty), the
number of candidates is 2n, where n is the number of components. More realistic cases
(where there are more than two modes) will lead to larger cardinalities.

Example 1. The simple hydraulic system depicted in Fig. 1, called hydraulic case study
(hcs) hereinafter, contains 11 components: a volumetric pump pm (delivering a constant
ﬂow equal to FK ), pipes p1, p2, p3, p4, p5, p6, valves v1 and v2, and three-way nodes n1
and n2. The ports in the system are: t1, . . . , t13 (connecting components together), sv1 and
sv2 (allowing one to set the state—open or closed—of valves v1 and v2, respectively).

We suppose that each component has one ok behavioral mode, which represents its
normal behavior. The considered faults are: external leaks (denoted by the predicate leak),
which affect pumps, pipes, and valves; stuck-at-closed and stuck-at-open faults (denoted by
the predicates stuckC and stuckO, respectively), which affect valves; low or high delivered
ﬂowrates (denoted by the predicates loF and hiF), which affect pumps.

The behavioral descriptions of the components are given in Table 1. For simplicity, we
suppose that three-way nodes cannot be faulty, i.e., they have only a normal behavioral
mode. Moreover, we consider two component types: one for three-way nodes with one
intended input and two outputs, called twoOut, and one for three-way nodes with two
intended inputs and one output, called twoIn.

152

L. Chittaro, R. Ranon / Artiﬁcial Intelligence 155 (2004) 147–182

Fig. 1. Layout of the hydraulic case study (component names are shown in bold).

Table 1
Behavioral descriptions for components in the hcs

Component

pump

Type predicate
pump(x, [in, out])

pipe

valve

pipe(x, [in, out])

valve(x, [s, in, out])

three-way node

twoOut(x, [in, out1, out2])
twoIn(x, [in1, in2, out])

Behavioral modes
ok(x) ⊃ in = out = FK
leak(x) ⊃ in > out
loF(x) ⊃ in = out < FK
hiF(x) ⊃ in = out > FK
ok(x) ⊃ in = out
leak(x) ⊃ in > out
ok(x) ⊃ [(s = closed ∧ in = out = 0) ∨ (s = open ∧ in = out)]
leak(x) ⊃ in > out
stuckO(x) ⊃ (s = closed ∧ in = out > 0)
stuckC(x) ⊃ (s = open ∧ in = out = 0)
ok(x) ⊃ in = out1 + out2
ok(x) ⊃ in1 + in2 = out

The compositional description CD for the hcs is the following formula:

(cid:1)

(cid:8)
hcs, [t1, t13, sv1, sv2
hydSystem

(cid:9)

]

≡ ∃t2, . . . , t12

pump( pm, [t1, t2]) ∧
pipe(p1, [t2, t3]) ∧ twoOut(n1, [t3, t4, t5]) ∧ pipe(p2, [t4, t6]) ∧
pipe(p3, [t5, t7]) ∧ valve(v1, [sv1, t6, t8]) ∧ valve(v2, [sv2, t7, t9]) ∧
pipe(p4, [t8, t10]) ∧ pipe(p5, [t9, t11]) ∧ twoIn(n2, [t10, t11, t12]) ∧
pipe(p6, [t12, t13])

(cid:2)

Finally, for this system, |CANDS(D, COMPS)| = 4 · 26 · 42 = 4096.

L. Chittaro, R. Ranon / Artiﬁcial Intelligence 155 (2004) 147–182

153

2.2. Representing abstraction

We adopt the semantic theory of abstraction [15], viewing abstractions as model level
mappings. From this perspective, abstracting a theory is a two-step process that ﬁrst
abstracts the intended domain model, and then builds an abstract theory to capture the
abstracted domain model. Although there are also other theories that could be used for our
purposes (see, e.g., [11]), the theory we adopt has the advantage of explicitly representing
the motivation and choices behind a given abstraction.

More formally, given U0 and U1, sets of sentences2 in languages L0 and L1, then
an abstraction mapping π is a function that maps models of a (base) theory U0 to
corresponding interpretations of an (abstract) language L1:

π : Models(U0) → Interpretations(L1)

Given any model M0 of U0, π builds the interpretation π(M0) for L1 by deﬁning:

• a formula π∀ (with one free variable, x1), that deﬁnes the abstract universe;
• for each n-ary relation R in L1, a formula πR ∈ L0 with n free variables x1, . . . , xn,
that deﬁnes R. Given any model M0 of U0, πR deﬁnes an n-ary relation in M0. The
denotation of R in π(M0) is πR restricted to the universe of π(M0);

• similar formulas to specify the denotation of abstract object and function constants

(see [15] for more details).

U1 is an abstraction of U0, given the abstraction mapping π , if and only if U1 captures all
the abstract models (with respect to π ) of U0. This is captured by the deﬁnition of model
increasing (MI) abstractions:

Deﬁnition 4 (model increasing abstraction). Let U0 and U1 be sets of sentences in
languages L0 and L1, respectively. Let π : Models(U0) → Interpretations(L1) be an
abstraction mapping. U1 is a Model Increasing (MI) Abstraction of U0 with respect to
π (written U1 <π U0) if for every model M0 of U0, π(M0) is a model of U1.

MI abstractions cover various common model level abstractions, such as taking the

union of a set of predicates (see [15] for examples of other MI abstractions).

Example 2. Consider the behavioral description for a valve that has been given in Example
1. Suppose that we want to build a more abstract description where we want to represent
only two fault modes instead of three: one ( faultyO), covers all the faults in the open state,
and the other ( faultyC), covers all the faults in the closed state, i.e.:

(cid:8)
valve
(cid:8)
valve

x, [s, in, out]
x, [s, in, out]

(cid:1)

(cid:1)

(cid:9)

(cid:9)

⊃

⊃

faultyO(x) ⊃ (s = open) ∧ (in > out ∨ in = out = 0)
faultyC(x) ⊃ (s = closed) ∧ (in (cid:20)= 0 ∨ out (cid:20)= 0)

(cid:2)

(cid:2)

,

2 We adopt the convention of using a greater subscript to indicate a more abstract, simpler theory.

154

L. Chittaro, R. Ranon / Artiﬁcial Intelligence 155 (2004) 147–182

The abstraction mapping we must adopt is such that the denotation of predicate faultyO(x)
is the union of the denotations of predicates leak (restricted to the cases where s = open)
and stuckC, while the denotation of predicate faultyC(x) is the union of the denotations of
predicates leak (restricted to the cases where s = closed) and stuckO of Example 1, i.e.,
(cid:9)
(cid:8)
faultyO(x) ≡π s = open ∧
leak(x) ∨ stuckC(x)
,
(cid:9)
faultyC(x) ≡π s = closed ∧ (leak(x) ∨ stuckO(x)

Other kind of abstractions, which are not MI, but can be useful in reasoning, can be
viewed as MI abstractions in conjunction with simplifying assumptions [15], i.e., U1 is a
MI abstraction of U0 under simplifying assumption A if there is a theory UA ⊆ U0 such
that UA is consistent with A and U1 is a MI abstraction of UA ∪ A.

We are interested in the following properties of MI abstractions (see [15] for more

details):

Proposition 1. Let U1 be a MI abstraction of U0. If U1 is inconsistent, then U0 is
inconsistent.

Proposition 1 implies that to prove the inconsistency of a base theory, it sufﬁces to prove
the inconsistency of a (potentially simpler) MI abstraction of that theory (in general, the
converse does not hold).

Proposition 2. Let U1 be a MI abstraction of U0 and V1 be a MI abstraction of V0 under
the same interpretation mapping π . Then U1 ∪ V1 is a MI abstraction of U0 ∪ V0 under π .

Proposition 2 implies that MI abstractions are compositional, allowing one to build

abstract theories by composing knowledge from different sources.

3. Formalizing structural abstraction

In this section, we propose a formalization for the concept of structural abstraction in
diagnosis. We will deﬁne the structural abstraction of a diagnosis problem D as a (more
abstract) diagnosis problem whose components are: (i) some new (super)components, each
one representing the aggregation of a set of connected components of D, and (ii) the
components of D which are not involved in the aggregations. Following the approach of
the semantic theory of abstraction, we will ﬁrst deﬁne a proper interpretation mapping,
i.e., an interpretation mapping that encodes the aggregation of structure and behavior of
components at the model level, and then deﬁne the structural abstraction of a diagnosis
problem with respect to that interpretation mapping.

As we will see, structural abstraction is a MI abstraction. This will allow us to formalize
a correspondence between the solutions of a diagnosis problem and the solutions of
its structural abstraction. This correspondence will be the basis for the exploitation of
structural abstraction in diagnostic reasoning.

At the end of this section, we include a comparison with previous formalizations of

structural abstraction and highlight relations and improvements.

L. Chittaro, R. Ranon / Artiﬁcial Intelligence 155 (2004) 147–182

155

3.1. Informal deﬁnitions and assumptions

Suppose we are given a diagnosis problem D0, and we want to build a more abstract
version of it D1, in which a single (super)component, called sc, replaces a set AGGR of
connected components of D0.

A ﬁrst desirable requirement is that the parts of D0 which do not refer to the components

in AGGR remain identical in D1. Thus, in general, we want that:

• COMPS1 is composed by sc and those components of COMPS0 that do not belong to

AGGR;

• the behavioral descriptions BD1 of D1 is composed by the behavioral descriptions
(which are the same as in D0) of the components that do not belong to AGGR, and a
behavioral description of sc (which must be provided);

• the compositional description CD1 of D1 connects the components that do not belong

to AGGR as they are connected in CD0 of D0;

• OBS1 contains those observations in OBS0 that refer to components that do not belong

to AGGR.

Moreover, we want to deﬁne a relation between the representation of sc and the
representation of the components in AGGR, which can be then exploited in diagnosis
(e.g., knowing that sc is faulty in some way, we want to make hypotheses on the faults
in its subcomponents). We break down this requirement into three parts, which separately
consider the behavioral description, the structural description, and the observations.

With respect to the behavioral description, we want each behavioral mode of sc to
correspond to (more precisely, to be an abstraction of) a set of combinations of behavioral
modes of its subcomponents. This denotes the fact that, in real systems, we can know
what a supercomponent is doing by checking what the subcomponents are doing, and then
composing their behaviors.

(cid:10)

x∈AGGR mi(x) (where each mi

The fact that the components in AGGR are behaving in a certain way can be expressed
by the formula
is a proper mode of the behavioral
description of x), i.e., a partial candidate for the components in AGGR. The set of all
possible combinations of behaviors for the components belonging to AGGR is the set
CANDS(D0, AGGR). We then create a number of sets of partial candidates BM1, . . . , BMl
that partition the set CANDS(D0, AGGR), in such a way that each BMi corresponds
to a behavioral mode for the supercomponent, i.e., the supercomponent is in a certain
behavioral mode only if its subcomponents behave consistently with at least one of the
partial candidates in the corresponding BMi set.

From the structural point of view, since the supercomponent is supposed to replace the
components in AGGR, the ports of the supercomponent will be all and only the ports of the
components in AGGR that connect them to other components not in AGGR, i.e., the ports
(cid:5)zsc of the subsystem whose compositional description is

T (sc, (cid:5)zsc) ≡

(cid:4)

c∈AGGR

Tc(c, (cid:5)zc)

156

L. Chittaro, R. Ranon / Artiﬁcial Intelligence 155 (2004) 147–182

where T will be the type of supercomponent sc. The ports that are internal to the subsystem
which is aggregated will be then neglected in the abstraction.

Finally, since the internal ports of the subsystem which is aggregated are not present in

D1, observations concerning them will not be included in OBS1.

3.2. Formal deﬁnitions

We now formally express the above illustrated requirements using the semantic theory
of Nayak and Levy, i.e., using interpretation mappings to perform the aggregation at the
model level. We begin by deﬁning a basic structural abstraction that aggregates one set
of connected components into a supercomponent, and then consider the general case,
where more aggregations can be performed. The following deﬁnition characterizes the
interpretation mappings for structural abstraction.

Deﬁnition 5 (interpretation mapping for structural abstraction). Let D0 = (SD0, OBS0,
COMPS0) be a diagnosis problem in language L0. Let SA = (cid:21)AGGR, BM1, . . . , BMk(cid:22) be a
tuple of non-empty sets such that

• AGGR ⊆ COMPS0 and |AGGR| = k,
• the sets BMi are a partition of the set CANDS(D0, AGGR).

Let L1 be the language that will be used to deﬁne the abstract diagnosis problem. L1
includes sc, the name of the supercomponent that will result from the aggregation of the
components in AGGR, Tsc, its type predicate, and m1, . . . , mk the predicates identifying its
behavioral modes.

Let πSA : Models(D0) → Interpretations(L1) be an interpretation mapping for which

πSA∀ ≡ (x1 = x1). π is an interpretation mapping for structural abstraction of D0 if:

• Tsc(sc, (cid:5)zsc) ≡πSA
∃w1, . . . , wn(
(cid:11)
• mi(sc, (cid:5)z) ≡πSA
pc∈BMi
• in any other case, πSA is the identity function.

pc, i = 1, . . . , k,

c∈AGGR Tc(c, (cid:5)zc)),

(cid:10)

The interpretation mapping πSA does not change the domains in which the system
operates3 (e.g., real numbers for ﬂows in the hydraulic domain, or binary quantities for
electronic systems).

The ﬁrst requirement states that the denotation of the type predicate of sc is the
restriction, in the abstract universe, of the compositional description of the subsystem
that is aggregated. This establishes a link between a supercomponent and its underlying
structure.

The second requirement states that the denotation of a given behavioral mode of sc is
the restriction in the abstract universe of the disjunction of the partial candidates contained

3 Changing them would require a behavioral abstraction.

L. Chittaro, R. Ranon / Artiﬁcial Intelligence 155 (2004) 147–182

157

in a corresponding BM set. This establishes a link between a set of partial candidates for
the subcomponents, and the behavioral mode of the supercomponent that abstracts them.

Finally, the last requirement says that the denotation of any other object does not change,

i.e., all the parts of D0 which are not involved in the aggregation remain as they are.

As one can notice, such interpretation mapping “encodes” into its deﬁnition the sets
AGGR, BM1, . . . , BMk which are the choices one makes when performing a structural
abstraction in a diagnosis problem.

Given the deﬁnition above, we now deﬁne a basic structural abstraction of a diagnosis

problem.

Deﬁnition 6 (structural abstraction of a diagnosis problem—basic case). Let D0 =
(SD0, OBS0, COMPS0) and D1 = (SD1, OBS1, COMPS1) be two diagnosis problems
in language L0 and L1, respectively, and πSA : Models(D0) → Interpretations(L1) an
interpretation mapping for structural abstraction of D0. D1 is a basic structural abstraction
of D0 with respect to πSA if

• COMPS1 = (COMPS0 − AGGR) ∪ {sc},
• CD1 = T (S, (cid:5)zs ) ≡ ∃z1, . . . , zn(Tsc(sc, (cid:5)zsc) ∧

(cid:10)

c /∈AGGR Tc(c, (cid:5)zc)) where the type

declarations for the components not belonging to AGGR are as in CD0,

(cid:12)

• BD1 = (BD0 −
• OBS1 contains only those observations in OBS0 that refer to ports that are present in

c∈AGGR BDc) ∪ BDsc,

D1.

This deﬁnition speciﬁes how the formulas of D1 should be constructed. D1 contains
sc and all the components of D0 which are not involved in the aggregation. The abstract
compositional description CD1 is obtained by simply removing from CD0 the predicates
that refer to the components in AGGR, and introducing the predicate for sc. Those ports that
are internal to the subsystem AGGR are thus not included in D1. The abstract behavioral
description BD1 contains the behavioral descriptions in BD0 of the components that are
not in AGGR, and the behavioral description of sc. The behavioral description of sc must
satisfy the adopted interpretation mapping πSA, i.e., the relation between behavioral modes
and BMi sets encoded in πSA. Finally, OBS1 is simply a subset of OBS0, omitting the
observations concerning ports that are not present in D1.

Example 3. Consider the diagnosis problem illustrated in Example 1, and suppose we want
to build a structural abstraction by aggregating the components pm and p1 into a single
supercomponent sc, i.e., AGGR = {pm, p1}. We now deﬁne the sets BM1, . . . , BMk which
will correspond to the behavioral modes of sc. Since there are four behavioral modes for
the pump and two behavioral modes for the pipe, there are eight possible partial candidates
for pm and p1, which we group in the following four sets:

(cid:13)

(cid:13)

BM1 =
BM2 =

(cid:14)

,

ok( pm) ∧ ok(p1)
ok( pm) ∧ leak(p1), leak( pm) ∧ ok(p1), leak( pm) ∧ leak(p1),
loF( pm) ∧ leak(p1), hiF( pm) ∧ leak(p1)

(cid:14)
,

158

L. Chittaro, R. Ranon / Artiﬁcial Intelligence 155 (2004) 147–182

(cid:13)

(cid:13)

BM3 =
BM4 =

loF( pm) ∧ ok(p1)
hiF( pm) ∧ ok(p1)

(cid:14)
,
(cid:14)

The ﬁrst set represents a normal behavior; the second set represents all situations where
there is a leak; the third and fourth sets correspond to situations where p1 is normal, and
pm is delivering a wrong amount of ﬂow (low or high, respectively). The four sets will be
abstracted by the behavioral modes of the supercomponent called ok, leak, loF, and hiF,
respectively. By Deﬁnition 5, we construct an interpretation mapping π in which:

ok(sc) ≡π BM1,
leak(sc) ≡π BM2,
loF(sc) ≡π BM3,
hiF(sc) ≡π BM4,
(cid:9)
(cid:8)
sc, [t1, t3]
TYPE

≡π ∃t2

(cid:1)

pump( pm, [t1, t2]) ∧ pipe(p1, [t2, t3])

(cid:2)

In the resulting abstract diagnosis problem, COMPS = {sc, n1, p2, p3, v1, v2, p4, p5,
n2, p6}; the behavioral description is the same given in Example 1, except that the
behavioral descriptions for pm and p1 are omitted, and the behavioral description for sc
is added. Given the adopted interpretation mapping, the type pump can be assigned to sc.
Finally, the abstract compositional description is

]

(cid:9)

(cid:8)
hcs, [t1, t13, sv1, sv2
hydSystem

(cid:1)
pump(sc, [t1, t3)]) ∧
twoOut(n1, [t3, t4, t5]) ∧ pipe(p2, [t4, t6]) ∧ pipe(p3, [t5, t7]) ∧
valve(v1, [sv1, t6, t8]) ∧ valve(v2, [sv2, t7, t9]) ∧ pipe(p4, [t8, t10]) ∧
pipe(p5, [t9, t11]) ∧ twoIn(n2, [t10, t11, t12]) ∧ pipe(p6, [t12, t13])

≡ ∃t3, . . . , t12

(cid:2)

We now deﬁne the general case for structural abstraction, where more than one
basic structural abstractions are applied in order to obtain the desired level of structural
complexity.

Deﬁnition 7 (structural abstraction—general case). Let D0 be a diagnosis problem, D1
and D2 be (basic) structural abstractions of D0 and D1 with interpretation mappings πA
and πB , respectively. Then, D2 is a structural abstraction of D0 with interpretation mapping
πB ◦ πA.

Typically, one might not want to directly abstract a system with many components into a
system with a few or even one component, but rather wants to have more than one different
structural abstractions of the same system, for example to be able to choose a proper level
of detail for reasoning on the situation at hand.

This is usually accomplished by building a multi-level hierarchy of structural abstrac-
tions, i.e., a list of diagnosis problems, each one representing the same system at a dif-
ferent level of detail, with the ﬁrst one (i.e., the bottom level of the hierarchy) being the
most detailed one, and every other (i.e., the other levels of the hierarchy) being a structural
abstraction of the previous one.

L. Chittaro, R. Ranon / Artiﬁcial Intelligence 155 (2004) 147–182

159

Deﬁnition 8 (multi-level hierarchy of structural abstractions). A multi-level hierarchy of
structural abstractions H is an ordered set of q diagnosis problems {(SDi, OBSi, COMPSi)}
with i = 0, . . . , q − 1, where for every j , with j = 0, . . . , q − 2, Dj +1 is a structural ab-
straction of Dj with respect to some interpretation mapping πj .

Example 4. A multi-level hierarchy of structural abstractions organized in six levels for the
hcs is shown in Fig. 2. For each level, the ﬁgure illustrates the layout of the components
and the ports, and highlights the components which have been aggregated.

In particular, in level 1 we aggregated pipe p2 and valve v1 into valve sc1, and pipe p3
and valve v2 into valve sc2. Both aggregations exploit a similar interpretation mapping: in
the case of sc1, the interpretation mapping π is such that (we omit the deﬁnitions of the
BMi sets, which can be derived from the right-hand part of the following sentences):

ok(sc1) ≡π ok(p2) ∧ ok(v1),
leak(sc1) ≡π leak(p2) ∨ leak(v1),
stuckO(sc1) ≡π ok(p2) ∧ stuckO(v1),
stuckC(sc1) ≡π ok(p2) ∧ stuckC(v1)

and TYPE(sc1, [sv1, t4, t8]) ≡π ∃t6[ pipe(p2, [t4, t6]) ∧ valve(v1, [t6, t8])]. In the case of
sc2, the interpretation mapping is the same, but the involved components are p3 and v2.

In level 2, we aggregated valve sc1 and pipe p4 into valve sc3, and valve sc2 and pipe p5
into valve sc4. Both aggregations are performed using an interpretation mapping analogous
to the ones used in the previous level.

In level 3, we aggregated valves sc3, sc4 and three-way nodes n1 and n2 into sc5, which
is a valve with two ports for setting the state (sc5 is closed if and only if both sv1 and sv2
are set to closed), whose component type predicate is valve2.

Its behavioral description is as follows:

(cid:8)
x, [s1, s2, in, out]

(cid:9)

⊃

(cid:1)

valve2

ok(x) ⊃ ((s1 = closed ∧ s2 = closed ∧

in = out = 0) ∨ ((s1 = open ∨ s2 = open) ∧ in = out))
(cid:1)

(cid:9)

(cid:2)

(cid:8)
x, [s1, s2, in, out]
(cid:8)
x, [s1, s2, in, out]

(cid:9)

valve2

valve2

⊃

⊃

(cid:1)

leak(x) ⊃ in > out
stuckO(x) ⊃

,

((s1 = closed ∧ s2 = closed) ∧ in = out > 0)
(cid:9)

(cid:8)
x, [s1, s2, in, out]

⊃

valve2
(cid:1)

stuckC(x) ⊃ ((s1 = open ∨ s2 = open) ∧ in = out = 0)

(cid:2)
,

(cid:2)
,

(cid:2)

In level 4, we aggregated pm and p1 into pump sc6 (using an interpretation mapping
analogous to the one used in Example 3), and sc5 and p6 into sc7 (which is a valve with
two ports for the state as sc5).

Finally, in level 5 we aggregated sc6 and sc7 into sc8, which is basically a pump with
two ports sv1 and sv2 for setting its state, and that delivers a constant ﬂow equal to FK when
at least one port is set to open, and delivers no ﬂow otherwise.

160

L. Chittaro, R. Ranon / Artiﬁcial Intelligence 155 (2004) 147–182

Fig. 2. A hierarchy of structural abstractions of the hcs with 6 levels.

3.3. Properties of structural abstractions

In this section, we examine the properties of structural abstractions that are useful in
diagnosis. In particular, given a diagnosis problem D0 and its structural abstraction D1,

L. Chittaro, R. Ranon / Artiﬁcial Intelligence 155 (2004) 147–182

161

we ﬁrst deﬁne the reﬁnement of a candidate of D1 as any candidate of D0 which makes
consistent predictions at a more detailed level. Then, we prove that structural abstractions
are MI abstractions, and consequently have the properties illustrated in Section 2. Using
these properties, we can prove that if a candidate of any structural abstraction of a diagnosis
problem D is not a diagnosis, then all its reﬁnements are not diagnoses of D.

Deﬁnition 9 (reﬁnement of a candidate). Let D0, D1 be two diagnosis problems in
languages L0 and L1, respectively, such that D1 is a structural abstraction of D0 with
respect to an interpretation mapping π . Let AGGR be the set of components of D0 that are
aggregated, and let sc ∈ COMPS1 be the name of their supercomponent.

Let C1 = P C ∧ msc(sc) be a candidate of D1, where PC is a partial candidate for the
components in the set COMPS1 − {sc}. A candidate C0 of D0 is called a reﬁnement of C1
if:

(cid:10)

• C0 =
• msc(sc) ≡π

c∈AGGR mc(c) ∧ PC,

(cid:10)

c∈AGGR mc(c) ∨ ∆, where ∆ is a (possibly empty) disjunction of partial

candidates for the components belonging to AGGR.

The idea is that a candidate and its reﬁnements contain the same behavioral modes
assignments for the components that are not involved in the abstraction, while the
behavioral mode m for the supercomponent is substituted in the reﬁnement with a partial
candidate abstracted by m itself. Note that by deﬁnition of structural abstraction every
candidate in an abstract diagnosis problem has at least one reﬁnement (the BMi sets are a
partition of the set of all partial candidates, and then each partial candidate is abstracted
into a behavioral mode for the supercomponent).

The following theorem states that every structural abstraction is also a MI abstraction.

Theorem 3. Let D0, D1 be two diagnosis problems in languages L0 and L1, respectively,
such that D1 is a structural abstraction of D0 with respect to an interpretation mapping
π . Then, D1 <π D0, i.e., D1 is a MI abstraction of D0 with respect to π .

Proof (outline). Consider any model of D0, which is an assignment I of values to the ports
of D0 for which there is at least a candidate C0 of D0 such that

I |= SD0 ∧ OBS0 ∧ C0

We must show that π(I ) is a model of D1, i.e., there is a candidate C1 of D1 such that

π(I ) |= SD1 ∧ OBS1 ∧ C1

(1)

(2)

By deﬁnition of structural abstraction, π(I ) and OBS1 are restrictions of I and OBS0,
respectively, which assign a value only to the ports that are present in both D0 and D1.
Thus,

π(I ) |= SD0 ∧ OBS1 ∧ C0

(3)

One can substitute SD0 with SD1 in (3) because the denotation of CD0 and CD1, BD0
and BD1 are the same in the considered restriction of I . Then, we take C1 such that C0

162

L. Chittaro, R. Ranon / Artiﬁcial Intelligence 155 (2004) 147–182

is one of its reﬁnements. The partial candidate contained in C1 that assigns a mode to the
components that are shared between D0 and D1 has π(I ) as a model (again, the restriction
does not involve the components, observations, etc. that are not aggregated). Finally, by
deﬁnition of reﬁnement, π(I ) is a model also of the partial candidate contained in C1 that
assigns a mode to the aggregations of components in D0. ✷

Since structural abstractions are MI, we can prove the following relation between any
candidate of the more abstract diagnosis problem and its reﬁnements:

Theorem 4. Let D0, D1 be two diagnosis problems in languages L0 and L1, respectively,
such that D1 is a structural abstraction of D0 with respect to the interpretation mapping
π . Let C1 be a candidate of D1 which is not a diagnosis. Then, any reﬁnement C0 of C1 is
not a diagnosis for D0.

Proof. Since C1 is not a diagnosis, then C1 ∧ SD1 ∧ OBS1 is inconsistent. Moreover, D1
is a structural abstraction of D0, thus SD1 <π SD0 and OBS1 <π OBS0. Finally, C1 <π C0
by hypothesis. By compositionality of MI abstractions we can write

C1 ∧ SD1 ∧ OBS1 <π C0 ∧ SD0 ∧ OBS0

Since C1 ∧ SD1 ∧ OBS1 is inconsistent, then for property 1 also C0 ∧ SD0 ∧ OBS0 is

inconsistent, i.e., C0 is not a diagnosis. ✷

This theorem allows one to exclude from the possible solutions of a diagnosis problem
D every reﬁnement of an impossible diagnosis. The advantage is that, by eliminating a
candidate in a (potentially simpler) abstract diagnosis problem, one can possibly rule out
many candidates in the original diagnosis problem.

On the other hand, if we ﬁnd that an abstract candidate is a diagnosis, we cannot

guarantee that its reﬁnements are diagnoses too, as shown by the following example.

Example 5. Consider the diagnosis problem for the hcs given in Example 1. Suppose
that there is only one observations specifying that ﬂow at port t2 is greater than zero, but
below FK . In the structural abstraction given in Example 3, port t2 is not present, thus the
candidate

ok(sc) ∧ ok(n1) ∧ ok(p2) ∧ ok(p3) ∧ ok(v1) ∧ ok(v2) ∧ ok(p4) ∧ ok(p5) ∧

ok(n2) ∧ ok(p6)

is a diagnosis for the abstract diagnosis problem, while its reﬁnement

ok( pm) ∧ ok(p1) ∧ ok(n1) ∧ ok(p2) ∧ ok(p3) ∧ ok(v1) ∧ ok(v2) ∧ ok(p4) ∧

ok(p5) ∧ ok(n2) ∧ ok(p6)

is not a diagnosis, since the considered situation can only be explained by pm delivering a
low amount of ﬂow.

L. Chittaro, R. Ranon / Artiﬁcial Intelligence 155 (2004) 147–182

163

3.4. Some remarks on the aggregation of components

(cid:15)

In general, when aggregating a set of components c1, . . . , ck into a component sc, the
number of behavioral modes for sc can be (at worst) N =
i=1,...,k Mi , where Mi is the
number of behavioral modes for component ci . The motivation is that, in principle, each
combination of behavioral modes for the subcomponents could be represented as a distinct
behavioral mode for the supercomponent. In this case, the complexity reduction we want
to obtain with the abstraction vanishes because of the number of supercomponent modes
that have to be considered: since N is exactly the number of partial candidates involving
the subcomponents, the number of candidates remains equal to the more detailed diagnosis
problem.

Therefore, one needs to ﬁnd suitable aggregations of components that are able to reduce
the complexity of reasoning. In some cases, those aggregations are easily found, because
some combinations of behavioral modes for the subcomponents will not be distinguishable
in terms of values at the supercomponent ports, and thus they will be naturally combined
into the same behavioral mode. In Example 3, the combinations of subcomponent modes

hiﬂow( pm) ∧ leak(p1),
ok( pm) ∧ leak(p1)

may predict different values for port t3. In the ﬁrst case, ﬂow at t3 may be greater
than FK , while in the second case it must be less than FK . However, both sentences
predict that input ﬂow of sc is greater than its output ﬂow, and thus both of them can
be abstracted by a leak mode. However, easy aggregations may not be possible in some
systems: in this case, a possible solution is to forget some combination of modes in the
abstraction. This solution can be adopted, for example, when a combination of modes
yields a very complex behavior. In such situations, the structural abstraction is not MI
(each model of the forgotten combination of behaviors has no corresponding model in the
more abstract diagnosis problem). However, it can be viewed as a structural abstraction
under the simplifying assumption that the forgotten combination of modes cannot occur.
This has to be taken into account by diagnostic reasoning, which has to consider two cases:
one in which the simplifying assumption holds (where the abstract diagnosis problem can
be used), and one in which the simplifying assumption does not hold (where only the more
detailed diagnosis problem can be used). The union of the solutions of the two cases is the
solution of the original diagnosis problem.

3.5. Related work

Formalizations of structural abstraction have been proposed by Struss [19], Mozetic
[14], and more recently, by Autio and Reiter [1]. Genesereth [10] was probably the ﬁrst
to advocate the use of structural abstraction as a way to reduce the computational cost
of model-based diagnosis, and to recognize also that loss of information can lead to
undiagnosability of the abstract representation.

164

L. Chittaro, R. Ranon / Artiﬁcial Intelligence 155 (2004) 147–182

In [14], structural abstraction is addressed as follows. The representation of a system
is constituted by a mapping m between any state of the system (normal or faulty) to
corresponding input-output observations:4

m : x → y

where x is a state of the system (e.g., a normal state) and y is a tuple of input-output
observations.

The reﬁnement/abstraction operators allow one to start from a mapping m representing
the system and to derive a more abstract mapping m(cid:27) representing the same system with
less detail. To relate the two representations, one needs a function h that maps between
states in m and states in m(cid:27), and between input-output values in m and m(cid:27). That is, h(x(cid:27), x)
maps between a state x of m and a state x(cid:27) of m(cid:27) (and vice versa), and the same function
h(y(cid:27), y) maps between input-output values y of m and input-output values y(cid:27) of m(cid:27) (and
vice versa).

When the system is composed by components c1, . . . , cn, the representation can be

deﬁned by a composition of mappings in the following way:

m(x, y) ← c1(x1, z1), . . . , cn(xn, zn)

where c1, . . . , cn are the mappings that deﬁne the relation between the states of the
components and their input-output observations. One can aggregate some components,
e.g., c1, . . . , ck in the representation into a supercomponent c and obtain the following
simpler system representation:

m(cid:27)(x(cid:27), y(cid:27)) ← c(xc, zc), ck+1(xk+1, zk+1), . . . , cn(xn, zn)

By repeated applications of abstraction operators, one can obtain a multi-level hierarchy of
representations of the system, each one at a different level of detail.

To ensure correctness in diagnostic reasoning, it must be guaranteed that the diagnoses
which are impossible at an abstract level are impossible at a more detailed level as well.
This requirement is formulated by Mozetic in terms of a global consistency condition that
must be satisﬁed among the different levels: given two adjacent levels of the hierarchy (m
more detailed, and m(cid:27) more abstract), the consistency condition is expressed as:

(cid:8)

(cid:9)

∀x, ym(x, y) ∧

1 h(x(cid:27)
⇒ ∃x(cid:27), y(cid:27) m(cid:27)(x(cid:27), y(cid:27)) ∧ h(x(cid:27), x) ∧ h(y(cid:27), y)

1, x)

∃x(cid:27)

(4)

which guarantees that (see [14] for a detailed discussion):

• given a more detailed mapping m, a state x with an abstraction x(cid:27) cannot be mapped

to input-output values y which do not have a corresponding abstract y(cid:27);

• if x maps to y (i.e., in state x the possible input-outputs are y), and we have

abstractions x(cid:27) and y(cid:27) for x and y respectively, then x(cid:27) must map to y(cid:27).

4 We repeat here the original notation of [14]. Note that letters (such as m and c) may have different meanings

from those adopted in the rest of this paper.

L. Chittaro, R. Ranon / Artiﬁcial Intelligence 155 (2004) 147–182

165

Our deﬁnition of structural abstraction (as shown by Theorem 4) satisﬁes the
consistency condition. Our deﬁnition is slightly stronger in the sense that every part
of the detailed representation must be abstracted, while Mozetic’s deﬁnition allows for
incompleteness in the abstraction process (e.g., some faulty modes could not be abstracted
at all). However, as discussed in the previous section, we introduce that possibility by using
simplifying assumptions.

As a consequence, the consistency condition in our approach needs not to be checked
for each derived abstract level, but is enforced during the abstraction process (i.e., the
interpretation mapping used by each aggregation must satisfy Deﬁnition 5). In other
words, our deﬁnition clearly states the rules that each aggregation has to follow in order
to guarantee the consistency condition, while in Mozetic’s formalization the consistency
condition has to be veriﬁed globally for each level.

In [19], structural abstraction is viewed as one of the possible model relations called
reﬁnement. Reﬁnement deﬁnes structural abstraction for diagnosis problems as follows.
Suppose that formula ok(c) represents the correct behavioral mode of a supercomponent
sc, and that formulae ok(c1), . . . , ok(ck) represent the correct behavioral modes of
its subcomponents c1, . . . , ck, respectively. Then, ok(sc) (the theory describing the
supercomponent’s behavior) is a structural abstraction of ok(c1), . . . , ok(ck) (the theories
describing the subcomponents’ behavior) if

ok(c1) ∧ · · · ∧ ok(ck) ⇒ ok(sc),

which expresses the assumption that “If all parts of a system work correctly, then
so does the entire system”. This formalization does not deal with components with
multiple behavioral modes, so it is applicable only to some diagnosis problems. Moreover,
the formalization characterizes only the behavioral descriptions of the supercomponent,
without dealing at all with the representational changes in structure that are brought by
structural abstraction. Our formalization can be seen as an extension of the one proposed
by Struss: if one represents only the normal behavior of components, the requirement on
our abstraction mapping becomes

ok(sc) ≡π

(cid:4)

ok(ci)

ci ∈AGGR

which is the same deﬁnition of structural abstraction given by Struss, but formalized using
the semantic theory of abstraction.

In the approach proposed by [1], a hierarchical representation is composed by multiple
system descriptions, each one at a different level of structural detail, and a component
hierarchy, which is represented as a tree with nodes corresponding to components at
any level of detail. More precisely, the leaves are the components belonging to the most
detailed description, while interior nodes are abstract components obtained by successive
aggregations starting from the primitive components. The component hierarchy represents
the structural abstractions that have been performed in order to build the hierarchical
representation. Autio and Reiter [1] do not consider components with multiple behavioral
modes, but diagnostic theories where the behavioral description consists only in the correct
behavior of components.

166

L. Chittaro, R. Ranon / Artiﬁcial Intelligence 155 (2004) 147–182

Fig. 3. Layout of a circuit with two inverters.

A system (SD(cid:27), COMPS(cid:27)) is deﬁned to be a structural abstraction of a system
(SD, COMPS) if for every component c in COMPS(cid:27) there exists a system (SDc, COMPSc)
such that its components are components of COMPS, and these subsystems are properly
connected to form the compositional description of (SD, COMPS). It is required that the
structural abstraction of a set of subcomponents c1, . . . , cm into their supercomponent c
must satisfy the following assumptions:

• if a (super)component c is abnormal, then at least one of its subcomponents c1, . . . , cm

must be abnormal as well, i.e., ¬ok(c) ⇒ ¬ok(c1) ∨ · · · ∨ ¬ok(cm),

• if a (super)component is normal, then all its subcomponents are normal as well, i.e.,

ok(c) ⇒ ok(c1) ∧ · · · ∧ ok(cm).

These assumptions are referred to by Autio and Reiter as abnormality axioms. The
ﬁrst abnormality axiom is equivalent to the deﬁnition by Struss discussed above. The
second abnormality axiom poses serious problems in situations such as fault masking
or fault compensation. For example, consider the well-known logic circuit shown in
Fig. 3, composed by two inverters I1 and I2. Suppose that the measurements report
A = 1, B = 1, C = 1, indicating that both inverters are faulty (e.g., they are both stuck
at 1). We aggregate both inverters into a single component I with input A and output C,
as shown by the ﬁgure. By looking only at I , we can consider it normal, because the two
associated observations are not symptoms (this happens because the two faults in inverters
I1 and I2 mask each other). By applying the second abnormality axiom, we conclude that
both I1 and I2 are normal, which is not true. Thus, when fault masking occurs, the second
abnormality axiom can result in wrong conclusions.

We critique the second abnormality axiom also from a common-sense point of view. It
says that “if a system works correctly, then so do all its parts”: an expert would use this
assumption only to focus reasoning ﬁrst on more evident faults, but then would remove it
to consider more subtle faults.

Finally, Autio and Reiter prove that structural abstraction in their formalization is sound,
in the sense that for every diagnosis D involving a supercomponent c, there is at least a
corresponding diagnosis where c is substituted by its subcomponents. They also prove that
structural abstraction is not complete, in the sense that there is the possibility of ruling
out valid diagnoses when reasoning at abstract levels (this is shown also in the circuit
example). This is a serious limitation in reasoning, because it means that one cannot
exclude impossible diagnoses by reasoning at an abstract level, and thus, in order to ﬁnd all
possible diagnoses, one has to reason only with the most detailed representation available.

L. Chittaro, R. Ranon / Artiﬁcial Intelligence 155 (2004) 147–182

167

4. Reasoning with structural abstraction

In this section, we will examine the problem of diagnostic reasoning with structural
abstraction. First, we will consider the well-known Mozetic’s approach [14] to hierarchical
diagnosis and apply it to multi-level hierarchies of structural abstractions. Then, we
will analyze why,
the efﬁciency of Mozetic’s approach is not as
good as one would expect. In general, this originates from the fact that the same
hierarchical representation is used for a system, regardless of the currently available
observations. Finally, we will propose two novel approaches that, in the case of structural
abstraction, overcome this problem, and we will show the obtained improvements using
the experimental evaluation we performed.

in many cases,

4.1. A formalization of Mozetic’s algorithm for multi-level hierarchies of structural
abstractions

In the following, we provide a procedural formulation of Mozetic’s approach for
consistency-based diagnosis problems, clearly separating the main activities that have to
be performed, namely abstraction of observations and fault diagnosis. Our formalization
of Mozetic’s algorithm will be called Hierarchical Diagnosis (HD) in the remaining part
of the paper.

The key idea of HD is to apply (in principle) any plain, one-level diagnostic strategy to a
multi-level hierarchical representation. The strategy is applied one level at a time, starting
from the most abstract possible level and then proceeding to lower ones, and the diagnoses
that are found at each level are used to reduce the number of possible diagnoses at lower
levels.

In our formalization, the input given to HD is a multi-level hierarchy of q diagnosis
problems Di = {(SDi, OBSi, COMPSi)}, i = 0, . . . , q − 1. For simplicity, input observa-
tions are given at the most detailed level.5

We assume that two functions, Abstract and Detailed, which depend on the abstractions

that have been employed to build the multi-level hierarchy, are available:

• Abstract : OBSj → OBSj +1, j = 0, . . . , q − 2, which corresponds to Mozetic’s
abstract predicate, mapping the observations at level j to observations at level j + 1,
and

• Detailed : Cj +1 → Cj , j = 0, . . . , q − 2, which corresponds to Mozetic’s detailed

predicate, mapping a candidate at level j + 1 into its reﬁnements at level j .

We formalize HD in Fig. 4, dividing it into two separate procedures. The ﬁrst
one (Abstract-Observations) associates the available observations to the proper
abstract levels of the hierarchical representation. Then, the second one (Top-Down-
diagnosis) performs the diagnosis.

5 Giving observations at any level of the hierarchy would be straightforward: one need only to slightly modify
the Abstract-Observations procedure in Fig. 4 such that the mapping of observations is performed both
upwards and downwards.

168

L. Chittaro, R. Ranon / Artiﬁcial Intelligence 155 (2004) 147–182

Procedure Abstract-Observations

l ← 0;
q ← number of levels of the hierarchical representation;
WHILE l < q − 1 ∧ OBSl (cid:20)= ∅ DO
OBSl+1 ← Abstract(OBSl );
l ← l + 1;
ENDWHILE;
IF OBSl = ∅ THEN CLO ← l − 1;
Procedure Top-Down-Diagnosis

l ← CLO;
Candl ← all candidates at level l;
WHILE l (cid:1) 0 DO

Diagl ← Verify(Dl, Candl );
\∗ CandNAl ← all candidates at level l which have no abstraction;
IF l < CLO THEN

Diagl ← Diagl ∪ Verify(Dl, CandNAl); ∗\

IF l > 0 THEN Candl−1 ← Detailed(Diagl );
l ← l − 1;
ENDWHILE;

HIERARCHICAL DIAGNOSIS

Abstract-Observations;
Top-down-Diagnosis.

Fig. 4. The HD algorithm (i.e., Mozetic’s algorithm for multi-level hierarchies of consistency-based diagnosis
problems). Statements in comments have to be executed only when using structural abstractions with simplifying
assumptions.

In particular, Abstract-Observations takes as input the initially available
observations OBS0 (which refer to level 0 of the hierarchical representation), and, by
applying the Abstract function, determines the available observations (if any) for level 1.
The same function is then repeatedly applied to derive the observations for the other levels,
until a level with no available observations is reached or all levels have been considered.
The number of the Coarsest Level with Observations (hereinafter, CLO) is stored into
variable CLO. Levels from CLO to 0 are then considered by procedure Top-down-
Diagnosis in the following way:

• First, all the diagnoses that are consistent with the observations at the current level
are determined by using the function Verify (corresponding to the verify predicate in
Mozetic’s original formulation). Verify takes the diagnosis problem Dl at the current
level, and a set Candl which contains the possible diagnoses at the current level (for
level CLO, all candidates are considered), and returns those elements of Candl which
are diagnoses, i.e., every C ∈ Candl such that SDl ∪ OBSl ∪ C is consistent.6 After the
Verify function has been applied, Diagl stores the diagnoses at the current level.

6 It must be noted that no assumption is made on the implementation of this function (e.g., it can exploit a

generate-and-test method, a GDE-like reasoner [7,9], or other model-based diagnosis techniques).

L. Chittaro, R. Ranon / Artiﬁcial Intelligence 155 (2004) 147–182

169

• Second, if l is greater than zero (i.e., current the level is not the most detailed one), the
algorithm applies the function Detailed to the obtained diagnoses in order to derive
their more detailed versions at level l − 1, which will be the possible diagnoses at level
l − 1.

After level 0 has been considered, the Top-Down-Diagnosis procedure ends, and the
ﬁnal diagnoses are found in variable Diag0.

If some candidates of the currently considered level have no abstraction at (previously
considered) more abstract levels (i.e., we are using some simplifying assumptions), then
they must be considered at the current level for the ﬁrst time. In such case, one has to
execute also the statements provided in comments in Fig. 4: in that way, the algorithm
applies a second time the Verify procedure, but considering only candidates with no
abstraction (stored in the variable CandNAl) as possible diagnoses. All found diagnoses
are then detailed into candidates for the next level.

The correctness and completeness of the algorithm rely on the consistency conditions
discussed in the previous section. Since structural abstraction satisﬁes them, we can apply
HD to any multi-level hierarchy of structural abstractions without having to check any
consistency condition.

By taking advantage of the smaller search space at the more abstract levels, in many
cases HD is able to outperform diagnostic reasoning applied only to the most detailed
level. From a theoretical point of view, the speed up that can be achieved in the ideal case
is exponential [14]. Experimental testing performed by Mozetic reported, in one medical
example involving a four-level qualitative representation of the heart, a speed up by a
factor of 20 over one-level diagnosis. Our experimental results with HD conﬁrm similar
improvements in the average case (as illustrated in Section 4.4).

4.2. Some remarks on the efﬁciency of HD

In this section, we use two examples to show that the efﬁciency of HD depends on both
the chosen multi-level hierarchical representation and the actual observations that are given
as input.

Example 6. Using the six-level hierarchical representation of the hcs illustrated in Example
4 and Fig. 2, we suppose that the following observation is available: ﬂow at port t7 has
a value that is different from expected. Using the chosen multi-level representation, this
observation cannot be abstracted to level 1, because t7 is not present at that level. Hence,
at the end of the execution of the Abstract-Observations procedure, CLO = 0.
Since diagnosis is started at level 0, the efﬁciency of HD is similar (slightly worse, due
to the extra reasoning activities of the Abstract-Observations procedure) to direct
diagnosis of the most detailed representation of the system.

Note that by using a different multi-level representation, we can obtain better results
with HD in Example 6. Consider an alternative six-level representation of the hcs which
differs from the one illustrated in Fig. 2 only in levels 1 and 2: in level 1, sc2 is obtained
by aggregating v2 and p5 into sc2 (instead of p3 and v2), and in level 2, sc4 is obtained by

170

L. Chittaro, R. Ranon / Artiﬁcial Intelligence 155 (2004) 147–182

aggregating p3 and sc2 (instead of sc2 and p5). In this case, the observation of Example
6 can be abstracted up to level 1, and diagnosis would start from a more abstract problem
(CLO = 1).

Example 7. Using the six-level hierarchical representation of the hcs illustrated in Example
4 and Fig. 2, we suppose that the following observations are available: ﬂow at the port
= closed). Using the chosen
t6 is a > 0, and valve v1 is expected to be closed (i.e., sv1
multi-level representation, the observation on t6 cannot be abstracted to level 1, but the
observation on sv1 can be abstracted up to level 5. Hence, CLO is equal to 5. Unfortunately,
at this level, the observation on sv1 allows one to exclude only those candidates in which
v1 is stuck at open. Then, reasoning at levels 4, 3, 2, and 1 does not allow to exclude other
candidates. At each of these levels, diagnostic reasoning has to consider a lot of candidates
without useful results (and thus using the hierarchical algorithm is counterproductive in
terms of efﬁciency).

More generally, the situations that can heavily limit the effectiveness of HD are the

following:

• the algorithm cannot use at all some abstract levels (where potentially a lot of
candidates could be excluded with little effort), since no observations are available
for them (as Example 6 shows);

• only a few of the given observations are available at those abstract levels where
diagnosis can be performed. In this case, diagnosing those levels could be scarcely
effective in reducing the candidate space, or even be counterproductive, resulting in a
loss of efﬁciency (as Example 7 shows).

With structural abstraction, when a component is aggregated all the observations that
refer only to it become unavailable at the upper levels. Therefore, to avoid the above
mentioned situations, one should build the multi-level representation in such a way that
the relevant diagnostic information (i.e., current observations) is kept as much as possible
available at more abstract levels, i.e., diagnosability at abstract levels is preserved. In
principle, this implies that for every set of observable ports, one should build a different
multi-level representation to guarantee efﬁcient hierarchical reasoning.

However, building a new hierarchical representation by hand for each possible
diagnostic scenario cannot be a viable approach: multi-level system representations are
often hard to build, and the only one that could be possibly readily available is the one
coming from system design. Moreover, general automatic methods for building multi-level
representations are not available, or are heavily dependent on a particular system or domain
(e.g., [3,13]).

In a system where the position of measurement sensors is known and does not change,
one can think about building only one multi-level representation by using sensors position
to guide the abstraction process, i.e., choosing the aggregations in such a way that the most
abstract levels have always (or at least often) some observation available. However, this
solution: (i) is not applicable to every system and (ii) whenever some sensors do not return
measurements (e.g., because they are broken) the chosen hierarchical representation may

L. Chittaro, R. Ranon / Artiﬁcial Intelligence 155 (2004) 147–182

171

not be effective anymore, because some abstract levels may not have sufﬁcient observations
available.

In our research, we do not aim at building the optimal multi-level hierarchy for a given
set of observations, but instead consider any chosen multi-level hierarchical representation,
and aim at preserving diagnosability at abstract levels in those situations where the given
observations do not allow HD to be effective.

4.3. Extensions to Mozetic’s approach

In the following, we propose two extensions of HD that tackle the problems highlighted

in the previous section.

More speciﬁcally, the extensions are called REARRANGE (presented in Section 4.3.2)
and BOTTOM-UP (presented in Section 4.3.3). The idea behind both extensions is to
tailor an existing multi-level hierarchical representation in order to obtain a more efﬁcient
diagnosis with the current observations (to this purpose, each extension uses a different
strategy).

Our approach does not exploit any speciﬁc system or domain knowledge, and thus it is
not limited to a particular domain or system. Moreover, the two extensions can be easily
combined together in order to sum up their respective advantages.

Both extensions exploit an additional data structure, called structural tree, which is

presented in the next section.

4.3.1. The structural tree

We associate any multi-level hierarchical representation (built with structural abstrac-
tions) H to a data structure ST(H), called a structural tree. In the structural tree, each node
represents a component of some level of H , and the sons of the node correspond to the sub-
components. In the following, given a tree T , we use the function root(T ) with its obvious
meaning; for each node n ∈ T , the function sons(n) returns the set of its sons.

Given a multi-level hierarchical representation of a diagnostic problem H = {(SDi,

OBSi, COMPSi)}, i = 0, . . . , q − 1, the structural tree ST(H ) is built as follows:

• ﬁrst, for each component c ∈ COMPS0, a leaf c is created;
• then, for each aggregation of AGGR ⊆ COMPSi into sc ∈ COMPSi+1 such that each
c ∈ AGGR has already been added as a node of the tree, a node sc is created such that
sons(sc) = AGGR.

The root of ST(H ) is associated with the component that represents the whole system, i.e.,
root(ST(H )) = c ∈ COMPSq−1.

In general, one might not have a most abstract level with only one component
representing the whole system. In this case, the derivation procedure outlined above would
not derive a tree but a forest. In the remaining part of the paper, we assume that the most
abstract level always contains just one component. However, multi-level hierarchies where
this is not true can be still represented by a structural tree by simply adding an additional
abstract level with just one component (representing the whole system) having just one

172

L. Chittaro, R. Ranon / Artiﬁcial Intelligence 155 (2004) 147–182

behavioral mode which abstracts all the candidates of the original most abstract level.
Obviously, the newly added level would not bring any efﬁciency advantage.

Since each node c ∈ ST(H ) is a component c ∈ COMPSi for some i = 1, . . . , q − 1,
we associate to it the theory SDc ⊆ SDi and the observations OBSc ⊆ OBSi (with OBSc
possibly empty).

The ST of a multi-level hierarchical representation H can be used to derive new levels
(that are not in H ) using the same aggregations that were employed in H . The following
proposition deﬁnes the conditions under which a set of nodes in the ST characterizes a
diagnosis problem for the considered system.

Proposition 5. Given a multi-level hierarchical representation H , any set S of nodes
belonging to ST(H ) such that:

• for each node in the set, no descendants or ancestors are included in the set,
• the descendants of all nodes in the set include all the leaves

characterizes a diagnosis problem for the considered system, in which COMPS = S.

The resulting diagnosis problem can be easily built by retrieving from H all the nec-
essary behavioral descriptions and observations, and by deriving a proper compositional
description by simple conjunction of the type predicates for the chosen components (the
needed instances of the type predicates are taken from the compositional descriptions of
the diagnosis problems in H ).

Example 8. Consider the multi-level hierarchical representation of the hcs shown in Fig. 2.
Fig. 5 shows its structural tree. The diagnosis problem with components sc6, n1, sc3, sc2,
p5, n2, and p6 is not in the multi-level representation, but is a diagnosis problem for the
hcs.

Fig. 5. Structural tree for the hcs derived from the multi-level hierarchical representation of Fig. 2.

L. Chittaro, R. Ranon / Artiﬁcial Intelligence 155 (2004) 147–182

173

4.3.2. The REARRANGE extension to Mozetic’s approach

The extension presented in this section dynamically determines a multi-level hierarchi-
cal representation suited to diagnose the speciﬁc situation described by the current obser-
vations. The derived multi-level hierarchical representation will be built by rearranging
the levels of a given hierarchical representation H by reasoning with the corresponding
ST(H ) and the available observations.

The idea is to improve HD when it is not able to fully exploit the hierarchical
representation, by providing a new, tailored hierarchical representation consisting of: (i)
all levels of the original hierarchical representation which contain observations (i.e., the
levels considered by HD), and (ii) additional, more abstract levels which are not present in
the original hierarchy, and have the same observations of the coarsest level considered by
HD.

We now show with an example how these additional levels can be built with little effort.
Consider the scenario presented in Example 6, where diagnosis is started at level 0 (which
contains 11 components). An hypothetical diagnosis problem (let us call it Better) with
components sc6, n1, sc3, p3, v2, n2, p5, and p6 is more abstract than level 0 and has the
same observations (i.e., ﬂow at t7 is not as expected). The search space of Better is much
smaller: the diagnosis problem at level 0 has 4096 possible candidates, while Better has
512 possible candidates.

HD cannot start from Better because this diagnosis problem is not available in the given

hierarchical representation: the only level with observations is level 0.

We can derive Better by properly selecting nodes in the structural tree of Fig. 5. The
structural tree highlights indeed the aggregations used in the hierarchical representation,
regardless of the order in which they were performed. One can derive Better by selecting
a set of nodes in the structural tree which: (i) represent the full system, (ii) keep the same
observations that are present at the level where HD starts, (iii) are as abstract as possible.
This can be done by starting with a set of nodes which corresponds to HD starting level,
and then try to substitute some of them with their parent provided that no observation
is lost. Each possible substitution derives a new level (i.e., all requirements imposed by
Proposition 5 are satisﬁed), from which the process of searching for more abstract levels
can be repeated.

We implemented this strategy as an extension to HD, which we call REARRANGE.
More speciﬁcally, the additional activity of building new levels is performed between the
Abstract-Observations and the Top-Down-Diagnosis procedures, as shown
in Fig. 6.

The added Rearrange procedure operates as follows:

• each observation available at level CLO (which is the same calculated by HD) is

associated to the corresponding nodes in ST(H ) (obtaining the OBSn sets);

• then, possible new levels, which are more abstract than CLO, are added to the levels of
H with available observations, deriving a new multi-level hierarchical representation
H (cid:27). These new levels are built by:
(1) considering the components of the current level (which initially is CLO), which

are assigned to the set NodesToCheck;

174

L. Chittaro, R. Ranon / Artiﬁcial Intelligence 155 (2004) 147–182

Procedure HIERARCHICAL-DIAGNOSIS

Abstract-Observations;
Rearrange;
Top-down-diagnosis.

Procedure Rearrange
IF CLO < g − 1 THEN

H (cid:27) ← all levels of H from 0 to CLO;
FOR each node n of ST(H ) referred by OBSCLO

OBSn ← {a = v|a = v ∈ OBSCLO ∧ a is a port of n};

NodesToCheck ← COMPSCLO;
WHILE NodesToCheck (cid:20)= ∅ DO
n ← ﬁrst(NodesToCheck);
c ← father(n);
IF sons(c) ⊆ COMPSCLO ∧ (
CLO ← CLO + 1;
COMPSCLO = (COMPSCLO−1 − sons(c)) ∪ {c};
ADD a new level numbered CLO with components COMPSCLO to H (cid:27)
NodesToCheck ← COMPSCLO;

s∈sons(c) OBSs) = OBSc THEN

(cid:12)

;

ELSE

NodesToCheck ← NodesToCheck − sons(c);

ENDIF;
ENDWHILE;

ENDIF.

Fig. 6. The REARRANGE extension to HD.

(2) ﬁnding a subset of NodesToCheck that contains all and only the sons of a node
c in ST(H ) such that the observations associated to the sons are exactly the
observations associated to c (i.e., by substituting the sons with their father we
do not lose any observation);

(3) if such set of components does not exist, the algorithm stops; otherwise, we add
to H (cid:27) a new top level obtained from the current level by substituting the sons of
c with c itself. The newly added level is a diagnosis problem for the considered
system, since it satisﬁes the requirements of Proposition 5. Since it is required that
no observation is lost in the substitution, the newly derived level contains exactly
the same observations as the starting one. Then, we go to point 2 considering the
newly added level as the current one.

After the execution of the Rearrange procedure, the most abstract level derived by
it is the new top level from which diagnosis is started. Note that when Abstract-
Observations is already able to reach the most abstract
then the
Rearrange procedure does nothing, and the whole reasoning process is identical to HD.
The computational cost of the Rearrange procedure is polynomial in the number of
nodes of the structural tree: for each newly generated level, at worst all the nodes in the
level are examined once, and each examination consists of testing whether the node has

in H ,

level

L. Chittaro, R. Ranon / Artiﬁcial Intelligence 155 (2004) 147–182

175

Table 2
Levels employed by HD (HD) and REARRANGE (R) in Example 9. The last two columns indicate whether the
corresponding approach is able or not to exploit the level for top-down diagnosis

Level

Components

3
2
1
0

sc6, n1, sc3, p3, v2, p5, n2, p6 (8)
pm, p1, n1, sc3, p3, v2, p5, n2, p6 (9)
pm, p1, n1, p3, sc1, v2, p4, p5, n2, p6 (10)
pm, p1, n1, p3, p2, v1, v2, p4, p5, n2, p6 (11)

Candidates

512
1024
2048
4096

HD

no
no
no
yes

R

yes
yes
yes
yes

a father, whether the observations associated to the father are the same of its sons, and
whether all its sons belong to the current level.

We now reconsider the previously illustrated examples, and show how the RE-

ARRANGE extension behaves on them.

Example 9. Considering the observations given for the hcs in Example 6 (i.e., ﬂow at
port t7 is not as expected), the CLO in the original multi-level hierarchy is level 0. The
Rearrange procedure is able to derive ﬁrst a level 1 with components pm, p1, n1, sc1, p3,
v2, p4, p5, n2, and p6 (p2 and v1 can be aggregated into sc1 without losing observations).
Then, level 2 is derived with components pm, p1, n1, sc3, p3, v2, p5, n2, and p6 (sc1 and
p4 can be aggregated into sc3 without losing observations). Finally, the most abstract level
(from which diagnosis will start) is derived with components sc6, n1, sc3, p3, v2, p5, n2
and p6 (pm and p1 can be aggregated into sc6 without losing observations). The number
of candidates associated to the above candidates levels are shown in Table 2.

Example 10. Considering the observations given for the hcs in Example 7 (i.e., ﬂow at port
t6 is a > 0, and valve v1 is expected to be closed), since the abstractions of observations
proceeds up to level 5, the Rearrange procedure is not executed (because CLO is the
most abstract level of the hierarchy), and the diagnostic reasoning proceeds exactly as in
HD.

4.3.3. The BOTTOM-UP extension to Mozetic’s approach

In this section, we propose a different strategy that also uses the available observations to
reduce the complexity of hierarchical diagnosis. This second extension (called BOTTOM-
UP) tries to exploit at a given level the observations that are only available at more detailed
levels, and were forgotten in the abstraction process. The additional diagnostic information
derived is used to eliminate impossible diagnoses, thus reducing the computational cost of
reasoning at more detailed levels.

We now show with an example how the strategy works. Consider the scenario presented
in Example 7, where diagnosis is started by HD at level 5. The only information available
= closed, which only allows one to eliminate all candidates
at levels 5, 4, 3, 2, and 1 is sv1
= open. However, a stuckO fault in valve v1 is easily detectable at level 0
in which sv1
(since ﬂow at the input of the valve is greater than zero), by running a diagnose procedure
that separately considers only the observed components (i.e., p2 and v1). Thus, all the
behavioral modes of valve v1, with the exception of stuckO, can be removed from its
behavioral description.

176

L. Chittaro, R. Ranon / Artiﬁcial Intelligence 155 (2004) 147–182

Moreover, since the ok mode is excluded from v1, we can also remove all the behavioral
modes that are abstractions of ok in all its supercomponents. In this way, we can exclude
also ok(sc1), ok(sc3), ok(sc5), ok(sc7), ok(sc8). As a result, when reasoning starts at level
5, we already know that the system cannot be normal.

The BOTTOM-UP strategy extends HD by executing, after the abstraction of observa-
tions, a reasoning activity that considers all observed nodes in the ST, and removes from
the behavioral representation associated to the node every mode which is not consistent
with the associated observations.

Moreover, since the additional reasoning activity is performed using the ST in a bottom-
up fashion, the diagnostic conclusions reached for the subcomponents can be reused when
considering a node: in particular, since each mode m of a component c abstracts a set of
partial candidates BM for the subcomponents of c, if all partial candidates in BM have
been previously removed we can remove also m (even if the observations associated to c
in isolation would not allow to do it).

The BOTTOM-UP extension to HD is illustrated in Fig. 7. The new activities performed

by the Bottom-up procedure are:

(1) building of a list (recorded into the variable NodesToCheck) of the observed nodes in
the structural tree, and all their ancestors; these nodes are then visited in increasing
level order (i.e., when a node is visited, all its sons have been already visited);

(1) for each node c in the list, we consider each mode m of its behavioral description BDc,

and try to eliminate m in the following way:
• ﬁrst, we check if m is actually an abstraction of previously eliminated partial
candidates for the subcomponents of c: we determine with the function Detailed

Procedure HIERARCHICAL-DIAGNOSIS

Abstract-Observations;
Bottom-up;
Top-Down-Diagnosis.

Procedure Bottom-up

IF CLO (cid:20)= 0 THEN

NodesToCheck ← ∅;
FOR each node n of ST(H ) referred in OBS0

NodesToCheck ← NodesToCheck ∪ {n} ∪ ancestors(n);

order NodesToCheck by increasing level;
WHILE NodesToCheck (cid:20)= ∅ DO
n ← ﬁrst(NodesToCheck);
FOR each mode m of n

IF (Detailed(m(n)) = ∅) ∨

(OBSn (cid:20)= ∅ ∧ Verify((BDn, OBSn, {n}), {m(n)}) = ∅) THEN
remove m from BDn;

remove n from NodesToCheck;

ENDWHILE;

ENDIF.

Fig. 7. The BOTTOM-UP extension to Mozetic’s algorithm.

L. Chittaro, R. Ranon / Artiﬁcial Intelligence 155 (2004) 147–182

177

(deﬁned previously) the partial candidates abstracted by m, and if the result is
the empty set (because previous reasoning on the sons of c eliminated all those
candidates), then we remove m from the behavioral description of c;

• if Detailed(m(c)) is not empty, then using the function Verify (deﬁned previously),
we check the consistency of candidate m(c) with the observations on c (i.e., OBSc)
and the behavioral description of c (i.e., BDc). If Verify does not return the partial
candidate m(c), then mode m is not consistent with the observations, and is removed
from the behavioral description of c.

The computational cost of the Bottom-up procedure can be characterized as follows.
At worst, all nodes of the ST have to be considered. For each node, we have to
solve a diagnosis problem with just one component (which requires to verify a small
number of modes and requires no propagation of values). Note that some modes in the
supercomponent may require no veriﬁcation because all their possible reﬁnements have
been excluded by reasoning with subcomponents. However, in a worst case scenario the
computational complexity of the Bottom-up procedure can be characterized as the sum
of the costs required to diagnose each node of the ST in isolation.

We now reconsider the previously illustrated examples, and show how the BOTTOM-UP

extension behaves on them.

Example 11. Considering the observations given for the hcs in Example 6 (i.e., ﬂow at port
t7 is not as expected), the CLO in the original multi-level hierarchy is level 0. Since the
most abstract level with observations is level 0, the Bottom-up procedure is not executed,
and reasoning proceeds exactly as in HD.

Example 12. Considering the observations given for the hcs in Example 7 (i.e., ﬂow at the
port t6 is a > 0, and valve v1 is expected to be closed), level 5 is the CLO. The Bottom-
up procedure considers the following nodes (in increasing level order): p2, v1, sc1, sc3,
sc5, sc7, and sc8. Diagnosing p2 does not allow one to remove any of its behavioral modes,
while diagnosing v1 allows one to remove its ok and stuckC behavioral modes (leak is
still possible, since we do not know anything about the output of v1). Reasoning then
proceeds to sc1. Since its ok and stuckC modes abstract only situations in which its son v1
is respectively ok and stuckC, then we can remove these modes also from sc1 even if the
= closed. Then, diagnosing sc1 with the remaining modes
only available observation is sv1
does not allow to remove any of them. The levels used by HD and by the BOTTOM-UP

Table 3
Levels and corresponding number of candidates employed by HD and BOTTOM-UP in Example 12

Level

Number of candidates (HD)

Number of candidates (BOTTOM-UP)

5
4
3
2
1
0

6
16
64
256
1024
4096

5
8
32
64
256
1024

178

L. Chittaro, R. Ranon / Artiﬁcial Intelligence 155 (2004) 147–182

Procedure HIERARCHICAL-DIAGNOSIS

Abstract-Observations;
Rearrange;
Bottom-up;
Top-down-diagnosis.

Fig. 8. The COMBINED extension to Mozetic’s algorithm.

extension with the associated number of components that have to be considered are shown
in Table 3. The two algorithms exploit the same levels, but BOTTOM-UP is able to reduce
the number of candidates that have to be considered at each level.

4.3.4. Combining the two strategies

The two proposed extensions to HD can be combined together in the following way:
ﬁrst, a tailored structural representation is built using the Rearrange procedure, and then
the Bottom-up procedure is performed. The procedure that implements both strategies,
which we call COMBINED, is shown in Fig. 8. By running this procedure on the previously
analyzed diagnostic examples, one obtains all the advantages already described in the
previous two sections.

4.4. Experimental evaluation

In this section, we describe the experimental activity that we carried out to evaluate the
proposed algorithms. We compared HD, and its three extended versions REARRANGE,
BOTTOM-UP, and COMBINED.

All algorithms were implemented in SWI Prolog [21] and run on a PowerPC G3 400
Mhz (Apple iMac DV) under the LinuxPPC 2000 operating system. The Verify procedure
used by all algorithms was implemented as a generate-and-test algorithm, i.e., a procedure
that considers each possible candidate and then veriﬁes its consistency with the system
description and the observations. Obviously, this is not an efﬁcient implementation of
the Verify function, but it has the advantage of giving us a worst case scenario (i.e., the
exact size of the considered portion of the search space) for every diagnostic reasoning
strategy we tested. The Top-Down Diagnosis and the Abstract-Observations
procedures were the same for each algorithm.

The experimental comparison of the algorithms was performed with diagnosis problems
of different sizes. We considered hydraulic systems, composed by volumetric pumps,
pipes, valves, n-way nodes, sources, and sinks. The considered systems differed in the
layout and in the number of components and ports. More precisely, the simplest system was
the hcs (11 components and 13 ports), while the most complex system was a Heavy Fuel
Oil Transfer System (HFOTS) (with 27 components and 25 ports) of a modern container
ship. The layout and functioning of the HFOTS are described in [3].

For each hydraulic system, we considered several possible sets of observations. Each
set was composed by a minimum of one observation and a maximum of Nobs observations,
with

Nobs = trunc(0.4 ∗ o)

L. Chittaro, R. Ranon / Artiﬁcial Intelligence 155 (2004) 147–182

179

where o is the number of ports for the considered system (e.g., in systems with 10 ports,
each set was composed by a minimum of one and a maximum of four observations). The
justiﬁcation for this choice is twofold: ﬁrst, with only a few observations, the problem is
more difﬁcult (and this is the typical case in which one needs to use abstraction); second,
observations in real-world systems are often too few because sensors are too costly and/or
too unreliable.

Each test was generated by ﬁrst randomly choosing a number m of observations between
one and Nobs, and then assigning a random value to m observables (randomly selected
among the available ones). Each generated test was ﬁrst checked in order to ensure that it
had at least a solution, and then diagnosed using the four algorithms. For each algorithm
execution, we recorded:

• total time spent (measured in seconds),
• total number of candidates considered for veriﬁcation.

Fig. 9 illustrates the average time we obtained considering 1000 diagnostic scenarios
for each considered hydraulic system. All three extensions perform better than HD: in
particular, REARRANGE is signiﬁcantly more efﬁcient as the size of the considered system
increases. This is due to the fact that as the number of components increases, REARRANGE
has more possibilities of deriving additional levels for diagnosis. BOTTOM-UP obtains
small improvements with respect to HD; as we hypothesized, the improvements obtained
by COMBINED are better than both REARRANGE and BOTTOM-UP.

As one can see, for any algorithm the average time becomes very high for small
increases in the number of components. This is due to the fact that we adopted a generate
and test diagnostic strategy.

We now consider in more detail the experimentation on the most complex of the
considered systems, i.e., the HFOTS. Our most detailed representation of the HFOTS was
composed by one pump, 6 valves, 10 pipes, 1 three-way node, 2 four-way nodes, and 3
ﬁve-way nodes, with 2,985,984 possible candidates. Moreover, there were 43 ports and
thus the number of observations ranged from 1 to 10. We built a hierarchy of structural

Fig. 9. Comparison using several hydraulic systems with different number of components.

180

L. Chittaro, R. Ranon / Artiﬁcial Intelligence 155 (2004) 147–182

Table 4
Number of candidates veriﬁed on the HFOTS considering 1000 diagnostic scenarios

Candidates

Average
Maximum
Minimum

HD

238,878
2,985,984
240

REARRANGE

BOTTOM-UP

COMBINED

117,529
947,327
240

172,372
2,985,984
180

89,234
732,183
180

Table 5
Time (in seconds) spent to diagnose the HFOTS considering 1000 diagnostic scenarios

Time

Average
Maximum
Minimum

HD

1274
12742
2.13

REARRANGE

BOTTOM-UP

COMBINED

651
3264
2.15

1073
9376
1.74

496
2823
1.77

abstractions for the HFOTS organized in 15 levels, where the most abstract level contains
just one component representing the whole HFOTS.

Table 4 lists the average, maximum, and minimum number of candidates veriﬁed by
each algorithm. Considering the average number of candidates, the value obtained with
our extensions is 49% (REARRANGE), 72% (BOTTOM-UP), and 37% (COMBINED), of
the value obtained with HD. The values of the maximum number of candidates can be
explained as follows. In some cases, HD veriﬁes all candidates at level 0: as we illustrated
previously, this happens whenever it is not possible to abstract the available observations
to upper levels. For the same reason, BOTTOM-UP exhibits a worst case which is identical
to HD. The value for REARRANGE shows that the extension never reasons with just
one level, i.e., it is able to exploit hierarchical reasoning in all considered scenarios.
The value for COMBINED shows that, by combining the two extensions, one is able to
further reduce the maximum number of veriﬁed candidates in the considered scenarios.
The minimum values of candidates considered refer to situations where the hierarchy is
fully exploited: thus, HD and REARRANGE obtain the same result. BOTTOM-UP (and
thus COMBINED) is able in this case to slightly reduce the number of candidates that have
to be veriﬁed.

Table 5 takes into consideration the time spent by each algorithm on the considered tests
on the HFOTS. The average values show that all three extensions perform better than HD
on the HFOTS. In particular, the values obtained by our extensions are respectively 52%
(REARRANGE), 77% (BOTTOM-UP), and 39% (COMBINED) of the value obtained with
HD.

Experimental evaluation on the HFOTS showed also that as the number of observations
increases, the performance gains of REARRANGE over HD decrease, while those of
BOTTOM-UP increase. This is explained as follows. As the number of observations
increases, it is more likely that observations can be abstracted to coarser levels: in those
cases, the performance of REARRANGE can only be slightly better than HD. On the other
hand, it is also more likely that BOTTOM-UP is able to exclude more candidates with
bottom-up reasoning, and thus to signiﬁcantly improve performance over HD.

L. Chittaro, R. Ranon / Artiﬁcial Intelligence 155 (2004) 147–182

181

5. Conclusions

This paper considered structural abstraction in the context of model-based diagnosis,
presented a formalization for it, and proposed an automated approach to the problem of
obtaining effective structural abstractions, i.e., abstractions that are effective for reducing
the computational effort which is required for the situation at hand. The effectiveness of
the proposed algorithms was shown by experimental comparison with the most cited one in
the literature, i.e., Mozetic’s algorithm [14]. In the following, we outline some limitations
of the experimental activity and directions for improvements.

First, the performed experimental evaluation needs to be extended by both considering
other domains (such as electronics) and especially by considering other real-world systems.
Moreover, the experimental evaluation needs also to be scaled up to systems with hundreds
or thousands of components. In general, there is no reason to suspect that both the general
advantages of hierarchical reasoning and those introduced by our extensions will not scale
up considerably with the size of the system. Nevertheless, further experimental activity
is needed to better evaluate the advantages of the proposed techniques in real-world
situations.

Second, the experimental evaluation was performed by using a generate-and-test
approach for the diagnosis of a single level, which caused generally high running times.
Although this choice was taken to give us the exact size of the considered portion of
the search space, it would be interesting to consider also more efﬁcient approaches to
diagnosis (such as the GDE approach). This would allow us to more precisely establish the
performance gains that can be obtained in real-world diagnostic applications.

Finally, it must be noted that the tailoring of the hierarchical representation which
is performed by our proposed algorithms may not always be the optimal one, and
other criteria for tailoring the hierarchical representation could be tried. In its current
formalization, the REARRANGE extension tries to derive more abstract levels without
losing any available observations. Another possible criteria could be to allow losing
observations in exchange for more abstract levels. The choice of which observations to
keep in the abstract levels could be taken by considering the discriminating power of each
observation, as described in [9].

References

[1] K. Autio, R. Reiter, Structural abstraction in model-based diagnosis, in: Proceedings of the Thirteenth
European Conference on Artiﬁcial Intelligence (ECAI-98), Brighton, UK, Wiley, New York, 1998, pp. 269–
273.

[2] L. Chittaro, R. Ranon, Hierarchical diagnosis guided by observations, in: Proceedings of IJCAI-2001,

Seattle, WA, Morgan Kaufmann, San Mateo, CA, 2001, pp. 573–578.

[3] L. Chittaro, R. Ranon, A. Soldati, Introducing deviations and multiple abstraction levels in the functional

diagnosis of ﬂuid transfer systems, Artiﬁcial Intelligence in Engineering 12 (1998) 355–373.

[4] L. Console, P. Torasso, A spectrum of logical deﬁnitions of model-based diagnosis, in: W.H.L. Console, J.
de Kleer (Eds.), Readings in Model-Based Diagnosis, Morgan Kaufmann, San Mateo, CA, 1992, pp. 78–87.
[5] R. Davis, Diagnostic reasoning based on structure and behavior, Artiﬁcial Intelligence 24 (1984) 347–410.
[6] R. Davis, W. Hamscher, Model-based reasoning: troubleshooting, in: W.H.L. Console, J. de Kleer (Eds.),

Readings in Model-Based Diagnosis, Morgan Kaufmann, San Mateo, CA, 1992, pp. 3–24.

182

L. Chittaro, R. Ranon / Artiﬁcial Intelligence 155 (2004) 147–182

[7] J. de Kleer, Diagnosis with behavioral modes, in: Proceedings of IJCAI-89, Detroit, MI, Morgan Kaufmann,

San Mateo, CA, 1989, pp. 104–109.

[8] J. de Kleer, A.K. Mackworth, R. Reiter, Characterizing diagnoses and systems, Artiﬁcial Intelligence 56

(1992) 197–222.

[9] J. de Kleer, B.C. Williams, Diagnosing multiple faults, Artiﬁcial Intelligence 32 (1987) 97–130.
[10] M. Genesereth, The use of design descriptions in automated diagnosis, Artiﬁcial Intelligence 24 (1984)

411–436.

[11] F. Giunchiglia, T. Walsh, A theory of abstraction, Artiﬁcial Intelligence 57 (2–3) (1992) 323–389.
[12] W.C. Hamscher, Modeling digital circuits for troubleshooting, Artiﬁcial Intelligence 51 (1991) 223–271.
[13] J. Mauss, M. Sachenbacher, Conﬂict-driven diagnosis using relational aggregations, in: Proceedings of the
Tenth International Workshop on Principles of Diagnosis (DX-99), Loch Awe, Scotland, 1999, pp. 174–183.
[14] I. Mozetic, Hierarchical diagnosis, in: W.H.L. Console, J. de Kleer (Eds.), Readings in Model-Based

Diagnosis, Morgan Kaufmann, San Mateo, CA, 1992, pp. 354–372.

[15] P.P. Nayak, A.Y. Levy, A semantic theory of abstractions, in: Proceedings of IJCAI-95, Montreal, QB,

Morgan Kaufmann, San Mateo, CA, 1995, pp. 196–203.

[16] C.J. Price, N.S. Taylor, Multiple fault diagnosis using fmea, in: Proceedings of AAAI-97, Providence, RI,

AAAI Press, 1997, pp. 1052–1057.

[17] R. Ranon, The closure properties of functional ﬂow-based approaches and their relevance to diagnosis, in:
Proceedings of the Thirteenth European Conference on Artiﬁcial Intelligence (ECAI-98), Brighton, UK,
Wiley, New York, 1998, pp. 289–290.

[18] R. Reiter, A theory of diagnosis from ﬁrst principles, in: W.H.L. Console, J. de Kleer (Eds.), Readings in

Model-Based Diagnosis, Morgan Kaufmann, San Mateo, CA, 1992, pp. 29–48.

[19] P. Struss, What’s in sd? towards a theory of diagnosis, in: W.H.L. Console, J. de Kleer (Eds.), Readings in

Model-Based Diagnosis, Morgan Kaufmann, San Mateo, CA, 1992, pp. 419–449.

[20] M. Stumptner, F. Wotawa, Guest-editorial special issue on industrial applications of model-based reasoning,

AI Comm. 13 (2).

[21] Swi prolog, University of Amsterdam, http://www.swi-prolog.org.
[22] L. Travé-Massuyés, T. Escobet, R. Milne, Model-based diagnosability and sensor placement application to a
frame 6 gas turbine subsystem, in: Proceedings of IJCAI-2001, Seattle, WA, Morgan Kaufmann, San Mateo,
CA, 2001, pp. 551–556.

