Artiﬁcial Intelligence 217 (2014) 20–42

Contents lists available at ScienceDirect

Artiﬁcial  Intelligence

www.elsevier.com/locate/artint

Complexity  of  and  algorithms  for  the  manipulation  of  Borda, 
Nanson’s  and  Baldwin’s  voting  rules ✩
Jessica Davies a,  George Katsirelos b,  Nina Narodytska a,  Toby Walsh c,∗
Lirong Xia d
a University of Toronto, Toronto, Canada
b INRA, Toulouse, France
c NICTA and UNSW, Sydney, Australia
d Rensselaer Polytechnic Institute, Troy, USA

, 

a  r  t  i  c  l  e 

i  n  f  o

a  b  s  t  r  a  c  t

Article history:
Received 4 October 2011
Received in revised form 12 July 2014
Accepted 13 July 2014
Available online 23 July 2014

Keywords:
Social choice
Voting methods
Manipulation
Borda voting
Nanson’s voting rule
Baldwin’s voting rule

We  investigate  manipulation  of  the  Borda  voting  rule,  as  well  as  two  elimination  style 
voting  rules,  Nanson’s  and  Baldwin’s  voting  rules,  which  are  based  on  Borda  voting. 
We  argue  that  these  rules  have  a  number  of  desirable  computational  properties.  For 
unweighted Borda voting, we prove that it is NP-hard for a coalition of two manipulators to 
compute a manipulation. This resolves a long-standing open problem in the computational 
complexity of manipulating common voting rules. We prove that manipulation of Baldwin’s 
and Nanson’s rules is computationally more diﬃcult than manipulation of Borda, as it is 
NP-hard  for  a  single manipulator  to  compute  a  manipulation.  In  addition,  for  Baldwin’s 
and  Nanson’s  rules  with  weighted  votes,  we  prove  that  it  is  NP-hard  for  a  coalition  of 
manipulators to compute a manipulation with a small number of candidates.
Because of these NP-hardness results, we compute manipulations using heuristic algorithms 
that attempt to minimise the number of manipulators. We propose several new heuristic 
methods.  Experiments  show  that  these  methods  signiﬁcantly  outperform  the  previously 
best known heuristic method for the Borda rule. Our results suggest that, whilst computing 
a  manipulation  of  the  Borda  rule  is  NP-hard,  computational  complexity  may  provide 
only  a  weak  barrier  against  manipulation  in  practice.  In  contrast  to  the  Borda  rule,  our 
experiments with Baldwin’s and Nanson’s rules demonstrate that both of them are often 
more diﬃcult to manipulate in practice. These results suggest that elimination style voting 
rules deserve further study.

Crown Copyright © 2014 Published by Elsevier B.V. All rights reserved.

1.  Introduction

Voting is a simple mechanism to combine preferences in multi-agent systems. Results like those of Gibbard and Satterth-
waite  demonstrate  that  it  may  often  pay  for  agents  to  manipulate  an  election  by  misreporting  their  preferences  [24,34]. 
One  appealing  escape  from  manipulation  is  computational  complexity  [3]. Whilst  a  manipulation  may  exist,  perhaps  it  is 
computationally too diﬃcult to ﬁnd? With a single manipulator, there is only a small set of voting rules that are known to 

This paper is an invited revision of the winner of the Outstanding Paper award at the Twenty-ﬁfth AAAI Conference on Artiﬁcial Intelligence (AAAI-11). 

E-mail addresses: jdavies@cs.toronto.edu (J. Davies), gkatsi@gmail.com (G. Katsirelos), ninan@cs.toronto.edu (N. Narodytska), toby.walsh@nicta.com.au

✩
Parts of this paper also appear in [14].
* Corresponding author.
(T. Walsh), xial@cs.rpi.edu (L. Xia).

http://dx.doi.org/10.1016/j.artint.2014.07.005
0004-3702/Crown Copyright © 2014 Published by Elsevier B.V. All rights reserved.

J. Davies et al. / Artiﬁcial Intelligence 217 (2014) 20–42

21

be NP-hard to manipulate with unweighted votes: the second order Copeland rule [13,3], single transferable vote (STV) [2]
and ranked pairs [35,40]. With two or more manipulators, computing a manipulation is NP-hard for some other common 
voting rules [19,40,20,41]. One case that remains open is Borda voting. Xia, Conitzer, and Procaccia [41] observe that:

“The exact complexity of the problem [computing a manipulation with unweighted votes] is now known with respect to almost all 
of the prominent voting rules, with the glaring exception of Borda”.

Computing a manipulation of Borda is NP-hard when votes are weighted and we have a coalition of manipulators [12]. 
On  the  other  hand,  computing  a  manipulation  of  Borda  is  polynomial-time  when  votes  are  unweighted  and  there  is  just 
a single manipulator [3]. For a coalition of manipulators and unweighted votes, it has been conjectured that the problem 
is NP-hard [43]. Note that there exist other scoring rules besides Borda where computing a manipulation with unweighted 
votes  has  been  show  to  be  NP-hard  [41].  One  of  the  most  important  contributions  of  this  paper  is  to  close  the  question 
of the computational complexity of computing a coalitional manipulation for Borda with unweighted votes. We prove that 
computing a manipulation of Borda with just two manipulators is NP-hard. This result was proven independently in [7]. We 
will discuss the similarities and differences between the two proofs later in the paper.

We  also  study  two  voting  rules  that  are  closely  related  to  the  Borda  rule:  Nanson’s  and  Baldwin’s  rules.  These  are 
elimination style rules that use Borda scoring to eliminate candidates over a number of rounds. The two rules have been 
used in real elections in the University of Melbourne (between 1926 and 1982), the University of Adelaide (since 1968), and 
the State of Michigan (in the 1920s). There are several reasons we consider Nanson’s and Baldwin’s rules. Firstly, they have 
features  that  might  appeal  to  the  two  opposing  camps  that  support  Borda  and  Condorcet.  In  particular,  unlike  the  Borda 
rule itself, both Nanson’s and Baldwin’s rules are Condorcet consistent as they elect the candidate who beats all others in 
pairwise elections. Secondly, statistical analysis suggests that, whilst the Borda rule is often vulnerable to manipulation [10], 
Nanson’s  rule  is  particularly  resistant  [22].  We  might  expect  Baldwin  to  be  similarly  resistant.  Thirdly,  for  any  Condorcet 
consistent rule (and thus for Nanson’s and Baldwin’s rules), Brandt et al. [8] have shown that many types of control and 
manipulation problems have polynomial-time algorithms when votes are single-peaked. It is an interesting question then if 
such manipulation problems remain polynomial when we drop the domain restriction.

Nanson’s and Baldwin’s rules are also interesting to study as they are elimination style rules, and elimination style rules 
are often computationally harder to manipulate than the base rule from which they are derived [2,15]. Elkind and Lipmaa 
have conjectured that computing a manipulation for the closure of many voting rules (where we successively use the rule to 
eliminate candidates) is NP-hard [16]. One of our contributions is to prove that computing a manipulation of Baldwin’s rule, 
which is the closure of Borda voting, is NP-hard with a single manipulator. We also prove that manipulation of Nanson’s 
rule  is  NP-hard,  again  with  a  single  manipulator  and  unweighted  votes.  Finally,  we  consider  the  problem  of  computing  a 
manipulation with weighted votes and a coalition of manipulators. We show that Baldwin’s and Nanson’s rules are NP-hard 
to manipulate in this setting with just three and four candidates respectively.

Our  theoretical  results  suggest  that  all  three  rules  are  computationally  diﬃcult  to  manipulate  in  the  worst  case.  We 
also investigate whether these rules are resistant to manipulation in practice [37–39]. We propose several polynomial-time 
heuristic algorithms for the three voting rules that try to minimise the number of manipulators required to ensure a partic-
ular result. Our experiments suggest that the Borda rule is often easy to manipulate in practice. The heuristics that we study 
are able to ﬁnd an optimal manipulation in 99% of the cases. Interestingly, these heuristics were signiﬁcantly less effective 
for Baldwin’s and Nanson’s rules. These empirical results, together with our theoretical results, provide further evidence for 
the recent claim that elimination style voting rules tend to be more computationally resistant to manipulation [15].

The  focus  in  this  paper  is  on  manipulation  problems.  It  would,  however,  be  interesting  in  the  future  to  consider  also 
control and bribery problems [4,17]. Control is somewhat different from manipulation since in control problems we change 
the  structure  of  the  election  (number  of  candidates,  number  of  voters,  etc.).  Bribery,  on  the  other  hand,  is  very  close  to 
manipulation  since  we  only  change  the  votes.  Manipulation  is  also  related  to  the  possible  winner  problem  [26] and  to 
dealing  with  uncertainty  when  eliciting  and  aggregating  preferences  [36,32,33].  See  [21] for  a  longer  discussion  on  the 
connections between these problems.

The  rest  of  the  paper  is  organised  as  follows.  In  Section 2 we  provide  background.  Section 3 focuses  on  unweighted 
manipulation and Section 4 on the weighted case. Section 5 presents four heuristic algorithms that aim to ﬁnd the minimum 
number of manipulators and Section 6 evaluates these algorithms experimentally. In Section 7 we present two interesting 
connections between unweighted coalitional manipulation of the Borda rule and two problems from discrete mathematics. 
We conclude in Section 8.

2.  Background

Let C = {c1, . . . , cm} be the set of m candidates (or alternatives). A linear order on C is a transitive, antisymmetric, and 
total relation on C. The set of all linear orders on C is denoted by L(C). An n-voter proﬁle  P on C consists of n linear orders 
on C. That is, P = (V 1, . . . , V n), where for every  j ≤ n, V j ∈ L(C). The set of all n-proﬁles is denoted by Fn. A (deterministic) 
voting rule r is a function that maps any proﬁle on C to a unique winning candidate, that is, r : F1 ∪ F2 ∪ . . . → C. When 
voters  are  weighted,  we  have  a  function  w that  associates  each  voter  j with  a  ﬁxed  positive  integer  w( j).  A  voting  rule 
treats weights as if we had  w( j) identical copies of the voter  j.

22

J. Davies et al. / Artiﬁcial Intelligence 217 (2014) 20–42

Borda rule  The  Borda rule,  proposed  by  Jean-Charles  de  Borda  in  1770,  is  a  positional  scoring  rule  that  gives  a  score  of 
m − i to candidate a for each vote that puts candidate a in ith place. The candidate with the highest total Borda score wins. 
We  write  s(a, P ) for  the  total  Borda  score  given  to  candidate a from  the  proﬁle  of  votes  P ,  and  s(a) where  P is  obvious 
from the context. A score vector (cid:7)s1, . . . , sm(cid:8) indicates that the  ith candidate receives the Borda score  si . The Borda rule is 
used in parliamentary elections in Slovenia and, in modiﬁed form, in elections within the Paciﬁc Island states of Kiribati and 
Nauru. The Borda rule or similar scoring rules are also used by many organisations and competitions including the Robocup 
autonomous robot soccer competition, the X.Org Foundation, the Eurovision song contest, and in the election of the Most 
Valuable Player in major league baseball. The Borda rule has many good features. For instance, it is monotone, as increasing 
the score for a candidate only helps them win. It never elects the Condorcet loser (a candidate that loses to all others in 
pairwise elections). However, it may fail to elect a Condorcet winner (a candidate that beats all others in pairwise elections) 
even if one exists.

Nanson’s and Baldwin’s rules  These rules are derived from the Borda rule. Nanson’s rule eliminates all candidates with less 
than  the  average  Borda  score [29].  This  step  is  then  repeated  with  the  reduced  set  of  candidates  until  there  is  a  single 
candidate  left.  A  closely  related  voting  rule  proposed  by  Baldwin  successively  eliminates  one  of  the  candidates  with  the 
lowest Borda score1 until one candidate remains [1]. The two rules are closely related. Indeed, they are sometimes confused 
in the literature. One of the most appealing properties of Nanson’s and Baldwin’s rules is that they are Condorcet consistent, 
i.e. they elect the Condorcet winner whenever one exists. This follows from the fact that the Borda score of the Condorcet 
winner  is  never  below  the  average  Borda  score.  Both  rules  satisfy  several  other  desirable  criteria,  including  the  majority 
criterion,  i.e.,  a  candidate  that  is  preferred  by  a  majority  of  voters  always  wins,  and  the  Condorcet  loser  criterion.  There 
are also properties which distinguish them. For instance, Nanson’s rule satisﬁes reversal symmetry (i.e. if there is a unique 
winner under all tie breaking rules and all voters reverse their votes then the winner changes) but Baldwin’s rule does not. 
Finally, there are also desirable properties that neither rule satisﬁes like monotonicity.

The manipulation problem  We  can  now  formally  deﬁne  the  different  manipulation  problems  we  consider.  The  unweighted 
coalitional manipulation problem is deﬁned as follows.

Deﬁnition 1  (r-Coalitional-Manipulation).  Given  a  tuple  (P NM, p, M),  where  P NM is  the  non-manipulators’  proﬁle,  p is 
the  candidate  preferred  by  the  manipulators,  and  M is  the  set  of  manipulators,  does  there  exist  a  proﬁle  P M for  the 
manipulators  such  that  r(P NM ∪ P M ) = p?  In  other  words,  does  there  exist  a  proﬁle  P M for  the  manipulators  such  that 
candidate  p wins an election under the voting rule r and the proﬁle  P NM ∪ P M ?

We  drop  the  word  “coalitional”  when  there  is  a  single  manipulator.  The  weighted coalitional manipulation is  deﬁned 

similarly, where the weights of the voters (both non-manipulators and manipulators) are also given as inputs.

Deﬁnition 2 (r-Weighted-Coalitional-Manipulation). Given a tuple (P NM, p, w, M), where  P NM is the non-manipulators’ 
proﬁle,  p is  the  candidate  preferred  by  the  manipulators,  w is  the  weighting  function  and  M is  the  set  of  manipulators, 
does there exist a proﬁle  P M for the manipulators such that r(w, P NM ∪ P M ) = p? In words, does there exist a proﬁle  P M
for the manipulators such that candidate  p wins an election under the voting rule r and the proﬁle  P NM ∪ P M ?

The corresponding optimisation versions of these problems seek to minimise |M|, the number of manipulators.
As is common in much of the literature, we break ties in favour of the coalition of the manipulators. This tie-breaking 
rule  was  originally  used  in  [3];  see  [18] for  a  discussion  of  why  this  has  become  a  “tradition”.  We  also  assume  that  the 
manipulators have complete knowledge about the scores from the votes of the non-manipulators. Again, this has become 
the “tradition” within the literature from some of the earliest work. The argument often put forward for the assumption of 
complete information is that partial or probabilistic information about the votes of the non-manipulators would add to the 
computational complexity of computing a manipulation.

Given a set of votes and n manipulators, it is in the best interest of all manipulators to place the preferred candidate, 
p,  ﬁrst  for  the  Borda  rule.  Hence,  p will  have  Borda  score  s(p) + n(m − 1).  We  deﬁne  the  gap of  candidate  i as  g(i) =
s(p) + n(m − 1) − s(i). For p to win under Borda voting, we need the manipulating votes to give to candidate i (where i (cid:9)= p) 
a total Borda score which is less than or equal to  g(i). Note that if  g(i) is negative for even one i, then  p cannot win under 
Borda voting.

In the proofs of this paper, we will often need to refer to pairs of votes of a particular form. We deﬁne the pair of votes 
W (u,v) = {u (cid:10) v (cid:10) Others, rev(Others) (cid:10) u (cid:10) v} where  Others is a total order in which the candidates in C \ {u, v} are in a 
pre-deﬁned lexicographic order, and rev(Others) is its reverse.

1 If multiple candidates have the lowest score, then we use a tie-breaking mechanism to eliminate one of them.

J. Davies et al. / Artiﬁcial Intelligence 217 (2014) 20–42

23

3.  Unweighted coalitional manipulation

We  start  by  considering  the  computational  complexity  of  manipulating  Borda,  Nanson’s  and  Baldwin’s  rules  with  un-
weighted  votes.  We  prove  that  the  coalitional  manipulation  problem  is  NP-complete  under  the  Borda  rule  with  two 
manipulators.  This  settles  an  open  problem  in  computational  social  choice.  We  also  show  that  Baldwin’s  and  Nanson’s 
rules are NP-complete to manipulate even with a single manipulator.

3.1.  Borda rule

In this section we present one of our main results. We prove that computing a manipulation of the Borda rule is NP-hard 
for  two  manipulators.  Our  NP-hardness  proof  uses  a  reduction  from  a  specialised  permutation  problem  that  is  strongly 
NP-complete [42].

Deﬁnition 3 (Permutation Sum). Given q integers  X1 ≤ · · · ≤ Xq where 
σ and π of 1 to q such that σ (i) + π (i) = Xi ?

(cid:2)
q

i=1 Xi = q(q + 1), do there exist two permutations 

We ﬁrst give a technical lemma that shows we can construct votes for the non-manipulators with a given target sum.

Lemma 1. Given integers X1 to Xm, we can construct, in time polynomial in 
Borda score of candidate ci is Xi + C for 1 ≤ i ≤ m, and for candidate cm+1 is y ≤ C , for some integer C ≥ 0.

i=1 Xi , votes over m + 1 candidates such that the total 

m

(cid:2)

Proof. This proof uses the construction of McGarvey [28], which has been used elsewhere in the computational social choice 
literature [41,6]. We show how to increase the score of a candidate by 1 more than the other candidates except for the last 
candidate whose score increases by 1 less. For instance, suppose we wish to increase the score of candidate c1 by 1 more 
than candidates c2 to cm, and by 2 more than candidate cm+1. Consider the pair of votes  W (c1,cm+1) deﬁned in Section 2, 
and given below:

c1 (cid:10) cm+1 (cid:10) c2 (cid:10) . . . (cid:10) cm−1 (cid:10) cm
cm (cid:10) cm−1 (cid:10) . . . (cid:10) c2 (cid:10) c1 (cid:10) cm+1.

The score of candidate c1 increases by m + 1, of candidates c2 to cm by m, and of candidate cm+1 by m − 1. By repeated 
construction of such votes, we can achieve the desired result. For example, we may construct  Xi copies of W (ci ,cm+1) for all 
1 ≤ i ≤ m.

As the number of votes is linear in 

m

i=1 Xi , the time is polynomial in the sum of the given integers. (cid:2)

(cid:2)

Theorem 1. Unweighted coalitional manipulation for the Borda rule is NP-complete with two manipulators.

Proof. The problem is clearly in NP, since a set of manipulator votes that make the preferred candidate win is a polynomial 
witness that a manipulation exists.

To  show  NP-hardness,  we  reduce  from  the Permutation Sum problem.  Given  an  instance  of Permutation Sum with  q
integers,  X1 to  Xq,  we  assume,  without  loss  of  generality,  that  2 ≤ Xi ≤ 2q for  all  i ∈ {1, . . . , q}.  Given  such  an  instance 
of Permutation Sum,  we  create  a  manipulation  problem  with  m = q + 3 candidates  p, a1 . . . , aq+2 where  the  preferred 
candidate  of  the  two  manipulators  is  p.  By  Lemma 1,  we  can  construct  an  election  in  which  the  non-manipulators  cast 
votes to give the score vector for (cid:7)p, a1, . . . aq+2(cid:8) of:

(cid:3)

C, 2(q + 2) − X1 + C, . . . , 2(q + 2) − Xq + C, 2(q + 2) + C, y

(cid:4)

for some C ≥ 0 and  y ≤ C . We show next that two manipulators can make candidate  p win such an election if and only if 
the Permutation Sum problem has a solution.

(⇒) Suppose we have two permutations σ and π of 1 to n with σ (i) + π (i) = Xi . We construct two manipulating votes, 

in which the candidates get the following scores, respectively:

(cid:3)
q + 2, σ (1), . . . , σ (q), 0, q + 1
(cid:3)
q + 2, π (1), . . . , π (q), 0, q + 1

(cid:4)

(cid:4)

.

Since σ (i) + π (i) = Xi , these give a total score vector:

(cid:3)

2(q + 2) + C, 2(q + 2) + C, . . . , 2(q + 2) + C, 2(q + 1) + y

(cid:4)
.

As  y ≤ C and we tie-break in favour of the manipulators, candidate  p wins.

24

J. Davies et al. / Artiﬁcial Intelligence 217 (2014) 20–42

(⇐) Suppose we have a successful manipulation. To ensure candidate  p beats candidate aq+1, both manipulators must 
put candidate  p in ﬁrst place. Similarly, both manipulators must put candidate aq+1 in last place, otherwise candidate aq+1
will beat our preferred candidate. Hence the ﬁnal score of candidate  p is 2(q + 2) + C . The gap between the ﬁnal score of 
candidate  p and the current score of candidate ai (where 1 ≤ i ≤ q) is  Xi . The sum of these gaps is q(q + 1). Therefore, if 
any candidate a1 to aq gets a score of q + 1 then candidate  p will be beaten. Hence, the two scores of q + 1 have to go to 
the least dangerous candidate which is candidate aq+2.
The votes of the manipulators are thus of the form:

(cid:3)
q + 2, σ (1), . . . , σ (q), 0, q + 1
(cid:3)
q + 2, π (1), . . . , π (q), 0, q + 1

(cid:4)

(cid:4)

where σ and π are two permutations of 1 to q. To ensure candidate  p beats candidate a j for  j ∈ [1, q], we must have:

2(q + 2) − X j + C + σ ( j) + π ( j) ≤ 2(q + 2) + C.

Rearranging this gives:

σ ( j) + π ( j) ≤ X j.
(cid:2)
q

i=1 Xi = q(q + 1) and 

Since 

(cid:2)
q

i=1 σ (i) =

σ ( j) + π ( j) = X j.

(cid:2)
q

i=1 π (i) = q(q+1)

2

, there can be no slack in any of these inequalities. Hence,

That is, we have a solution of the Permutation Sum problem.  (cid:2)

The  result  of  Theorem 1 was  proved  independently  by  Betzler  et  al. [7] using  a  different  reduction  from  the  same 
problem.  Their  proof  relies  on  the  same  basic  idea  as  ours  –  constructing  a  set  of  non-manipulating  votes  such  that  the 
candidates have speciﬁc gaps. In contrast to our proof which needs Θ(m) non-manipulators and a single dummy candidate 
using  the  construction  of  Lemma 1,  Betzler  et  al.  use  a  more  complicated  construction  which  introduces  Θ(m) dummy 
candidates but needs only three non-manipulating votes. It follows therefore that the problem of computing a manipulation 
is not ﬁxed parameter tractable in the number of voters.

3.2.  Baldwin’s rule

Our next result is proved by reduction from the exact 3-cover (X3C) problem.

Deﬁnition 4 (X3C). Given two sets V = {v 1, . . . , vq}, q = 3r, and S = {S1, . . . , St}, where t ≥ 2 and for all  j ≤ t, |S j| = 3 and 
S j ⊆ V , does there exist a subset S (cid:15)

of S such that each element in V is in exactly one of the 3-sets in S (cid:15)

?

Theorem 2. Unweighted manipulation for Baldwin’s rule is NP-complete with one manipulator.

Proof. We give a reduction from X3C. Given an X3C instance V = {v 1, . . . , vq}, S = {S1, . . . , St}, we let the set of candidates 
be  C = {p, d, b} ∪ V ∪ A,  where  p is  the  manipulator’s  preferred  candidate,  A = {a1, . . . , at},  and  d and  b are  additional 
candidates. Members of A correspond to the 3-sets in S. Let m = |C| = q + t + 3.

The proﬁle  P contains two parts:  P 1, which is used to control the changes in the score differences between candidates, 

after a set of candidates is removed, and  P 2, which is used to balance the score differences between the candidates.

We make the following observations about the pair of votes  W (c1,c2), which were deﬁned in Section 2. First, these two 

votes give the following scores to each candidate

s(c1): m
s(c2): m − 2
s(e): m − 1 for e ∈ Others

Second, for any set of candidates C(cid:15) ⊆ C and any pair of candidates e1, e2 ∈ C \ C(cid:15)

,

s(e1, W (c1,c2)|C\C(cid:15) ) − s(e2, W (c1,c2)|C\C(cid:15) ) = s(e1, W (c1,c2)) − s(e2, W (c1,c2)) +

⎧
⎨

⎩

if e1 = c2 and c1 ∈ C(cid:15)
1
−1 if e1 = c1 and c2 ∈ C(cid:15)
0

otherwise.

(1)

Here W (c1,c2)|C\C(cid:15) is the pair of votes obtained from W (c1,c2) by removing all candidates in C(cid:15)
. In words, the formula states 
that after C(cid:15)
is removed, the score difference between e1 and e2 is increased by 1 if and only if e1 = c2 and c1 is removed; 
it  is  decreased  by  1 if  and  only  if  e1 = c1 and  c2 is  removed;  for  any  other  cases,  the  score  difference  does  not  change. 
Additionally, for any e ∈ C \ {c1, c2}, s(c1, W (c1,c2)) − s(e, W (c1,c2)) = 1 and s(c2, W (c1,c2)) − s(e, W (c1,c2)) = −1.

We  next  show  how  to  use  votes  of  the  form  W (c1,c2) to  construct  the  ﬁrst  part  of  the  proﬁle  P 1.  We  recall  that m =

|C| = q + t + 3.  P 1 is composed of the following votes:

J. Davies et al. / Artiﬁcial Intelligence 217 (2014) 20–42

25

• for each  j ≤ t and each v i ∈ S j , there are 2m copies of W (v i ,a j );
• for each i ≤ q, there are m copies of W (b,v i );
• there are m(t + 6) copies of W (b,p).

Let  avg(P 1) be  the  average  score  of  candidates  in  P 1.  That  is,  avg(P 1) = s(d, P 1) = (m − 1)(6mt + mq + m(t + 6)).  Deﬁne 
occ(i) to be the number of occurrences of the element v i in sets in S. The votes in  P 1 give the scores

s(v i, P 1): avg(P 1) + 2m · occ(i) − m
s(a j, P 1): avg(P 1) − 6m
s(p, P 1):
s(b, P 1):
s(d, P 1):

avg(P 1) − m(t + 6)
avg(P 1) + mq + m(t + 6)
avg(P 1)

It is not hard to verify that s(b, P 1) − s(p, P 1) ≥ mq, and for any c
following votes:

(cid:15) ∈ V ∪ A, s(c

(cid:15), P 1) − s(p, P 1) ≥ 2m.  P 2 is composed of the 

• for each i ≤ q, there are s(v i, P 1) − s(p, P 1) − m = 2m · occ(i) + mt + 4m copies of W (d,v i );
• for each  j ≤ t, there are s(a j, P 1) − s(p, P 1) − 1 = mt − 1 copies of W (d,a j );
• there are s(b, P 1) − s(p, P 1) − mq = 2m(t + 6) copies of W (d,b).

Let avg(P 2) be the average score of candidates in  P 2. That is, avg(P 2) = s(p, P 2) = (m − 1)(2m ·
t(mt − 1) + 2m(t + 6)). The votes in  P 2 give the scores:

(cid:2)
q

i=1 occ(i) + mtq + 4mq +

s(v i, P 2): avg(P 2) − (2m · occ(i) + mt + 4m)
s(a j, P 2): avg(P 2) − (mt − 1)
s(p, P 2):
avg(P 2)
avg(P 2) − 2m(t + 6)
s(b, P 2):
avg(P 2) + 2m ·
s(d, P 2):

(cid:2)
q

i=1 occ(i) + mtq + 4mq + t(mt − 1) + 2m(t + 6)

Let  P = P 1 ∪ P 2, avg(P ) = avg(P 1) + avg(P 2). The combined Borda scores are:

s(v i, P ): avg(P ) − m(t + 5)
s(a j, P ): avg(P ) − m(t + 6) + 1
s(p, P ):
s(b, P ):
s(d, P ):

avg(P ) − m(t + 6)
avg(P ) + mq − m(t + 6)
avg(P ) + qm(t + 5) + t(m(t + 6) − 1) + 2m(t + 6) − mq

We make the following observations about the Borda scores of the candidates in  P .

• For any i ≤ q, s(v i, P ) − s(p, P ) = m.
• For any  j ≤ t, s(a j, P ) − s(p, P ) = 1.
• s(b, P ) − s(p, P ) = mq.

Suppose the X3C instance has a solution  S1, . . . , Sq/3 (this is without loss of generality since we can rename the sub-

scripts of the 3-sets in the solution to {1, . . . , q/3}). Then, we let the manipulator vote as follows:

p (cid:10) d (cid:10) aq/3+1 (cid:10) · · · (cid:10) at (cid:10) b (cid:10) V (cid:10) aq/3 (cid:10) · · · (cid:10) a1.

In the following, we use Ck to denote the set of candidates that have not yet been eliminated after round k.
The candidates with the lowest Borda score before the manipulator’s vote are  p followed by all a j ’s, which all have 1 
more, as explained above. With the manipulator’s vote,  p overtakes all a j . Moreover, a1 has the lowest Borda score, which 
means that a1 is eliminated in the ﬁrst round. We next show that for all  j = 1, . . . , q/3, in round  4 j − 3, candidate a j is 
eliminated, and in round 4 j − 2, 4 j − 1, 4 j,  S j are eliminated.

Suppose  this  holds  for  all  rounds  before  round  4 j − 2.  In  round  4 j − 3 candidate  a j is  eliminated.  By  Eq. (1),  for  all 

c

(cid:15) ∈ C4 j−3 \ (S j ∪ {d, p}), we have
(cid:9)

(cid:15)

(cid:8)
c

, P |C4 j−3

(cid:8)
s
c
s(d, P |C4 j−3 ) − s(p, P |C4 j−3 ) = s(d, P |C4 j−4 ) − s(p, P |C4 j−4 ) − (mt − 1)

− s(p, P |C4 j−3 ) = s

− s(p, P |C4 j−4 )

, P |C4 j−4

(cid:9)

(cid:15)

and for any v ∈ S j , we have

s(v, P |C4 j−3 ) − s(p, P |C4 j−3 ) = s(v, P |C4 j−4 ) − s(p, P |C4 j−4 ) − 2m

26

J. Davies et al. / Artiﬁcial Intelligence 217 (2014) 20–42

Therefore, in round 4 j − 2, the difference between  p and the candidates in  S j is decreased by 2m, which covers their 
initial  difference  of  m and  also  the  difference  in  the  manipulator’s  vote  (as  this  can  be  at  most  m − 2).  Meanwhile,  d is 
still  leading  by  a  large  margin.  Therefore,  in  rounds  4 j − 2, 4 j − 1, 4 j,  the  candidates  in  S j are  eliminated  (the  order  of 
elimination does not matter). Eliminating each v ∈ S j has three effects on score difference between p and other candidates:

1. the score difference between all ak with v ∈ Sk and  p is increased by 2m;
2. the score difference between b and  p is decreased by m;
3. the score difference between d and  p is decreased by the number of copies of W (d,v) in  P .

These do not affect the fact that candidates in  S j are eliminated in rounds 4 j − 2, 4 j − 1, 4 j, and we also note that for all 
j < k ≤ q/3, the score difference between p and ak does not change. Therefore, in round 4 j + 1 candidate  j + 1 is eliminated.
Continuing, after the ﬁrst 4q/3 rounds, all candidates  v i are eliminated, each decreasing the score difference between b
and p by m for a total of mq. Hence b and p are tied for the lowest total Borda score in  P (it is not hard to verify that other 
ak and  d still  have  higher  scores).  Considering  the  manipulator’s  vote,  b is  eliminated  next.  This  decreases  the  difference 
between d and  p by  3m(t + 6) (which  is  the  cumulative  effect  of  the  third  set  of  votes  in  P 1 and  the  third  set  of  votes 
in  P 2), and between aq/3+1, . . . , aq and  p by m(t + 6) (by the third set of votes in  P 1). It follows that in the next t − q/3
rounds, all remaining candidates in A are eliminated. Finally, when only  p and d remain, they are tied in  P . But since the 
manipulator prefers  p to d,  p is the winner.

Suppose  the  manipulator  can  cast  a  vote  to  make  p the  winner.  We  ﬁrst  note  that,  from  the  votes  in  P 1,  as  long  as 
not  all  of  the  candidates  in  V ,  A and  b are  eliminated,  the  difference  between  the  score  of  d and  p is  greater  than  m, 
so  it  cannot  be  covered  by  the  vote  of  the  manipulator.  Hence,  d must  be  eliminated  after  these  other  candidates,  that 
is,  in  the  last  round.  In  the  round  when  b is  eliminated,  the  score  of  b can  be  no  more  than  the  score  of  p.  We  note 
that  s(b, P ) − s(p, P ) = mq and  the  score  difference  can  only  be  reduced  by  the  manipulator  ranking  b below  p,  and  by 
eliminating  v 1, . . . , vq before  b.  However,  ranking  b below  p reduces  the  score  difference  by  no  more  than  m − 1 and 
eliminating any single candidate in V reduces the difference by m. Therefore, before b drops out, all q candidates in V must 
have already dropped out. We note that for any  v i ∈ V , s(v i, P ) − s(p, P ) = m, so the manipulator’s vote cannot cover this 
difference.  Also  the  only  other  way  to  reduce  this  difference  is  by  eliminating  some  a j with  v i ∈ S j .  Therefore,  for  each 
v i ∈ V , there exists at least one a j with  v i ∈ S j that is removed before  v i . For any such a j , no candidate  v i ∈ S j can drop 
out before a j . Otherwise the difference between a j and p is increased by 2m, reaching 2m + 1. Therefore, before b drops out, 
this difference cannot be covered by the manipulator’s vote, which means that p drops out before a j . This is a contradiction 
since we assume that  p drops out after b. On the other hand, no other candidate ak with  S j ∩ Sk (cid:9)= ∅ can drop out before 
b, because when the candidates in the intersection of  S j and  Sk drop out, the difference between ak and  p is increased by 
2m and becomes positive. Finally, we note that after a j drops out, in the next three rounds the candidates in  S j drop out. 
It follows that the set of candidates in A that drop out before the candidates in V that they cover corresponds to an exact 
cover of V . After all the candidates in V drop out, b drops out, followed by the rest of the candidates in A and then d, as 
above.

Therefore,  the  unweighted  manipulation  problem  under  Baldwin’s  rule  is  NP-complete  with  only  a  single  manipula-

tor. (cid:2)

3.3.  Nanson’s rule

We reduce the exact 3-cover (X3C) problem to a manipulation problem under Nanson’s rule.

Theorem 3. Unweighted manipulation for Nanson’s rule is NP-complete with one manipulator.

Proof. The  idea  of  the  proof  is  similar  to  that  of  the  proof  of  Theorem 2.  We  prove  NP-completeness  by  reduction  from
X3C with  t ≥ 3q (this  is  without  loss  of  generality  because  if  t < q then  we  can  add  dummy  S 1’s  to  S).  Given  an X3C
instance  V = {v 1, . . . , vq},  S = {S1, . . . , St},  we  let  the  set  of  alternatives  be  C = {p, d, b1, b2} ∪ V ∪ A,  where  p is  the 
manipulator’s preferred candidate, V = {v 1, . . . , vq}, A = {a1, . . . , at}, and d, b1, and b2 are auxiliary alternatives. Without 
loss of generality, both q and t are even, and t ≥ 3q. We will use the votes  W (c1,c2) deﬁned in Section 2 to construct the 
proﬁle. For any C(cid:15) (cid:2) C, we make the following observations about W (c1,c2).

(cid:8)
c

(cid:15)

s

, W (c1,c2)|C\C(cid:15)

(cid:9)

− |C \ C(cid:15)| + 1 =

(cid:15) = c1 and c2 /∈ C(cid:15)
(cid:15) = c2 and c1 /∈ C(cid:15)

(2)

⎧
⎨

⎩

1
if c
−1 if c
0

otherwise.

We note that |C \ C(cid:15)| − 1 is the average score of the alternatives in W (c1,c2)|C\C(cid:15) .

Let  m = q + t + 4.  Again,  the  proﬁle  has  two  parts:  P 1,  which  is  used  to  control  the  score  differences  between  the 

alternatives and the average score, and  P 2, which is used to set the initial scores.  P 1 consists of the following votes:

• for every  j ≤ t there are 7m/2 − q/3 copies of W (a j ,b1);

J. Davies et al. / Artiﬁcial Intelligence 217 (2014) 20–42

27

• for every v i ∈ S j (there are three of them), there are m copies of W (v i ,a j );
• for every i ≤ q, there are m copies of W (v i ,p);
• there are mq copies of W (p,b1);
• there are mq + t(7m/2 − q/3) copies of W (b1,b2).

The second part of the proﬁle, P 2, consists of the following votes, where occ(v i) is the number of times that v i is covered 

by the 3-sets in S:

• for any i ≤ q, there are m · occ(v i) copies of W (d,v i ),

Let  P = P 1 ∪ P 2 and let avg(P ) = (m − 1)|P |/2. We make the following observations about  P :

(cid:2)
q

• s(p, P ) − avg(P ) = 0.
• s(d, P ) − avg(P ) = m(
• s(b1, P ) − avg(P ) = 0.
• s(b2, P ) − avg(P ) = −(mq + t(7m/2 − q/3)).
• For any  j ≤ t, s(a j, P ) − avg(P ) = m/2 − q/3.
• For any i ≤ q, s(v i, P ) − avg(P ) = m.

i=1 occ(v i)) = 3mt.

Suppose the X3C instance has a solution {S1, . . . , Sq/3} (this is without loss of generality since we can rename the subscripts 
of the 3-sets in the solution to {1, . . . , q/3}). Then, we let the manipulator vote as follows:

p (cid:10) b1 (cid:10) b2 (cid:10) d (cid:10) aq/3+1 (cid:10) · · · (cid:10) at (cid:10) V (cid:10) aq/3 (cid:10) · · · (cid:10) a1.

The  manipulator’s  vote  does  not  change  the  score  of  any  candidate  with  respect  to  the  average  by  more  than  (m − 1)/2, 
therefore b2 will be eliminated in the ﬁrst round. The difference between the score of candidate a j for 1 ≤ j ≤ q/3 and the 
average will be m/2 − q/3 − ((m − 1)/2 − j + 1). Since  j ≤ q/3, this is seen to be less than or equal to −1/2, hence these 
candidates are also eliminated in the ﬁrst round. No other candidates are eliminated in the ﬁrst round: for all candidates in 
V , the manipulator’s vote is not enough to make their score less than the average, while all other candidates receive more 
than the average from the manipulator.

Let C1 = C \ {a1, . . . , aq/3}. In the second round, by Eq. (2), for any  v i ∈ V , s(v i, P |C1 ) − avg(P |C1 ) = 0. The reason is that 
each  v i gets m(occ(i) − 1) points from the second part of  P 1 because {S1, . . . , Sq/3} covers V , m points from the third part 
of  P 1, and −m · occ(i) points from  P 2. Counting in the manipulator’s vote and recalling that we assumed t ≥ 2q, we have 
that the scores of all candidates in V are below the average score. Moreover, because b2 was eliminated in the ﬁrst round, 
the score of b1 is now below the average. Therefore, b1 and all the candidates in V are the only candidates eliminated in 
the second round.

Let  C2 = C \ ({b1, b2, a1, . . . , aq/3} ∪ V).  In  the  beginning  of  the  third  round,  because  b1, b2,  and  all  candidates  in  V
were  eliminated,  we  have  that  for  each  W (c1,c2) in  P ,  at  least  one  of  c1 and  c2 was  eliminated.  Therefore,  the  score  of 
all remaining candidates is the same as the average score in  P |C2 . Moreover, for the same reason, in any later round the 
score of all remaining candidates is the same as the average score in  P (restricted to the remaining candidates). Therefore 
the manipulator’s vote becomes decisive. It follows that in each of the following rounds, the candidates ranked below the 
mid-position in the manipulator’s votes are eliminated. The ﬁnal winner is the manipulator’s top-ranked candidate, which 
is  p.

Next, we show that if the manipulator can cast a vote to make  p win, then there exists a solution to the X3C instance. 
In the ﬁrst round b2 deﬁnitely drops out. This makes the score of b1 below the average score in the second round (from the 
mq + t(7m/2 − q/3) copies of  W (b1,b2) in  P 1), which means that b1 will deﬁnitely drop out in the second round. If any of 
the v i candidates remain in the third round, then the score of p will be strictly lower than the average score (from m copies 
of  W (v i ,p) in  P 1). Therefore, all alternatives in V must drop out in the ﬁrst and second rounds. In fact,  v i ’s can only drop 
out in the second round, and only when there exists  j such that v i ∈ S j and the alternative a j drops out in the ﬁrst round. 
Moreover, no more than q/3 alternatives in A can possibly drop out in the ﬁrst round (since the only way for them to drop 
out is to be ranked among the bottom q/3 positions). Therefore, in order for  p to survive the third round, the bottom q/3
alternatives in the manipulator’s vote must be among A and they must correspond to an exact cover of V , which means 
that the X3C instance has a solution.

Therefore, the unweighted manipulation problem under Nanson’s rule is NP-complete when there is only one manipula-

tor. (cid:2)

Our results about the complexity of manipulating Baldwin’s and Nanson’s rules signiﬁcantly increase the size of the set 
of voting rules used in practice that are known to be NP-hard to manipulate with a single manipulator. They also contrast to 
Borda where computing a manipulation with a single manipulator can be done in polynomial time [3]. Adding elimination 
rounds  to  Borda  to  get  Nanson’s  or  Baldwin’s  rules  increases  the  computational  complexity  of  computing  a  manipulation 
with one manipulator from polynomial-time to NP-hard.

28

J. Davies et al. / Artiﬁcial Intelligence 217 (2014) 20–42

4.  Weighted coalitional manipulation

In this section we show that weighted coalitional manipulation under Baldwin’s or Nanson’s rules is NP-complete. It has 
already been shown that the weighted coalitional manipulation problem for Borda is NP-hard for three or more candidates 
[12].

4.1.  Baldwin’s rule

Similar to the case of Borda, we prove that the weighted coalitional manipulation problem for Baldwin’s rule is NP-hard 

for three or more candidates. Our result is proved by reduction from the Partition problem.

Deﬁnition 5  (Partition).  Given  a  set  of  integers  A = {k1, . . . , kq} such  that 
these numbers into two sets the elements in each of which sum to  K ?

(cid:2)
q

i=1 ki = 2K ,  does  there  exist  a  partition  of 

A partition that witnesses the satisﬁability of a Partition instance is called a perfect partition.

Theorem 4. For Baldwin’s rule and weighted votes, the coalitional manipulation problem is NP-hard with three or more candidates.

Proof. We reduce from the partition problem. We construct a coalitional manipulation problem with three candidates (a, 
b, and  p) in which the manipulators want to make  p win.

We suppose the non-manipulators have voted as in the following table.

weights

11K
5K
14K
2K − 1
5K
5K

votes
a (cid:10) b (cid:10) p
a (cid:10) p (cid:10) b
b (cid:10) p (cid:10) a
b (cid:10) a (cid:10) p
p (cid:10) a (cid:10) b
p (cid:10) b (cid:10) a

At this point the scores of the candidates are

s(a): 39K − 1
s(b): 48K − 2
s(p): 39K .

For each integer ki ∈ A, we have a member of the manipulating coalition with weight 3ki .
Suppose there is a perfect partition. Let the manipulators corresponding to the integers in one half of the partition vote 
a (cid:10) p (cid:10) b, and the others vote p (cid:10) a (cid:10) b. The scores are now as follows: s(a) = 48K − 1, s(b) = 48K − 2, s(p) = 48K . Hence b
will be eliminated. In the next round,  p wins as s(a) = 21K − 1 but s(p) = 27K . Thus the manipulators can make  p win if 
a perfect partition exists.

Conversely, suppose there is a manipulation in which p wins. Suppose a is eliminated in the ﬁrst round. Then the scores 
in the second round from the non-manipulators are: s(b) = 27K − 1, and s(p) = 15K . The manipulators cannot now prevent 
b from winning. Hence b must be eliminated in the ﬁrst round. If any manipulator puts b above last place, b will not be 
eliminated and will win. Thus all the votes of the manipulators are a (cid:10) p (cid:10) b or  p (cid:10) a (cid:10) b. Consider the following partition 
of  A constructed  from  any  successful  manipulation.  In  the  ﬁrst  half  of  the  partition,  we  put  all  integers  associated  with 
weighted votes of the manipulators of the form a (cid:10) p (cid:10) b. In the second half, we put all integers associated with weighted 
votes of the form  p (cid:10) a (cid:10) b. Suppose the ﬁrst half of the partition sums up to  K − x and the second half sums up to  K + x. 
Then we have scores: s(a) = 48K − 1 − 3x, s(b) = 48K − 2 and s(p) = 48K + 3x. If x ≥ 1 then a is eliminated. On the other 
hand, if x ≤ −1 then  p is eliminated. Hence x = 0 and we have a perfect partition. For more than three candidates, we add 
“harmless” candidates that are in the last places of every vote of the non-manipulators. (cid:2)

Note that Coleman and Teague in Theorem 13 of [11] provide an NP-hardness result for the weighted coalitional manipu-
lation problem for voting rules like Baldwin’s that eliminate candidates one by one. Our result for Baldwin’s rule is different 
in two aspects. First, Coleman and Teague use a different tie-breaking rule. They break ties against the manipulator whilst, 
as is more common in the literature, we suppose ties are broken in their favour. The second difference is that Coleman and 
Teague  do  not  specify  a  precise  bound  on  the  number  of  candidates,  while  we  present  a  proof  that  weighted  coalitional 
manipulation under Baldwin’s rule is NP-hard for just three candidates.

J. Davies et al. / Artiﬁcial Intelligence 217 (2014) 20–42

29

4.2.  Nanson’s rule

We  show  that  the  weighted  coalitional  manipulation  problem  under  Nanson’s  rule  is  NP-complete  with  four  or  more 
candidates.  However,  if  there  are  at  most  three  candidates,  the  computational  complexity  of  computing  a  manipulation 
under Nanson’s rule is polynomial-time.

Theorem 5. For Nanson’s rule and weighted votes, the coalitional manipulation problem is NP-complete with four or more candidates.

Proof. We reduce from partition. For any partition instance, we construct a coalitional manipulation problem with four 
candidates (a, b, c, and  p) where  p is the candidate that the manipulators wish to win. We suppose the non-manipulators 
have voted as in the following table.

weights
2(2K + 1)
2(2K + 1)
2(2K + 1)
2(2K + 1)
2(K + 2)
2(K + 2)
1
1
1
2
2
2

votes
b (cid:10) p (cid:10) c (cid:10) a
a (cid:10) c (cid:10) b (cid:10) p
c (cid:10) p (cid:10) b (cid:10) a
a (cid:10) b (cid:10) c (cid:10) p
p (cid:10) a (cid:10) b (cid:10) c
c (cid:10) b (cid:10) p (cid:10) a
p (cid:10) a (cid:10) b (cid:10) c
a (cid:10) b (cid:10) c (cid:10) p
a (cid:10) b (cid:10) p (cid:10) c
c (cid:10) p (cid:10) a (cid:10) b
a (cid:10) c (cid:10) p (cid:10) b
b (cid:10) p (cid:10) a (cid:10) c

The total scores from non-manipulators are as follows:  s(a) = 28K + 38,  s(b) = 34K + 37,  s(c) = 34K + 37 and  s(p) =
24K + 38. The average score is 30K + 37.5. For each integer ki , we have a member of the manipulating coalition with weight 
2ki . Now, suppose there is a solution to the partition instance. Let the manipulators corresponding to the integers in one 
half of the partition vote  p (cid:10) a (cid:10) b (cid:10) c, and let the others vote  p (cid:10) a (cid:10) c (cid:10) b.

The total scores are now as follows: s(a) = 36K + 38, s(b) = 36K + 37, s(c) = 36K + 37 and s(p) = 36K + 38. The average 

score is 36K + 37.5.

The alternatives b and c are eliminated, and  p wins in the second round. Thus the manipulators can make  p win if a 

perfect partition exists.

Conversely, suppose there is a successful manipulation. Clearly, we need to ensure that  p is not eliminated in the ﬁrst 
round. To ensure this, all manipulators must rank  p ﬁrst. Otherwise, the score of  p would be less than the average score 
36K + 37.5, so  p would be eliminated. Next, we show that if b and c are not eliminated in the ﬁrst round,  p cannot win 
overall. We consider all possible sets of candidates besides b and c that could be eliminated in the ﬁrst round. There are six 
cases.

1. only a is eliminated in the ﬁrst round. The scores from non-manipulators in the second round are as follows:  s(b) =
24K + 27, s(c) = 24K + 27, and s(p) = 12K + 21. The average score is 20K + 25. Even with the maximum possible score 
of 8K from the manipulators,  p is eliminated. This contradicts the assumption that  p wins.

2. only b is eliminated in the ﬁrst round. Note that if a is not ranked second in the votes of all manipulators, its score 
will  be  less  than  the  average  36K + 37.5 and  it  will  be  eliminated.  This  contradicts  our  assumption  that  p and  a
are  not  eliminated  in  the  ﬁrst  round.  Hence,  all  manipulators  have  to  cast  votes  that  rank  p ﬁrst  and  a second.  The 
votes of the manipulators in the second round will then be  p (cid:10) a (cid:10) c, giving scores s(a) = 22K + 23, s(c) = 24K + 25, 
and  s(p) = 26K + 27.  The  average  score  is  24K + 25.  Hence,  a is  eliminated.  In  the  next  round,  p is  eliminated,  as 
s(p) = 10K + 10, s(c) = 14K + 15, and the average score is 12K + 12.5. This contradicts the assumption that  p wins.

3. only c is eliminated in the ﬁrst round. This case is symmetric to the second case.
4. a and b are eliminated in the ﬁrst round. In the second round, the scores from non-manipulators are s(c) = 14K + 15
and s(p) = 6K + 10. The 4K points from the manipulators cannot now prevent p from being eliminated. This contradicts 
the assumption that  p wins.

5. a and c are eliminated in the ﬁrst round. This is symmetric to the fourth case.
6. a, b, and c are all eliminated in the ﬁrst round. This case is impossible because if b and c are eliminated then a must 

get 8K points from the manipulators. Hence, a reaches the second round.

Thus, the only way for  p to win is if b and c are eliminated in the ﬁrst round. For this to occur, the manipulators have 
to put  p in ﬁrst place, and a in second place. If b gets more than a score of 2K from the manipulators in the ﬁrst round, 
then its total score will be greater then the average of 36K + 37.5 and it will not be eliminated in the ﬁrst round. Similarly, 

30

J. Davies et al. / Artiﬁcial Intelligence 217 (2014) 20–42

if c gets more than a score of 2K from the manipulators, then it will not eliminated in the ﬁrst round. However, as both the 
ﬁrst and second place in the manipulators votes are ﬁxed, there is exactly 4K points to divide between them. Hence, they 
must divide the 4K points equally. Hence, there exists a solution to the partition instance. For more than four candidates, 
we add “harmless” candidates that are in last place in every vote of the non-manipulators. (cid:2)

Clearly,  there  is  a  polynomial-time  algorithm  to  compute  a  manipulation  of  Baldwin’s  rule  with  two  candidates  (since 
this case degenerates to majority voting). For Nanson’s rule, on the other hand, there is a polynomial-time algorithm for up 
to three candidates.

Theorem 6. For Nanson’s rule and weighted votes, the coalitional manipulation problem can be solved in polynomial time for up to 
three candidates.

Proof. Consider an election with three candidates (a, b, and  p) in which the manipulators want  p to win. We prove that in 
a successful manipulation, either all manipulators vote  p (cid:10) a (cid:10) b or they all vote  p (cid:10) b (cid:10) a. If  p does not win using one of 
these two votes, then  p cannot win. Therefore we simply try out the two votes and compute if  p wins in either case.

Suppose the manipulators can make  p win. We ﬁrst note that there is no harm in raising  p to the ﬁrst position while 
keeping the other parts of their preferences the same. By doing so, we ensure that the score of  p goes up and the scores of 
a and b go down. The only possible change in the elimination process is that now both a and b drop out in the ﬁrst round, 
so that  p still wins.

Now,  suppose  that  all  manipulators  rank  p in  their  top  positions.  Let  P M denote  a  proﬁle  for  the  manipulators  that 
makes  p win. Because Nanson’s rule never selects the Condorcet loser, it cannot be the case that both a majority of voters 
prefer a to  p, and b to  p. Without loss of generality, suppose that a majority of voters prefer  p to a. We argue that if all 
manipulators vote  p (cid:10) a (cid:10) b, then  p still wins. For the sake of contradiction, suppose all manipulators vote  p (cid:10) a (cid:10) b but 
p does not win. As the manipulators still rank  p in their top positions, the score of  p in the ﬁrst round is the same as in 
P M . Therefore,  p must enter (and lose) the second round. Hence, only a is eliminated in the ﬁrst round, and in the second 
round a majority of voters prefer b to  p. However, having the manipulators vote  p (cid:10) a (cid:10) b only lowers b’s score in the ﬁrst 
round, compared to the case where they vote  P M . Hence, when the manipulators vote  P M , b also enters the second round 
and then a majority of voters prefer b to  p, which is a contradiction.

Therefore,  if  the  manipulators  can  make  p win,  then  they  can  make  p win  by  all  voting  p (cid:10) a (cid:10) b,  or  all  voting 

p (cid:10) b (cid:10) a. (cid:2)

The reason that the above algorithm does not work for manipulating Baldwin’s rule is that the algorithm requires that we 
can place p as the ﬁrst choice in every manipulating vote. However, in a successful manipulation in the proof of Theorem 4, 
the manipulators are split between p (cid:10) a (cid:10) b and a (cid:10) p (cid:10) b, and switching the votes of the latter group into p (cid:10) a (cid:10) b spoils 
the manipulation.

The results in this section suggest that Baldwin’s rule is arguably harder to manipulate because Nanson’s rule is poly-
nomial to manipulate with three candidates, and requires at least four candidates to be NP-hard, but Baldwin’s is NP-hard 
already  with  three  candidates.  It  follows  that  computing  a  manipulation  is  NP-hard  for  both  rules  when  votes  are  un-
weighted,  the  number  of  candidates  is  small,  and  there  is  uncertainty  about  how  agents  have  voted  in  the  form  of  a 
probability distribution [12]. Note that the coalitional manipulation problem for Borda with weighted votes is NP-hard for 
three  or  more  candidates  [12].  Thus,  somewhat  surprisingly,  adding  an  elimination  round  to  Borda,  which  gives  us  Nan-
son’s rule, decreases the computational complexity of computing a manipulation with three manipulators from NP-hard to 
polynomial-time.

5.  Heuristic methods

NP-hardness  only  characterises  the  worst-case  complexity  of  computing  a  manipulation.  Given  enough  manipulators, 
we can easily make any candidate win. We consider next minimising the number of manipulators required. For example, 
Reverse is a simple heuristic method proposed to compute Borda manipulations [43]. The method constructs each manipu-
lator’s vote in turn: preferred candidate p is put in ﬁrst place, and the remaining candidates are put in reverse order of their 
current Borda scores. The method continues constructing manipulating votes until  p wins. A long and intricate argument 
shows that Reverse constructs a manipulation which uses at most one more manipulator than is optimal.

Example 1. Suppose we have four candidates, c1, c2, c3, p, and the two non-manipulators have cast votes: c3 (cid:10) c1 (cid:10) c2 (cid:10) p
and  c2 (cid:10) c3 (cid:10) c1 (cid:10) p. Then we have the score vector (cid:7)3, 4, 5, 0(cid:8). We use Reverse to construct a manipulation that makes 
candidate  p win.  Reverse ﬁrst  constructs  the  vote:  p (cid:10) c1 (cid:10) c2 (cid:10) c3.  The  score  vector  is  now  (cid:7)5, 5, 5, 3(cid:8).  Reverse next 
constructs the vote:  p (cid:10) c1 (cid:10) c2 (cid:10) c3. (It will not matter how ties between 1, 2, and 3 are broken.) The score vector is now 
(cid:7)7, 6, 5, 6(cid:8).  Finally,  Reverse constructs  the  vote:  p (cid:10) c3 (cid:10) c2 (cid:10) c1.  The  score  vector  is  (cid:7)7, 7, 7, 9(cid:8).  Hence,  Reverse requires 
three manipulating votes to make candidate  p win. As we will see later, this is one more vote than in the optimal solution.

J. Davies et al. / Artiﬁcial Intelligence 217 (2014) 20–42

31

Following  [43],  we  propose  four  new  heuristic  methods.  The  ﬁrst  two  algorithms  work  with  all  three  voting  rules. 
However,  the  last  two  algorithms  are  designed  speciﬁcally  for  the  elimination  style  of  Baldwin’s  and  Nanson’s  rules.  All 
algorithms  attempt  to  construct  a  manipulation  with  a  speciﬁc  number  of  manipulators.  Hence,  in  order  to  ﬁnd  the  best 
possible number of manipulators using one of these algorithms, we run it for one manipulator, then two and so on until a 
manipulation is found. We refer to a manipulation with k manipulators as a k-manipulation.

5.1.  Manipulation matrices

In this section we prove some auxiliary results that are needed to develop our heuristic algorithms.
We  can  view  Reverse as  greedily  constructing  a  manipulation  matrix.  A  manipulation matrix is  an  n by  m matrix  A, 
where n is the number of manipulators, m is the number of candidates, and  A(i, j) = k if and only if the ith manipulator 
adds a score of k to candidate c j . The  jth column of the matrix,  A( j), is the set of scores received by candidate c j , and each 
of the n rows is a permutation of 0 to m − 1. We require that the sum of the  jth column is less than or equal to  g(c j), the 
maximum score candidate c j can receive without defeating  p. Reverse constructs this matrix row by row.

Our new methods break out of the straightjacket of constructing a manipulation matrix in row-wise order. To achieve 
this, we take advantage of an interesting result that relaxes the constraint that each row is a permutation of 0 to m − 1. This 
lets us construct a relaxed manipulation matrix. This is an n by m matrix that contains n copies of 0 to m − 1 in which the 
sum of the  jth column is again less than or equal to  g(c j). In a relaxed manipulation matrix, a row can repeat an integer 
provided other rows compensate by not having that integer at all.

Theorem 7. Suppose there is an n by m relaxed manipulation matrix A. Then there is an n by m manipulation matrix B with the same 
column sums.

Proof. The proof is by induction on n. In the base case, n = 1 and we just set  B(1, j) = A(1, j) for all  j ∈ {1, . . . , m}. In the 
inductive step, we assume the theorem holds for all relaxed manipulation matrices with n − 1 rows. Let h(i) be the sum of 
the ith column of  A. We use a perfect matching in a suitable bipartite graph to construct the ﬁrst row of B and then appeal 
to the induction hypothesis on an n − 1 by m relaxed manipulation matrix constructed by removing the values in the ﬁrst 
row from  A.

We  build  a  bipartite  graph  as  follows.  The  ﬁrst  half  of  the  bipartite  graph  consists  of  m vertices  {V i}|m−1

i=0 ,  while  the 
j=1. Each vertex  V i represents a score, i, that must appear in the ﬁrst 

second half of the graph consists of m vertices {W j}|m
row of  B. Each vertex W j represents the  jth column of  A.

We add the edge (V i, W j) to this bipartite graph for each i ∈ [0, m − 1],  j ∈ [1, m], and k ∈ [1, n] where  A(k, j) = i. An 

edge (V i, W j) therefore means that score i can be taken from the  jth column of  A.

Note that there can be multiple edges between any pair of vertices. By construction, the degree of each vertex is n.
Suppose  we  take  any  U ⊆ {V i | i ∈ [0, m − 1]}.  Recall  ﬁrst  that  the  Hall  condition  [25] states  that  a  perfect  matching 
exists if and only if |V | ≤ |N(V )| for all sets of vertices  V (where  N(V ) is the neighbourhood of  V ). Since the degree of 
each  vertex  is n,  there  are n|U | edges  leaving  U .  For  the  same  reason,  each  vertex  in  N(U ) can  accommodate  at  most n
incoming edges. Therefore n|U | ≤ n|N(U )|. Hence, the Hall condition holds and a perfect matching exists. Consider an edge 
(V i, W j) in  such  a  perfect  matching.  We  construct  the  ﬁrst  row  of  B by  setting  B(1, j) = i.  As  this  is  a  matching,  each 
i ∈ [0, m − 1] occurs once, and each column is used exactly one time. We now construct an n − 1 by m matrix from  A by 
removing one element equal to  B(1, j) from each column  j. By construction, each value i ∈ [0, m − 1] occurs n − 1 times, 
and  the  column  sums  are  now h( j) − B(1, j).  Hence  it  is  a  relaxed  manipulation  matrix.  We  can  therefore  appeal  to  the 
induction hypothesis. This gives us an n by m manipulation matrix  B with the same column sums as  A. (cid:2)

We can extract from this proof a polynomial-time method to convert a relaxed manipulation matrix into a manipulation 
matrix. Hence, it is enough to propose new heuristic methods that construct relaxed manipulation matrices. This is advan-
tageous for greedy methods like those proposed here, as we have more ﬂexibility in placing integers into good positions in 
a relaxed manipulation matrix.

5.2.  Largest Fit

Our ﬁrst heuristic method, Largest Fit is inspired by bin packing and multiprocessor scheduling. Constructing an n by m
relaxed manipulation matrix is similar to packing nm objects into m bins with a constraint on the capacity of the different 
bins  and  an  extra  constraint  on  the  number  of  items  (n)  that  can  be  placed  in  each  bin.  The  problem  is  also  similar  to 
scheduling nm unit length jobs with different memory requirements on n different processors with a constraint on the total 
memory footprint of the n different jobs running at every clock tick and schedule length ﬁxed to m. Krause et al. [27] have 
proposed a simple heuristic for this problem that schedules the unassigned job with the largest memory requirement to the 
time step with the maximum remaining available memory that has less than n jobs assigned.

Largest Fit works in a similar way to construct a relaxed manipulation matrix. It assigns the largest unallocated score 
to the largest gap. More precisely, it ﬁrst assigns n instances of m − 1 to column  p of the matrix (since it is best for the 

32

J. Davies et al. / Artiﬁcial Intelligence 217 (2014) 20–42

manipulators to put  p in ﬁrst place in their votes). It then allocates the remaining (n − 1)m numbers in reverse order to 
the columns corresponding to the candidate with the currently smallest score who has not yet received n votes from the 
manipulators. Unlike Reverse, we do not necessarily ﬁll the matrix in row-wise order.

Example 2. Consider again Example 1. We start with the score vector (cid:7)3, 4, 5, 0(cid:8). One manipulator alone cannot increase the 
score of candidate  p enough to beat c2 or c3. Therefore, we need at least two manipulators. Largest Fit ﬁrst puts two 3s in 
column 4 of the relaxed manipulation matrix. This gives the score vector (cid:7)3, 4, 5, 6(cid:8). The next largest score is 2. Largest Fit
puts this into column 1 as this has the larger gap. This gives the score vector (cid:7)5, 4, 5, 6(cid:8). The next largest score is again 2. 
Largest Fit puts this into column 2 giving the score vector (cid:7)5, 6, 5, 6(cid:8). The two next largest scores are 1. Largest Fit puts 
them in columns 1 and 3, giving the score vector (cid:7)6, 6, 6, 6(cid:8). Finally, the two remaining scores of 0 are put in columns 2
and 3, so all columns contain two scores. This gives a relaxed manipulation matrix corresponding to the manipulating votes: 
p (cid:10) c2 (cid:10) c1 (cid:10) c3 and  p (cid:10) c1 (cid:10) c3 (cid:10) c2. With these votes,  p wins based on the tie-breaking rule. Unlike Reverse, Largest Fit
constructs an optimal manipulation with just two manipulators.

As we show in Section 5.5, Largest Fit and Reverse, are, in fact, incomparable. There is an inﬁnite family of problems on 

which Largest Fit ﬁnds an optimal manipulation but Reverse does not, and vice versa.

5.3.  Average Fit

Our second heuristic method, Average Fit takes into account both the size of the gap and the number of scores still to 
be added to each column. If two columns have the same gap, we want to choose the column that contains fewer scores. To 
achieve this, we look at the average score required to ﬁll each gap: that is, the size of the gap divided by the number of 
scores still to be added to the column. Each manipulator gives their largest score, m − 1, to the preferred candidate  p and 
then has to distribute their remaining scores among other candidates. Initially, a manipulator has m − 1 scores to distribute. 
We call all manipulator scores that have not been distributed so far “unassigned scores”. At each step, Average Fit selects 
a column and a score to distribute to that column. First, the column is chosen, by selecting the column for which the size 
of the remaining gap divided by the number of scores still to be added to the column is largest. We tie-break by choosing 
the column containing the fewest scores. Then, an unassigned score is chosen to distribute to that column. We choose the 
largest unassigned score that will ﬁt into that column’s gap. If there is no unassigned score that will ﬁt into the gap, then 
the largest unassigned score is chosen.

Example 3. Consider again Examples 1 and 2. We start with the score vector (cid:7)3, 4, 5, 0(cid:8). This method computes, identically 
to Largest Fit, that two manipulators are needed. Like Largest Fit, Average Fit ﬁrst puts two 3s in column 4 of the relaxed 
manipulation matrix. This gives the score vector (cid:7)3, 4, 5, 6(cid:8). The next largest score is 2. Average Fit puts this into column 
1 as this has the largest average 3/2. This gives the score vector (cid:7)5, 4, 5, 6(cid:8). The next largest score is again 2. Average Fit
puts this into column 2, which has average 2/2 = 1, giving the score vector (cid:7)5, 6, 5, 6(cid:8). The two next largest scores are 1. 
Average Fit puts the ﬁrst 1 in column 1, which has average 1/1 and the next 1 in column 3 which has average 1/2. This 
gives the score vector (cid:7)6, 6, 6, 6(cid:8). Finally, the two remaining scores of 0 are put in columns 2 and 3, so all columns contain 
two scores. This is identical to the manipulation computed by Largest Fit, with votes  p (cid:10) c2 (cid:10) c1 (cid:10) c3 and  p (cid:10) c1 (cid:10) c3 (cid:10) c2.

For  an  example  on  which  Average Fit beats  Largest Fit,  see  Theorem 9.  For  an  example  on  which  Largest Fit beats 

Average Fit, see Theorem 10.

5.4.  Eliminate and Reverse Eliminate

Our next methods are designed to take into account the elimination style nature of Baldwin’s and Nanson’s rules.
The  ﬁrst  method,  which  we  call Eliminate,  repeatedly  constructs  votes  in  which  the  desired  candidate  is  put  in  ﬁrst 
place, and the other candidates in the reverse of the current elimination order. Thus, the ﬁrst candidate eliminated is put 
in  last  place,  the  second  candidate  eliminated  is  put  in  the  penultimate  place,  and  so  on.  For  Nanson’s  rule,  we  order 
candidates eliminated in the same round by their Borda score in that round. The intuition behind Eliminate is to move the 
desired candidate up the elimination order whilst keeping the rest of the order unchanged.

Our ﬁnal method, which we call RevEliminate, repeatedly construct votes in which the desired candidate is put in ﬁrst 
place, and the other candidates in the current elimination order. For instance, the ﬁrst candidate eliminated is put in second 
place.  For  Nanson’s  rule,  we  order  candidates  eliminated  in  the  same  round  by  the  inverse  of  their  Borda  score  in  that 
round.  The  intuition  behind RevEliminate is  to  move  the  desired  candidate  up  the  elimination  order,  and  to  assign  the 
largest Borda scores to the least dangerous candidates.

It is easy to show that all methods will eventually compute a manipulation of Nanson’s or Baldwin’s rule in which the 

desired candidate wins.

Example 4.  We  revisit  Examples 1–3 and  show  the  operation  of Eliminate for  Baldwin’s  rule.  The  initial  score  vector  is 
(cid:7)3, 4, 5, 0(cid:8), so  p is eliminated in the ﬁrst round. In the second round, the score vector is (cid:7)1, 2, 3(cid:8), so c1 gets eliminated, and 

J. Davies et al. / Artiﬁcial Intelligence 217 (2014) 20–42

33

in the last round c3 and c2 are in a tie with the score vector (cid:7)1, 1(cid:8). We assume the tie is broken in favour of c2, so it wins 
the  election.  Therefore, Eliminate will  have  the  ﬁrst  manipulator  vote  p (cid:10) c2 (cid:10) c3 (cid:10) c1.  With  one  manipulator,  this  gives 
the score vector (cid:7)3, 6, 6, 3(cid:8). With tie breaking in favour of  p, c1 is eliminated in the ﬁrst round, so the score vector in the 
second round is (cid:7)4, 3, 2(cid:8), so  p is eliminated in the second round. This means that we need at least one more manipulator. 
By construction, Eliminate can only change the step in which  p is eliminated. The other candidates are eliminated in the 
same order amongst themselves. Hence, the vote of the second manipulator is also  p (cid:10) c2 (cid:10) c3 (cid:10) c1. The initial score vector 
is now (cid:7)3, 8, 7, 6(cid:8). The candidate c1 is again eliminated in the ﬁrst round. In the second round, the score vector is (cid:7)5, 3, 4(cid:8). 
Therefore, c3 is eliminated. In the third round, c2 and  p are tied with the score vector (cid:7)2, 2(cid:8). Since we break ties in favour 
of the preferred candidate, Eliminate has computed a manipulation with two manipulators. This is optimal.

With RevEliminate, the ﬁrst manipulator votes  p (cid:10) c1 (cid:10) c3 (cid:10) c2. This gives the score vector (cid:7)5, 4, 6, 3(cid:8). Hence  p is again 
eliminated in the ﬁrst round. The score vector in the second round is (cid:7)3, 2, 4(cid:8). Hence c2 is eliminated. In the third round, 
The score vector in the second round is (cid:7)1, 2(cid:8). Hence c1 is eliminated and c3 wins. The vote of the second manipulator is 
therefore  p (cid:10) c2 (cid:10) c1 (cid:10) c3. This gives the score vector (cid:7)6, 6, 6, 6(cid:8). We suppose tie breaking eliminates c3. The score vector 
in the second round is (cid:7)4, 4, 4(cid:8). We suppose tie breaking now eliminates c2. The score vector in the third round is (cid:7)2, 2(cid:8). 
Since we break ties in favour of  p, RevEliminate has also computed an optimal manipulation.

5.5.  Theoretical properties

First,  we  show  that  Largest Fit is  incomparable  to  Reverse since  there  exists  an  inﬁnite  family  of  problems  on  which 

Largest Fit ﬁnds an optimal manipulation but Reverse does not, and vice versa.

Theorem 8. For Borda voting, there exists an election for which Largest Fit ﬁnds an optimal 2-manipulation, but Reverse produces a 
3-manipulation.

Proof. We  suppose  there  are  just  two  non-manipulators  with  votes  σ and  σ (cid:15)
σ = (cid:7)1, 2, . . . , m − 1, 0(cid:8) and let

,  and  the  preferred  candidate  p is  cm.  Let 

σ (cid:15) =

(cid:10)

m

2

+ 1,

m

2

+ 2, ...,

m

2

+ m
2

− 1, 1, 2, ...,

(cid:11)

, 0

.

m

2

Then

σ + σ (cid:15) =

(cid:10)(cid:12)

(cid:13)

(cid:12)

+ 1

,

2 + m
2

1 + m
2

(cid:13)

(cid:12)

+ 2

, ...,

m

2

− 1 + m
2

+ m
2

(cid:13)

(cid:12)

− 1

,

m

2

(cid:13)

+ 1

, ...,

(cid:12)
m − 1 + m
2

(cid:13)

(cid:11)

, 0

.

2

This  gives  m
2
1 ≤ i ≤ m − 1. Before continuing, we rename the candidates so that s(cm, P ) = 0 and s(ci, P ) = m
2

2 ,  or  in  other  words,  there  exists  a  score  m

+ 2x for  1 ≤ x ≤ m
2

+ 2x − 1 for  1 ≤ x ≤ m

− 1 and  m
2

Recall that the preferred candidate is  p = cm. The ﬁrst vote generated by Reverse is  v 1 = p (cid:10) c1 (cid:10) c2 (cid:10) · · · (cid:10) cm−1, after 
which  s(ci, P ∪ {v 1}) = m
+ m − 1 for  all  candidates  ci (cid:9)= cm.  This  is  larger  than  the  score  of  the  distinguished  candidate 
2
s(p, P ∪ {v 1}) = m − 1. Therefore another manipulator is added. Without loss of generality, we suppose its vote is v 2 = cm (cid:10)
+ (m − 1) + (m − i − 1) =
c1 (cid:10) c2 (cid:10) · · · (cid:10) cm−1. The resulting scores of the competing candidates are s(ci, P ∪ {v 1, v 2}) = m
2
(5/2)m − 2 − i. So candidate c1 still has larger score than  s(p, P ∪ {v 1, v 2}) = 2m − 2. Therefore,  Reverse does not ﬁnd a 
2-manipulation. Note that, as Reverse never uses more than one additional manipulator than is optimal, it will successfully 
ﬁnd a 3-manipulation.

+ i for all 1 ≤ i ≤ m − 1.

+ i for  all 

Largest Fit will  ﬁrst  give  the  highest  scores,  m − 1,  from  both  manipulators  to  the  preferred  candidate.  Then  in  each 
iteration, Largest Fit will place a score from the multi-set  S2 = {0, . . . , m − 2} (cid:18) {0, . . . , m − 2} into the manipulation ma-
trix B.  The  ﬁrst m − 1 iterations  of  Largest Fit will  place  the kth  largest  score  from  S 2 into  the kth  column  of  matrix  B
for  1 ≤ k ≤ m − 1.  Note  that  the kth  largest  score  is m − 2 − (cid:19)(k − 1)/2(cid:20).  Let  Bm−1 be  the  tentative  manipulation  matrix 
at this point and write sum(Bm−1(i)) for the sum of the elements of its ith column. Then, the score of candidate ci under 
this partial manipulation is sum(Bm−1(i)) + s(ci, P ) = (m − 2 − (cid:19)(i − 1)/2(cid:20)) + m
+ i for all i, hence sum(Bm−1(i)) + s(ci, P ) ≤
2
sum(Bm−1(i + 1)) + s(ci+1, P ) for all 1 ≤ i ≤ m − 2, and so the relative order of the candidates’ scores does not change. The 
− 2}. The next m − 1 iterations of Largest Fit will 
multi-set of scores available at this point is S
(cid:15)
2 into the kth column of matrix B for 1 ≤ k ≤ m − 1. So column i will receive the element 
place the kth largest score from  S
− 1 − (cid:21)(i − 1)/2(cid:22). Let B2(m−1) be the matrix when the loop terminates. The score of candidate ci under the manipulation 
m
2
B2(m−1) is  sum(B2(m−1)(i)) + s(ci, P ) = (m − 2 − (cid:19)(i − 1)/2(cid:20)) + ( m
− 1 − (cid:21)(i − 1)/2(cid:22)) = 2(m − 1) for all  i, while 
2
the achievable score of candidate p is also 2(m − 1). Therefore, Largest Fit ﬁnds a 2-manipulation. Fig. 1 illustrates how the 
scores are placed in matrix  B by Largest Fit, where the shaded area represents the scores s(ci, P ). (cid:2)

− 1} (cid:18) {0, . . . , m
2

= {0, . . . , m
2

+ i) + ( m
2

(cid:15)
2

Unfortunately, Largest Fit does not share the guarantee of Reverse that in the worst case it requires one more manipu-

lator than is optimal. In fact the number of extra manipulators used by Largest Fit is not bounded.

34

J. Davies et al. / Artiﬁcial Intelligence 217 (2014) 20–42

Fig. 1. The 2-manipulation generated by Largest Fit for the election in Theorem 8.

Theorem 9. For Borda voting, there exists an election with 4 candidates and 2k votes (k divisible by 36) on which both Reverse and 
Average Fit will ﬁnd an optimal manipulation but Largest Fit requires at least k/9 − 3 additional manipulators.

Proof. Consider a Borda election in which the scores of four candidates after the non-manipulators  P vote are s(c1, P ) = 6k, 
s(c2, P ) = 4k, s(c3, P ) = 2k, s(p, P ) = 0. These scores can be achieved if all 2k votes are c1 (cid:10) c2 (cid:10) c3 (cid:10) p. Reverse will use 2k
manipulators, all voting  p (cid:10) c3 (cid:10) c2 (cid:10) c1, to achieve a score of 6k for all candidates. This is the only optimal manipulation. 
To see that Average Fit will ﬁnd the optimal manipulation, note that the initial gaps are 0, 2k, and 4k and the averages 0, 1, 
and 2 for candidates c1, c2 and c3, respectively. In the ﬁrst step, Average Fit will assign a score of 2 to candidate c3 and will 
continue to do that as long as the average of candidate c3 is greater than that of candidate c2. To ﬁnd when that happens, 
we let x be the number of iterations and solve  4k−2x
= 1 ⇒ x = 2k. This means that Average Fit will give all 2k scores of 2 
2k−x
to candidate c3. Similarly, we see that it will give all scores of 1 to candidate c2 and only scores of 0 to candidate c1. This 
means that all manipulators will vote  p (cid:10) c3 (cid:10) c2 (cid:10) c1, the only optimal manipulation.

It remains to argue that Largest Fit requires more than 2k + k/9 − 4 manipulators. We exploit the fact that Largest Fit
is  monotonic,  in  the  sense  that  if  it  ﬁnds  a  successful  Borda  manipulation  with  a  given  number  of  manipulators,  it  also 
succeeds with more. Additional manipulators only give Largest Fit more opportunity to increase the score of the preferred 
candidate over the other candidates. Assume for contradiction that we ﬁnd a manipulation using n = 2k +k/9 −4 = 19k/9 −4
manipulators.  We  will  follow  the  execution  of  Largest Fit until  a  contradiction  is  obtained.  By  monotonicity,  Largest Fit
cannot use 2k + k/9 − 4 or fewer manipulators. Note that given our deﬁnition of n, since k is divisible by 4 and 9,  n−k
is an 
integer.

Let  B denote  the  relaxed  manipulation  matrix  constructed  by  Largest Fit,  and  let  B(i),  i ∈ {1, . . . , m} denote  its  ith 
column. We write sum(B(i)) for the sum of the elements in B(i). First, the algorithm will place k 2’s in B(3), at which point 
sum(B(3)) = 2k + 2k = 4k = s(2, P ).  Then  it  will  begin  to  place  2’s  in  columns  B(2) and  B(3) evenly,  until  all  remaining 
n − k 2’s  have  been  placed  into  B.  At  this  point,  B(2) contains  n−k
2’s,  and  the  number  of  2’s  that  B(3) contains  is 
k + n−k
= k/2 + n/2 = k/2 + (19k/9 − 4)/2 = 14k/9 − 2 < 19k/9 − 4 = n. So at this point, neither  B(3) nor  B(2) is full yet 
(B(2) has  fewer  elements  than  B(3)).  Both  columns  sum  to  4k + 2( n−k
2 ) = 46k/9 − 4 = 5k + k/9 − 4 < 6k.  Therefore,  the 
algorithm will start putting 1’s in both  B(2) and  B(3) evenly, until either their column sums reach 6k or  B(3) gets ﬁlled. 
In fact,  B(3) will be ﬁlled before its sum reaches 6k, since  B(3) requires  n−k
2 more elements to be ﬁlled, but at this point, 
sum(B(2)) = sum(B(3)) = 46k/9 − 4 + n−k
= 51k/9 − 6 = 5k + 2k/3 − 6 < 6k.

Now, the algorithm will continue by putting k/3 + 6 1’s into B(2), at which point sum(B(2)) = 51k/9 − 6 + k/3 + 6 = 6k. 
Then the algorithm will start putting 1’s evenly in both B(1) and B(2), until either it runs out of 1’s or B(2) is ﬁlled. In fact, 
the 1’s will run out before  B(2) is ﬁlled, since  B(2) requires n − ( n−k
+ k/3 + 6) = 2k/3 − 6 more elements, which 
is  equal  to  the  number  of  remaining  1’s,  but  these  are  spread  between  B(1) and  B(2).  So  B(2) will  get  (2k/3 − 6)/2 =
k/3 − 3 additional  1’s,  for  a  total  of  sum(B(2)) = 4k + 2( n−k
+ k/3 + 6 + k/3 − 3 = 19k/3 − 3 > 19k/3 − 12 = 3n. 
Since  sum(B(2)) > 3n there  is  no  manipulation  using n = 19k/9 − 4 manipulators.  Therefore,  Largest Fit requires  at  least 
n + 1 = 2k + k/9 − 3 manipulators. (cid:2)

2 ) + n−k

+ n−k
2

2

2

2

2

2

2

Average Fit is also incomparable to Largest Fit. Like Reverse, Average Fit ﬁnds optimal manipulations on the elections in 
the proof of Theorem 9. However, there exist examples on which Largest Fit ﬁnds an optimal manipulation but Average Fit
does not.

J. Davies et al. / Artiﬁcial Intelligence 217 (2014) 20–42

35

Theorem 10. For Borda voting, there exist an election on which Largest Fit ﬁnds an optimal manipulation but Average Fit requires 
an additional vote.

Proof. We failed to ﬁnd a simple example but a computer search using randomly generated instances gave the following. 
Consider an election in which the manipulators wish candidate c8 to win, and 8 non-manipulators have voted as follows:

#voters

3
1
1
1
2

vote
c1 (cid:10) c2 (cid:10) c3 (cid:10) c4 (cid:10) c5 (cid:10) c6 (cid:10) c7 (cid:10) c8
c1 (cid:10) c2 (cid:10) c3 (cid:10) c4 (cid:10) c5 (cid:10) c7 (cid:10) c6 (cid:10) c8
c1 (cid:10) c2 (cid:10) c3 (cid:10) c6 (cid:10) c5 (cid:10) c4 (cid:10) c7 (cid:10) c8
c7 (cid:10) c1 (cid:10) c6 (cid:10) c5 (cid:10) c4 (cid:10) c2 (cid:10) c3 (cid:10) c8
c8 (cid:10) c7 (cid:10) c6 (cid:10) c5 (cid:10) c4 (cid:10) c3 (cid:10) c2 (cid:10) c1

This gives the score vector for (cid:7)c1, . . . , c8(cid:8) of:

(cid:7)41, 34, 30, 27, 27, 26, 25, 14(cid:8).

On this problem, Largest Fit ﬁnds an optimal manipulation that makes the ﬁnal candidate win but Average Fit requires an 
additional vote. The calculations are shown in Appendix A. (cid:2)

So far we have not found any instances where Reverse performs better than Average Fit.
Finally, we consider properties of heuristic algorithms with respect to Baldwin’s and Nanson’s rules. It appears that it is 
harder to ﬁnd an approximately optimal manipulation for these rules than for the Borda rule. For all our heuristic methods, 
we can give examples where the heuristic computes a manipulation that uses several more manipulators than is optimal. 
The  most  interesting  result  is  that  although Reverse was  shown  to  never  require  more  than  one  extra  manipulator  than 
optimal under the Borda rule [43], the result does not transfer to Baldwin’s and Nanson’s rules. Indeed, even with a ﬁxed 
number of candidates, Reverse can require an unbounded number of extra manipulators.

Theorem 11. For Baldwin’s rule, there exists an election with 7 candidates and 42n votes (n even) where Reverse computes a manip-
ulation with at least 10n more votes than is optimal.

Proof. Consider an election over candidates a, b, c, d, e,  f , and p where p is the preferred candidate of the manipulators. We 
deﬁne  V (u,v) as the pair of votes: {u (cid:10) v (cid:10) Others (cid:10) p, rev(Others) (cid:10) u (cid:10) v (cid:10) p}, where Others is some ﬁxed ordering of the 
other candidates and rev(Others) is its reverse. Note that these votes differ from the pair of votes W (u,v) deﬁned in Section 2. 
The  non-manipulators  cast  the  following  votes:  3n copies  of  V (a,b),  V (b,c),  V (c,d),  V (d,e),  and  V (e, f ).  In  addition,  there  are 
6n copies of the votes:  p (cid:10) a (cid:10) Others and rev(Others) (cid:10) p (cid:10) a. After the non-manipulators have voted, s(a) = s( f ) = 138n, 
s(b) = s(c) = s(d) = s(e) = 141n, and s(p) = 42n.

If 18n manipulators vote identically  p (cid:10) a (cid:10) . . . (cid:10) f then  p wins. The following table shows scores of all candidates in 6 

rounds.

s(a)

228n
189n
150n
111n
72n
30n

s(b)

213n
174n
135n
96n
54n
−

s(c)

195n
156n
117n
73n
−
−

s(d)

177n
138n
96n
−
−
−

s(e)

s( f )

s(p)

138n

159n
117n −
−
−
−
−
−
−
−
−

150n
126n
102n
78n
54n
30n

Round 1
Round 2
Round 3
Round 4
Round 5
Round 6

By the tie-breaking rule,  p wins in the last round.

This manipulation provides an upper bound on the size of an optimal manipulation for Baldwin’s rule.
Reverse will put  p in the ﬁrst place, then a and  f

in some order, and then the remaining candidates. Without loss of 
generality, we suppose Reverse breaks ties by constructing the vote  p (cid:10) a (cid:10) f (cid:10) b (cid:10) c (cid:10) d (cid:10) e. It alternates this vote with 
p (cid:10) a (cid:10) f (cid:10) e (cid:10) d (cid:10) c (cid:10) b. After n such manipulating votes have been constructed, the scores of candidates a to  f are level 
at  142n + n/2, and  p is at  48n. From then on, the manipulators put  p in ﬁrst place and alternate the order of the other 
candidates. Without loss of generality, we suppose Reverse breaks ties by constructing the vote  p (cid:10) a (cid:10) b (cid:10) c (cid:10) d (cid:10) e (cid:10) f . 
It alternates this vote with  p (cid:10) f (cid:10) e (cid:10) d (cid:10) c (cid:10) b (cid:10) a. At least 28n votes are therefore required in total for  p to move out of 
last place. Hence, Reverse requires at least 10n extra manipulators compared to the optimum number for Baldwin’s. (cid:2)

Theorem 12. For Nanson’s rule, there exists an election with four candidates and 110n votes where Reverse computes a manipulation 
with at least 4n more votes than is optimal.

36

J. Davies et al. / Artiﬁcial Intelligence 217 (2014) 20–42

Table 1
Percentage of elections drawn from the impartial culture model for which each heuristic found an optimal manipulation with Borda voting.

m

4
8
16
32
64
128

Total

# Inst.

2771
5893
5966
5968
5962
5942

32 502

Reverse

Largest Fit

Average Fit

94.2%
85.5%
76.8%
71.1%
66.8%
65.3%

74.9%

92.9%
87.7%
81.9%
80.7%
80.0%
79.9%

83.0%

100.0%
99.3%
98.6%
98.5%
98.4%
98.0%

98.7%

Largest Fit
beats
Average Fit
0.00%
0.03%
0.05%
0.02%
0.05%
0.03%

0.03%

Proof. Consider an election over a, b, c, and  p, where  p is the preferred candidate of the manipulators. We use the votes 
W (u,v) deﬁned in Section 2. Non-manipulators cast the following votes:  15n copies of  W (a,c),  W (b,c) and  W (b,p), and  10n
copies of W (a,p). After the non-manipulators have voted, s(a) = 190n, s(b) = 195n, s(c) = 135n, and s(p) = 140n. The average 
score is 165n.

If 21n manipulators vote identically  p (cid:10) c (cid:10) a (cid:10) b then  p wins. The following table shows scores of all candidates in two 

rounds.

average

s(a)

Round 1
Round 2

196.5n
65.5n

211n
65n

s(b)

195n
−

s(c)

177n
−

s(p)

203n
66n

Hence,  p wins in the last round.

This manipulation provides an upper bound on the size of an optimal manipulation for Nanson’s rule.
Reverse will construct the vote  p (cid:10) c (cid:10) a (cid:10) b. After 5n such manipulating votes, the scores of a and b will become level.
Reverse will then alternate between p (cid:10) c (cid:10) b (cid:10) a and p (cid:10) c (cid:10) a (cid:10) b. In total, Reverse will construct 25n such manipulating 
votes, 15n for  p (cid:10) c (cid:10) a (cid:10) b and 10n for  p (cid:10) c (cid:10) b (cid:10) a. At this point,  p wins under Nanson’s rule as demonstrated in the 
following table.

average

s(a)

s(b)

s(c)

Round 1
Round 2

202.5n
135n

205n
135n

185n

205n
135n −

s(p)

215n
135n

Note that p wins in the second round by our tie-breaking assumption. Hence, Reverse uses 4n extra manipulators compared 
to the optimum number for Nanson’s. (cid:2)

These results demonstrate that, for Baldwin’s and Nanson’s rules, Reverse does not approximate the optimal number of 

manipulators by an additive constant (as it does for Borda).

6.  Experimental results

To  test  the  performance  of  these  heuristic  methods  in  practice,  we  ran  some  experiments.  Our  experimental  setup  is 
based  on  that  in [38].  We  generated  votes  drawn  either  from  the  impartial  culture  model,  or  the  Polya–Eggenberger  urn 
model [5].  In  the  urn  model,  votes  are  placed  in  an  urn  and  drawn  at  random.  Votes  are  placed  back  into  the  urn  along 
with b other votes of the same type. This captures varying degrees of social homogeneity. We set b = m! so that there is an 
approximately 50% chance that the second vote is the same as the ﬁrst. In both models, we generated between 22 and 27
votes for varying m.

6.1.  Borda rule

First we present our results for the Borda rule. Manipulation under the Borda rule can be easily modelled as a constraint 
satisfaction problem. We used this property to obtain optimal solutions for our instances. We tested 1000 instances at each 
problem  size  and  determined  if  the  returned  manipulations  are  optimal,  by  modelling  the  problem  of  ﬁnding  an  optimal 
manipulation as a constraint satisfaction problem and solving it using the solver Gecode [23].

The  constraint  solver  found  an  optimal  manipulation  in  32 502  out  of  the  32 679  distinct  impartial  culture  elections 
within the 1 hour time-out. Results are shown in Table 1. Both Largest Fit and Average Fit provide a signiﬁcant improve-
ment  over  Reverse,  solving  83%  and  99%  of  instances  to  optimality.  Reverse solves  fewer  problems  to  optimality  as  the 

J. Davies et al. / Artiﬁcial Intelligence 217 (2014) 20–42

37

Table 2
Percentage of elections drawn from an urn model for which each heuristic found an optimal manipulation with Borda voting.

m

4
8
16
32
64
128

Total

# Inst.

3929
5501
5502
5532
5494
5571

31 529

Reverse

Largest Fit

Average Fit

93.3%
85.6%
79.2%
72.4%
67.6%
64.5%

76.3%

66.3%
50.1%
41.1%
36.3%
33.0%
30.6%

41.7%

100.0%
99.9%
99.5%
99.5%
99.7%
99.9%

99.7%

Largest Fit
beats
Average Fit
0.00%
0.00%
0.02%
0.00%
0.00%
0.00%

0.00%

Table 3
Average number of manipulators required by each heuristic in elections drawn from an impartial culture model using the Borda rule.

n

4
8
16
32
64
128

Opt.

9.30
6.33
7.08
7.86
8.62
9.29

Reverse

Largest Fit

Average Fit

9.36
6.48
7.31
8.15
8.95
9.63

9.37
6.45
7.26
8.06
8.82
9.49

9.30
6.34
7.10
7.88
8.63
9.31

Table 4
Average number of manipulators required by each heuristic in elections drawn from an urn model using the Borda rule.

n

4
8
16
32
64
128

Opt.

42.21
32.67
34.08
35.06
36.76
37.70

Reverse

Largest Fit

Average Fit

42.28
32.82
34.29
35.34
37.09
38.06

42.94
33.78
35.68
36.97
38.92
39.98

42.21
32.67
34.09
35.07
36.77
37.71

number of candidates increases, while Average Fit does not seem to suffer from this problem as much: Average Fit solved 
all of the four candidate instances and 98% of the 128 candidate ones. Table 3 shows the average number of manipulators 
used by each of the heuristics, compared to the average optimal number of manipulators. We also note that in every one 
of the 32 502 instances, if Reverse found a k vote manipulation either Average Fit did too, or Average Fit found a (k − 1)
vote manipulation, i.e., Average Fit never found a worse solution than Reverse. Furthermore, Largest Fit used at most two 
more manipulators than the optimum.

With  the  urn  model,  we  were  able  to  ﬁnd  an  optimal  manipulation  for  31 529  out  of  the  31 530  elections  within  the 
1 hour time-out. Tables 2 and 4 give results.  Reverse solves about the same proportion of the urn instances as impartial 
culture instances, 76%. However, the performance of Largest Fit drops signiﬁcantly. It is much worse than Reverse solving 
only 42% of instances to optimality. Furthermore, in contrast to the impartial culture elections where  Largest Fit used at 
most  two  extra  manipulators,  here  Largest Fit used  up  to  14  more  manipulators  than  the  optimum.  The  reason  for  such 
behaviour is that the non-manipulators’ proﬁles in urn instances are similar to the proﬁles in the proof of Theorem 9, where 
Largest Fit requires an unbounded number of additional manipulators. The good performance of Average Fit is maintained. 
It  found  an  optimal  manipulation  on  more  than  99%  of  the  instances.  It  never  lost  to  Reverse and  was  only  beaten  by 
Largest Fit on one instance in our experiments.

These results suggest that while Borda manipulation is NP-hard, in practice the simple heuristic algorithms that we pro-
posed can compute optimal manipulations in the vast majority of cases. Thus, it appears that Borda elections are vulnerable 
to manipulation.

6.2.  Baldwin’s and Nanson’s rules

It  is  much  more  diﬃcult  to  model  the  unweighted  coalitional  manipulation  problem  under  Baldwin’s  and  Nanson’s 
rules  as  a  constraint  satisfaction  problem  since  the  scores  of  the  candidates  in  each  vote  change  in  each  round.  Hence, 
we partitioned our experiments into two parts: small problems where we can ﬁnd an optimum solution in a brute-force 
manner and large problems that show how heuristic algorithms scale.

Our  ﬁrst  set  of  experiments  used  3000  elections  with  ﬁve  candidates  and  ﬁve  non-manipulating  voters.  This  is  small 
enough to ﬁnd the optimal number of manipulators using brute force search, and thus to determine how often a heuristic 
computes  an  optimal  solution.  We  threw  out  the  20%  or  so  of  instances  generated  in  which  the  preferred  candidate  has 

38

J. Davies et al. / Artiﬁcial Intelligence 217 (2014) 20–42

Table 5
Percentage of elections drawn from an impartial culture model with ﬁve candidates where the heuristic ﬁnds an optimal manipulation.

Rules

Baldwin
Nanson
Borda

Reverse

74.4%
74.6%
95.7%

Largest Fit

Average Fit

Eliminate

RevEliminate

74.4%
76.0%
98.8%

75.8%
78.0%
99.8%

62.2%
65.4%
95.7%

75.2%
66.9%
10.7%

Table 6
Percentage of elections drawn from an urn model with ﬁve candidates where the heuristic ﬁnds an optimal manipulation.

Rules

Baldwin
Nanson
Borda

Reverse

Largest Fit

Average Fit

Eliminate

RevEliminate

75.1%
78.1%
96.1%

75.4%
79.0%
92.7%

77.3%
79.8%
99.9%

68.9%
72.2%
96.1%

83.4%
79.4%
4.4%

Table 7
Average number of manipulators required by each heuristic in elections drawn from an impartial culture model using Baldwin’s rule.

n

4
8
16
32
64
128

Reverse

Largest Fit

Average Fit

Eliminate

RevEliminate

2.25
2.99
4.31
5.93
8.56
12.13

2.25
3.07
4.41
6.03
8.65
12.24

2.25
3.01
4.40
6.14
8.84
12.41

2.44
3.35
4.79
6.61
9.54
13.37

2.21
3.06
4.67
6.84
11.02
16.06

Table 8
Average number of manipulators required by each heuristic in elections drawn from an impartial culture model using Nanson’s rule.

n

4
8
16
32
64
128

Reverse

Largest Fit

Average Fit

Eliminate

RevEliminate

2.15
2.91
4.13
5.80
8.51
12.07

2.17
2.96
4.27
5.88
8.58
12.09

2.15
2.84
4.05
5.81
8.82
13.00

2.25
3.05
4.44
6.18
8.99
12.60

2.28
3.21
4.99
7.46
12.04
17.90

Table 9
Average number of manipulators required by each heuristic in elections drawn from an urn model using Baldwin’s rule.

n

4
8
16
32
64
128

Reverse

Largest Fit

Average Fit

Eliminate

RevEliminate

3.26
5.95
11.64
21.70
43.09
82.19

3.23
5.96
11.66
21.78
43.37
81.82

3.24
5.99
11.87
22.35
44.24
83.62

3.35
6.37
12.74
24.67
49.07
95.37

3.14
5.82
11.52
22.41
45.70
91.80

already won before the manipulators vote. Results are given in Tables 5–6. The tables demonstrate that heuristics that are 
very  effective  at  ﬁnding  an  optimal  manipulation  for  the  Borda  rule  do  not  perform  as  well  for  Baldwin’s  and  Nanson’s 
rules.  For  example, AverageFit almost  always  ﬁnds  an  optimal  manipulation  of  the  Borda  rule  but  can  only  ﬁnd  optimal 
solutions about three quarters of the time for Baldwin’s or Nanson’s rules. Note that Eliminate and RevEliminate are strictly 
speaking deﬁned just for Nanson’s and Baldwin’s rules. With the Borda rule, we can simply use the same manipulating votes 
they construct with, say, Baldwin’s rule. These put the preferred candidate in ﬁrst place so eventually must be successful in 
constructing a successful Borda manipulation.

In our second set of experiments, we eschew computation of an optimal manipulation in order to use larger problems. 
This ampliﬁes the differences between the different heuristic methods. Similarly to Section 6.1, we tested 1000 instances at 
each problem size, which gives 6000 instances in total.

Tables 7–10 show the results for the average number of manipulators. The results show that, with Nanson’s and Baldwin’s 
rules, Reverse works slightly better overall compared to LargestFit and AverageFit, which themselves outperform the other 
two methods especially for problems with large number of candidates. This contrasts with the results on the Borda rule in 
the  previous  section,  where LargestFit and AverageFit do  much  better  than Reverse.  In  most  cases AverageFit is  less 
effective than LargestFit except urn elections with Nanson’s rule.

These experimental results suggest that Baldwin’s and Nanson’s rules are harder to manipulate in practice than Borda. 
Heuristic methods that work well on the Borda rule are signiﬁcantly less effective on these rules. Overall, Reverse, Largest-
Fit, and AverageFit appear to offer the best performance, though no heuristic dominates.

J. Davies et al. / Artiﬁcial Intelligence 217 (2014) 20–42

39

Table 10
Average number of manipulators required by each heuristic in elections drawn from an urn model using Nanson’s rule.

n

4
8
16
32
64
128

Reverse

Largest Fit

Average Fit

Eliminate

RevEliminate

3.20
5.93
11.62
22.36
44.56
87.18

3.19
5.98
11.93
22.78
45.50
87.55

3.20
5.95
11.64
22.53
44.77
86.76

3.28
6.13
12.16
24.00
48.81
97.02

3.22
6.09
12.37
24.39
49.69
99.43

Fig. 2. Permutation matrix with restricted diagonals sums (PMRDS).

7.  Related problems

There  exists  an  interesting  connection  between  the  problem  of  ﬁnding  a  coalition  of  two  manipulators  for  the  Borda 
voting rule and two other problems in discrete mathematics: the problem of ﬁnding a permutation matrix with restricted 
diagonals  sums  (PMRDS) [9] and  the  problem  of  ﬁnding  multi  Skolem  sequences [30].  We  consider  this  connection  for 
two reasons. First, future advances in these adjacent areas may give insights into new manipulation algorithms or into the 
complexity of manipulation. Second, this connection reveals an interesting open case for Borda manipulation – Nordh has 
conjectured that when the gaps  g(i) of all candidates are distinct, then manipulation can be done in polynomial time [31].
A  permutation  matrix  is  an  n by  n Boolean  matrix  which  is  obtained  from  an  identity  matrix  by  a  permutation  of 
its  columns.  Hence,  a  permutation  matrix  contains  a  single  value  1  in  each  row  and  each  column.  Consider  the  2n − 1
diagonals of the matrix, numbering them from the top right to bottom left, and let di be the sum of the elements of the ith 
diagonal. Finding a permutation matrix such that its diagonal sums form a given sequence (d1, . . . , d2n−1) is the permutation 
matrix with restricted diagonals sums problem. This problem occurs in discrete tomography, where we need to construct a 
permutation matrix from its X-rays for each row, column, and diagonal. The X-ray values for each row and column are one, 
while the values for the diagonal are represented by the sequence (d1, . . . , d2n−1).

We transform a Borda manipulation problem with m + 1 candidates and 2 manipulators such that 

i=1 g(i) = m(m − 1)
to  a  PMRDS  problem  on  an m by m matrix.  Note  that  here  we  use m to  denote  the  number  of  candidates  excluding  the 
preferred candidate. Note that such a manipulation problem is tight, i.e., all gaps will be matched exactly, and all candidates 
will have the same score after the manipulation. In parallel with the description of the transformation, we illustrate it with 
the  following  example  with  ﬁve  candidates.  Our  preferred  candidate  is  4.  Let  (cid:7)4, 4, 6, 6, 0(cid:8) be  a  score  vector,  where  our 
preferred  candidate  has  0  score,  and  (cid:7)4, 4, 2, 2(cid:8) be  the  corresponding  gap  vector.  We  label  rows  of  a  permutation  matrix 
with scores given by the ﬁrst manipulator, and columns of the permutation matrix with the reverse of the scores given by 
the second manipulator. We label each element of the matrix with the sum of its row and column labels. Fig. 2a shows the 
labelling for our example in gray.

(cid:2)

m

Note  that  each  element  on  a  diagonal  is  labelled  with  the  same  value.  Therefore,  each  diagonal  labelled  with  value k
represents the gap of size k in the manipulation problem. Hence, the sum of the diagonal di labelled with k encodes the 
number of occurrences of gaps of size k. For example, d3 = 2 ensures that there are two gaps of size 2 and d5 = 2 ensures 
that there are two gaps of size 4. The remaining diagonal sums, di , i ∈ {1, 2, 4, 6, 7}, are ﬁxed to zero.

Consider  a  solution  of  PMRDS  (Fig. 2b).  Suppose  the  cell  P (x, y) contains  the  value  one.  We  conclude  that  the  ﬁrst 
manipulator  gives  the  score  x and  the  second  gives  the  score  m − y − 1 to  a  candidate  with  the  gap  x + (m − y − 1). 
In  our  example,  cell  P (0, 1) contains  one,  hence  the  ﬁrst  manipulator  gives  the  score  0 and  the  second  gives  the  score 
m − y − 1 = 4 − 1 − 1 = 2 to a candidate with the gap 2. By examining all cells with the value one, we obtain the complete 
votes of the manipulators, which in our example are (4 (cid:10) 1 (cid:10) 2 (cid:10) 0 (cid:10) 3) for the ﬁrst manipulator and (4 (cid:10) 0 (cid:10) 3 (cid:10) 1 (cid:10) 2) for 
the second, to ﬁll the gaps (cid:7)4, 4, 2, 2(cid:8). As the number of ones in each diagonal is equal to the number of occurrences of the 
corresponding gap, the constructed two manipulator votes make our candidate a winner. The total scores are (cid:7)8, 8, 8, 8, 8(cid:8).

Finding  a  coalitional  manipulation  under  the  Borda  rule  using  two  manipulators  is  also  connected  to  the  problem  of 
ﬁnding multi Skolem sequences used for the construction of Steiner triple system [30]. Given a multi-set of positive integers 

40

J. Davies et al. / Artiﬁcial Intelligence 217 (2014) 20–42

Table 11
Operation of Largest Fit when trying to ﬁnd a manipulation with four manipulators. The ﬁrst seven columns 
show the gaps of the candidates. In the ﬁnal column, we use the notation x : y to indicate that Largest Fit
assigns vote  x to candidate  y. The preferred candidate (c8, not shown in the table) gets 7 from all four 
manipulators, thus its score is 42. We omit the 0 scores.

c1

c2

1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
0
0
0

8
8
8
8
8
8
8
8
8
8
4
4
4
4
4
4
1
1
1
1
1
1
0
0
0

c3

12
12
12
12
12
7
7
7
7
7
7
3
3
3
3
3
3
1
1
1
1
1
1
0
0

c4

15
15
15
15
9
9
9
9
9
5
5
5
5
2
2
2
2
2
0
0
0
0
0
0
0

c5

15
15
15
9
9
9
9
9
4
4
4
4
4
4
4
1
1
1
1
1
1
1
1
1
0

c6

16
16
10
10
10
10
10
5
5
5
5
5
5
5
2
2
2
2
2
0
0
0
0
0
0

c7

17
11
11
11
11
11
6
6
6
6
6
6
2
2
2
2
2
2
2
2
0
0
0
0
0

Vote

6:7
6:6
6:5
6:4
5:3
5:7
5:6
5:5
4:4
4:2
4:3
4:7
3:4
3:6
3:5
3:2
2:3
2:4
2:6
2:7
1:1
1:2
1:3
1:5

(cid:15)
i

m

H = {h1, . . . , hm} we need to decide whether there exists a partition  P of the set {1, . . . , 2m} into pairs (pi, p
so that  H ≡ {pi − p
| (pi, p
ulators with gaps  G = {g(1), . . . , g(m)} such that 
(cid:2)

(cid:15)
i), i = 1, . . . , m, 
(cid:15)
i) ∈ P }. There is a reduction from a manipulation problem with m + 1 candidates and 2 manip-
i=1 g(i) = m(m − 1) to a special case of multi Skolem sequences with 
i=1 hi = m2 similar to the reduction from a scheduling problem in [30].2 The multi Skolem sequence instance that corre-
sponds to a manipulation instance is deﬁned by  H = {2m − g(1) − 1, . . . , 2m − g(m) − 1}. If a manipulation is given by the 
votes σ , π , then the partitions (2m −σ (i), π (i) +1) satisfy 2m −σ (i) −π (i) −1 = 2m − g(i) −1. Conversely, suppose there ex-
(cid:15)
(cid:15)
ists partition  P of the set {1, . . . , 2m} into pairs (pi, p
i) ∈ P , i = 1, . . . , m. Then the 
i, (pi, p
− 1 = 2m −(2m − g(i) − 1) − 1 = g(i).
votes are given by σ (i) = 2m − pi, π (i) = p

(cid:15)
i), i = 1, . . . , m, so that hi = pi − p
(cid:15)
− 1, which satisfy σ (i) +π (i) = 2m − pi + p
i

(cid:2)

m

(cid:15)
i

8.  Conclusions

In this paper we have investigated theoretically and empirically the computational complexity of manipulation problems 
for the Borda voting rule and two extensions of Borda voting, Baldwin’s and Nanson’s rules. We proved that it is NP-hard 
to  compute  a  coalitional  manipulation  of  the  Borda  rule  with  just  two  manipulators.  This  resolves  a  long-standing  open 
question  regarding  the  computational  complexity  of  unweighted  coalitional  manipulation  for  common  voting  rules.  We 
showed  that  two  other  rules,  Baldwin’s  and  Nanson’s  rules,  which  are  derived  from  the  Borda  rule  are  also  NP-hard  to 
manipulate both with weighted and unweighted votes. Because of these NP-hardness results, we proposed several simple 
heuristic methods. We showed that they can compute optimal manipulations of the Borda rule in almost all the randomly 
generated elections. This suggests that the Borda rule is not resistant to manipulation in practice. In contrast, these heuristic 
algorithms did not perform as well in either Baldwin or Nanson elections, suggesting that these elimination style rules are 
more resistant to manipulation than the Borda rule.

Acknowledgements

George Katsirelos was partially supported by the ANR UNLOC project ANR 08-BLAN-0289-01. Nina Narodytska and Toby 
Walsh are supported by the Australian Department of Broadband, Communications and the Digital Economy, the Australian 
Research Council, and the Asian Oﬃce of Aerospace Research and Development (AOARD-104123). Toby Walsh is currently 
supported  by  the  German  Federal  Ministry  for  Education  and  Research  through  the  Alexander  von  Humboldt  Foundation. 
Lirong Xia acknowledges an RPI startup fund, NSF Grant #1136996 to the Computing Research Association for the CIFellows 
Project, and Vincent Conitzer’s NSF CAREER 0953756 and IIS-0812113 for support.

2 The reduction implicitly assumes that 

m

i=1 hi = m2 as the author conﬁrmed in a private communication.

(cid:2)

J. Davies et al. / Artiﬁcial Intelligence 217 (2014) 20–42

41

Table 12
Operation of Average Fit when trying to ﬁnd a manipulation with four manipulators. Since the algorithm works on averages, we show averages as fractions 
to convey both the actual gap, and the remaining number of votes.

c1

1/4
1/4
1/4
1/4
1/4
1/4
1/4
1/4
1/4
1/4
1/4
1/4
1/4
1/4
1/4
1/4
1/4
1/4
1/4
1/4

c2

8/4
8/4
8/4
8/4
8/4
8/4
8/4
8/4
8/4
8/4
8/4
8/4
8/4
8/4
5/3
5/3
5/3
5/3
3/2
1/1

c3

12/4
12/4
12/4
12/4
12/4
12/4
12/4
7/3
7/3
7/3
7/3
7/3
7/3
4/2
4/2
1/1
1/1
1/1
1/1
1/1

c4

15/4
15/4
15/4
15/4
9/3
9/3
9/3
9/3
9/3
5/2
5/2
5/2
1/1
1/1
1/1
1/1
1/1
1/1
1/1
1/1

c5

15/4
15/4
15/4
9/4
9/3
9/3
9/3
9/3
4/2
4/2
4/2
4/2
4/2
4/2
4/2
4/2
1/1
1/1
1/1
1/1

c6

16/4
16/4
10/3
10/3
10/3
10/3
5/2
5/2
5/2
5/2
5/2
1/1
1/1
1/1
1/1
1/1
1/1
1/1
1/1
1/1

c7

17/4
11/3
11/3
11/3
11/3
6/2
6/2
6/2
6/2
6/2
2/1
2/1
2/1
2/1
2/1
2/1
2/1
0/0
0/0
0/0

Vote

6:7
6:6
6:5
6:4
5:7
5:6
5:3
5:5
4:4
4:7
4:6
4:4
3:3
3:2
3:3
3:5
2:7
2:2
2:2

Appendix A.  Proof of Theorem 10

In Table 11, we show the operation of Largest Fit when trying to ﬁnd a manipulation with four manipulators. This is eas-
ily seen to be optimal because the maximum score of the preferred candidate that can be achieved with three manipulators
is  35,  which  is  not  enough  to  defeat  the  1st  candidate.  Based  on  these  assignments,  we  ﬁnd  a  perfect  matching  on  the 
manipulation matrix (not shown), as described in Theorem 7. This gives the following votes for the manipulators:

(cid:7)0, 4, 2, 3, 1, 5, 6, 7(cid:8)
(cid:7)1, 0, 4, 2, 3, 6, 5, 7(cid:8)
(cid:7)0, 1, 5, 4, 6, 3, 2, 7(cid:8)
(cid:7)0, 3, 1, 6, 5, 2, 4, 7(cid:8)

In Table 12, we show the operation of Average Fit. At this point, the algorithm has yet to place a 2, but all candidates have 
gap of at most 1, so it has failed to ﬁnd a manipulation. (cid:2)

References

[1] J. Baldwin, The technique of the Nanson preferential majority system of election, Trans. Proc. R. Soc. Vic. 39 (1926) 42–52.
[2] J. Bartholdi, J. Orlin, Single transferable vote resists strategic voting, Soc. Choice Welf. 8 (4) (1991) 341–354.
[3] J. Bartholdi, C. Tovey, M. Trick, The computational diﬃculty of manipulating an election, Soc. Choice Welf. 6 (3) (1989) 227–241.
[4] J. Bartholdi, C. Tovey, M. Trick, How hard is it to control an election? Math. Comput. Model. 16 (8–9) (1992) 27–40.
[5] S. Berg, Paradox of voting under an urn model: the effect of homogeneity, Public Choice 47 (1985) 337–387.
[6] N. Betzler, B. Dorn, Towards a dichotomy of ﬁnding possible winners in elections based on scoring rules, J. Comput. Syst. Sci. 76 (8) (2010) 812–836.
[7] N. Betzler, R. Niedermeier, G. Woeginger, Unweighted coalitional manipulation under the Borda rule is NP-hard, in: Proceedings of the 22nd Interna-

tional Joint Conference on Artiﬁcial Intelligence, IJCAI-11, 2011, pp. 55–60.

[8] F. Brandt, M. Brill, E. Hemaspaandra, L. Hemaspaandra, Bypassing combinatorial protections: polynomial-time algorithms for single-peaked electorates, 

in: Proceedings of the 24th AAAI Conference on Artiﬁcial Intelligence, AAAI-10, 2010, pp. 715–722.

[9] S. Brunetti, A. Del Lungo, P. Gritzmann, S. de Vries, On the reconstruction of binary and permutation matrices under (binary) tomographic constraints, 

[10] J. Chamberlin, An investigation into the relative manipulability of four voting systems, Behav. Sci. 30 (1985) 195–203.
[11] T. Coleman, V. Teague, On the complexity of manipulating elections, in: Proceedings of the 13th Conference “Computing: The Australasian Theory 

Theor. Comput. Sci. 406 (1–2) (2008) 63–71.

Symposium”, CATS2007, 2007, pp. 25–33.

gan, 1951.

Computational Social Choice, COMSOC-10, 2010.

Artiﬁcial Intelligence, AAAI-2012, 2012.

Computation, ISAAC 2005, 2005, pp. 206–215.

[12] V. Conitzer, T. Sandholm, J. Lang, When are elections with few candidates hard to manipulate?, J. ACM 54 (3) (2007) 1–33.
[13] A.H. Copeland, A ‘reasonable’ social welfare function. Notes from a seminar on applications of mathematics to the social sciences, University of Michi-

[14] J. Davies, G. Katsirelos, N. Narodytska, T. Walsh, An empirical study of Borda manipulation, in: Proceedings of the 3rd International Workshop on 

[15] J. Davies, N. Narodytska, T. Walsh, Eliminating the weakest link: making manipulation intractable?, in: Proceedings of the 26th AAAI Conference on 

[16] E. Elkind, H. Lipmaa, Hybrid voting protocols and hardness of manipulation, in: Proceedings of 16th International Symposium on Algorithms and 

[17] P. Faliszewski, E. Hemaspaandra, L. Hemaspaandra, How hard is bribery in elections?, J. Artif. Intell. Res. 35 (1) (2009) 485–532.
[18] P. Faliszewski, E. Hemaspaandra, L. Hemaspaandra, J. Rothe, A Richer understanding of the complexity of election systems, in: Fundamental Problems 

in Computing: Essays in Honor of Professor Daniel J. Rosenkrantz, 2009, pp. 375–406.

42

J. Davies et al. / Artiﬁcial Intelligence 217 (2014) 20–42

[19] P. Faliszewski, E. Hemaspaandra, H. Schnoor, Copeland voting: ties matter, in: Proceedings of the 7th International Joint Conference on Autonomous 

[20] P. Faliszewski, E. Hemaspaandra, H. Schnoor, Manipulation of Copeland elections, in: Proceedings of the 9th International Conference on Autonomous 

Agents and Multiagent Systems, AAMAS-08, 2008, pp. 983–990.

Agents and Multiagent Systems, AAMAS-10, 2010, pp. 367–374.

[21] P. Faliszewski, A. Procaccia, AI’s war on manipulation: are we winning?, AI Mag. 31 (4) (2010) 53–64.
[22] P. Favardin, D. Lepelley, Some further results on the manipulability of social choice rules, Soc. Choice Welf. 26 (2006) 485–509.
[23] Gecode Team, Gecode: generic constraint development environment, 2006.
[24] A. Gibbard, Manipulation of voting schemes: a general result, Econometrica 41 (4) (1973) 587–601.
[25] P. Hall, On representatives of subsets, J. Lond. Math. Soc. (1935) 26–30.
[26] K. Konczak, J. Lang, Voting procedures with incomplete preferences, in: Proceedings of the IJCAI-2005 Workshop on Advances in Preference Handling, 

[27] K.L. Krause, V.Y. Shen, H.D. Schwetman, Analysis of several task-scheduling algorithms for a model of multiprogramming computer systems, J. ACM 

2005.

22 (4) (1975) 522–550.

[28] D. McGarvey, A theorem on the construction of voting paradoxes, Econometrica 21 (4) (1953) 608–610.
[29] E. Nanson, Methods of election, Trans. Proc. R. Soc. Vic. 19 (1882) 197–240.
[30] G. Nordh, A note on the hardness of Skolem-type sequences, Discrete Appl. Math. 158 (8) (2010) 63–71.
[31] G. Nordh, Personal communication, 2011.
[32] M.  Pini,  F.  Rossi,  B.  Venable,  T.  Walsh,  Incompleteness  and  incomparability  in  preference  aggregation,  in:  Proceedings  of  20th  International  Joint 

Conference on Artiﬁcial Intelligence, IJCAI-2007, 2007, pp. 1464–1469.

[33] M. Pini, F. Rossi, B. Venable, T. Walsh, Incompleteness and incomparability in preference aggregation, Artif. Intell. 175 (7–8) (2011) 1272–1289.
[34] M.A. Satterthwaite, Strategy-proofness and Arrow’s conditions: existence and correspondence theorems for voting procedures and social welfare func-

tions, J. Econ. Theory 10 (2) (1975) 187–217.

[35] T.N. Tideman, Independence of clones as a criterion for voting rules, Soc. Choice Welf. 4 (1987) 185–206.
[36] T. Walsh, Uncertainty in preference elicitation and aggregation, in: Proceedings of the 22nd AAAI Conference on Artiﬁcial Intelligence, AAAI-2007, 2007, 

pp. 3–8.

[37] T. Walsh, Where are the really hard manipulation problems? The phase transition in manipulating the veto rule, in: Proceedings of the 21st Interna-

tional Joint Conference on Artiﬁcial Intelligence, IJCAI-2009, 2009, pp. 324–329.

[38] T. Walsh, An empirical study of the manipulability of single transferable voting, in: Proceedings of the 19th European Conference on Artiﬁcial Intelli-

gence, ECAI-2010, 2010, pp. 257–262.

[39] T. Walsh, Where are the really hard manipulation problems?, J. Artif. Intell. Res. 42 (2011) 1–29.
[40] L. Xia, M. Zuckerman, A. Procaccia, V. Conitzer, J. Rosenschein, Complexity of unweighted coalitional manipulation under some common voting rules, 

in: Proceedings of the 21st International Joint Conference on Artiﬁcial Intelligence, IJCAI-2009, 2009, pp. 348–353.

[41] L. Xia, V. Conitzer, A. Procaccia, A scheduling approach to coalitional manipulation, in: Proceedings of the 11th ACM Conference on Electronic Com-

[42] W. Yu, H. Hoogeveen, J.K. Lenstra, Minimizing makespan in a two-machine ﬂow shop with delays and unit-time operations is NP-hard, J. Sched. 7 (5) 

merce, EC-2010, 2010, pp. 275–284.

(2004) 333–348.

[43] M. Zuckerman, A. Procaccia, J. Rosenschein, Algorithms for the coalitional manipulation problem, Artif. Intell. 173 (2) (2009) 392–412.

